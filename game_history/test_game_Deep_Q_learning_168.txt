 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[31.342072]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -210        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000215 

action type: buy - action -1
Learning step: -120003.1953125
desired expected reward: -120138.15625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 24.188986]
 [ 42.85084 ]
 [ 35.70314 ]
 [-35.17901 ]
 [ 44.220684]
 [ 32.265385]
 [ 38.707466]
 [ 30.4133  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 31.291580200195312



buy possibilites: [-1] 
expected returns: [[26.880226]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 44.220699310302734






Player: 1 
cards in hand: [3. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[33.829136]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.  3.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 26.880226135253906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 25.533012 ]
 [ 44.710598 ]
 [ 37.75949  ]
 [-40.666336 ]
 [ 47.975582 ]
 [ 46.36559  ]
 [ 33.639145 ]
 [ 53.840252 ]
 [  1.7493896]
 [ 40.66371  ]
 [ 31.376747 ]
 [ 31.578022 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.  3.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 33.07004928588867



buy possibilites: [-1] 
expected returns: [[33.446102]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.  3.  0.  3.  0.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 93 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 53.84025955200195






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3. 3. 3. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3. 3. 3. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 3.  3.  3.  0.  3.  0. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[26.042713]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 33.446102142333984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 18.669214]
 [ 37.978172]
 [ 30.065598]
 [-44.48346 ]
 [ 38.141273]
 [ 26.339497]
 [ 32.010464]
 [ 25.428635]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 25.048179626464844



buy possibilites: [-1] 
expected returns: [[23.48381]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0  54   0] 
sum of rewards: 19 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 38.141265869140625






Player: 1 
cards in hand: [ 0.  3. 15.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15.  0.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [29.  0.  3.  0.  0.] 
adversary cards in discard: [11.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 15.  0.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [29.  0.  3.  0.  0.] 
adversary cards in discard: [11.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 15.  0.  3.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [29.  0.  3.  0.  0.] 
adversary cards in discard: [11.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [29.  0.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[22.851208]
 [40.109173]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  0.  0.] 
cards in discard: [11.  0.  3.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  0.  3. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 23.483810424804688



action possibilites: [-1.] 
expected returns: [[25.16646]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  3.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  0.  3. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 40.04573059082031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 21.375208  ]
 [ 37.807747  ]
 [ 30.200752  ]
 [  5.1938195 ]
 [-36.39687   ]
 [ 40.80361   ]
 [ 37.83861   ]
 [ 28.91082   ]
 [ 49.73161   ]
 [ 45.616745  ]
 [ -0.96481466]
 [ 33.215416  ]
 [ 33.398933  ]
 [ 12.460739  ]
 [ 24.796684  ]
 [ 26.81744   ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  3.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  0.  3. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 25.166460037231445



buy possibilites: [-1] 
expected returns: [[55.311344]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  3.  0.  3.  0. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10.  9.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  0.  3. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 235 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 49.731597900390625






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 0.  0.  3. 15.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10.  9.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [11. 29.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25] -> size -> 14 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 0.  0.  3. 15.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10.  9.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [11. 29.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25] -> size -> 14 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 0.  0.  3. 15.  0.  3. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10.  9.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [11. 29.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25] -> size -> 14 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [11. 29.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 11.] 
expected returns: [[23.270142]
 [34.998814]
 [41.946712]
 [34.998814]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10.  9.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 55.311344146728516



action possibilites: [-1. 11. 11.] 
expected returns: [[27.756317]
 [38.98424 ]
 [38.98424 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10.  9.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 41.07188034057617



action possibilites: [-1] 
expected returns: [[32.577435]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 41.231075286865234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 28.447205]
 [ 45.34906 ]
 [ 36.629665]
 [-14.51684 ]
 [ 44.324566]
 [ 35.672047]
 [ 38.76469 ]
 [ 33.616196]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  0.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7. 10.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 32.57743453979492



buy possibilites: [-1] 
expected returns: [[57.445896]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  0.] 
cards in discard: [10.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  7. 10.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 59 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 45.34904861450195






Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  7. 10.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 25.  0.] 
adversary cards in discard: [10.  1. 29. 11.  3.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1] -> size -> 16 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  7. 10.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 25.  0.] 
adversary cards in discard: [10.  1. 29. 11.  3.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1] -> size -> 16 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[18.57611 ]
 [38.781643]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 25.  0.] 
cards in discard: [10.  1. 29. 11.  3.  0. 11.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  7. 10.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 15. 11.  0.  0.] 
adversary cards in discard: [3. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 57.44589614868164



action possibilites: [-1] 
expected returns: [[22.213022]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0. 0.] 
cards in discard: [10.  1. 29. 11.  3.  0. 11.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7. 10.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 15. 11.  0.  0.] 
adversary cards in discard: [3. 0. 0. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 38.16754913330078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 17.735518 ]
 [ 33.331417 ]
 [ 27.20443  ]
 [ -1.9023423]
 [-27.105345 ]
 [ 38.097874 ]
 [ 35.65401  ]
 [ 25.452374 ]
 [ 47.881424 ]
 [ 42.03596  ]
 [ -8.393903 ]
 [ 29.46183  ]
 [ 31.068493 ]
 [  7.3743653]
 [ 19.368237 ]
 [ 23.460756 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0. 0.] 
cards in discard: [10.  1. 29. 11.  3.  0. 11.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7. 10.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 15. 11.  0.  0.] 
adversary cards in discard: [3. 0. 0. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 22.213022232055664



buy possibilites: [-1] 
expected returns: [[26.592922]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0. 0.] 
cards in discard: [10.  1. 29. 11.  3.  0. 11.  0. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7. 10.  8.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 15. 11.  0.  0.] 
adversary cards in discard: [3. 0. 0. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 235 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 47.88143539428711






Player: 1 
cards in hand: [ 0. 15. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 11.  0.  0.] 
cards in discard: [3. 0. 0. 0. 3. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7. 10.  8.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 29.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25] -> size -> 17 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 11.  0.  0.] 
cards in discard: [3. 0. 0. 0. 3. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7. 10.  8.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 29.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25] -> size -> 17 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 11.  0.  0.] 
cards in discard: [3. 0. 0. 0. 3. 6. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 29. 30. 29. 30.  8.  9. 10.  7. 10.  8.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 29.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25] -> size -> 17 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 3. 29.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[13.120216]
 [31.475266]
 [23.730858]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0. 11.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  9. 10.  7. 10.  8.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 26.59292221069336



action possibilites: [-1. 11. 11.] 
expected returns: [[19.97577 ]
 [30.568295]
 [30.568295]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  3. 11.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8.  9. 10.  7. 10.  8.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 30.94137954711914



action possibilites: [-1] 
expected returns: [[25.049744]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 11.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8.  9. 10.  7. 10.  8.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 34.80570602416992





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 24.967865]
 [ 30.301235]
 [-27.487606]
 [ 30.032398]
 [ 28.090424]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 11.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 29. 30.  8.  9. 10.  7. 10.  8.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 25.04974365234375



buy possibilites: [-1] 
expected returns: [[36.9626]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 11.] 
cards in discard: [10.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  9. 10.  7. 10.  8.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0] -> size -> 16 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 81 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 30.301239013671875






Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8.  9. 10.  7. 10.  8.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [25.  3.  0.  0.  1.] 
adversary cards in discard: [10.  3. 29. 11.  3.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3] -> size -> 19 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 28. 30.  8.  9. 10.  7. 10.  8.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [25.  3.  0.  0.  1.] 
adversary cards in discard: [10.  3. 29. 11.  3.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3] -> size -> 19 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  7. 10.  8.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [25.  3.  0.  0.  1.] 
adversary cards in discard: [10.  3. 29. 11.  3.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3] -> size -> 19 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [25.  3.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[30.714703]
 [45.74651 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0.  0.  1.] 
cards in discard: [10.  3. 29. 11.  3.  0.  3. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  9. 10.  7. 10.  8.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 15.  3.] 
adversary cards in discard: [0. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0] -> size -> 17 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 36.96260070800781



action possibilites: [-1] 
expected returns: [[22.80784]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 1. 0. 0.] 
cards in discard: [10.  3. 29. 11.  3.  0.  3. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  8. 10.  7. 10.  8.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 15.  3.] 
adversary cards in discard: [0. 0. 0. 0. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 43.88661193847656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 16.687508]
 [ 34.55809 ]
 [ 12.868267]
 [ 26.340223]
 [ -4.141087]
 [-30.14932 ]
 [ 38.975235]
 [ 36.455433]
 [ 25.540596]
 [ 50.051888]
 [ 42.378567]
 [-10.524813]
 [ 27.469097]
 [ 30.073238]
 [  5.26485 ]
 [ 17.152193]
 [ 24.464361]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 0. 0.] 
cards in discard: [10.  3. 29. 11.  3.  0.  3. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 6 
card supply: [27. 29. 30. 28. 30.  8.  8. 10.  7. 10.  8.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 15.  3.] 
adversary cards in discard: [0. 0. 0. 0. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 22.80784034729004



buy possibilites: [-1] 
expected returns: [[7.3356643]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 0. 0.] 
cards in discard: [10.  3. 29. 11.  3.  0.  3. 11. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8.  8. 10.  7. 10.  7.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 15.  3.] 
adversary cards in discard: [0. 0. 0. 0. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.   0.   0.  30.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 107.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 50.0518913269043






Player: 1 
cards in hand: [ 0.  0.  0. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 15.  3.] 
cards in discard: [0. 0. 0. 0. 3. 3. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  8. 10.  7. 10.  7.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 25. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25] -> size -> 20 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 15.  3.] 
cards in discard: [0. 0. 0. 0. 3. 3. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 28. 30.  8.  8. 10.  7. 10.  7.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 25. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25] -> size -> 20 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 15.  3.] 
cards in discard: [0. 0. 0. 0. 3. 3. 6. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 29. 30. 28. 30.  8.  8. 10.  7. 10.  7.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 25. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25] -> size -> 20 
adversary victory points: 4
player victory points: 2 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 0. 25. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
expected returns: [[20.992243]
 [39.82344 ]
 [23.967213]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  8. 10.  7. 10.  7.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 11.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  3.  6.  0.  0.  0.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0] -> size -> 19 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 7.33566427230835



action possibilites: [-1] 
expected returns: [[1.237472]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  7. 10.  7. 10.  7.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 11.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  3.  6.  0.  0.  0.  0. 15.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6] -> size -> 20 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 38.9516487121582





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-10.921032 ]
 [  7.8136544]
 [ -1.7204833]
 [-91.19856  ]
 [ 13.30039  ]
 [ 10.216417 ]
 [  2.8319373]
 [ 18.436415 ]
 [-42.164646 ]
 [  8.225721 ]
 [ -6.4262495]
 [  2.2198477]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 28. 30.  8.  7. 10.  7. 10.  7.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 11.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  3.  6.  0.  0.  0.  0. 15.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6] -> size -> 20 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 1.2374720573425293



buy possibilites: [-1] 
expected returns: [[25.779613]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.  0. 11.] 
cards in discard: [29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  7. 10.  7. 10.  7.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 11.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  3.  6.  0.  0.  0.  0. 15.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6] -> size -> 20 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 203 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 18.43643569946289






Player: 1 
cards in hand: [ 0.  3.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 11.] 
cards in discard: [ 0.  0.  0.  0.  3.  3.  6.  0.  0.  0.  0. 15.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  7. 10.  7. 10.  7.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [25. 11. 29.  3.  0.] 
adversary cards in discard: [29. 25.  0. 10.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29] -> size -> 21 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 11.] 
cards in discard: [ 0.  0.  0.  0.  3.  3.  6.  0.  0.  0.  0. 15.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 28. 30.  8.  7. 10.  7. 10.  7.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [25. 11. 29.  3.  0.] 
adversary cards in discard: [29. 25.  0. 10.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29] -> size -> 21 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 11.] 
cards in discard: [ 0.  0.  0.  0.  3.  3.  6.  0.  0.  0.  0. 15.  3.  6. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  7. 10.  7. 10.  7.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [25. 11. 29.  3.  0.] 
adversary cards in discard: [29. 25.  0. 10.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29] -> size -> 21 
adversary victory points: 4
player victory points: 1 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [25. 11. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 29.] 
expected returns: [[41.18921 ]
 [63.196857]
 [54.682804]
 [59.3978  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11. 29.  3.  0.] 
cards in discard: [29. 25.  0. 10.  0.  0.  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  7. 10.  7. 10.  7.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11.  6.  0.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10] -> size -> 21 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 25.779613494873047



action possibilites: [-1] 
expected returns: [[15.779837]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  3.  0.  3.  0.] 
cards in discard: [29. 25.  0. 10.  0.  0.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  6. 10.  7. 10.  7.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11.  6.  0.  0.  6.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6] -> size -> 22 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 62.10396957397461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 15.235199]
 [ 24.136194]
 [-20.906246]
 [ 23.19349 ]
 [ 20.489128]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29.  3.  0.  3.  0.] 
cards in discard: [29. 25.  0. 10.  0.  0.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8.  6. 10.  7. 10.  7.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11.  6.  0.  0.  6.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6] -> size -> 22 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 15.779836654663086



buy possibilites: [-1] 
expected returns: [[25.293133]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29.  3.  0.  3.  0.] 
cards in discard: [29. 25.  0. 10.  0.  0.  0. 11.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  6. 10.  7. 10.  7.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11.  6.  0.  0.  6.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6] -> size -> 22 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 151 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 24.136219024658203






Player: 1 
cards in hand: [11.  6.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0.  0.  6.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  6. 10.  7. 10.  7.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  3.  1.  0. 25.] 
adversary cards in discard: [29. 25.  0. 10.  0.  0.  0. 11.  3. 25. 11. 29.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3] -> size -> 22 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  0.  0.  6.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 27. 30.  8.  6. 10.  7. 10.  7.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  3.  1.  0. 25.] 
adversary cards in discard: [29. 25.  0. 10.  0.  0.  0. 11.  3. 25. 11. 29.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3] -> size -> 22 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  0.  0.  6.] 
cards in discard: [6. 3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  6. 10.  7. 10.  7.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  3.  1.  0. 25.] 
adversary cards in discard: [29. 25.  0. 10.  0.  0.  0. 11.  3. 25. 11. 29.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3] -> size -> 22 
adversary victory points: 5
player victory points: 1 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  1.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[18.14553]
 [36.2154 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  1.  0. 25.] 
cards in discard: [29. 25.  0. 10.  0.  0.  0. 11.  3. 25. 11. 29.  3.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  6. 10.  7. 10.  7.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [ 6.  3. 11.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3] -> size -> 23 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 25.293132781982422



action possibilites: [-1] 
expected returns: [[-13.008377]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  1.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  5. 10.  7. 10.  7.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [ 6.  3. 11.  6.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6] -> size -> 24 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 36.215389251708984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ -22.95289  ]
 [  -4.658222 ]
 [ -10.051605 ]
 [-100.89284  ]
 [   1.2784886]
 [   0.4773531]
 [ -11.178139 ]
 [   7.822327 ]
 [ -50.321632 ]
 [  -1.6107883]
 [  -8.866618 ]
 [  -7.8643427]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  1.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 26. 30.  8.  5. 10.  7. 10.  7.  8. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [ 6.  3. 11.  6.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6] -> size -> 24 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: -13.008377075195312



buy possibilites: [-1] 
expected returns: [[12.044006]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  1.  0.  0. 10.] 
cards in discard: [29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  5. 10.  7. 10.  7.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [ 6.  3. 11.  6.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6] -> size -> 24 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 263 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 7.822343349456787






Player: 1 
cards in hand: [0. 0. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [ 6.  3. 11.  6.  0.  0.  6.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  5. 10.  7. 10.  7.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11. 29.  3.  0.  0.] 
adversary cards in discard: [29. 25.  3.  3.  1.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29] -> size -> 23 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [ 6.  3. 11.  6.  0.  0.  6.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 26. 30.  8.  5. 10.  7. 10.  7.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11. 29.  3.  0.  0.] 
adversary cards in discard: [29. 25.  3.  3.  1.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29] -> size -> 23 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [ 6.  3. 11.  6.  0.  0.  6.  6. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  5. 10.  7. 10.  7.  7. 10. 10.  7. 10.  8.] 
adversary cards in hand: [11. 29.  3.  0.  0.] 
adversary cards in discard: [29. 25.  3.  3.  1.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29] -> size -> 23 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [11. 29.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[14.858154]
 [24.23494 ]
 [29.150223]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  3.  0.  0.] 
cards in discard: [29. 25.  3.  3.  1.  0.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  5. 10.  7. 10.  7.  7. 10. 10.  7. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [ 6.  3. 11.  6.  0.  0.  6.  6. 15.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15] -> size -> 25 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 12.04400634765625



action possibilites: [-1. 11.] 
expected returns: [[24.40192 ]
 [36.136047]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0.  3.] 
cards in discard: [29. 25.  3.  3.  1.  0.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 26. 30.  8.  5. 10.  7. 10.  7.  7. 10. 10.  7. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [ 6.  3. 11.  6.  0.  0.  6.  6. 15.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15] -> size -> 25 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 29.052261352539062



action possibilites: [-1] 
expected returns: [[15.242527]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [29. 25.  3.  3.  1.  0.  0. 10. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 26. 30.  8.  5. 10.  7. 10.  7.  7. 10. 10.  6. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [ 6.  3. 11.  6.  0.  0.  6.  6. 15.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15] -> size -> 25 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 212 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 37.80681610107422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 11.9855385]
 [ 26.035143 ]
 [ 20.083048 ]
 [-20.485668 ]
 [ 27.099094 ]
 [ 17.833912 ]
 [ 22.027388 ]
 [ 16.53017  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [29. 25.  3.  3.  1.  0.  0. 10. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 26. 30.  8.  5. 10.  7. 10.  7.  7. 10. 10.  6. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [ 6.  3. 11.  6.  0.  0.  6.  6. 15.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15] -> size -> 25 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: 15.24252700805664



buy possibilites: [-1] 
expected returns: [[29.667004]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [29. 25.  3.  3.  1.  0.  0. 10. 10. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  5. 10.  6. 10.  7.  7. 10. 10.  6. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [ 6.  3. 11.  6.  0.  0.  6.  6. 15.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15] -> size -> 25 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 239 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 27.099117279052734






Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [ 6.  3. 11.  6.  0.  0.  6.  6. 15.  0.  0.  0.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  5. 10.  6. 10.  7.  7. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0. 11. 25.  0.] 
adversary cards in discard: [29. 25.  3.  3.  1.  0.  0. 10. 10. 11. 29. 11.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10
 11] -> size -> 25 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [ 6.  3. 11.  6.  0.  0.  6.  6. 15.  0.  0.  0.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 26. 30.  8.  5. 10.  6. 10.  7.  7. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0. 11. 25.  0.] 
adversary cards in discard: [29. 25.  3.  3.  1.  0.  0. 10. 10. 11. 29. 11.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10
 11] -> size -> 25 
adversary victory points: 5
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 11. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[60.72189 ]
 [67.7171  ]
 [78.795456]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11. 25.  0.] 
cards in discard: [29. 25.  3.  3.  1.  0.  0. 10. 10. 11. 29. 11.  3.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  5. 10.  6. 10.  7.  7. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  3. 10.  0.  0.] 
adversary cards in discard: [ 6.  3. 11.  6.  0.  0.  6.  6. 15.  0.  0.  0.  0.  6.  0.  3.  0.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15] -> size -> 25 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 29.667003631591797



action possibilites: [-1] 
expected returns: [[3.2606587]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0. 25. 29.] 
cards in discard: [29. 25.  3.  3.  1.  0.  0. 10. 10. 11. 29. 11.  3.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  4. 10.  6. 10.  7.  7. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  3. 10.  0.  0.] 
adversary cards in discard: [ 6.  3. 11.  6.  0.  0.  6.  6. 15.  0.  0.  0.  0.  6.  0.  3.  0.  0.
  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6] -> size -> 26 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 78.79544830322266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ -3.9375262]
 [  4.87587  ]
 [-77.31663  ]
 [  6.818496 ]
 [  6.3133044]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  0. 25. 29.] 
cards in discard: [29. 25.  3.  3.  1.  0.  0. 10. 10. 11. 29. 11.  3.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 26. 30.  8.  4. 10.  6. 10.  7.  7. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  3. 10.  0.  0.] 
adversary cards in discard: [ 6.  3. 11.  6.  0.  0.  6.  6. 15.  0.  0.  0.  0.  6.  0.  3.  0.  0.
  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6] -> size -> 26 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 3.2606587409973145



buy possibilites: [-1] 
expected returns: [[-14.695707]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  0. 25. 29.] 
cards in discard: [29. 25.  3.  3.  1.  0.  0. 10. 10. 11. 29. 11.  3.  0.  0.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10
 11  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  4. 10.  6.  9.  7.  7. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  3. 10.  0.  0.] 
adversary cards in discard: [ 6.  3. 11.  6.  0.  0.  6.  6. 15.  0.  0.  0.  0.  6.  0.  3.  0.  0.
  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6] -> size -> 26 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 181 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 6.81847620010376






Player: 1 
cards in hand: [ 3.  3. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.  0.  0.] 
cards in discard: [ 6.  3. 11.  6.  0.  0.  6.  6. 15.  0.  0.  0.  0.  6.  0.  3.  0.  0.
  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  4. 10.  6.  9.  7.  7. 10. 10.  6. 10.  8.] 
adversary cards in hand: [29.  0.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10
 11  8] -> size -> 26 
adversary victory points: 5
player victory points: -1 


action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  0. 15.] 
cards in discard: [ 6.  3. 11.  6.  0.  0.  6.  6. 15.  0.  0.  0.  0.  6.  0.  3.  0.  0.
  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  4. 10.  6.  9.  7.  7. 10. 10.  6. 10.  8.] 
adversary cards in hand: [29.  0.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10
 11  8] -> size -> 26 
adversary victory points: 5
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  0. 15.] 
cards in discard: [ 6.  3. 11.  6.  0.  0.  6.  6. 15.  0.  0.  0.  0.  6.  0.  3.  0.  0.
  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 26. 30.  8.  4. 10.  6.  9.  7.  7. 10. 10.  6. 10.  8.] 
adversary cards in hand: [29.  0.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10
 11  8] -> size -> 26 
adversary victory points: 5
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  0. 15.] 
cards in discard: [ 6.  3. 11.  6.  0.  0.  6.  6. 15.  0.  0.  0.  0.  6.  0.  3.  0.  0.
  3.  6.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  6.  9.  7.  7. 10. 10.  6. 10.  8.] 
adversary cards in hand: [29.  0.  3. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10
 11  8] -> size -> 26 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [29.  0.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[ 7.4065194]
 [21.421753 ]
 [11.624655 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3. 10.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10
 11  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  6.  9.  7.  7. 10. 10.  6. 10.  8.] 
adversary cards in hand: [0. 6. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3] -> size -> 27 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.695707321166992



action possibilites: [-1. 10.] 
expected returns: [[23.812536]
 [23.648928]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10
 11  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  6.  9.  7.  7. 10. 10.  6. 10.  8.] 
adversary cards in hand: [0. 6. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3] -> size -> 27 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 20.040639877319336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[  0.1446042]
 [ 13.302883 ]
 [  4.182031 ]
 [-65.55852  ]
 [ 29.469498 ]
 [ 24.549582 ]
 [ 14.493195 ]
 [ 36.74183  ]
 [-26.052025 ]
 [ 24.368185 ]
 [  3.0219007]
 [ 25.539003 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10
 11  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  6.  9.  7.  7. 10. 10.  6. 10.  8.] 
adversary cards in hand: [0. 6. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3] -> size -> 27 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 23.812532424926758



buy possibilites: [-1] 
expected returns: [[7.4857745]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0.  0.] 
cards in discard: [29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10
 11  8 29] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  6.  9.  7.  6. 10. 10.  6. 10.  8.] 
adversary cards in hand: [0. 6. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3] -> size -> 27 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 293 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 36.7418327331543






Player: 1 
cards in hand: [0. 6. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 6. 3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  6.  9.  7.  6. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 10.  8.  0.  0.] 
adversary cards in discard: [29. 29.  0.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10
 11  8 29] -> size -> 27 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6. 3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 25. 30.  8.  4. 10.  6.  9.  7.  6. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 10.  8.  0.  0.] 
adversary cards in discard: [29. 29.  0.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10
 11  8 29] -> size -> 27 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6. 3.] 
cards in discard: [0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 25. 30.  8.  4. 10.  6.  9.  7.  6. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 10.  8.  0.  0.] 
adversary cards in discard: [29. 29.  0.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10
 11  8 29] -> size -> 27 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 3. 10.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[14.298853]
 [21.46911 ]
 [15.531324]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  8.  0.  0.] 
cards in discard: [29. 29.  0.  3. 10.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10
 11  8 29] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  4. 10.  6.  9.  7.  6. 10. 10.  6. 10.  8.] 
adversary cards in hand: [3. 0. 6. 6. 3.] 
adversary cards in discard: [0. 0. 6. 0. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0] -> size -> 28 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 7.485774517059326



action possibilites: [-1.  8. 25.] 
expected returns: [[12.52079 ]
 [14.374607]
 [31.25335 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0.  0. 25.] 
cards in discard: [29. 29.  0.  3. 10.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10
 11  8 29] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  4. 10.  6.  9.  7.  6. 10. 10.  6. 10.  8.] 
adversary cards in hand: [3. 0. 6. 6. 3.] 
adversary cards in discard: [0. 0. 6. 0. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0] -> size -> 28 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 21.46912384033203



action possibilites: [-1.  8. 29. 29.] 
expected returns: [[-3.612109 ]
 [-2.3363037]
 [ 9.005299 ]
 [ 9.005299 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0.  0. 29. 29.] 
cards in discard: [29. 29.  0.  3. 10.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10
 11  8 29] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  3. 10.  6.  9.  7.  6. 10. 10.  6. 10.  8.] 
adversary cards in hand: [3. 0. 6. 6. 3.] 
adversary cards in discard: [0. 0. 6. 0. 6. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6] -> size -> 29 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 31.25335693359375



action possibilites: [-1.  8. 29.] 
expected returns: [[25.147629]
 [28.173946]
 [39.568447]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0.  0. 29.  3.] 
cards in discard: [29. 29.  0.  3. 10.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 25. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10
 11  8 29] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 25. 30.  8.  3. 10.  6.  9.  7.  6. 10. 10.  6. 10.  8.] 
adversary cards in hand: [3. 0. 6. 6. 3.] 
adversary cards in discard: [0. 0. 6. 0. 6. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6] -> size -> 29 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 9.005300521850586



action possibilites: [-1.  8. 25.] 
expected returns: [[23.044388]
 [24.671642]
 [38.04953 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0.  0.  3. 25.] 
cards in discard: [29. 29.  0.  3. 10.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 25. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10
 11  8 29] -> size -> 27 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 25. 30.  8.  3. 10.  6.  9.  7.  6. 10. 10.  6. 10.  8.] 
adversary cards in hand: [3. 0. 6. 6. 3.] 
adversary cards in discard: [0. 0. 6. 0. 6. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6] -> size -> 29 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 39.56846618652344



action possibilites: [-1] 
expected returns: [[45.855106]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0. 3. 0. 0.] 
cards in discard: [29. 29.  0.  3. 10.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 25. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10
 11  8 29] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 25. 30.  8.  2. 10.  6.  9.  7.  6. 10. 10.  6. 10.  8.] 
adversary cards in hand: [3. 0. 6. 6. 3.] 
adversary cards in discard: [0. 0. 6. 0. 6. 3. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6] -> size -> 30 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 38.049537658691406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 41.295444]
 [ 55.999912]
 [ 40.028023]
 [ 51.00488 ]
 [ 26.116457]
 [-11.210329]
 [ 58.135784]
 [ 58.215282]
 [ 46.63491 ]
 [ 67.0319  ]
 [ 61.502445]
 [ 21.29781 ]
 [ 53.147026]
 [ 52.942184]
 [ 35.075123]
 [ 44.02484 ]
 [ 46.02381 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 3. 0. 0.] 
cards in discard: [29. 29.  0.  3. 10.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 25. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10
 11  8 29] -> size -> 27 
action values: 0 
buys: 1 
player value: 6 
card supply: [25. 29. 30. 25. 30.  8.  2. 10.  6.  9.  7.  6. 10. 10.  6. 10.  8.] 
adversary cards in hand: [3. 0. 6. 6. 3.] 
adversary cards in discard: [0. 0. 6. 0. 6. 3. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6] -> size -> 30 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action -1
Learning step: 0
desired expected reward: 45.855106353759766



buy possibilites: [-1] 
expected returns: [[60.24349]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 3. 0. 0.] 
cards in discard: [29. 29.  0.  3. 10.  0.  0. 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 25. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10
 11  8 29 25] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 25. 30.  8.  2. 10.  6.  9.  6.  6. 10. 10.  6. 10.  8.] 
adversary cards in hand: [3. 0. 6. 6. 3.] 
adversary cards in discard: [0. 0. 6. 0. 6. 3. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6] -> size -> 30 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5.    0.    0.  150.    0.    0.  100.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 307.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 67.03190612792969






Player: 1 
cards in hand: [3. 0. 6. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 6. 3.] 
cards in discard: [0. 0. 6. 0. 6. 3. 6. 6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  2. 10.  6.  9.  6.  6. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  1. 11. 11.  3.] 
adversary cards in discard: [29. 29.  0.  3. 10.  0.  0. 25. 10. 25. 29. 29. 25.  3.  8.  0.  0.  3.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10
 11  8 29 25] -> size -> 28 
adversary victory points: 5
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 6. 3.] 
cards in discard: [0. 0. 6. 0. 6. 3. 6. 6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 25. 30.  8.  2. 10.  6.  9.  6.  6. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  1. 11. 11.  3.] 
adversary cards in discard: [29. 29.  0.  3. 10.  0.  0. 25. 10. 25. 29. 29. 25.  3.  8.  0.  0.  3.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10
 11  8 29 25] -> size -> 28 
adversary victory points: 5
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 6. 3.] 
cards in discard: [0. 0. 6. 0. 6. 3. 6. 6. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 25. 30.  8.  2. 10.  6.  9.  6.  6. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  1. 11. 11.  3.] 
adversary cards in discard: [29. 29.  0.  3. 10.  0.  0. 25. 10. 25. 29. 29. 25.  3.  8.  0.  0.  3.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10
 11  8 29 25] -> size -> 28 
adversary victory points: 5
player victory points: -2 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 3.  1. 11. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[-13.0578575]
 [ -5.2693634]
 [ -5.2693634]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 11. 11.  3.] 
cards in discard: [29. 29.  0.  3. 10.  0.  0. 25. 10. 25. 29. 29. 25.  3.  8.  0.  0.  3.
  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10
 11  8 29 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 25. 30.  8.  2. 10.  6.  9.  6.  6. 10. 10.  6. 10.  8.] 
adversary cards in hand: [0. 6. 0. 3. 3.] 
adversary cards in discard: [0. 0. 6. 0. 6. 3. 6. 6. 0. 3. 0. 6. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0] -> size -> 31 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 60.24348831176758



action possibilites: [-1] 
expected returns: [[40.90005]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 11.  3.] 
cards in discard: [29. 29.  0.  3. 10.  0.  0. 25. 10. 25. 29. 29. 25.  3.  8.  0.  0.  3.
  0.  0. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10
 11  8 29 25 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 25. 30.  8.  2. 10.  6.  9.  6.  6. 10. 10.  6. 10.  7.] 
adversary cards in hand: [0. 6. 0. 3. 3.] 
adversary cards in discard: [0. 0. 6. 0. 6. 3. 6. 6. 0. 3. 0. 6. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0] -> size -> 31 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 289 

action type: gain_card_n - action 10
Learning step: 0
desired expected reward: -5.913448333740234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 28.564713]
 [ 43.576645]
 [-13.969578]
 [ 39.708782]
 [ 41.581833]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 11.  3.] 
cards in discard: [29. 29.  0.  3. 10.  0.  0. 25. 10. 25. 29. 29. 25.  3.  8.  0.  0.  3.
  0.  0. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10
 11  8 29 25 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 25. 30.  8.  2. 10.  6.  9.  6.  6. 10. 10.  6. 10.  7.] 
adversary cards in hand: [0. 6. 0. 3. 3.] 
adversary cards in discard: [0. 0. 6. 0. 6. 3. 6. 6. 0. 3. 0. 6. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0] -> size -> 31 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 40.90005111694336



buy possibilites: [-1] 
expected returns: [[33.691166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 11.  3.] 
cards in discard: [29. 29.  0.  3. 10.  0.  0. 25. 10. 25. 29. 29. 25.  3.  8.  0.  0.  3.
  0.  0. 15.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10
 11  8 29 25 15  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 30.  8.  2. 10.  6.  9.  6.  6. 10. 10.  6. 10.  7.] 
adversary cards in hand: [0. 6. 0. 3. 3.] 
adversary cards in discard: [0. 0. 6. 0. 6. 3. 6. 6. 0. 3. 0. 6. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0] -> size -> 31 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 271 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 43.57664108276367






Player: 1 
cards in hand: [0. 6. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 3. 3.] 
cards in discard: [0. 0. 6. 0. 6. 3. 6. 6. 0. 3. 0. 6. 6. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 30.  8.  2. 10.  6.  9.  6.  6. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 3. 10. 25. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10
 11  8 29 25 15  3] -> size -> 30 
adversary victory points: 6
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3. 3.] 
cards in discard: [0. 0. 6. 0. 6. 3. 6. 6. 0. 3. 0. 6. 6. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 24. 30.  8.  2. 10.  6.  9.  6.  6. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 3. 10. 25. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10
 11  8 29 25 15  3] -> size -> 30 
adversary victory points: 6
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3. 3.] 
cards in discard: [0. 0. 6. 0. 6. 3. 6. 6. 0. 3. 0. 6. 6. 3. 8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 30.  8.  2. 10.  6.  8.  6.  6. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 3. 10. 25. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10
 11  8 29 25 15  3] -> size -> 30 
adversary victory points: 6
player victory points: -2 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 25. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 11. 10.] 
expected returns: [[ 5.5090795]
 [10.482815 ]
 [25.354053 ]
 [15.279255 ]
 [10.482815 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 25. 11. 10.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10
 11  8 29 25 15  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 30.  8.  2. 10.  6.  8.  6.  6. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  0.  0. 15. 10.] 
adversary cards in discard: [0. 0. 6. 0. 6. 3. 6. 6. 0. 3. 0. 6. 6. 3. 8. 0. 6. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0  8] -> size -> 32 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 33.691165924072266



action possibilites: [-1] 
expected returns: [[-11.536511]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11. 10. 25.  3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10
 11  8 29 25 15  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 30.  8.  1. 10.  6.  8.  6.  6. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  0.  0. 15. 10.] 
adversary cards in discard: [0. 0. 6. 0. 6. 3. 6. 6. 0. 3. 0. 6. 6. 3. 8. 0. 6. 0. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0  8  6] -> size -> 33 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 25.35405921936035





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-29.524796]
 [-85.27181 ]
 [ -9.110971]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 11. 10. 25.  3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10
 11  8 29 25 15  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 29. 30. 24. 30.  8.  1. 10.  6.  8.  6.  6. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  0.  0. 15. 10.] 
adversary cards in discard: [0. 0. 6. 0. 6. 3. 6. 6. 0. 3. 0. 6. 6. 3. 8. 0. 6. 0. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0  8  6] -> size -> 33 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: -11.536511421203613






Player: 1 
cards in hand: [ 0.  0.  0. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 15. 10.] 
cards in discard: [0. 0. 6. 0. 6. 3. 6. 6. 0. 3. 0. 6. 6. 3. 8. 0. 6. 0. 3. 3. 6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0  8  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 30.  8.  1. 10.  6.  8.  6.  6. 10. 10.  6. 10.  7.] 
adversary cards in hand: [29.  3. 29.  0.  0.] 
adversary cards in discard: [25.  3. 10. 11. 10. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10
 11  8 29 25 15  3] -> size -> 30 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 15. 10.] 
cards in discard: [0. 0. 6. 0. 6. 3. 6. 6. 0. 3. 0. 6. 6. 3. 8. 0. 6. 0. 3. 3. 6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0  8  6] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 29. 30. 24. 30.  8.  1. 10.  6.  8.  6.  6. 10. 10.  6. 10.  7.] 
adversary cards in hand: [29.  3. 29.  0.  0.] 
adversary cards in discard: [25.  3. 10. 11. 10. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10
 11  8 29 25 15  3] -> size -> 30 
adversary victory points: 6
player victory points: -3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [29.  3. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[-6.510582]
 [ 8.253696]
 [ 8.253696]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 29.  0.  0.] 
cards in discard: [25.  3. 10. 11. 10. 25.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10
 11  8 29 25 15  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 30.  8.  1. 10.  6.  8.  6.  6. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 3. 15.  0.  6. 11.] 
adversary cards in discard: [ 0.  0.  6.  0.  6.  3.  6.  6.  0.  3.  0.  6.  6.  3.  8.  0.  6.  0.
  3.  3.  6.  0.  0.  0. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0  8  6] -> size -> 33 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -9.110965728759766



action possibilites: [-1. 29.] 
expected returns: [[-10.047413 ]
 [  5.7027793]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  0.  0.] 
cards in discard: [25.  3. 10. 11. 10. 25.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10
 11  8 29 25 15  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 24. 30.  8.  1. 10.  6.  8.  6.  6. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 3. 15.  0.  6. 11.] 
adversary cards in discard: [ 0.  0.  6.  0.  6.  3.  6.  6.  0.  3.  0.  6.  6.  3.  8.  0.  6.  0.
  3.  3.  6.  0.  0.  0. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0  8  6] -> size -> 33 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 8.25373649597168



action possibilites: [-1.  8.] 
expected returns: [[3.9910703]
 [5.1164136]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 8.] 
cards in discard: [25.  3. 10. 11. 10. 25.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10
 11  8 29 25 15  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 2 
card supply: [24. 29. 30. 24. 30.  8.  1. 10.  6.  8.  6.  6. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 3. 15.  0.  6. 11.] 
adversary cards in discard: [ 0.  0.  6.  0.  6.  3.  6.  6.  0.  3.  0.  6.  6.  3.  8.  0.  6.  0.
  3.  3.  6.  0.  0.  0. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0  8  6] -> size -> 33 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 5.702817440032959



action possibilites: [-1] 
expected returns: [[20.6604]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [25.  3. 10. 11. 10. 25.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 29. 30. 24. 30.  8.  1. 10.  6.  8.  6.  6. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 3. 15.  0.  6. 11.] 
adversary cards in discard: [ 0.  0.  6.  0.  6.  3.  6.  6.  0.  3.  0.  6.  6.  3.  8.  0.  6.  0.
  3.  3.  6.  0.  0.  0. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0  8  6] -> size -> 33 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: trash_cards_n_from_hand - action 5
Learning step: 0
desired expected reward: 15.571159362792969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 17.215897]
 [ 23.15008 ]
 [-33.49994 ]
 [ 22.818098]
 [ 20.945862]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [25.  3. 10. 11. 10. 25.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 24. 30.  8.  1. 10.  6.  8.  6.  6. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 3. 15.  0.  6. 11.] 
adversary cards in discard: [ 0.  0.  6.  0.  6.  3.  6.  6.  0.  3.  0.  6.  6.  3.  8.  0.  6.  0.
  3.  3.  6.  0.  0.  0. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0  8  6] -> size -> 33 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: take_action - action -1
Learning step: 0
desired expected reward: 20.660400390625



buy possibilites: [-1] 
expected returns: [[8.197542]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [25.  3. 10. 11. 10. 25.  3.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 23. 30.  8.  1. 10.  6.  8.  6.  6. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 3. 15.  0.  6. 11.] 
adversary cards in discard: [ 0.  0.  6.  0.  6.  3.  6.  6.  0.  3.  0.  6.  6.  3.  8.  0.  6.  0.
  3.  3.  6.  0.  0.  0. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0  8  6] -> size -> 33 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  60   0   0   0   0   0   0   0  16   0] 
sum of rewards: 371 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 23.150074005126953






Player: 1 
cards in hand: [ 3. 15.  0.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0.  6. 11.] 
cards in discard: [ 0.  0.  6.  0.  6.  3.  6.  6.  0.  3.  0.  6.  6.  3.  8.  0.  6.  0.
  3.  3.  6.  0.  0.  0. 15. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0  8  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 23. 30.  8.  1. 10.  6.  8.  6.  6. 10. 10.  6. 10.  7.] 
adversary cards in hand: [25.  0.  0.  0.  3.] 
adversary cards in discard: [25.  3. 10. 11. 10. 25.  3.  3. 29. 29.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3] -> size -> 28 
adversary victory points: 7
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0.  6.] 
cards in discard: [ 0.  0.  6.  0.  6.  3.  6.  6.  0.  3.  0.  6.  6.  3.  8.  0.  6.  0.
  3.  3.  6.  0.  0.  0. 15. 10. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0  8  6 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 23. 30.  8.  1. 10.  5.  8.  6.  6. 10. 10.  6. 10.  7.] 
adversary cards in hand: [25.  0.  0.  0.  3.] 
adversary cards in discard: [25.  3. 10. 11. 10. 25.  3.  3. 29. 29.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3] -> size -> 28 
adversary victory points: 7
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  0.  6.] 
cards in discard: [ 0.  0.  6.  0.  6.  3.  6.  6.  0.  3.  0.  6.  6.  3.  8.  0.  6.  0.
  3.  3.  6.  0.  0.  0. 15. 10. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0  8  6 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 29. 30. 23. 30.  8.  1. 10.  5.  8.  6.  6. 10. 10.  6. 10.  7.] 
adversary cards in hand: [25.  0.  0.  0.  3.] 
adversary cards in discard: [25.  3. 10. 11. 10. 25.  3.  3. 29. 29.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3] -> size -> 28 
adversary victory points: 7
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  0.  6.] 
cards in discard: [ 0.  0.  6.  0.  6.  3.  6.  6.  0.  3.  0.  6.  6.  3.  8.  0.  6.  0.
  3.  3.  6.  0.  0.  0. 15. 10. 11.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0  8  6 11  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 23. 30.  8.  1. 10.  5.  8.  6.  6. 10. 10.  6. 10.  7.] 
adversary cards in hand: [25.  0.  0.  0.  3.] 
adversary cards in discard: [25.  3. 10. 11. 10. 25.  3.  3. 29. 29.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3] -> size -> 28 
adversary victory points: 7
player victory points: -3 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [25.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[ 6.9956155]
 [26.646954 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.  0.  3.] 
cards in discard: [25.  3. 10. 11. 10. 25.  3.  3. 29. 29.  8.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 23. 30.  8.  1. 10.  5.  8.  6.  6. 10. 10.  6. 10.  7.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0  8  6 11  0] -> size -> 35 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 8.197542190551758



action possibilites: [-1] 
expected returns: [[-10.462723]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 10. 25.] 
cards in discard: [25.  3. 10. 11. 10. 25.  3.  3. 29. 29.  8.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 23. 30.  8.  0. 10.  5.  8.  6.  6. 10. 10.  6. 10.  7.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0  8  6 11  0  6] -> size -> 36 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 26.64694595336914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-26.665697 ]
 [-12.26247  ]
 [-17.045809 ]
 [  2.2464046]
 [-12.418232 ]
 [  2.0591745]
 [ -1.6762319]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 10. 25.] 
cards in discard: [25.  3. 10. 11. 10. 25.  3.  3. 29. 29.  8.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 29. 30. 23. 30.  8.  0. 10.  5.  8.  6.  6. 10. 10.  6. 10.  7.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0  8  6 11  0  6] -> size -> 36 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: -10.462722778320312



buy possibilites: [-1] 
expected returns: [[10.6064]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 10. 25.] 
cards in discard: [25.  3. 10. 11. 10. 25.  3.  3. 29. 29.  8.  3. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 23. 30.  8.  0. 10.  4.  8.  6.  6. 10. 10.  6. 10.  7.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0  8  6 11  0  6] -> size -> 36 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 369 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 2.2463879585266113






Player: 1 
cards in hand: [11.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [6.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0  8  6 11  0  6] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 23. 30.  8.  0. 10.  4.  8.  6.  6. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 3. 11. 29. 11.  1.] 
adversary cards in discard: [25.  3. 10. 11. 10. 25.  3.  3. 29. 29.  8.  3. 11. 25.  0.  0.  0.  3.
 10. 25.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11] -> size -> 29 
adversary victory points: 7
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 6. 15.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0  8  6 11  0  6 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 23. 30.  8.  0. 10.  4.  8.  6.  6. 10. 10.  6. 10.  6.] 
adversary cards in hand: [ 3. 11. 29. 11.  1.] 
adversary cards in discard: [25.  3. 10. 11. 10. 25.  3.  3. 29. 29.  8.  3. 11. 25.  0.  0.  0.  3.
 10. 25.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11] -> size -> 29 
adversary victory points: 7
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 6. 15.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0  8  6 11  0  6 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 29. 30. 23. 30.  8.  0. 10.  4.  8.  6.  6. 10. 10.  6. 10.  6.] 
adversary cards in hand: [ 3. 11. 29. 11.  1.] 
adversary cards in discard: [25.  3. 10. 11. 10. 25.  3.  3. 29. 29.  8.  3. 11. 25.  0.  0.  0.  3.
 10. 25.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11] -> size -> 29 
adversary victory points: 7
player victory points: -4 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 3. 11. 29. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 11.] 
expected returns: [[-51.51792 ]
 [-44.933384]
 [-38.78741 ]
 [-44.933384]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 29. 11.  1.] 
cards in discard: [25.  3. 10. 11. 10. 25.  3.  3. 29. 29.  8.  3. 11. 25.  0.  0.  0.  3.
 10. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 23. 30.  8.  0. 10.  4.  8.  6.  6. 10. 10.  6. 10.  6.] 
adversary cards in hand: [6. 0. 0. 6. 6.] 
adversary cards in discard: [ 6. 15. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0  8  6 11  0  6 15] -> size -> 37 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 10.606399536132812



action possibilites: [-1. 11. 11. 29.] 
expected returns: [[40.007782]
 [46.652843]
 [46.652843]
 [51.228344]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 11. 29.] 
cards in discard: [25.  3. 10. 11. 10. 25.  3.  3. 29. 29.  8.  3. 11. 25.  0.  0.  0.  3.
 10. 25.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 23. 30.  8.  0. 10.  4.  8.  6.  6. 10. 10.  6. 10.  6.] 
adversary cards in hand: [6. 0. 0. 6. 6.] 
adversary cards in discard: [ 6. 15. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0  8  6 11  0  6 15] -> size -> 37 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -46.13324737548828



action possibilites: [-1. 11. 11.] 
expected returns: [[46.343365]
 [58.082813]
 [58.082813]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 11.] 
cards in discard: [25.  3. 10. 11. 10. 25.  3.  3. 29. 29.  8.  3. 11. 25.  0.  0.  0.  3.
 10. 25.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 2 
card supply: [23. 29. 30. 23. 30.  8.  0. 10.  4.  8.  6.  6. 10. 10.  6. 10.  6.] 
adversary cards in hand: [6. 0. 0. 6. 6.] 
adversary cards in discard: [ 6. 15. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0  8  6 11  0  6 15] -> size -> 37 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 365 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 47.571922302246094



action possibilites: [-1] 
expected returns: [[16.058401]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.] 
cards in discard: [25.  3. 10. 11. 10. 25.  3.  3. 29. 29.  8.  3. 11. 25.  0.  0.  0.  3.
 10. 25.  1.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 29. 30. 23. 30.  8.  0. 10.  4.  7.  6.  6. 10. 10.  6. 10.  6.] 
adversary cards in hand: [6. 0. 0. 6. 6.] 
adversary cards in discard: [ 6. 15. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0  8  6 11  0  6 15] -> size -> 37 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0  60   0   0   0   0   0   0   0   8   0] 
sum of rewards: 393 

action type: gain_card_n - action 5
Learning step: 0
desired expected reward: 58.10011672973633





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 7.975346]
 [13.925138]
 [14.066437]
 [16.55706 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.] 
cards in discard: [25.  3. 10. 11. 10. 25.  3.  3. 29. 29.  8.  3. 11. 25.  0.  0.  0.  3.
 10. 25.  1.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 23. 30.  8.  0. 10.  4.  7.  6.  6. 10. 10.  6. 10.  6.] 
adversary cards in hand: [6. 0. 0. 6. 6.] 
adversary cards in discard: [ 6. 15. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0  8  6 11  0  6 15] -> size -> 37 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: take_action - action -1
Learning step: 0
desired expected reward: 16.058401107788086






Player: 1 
cards in hand: [6. 0. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 6. 6.] 
cards in discard: [ 6. 15. 11.  0.  0.  0.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0  8  6 11  0  6 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 23. 30.  8.  0. 10.  4.  7.  6.  6. 10. 10.  6. 10.  6.] 
adversary cards in hand: [25. 11.  8.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8] -> size -> 30 
adversary victory points: 7
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 6. 6.] 
cards in discard: [ 6. 15. 11.  0.  0.  0.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0  8  6 11  0  6 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 23. 30.  8.  0. 10.  4.  7.  6.  6. 10. 10.  6. 10.  6.] 
adversary cards in hand: [25. 11.  8.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8] -> size -> 30 
adversary victory points: 7
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 6. 6.] 
cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0  8  6 11  0  6 15  8] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 23. 30.  8.  0. 10.  4.  6.  6.  6. 10. 10.  6. 10.  6.] 
adversary cards in hand: [25. 11.  8.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8] -> size -> 30 
adversary victory points: 7
player victory points: -4 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [25. 11.  8.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.  8. 15.] 
expected returns: [[-11.660475  ]
 [  0.24173498]
 [ -8.730518  ]
 [-14.569826  ]
 [-20.068853  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11.  8.  3. 15.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 23. 30.  8.  0. 10.  4.  6.  6.  6. 10. 10.  6. 10.  6.] 
adversary cards in hand: [0. 6. 6. 3. 3.] 
adversary cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  8.  6.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0  8  6 11  0  6 15  8] -> size -> 38 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 16.557048797607422



action possibilites: [-1] 
expected returns: [[-9.412682]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  3. 15.  0. 29.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 23. 30.  8.  0. 10.  4.  6.  6.  6. 10. 10.  6. 10.  6.] 
adversary cards in hand: [0. 6. 6. 3. 3.] 
adversary cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  8.  6.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0  8  6 11  0  6 15  8] -> size -> 38 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 0.24173307418823242





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-29.629519]
 [-10.650011]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  3. 15.  0. 29.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 29. 30. 23. 30.  8.  0. 10.  4.  6.  6.  6. 10. 10.  6. 10.  6.] 
adversary cards in hand: [0. 6. 6. 3. 3.] 
adversary cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  8.  6.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0  8  6 11  0  6 15  8] -> size -> 38 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: -9.412681579589844






Player: 1 
cards in hand: [0. 6. 6. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 3. 3.] 
cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  8.  6.  0.  0.  6.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0  8  6 11  0  6 15  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 23. 30.  8.  0. 10.  4.  6.  6.  6. 10. 10.  6. 10.  6.] 
adversary cards in hand: [ 3. 25.  0. 11. 10.] 
adversary cards in discard: [25. 11.  8.  3. 15.  0. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8] -> size -> 30 
adversary victory points: 7
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 3. 3.] 
cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  8.  6.  0.  0.  6.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0  8  6 11  0  6 15  8] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 29. 30. 23. 30.  8.  0. 10.  4.  6.  6.  6. 10. 10.  6. 10.  6.] 
adversary cards in hand: [ 3. 25.  0. 11. 10.] 
adversary cards in discard: [25. 11.  8.  3. 15.  0. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8] -> size -> 30 
adversary victory points: 7
player victory points: -4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 3. 25.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 10.] 
expected returns: [[-18.102686]
 [  2.020516]
 [ -9.635386]
 [-14.676699]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  0. 11. 10.] 
cards in discard: [25. 11.  8.  3. 15.  0. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 23. 30.  8.  0. 10.  4.  6.  6.  6. 10. 10.  6. 10.  6.] 
adversary cards in hand: [ 0. 15.  0. 11.  0.] 
adversary cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  8.  6.  0.  0.  6.  6.  0.  6.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0  8  6 11  0  6 15  8] -> size -> 38 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -10.649965286254883



action possibilites: [-1] 
expected returns: [[-1.1311808]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11. 10. 29.  0.] 
cards in discard: [25. 11.  8.  3. 15.  0. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 23. 30.  8.  0. 10.  4.  6.  6.  6. 10. 10.  6. 10.  6.] 
adversary cards in hand: [ 0. 15.  0. 11.  0.] 
adversary cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  8.  6.  0.  0.  6.  6.  0.  6.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0  8  6 11  0  6 15  8] -> size -> 38 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 2.020512580871582





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-1.0593653 ]
 [ 4.114781  ]
 [ 2.0234113 ]
 [-0.00842714]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11. 10. 29.  0.] 
cards in discard: [25. 11.  8.  3. 15.  0. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 23. 30.  8.  0. 10.  4.  6.  6.  6. 10. 10.  6. 10.  6.] 
adversary cards in hand: [ 0. 15.  0. 11.  0.] 
adversary cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  8.  6.  0.  0.  6.  6.  0.  6.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0  8  6 11  0  6 15  8] -> size -> 38 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: -1.131180763244629



buy possibilites: [-1] 
expected returns: [[8.647606]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11. 10. 29.  0.] 
cards in discard: [25. 11.  8.  3. 15.  0. 29.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 22. 30.  8.  0. 10.  4.  6.  6.  6. 10. 10.  6. 10.  6.] 
adversary cards in hand: [ 0. 15.  0. 11.  0.] 
adversary cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  8.  6.  0.  0.  6.  6.  0.  6.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0  8  6 11  0  6 15  8] -> size -> 38 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 391 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 4.114782810211182






Player: 1 
cards in hand: [ 0. 15.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0. 11.  0.] 
cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  8.  6.  0.  0.  6.  6.  0.  6.  6.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6
 15  6  3  0  6  6  0  8  6 11  0  6 15  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 22. 30.  8.  0. 10.  4.  6.  6.  6. 10. 10.  6. 10.  6.] 
adversary cards in hand: [ 3.  3. 10. 25.  3.] 
adversary cards in discard: [25. 11.  8.  3. 15.  0. 29.  3. 25.  3.  0. 11. 10. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3] -> size -> 31 
adversary victory points: 8
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.] 
cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  8.  6.  0.  0.  6.  6.  0.  6.  6.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6 15
  6  3  0  6  6  0  8  6 11  0  6 15  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 29. 30. 22. 30.  8.  0. 10.  4.  6.  6.  6. 10. 10.  6. 10.  6.] 
adversary cards in hand: [ 3.  3. 10. 25.  3.] 
adversary cards in discard: [25. 11.  8.  3. 15.  0. 29.  3. 25.  3.  0. 11. 10. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3] -> size -> 31 
adversary victory points: 8
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.] 
cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  8.  6.  0.  0.  6.  6.  0.  6.  6.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6 15
  6  3  0  6  6  0  8  6 11  0  6 15  8] -> size -> 37 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 29. 30. 22. 30.  8.  0. 10.  4.  6.  6.  6. 10. 10.  6. 10.  6.] 
adversary cards in hand: [ 3.  3. 10. 25.  3.] 
adversary cards in discard: [25. 11.  8.  3. 15.  0. 29.  3. 25.  3.  0. 11. 10. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3] -> size -> 31 
adversary victory points: 8
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.] 
cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  8.  6.  0.  0.  6.  6.  0.  6.  6.  3.  3.
  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6 15
  6  3  0  6  6  0  8  6 11  0  6 15  8  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 29. 30. 21. 30.  8.  0. 10.  4.  6.  6.  6. 10. 10.  6. 10.  6.] 
adversary cards in hand: [ 3.  3. 10. 25.  3.] 
adversary cards in discard: [25. 11.  8.  3. 15.  0. 29.  3. 25.  3.  0. 11. 10. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3] -> size -> 31 
adversary victory points: 8
player victory points: -3 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 3.  3. 10. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[-0.3507557]
 [ 0.9147291]
 [13.370167 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10. 25.  3.] 
cards in discard: [25. 11.  8.  3. 15.  0. 29.  3. 25.  3.  0. 11. 10. 29.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 21. 30.  8.  0. 10.  4.  6.  6.  6. 10. 10.  6. 10.  6.] 
adversary cards in hand: [ 6.  0.  0.  8. 10.] 
adversary cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  8.  6.  0.  0.  6.  6.  0.  6.  6.  3.  3.
  3. 15.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6 15
  6  3  0  6  6  0  8  6 11  0  6 15  8  3] -> size -> 38 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 8.647605895996094



action possibilites: [-1] 
expected returns: [[32.326054]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.  3.  3.  3.] 
cards in discard: [25. 11.  8.  3. 15.  0. 29.  3. 25.  3.  0. 11. 10. 29.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 21. 30.  8.  0. 10.  4.  6.  6.  6. 10. 10.  6. 10.  6.] 
adversary cards in hand: [ 6.  0.  0.  8. 10.] 
adversary cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  8.  6.  0.  0.  6.  6.  0.  6.  6.  3.  3.
  3. 15.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6 15
  6  3  0  6  6  0  8  6 11  0  6 15  8  3] -> size -> 38 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 13.370168685913086





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[26.011837]
 [32.8763  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.  3.  3.  3.] 
cards in discard: [25. 11.  8.  3. 15.  0. 29.  3. 25.  3.  0. 11. 10. 29.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 29. 30. 21. 30.  8.  0. 10.  4.  6.  6.  6. 10. 10.  6. 10.  6.] 
adversary cards in hand: [ 6.  0.  0.  8. 10.] 
adversary cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  8.  6.  0.  0.  6.  6.  0.  6.  6.  3.  3.
  3. 15.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6 15
  6  3  0  6  6  0  8  6 11  0  6 15  8  3] -> size -> 38 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: 32.326053619384766






Player: 1 
cards in hand: [ 6.  0.  0.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0.  8. 10.] 
cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  8.  6.  0.  0.  6.  6.  0.  6.  6.  3.  3.
  3. 15.  0. 11.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 15  0 11  6  0  0  6  0  6 10  6  3  6 15
  6  3  0  6  6  0  8  6 11  0  6 15  8  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 21. 30.  8.  0. 10.  4.  6.  6.  6. 10. 10.  6. 10.  6.] 
adversary cards in hand: [10.  0.  1. 25.  8.] 
adversary cards in discard: [25. 11.  8.  3. 15.  0. 29.  3. 25.  3.  0. 11. 10. 29.  0. 25.  3.  3.
 10.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3] -> size -> 31 
adversary victory points: 8
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  8.  6.  0.  0.  6.  6.  0.  6.  6.  3.  3.
  3. 15.  0. 11.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0
  6  6  0  8  6 11  0  6 15  8  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 21. 30.  8.  0. 10.  4.  6.  6.  6. 10. 10.  6. 10.  6.] 
adversary cards in hand: [10.  0.  1. 25.  8.] 
adversary cards in discard: [25. 11.  8.  3. 15.  0. 29.  3. 25.  3.  0. 11. 10. 29.  0. 25.  3.  3.
 10.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3] -> size -> 31 
adversary victory points: 8
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  8.  6.  0.  0.  6.  6.  0.  6.  6.  3.  3.
  3. 15.  0. 11.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0
  6  6  0  8  6 11  0  6 15  8  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 29. 30. 21. 30.  8.  0. 10.  4.  6.  6.  6. 10. 10.  6. 10.  6.] 
adversary cards in hand: [10.  0.  1. 25.  8.] 
adversary cards in discard: [25. 11.  8.  3. 15.  0. 29.  3. 25.  3.  0. 11. 10. 29.  0. 25.  3.  3.
 10.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3] -> size -> 31 
adversary victory points: 8
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  8.  6.  0.  0.  6.  6.  0.  6.  6.  3.  3.
  3. 15.  0. 11.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0
  6  6  0  8  6 11  0  6 15  8  3  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 29. 30. 21. 30.  8.  0. 10.  4.  6.  6.  6. 10. 10.  6. 10.  6.] 
adversary cards in hand: [10.  0.  1. 25.  8.] 
adversary cards in discard: [25. 11.  8.  3. 15.  0. 29.  3. 25.  3.  0. 11. 10. 29.  0. 25.  3.  3.
 10.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3] -> size -> 31 
adversary victory points: 8
player victory points: -2 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [10.  0.  1. 25.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.  8.] 
expected returns: [[ 5.421286 ]
 [ 5.218559 ]
 [16.004044 ]
 [ 1.2374167]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  1. 25.  8.] 
cards in discard: [25. 11.  8.  3. 15.  0. 29.  3. 25.  3.  0. 11. 10. 29.  0. 25.  3.  3.
 10.  3.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 21. 30.  8.  0. 10.  4.  6.  6.  6. 10. 10.  6. 10.  6.] 
adversary cards in hand: [0. 6. 6. 3. 3.] 
adversary cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  8.  6.  0.  0.  6.  6.  0.  6.  6.  3.  3.
  3. 15.  0. 11.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0
  6  6  0  8  6 11  0  6 15  8  3  0] -> size -> 36 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 32.87630844116211



action possibilites: [-1] 
expected returns: [[33.440987]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  1.  8. 29. 11.] 
cards in discard: [25. 11.  8.  3. 15.  0. 29.  3. 25.  3.  0. 11. 10. 29.  0. 25.  3.  3.
 10.  3.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 21. 30.  8.  0. 10.  4.  6.  6.  6. 10. 10.  6. 10.  6.] 
adversary cards in hand: [0. 6. 6. 3. 3.] 
adversary cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  8.  6.  0.  0.  6.  6.  0.  6.  6.  3.  3.
  3. 15.  0. 11.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0
  6  6  0  8  6 11  0  6 15  8  3  0] -> size -> 36 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 16.004047393798828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[26.749184]
 [39.802876]
 [33.332638]
 [40.29245 ]
 [32.453354]
 [36.237057]
 [34.951862]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  1.  8. 29. 11.] 
cards in discard: [25. 11.  8.  3. 15.  0. 29.  3. 25.  3.  0. 11. 10. 29.  0. 25.  3.  3.
 10.  3.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 29. 30. 21. 30.  8.  0. 10.  4.  6.  6.  6. 10. 10.  6. 10.  6.] 
adversary cards in hand: [0. 6. 6. 3. 3.] 
adversary cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  8.  6.  0.  0.  6.  6.  0.  6.  6.  3.  3.
  3. 15.  0. 11.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0
  6  6  0  8  6 11  0  6 15  8  3  0] -> size -> 36 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: 33.44098663330078



buy possibilites: [-1] 
expected returns: [[48.2777]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  1.  8. 29. 11.] 
cards in discard: [25. 11.  8.  3. 15.  0. 29.  3. 25.  3.  0. 11. 10. 29.  0. 25.  3.  3.
 10.  3.  3.  3. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 21. 30.  8.  0. 10.  3.  6.  6.  6. 10. 10.  6. 10.  6.] 
adversary cards in hand: [0. 6. 6. 3. 3.] 
adversary cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  8.  6.  0.  0.  6.  6.  0.  6.  6.  3.  3.
  3. 15.  0. 11.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0
  6  6  0  8  6 11  0  6 15  8  3  0] -> size -> 36 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 369 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 40.292476654052734






Player: 1 
cards in hand: [0. 6. 6. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 3. 3.] 
cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  8.  6.  0.  0.  6.  6.  0.  6.  6.  3.  3.
  3. 15.  0. 11.  0.  0.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0
  6  6  0  8  6 11  0  6 15  8  3  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 21. 30.  8.  0. 10.  3.  6.  6.  6. 10. 10.  6. 10.  6.] 
adversary cards in hand: [ 3. 11. 10. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11] -> size -> 32 
adversary victory points: 8
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 3. 3.] 
cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  8.  6.  0.  0.  6.  6.  0.  6.  6.  3.  3.
  3. 15.  0. 11.  0.  0.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0
  6  6  0  8  6 11  0  6 15  8  3  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 29. 30. 21. 30.  8.  0. 10.  3.  6.  6.  6. 10. 10.  6. 10.  6.] 
adversary cards in hand: [ 3. 11. 10. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11] -> size -> 32 
adversary victory points: 8
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 3. 11. 10. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11. 29.] 
expected returns: [[-9.081008 ]
 [-2.17279  ]
 [-6.9700537]
 [-2.17279  ]
 [ 3.2065644]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10. 11. 29.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 21. 30.  8.  0. 10.  3.  6.  6.  6. 10. 10.  6. 10.  6.] 
adversary cards in hand: [ 0. 15.  6.  3.  3.] 
adversary cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  8.  6.  0.  0.  6.  6.  0.  6.  6.  3.  3.
  3. 15.  0. 11.  0.  0.  8.  0.  0.  6.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0
  6  6  0  8  6 11  0  6 15  8  3  0] -> size -> 36 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 48.2776985168457



action possibilites: [-1. 11. 10. 11. 25.] 
expected returns: [[-3.9213138]
 [-2.2755938]
 [-1.7793899]
 [-2.2755938]
 [10.455151 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11. 25.] 
cards in discard: [3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 29. 30. 21. 30.  8.  0. 10.  3.  6.  6.  6. 10. 10.  6. 10.  6.] 
adversary cards in hand: [ 0. 15.  6.  3.  3.] 
adversary cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  8.  6.  0.  0.  6.  6.  0.  6.  6.  3.  3.
  3. 15.  0. 11.  0.  0.  8.  0.  0.  6.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0
  6  6  0  8  6 11  0  6 15  8  3  0] -> size -> 36 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -2.0193238258361816



action possibilites: [-1] 
expected returns: [[-14.811352]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11.  1. 10.] 
cards in discard: [3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 29. 30. 21. 30.  8.  0. 10.  3.  6.  6.  6. 10. 10.  6. 10.  6.] 
adversary cards in hand: [ 0. 15.  6.  3.  3.] 
adversary cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  8.  6.  0.  0.  6.  6.  0.  6.  6.  3.  3.
  3. 15.  0. 11.  0.  0.  8.  0.  0.  6.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0
  6  6  0  8  6 11  0  6 15  8  3  0] -> size -> 36 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 10.455158233642578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-27.752598 ]
 [-13.628958 ]
 [-20.22882  ]
 [ -2.8393233]
 [-14.438528 ]
 [ -1.8562865]
 [-12.521426 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 11.  1. 10.] 
cards in discard: [3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 29. 30. 21. 30.  8.  0. 10.  3.  6.  6.  6. 10. 10.  6. 10.  6.] 
adversary cards in hand: [ 0. 15.  6.  3.  3.] 
adversary cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  8.  6.  0.  0.  6.  6.  0.  6.  6.  3.  3.
  3. 15.  0. 11.  0.  0.  8.  0.  0.  6.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0
  6  6  0  8  6 11  0  6 15  8  3  0] -> size -> 36 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: take_action - action -1
Learning step: 0
desired expected reward: -14.811351776123047



buy possibilites: [-1] 
expected returns: [[1.1001525]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 11.  1. 10.] 
cards in discard: [ 3. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 21. 30.  8.  0. 10.  3.  6.  6.  6. 10. 10.  5. 10.  6.] 
adversary cards in hand: [ 0. 15.  6.  3.  3.] 
adversary cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  8.  6.  0.  0.  6.  6.  0.  6.  6.  3.  3.
  3. 15.  0. 11.  0.  0.  8.  0.  0.  6.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0
  6  6  0  8  6 11  0  6 15  8  3  0] -> size -> 36 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 389 

action type: buy - action 10.0
Learning step: 0
desired expected reward: -1.856269359588623






Player: 1 
cards in hand: [ 0. 15.  6.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  6.  3.  3.] 
cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  8.  6.  0.  0.  6.  6.  0.  6.  6.  3.  3.
  3. 15.  0. 11.  0.  0.  8.  0.  0.  6.  6.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0
  6  6  0  8  6 11  0  6 15  8  3  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 21. 30.  8.  0. 10.  3.  6.  6.  6. 10. 10.  5. 10.  6.] 
adversary cards in hand: [11.  3. 25.  3.  3.] 
adversary cards in discard: [ 3. 10. 29. 25. 11. 10. 11.  1. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10] -> size -> 33 
adversary victory points: 8
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  6.  3.  3.] 
cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  8.  6.  0.  0.  6.  6.  0.  6.  6.  3.  3.
  3. 15.  0. 11.  0.  0.  8.  0.  0.  6.  6.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0
  6  6  0  8  6 11  0  6 15  8  3  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 29. 30. 21. 30.  8.  0. 10.  3.  6.  6.  6. 10. 10.  5. 10.  6.] 
adversary cards in hand: [11.  3. 25.  3.  3.] 
adversary cards in discard: [ 3. 10. 29. 25. 11. 10. 11.  1. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10] -> size -> 33 
adversary victory points: 8
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  6.  3.  3.] 
cards in discard: [ 6. 15. 11.  0.  0.  0.  0.  8.  6.  0.  0.  6.  6.  0.  6.  6.  3.  3.
  3. 15.  0. 11.  0.  0.  8.  0.  0.  6.  6.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0
  6  6  0  8  6 11  0  6 15  8  3  0  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 21. 30.  8.  0. 10.  3.  6.  6.  6. 10. 10.  5. 10.  6.] 
adversary cards in hand: [11.  3. 25.  3.  3.] 
adversary cards in discard: [ 3. 10. 29. 25. 11. 10. 11.  1. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10] -> size -> 33 
adversary victory points: 8
player victory points: -2 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [11.  3. 25.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[-27.26083  ]
 [-18.03914  ]
 [ -7.9840956]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 25.  3.  3.] 
cards in discard: [ 3. 10. 29. 25. 11. 10. 11.  1. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 21. 30.  8.  0. 10.  3.  6.  6.  6. 10. 10.  5. 10.  6.] 
adversary cards in hand: [ 0.  3.  0.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0
  6  6  0  8  6 11  0  6 15  8  3  0  0] -> size -> 37 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 1.1001524925231934



action possibilites: [-1] 
expected returns: [[-20.007824]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  3.  3. 11.  8.] 
cards in discard: [ 3. 10. 29. 25. 11. 10. 11.  1. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 21. 30.  8.  0. 10.  3.  6.  6.  6. 10. 10.  5. 10.  6.] 
adversary cards in hand: [ 0.  3.  0.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0
  6  6  0  8  6 11  0  6 15  8  3  0  0] -> size -> 37 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -7.984095573425293





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-25.02858 ]
 [-19.611845]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  3.  3. 11.  8.] 
cards in discard: [ 3. 10. 29. 25. 11. 10. 11.  1. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 29. 30. 21. 30.  8.  0. 10.  3.  6.  6.  6. 10. 10.  5. 10.  6.] 
adversary cards in hand: [ 0.  3.  0.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0
  6  6  0  8  6 11  0  6 15  8  3  0  0] -> size -> 37 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: -20.007823944091797






Player: 1 
cards in hand: [ 0.  3.  0.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  6. 11.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0
  6  6  0  8  6 11  0  6 15  8  3  0  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 21. 30.  8.  0. 10.  3.  6.  6.  6. 10. 10.  5. 10.  6.] 
adversary cards in hand: [11. 29.  3. 29. 15.] 
adversary cards in discard: [ 3. 10. 29. 25. 11. 10. 11.  1. 10. 25. 11.  3.  3.  3. 11.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10] -> size -> 33 
adversary victory points: 8
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 6.] 
cards in discard: [8.] 
cards in deck: 32 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0
  6  6  0  8  6 11  0  6 15  8  3  0  0  8] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 21. 30.  8.  0. 10.  3.  5.  6.  6. 10. 10.  5. 10.  6.] 
adversary cards in hand: [11. 29.  3. 29. 15.] 
adversary cards in discard: [ 3. 10. 29. 25. 11. 10. 11.  1. 10. 25. 11.  3.  3.  3. 11.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10] -> size -> 33 
adversary victory points: 8
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6.] 
cards in discard: [8.] 
cards in deck: 32 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0
  6  6  0  8  6 11  0  6 15  8  3  0  0  8] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 29. 30. 21. 30.  8.  0. 10.  3.  5.  6.  6. 10. 10.  5. 10.  6.] 
adversary cards in hand: [11. 29.  3. 29. 15.] 
adversary cards in discard: [ 3. 10. 29. 25. 11. 10. 11.  1. 10. 25. 11.  3.  3.  3. 11.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10] -> size -> 33 
adversary victory points: 8
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6.] 
cards in discard: [8. 3.] 
cards in deck: 32 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0
  6  6  0  8  6 11  0  6 15  8  3  0  0  8  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 20. 30.  8.  0. 10.  3.  5.  6.  6. 10. 10.  5. 10.  6.] 
adversary cards in hand: [11. 29.  3. 29. 15.] 
adversary cards in discard: [ 3. 10. 29. 25. 11. 10. 11.  1. 10. 25. 11.  3.  3.  3. 11.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10] -> size -> 33 
adversary victory points: 8
player victory points: -1 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [11. 29.  3. 29. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 29. 15.] 
expected returns: [[-67.60018 ]
 [-59.25279 ]
 [-44.353466]
 [-44.353466]
 [-78.00228 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  3. 29. 15.] 
cards in discard: [ 3. 10. 29. 25. 11. 10. 11.  1. 10. 25. 11.  3.  3.  3. 11.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 20. 30.  8.  0. 10.  3.  5.  6.  6. 10. 10.  5. 10.  6.] 
adversary cards in hand: [6. 0. 3. 3. 6.] 
adversary cards in discard: [ 8.  3. 11.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0
  6  6  0  8  6 11  0  6 15  8  3  0  0  8  3] -> size -> 39 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -19.611852645874023



action possibilites: [-1. 29. 15.] 
expected returns: [[44.258068]
 [56.180813]
 [37.691692]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 15.  0.] 
cards in discard: [ 3. 10. 29. 25. 11. 10. 11.  1. 10. 25. 11.  3.  3.  3. 11.  8. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 20. 30.  8.  0. 10.  3.  5.  6.  6. 10. 10.  5. 10.  6.] 
adversary cards in hand: [6. 0. 3. 3. 6.] 
adversary cards in discard: [ 8.  3. 11.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0
  6  6  0  8  6 11  0  6 15  8  3  0  0  8  3] -> size -> 39 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -71.60785675048828



action possibilites: [-1. 15.] 
expected returns: [[33.06186 ]
 [24.005306]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  3.] 
cards in discard: [ 3. 10. 29. 25. 11. 10. 11.  1. 10. 25. 11.  3.  3.  3. 11.  8. 11.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10] -> size -> 33 
action values: 1 
buys: 0 
player value: 2 
card supply: [21. 29. 30. 20. 30.  8.  0. 10.  3.  5.  6.  6. 10. 10.  5. 10.  6.] 
adversary cards in hand: [6. 0. 3. 3. 6.] 
adversary cards in discard: [ 8.  3. 11.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0
  6  6  0  8  6 11  0  6 15  8  3  0  0  8  3] -> size -> 39 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 51.93901824951172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[24.286041]
 [37.4933  ]
 [31.429688]
 [38.745403]
 [30.288666]
 [34.050903]
 [33.189163]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  3.] 
cards in discard: [ 3. 10. 29. 25. 11. 10. 11.  1. 10. 25. 11.  3.  3.  3. 11.  8. 11.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 29. 30. 20. 30.  8.  0. 10.  3.  5.  6.  6. 10. 10.  5. 10.  6.] 
adversary cards in hand: [6. 0. 3. 3. 6.] 
adversary cards in discard: [ 8.  3. 11.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0
  6  6  0  8  6 11  0  6 15  8  3  0  0  8  3] -> size -> 39 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 33.06188201904297



buy possibilites: [-1] 
expected returns: [[0.683218]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  3.] 
cards in discard: [ 3. 10. 29. 25. 11. 10. 11.  1. 10. 25. 11.  3.  3.  3. 11.  8. 11.  3.
 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 20. 30.  8.  0. 10.  2.  5.  6.  6. 10. 10.  5. 10.  6.] 
adversary cards in hand: [6. 0. 3. 3. 6.] 
adversary cards in discard: [ 8.  3. 11.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0
  6  6  0  8  6 11  0  6 15  8  3  0  0  8  3] -> size -> 39 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 359 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 38.74540328979492






Player: 1 
cards in hand: [6. 0. 3. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 3. 6.] 
cards in discard: [ 8.  3. 11.  0.  3.  0.  6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0
  6  6  0  8  6 11  0  6 15  8  3  0  0  8  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 20. 30.  8.  0. 10.  2.  5.  6.  6. 10. 10.  5. 10.  6.] 
adversary cards in hand: [25.  8.  0.  3.  0.] 
adversary cards in discard: [ 3. 10. 29. 25. 11. 10. 11.  1. 10. 25. 11.  3.  3.  3. 11.  8. 11.  3.
 11. 29. 29. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11] -> size -> 34 
adversary victory points: 8
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 3. 6.] 
cards in discard: [ 8.  3. 11.  0.  3.  0.  6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0
  6  6  0  8  6 11  0  6 15  8  3  0  0  8  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 29. 30. 20. 30.  8.  0. 10.  2.  5.  6.  6. 10. 10.  5. 10.  6.] 
adversary cards in hand: [25.  8.  0.  3.  0.] 
adversary cards in discard: [ 3. 10. 29. 25. 11. 10. 11.  1. 10. 25. 11.  3.  3.  3. 11.  8. 11.  3.
 11. 29. 29. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11] -> size -> 34 
adversary victory points: 8
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [25.  8.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[24.059465]
 [40.906593]
 [21.266903]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8.  0.  3.  0.] 
cards in discard: [ 3. 10. 29. 25. 11. 10. 11.  1. 10. 25. 11.  3.  3.  3. 11.  8. 11.  3.
 11. 29. 29. 15.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 20. 30.  8.  0. 10.  2.  5.  6.  6. 10. 10.  5. 10.  6.] 
adversary cards in hand: [ 0. 15.  3.  6.  6.] 
adversary cards in discard: [ 8.  3. 11.  0.  3.  0.  6.  6.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0
  6  6  0  8  6 11  0  6 15  8  3  0  0  8  3] -> size -> 39 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 0.6832180023193359



action possibilites: [-1] 
expected returns: [[46.76289]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3.  0.  3. 10.] 
cards in discard: [ 3. 10. 29. 25. 11. 10. 11.  1. 10. 25. 11.  3.  3.  3. 11.  8. 11.  3.
 11. 29. 29. 15.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 20. 30.  8.  0. 10.  2.  5.  6.  6. 10. 10.  5. 10.  6.] 
adversary cards in hand: [ 0. 15.  3.  6.  6.] 
adversary cards in discard: [ 8.  3. 11.  0.  3.  0.  6.  6.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0
  6  6  0  8  6 11  0  6 15  8  3  0  0  8  3] -> size -> 39 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 40.90658950805664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[40.343502]
 [46.1252  ]
 [45.846012]
 [48.531475]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3.  0.  3. 10.] 
cards in discard: [ 3. 10. 29. 25. 11. 10. 11.  1. 10. 25. 11.  3.  3.  3. 11.  8. 11.  3.
 11. 29. 29. 15.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 29. 30. 20. 30.  8.  0. 10.  2.  5.  6.  6. 10. 10.  5. 10.  6.] 
adversary cards in hand: [ 0. 15.  3.  6.  6.] 
adversary cards in discard: [ 8.  3. 11.  0.  3.  0.  6.  6.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0
  6  6  0  8  6 11  0  6 15  8  3  0  0  8  3] -> size -> 39 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 46.76288986206055






Player: 1 
cards in hand: [ 0. 15.  3.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3.  6.  6.] 
cards in discard: [ 8.  3. 11.  0.  3.  0.  6.  6.  0.  3.  3.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0
  6  6  0  8  6 11  0  6 15  8  3  0  0  8  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 20. 30.  8.  0. 10.  2.  5.  6.  6. 10. 10.  5. 10.  6.] 
adversary cards in hand: [ 0. 29. 25. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11] -> size -> 34 
adversary victory points: 8
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  3.  6.  6.] 
cards in discard: [ 8.  3. 11.  0.  3.  0.  6.  6.  0.  3.  3.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0
  6  6  0  8  6 11  0  6 15  8  3  0  0  8  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 29. 30. 20. 30.  8.  0. 10.  2.  5.  6.  6. 10. 10.  5. 10.  6.] 
adversary cards in hand: [ 0. 29. 25. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11] -> size -> 34 
adversary victory points: 8
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  3.  6.  6.] 
cards in discard: [ 8.  3. 11.  0.  3.  0.  6.  6.  0.  3.  3.  6.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0
  6  6  0  8  6 11  0  6 15  8  3  0  0  8  3  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 29. 30. 20. 30.  8.  0. 10.  2.  5.  6.  6. 10. 10.  5. 10.  6.] 
adversary cards in hand: [ 0. 29. 25. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11] -> size -> 34 
adversary victory points: 8
player victory points: -1 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 25. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29.] 
expected returns: [[-13.647547 ]
 [ -2.8749242]
 [  2.181785 ]
 [ -2.8749242]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 25. 29.  0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 20. 30.  8.  0. 10.  2.  5.  6.  6. 10. 10.  5. 10.  6.] 
adversary cards in hand: [ 0. 15.  0.  0.  8.] 
adversary cards in discard: [ 8.  3. 11.  0.  3.  0.  6.  6.  0.  3.  3.  6.  0.  0. 15.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0
  6  6  0  8  6 11  0  6 15  8  3  0  0  8  3  0] -> size -> 40 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 48.53147506713867



action possibilites: [-1] 
expected returns: [[-21.712414]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29.  0. 11. 10.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 20. 30.  8.  0. 10.  2.  5.  6.  6. 10. 10.  5. 10.  6.] 
adversary cards in hand: [ 0. 15.  0.  0.  8.] 
adversary cards in discard: [ 8.  3. 11.  0.  3.  0.  6.  6.  0.  3.  3.  6.  0.  0. 15.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0
  6  6  0  8  6 11  0  6 15  8  3  0  0  8  3  0] -> size -> 40 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 2.18178653717041





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-42.649673]
 [-37.356018]
 [-26.353325]
 [-26.273796]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 29.  0. 11. 10.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 29. 30. 20. 30.  8.  0. 10.  2.  5.  6.  6. 10. 10.  5. 10.  6.] 
adversary cards in hand: [ 0. 15.  0.  0.  8.] 
adversary cards in discard: [ 8.  3. 11.  0.  3.  0.  6.  6.  0.  3.  3.  6.  0.  0. 15.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0
  6  6  0  8  6 11  0  6 15  8  3  0  0  8  3  0] -> size -> 40 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: -21.712413787841797






Player: 1 
cards in hand: [ 0. 15.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.  0.  8.] 
cards in discard: [ 8.  3. 11.  0.  3.  0.  6.  6.  0.  3.  3.  6.  0.  0. 15.  3.  6.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0
  6  6  0  8  6 11  0  6 15  8  3  0  0  8  3  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 20. 30.  8.  0. 10.  2.  5.  6.  6. 10. 10.  5. 10.  6.] 
adversary cards in hand: [15. 25. 11. 10.  0.] 
adversary cards in discard: [25.  0. 29. 29.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11] -> size -> 34 
adversary victory points: 8
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.] 
cards in discard: [ 8.  3. 11.  0.  3.  0.  6.  6.  0.  3.  3.  6.  0.  0. 15.  3.  6.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0  6
  6  0  8  6 11  0  6 15  8  3  0  0  8  3  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 20. 30.  8.  0. 10.  2.  5.  6.  6. 10. 10.  5. 10.  6.] 
adversary cards in hand: [15. 25. 11. 10.  0.] 
adversary cards in discard: [25.  0. 29. 29.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11] -> size -> 34 
adversary victory points: 8
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.] 
cards in discard: [ 8.  3. 11.  0.  3.  0.  6.  6.  0.  3.  3.  6.  0.  0. 15.  3.  6.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0  6
  6  0  8  6 11  0  6 15  8  3  0  0  8  3  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 29. 30. 20. 30.  8.  0. 10.  2.  5.  6.  6. 10. 10.  5. 10.  6.] 
adversary cards in hand: [15. 25. 11. 10.  0.] 
adversary cards in discard: [25.  0. 29. 29.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11] -> size -> 34 
adversary victory points: 8
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.] 
cards in discard: [ 8.  3. 11.  0.  3.  0.  6.  6.  0.  3.  3.  6.  0.  0. 15.  3.  6.  6.
  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0  6
  6  0  8  6 11  0  6 15  8  3  0  0  8  3  0  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 29. 30. 20. 30.  8.  0. 10.  2.  5.  6.  6. 10. 10.  5. 10.  6.] 
adversary cards in hand: [15. 25. 11. 10.  0.] 
adversary cards in discard: [25.  0. 29. 29.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11] -> size -> 34 
adversary victory points: 8
player victory points: -1 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [15. 25. 11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25. 11. 10.] 
expected returns: [[ -4.6667576]
 [-11.347525 ]
 [ 24.205004 ]
 [  8.616514 ]
 [  4.295365 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 25. 11. 10.  0.] 
cards in discard: [25.  0. 29. 29.  0. 11. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 20. 30.  8.  0. 10.  2.  5.  6.  6. 10. 10.  5. 10.  6.] 
adversary cards in hand: [15.  0.  0.  0.  6.] 
adversary cards in discard: [ 8.  3. 11.  0.  3.  0.  6.  6.  0.  3.  3.  6.  0.  0. 15.  3.  6.  6.
  0.  8. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0  6
  6  0  8  6 11  0  6 15  8  3  0  0  8  3  0  0] -> size -> 40 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -26.273794174194336



action possibilites: [-1] 
expected returns: [[-25.683434]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11. 10.  0. 11.  3.] 
cards in discard: [25.  0. 29. 29.  0. 11. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 20. 30.  8.  0. 10.  2.  5.  6.  6. 10. 10.  5. 10.  6.] 
adversary cards in hand: [15.  0.  0.  0.  6.] 
adversary cards in discard: [ 8.  3. 11.  0.  3.  0.  6.  6.  0.  3.  3.  6.  0.  0. 15.  3.  6.  6.
  0.  8. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0  6
  6  0  8  6 11  0  6 15  8  3  0  0  8  3  0  0] -> size -> 40 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 24.204975128173828





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-30.50559 ]
 [-24.990604]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 11. 10.  0. 11.  3.] 
cards in discard: [25.  0. 29. 29.  0. 11. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 29. 30. 20. 30.  8.  0. 10.  2.  5.  6.  6. 10. 10.  5. 10.  6.] 
adversary cards in hand: [15.  0.  0.  0.  6.] 
adversary cards in discard: [ 8.  3. 11.  0.  3.  0.  6.  6.  0.  3.  3.  6.  0.  0. 15.  3.  6.  6.
  0.  8. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0  6
  6  0  8  6 11  0  6 15  8  3  0  0  8  3  0  0] -> size -> 40 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: -25.683433532714844






Player: 1 
cards in hand: [15.  0.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  0.  6.] 
cards in discard: [ 8.  3. 11.  0.  3.  0.  6.  6.  0.  3.  3.  6.  0.  0. 15.  3.  6.  6.
  0.  8. 15.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0  6
  6  0  8  6 11  0  6 15  8  3  0  0  8  3  0  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 20. 30.  8.  0. 10.  2.  5.  6.  6. 10. 10.  5. 10.  6.] 
adversary cards in hand: [ 3.  3.  3. 10.  3.] 
adversary cards in discard: [25.  0. 29. 29.  0. 11. 10. 25. 15. 11. 10.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11] -> size -> 34 
adversary victory points: 8
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.  0.  6.] 
cards in discard: [ 8.  3. 11.  0.  3.  0.  6.  6.  0.  3.  3.  6.  0.  0. 15.  3.  6.  6.
  0.  8. 15.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0  6
  6  0  8  6 11  0  6 15  8  3  0  0  8  3  0  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 29. 30. 20. 30.  8.  0. 10.  2.  5.  6.  6. 10. 10.  5. 10.  6.] 
adversary cards in hand: [ 3.  3.  3. 10.  3.] 
adversary cards in discard: [25.  0. 29. 29.  0. 11. 10. 25. 15. 11. 10.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11] -> size -> 34 
adversary victory points: 8
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.  0.  6.] 
cards in discard: [ 8.  3. 11.  0.  3.  0.  6.  6.  0.  3.  3.  6.  0.  0. 15.  3.  6.  6.
  0.  8. 15.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0  6
  6  0  8  6 11  0  6 15  8  3  0  0  8  3  0  0  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 3 
card supply: [18. 29. 30. 20. 30.  8.  0. 10.  2.  5.  6.  6. 10. 10.  5. 10.  6.] 
adversary cards in hand: [ 3.  3.  3. 10.  3.] 
adversary cards in discard: [25.  0. 29. 29.  0. 11. 10. 25. 15. 11. 10.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11] -> size -> 34 
adversary victory points: 8
player victory points: -1 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  3. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[21.015244]
 [26.993042]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3. 10.  3.] 
cards in discard: [25.  0. 29. 29.  0. 11. 10. 25. 15. 11. 10.  0. 11.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 20. 30.  8.  0. 10.  2.  5.  6.  6. 10. 10.  5. 10.  6.] 
adversary cards in hand: [6. 3. 6. 3. 0.] 
adversary cards in discard: [ 8.  3. 11.  0.  3.  0.  6.  6.  0.  3.  3.  6.  0.  0. 15.  3.  6.  6.
  0.  8. 15.  0.  0.  0. 15.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0  6
  6  0  8  6 11  0  6 15  8  3  0  0  8  3  0  0  0] -> size -> 41 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -24.990604400634766



action possibilites: [-1. 29.] 
expected returns: [[ 1.874845]
 [14.976673]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3.  3. 29.] 
cards in discard: [25.  0. 29. 29.  0. 11. 10. 25. 15. 11. 10.  0. 11.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 20. 30.  8.  0. 10.  2.  5.  6.  6. 10. 10.  5. 10.  6.] 
adversary cards in hand: [6. 3. 6. 3. 0.] 
adversary cards in discard: [ 8.  3. 11.  0.  3.  0.  6.  6.  0.  3.  3.  6.  0.  0. 15.  3.  6.  6.
  0.  8. 15.  0.  0.  0. 15.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0  6
  6  0  8  6 11  0  6 15  8  3  0  0  8  3  0  0  0] -> size -> 41 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 26.993038177490234



action possibilites: [-1.] 
expected returns: [[7.175287]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 3.] 
cards in discard: [25.  0. 29. 29.  0. 11. 10. 25. 15. 11. 10.  0. 11.  3.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11] -> size -> 34 
action values: 2 
buys: 0 
player value: 1 
card supply: [18. 29. 30. 20. 30.  8.  0. 10.  2.  5.  6.  6. 10. 10.  5. 10.  6.] 
adversary cards in hand: [6. 3. 6. 3. 0.] 
adversary cards in discard: [ 8.  3. 11.  0.  3.  0.  6.  6.  0.  3.  3.  6.  0.  0. 15.  3.  6.  6.
  0.  8. 15.  0.  0.  0. 15.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0  6
  6  0  8  6 11  0  6 15  8  3  0  0  8  3  0  0  0] -> size -> 41 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: discard_n_cards - action 0
Learning step: 0
desired expected reward: -3.3509418964385986





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[2.5176601]
 [7.173804 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 3.] 
cards in discard: [25.  0. 29. 29.  0. 11. 10. 25. 15. 11. 10.  0. 11.  3.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11] -> size -> 34 
action values: 2 
buys: 1 
player value: 1 
card supply: [18. 29. 30. 20. 30.  8.  0. 10.  2.  5.  6.  6. 10. 10.  5. 10.  6.] 
adversary cards in hand: [6. 3. 6. 3. 0.] 
adversary cards in discard: [ 8.  3. 11.  0.  3.  0.  6.  6.  0.  3.  3.  6.  0.  0. 15.  3.  6.  6.
  0.  8. 15.  0.  0.  0. 15.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0  6
  6  0  8  6 11  0  6 15  8  3  0  0  8  3  0  0  0] -> size -> 41 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 7.175286769866943






Player: 1 
cards in hand: [6. 3. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 6. 3. 0.] 
cards in discard: [ 8.  3. 11.  0.  3.  0.  6.  6.  0.  3.  3.  6.  0.  0. 15.  3.  6.  6.
  0.  8. 15.  0.  0.  0. 15.  0.  0.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0  6
  6  0  8  6 11  0  6 15  8  3  0  0  8  3  0  0  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 20. 30.  8.  0. 10.  2.  5.  6.  6. 10. 10.  5. 10.  6.] 
adversary cards in hand: [11.  3.  1.  8. 11.] 
adversary cards in discard: [25.  0. 29. 29.  0. 11. 10. 25. 15. 11. 10.  0. 11.  3.  3. 10. 29.  3.
  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11] -> size -> 34 
adversary victory points: 8
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 3. 0.] 
cards in discard: [ 8.  3. 11.  0.  3.  0.  6.  6.  0.  3.  3.  6.  0.  0. 15.  3.  6.  6.
  0.  8. 15.  0.  0.  0. 15.  0.  0.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0  6
  6  0  8  6 11  0  6 15  8  3  0  0  8  3  0  0  0] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 29. 30. 20. 30.  8.  0. 10.  2.  5.  6.  6. 10. 10.  5. 10.  6.] 
adversary cards in hand: [11.  3.  1.  8. 11.] 
adversary cards in discard: [25.  0. 29. 29.  0. 11. 10. 25. 15. 11. 10.  0. 11.  3.  3. 10. 29.  3.
  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11] -> size -> 34 
adversary victory points: 8
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 3. 0.] 
cards in discard: [ 8.  3. 11.  0.  3.  0.  6.  6.  0.  3.  3.  6.  0.  0. 15.  3.  6.  6.
  0.  8. 15.  0.  0.  0. 15.  0.  0.  0.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0  6
  6  0  8  6 11  0  6 15  8  3  0  0  8  3  0  0  0  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 29. 30. 20. 30.  8.  0. 10.  2.  5.  6.  6. 10. 10.  5. 10.  6.] 
adversary cards in hand: [11.  3.  1.  8. 11.] 
adversary cards in discard: [25.  0. 29. 29.  0. 11. 10. 25. 15. 11. 10.  0. 11.  3.  3. 10. 29.  3.
  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11] -> size -> 34 
adversary victory points: 8
player victory points: -1 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [11.  3.  1.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 11.] 
expected returns: [[ 5.694819 ]
 [11.2666855]
 [ 3.423903 ]
 [11.2666855]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  1.  8. 11.] 
cards in discard: [25.  0. 29. 29.  0. 11. 10. 25. 15. 11. 10.  0. 11.  3.  3. 10. 29.  3.
  3.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 20. 30.  8.  0. 10.  2.  5.  6.  6. 10. 10.  5. 10.  6.] 
adversary cards in hand: [ 0. 11.  0.  6.  0.] 
adversary cards in discard: [ 8.  3. 11.  0.  3.  0.  6.  6.  0.  3.  3.  6.  0.  0. 15.  3.  6.  6.
  0.  8. 15.  0.  0.  0. 15.  0.  0.  0.  6.  0.  6.  3.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0  6
  6  0  8  6 11  0  6 15  8  3  0  0  8  3  0  0  0  0] -> size -> 42 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 7.173802852630615



action possibilites: [-1] 
expected returns: [[26.125751]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  8. 11.] 
cards in discard: [25.  0. 29. 29.  0. 11. 10. 25. 15. 11. 10.  0. 11.  3.  3. 10. 29.  3.
  3.  3.  3. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 20. 30.  8.  0. 10.  2.  5.  6.  6. 10. 10.  5. 10.  5.] 
adversary cards in hand: [ 0. 11.  0.  6.  0.] 
adversary cards in discard: [ 8.  3. 11.  0.  3.  0.  6.  6.  0.  3.  3.  6.  0.  0. 15.  3.  6.  6.
  0.  8. 15.  0.  0.  0. 15.  0.  0.  0.  6.  0.  6.  3.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0  6
  6  0  8  6 11  0  6 15  8  3  0  0  8  3  0  0  0  0] -> size -> 42 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 349 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 13.678569793701172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[17.525898]
 [25.754955]
 [24.701162]
 [27.733204]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  8. 11.] 
cards in discard: [25.  0. 29. 29.  0. 11. 10. 25. 15. 11. 10.  0. 11.  3.  3. 10. 29.  3.
  3.  3.  3. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 29. 30. 20. 30.  8.  0. 10.  2.  5.  6.  6. 10. 10.  5. 10.  5.] 
adversary cards in hand: [ 0. 11.  0.  6.  0.] 
adversary cards in discard: [ 8.  3. 11.  0.  3.  0.  6.  6.  0.  3.  3.  6.  0.  0. 15.  3.  6.  6.
  0.  8. 15.  0.  0.  0. 15.  0.  0.  0.  6.  0.  6.  3.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0  6
  6  0  8  6 11  0  6 15  8  3  0  0  8  3  0  0  0  0] -> size -> 42 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 26.125751495361328






Player: 1 
cards in hand: [ 0. 11.  0.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  6.  0.] 
cards in discard: [ 8.  3. 11.  0.  3.  0.  6.  6.  0.  3.  3.  6.  0.  0. 15.  3.  6.  6.
  0.  8. 15.  0.  0.  0. 15.  0.  0.  0.  6.  0.  6.  3.  6.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0  6
  6  0  8  6 11  0  6 15  8  3  0  0  8  3  0  0  0  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 20. 30.  8.  0. 10.  2.  5.  6.  6. 10. 10.  5. 10.  5.] 
adversary cards in hand: [ 3. 29. 25. 11. 25.] 
adversary cards in discard: [25.  0. 29. 29.  0. 11. 10. 25. 15. 11. 10.  0. 11.  3.  3. 10. 29.  3.
  3.  3.  3. 15. 11.  3.  1.  8. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15] -> size -> 35 
adversary victory points: 8
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0.] 
cards in discard: [ 8.  3. 11.  0.  3.  0.  6.  6.  0.  3.  3.  6.  0.  0. 15.  3.  6.  6.
  0.  8. 15.  0.  0.  0. 15.  0.  0.  0.  6.  0.  6.  3.  6.  3.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0  6
  6  0  8  6 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 20. 30.  8.  0. 10.  2.  5.  6.  6. 10. 10.  4. 10.  5.] 
adversary cards in hand: [ 3. 29. 25. 11. 25.] 
adversary cards in discard: [25.  0. 29. 29.  0. 11. 10. 25. 15. 11. 10.  0. 11.  3.  3. 10. 29.  3.
  3.  3.  3. 15. 11.  3.  1.  8. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15] -> size -> 35 
adversary victory points: 8
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0.] 
cards in discard: [ 8.  3. 11.  0.  3.  0.  6.  6.  0.  3.  3.  6.  0.  0. 15.  3.  6.  6.
  0.  8. 15.  0.  0.  0. 15.  0.  0.  0.  6.  0.  6.  3.  6.  3.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0  6
  6  0  8  6 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10] -> size -> 43 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 29. 30. 20. 30.  8.  0. 10.  2.  5.  6.  6. 10. 10.  4. 10.  5.] 
adversary cards in hand: [ 3. 29. 25. 11. 25.] 
adversary cards in discard: [25.  0. 29. 29.  0. 11. 10. 25. 15. 11. 10.  0. 11.  3.  3. 10. 29.  3.
  3.  3.  3. 15. 11.  3.  1.  8. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15] -> size -> 35 
adversary victory points: 8
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0.] 
cards in discard: [ 8.  3. 11.  0.  3.  0.  6.  6.  0.  3.  3.  6.  0.  0. 15.  3.  6.  6.
  0.  8. 15.  0.  0.  0. 15.  0.  0.  0.  6.  0.  6.  3.  6.  3.  0. 10.
 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0  6
  6  0  8  6 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 20. 30.  8.  0. 10.  2.  5.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [ 3. 29. 25. 11. 25.] 
adversary cards in discard: [25.  0. 29. 29.  0. 11. 10. 25. 15. 11. 10.  0. 11.  3.  3. 10. 29.  3.
  3.  3.  3. 15. 11.  3.  1.  8. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15] -> size -> 35 
adversary victory points: 8
player victory points: -1 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 3. 29. 25. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 11. 25.] 
expected returns: [[30.98785 ]
 [43.040318]
 [44.601376]
 [29.407562]
 [44.601376]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 25. 11. 25.] 
cards in discard: [25.  0. 29. 29.  0. 11. 10. 25. 15. 11. 10.  0. 11.  3.  3. 10. 29.  3.
  3.  3.  3. 15. 11.  3.  1.  8. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 20. 30.  8.  0. 10.  2.  5.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [0. 6. 6. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0  6
  6  0  8  6 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10] -> size -> 44 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 27.73318862915039



action possibilites: [-1] 
expected returns: [[76.976654]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 11. 25. 10.  0.] 
cards in discard: [25.  0. 29. 29.  0. 11. 10. 25. 15. 11. 10.  0. 11.  3.  3. 10. 29.  3.
  3.  3.  3. 15. 11.  3.  1.  8. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 20. 30.  8.  0. 10.  2.  5.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [0. 6. 6. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0  6
  6  0  8  6 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10] -> size -> 44 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 44.60139465332031





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[72.754265]
 [78.95193 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29. 11. 25. 10.  0.] 
cards in discard: [25.  0. 29. 29.  0. 11. 10. 25. 15. 11. 10.  0. 11.  3.  3. 10. 29.  3.
  3.  3.  3. 15. 11.  3.  1.  8. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 29. 30. 20. 30.  8.  0. 10.  2.  5.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [0. 6. 6. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0  6
  6  0  8  6 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10] -> size -> 44 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 76.97665405273438






Player: 1 
cards in hand: [0. 6. 6. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 3. 8.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15  0 11  0  0  6  0  6  6  3  6 15  6  3  0  6
  6  0  8  6 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 20. 30.  8.  0. 10.  2.  5.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [25.  1. 15. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15] -> size -> 35 
adversary victory points: 8
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6
  0  8  6 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 20. 30.  8.  0. 10.  2.  5.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [25.  1. 15. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15] -> size -> 35 
adversary victory points: 8
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6
  0  8  6 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 29. 30. 20. 30.  8.  0. 10.  2.  5.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [25.  1. 15. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15] -> size -> 35 
adversary victory points: 8
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3.] 
cards in discard: [0.] 
cards in deck: 39 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6
  0  8  6 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 29. 30. 20. 30.  8.  0. 10.  2.  5.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [25.  1. 15. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15] -> size -> 35 
adversary victory points: 8
player victory points: 0 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [25.  1. 15. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15. 11.  8.] 
expected returns: [[ 1.8191638]
 [16.480642 ]
 [-7.1130495]
 [ 6.625033 ]
 [ 0.7718315]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1. 15. 11.  8.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 20. 30.  8.  0. 10.  2.  5.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [0. 6. 0. 3. 0.] 
adversary cards in discard: [0. 8. 0. 6. 3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6
  0  8  6 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0] -> size -> 44 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 78.95191192626953



action possibilites: [-1] 
expected returns: [[-15.681179]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15. 11.  8. 11. 11.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 20. 30.  8.  0. 10.  2.  5.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [0. 6. 0. 3. 0.] 
adversary cards in discard: [0. 8. 0. 6. 3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6
  0  8  6 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0] -> size -> 44 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 16.480640411376953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-21.222832]
 [-16.037758]
 [-14.520248]
 [-14.956532]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15. 11.  8. 11. 11.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 29. 30. 20. 30.  8.  0. 10.  2.  5.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [0. 6. 0. 3. 0.] 
adversary cards in discard: [0. 8. 0. 6. 3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6
  0  8  6 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0] -> size -> 44 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: -15.68117904663086



buy possibilites: [-1] 
expected returns: [[-13.397128]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15. 11.  8. 11. 11.] 
cards in discard: [8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 20. 30.  8.  0. 10.  2.  4.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [0. 6. 0. 3. 0.] 
adversary cards in discard: [0. 8. 0. 6. 3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6
  0  8  6 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0] -> size -> 44 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0 -10   0   0  16   0] 
sum of rewards: 261 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -14.520254135131836






Player: 1 
cards in hand: [0. 6. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 3. 0.] 
cards in discard: [0. 8. 0. 6. 3.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6
  0  8  6 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 20. 30.  8.  0. 10.  2.  4.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [ 3. 29.  8.  0.  3.] 
adversary cards in discard: [ 8. 25.  1. 15. 11.  8. 11. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8] -> size -> 36 
adversary victory points: 8
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3. 0.] 
cards in discard: [0. 8. 0. 6. 3.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6
  0  8  6 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0] -> size -> 44 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 29. 30. 20. 30.  8.  0. 10.  2.  4.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [ 3. 29.  8.  0.  3.] 
adversary cards in discard: [ 8. 25.  1. 15. 11.  8. 11. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8] -> size -> 36 
adversary victory points: 8
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3. 0.] 
cards in discard: [0. 8. 0. 6. 3. 8.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6
  0  8  6 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8] -> size -> 45 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 29. 30. 20. 30.  8.  0. 10.  2.  3.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [ 3. 29.  8.  0.  3.] 
adversary cards in discard: [ 8. 25.  1. 15. 11.  8. 11. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8] -> size -> 36 
adversary victory points: 8
player victory points: 0 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 3. 29.  8.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[30.000275]
 [41.331207]
 [31.014423]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  8.  0.  3.] 
cards in discard: [ 8. 25.  1. 15. 11.  8. 11. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 20. 30.  8.  0. 10.  2.  3.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [6. 3. 6. 3. 8.] 
adversary cards in discard: [0. 8. 0. 6. 3. 8. 0. 6. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6
  0  8  6 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8] -> size -> 45 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: -13.397128105163574



action possibilites: [-1.] 
expected returns: [[-16.2551]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3.] 
cards in discard: [ 8. 25.  1. 15. 11.  8. 11. 11.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 29. 30. 20. 30.  8.  0. 10.  2.  3.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [6. 3. 6. 3. 8.] 
adversary cards in discard: [0. 8. 0. 6. 3. 8. 0. 6. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6
  0  8  6 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8] -> size -> 45 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 37.429508209228516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-25.695747]
 [-19.180162]
 [-18.893108]
 [-15.436302]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3.] 
cards in discard: [ 8. 25.  1. 15. 11.  8. 11. 11.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 29. 30. 20. 30.  8.  0. 10.  2.  3.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [6. 3. 6. 3. 8.] 
adversary cards in discard: [0. 8. 0. 6. 3. 8. 0. 6. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6
  0  8  6 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8] -> size -> 45 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.25510025024414






Player: 1 
cards in hand: [6. 3. 6. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 6. 3. 8.] 
cards in discard: [0. 8. 0. 6. 3. 8. 0. 6. 0. 3. 0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6
  0  8  6 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 20. 30.  8.  0. 10.  2.  3.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [29.  3.  3. 25. 25.] 
adversary cards in discard: [ 8. 25.  1. 15. 11.  8. 11. 11.  8. 29.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8] -> size -> 36 
adversary victory points: 8
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 3. 8.] 
cards in discard: [0. 8. 0. 6. 3. 8. 0. 6. 0. 3. 0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6
  0  8  6 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8] -> size -> 45 
action values: 1 
buys: 1 
player value: 0 
card supply: [16. 29. 30. 20. 30.  8.  0. 10.  2.  3.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [29.  3.  3. 25. 25.] 
adversary cards in discard: [ 8. 25.  1. 15. 11.  8. 11. 11.  8. 29.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8] -> size -> 36 
adversary victory points: 8
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 3. 8.] 
cards in discard: [0. 8. 0. 6. 3. 8. 0. 6. 0. 3. 0. 0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6
  0  8  6 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 20. 30.  8.  0. 10.  2.  3.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [29.  3.  3. 25. 25.] 
adversary cards in discard: [ 8. 25.  1. 15. 11.  8. 11. 11.  8. 29.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8] -> size -> 36 
adversary victory points: 8
player victory points: 0 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [29.  3.  3. 25. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 25.] 
expected returns: [[ 7.271754]
 [18.00266 ]
 [22.017357]
 [22.017357]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  3. 25. 25.] 
cards in discard: [ 8. 25.  1. 15. 11.  8. 11. 11.  8. 29.  3.  0.  3.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 20. 30.  8.  0. 10.  2.  3.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [0. 8. 0. 6. 3. 8. 0. 6. 0. 3. 0. 0. 6. 3. 6. 3. 8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6
  0  8  6 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0] -> size -> 46 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -15.436315536499023



action possibilites: [-1] 
expected returns: [[-2.0640316]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  3. 25. 29.  3.] 
cards in discard: [ 8. 25.  1. 15. 11.  8. 11. 11.  8. 29.  3.  0.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 20. 30.  8.  0. 10.  2.  3.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [0. 8. 0. 6. 3. 8. 0. 6. 0. 3. 0. 0. 6. 3. 6. 3. 8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6
  0  8  6 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0] -> size -> 46 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 22.017349243164062





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-11.377426 ]
 [ -1.3167186]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  3. 25. 29.  3.] 
cards in discard: [ 8. 25.  1. 15. 11.  8. 11. 11.  8. 29.  3.  0.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 29. 30. 20. 30.  8.  0. 10.  2.  3.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [0. 8. 0. 6. 3. 8. 0. 6. 0. 3. 0. 0. 6. 3. 6. 3. 8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6
  0  8  6 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0] -> size -> 46 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: -2.0640316009521484






Player: 1 
cards in hand: [8. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [0. 8. 0. 6. 3. 8. 0. 6. 0. 3. 0. 0. 6. 3. 6. 3. 8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6
  0  8  6 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 20. 30.  8.  0. 10.  2.  3.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [11.  0.  0. 11. 25.] 
adversary cards in discard: [ 8. 25.  1. 15. 11.  8. 11. 11.  8. 29.  3.  0.  3.  3. 25. 29.  3.  3.
 25. 29.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8] -> size -> 36 
adversary victory points: 8
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [0. 8. 0. 6. 3. 8. 0. 6. 0. 3. 0. 0. 6. 3. 6. 3. 8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6  0  8  6
 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 20. 30.  8.  0. 10.  2.  3.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [11.  0.  0. 11. 25.] 
adversary cards in discard: [ 8. 25.  1. 15. 11.  8. 11. 11.  8. 29.  3.  0.  3.  3. 25. 29.  3.  3.
 25. 29.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8] -> size -> 36 
adversary victory points: 8
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0. 8. 0. 6. 3. 8. 0. 6. 0. 3. 0. 0. 6. 3. 6. 3. 8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6  0  8  6
 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 29. 30. 20. 30.  8.  0. 10.  2.  3.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [11.  0.  0. 11. 25.] 
adversary cards in discard: [ 8. 25.  1. 15. 11.  8. 11. 11.  8. 29.  3.  0.  3.  3. 25. 29.  3.  3.
 25. 29.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8] -> size -> 36 
adversary victory points: 8
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0. 8. 0. 6. 3. 8. 0. 6. 0. 3. 0. 0. 6. 3. 6. 3. 8. 0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6  0  8  6
 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 29. 30. 20. 30.  8.  0. 10.  2.  3.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [11.  0.  0. 11. 25.] 
adversary cards in discard: [ 8. 25.  1. 15. 11.  8. 11. 11.  8. 29.  3.  0.  3.  3. 25. 29.  3.  3.
 25. 29.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8] -> size -> 36 
adversary victory points: 8
player victory points: 0 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [11.  0.  0. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 25.] 
expected returns: [[ 5.9198804]
 [10.104557 ]
 [10.104557 ]
 [22.479788 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 11. 25.] 
cards in discard: [ 8. 25.  1. 15. 11.  8. 11. 11.  8. 29.  3.  0.  3.  3. 25. 29.  3.  3.
 25. 29.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 20. 30.  8.  0. 10.  2.  3.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [ 0.  0. 11. 10.  0.] 
adversary cards in discard: [0. 8. 0. 6. 3. 8. 0. 6. 0. 3. 0. 0. 6. 3. 6. 3. 8. 0. 8. 0.] 
adversary owned cards: [ 0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6  0  8  6
 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0  0] -> size -> 44 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -1.3167176246643066



action possibilites: [-1] 
expected returns: [[41.665108]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 11. 10. 10.] 
cards in discard: [ 8. 25.  1. 15. 11.  8. 11. 11.  8. 29.  3.  0.  3.  3. 25. 29.  3.  3.
 25. 29.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 20. 30.  8.  0. 10.  2.  3.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [ 0.  0. 11. 10.  0.] 
adversary cards in discard: [0. 8. 0. 6. 3. 8. 0. 6. 0. 3. 0. 0. 6. 3. 6. 3. 8. 0. 8. 0.] 
adversary owned cards: [ 0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6  0  8  6
 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0  0] -> size -> 44 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 22.479755401611328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[46.22502 ]
 [55.192913]
 [49.55263 ]
 [43.17928 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0. 11. 10. 10.] 
cards in discard: [ 8. 25.  1. 15. 11.  8. 11. 11.  8. 29.  3.  0.  3.  3. 25. 29.  3.  3.
 25. 29.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 29. 30. 20. 30.  8.  0. 10.  2.  3.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [ 0.  0. 11. 10.  0.] 
adversary cards in discard: [0. 8. 0. 6. 3. 8. 0. 6. 0. 3. 0. 0. 6. 3. 6. 3. 8. 0. 8. 0.] 
adversary owned cards: [ 0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6  0  8  6
 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0  0] -> size -> 44 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 41.66510772705078



buy possibilites: [-1] 
expected returns: [[15.535624]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0. 11. 10. 10.] 
cards in discard: [ 8. 25.  1. 15. 11.  8. 11. 11.  8. 29.  3.  0.  3.  3. 25. 29.  3.  3.
 25. 29.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 19. 30.  8.  0. 10.  2.  3.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [ 0.  0. 11. 10.  0.] 
adversary cards in discard: [0. 8. 0. 6. 3. 8. 0. 6. 0. 3. 0. 0. 6. 3. 6. 3. 8. 0. 8. 0.] 
adversary owned cards: [ 0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6  0  8  6
 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0  0] -> size -> 44 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0 -20   0   0  16   0] 
sum of rewards: 281 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 55.1928825378418






Player: 1 
cards in hand: [ 0.  0. 11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 10.  0.] 
cards in discard: [0. 8. 0. 6. 3. 8. 0. 6. 0. 3. 0. 0. 6. 3. 6. 3. 8. 0. 8. 0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6  0  8  6
 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 19. 30.  8.  0. 10.  2.  3.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [10.  0. 11.  3. 29.] 
adversary cards in discard: [ 8. 25.  1. 15. 11.  8. 11. 11.  8. 29.  3.  0.  3.  3. 25. 29.  3.  3.
 25. 29.  3.  3. 25. 11.  0.  0. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8  3] -> size -> 37 
adversary victory points: 9
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [0. 8. 0. 6. 3. 8. 0. 6. 0. 3. 0. 0. 6. 3. 6. 3. 8. 0. 8. 0. 8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6  0  8  6
 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0  0  8] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 19. 30.  8.  0. 10.  2.  2.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [10.  0. 11.  3. 29.] 
adversary cards in discard: [ 8. 25.  1. 15. 11.  8. 11. 11.  8. 29.  3.  0.  3.  3. 25. 29.  3.  3.
 25. 29.  3.  3. 25. 11.  0.  0. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8  3] -> size -> 37 
adversary victory points: 9
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [0. 8. 0. 6. 3. 8. 0. 6. 0. 3. 0. 0. 6. 3. 6. 3. 8. 0. 8. 0. 8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6  0  8  6
 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0  0  8] -> size -> 45 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 29. 30. 19. 30.  8.  0. 10.  2.  2.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [10.  0. 11.  3. 29.] 
adversary cards in discard: [ 8. 25.  1. 15. 11.  8. 11. 11.  8. 29.  3.  0.  3.  3. 25. 29.  3.  3.
 25. 29.  3.  3. 25. 11.  0.  0. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8  3] -> size -> 37 
adversary victory points: 9
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [0. 8. 0. 6. 3. 8. 0. 6. 0. 3. 0. 0. 6. 3. 6. 3. 8. 0. 8. 0. 8. 8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6  0  8  6
 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0  0  8  8] -> size -> 46 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 29. 30. 19. 30.  8.  0. 10.  2.  1.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [10.  0. 11.  3. 29.] 
adversary cards in discard: [ 8. 25.  1. 15. 11.  8. 11. 11.  8. 29.  3.  0.  3.  3. 25. 29.  3.  3.
 25. 29.  3.  3. 25. 11.  0.  0. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8  3] -> size -> 37 
adversary victory points: 9
player victory points: 0 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [10.  0. 11.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 29.] 
expected returns: [[-63.165905]
 [-46.93869 ]
 [-47.47419 ]
 [-41.90112 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.  3. 29.] 
cards in discard: [ 8. 25.  1. 15. 11.  8. 11. 11.  8. 29.  3.  0.  3.  3. 25. 29.  3.  3.
 25. 29.  3.  3. 25. 11.  0.  0. 11. 10. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 19. 30.  8.  0. 10.  2.  1.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [ 0.  0.  6.  3. 15.] 
adversary cards in discard: [ 0.  8.  0.  6.  3.  8.  0.  6.  0.  3.  0.  0.  6.  3.  6.  3.  8.  0.
  8.  0.  8.  8. 11.  0.  0. 10.  0.] 
adversary owned cards: [ 0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6  0  8  6
 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0  0  8  8] -> size -> 46 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 15.535623550415039



action possibilites: [-1. 10. 11. 10.] 
expected returns: [[13.786728]
 [13.56628 ]
 [16.149769]
 [13.56628 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11. 10.] 
cards in discard: [ 8. 25.  1. 15. 11.  8. 11. 11.  8. 29.  3.  0.  3.  3. 25. 29.  3.  3.
 25. 29.  3.  3. 25. 11.  0.  0. 11. 10. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 29. 30. 19. 30.  8.  0. 10.  2.  1.  6.  6. 10. 10.  3. 10.  5.] 
adversary cards in hand: [ 0.  0.  6.  3. 15.] 
adversary cards in discard: [ 0.  8.  0.  6.  3.  8.  0.  6.  0.  3.  0.  0.  6.  3.  6.  3.  8.  0.
  8.  0.  8.  8. 11.  0.  0. 10.  0.] 
adversary owned cards: [ 0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6  0  8  6
 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0  0  8  8] -> size -> 46 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -45.95991897583008



action possibilites: [-1] 
expected returns: [[35.261597]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.] 
cards in discard: [ 8. 25.  1. 15. 11.  8. 11. 11.  8. 29.  3.  0.  3.  3. 25. 29.  3.  3.
 25. 29.  3.  3. 25. 11.  0.  0. 11. 10. 10.  3. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8  3 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 29. 30. 19. 30.  8.  0. 10.  2.  1.  6.  6. 10. 10.  3. 10.  4.] 
adversary cards in hand: [ 0.  0.  6.  3. 15.] 
adversary cards in discard: [ 0.  8.  0.  6.  3.  8.  0.  6.  0.  3.  0.  0.  6.  3.  6.  3.  8.  0.
  8.  0.  8.  8. 11.  0.  0. 10.  0.] 
adversary owned cards: [ 0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6  0  8  6
 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0  0  8  8] -> size -> 46 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0 -30   0   0  64   0] 
sum of rewards: 339 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 18.615205764770508





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[27.342068]
 [36.90962 ]
 [35.146946]
 [35.26163 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.] 
cards in discard: [ 8. 25.  1. 15. 11.  8. 11. 11.  8. 29.  3.  0.  3.  3. 25. 29.  3.  3.
 25. 29.  3.  3. 25. 11.  0.  0. 11. 10. 10.  3. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8  3 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 29. 30. 19. 30.  8.  0. 10.  2.  1.  6.  6. 10. 10.  3. 10.  4.] 
adversary cards in hand: [ 0.  0.  6.  3. 15.] 
adversary cards in discard: [ 0.  8.  0.  6.  3.  8.  0.  6.  0.  3.  0.  0.  6.  3.  6.  3.  8.  0.
  8.  0.  8.  8. 11.  0.  0. 10.  0.] 
adversary owned cards: [ 0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6  0  8  6
 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0  0  8  8] -> size -> 46 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action -1
Learning step: 0
desired expected reward: 35.2615966796875



buy possibilites: [-1] 
expected returns: [[11.613922]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.] 
cards in discard: [ 8. 25.  1. 15. 11.  8. 11. 11.  8. 29.  3.  0.  3.  3. 25. 29.  3.  3.
 25. 29.  3.  3. 25. 11.  0.  0. 11. 10. 10.  3. 15.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8  3 15  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 18. 30.  8.  0. 10.  2.  1.  6.  6. 10. 10.  3. 10.  4.] 
adversary cards in hand: [ 0.  0.  6.  3. 15.] 
adversary cards in discard: [ 0.  8.  0.  6.  3.  8.  0.  6.  0.  3.  0.  0.  6.  3.  6.  3.  8.  0.
  8.  0.  8.  8. 11.  0.  0. 10.  0.] 
adversary owned cards: [ 0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6  0  8  6
 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0  0  8  8] -> size -> 46 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0 -40   0   0  16   0] 
sum of rewards: 311 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 36.909603118896484






Player: 1 
cards in hand: [ 0.  0.  6.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6.  3. 15.] 
cards in discard: [ 0.  8.  0.  6.  3.  8.  0.  6.  0.  3.  0.  0.  6.  3.  6.  3.  8.  0.
  8.  0.  8.  8. 11.  0.  0. 10.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6  0  8  6
 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0  0  8  8] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 18. 30.  8.  0. 10.  2.  1.  6.  6. 10. 10.  3. 10.  4.] 
adversary cards in hand: [ 0. 11. 11.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8  3 15  3] -> size -> 39 
adversary victory points: 10
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6.  3. 15.] 
cards in discard: [ 0.  8.  0.  6.  3.  8.  0.  6.  0.  3.  0.  0.  6.  3.  6.  3.  8.  0.
  8.  0.  8.  8. 11.  0.  0. 10.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6  0  8  6
 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0  0  8  8] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 29. 30. 18. 30.  8.  0. 10.  2.  1.  6.  6. 10. 10.  3. 10.  4.] 
adversary cards in hand: [ 0. 11. 11.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8  3 15  3] -> size -> 39 
adversary victory points: 10
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6.  3. 15.] 
cards in discard: [ 0.  8.  0.  6.  3.  8.  0.  6.  0.  3.  0.  0.  6.  3.  6.  3.  8.  0.
  8.  0.  8.  8. 11.  0.  0. 10.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6  0  8  6
 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0  0  8  8  0] -> size -> 47 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 29. 30. 18. 30.  8.  0. 10.  2.  1.  6.  6. 10. 10.  3. 10.  4.] 
adversary cards in hand: [ 0. 11. 11.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8  3 15  3] -> size -> 39 
adversary victory points: 10
player victory points: 0 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 11.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 15.] 
expected returns: [[ -7.886308]
 [ -2.284929]
 [ -2.284929]
 [-16.451302]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  3. 15.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8  3 15  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 18. 30.  8.  0. 10.  2.  1.  6.  6. 10. 10.  3. 10.  4.] 
adversary cards in hand: [10.  0.  0.  3. 15.] 
adversary cards in discard: [ 0.  8.  0.  6.  3.  8.  0.  6.  0.  3.  0.  0.  6.  3.  6.  3.  8.  0.
  8.  0.  8.  8. 11.  0.  0. 10.  0.  0.  0.  0.  6.  3. 15.] 
adversary owned cards: [ 0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6  0  8  6
 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0  0  8  8  0] -> size -> 47 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 11.613922119140625



action possibilites: [-1] 
expected returns: [[-7.7652802]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3. 15.] 
cards in discard: [15.] 
cards in deck: 34 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8  3 15  3 15] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 18. 30.  8.  0. 10.  2.  1.  6.  6. 10. 10.  3. 10.  3.] 
adversary cards in hand: [10.  0.  0.  3. 15.] 
adversary cards in discard: [ 0.  8.  0.  6.  3.  8.  0.  6.  0.  3.  0.  0.  6.  3.  6.  3.  8.  0.
  8.  0.  8.  8. 11.  0.  0. 10.  0.  0.  0.  0.  6.  3. 15.] 
adversary owned cards: [ 0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6  0  8  6
 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0  0  8  8  0] -> size -> 47 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0 -50   0   0  64   0] 
sum of rewards: 329 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 3.022106647491455





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-13.947285]
 [ -7.938122]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3. 15.] 
cards in discard: [15.] 
cards in deck: 34 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8  3 15  3 15] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 29. 30. 18. 30.  8.  0. 10.  2.  1.  6.  6. 10. 10.  3. 10.  3.] 
adversary cards in hand: [10.  0.  0.  3. 15.] 
adversary cards in discard: [ 0.  8.  0.  6.  3.  8.  0.  6.  0.  3.  0.  0.  6.  3.  6.  3.  8.  0.
  8.  0.  8.  8. 11.  0.  0. 10.  0.  0.  0.  0.  6.  3. 15.] 
adversary owned cards: [ 0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6  0  8  6
 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0  0  8  8  0] -> size -> 47 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: -7.765280246734619






Player: 1 
cards in hand: [10.  0.  0.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3. 15.] 
cards in discard: [ 0.  8.  0.  6.  3.  8.  0.  6.  0.  3.  0.  0.  6.  3.  6.  3.  8.  0.
  8.  0.  8.  8. 11.  0.  0. 10.  0.  0.  0.  0.  6.  3. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6  0  8  6
 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0  0  8  8  0] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 18. 30.  8.  0. 10.  2.  1.  6.  6. 10. 10.  3. 10.  3.] 
adversary cards in hand: [11. 25. 25.  3. 10.] 
adversary cards in discard: [15. 11.  0. 11.  3. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8  3 15  3 15] -> size -> 40 
adversary victory points: 10
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3. 15.] 
cards in discard: [ 0.  8.  0.  6.  3.  8.  0.  6.  0.  3.  0.  0.  6.  3.  6.  3.  8.  0.
  8.  0.  8.  8. 11.  0.  0. 10.  0.  0.  0.  0.  6.  3. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6  0  8  6
 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0  0  8  8  0] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 29. 30. 18. 30.  8.  0. 10.  2.  1.  6.  6. 10. 10.  3. 10.  3.] 
adversary cards in hand: [11. 25. 25.  3. 10.] 
adversary cards in discard: [15. 11.  0. 11.  3. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8  3 15  3 15] -> size -> 40 
adversary victory points: 10
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3. 15.] 
cards in discard: [ 0.  8.  0.  6.  3.  8.  0.  6.  0.  3.  0.  0.  6.  3.  6.  3.  8.  0.
  8.  0.  8.  8. 11.  0.  0. 10.  0.  0.  0.  0.  6.  3. 15.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6  0  8  6
 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0  0  8  8  0  8] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 18. 30.  8.  0. 10.  2.  0.  6.  6. 10. 10.  3. 10.  3.] 
adversary cards in hand: [11. 25. 25.  3. 10.] 
adversary cards in discard: [15. 11.  0. 11.  3. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8  3 15  3 15] -> size -> 40 
adversary victory points: 10
player victory points: 0 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [11. 25. 25.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 25. 10.] 
expected returns: [[ 1.3294477]
 [ 6.677531 ]
 [14.443161 ]
 [14.443161 ]
 [ 2.4584436]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25. 25.  3. 10.] 
cards in discard: [15. 11.  0. 11.  3. 15.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8  3 15  3 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 18. 30.  8.  0. 10.  2.  0.  6.  6. 10. 10.  3. 10.  3.] 
adversary cards in hand: [ 3.  0. 11.  6.  0.] 
adversary cards in discard: [ 0.  8.  0.  6.  3.  8.  0.  6.  0.  3.  0.  0.  6.  3.  6.  3.  8.  0.
  8.  0.  8.  8. 11.  0.  0. 10.  0.  0.  0.  0.  6.  3. 15.  8. 10.  0.
  0.  3. 15.] 
adversary owned cards: [ 0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6  0  8  6
 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0  0  8  8  0  8] -> size -> 48 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -7.938133239746094



action possibilites: [-1] 
expected returns: [[27.675201]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25.  3. 10. 29. 10.] 
cards in discard: [15. 11.  0. 11.  3. 15.] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8  3 15  3 15] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 18. 30.  8.  0. 10.  2.  0.  6.  6. 10. 10.  3. 10.  3.] 
adversary cards in hand: [ 3.  0. 11.  6.  0.] 
adversary cards in discard: [ 0.  8.  0.  6.  3.  8.  0.  6.  0.  3.  0.  0.  6.  3.  6.  3.  8.  0.
  8.  0.  8.  8. 11.  0.  0. 10.  0.  0.  0.  0.  6.  3. 15.  8. 10.  0.
  0.  3. 15.] 
adversary owned cards: [ 0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6  0  8  6
 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0  0  8  8  0  8] -> size -> 48 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 14.443153381347656





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[25.834818]
 [27.938763]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 25.  3. 10. 29. 10.] 
cards in discard: [15. 11.  0. 11.  3. 15.] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8  3 15  3 15] -> size -> 40 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 29. 30. 18. 30.  8.  0. 10.  2.  0.  6.  6. 10. 10.  3. 10.  3.] 
adversary cards in hand: [ 3.  0. 11.  6.  0.] 
adversary cards in discard: [ 0.  8.  0.  6.  3.  8.  0.  6.  0.  3.  0.  0.  6.  3.  6.  3.  8.  0.
  8.  0.  8.  8. 11.  0.  0. 10.  0.  0.  0.  0.  6.  3. 15.  8. 10.  0.
  0.  3. 15.] 
adversary owned cards: [ 0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6  0  8  6
 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0  0  8  8  0  8] -> size -> 48 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: 27.675201416015625






Player: 1 
cards in hand: [ 3.  0. 11.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  6.  0.] 
cards in discard: [ 0.  8.  0.  6.  3.  8.  0.  6.  0.  3.  0.  0.  6.  3.  6.  3.  8.  0.
  8.  0.  8.  8. 11.  0.  0. 10.  0.  0.  0.  0.  6.  3. 15.  8. 10.  0.
  0.  3. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6  0  8  6
 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0  0  8  8  0  8] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 18. 30.  8.  0. 10.  2.  0.  6.  6. 10. 10.  3. 10.  3.] 
adversary cards in hand: [25.  3.  3.  0. 11.] 
adversary cards in discard: [15. 11.  0. 11.  3. 15. 25. 11. 25.  3. 10. 29. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8  3 15  3 15] -> size -> 40 
adversary victory points: 10
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 0.] 
cards in discard: [ 0.  8.  0.  6.  3.  8.  0.  6.  0.  3.  0.  0.  6.  3.  6.  3.  8.  0.
  8.  0.  8.  8. 11.  0.  0. 10.  0.  0.  0.  0.  6.  3. 15.  8. 10.  0.
  0.  3. 15. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6  0  8  6
 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0  0  8  8  0  8
 14] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 18. 30.  8.  0. 10.  2.  0.  6.  6.  9. 10.  3. 10.  3.] 
adversary cards in hand: [25.  3.  3.  0. 11.] 
adversary cards in discard: [15. 11.  0. 11.  3. 15. 25. 11. 25.  3. 10. 29. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8  3 15  3 15] -> size -> 40 
adversary victory points: 10
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0.] 
cards in discard: [ 0.  8.  0.  6.  3.  8.  0.  6.  0.  3.  0.  0.  6.  3.  6.  3.  8.  0.
  8.  0.  8.  8. 11.  0.  0. 10.  0.  0.  0.  0.  6.  3. 15.  8. 10.  0.
  0.  3. 15. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6  0  8  6
 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0  0  8  8  0  8
 14] -> size -> 49 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 29. 30. 18. 30.  8.  0. 10.  2.  0.  6.  6.  9. 10.  3. 10.  3.] 
adversary cards in hand: [25.  3.  3.  0. 11.] 
adversary cards in discard: [15. 11.  0. 11.  3. 15. 25. 11. 25.  3. 10. 29. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8  3 15  3 15] -> size -> 40 
adversary victory points: 10
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0.] 
cards in discard: [ 0.  8.  0.  6.  3.  8.  0.  6.  0.  3.  0.  0.  6.  3.  6.  3.  8.  0.
  8.  0.  8.  8. 11.  0.  0. 10.  0.  0.  0.  0.  6.  3. 15.  8. 10.  0.
  0.  3. 15. 14.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6  0  8  6
 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0  0  8  8  0  8
 14  3] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 17. 30.  8.  0. 10.  2.  0.  6.  6.  9. 10.  3. 10.  3.] 
adversary cards in hand: [25.  3.  3.  0. 11.] 
adversary cards in discard: [15. 11.  0. 11.  3. 15. 25. 11. 25.  3. 10. 29. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8  3 15  3 15] -> size -> 40 
adversary victory points: 10
player victory points: 1 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [25.  3.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[15.085608]
 [30.846123]
 [22.698648]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  3.  0. 11.] 
cards in discard: [15. 11.  0. 11.  3. 15. 25. 11. 25.  3. 10. 29. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8  3 15  3 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 17. 30.  8.  0. 10.  2.  0.  6.  6.  9. 10.  3. 10.  3.] 
adversary cards in hand: [ 0.  3. 15.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6  0  8  6
 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0  0  8  8  0  8
 14  3] -> size -> 50 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 27.938758850097656



action possibilites: [-1] 
expected returns: [[25.169476]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 11. 25. 15.] 
cards in discard: [15. 11.  0. 11.  3. 15. 25. 11. 25.  3. 10. 29. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8  3 15  3 15] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 17. 30.  8.  0. 10.  2.  0.  6.  6.  9. 10.  3. 10.  3.] 
adversary cards in hand: [ 0.  3. 15.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6  0  8  6
 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0  0  8  8  0  8
 14  3] -> size -> 50 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 30.846141815185547





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[19.615631]
 [24.97874 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 11. 25. 15.] 
cards in discard: [15. 11.  0. 11.  3. 15. 25. 11. 25.  3. 10. 29. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8  3 15  3 15] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 29. 30. 17. 30.  8.  0. 10.  2.  0.  6.  6.  9. 10.  3. 10.  3.] 
adversary cards in hand: [ 0.  3. 15.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6  0  8  6
 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0  0  8  8  0  8
 14  3] -> size -> 50 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 25.169475555419922






Player: 1 
cards in hand: [ 0.  3. 15.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15.  6.  6.] 
cards in discard: [] 
cards in deck: 45 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6  0  8  6
 11  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0  0  8  8  0  8
 14  3] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 17. 30.  8.  0. 10.  2.  0.  6.  6.  9. 10.  3. 10.  3.] 
adversary cards in hand: [ 1. 29.  3. 11. 11.] 
adversary cards in discard: [15. 11.  0. 11.  3. 15. 25. 11. 25.  3. 10. 29. 10. 25.  3.  3.  0. 11.
 25. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8  3 15  3 15] -> size -> 40 
adversary victory points: 10
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6.] 
cards in discard: [] 
cards in deck: 45 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6  0  8  6 11
  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0  0  8  8  0  8 14
  3] -> size -> 49 
action values: 0 
buys: 0 
player value: 3 
card supply: [13. 29. 30. 17. 30.  8.  0. 10.  2.  0.  6.  6.  9. 10.  3. 10.  3.] 
adversary cards in hand: [ 1. 29.  3. 11. 11.] 
adversary cards in discard: [15. 11.  0. 11.  3. 15. 25. 11. 25.  3. 10. 29. 10. 25.  3.  3.  0. 11.
 25. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8  3 15  3 15] -> size -> 40 
adversary victory points: 10
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6.] 
cards in discard: [] 
cards in deck: 45 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6  0  8  6 11
  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0  0  8  8  0  8 14
  3] -> size -> 49 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 29. 30. 17. 30.  8.  0. 10.  2.  0.  6.  6.  9. 10.  3. 10.  3.] 
adversary cards in hand: [ 1. 29.  3. 11. 11.] 
adversary cards in discard: [15. 11.  0. 11.  3. 15. 25. 11. 25.  3. 10. 29. 10. 25.  3.  3.  0. 11.
 25. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8  3 15  3 15] -> size -> 40 
adversary victory points: 10
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6.] 
cards in discard: [11.] 
cards in deck: 45 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6  0  8  6 11
  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0  0  8  8  0  8 14
  3 11] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 17. 30.  8.  0. 10.  1.  0.  6.  6.  9. 10.  3. 10.  3.] 
adversary cards in hand: [ 1. 29.  3. 11. 11.] 
adversary cards in discard: [15. 11.  0. 11.  3. 15. 25. 11. 25.  3. 10. 29. 10. 25.  3.  3.  0. 11.
 25. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8  3 15  3 15] -> size -> 40 
adversary victory points: 10
player victory points: 1 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [ 1. 29.  3. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11.] 
expected returns: [[ 7.425134]
 [27.13491 ]
 [19.811302]
 [19.811302]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  3. 11. 11.] 
cards in discard: [15. 11.  0. 11.  3. 15. 25. 11. 25.  3. 10. 29. 10. 25.  3.  3.  0. 11.
 25. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8  3 15  3 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 17. 30.  8.  0. 10.  1.  0.  6.  6.  9. 10.  3. 10.  3.] 
adversary cards in hand: [3. 0. 8. 6. 0.] 
adversary cards in discard: [11. 15.  3.  6.  6.] 
adversary owned cards: [ 3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6  0  8  6 11
  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0  0  8  8  0  8 14
  3 11] -> size -> 50 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 24.978740692138672



action possibilites: [-1. 11.] 
expected returns: [[42.837025]
 [52.64998 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  3.] 
cards in discard: [15. 11.  0. 11.  3. 15. 25. 11. 25.  3. 10. 29. 10. 25.  3.  3.  0. 11.
 25. 15.  3. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8  3 15  3 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [13. 29. 30. 17. 30.  8.  0. 10.  1.  0.  6.  6.  9. 10.  3. 10.  3.] 
adversary cards in hand: [3. 0. 8. 6. 0.] 
adversary cards in discard: [11. 15.  3.  6.  6.] 
adversary owned cards: [ 3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6  0  8  6 11
  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0  0  8  8  0  8 14
  3 11] -> size -> 50 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 5
Learning step: 0
desired expected reward: 19.878582000732422



action possibilites: [-1] 
expected returns: [[18.948284]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3.] 
cards in discard: [15. 11.  0. 11.  3. 15. 25. 11. 25.  3. 10. 29. 10. 25.  3.  3.  0. 11.
 25. 15.  3. 11.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8  3 15  3 15  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 28. 30. 17. 30.  8.  0. 10.  1.  0.  6.  6.  9. 10.  3. 10.  3.] 
adversary cards in hand: [3. 0. 8. 6. 0.] 
adversary cards in discard: [11. 15.  3.  6.  6.] 
adversary owned cards: [ 3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6  0  8  6 11
  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0  0  8  8  0  8 14
  3 11] -> size -> 50 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0 -60   0   0  27   0] 
sum of rewards: 272 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 57.58786392211914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[10.724367]
 [23.37821 ]
 [17.883112]
 [23.776361]
 [20.186626]
 [20.355566]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3.] 
cards in discard: [15. 11.  0. 11.  3. 15. 25. 11. 25.  3. 10. 29. 10. 25.  3.  3.  0. 11.
 25. 15.  3. 11.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8  3 15  3 15  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 28. 30. 17. 30.  8.  0. 10.  1.  0.  6.  6.  9. 10.  3. 10.  3.] 
adversary cards in hand: [3. 0. 8. 6. 0.] 
adversary cards in discard: [11. 15.  3.  6.  6.] 
adversary owned cards: [ 3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6  0  8  6 11
  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0  0  8  8  0  8 14
  3 11] -> size -> 50 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action -1
Learning step: 0
desired expected reward: 18.948284149169922



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 1 
Gold: 0 
Estate: 7 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 7 
Chapel: 2 
Witch: 4 
Poacher: 4 
Militia: 0 
Market: 0 
Village: 1 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [1. 3.] 
cards in discard: [15. 11.  0. 11.  3. 15. 25. 11. 25.  3. 10. 29. 10. 25.  3.  3.  0. 11.
 25. 15.  3. 11.  1. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3  3 11 29 11 25 10  1 25 10  3 25 29  3 29 10 11  8 29
 25 15  3  3 11  8  3 11 10 11 15  8  3 15  3 15  1 11] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 17. 30.  8.  0. 10.  0.  0.  6.  6.  9. 10.  3. 10.  3.] 
adversary cards in hand: [3. 0. 8. 6. 0.] 
adversary cards in discard: [11. 15.  3.  6.  6.] 
adversary owned cards: [ 3  3  3  3 15  0 11  0  0  0  6  6  3  6 15  6  3  0  6  6  0  8  6 11
  0  6 15  8  3  0  0  8  3  0  0  0  0 10 10  0  8  0  0  8  8  0  8 14
  3 11] -> size -> 50 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[     -5 3000000       0     270       0       0      40       0       0
       0       0     -70       0       0      27       0] 
sum of rewards: 3000262 

action type: buy - action 11.0
Learning step: 120009.5234375
desired expected reward: 120033.296875



