 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[117.86904]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0      30       0       0       0       0       0
       0       0     -50       0       0       8       0] 
sum of rewards: 2999983 

action type: buy - action 8.0
Learning step: 119999.015625
desired expected reward: 120006.5390625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[113.04943 ]
 [115.077156]
 [107.083984]
 [117.70287 ]
 [116.7365  ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 118.27352905273438



buy possibilites: [-1] 
expected returns: [[113.50727]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 16  0] 
sum of rewards: 11 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 117.70287322998047






Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [8. 3. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [8. 3. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [8. 3. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[110.27311]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [8. 3. 0. 0. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 113.50727081298828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[105.967186]
 [109.92412 ]
 [107.98218 ]
 [102.207054]
 [100.426216]
 [109.708374]
 [112.62752 ]
 [110.60415 ]
 [118.42211 ]
 [114.305336]
 [104.720924]
 [107.71734 ]
 [108.66222 ]
 [103.88828 ]
 [108.61311 ]
 [109.64851 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [8. 3. 0. 0. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 111.74224090576172



buy possibilites: [-1] 
expected returns: [[112.53429]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 8.  3.  0.  0.  3.  3. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 250   0] 
sum of rewards: 245 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 118.4220962524414






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25] -> size -> 12 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[110.00861]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 112.53428649902344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[105.493866]
 [109.74353 ]
 [107.653305]
 [ 99.20451 ]
 [112.64121 ]
 [110.48162 ]
 [108.391396]
 [109.30419 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 111.1116714477539



buy possibilites: [-1] 
expected returns: [[109.34734]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 112.64118957519531






Player: 1 
cards in hand: [0. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25.  0.  3.  0.  8.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25.  0.  3.  0.  8.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25.  0.  3.  0.  8.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [25.  0.  3.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[118.39589]
 [127.87089]
 [119.40397]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  3.  0.  8.] 
cards in discard: [11.  3.  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 3. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 109.34734344482422



action possibilites: [-1] 
expected returns: [[112.40756]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8. 0. 0.] 
cards in discard: [11.  3.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 3. 3. 3. 0. 6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 129.48899841308594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[113.247955]
 [117.32268 ]
 [115.313576]
 [107.08342 ]
 [117.09661 ]
 [120.09987 ]
 [118.03424 ]
 [121.80217 ]
 [111.869705]
 [116.02515 ]
 [115.944405]
 [116.84958 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 8. 0. 0.] 
cards in discard: [11.  3.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 3. 3. 3. 0. 6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 112.40756225585938



buy possibilites: [-1] 
expected returns: [[96.9448]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 8. 0. 0.] 
cards in discard: [11.  3.  0.  3.  0.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  9.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 3. 3. 3. 0. 6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 121.80216217041016






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 3. 3. 3. 0. 6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  9.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  3.  0. 25. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11 29] -> size -> 14 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 3. 3. 3. 0. 6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  9.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  3.  0. 25. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11 29] -> size -> 14 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 3. 3. 3. 0. 6. 4.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 4] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 29.  8.  9. 10.  9.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  3.  0. 25. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11 29] -> size -> 14 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [29.  3.  0. 25. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 11.] 
expected returns: [[108.194756]
 [112.39978 ]
 [116.19198 ]
 [110.770195]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0. 25. 11.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 29.  8.  9. 10.  9.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [4. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 4] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 96.9448013305664



action possibilites: [-1] 
expected returns: [[107.588554]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 29.  8.  8. 10.  9.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [4. 0. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 4 6] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 117.44263458251953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[102.67167 ]
 [104.74701 ]
 [ 96.3623  ]
 [107.54366 ]
 [106.160126]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 30. 29.  8.  8. 10.  9.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [4. 0. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 4 6] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 107.58855438232422



buy possibilites: [-1] 
expected returns: [[103.36898]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0. 11.  3.  0.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11 29  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 29.  8.  8. 10.  9.  8.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [4. 0. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 4 6] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -29 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 107.54366302490234






Player: 1 
cards in hand: [4. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 0. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 4 6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 29.  8.  8. 10.  9.  8.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [ 8. 25. 29.  3.  0. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11 29  8] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 0 6 4 6] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 30. 29.  8.  8. 10.  9.  8.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [ 8. 25. 29.  3.  0. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11 29  8] -> size -> 15 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0. 0. 0. 0.] 
cards in discard: [ 6. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0  6  4  6 15] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 29.  8.  8. 10.  9.  8.  9.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [ 8. 25. 29.  3.  0. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11 29  8] -> size -> 15 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [0. 8. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[102.71817]
 [103.89039]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 3.] 
cards in discard: [ 8. 25. 29.  3.  0. 11.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 11 29  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 29.  8.  8. 10.  9.  8.  9.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 6. 3.] 
adversary cards in discard: [ 6. 15.  4.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0  6  4  6 15] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 103.36898040771484



action possibilites: [-1] 
expected returns: [[110.146355]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8. 25. 29.  3.  0. 11.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 11 29  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 29.  8.  8. 10.  9.  8.  9.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 6. 3.] 
adversary cards in discard: [ 6. 15.  4.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0  6  4  6 15] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 107.94639587402344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[108.258095]
 [112.02237 ]
 [110.16592 ]
 [102.56955 ]
 [114.584335]
 [112.67652 ]
 [110.82009 ]
 [111.61001 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8. 25. 29.  3.  0. 11.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 11 29  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 29.  8.  8. 10.  9.  8.  9.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 6. 3.] 
adversary cards in discard: [ 6. 15.  4.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0  6  4  6 15] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 110.14635467529297



buy possibilites: [-1] 
expected returns: [[112.189476]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8. 25. 29.  3.  0. 11.  3.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 11 29  8 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 29.  8.  8. 10.  8.  8.  9.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 6. 3.] 
adversary cards in discard: [ 6. 15.  4.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0  6  4  6 15] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 9 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 114.5843276977539






Player: 1 
cards in hand: [0. 0. 3. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 6. 3.] 
cards in discard: [ 6. 15.  4.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0  6  4  6 15] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 29.  8.  8. 10.  8.  8.  9.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 11 29  8 11] -> size -> 15 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 3.] 
cards in discard: [ 6. 15.  4.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0  6  4  6 15] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 30. 29.  8.  8. 10.  8.  8.  9.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 11 29  8 11] -> size -> 15 
adversary victory points: 2
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [0. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[100.05543 ]
 [100.919655]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 11 29  8 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 29.  8.  8. 10.  8.  8.  9.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0  6  4  6 15] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 112.1894760131836



action possibilites: [-1] 
expected returns: [[103.96769]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  8 25 11 29  8 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 29.  8.  8. 10.  8.  8.  9.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0  6  4  6 15] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 102.79238891601562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 99.45237]
 [101.46291]
 [ 93.76709]
 [104.23179]
 [102.87529]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  8 25 11 29  8 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 30. 29.  8.  8. 10.  8.  8.  9.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0  6  4  6 15] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 103.96768951416016



buy possibilites: [-1] 
expected returns: [[96.51295]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  8 25 11 29  8 11  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 29.  8.  8. 10.  8.  7.  9.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0  6  4  6 15] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -29 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 104.23177337646484






Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0  6  4  6 15] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 29.  8.  8. 10.  8.  7.  9.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 11. 25.] 
adversary cards in discard: [8. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 25 11 29  8 11  8] -> size -> 14 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0  6  4  6 15] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 29.  8.  8. 10.  8.  7.  9.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 11. 25.] 
adversary cards in discard: [8. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 25 11 29  8 11  8] -> size -> 14 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0  6  4  6 15  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 30. 30. 30. 29.  8.  8. 10.  8.  7.  9.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 11. 25.] 
adversary cards in discard: [8. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 25 11 29  8 11  8] -> size -> 14 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 25.] 
expected returns: [[115.87087 ]
 [119.055374]
 [119.055374]
 [124.129524]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 11. 25.] 
cards in discard: [8. 8. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 25 11 29  8 11  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 29.  8.  8. 10.  8.  7.  9.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  6.  4. 15.] 
adversary cards in discard: [0. 3. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0  6  4  6 15  0] -> size -> 17 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 96.51294708251953



action possibilites: [-1] 
expected returns: [[90.29349]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 11.  3.  0.] 
cards in discard: [8. 8. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  8 25 11 29  8 11  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 29.  8.  7. 10.  8.  7.  9.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  6.  4. 15.] 
adversary cards in discard: [0. 3. 0. 0. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6] -> size -> 18 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 124.52821350097656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[90.34582 ]
 [94.28721 ]
 [92.35676 ]
 [84.12825 ]
 [97.175415]
 [94.96586 ]
 [93.03542 ]
 [93.96807 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 11.  3.  0.] 
cards in discard: [8. 8. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  8 25 11 29  8 11  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 30. 29.  8.  7. 10.  8.  7.  9.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  6.  4. 15.] 
adversary cards in discard: [0. 3. 0. 0. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6] -> size -> 18 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 90.29348754882812



buy possibilites: [-1] 
expected returns: [[102.649025]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 11.  3.  0.] 
cards in discard: [ 8.  8.  0.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  8 25 11 29  8 11  8 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 29.  8.  7. 10.  7.  7.  9.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  6.  4. 15.] 
adversary cards in discard: [0. 3. 0. 0. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6] -> size -> 18 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 9 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 97.17540740966797






Player: 1 
cards in hand: [ 0.  0.  6.  4. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6.  4. 15.] 
cards in discard: [0. 3. 0. 0. 3. 0. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 29.  8.  7. 10.  7.  7.  9.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  8. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 25 11 29  8 11  8 11] -> size -> 15 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6.  4. 15.] 
cards in discard: [0. 3. 0. 0. 3. 0. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 30. 29.  8.  7. 10.  7.  7.  9.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  8. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 25 11 29  8 11  8 11] -> size -> 15 
adversary victory points: 2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  8. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[101.41815 ]
 [102.39562 ]
 [105.404274]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8. 29.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 25 11 29  8 11  8 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 29.  8.  7. 10.  7.  7.  9.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 6. 0. 0.] 
adversary cards in discard: [ 0.  3.  0.  0.  3.  0.  6.  0.  0.  6.  4. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6] -> size -> 18 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 102.6490249633789



action possibilites: [-1.  8.] 
expected returns: [[115.49564]
 [116.82391]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  8 25 11 29  8 11  8 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 30. 29.  8.  7. 10.  7.  7.  9.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 6. 0. 0.] 
adversary cards in discard: [ 0.  3.  0.  0.  3.  0.  6.  0.  0.  6.  4. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6] -> size -> 18 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 107.37796783447266



action possibilites: [-1] 
expected returns: [[100.27993]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  8 25 11 29  8 11  8 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 30. 29.  8.  7. 10.  7.  7.  9.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 6. 0. 0.] 
adversary cards in discard: [ 0.  3.  0.  0.  3.  0.  6.  0.  0.  6.  4. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6] -> size -> 18 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 118.06831359863281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 96.972176]
 [ 98.3397  ]
 [ 92.18749 ]
 [100.348755]
 [ 98.7925  ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  8 25 11 29  8 11  8 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 30. 29.  8.  7. 10.  7.  7.  9.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 6. 0. 0.] 
adversary cards in discard: [ 0.  3.  0.  0.  3.  0.  6.  0.  0.  6.  4. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6] -> size -> 18 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 100.2799301147461



buy possibilites: [-1] 
expected returns: [[99.61767]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  8 25 11 29  8 11  8 11  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 29.  8.  7. 10.  7.  6.  9.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 6. 0. 0.] 
adversary cards in discard: [ 0.  3.  0.  0.  3.  0.  6.  0.  0.  6.  4. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6] -> size -> 18 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0  16   0] 
sum of rewards: -39 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 100.3487548828125






Player: 1 
cards in hand: [3. 0. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 0. 0.] 
cards in discard: [ 0.  3.  0.  0.  3.  0.  6.  0.  0.  6.  4. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 29.  8.  7. 10.  7.  6.  9.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 25.  0. 11.  0.] 
adversary cards in discard: [ 8. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  8 25 11 29  8 11  8 11  8] -> size -> 13 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 0.] 
cards in discard: [ 0.  3.  0.  0.  3.  0.  6.  0.  0.  6.  4. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 30. 29.  8.  7. 10.  7.  6.  9.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 25.  0. 11.  0.] 
adversary cards in discard: [ 8. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  8 25 11 29  8 11  8 11  8] -> size -> 13 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 0.] 
cards in discard: [ 0.  3.  0.  0.  3.  0.  6.  0.  0.  6.  4. 15.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 30. 30. 30. 29.  8.  7. 10.  7.  6.  9.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 25.  0. 11.  0.] 
adversary cards in discard: [ 8. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  8 25 11 29  8 11  8 11  8] -> size -> 13 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[119.875   ]
 [126.953606]
 [122.504036]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0. 11.  0.] 
cards in discard: [ 8. 29.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8 25 11 29  8 11  8 11  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 29.  8.  7. 10.  7.  6.  9.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0] -> size -> 19 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 99.61766815185547



action possibilites: [-1] 
expected returns: [[83.482796]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0. 11. 11.] 
cards in discard: [ 8. 29.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  8 25 11 29  8 11  8 11  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 29.  8.  6. 10.  7.  6.  9.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6] -> size -> 20 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 126.63117218017578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[79.00992 ]
 [82.366905]
 [80.726906]
 [74.21582 ]
 [84.85739 ]
 [82.940384]
 [81.30038 ]
 [82.15992 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0. 11. 11.] 
cards in discard: [ 8. 29.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  8 25 11 29  8 11  8 11  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 30. 29.  8.  6. 10.  7.  6.  9.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6] -> size -> 20 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 83.48279571533203



buy possibilites: [-1] 
expected returns: [[113.004425]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0. 11. 11.] 
cards in discard: [ 8. 29.  8.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  8 25 11 29  8 11  8 11  8 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 29.  8.  6. 10.  6.  6.  9.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6] -> size -> 20 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: -21 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 84.85737609863281






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 29.  8.  6. 10.  6.  6.  9.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  8. 11.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8 25 11 29  8 11  8 11  8 11] -> size -> 14 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 30. 30. 30. 29.  8.  6. 10.  6.  6.  9.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  8. 11.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8 25 11 29  8 11  8 11  8 11] -> size -> 14 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [6. 1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 30. 29.  8.  6. 10.  6.  6.  9.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  8. 11.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8 25 11 29  8 11  8 11  8 11] -> size -> 14 
adversary victory points: 0
player victory points: 2 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0.  8. 11.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.  8.  8.] 
expected returns: [[91.38565 ]
 [92.491844]
 [94.44299 ]
 [92.491844]
 [92.491844]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11.  8.  8.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8 25 11 29  8 11  8 11  8 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 29.  8.  6. 10.  6.  6.  9.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 4. 0. 0. 6.] 
adversary cards in discard: [6. 1. 0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1] -> size -> 21 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 113.00442504882812



action possibilites: [-1] 
expected returns: [[86.7305]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 8.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  8 25 11 29  8 11  8 11  8 11 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 29.  8.  6. 10.  6.  6.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 4. 0. 0. 6.] 
adversary cards in discard: [6. 1. 0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1] -> size -> 21 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -18 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 95.84944152832031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[85.212296]
 [81.28732 ]
 [86.89971 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8. 8.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  8 25 11 29  8 11  8 11  8 11 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 30. 29.  8.  6. 10.  6.  6.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 4. 0. 0. 6.] 
adversary cards in discard: [6. 1. 0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1] -> size -> 21 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 86.73049926757812






Player: 1 
cards in hand: [0. 4. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 4. 0. 0. 6.] 
cards in discard: [6. 1. 0. 0. 0. 3. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 29.  8.  6. 10.  6.  6.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11. 25. 11. 11.  0.] 
adversary cards in discard: [10. 11.  0.  8.  8.  8.] 
adversary owned cards: [ 0  0  0  0  8 25 11 29  8 11  8 11  8 11 10] -> size -> 15 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 4. 0. 0. 6.] 
cards in discard: [6. 1. 0. 0. 0. 3. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 30. 29.  8.  6. 10.  6.  6.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11. 25. 11. 11.  0.] 
adversary cards in discard: [10. 11.  0.  8.  8.  8.] 
adversary owned cards: [ 0  0  0  0  8 25 11 29  8 11  8 11  8 11 10] -> size -> 15 
adversary victory points: 0
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [11. 25. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 11. 11.] 
expected returns: [[ 97.018265]
 [100.03808 ]
 [105.57345 ]
 [100.03808 ]
 [100.03808 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25. 11. 11.  0.] 
cards in discard: [10. 11.  0.  8.  8.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8 25 11 29  8 11  8 11  8 11 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 29.  8.  6. 10.  6.  6.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  0.  3.] 
adversary cards in discard: [6. 1. 0. 0. 0. 3. 0. 0. 4. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1] -> size -> 21 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 86.89971160888672



action possibilites: [-1] 
expected returns: [[82.65925]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 11.  0. 29.  0.] 
cards in discard: [10. 11.  0.  8.  8.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  8 25 11 29  8 11  8 11  8 11 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 29.  8.  5. 10.  6.  6.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  0.  3.] 
adversary cards in discard: [6. 1. 0. 0. 0. 3. 0. 0. 4. 0. 0. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6] -> size -> 22 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 104.22998046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[77.627945]
 [79.27597 ]
 [72.86486 ]
 [81.44684 ]
 [80.521805]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 11.  0. 29.  0.] 
cards in discard: [10. 11.  0.  8.  8.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  8 25 11 29  8 11  8 11  8 11 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 30. 29.  8.  5. 10.  6.  6.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  0.  3.] 
adversary cards in discard: [6. 1. 0. 0. 0. 3. 0. 0. 4. 0. 0. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6] -> size -> 22 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 82.65924835205078



buy possibilites: [-1] 
expected returns: [[85.58364]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 11.  0. 29.  0.] 
cards in discard: [10. 11.  0.  8.  8.  8.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  8 25 11 29  8 11  8 11  8 11 10  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 29.  8.  5. 10.  6.  5.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.  0.  3.] 
adversary cards in discard: [6. 1. 0. 0. 0. 3. 0. 0. 4. 0. 0. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6] -> size -> 22 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -29 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 81.44683074951172






Player: 1 
cards in hand: [ 0. 15.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.  0.  3.] 
cards in discard: [6. 1. 0. 0. 0. 3. 0. 0. 4. 0. 0. 6. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 29.  8.  5. 10.  6.  5.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11. 11.  8.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8 25 11 29  8 11  8 11  8 11 10  8] -> size -> 16 
adversary victory points: 0
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [6. 1. 0. 0. 0. 3. 0. 0. 4. 0. 0. 6. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 29. 30. 30. 29.  8.  5. 10.  6.  5.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11. 11.  8.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8 25 11 29  8 11  8 11  8 11 10  8] -> size -> 16 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [6. 1. 0. 0. 0. 3. 0. 0. 4. 0. 0. 6. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 29. 30. 30. 29.  8.  5. 10.  6.  5.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11. 11.  8.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8 25 11 29  8 11  8 11  8 11 10  8] -> size -> 16 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [6. 1. 0. 0. 0. 3. 0. 0. 4. 0. 0. 6. 6. 4.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 28.  8.  5. 10.  6.  5.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11. 11.  8.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8 25 11 29  8 11  8 11  8 11 10  8] -> size -> 16 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [11. 11.  8.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8.  8.] 
expected returns: [[73.44976]
 [75.91914]
 [75.91914]
 [74.60112]
 [74.60112]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  8.  8.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8 25 11 29  8 11  8 11  8 11 10  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 28.  8.  5. 10.  6.  5.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [15.  6.  6.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4] -> size -> 22 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 85.5836410522461



action possibilites: [-1] 
expected returns: [[93.08358]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  8.  0.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  8 25 11 29  8 11  8 11  8 11 10  8 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 28.  8.  5. 10.  6.  5.  9.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [15.  6.  6.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4] -> size -> 22 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
   27    0] 
sum of rewards: -78 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 75.95494079589844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[92.04719]
 [87.57629]
 [94.34374]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  8.  0.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  8 25 11 29  8 11  8 11  8 11 10  8 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 30. 28.  8.  5. 10.  6.  5.  9.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [15.  6.  6.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4] -> size -> 22 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 93.08358001708984






Player: 1 
cards in hand: [15.  6.  6.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6.  6.  0.  3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 28.  8.  5. 10.  6.  5.  9.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0.  0. 11.  8.] 
adversary cards in discard: [10. 11. 11.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  8 25 11 29  8 11  8 11  8 11 10  8 10] -> size -> 17 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 29. 30. 30. 28.  8.  5. 10.  6.  5.  9.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0.  0. 11.  8.] 
adversary cards in discard: [10. 11. 11.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  8 25 11 29  8 11  8 11  8 11 10  8 10] -> size -> 17 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 30. 28.  8.  5. 10.  6.  5.  9.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0.  0. 11.  8.] 
adversary cards in discard: [10. 11. 11.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  8 25 11 29  8 11  8 11  8 11 10  8 10] -> size -> 17 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3.] 
cards in discard: [11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 28.  8.  5. 10.  5.  5.  9.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0.  0. 11.  8.] 
adversary cards in discard: [10. 11. 11.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  8 25 11 29  8 11  8 11  8 11 10  8 10] -> size -> 17 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [11.  0.  0. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8.] 
expected returns: [[81.803795]
 [84.633705]
 [84.633705]
 [82.95957 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 11.  8.] 
cards in discard: [10. 11. 11.  8.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8 25 11 29  8 11  8 11  8 11 10  8 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 28.  8.  5. 10.  5.  5.  9.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [11. 15.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11] -> size -> 22 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 94.34374237060547



action possibilites: [-1] 
expected returns: [[96.64807]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  8.] 
cards in discard: [10. 11. 11.  8.  8.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  8 25 11 29  8 11  8 11  8 11 10  8 10 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 28.  8.  5. 10.  5.  5.  9.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [11. 15.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11] -> size -> 22 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
   27    0] 
sum of rewards: -78 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 84.40593719482422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 96.6775  ]
 [ 98.49974 ]
 [ 91.202286]
 [100.92086 ]
 [ 99.63918 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  8.] 
cards in discard: [10. 11. 11.  8.  8.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  8 25 11 29  8 11  8 11  8 11 10  8 10 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 30. 28.  8.  5. 10.  5.  5.  9.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [11. 15.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11] -> size -> 22 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 96.6480712890625



buy possibilites: [-1] 
expected returns: [[99.634834]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  8.] 
cards in discard: [10. 11. 11.  8.  8.  0. 10.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  8 25 11 29  8 11  8 11  8 11 10  8 10 10  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 28.  8.  5. 10.  5.  4.  9.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [11. 15.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11] -> size -> 22 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -89 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 100.92086029052734






Player: 1 
cards in hand: [0. 0. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [11. 15.  6.  6.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 28.  8.  5. 10.  5.  4.  9.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [10. 25.  8.  8. 29.] 
adversary cards in discard: [10. 11. 11.  8.  8.  0. 10.  8. 11.  0.  0. 11.  8.] 
adversary owned cards: [ 0  0  0  0  8 25 11 29  8 11  8 11  8 11 10  8 10 10  8] -> size -> 19 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [11. 15.  6.  6.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 30. 28.  8.  5. 10.  5.  4.  9.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [10. 25.  8.  8. 29.] 
adversary cards in discard: [10. 11. 11.  8.  8.  0. 10.  8. 11.  0.  0. 11.  8.] 
adversary owned cards: [ 0  0  0  0  8 25 11 29  8 11  8 11  8 11 10  8 10 10  8] -> size -> 19 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [11. 15.  6.  6.  3.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 30. 28.  8.  5. 10.  5.  4.  9.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [10. 25.  8.  8. 29.] 
adversary cards in discard: [10. 11. 11.  8.  8.  0. 10.  8. 11.  0.  0. 11.  8.] 
adversary owned cards: [ 0  0  0  0  8 25 11 29  8 11  8 11  8 11 10  8 10 10  8] -> size -> 19 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [10. 25.  8.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.  8.  8. 29.] 
expected returns: [[72.961754]
 [72.017334]
 [79.49345 ]
 [73.50041 ]
 [73.50041 ]
 [76.40736 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25.  8.  8. 29.] 
cards in discard: [10. 11. 11.  8.  8.  0. 10.  8. 11.  0.  0. 11.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8 25 11 29  8 11  8 11  8 11 10  8 10 10  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 28.  8.  5. 10.  5.  4.  9.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 4. 4. 0.] 
adversary cards in discard: [11. 15.  6.  6.  3.  1.  0.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1] -> size -> 23 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 99.63483428955078



action possibilites: [-1] 
expected returns: [[88.66039]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  8. 29.  8.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  8 25 11 29  8 11  8 11  8 11 10  8 10 10  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 28.  8.  4. 10.  5.  4.  9.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 4. 4. 0.] 
adversary cards in discard: [11. 15.  6.  6.  3.  1.  0.  0.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6] -> size -> 24 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 78.39189147949219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[87.63132 ]
 [82.11219 ]
 [91.046875]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  8. 29.  8.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  8 25 11 29  8 11  8 11  8 11 10  8 10 10  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 30. 28.  8.  4. 10.  5.  4.  9.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 4. 4. 0.] 
adversary cards in discard: [11. 15.  6.  6.  3.  1.  0.  0.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6] -> size -> 24 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 88.66039276123047






Player: 1 
cards in hand: [3. 0. 4. 4. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 4. 4. 0.] 
cards in discard: [11. 15.  6.  6.  3.  1.  0.  0.  6.  0.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 28.  8.  4. 10.  5.  4.  9.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [10.  0.  8.  0.  8.] 
adversary cards in discard: [25. 10.  8.  8. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  8 25 11 29  8 11  8 11  8 11 10  8 10 10  8] -> size -> 19 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 4. 4. 0.] 
cards in discard: [11. 15.  6.  6.  3.  1.  0.  0.  6.  0.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 30. 28.  8.  4. 10.  5.  4.  9.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [10.  0.  8.  0.  8.] 
adversary cards in discard: [25. 10.  8.  8. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  8 25 11 29  8 11  8 11  8 11 10  8 10 10  8] -> size -> 19 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 4. 4. 0.] 
cards in discard: [11. 15.  6.  6.  3.  1.  0.  0.  6.  0.  0.  6.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 28.  8.  4. 10.  5.  4.  9.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [10.  0.  8.  0.  8.] 
adversary cards in discard: [25. 10.  8.  8. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  8 25 11 29  8 11  8 11  8 11 10  8 10 10  8] -> size -> 19 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [10.  0.  8.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8.] 
expected returns: [[85.01868]
 [83.945  ]
 [85.58586]
 [85.58586]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8.  0.  8.] 
cards in discard: [25. 10.  8.  8. 29.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8 25 11 29  8 11  8 11  8 11 10  8 10 10  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 28.  8.  4. 10.  5.  4.  9.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 1. 0. 3. 6.] 
adversary cards in discard: [11. 15.  6.  6.  3.  1.  0.  0.  6.  0.  0.  6.  3.  3.  0.  4.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6
  3] -> size -> 25 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 91.04686737060547



action possibilites: [-1] 
expected returns: [[92.35532]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [25. 10.  8.  8. 29.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10 10  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 28.  8.  4. 10.  5.  4.  9.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 1. 0. 3. 6.] 
adversary cards in discard: [11. 15.  6.  6.  3.  1.  0.  0.  6.  0.  0.  6.  3.  3.  0.  4.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6
  3] -> size -> 25 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 87.17599487304688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[91.47145]
 [87.40385]
 [93.75397]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [25. 10.  8.  8. 29.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10 10  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 29. 28.  8.  4. 10.  5.  4.  9.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 1. 0. 3. 6.] 
adversary cards in discard: [11. 15.  6.  6.  3.  1.  0.  0.  6.  0.  0.  6.  3.  3.  0.  4.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6
  3] -> size -> 25 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 92.3553237915039






Player: 1 
cards in hand: [0. 1. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 3. 6.] 
cards in discard: [11. 15.  6.  6.  3.  1.  0.  0.  6.  0.  0.  6.  3.  3.  0.  4.  4.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 28.  8.  4. 10.  5.  4.  9.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 10.  8. 11. 11.] 
adversary cards in discard: [25. 10.  8.  8. 29.  8.  0.  8.  0.] 
adversary owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10 10  8] -> size -> 16 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 6.] 
cards in discard: [11. 15.  6.  6.  3.  1.  0.  0.  6.  0.  0.  6.  3.  3.  0.  4.  4.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 28. 30. 29. 28.  8.  4. 10.  5.  4.  9.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 10.  8. 11. 11.] 
adversary cards in discard: [25. 10.  8.  8. 29.  8.  0.  8.  0.] 
adversary owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10 10  8] -> size -> 16 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 6.] 
cards in discard: [11. 15.  6.  6.  3.  1.  0.  0.  6.  0.  0.  6.  3.  3.  0.  4.  4.  0.
 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6
  3 16] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 28.  8.  4.  9.  5.  4.  9.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 10.  8. 11. 11.] 
adversary cards in discard: [25. 10.  8.  8. 29.  8.  0.  8.  0.] 
adversary owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10 10  8] -> size -> 16 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  8. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11. 11.] 
expected returns: [[82.93729]
 [82.4245 ]
 [83.73877]
 [85.08083]
 [85.08083]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8. 11. 11.] 
cards in discard: [25. 10.  8.  8. 29.  8.  0.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10 10  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 28.  8.  4.  9.  5.  4.  9.  9. 10. 10.  7. 10.  9.] 
adversary cards in hand: [15.  0.  3.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6
  3 16] -> size -> 26 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 93.75395965576172



action possibilites: [-1] 
expected returns: [[81.2281]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8. 11.] 
cards in discard: [25. 10.  8.  8. 29.  8.  0.  8.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10 10  8 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 28.  8.  4.  9.  5.  4.  9.  9. 10. 10.  6. 10.  9.] 
adversary cards in hand: [15.  0.  3.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6
  3 16] -> size -> 26 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
   27    0] 
sum of rewards: -78 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 85.54434967041016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[78.598335]
 [73.82238 ]
 [81.902306]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  8. 11.] 
cards in discard: [25. 10.  8.  8. 29.  8.  0.  8.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10 10  8 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 29. 28.  8.  4.  9.  5.  4.  9.  9. 10. 10.  6. 10.  9.] 
adversary cards in hand: [15.  0.  3.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6
  3 16] -> size -> 26 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 81.22810363769531






Player: 1 
cards in hand: [15.  0.  3.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  3.  6.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6
  3 16] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 28.  8.  4.  9.  5.  4.  9.  9. 10. 10.  6. 10.  9.] 
adversary cards in hand: [10.  8.  0. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10 10  8 10] -> size -> 17 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  3.  6.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6
  3 16] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 29. 28.  8.  4.  9.  5.  4.  9.  9. 10. 10.  6. 10.  9.] 
adversary cards in hand: [10.  8.  0. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10 10  8 10] -> size -> 17 
adversary victory points: 0
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [10.  8.  0. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11. 11.] 
expected returns: [[82.99579]
 [82.2279 ]
 [83.82126]
 [85.47895]
 [85.47895]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0. 11. 11.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10 10  8 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 28.  8.  4.  9.  5.  4.  9.  9. 10. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 4.] 
adversary cards in discard: [15.  0.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6
  3 16] -> size -> 26 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 81.90229034423828



action possibilites: [-1] 
expected returns: [[71.882324]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0. 11.] 
cards in discard: [10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10 10  8 10 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 28.  8.  4.  9.  5.  4.  9.  9. 10. 10.  5. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 4.] 
adversary cards in discard: [15.  0.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6
  3 16] -> size -> 26 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
   27    0] 
sum of rewards: -78 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 85.2716293334961





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[70.22729 ]
 [65.512085]
 [73.35648 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0. 11.] 
cards in discard: [10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10 10  8 10 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 29. 28.  8.  4.  9.  5.  4.  9.  9. 10. 10.  5. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 4.] 
adversary cards in discard: [15.  0.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6
  3 16] -> size -> 26 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 71.88232421875






Player: 1 
cards in hand: [3. 0. 0. 0. 4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 4.] 
cards in discard: [15.  0.  3.  6.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6
  3 16] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 28.  8.  4.  9.  5.  4.  9.  9. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 8. 25.  8. 29. 11.] 
adversary cards in discard: [10. 11. 10.  8.  0. 11.] 
adversary owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10 10  8 10 10] -> size -> 18 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 4.] 
cards in discard: [15.  0.  3.  6.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6
  3 16] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 29. 28.  8.  4.  9.  5.  4.  9.  9. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 8. 25.  8. 29. 11.] 
adversary cards in discard: [10. 11. 10.  8.  0. 11.] 
adversary owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10 10  8 10 10] -> size -> 18 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 4.] 
cards in discard: [15.  0.  3.  6.  0.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6
  3 16  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 28.  8.  4.  9.  5.  4.  9.  9. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 8. 25.  8. 29. 11.] 
adversary cards in discard: [10. 11. 10.  8.  0. 11.] 
adversary owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10 10  8 10 10] -> size -> 18 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 8. 25.  8. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.  8. 29. 11.] 
expected returns: [[80.302055]
 [81.339226]
 [88.551575]
 [81.339226]
 [84.77329 ]
 [83.225685]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25.  8. 29. 11.] 
cards in discard: [10. 11. 10.  8.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10 10  8 10 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 28.  8.  4.  9.  5.  4.  9.  9. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 1.  1. 16.  0.  0.] 
adversary cards in discard: [15.  0.  3.  6.  0.  1.  3.  0.  0.  0.  4.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6
  3 16  1] -> size -> 27 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 73.35649108886719



action possibilites: [-1] 
expected returns: [[65.730644]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 29. 11. 10.  8.] 
cards in discard: [10. 11. 10.  8.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10 10  8 10 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 28.  8.  3.  9.  5.  4.  9.  9. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 1.  1. 16.  0.  0.] 
adversary cards in discard: [15.  0.  3.  6.  0.  1.  3.  0.  0.  0.  4.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6
  3 16  1  6] -> size -> 28 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 86.47152709960938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[57.737606]
 [52.149006]
 [61.346317]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8. 29. 11. 10.  8.] 
cards in discard: [10. 11. 10.  8.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10 10  8 10 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 27. 30. 29. 28.  8.  3.  9.  5.  4.  9.  9. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 1.  1. 16.  0.  0.] 
adversary cards in discard: [15.  0.  3.  6.  0.  1.  3.  0.  0.  0.  4.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6
  3 16  1  6] -> size -> 28 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 65.73064422607422






Player: 1 
cards in hand: [ 1.  1. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1. 16.  0.  0.] 
cards in discard: [15.  0.  3.  6.  0.  1.  3.  0.  0.  0.  4.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6
  3 16  1  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 28.  8.  3.  9.  5.  4.  9.  9. 10. 10.  5. 10.  9.] 
adversary cards in hand: [10.  8.  0.  0. 11.] 
adversary cards in discard: [10. 11. 10.  8.  0. 11. 25.  8.  8. 29. 11. 10.  8.] 
adversary owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10 10  8 10 10] -> size -> 18 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 0.] 
cards in discard: [15.  0.  3.  6.  0.  1.  3.  0.  0.  0.  4.  6.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 28.  8.  3.  9.  5.  4.  9.  9. 10. 10.  5. 10.  9.] 
adversary cards in hand: [10.  8.  0.  0. 11.] 
adversary cards in discard: [10. 11. 10.  8.  0. 11. 25.  8.  8. 29. 11. 10.  8.] 
adversary owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10 10  8 10 10] -> size -> 18 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0.] 
cards in discard: [15.  0.  3.  6.  0.  1.  3.  0.  0.  0.  4.  6.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 27. 30. 28. 28.  8.  3.  9.  5.  4.  9.  9. 10. 10.  5. 10.  9.] 
adversary cards in hand: [10.  8.  0.  0. 11.] 
adversary cards in discard: [10. 11. 10.  8.  0. 11. 25.  8.  8. 29. 11. 10.  8.] 
adversary owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10 10  8 10 10] -> size -> 18 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0.] 
cards in discard: [15.  0.  3.  6.  0.  1.  3.  0.  0.  0.  4.  6.  3. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 27. 30. 28. 28.  8.  3.  9.  4.  4.  9.  9. 10. 10.  5. 10.  9.] 
adversary cards in hand: [10.  8.  0.  0. 11.] 
adversary cards in discard: [10. 11. 10.  8.  0. 11. 25.  8.  8. 29. 11. 10.  8.] 
adversary owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10 10  8 10 10] -> size -> 18 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [10.  8.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11.] 
expected returns: [[56.955257]
 [56.222607]
 [57.526962]
 [58.966698]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0.  0. 11.] 
cards in discard: [10. 11. 10.  8.  0. 11. 25.  8.  8. 29. 11. 10.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10 10  8 10 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 28.  8.  3.  9.  4.  4.  9.  9. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 3. 11.  6.  6.  4.] 
adversary cards in discard: [15.  0.  3.  6.  0.  1.  3.  0.  0.  0.  4.  6.  3. 11. 16.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11] -> size -> 29 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 61.3463134765625



action possibilites: [-1] 
expected returns: [[78.92011]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0.  0.] 
cards in discard: [10. 11. 10.  8.  0. 11. 25.  8.  8. 29. 11. 10.  8. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10 10  8 10 10 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 28.  8.  3.  9.  4.  4.  9.  9. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3. 11.  6.  6.  4.] 
adversary cards in discard: [15.  0.  3.  6.  0.  1.  3.  0.  0.  0.  4.  6.  3. 11. 16.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11] -> size -> 29 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
   27    0] 
sum of rewards: -78 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 61.76427459716797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[76.40222 ]
 [77.827774]
 [72.290596]
 [79.64078 ]
 [79.126724]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0.  0.] 
cards in discard: [10. 11. 10.  8.  0. 11. 25.  8.  8. 29. 11. 10.  8. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10 10  8 10 10 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 28. 28.  8.  3.  9.  4.  4.  9.  9. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3. 11.  6.  6.  4.] 
adversary cards in discard: [15.  0.  3.  6.  0.  1.  3.  0.  0.  0.  4.  6.  3. 11. 16.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11] -> size -> 29 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 78.92011260986328



buy possibilites: [-1] 
expected returns: [[94.63761]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0.  0.] 
cards in discard: [10. 11. 10.  8.  0. 11. 25.  8.  8. 29. 11. 10.  8. 10.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10 10  8 10 10 10  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 28.  8.  3.  9.  4.  3.  9.  9. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3. 11.  6.  6.  4.] 
adversary cards in discard: [15.  0.  3.  6.  0.  1.  3.  0.  0.  0.  4.  6.  3. 11. 16.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11] -> size -> 29 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -89 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 79.6407699584961






Player: 1 
cards in hand: [ 3. 11.  6.  6.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  6.  6.  4.] 
cards in discard: [15.  0.  3.  6.  0.  1.  3.  0.  0.  0.  4.  6.  3. 11. 16.  1.  1.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 28.  8.  3.  9.  4.  3.  9.  9. 10. 10.  4. 10.  9.] 
adversary cards in hand: [11.  8.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10 10  8 10 10 10  8] -> size -> 20 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 4.] 
cards in discard: [15.  0.  3.  6.  0.  1.  3.  0.  0.  0.  4.  6.  3. 11. 16.  1.  1.  0.
 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 28.  8.  3.  9.  4.  3.  9.  9.  9. 10.  4. 10.  9.] 
adversary cards in hand: [11.  8.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10 10  8 10 10 10  8] -> size -> 20 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 4.] 
cards in discard: [15.  0.  3.  6.  0.  1.  3.  0.  0.  0.  4.  6.  3. 11. 16.  1.  1.  0.
 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 27. 30. 28. 28.  8.  3.  9.  4.  3.  9.  9.  9. 10.  4. 10.  9.] 
adversary cards in hand: [11.  8.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10 10  8 10 10 10  8] -> size -> 20 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [11.  8.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8.] 
expected returns: [[73.78844]
 [75.88802]
 [73.89807]
 [73.89807]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0.  8.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10 10  8 10 10 10  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 28.  8.  3.  9.  4.  3.  9.  9.  9. 10.  4. 10.  9.] 
adversary cards in hand: [6. 6. 0. 3. 0.] 
adversary cards in discard: [15.  0.  3.  6.  0.  1.  3.  0.  0.  0.  4.  6.  3. 11. 16.  1.  1.  0.
 14. 11.  3.  6.  6.  4.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14] -> size -> 30 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 94.63761138916016



action possibilites: [-1] 
expected returns: [[47.83294]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 0.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10 10  8 10 10 10  8 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 28.  8.  3.  9.  4.  3.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [6. 6. 0. 3. 0.] 
adversary cards in discard: [15.  0.  3.  6.  0.  1.  3.  0.  0.  0.  4.  6.  3. 11. 16.  1.  1.  0.
 14. 11.  3.  6.  6.  4.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14] -> size -> 30 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
   27    0] 
sum of rewards: -78 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 75.80879974365234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[47.75887 ]
 [49.01564 ]
 [43.934128]
 [50.71219 ]
 [49.84957 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8. 0.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10 10  8 10 10 10  8 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 28. 28.  8.  3.  9.  4.  3.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [6. 6. 0. 3. 0.] 
adversary cards in discard: [15.  0.  3.  6.  0.  1.  3.  0.  0.  0.  4.  6.  3. 11. 16.  1.  1.  0.
 14. 11.  3.  6.  6.  4.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14] -> size -> 30 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 47.83293914794922



buy possibilites: [-1] 
expected returns: [[71.9423]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8. 0.] 
cards in discard: [10.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10 10  8 10 10 10  8 10  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 28.  8.  3.  9.  4.  2.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [6. 6. 0. 3. 0.] 
adversary cards in discard: [15.  0.  3.  6.  0.  1.  3.  0.  0.  0.  4.  6.  3. 11. 16.  1.  1.  0.
 14. 11.  3.  6.  6.  4.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14] -> size -> 30 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -89 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 50.712196350097656






Player: 1 
cards in hand: [6. 6. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 3. 0.] 
cards in discard: [15.  0.  3.  6.  0.  1.  3.  0.  0.  0.  4.  6.  3. 11. 16.  1.  1.  0.
 14. 11.  3.  6.  6.  4.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 28.  8.  3.  9.  4.  2.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [10.  8. 10. 29.  8.] 
adversary cards in discard: [10.  8. 11.  8.  0.  8.  0.] 
adversary owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10 10  8 10 10 10  8 10  8] -> size -> 22 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 3. 0.] 
cards in discard: [15.  0.  3.  6.  0.  1.  3.  0.  0.  0.  4.  6.  3. 11. 16.  1.  1.  0.
 14. 11.  3.  6.  6.  4.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 28. 28.  8.  3.  9.  4.  2.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [10.  8. 10. 29.  8.] 
adversary cards in discard: [10.  8. 11.  8.  0.  8.  0.] 
adversary owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10 10  8 10 10 10  8 10  8] -> size -> 22 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 3. 0.] 
cards in discard: [15.  0.  3.  6.  0.  1.  3.  0.  0.  0.  4.  6.  3. 11. 16.  1.  1.  0.
 14. 11.  3.  6.  6.  4.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 27. 30. 28. 28.  8.  3.  9.  4.  2.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [10.  8. 10. 29.  8.] 
adversary cards in discard: [10.  8. 11.  8.  0.  8.  0.] 
adversary owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10 10  8 10 10 10  8 10  8] -> size -> 22 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [10.  8. 10. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 10. 29.  8.] 
expected returns: [[65.153915]
 [63.50564 ]
 [64.98729 ]
 [63.50564 ]
 [68.19603 ]
 [64.98729 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 10. 29.  8.] 
cards in discard: [10.  8. 11.  8.  0.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10 10  8 10 10 10  8 10  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 28. 28.  8.  3.  9.  4.  2.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 14.  0.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0] -> size -> 31 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 71.94229888916016



action possibilites: [-1. 10.  8. 10.  8. 11.] 
expected returns: [[54.39119 ]
 [53.057167]
 [54.634026]
 [53.057167]
 [54.634026]
 [56.3683  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 10.  8. 11.] 
cards in discard: [10.  8. 11.  8.  0.  8.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10 10  8 10 10 10  8 10  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 28. 28.  8.  3.  9.  4.  2.  9.  9.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 14.  0.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0] -> size -> 31 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 68.19603729248047



action possibilites: [-1] 
expected returns: [[65.075386]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 10.  8.] 
cards in discard: [10.  8. 11.  8.  0.  8.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10 10  8 10 10 10  8 10  8 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 28. 28.  8.  3.  9.  4.  2.  9.  9.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 0. 14.  0.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0] -> size -> 31 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
   27    0] 
sum of rewards: -58 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 57.945167541503906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[62.329224]
 [58.380466]
 [65.282234]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 10.  8.] 
cards in discard: [10.  8. 11.  8.  0.  8.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10 10  8 10 10 10  8 10  8 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 28. 28.  8.  3.  9.  4.  2.  9.  9.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 0. 14.  0.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0] -> size -> 31 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action -1
Learning step: 0
desired expected reward: 65.07538604736328






Player: 1 
cards in hand: [ 0. 14.  0.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  6.  6.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 28. 28.  8.  3.  9.  4.  2.  9.  9.  9. 10.  2. 10.  9.] 
adversary cards in hand: [10.  8.  0.  8. 10.] 
adversary cards in discard: [10.  8. 11.  8.  0.  8.  0. 10. 29. 11. 10.  8. 10.  8.] 
adversary owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10 10  8 10 10 10  8 10  8 10] -> size -> 23 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 6.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 27. 30. 28. 28.  8.  3.  9.  4.  2.  9.  9.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 8.  8. 10.] 
adversary cards in discard: [10.  8. 11.  8.  0.  8.  0. 10. 29. 11. 10.  8. 10.  8.  0. 10.] 
adversary owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10 10  8 10 10 10  8 10  8 10] -> size -> 23 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 27. 30. 28. 28.  8.  3.  9.  4.  2.  9.  9.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 8.  8. 10.] 
adversary cards in discard: [10.  8. 11.  8.  0.  8.  0. 10. 29. 11. 10.  8. 10.  8.  0. 10.] 
adversary owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10 10  8 10 10 10  8 10  8 10] -> size -> 23 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6.] 
cards in discard: [29.] 
cards in deck: 26 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 28. 28.  8.  3.  9.  4.  2.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 8.  8. 10.] 
adversary cards in discard: [10.  8. 11.  8.  0.  8.  0. 10. 29. 11. 10.  8. 10.  8.  0. 10.] 
adversary owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10 10  8 10 10 10  8 10  8 10] -> size -> 23 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 8.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.] 
expected returns: [[91.89133]
 [92.15763]
 [92.15763]
 [90.30355]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 10.] 
cards in discard: [10.  8. 11.  8.  0.  8.  0. 10. 29. 11. 10.  8. 10.  8.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10 10  8 10 10 10  8 10  8 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 28. 28.  8.  3.  9.  4.  2.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  1.  4. 11.  6.] 
adversary cards in discard: [29. 14.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29] -> size -> 32 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 149.97152709960938



action possibilites: [-1] 
expected returns: [[87.14279]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [10.  8. 11.  8.  0.  8.  0. 10. 29. 11. 10.  8. 10.  8.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10  8 10 10 10  8 10  8 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 28. 28.  8.  3.  9.  4.  2.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  1.  4. 11.  6.] 
adversary cards in discard: [29. 14.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29] -> size -> 32 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 92.7661361694336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[84.7426 ]
 [81.63111]
 [87.59963]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [10.  8. 11.  8.  0.  8.  0. 10. 29. 11. 10.  8. 10.  8.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10  8 10 10 10  8 10  8 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 27. 30. 28. 28.  8.  3.  9.  4.  2.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  1.  4. 11.  6.] 
adversary cards in discard: [29. 14.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29] -> size -> 32 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 87.14279174804688






Player: 1 
cards in hand: [ 0.  1.  4. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  4. 11.  6.] 
cards in discard: [29. 14.  0.  0.  6.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 28. 28.  8.  3.  9.  4.  2.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [11. 10. 11. 11. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10  8 10 10 10  8 10  8 10] -> size -> 22 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 4. 6.] 
cards in discard: [29. 14.  0.  0.  6.  6.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 28.  8.  3.  9.  4.  2.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [11. 10. 11. 11. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10  8 10 10 10  8 10  8 10] -> size -> 22 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 4. 6.] 
cards in discard: [29. 14.  0.  0.  6.  6.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 27. 30. 27. 28.  8.  3.  9.  4.  2.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [11. 10. 11. 11. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10  8 10 10 10  8 10  8 10] -> size -> 22 
adversary victory points: 0
player victory points: 5 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [11. 10. 11. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11. 11. 25.] 
expected returns: [[76.088196]
 [77.08264 ]
 [74.66326 ]
 [77.08264 ]
 [77.08264 ]
 [80.52539 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11. 11. 25.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10  8 10 10 10  8 10  8 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 28.  8.  3.  9.  4.  2.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [11.  6. 15.  3.  6.] 
adversary cards in discard: [29. 14.  0.  0.  6.  6.  3. 11.  0.  1.  4.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29  3] -> size -> 33 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 87.5996322631836



action possibilites: [-1] 
expected returns: [[50.70585]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11. 11. 10.  8.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10  8 10 10 10  8 10  8 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 28.  8.  2.  9.  4.  2.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [11.  6. 15.  3.  6.] 
adversary cards in discard: [29. 14.  0.  0.  6.  6.  3. 11.  0.  1.  4.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29  3  6] -> size -> 34 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 80.17413330078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[45.137882]
 [42.02894 ]
 [48.137943]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 11. 11. 10.  8.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10  8 10 10 10  8 10  8 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 27. 30. 27. 28.  8.  2.  9.  4.  2.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [11.  6. 15.  3.  6.] 
adversary cards in discard: [29. 14.  0.  0.  6.  6.  3. 11.  0.  1.  4.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29  3  6] -> size -> 34 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 50.705848693847656






Player: 1 
cards in hand: [11.  6. 15.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6. 15.  3.  6.] 
cards in discard: [29. 14.  0.  0.  6.  6.  3. 11.  0.  1.  4.  6.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29  3  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 28.  8.  2.  9.  4.  2.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 0. 10. 11.  8. 10.] 
adversary cards in discard: [25. 11. 10. 11. 11. 10.  8.] 
adversary owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10  8 10 10 10  8 10  8 10] -> size -> 22 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6. 15.  3.  6.] 
cards in discard: [29. 14.  0.  0.  6.  6.  3. 11.  0.  1.  4.  6.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29  3  6] -> size -> 34 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 27. 30. 27. 28.  8.  2.  9.  4.  2.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 0. 10. 11.  8. 10.] 
adversary cards in discard: [25. 11. 10. 11. 11. 10.  8.] 
adversary owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10  8 10 10 10  8 10  8 10] -> size -> 22 
adversary victory points: 0
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 11.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.  8. 10.] 
expected returns: [[58.823433]
 [57.19672 ]
 [60.2629  ]
 [58.60554 ]
 [57.19672 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  8. 10.] 
cards in discard: [25. 11. 10. 11. 11. 10.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10  8 10 10 10  8 10  8 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 28.  8.  2.  9.  4.  2.  9.  8.  9. 10.  2. 10.  9.] 
adversary cards in hand: [16.  3.  0.  1.  0.] 
adversary cards in discard: [29. 14.  0.  0.  6.  6.  3. 11.  0.  1.  4.  6.  6. 11.  6. 15.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29  3  6] -> size -> 34 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 48.13794708251953



action possibilites: [-1] 
expected returns: [[60.09829]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8. 10.] 
cards in discard: [25. 11. 10. 11. 11. 10.  8. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10  8 10 10 10  8 10  8 10 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 28.  8.  2.  9.  4.  2.  9.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [16.  3.  0.  1.  0.] 
adversary cards in discard: [29. 14.  0.  0.  6.  6.  3. 11.  0.  1.  4.  6.  6. 11.  6. 15.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29  3  6] -> size -> 34 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
   27    0] 
sum of rewards: -78 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 61.671730041503906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[56.885933]
 [53.021217]
 [60.545753]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  8. 10.] 
cards in discard: [25. 11. 10. 11. 11. 10.  8. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10  8 10 10 10  8 10  8 10 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 27. 28.  8.  2.  9.  4.  2.  9.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [16.  3.  0.  1.  0.] 
adversary cards in discard: [29. 14.  0.  0.  6.  6.  3. 11.  0.  1.  4.  6.  6. 11.  6. 15.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29  3  6] -> size -> 34 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 60.098289489746094






Player: 1 
cards in hand: [16.  3.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  0.  1.  0.] 
cards in discard: [29. 14.  0.  0.  6.  6.  3. 11.  0.  1.  4.  6.  6. 11.  6. 15.  3.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29  3  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 28.  8.  2.  9.  4.  2.  9.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [10.  8.  8.  8. 10.] 
adversary cards in discard: [25. 11. 10. 11. 11. 10.  8. 10. 11.  0. 10.  8. 10.] 
adversary owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10  8 10 10 10  8 10  8 10 10] -> size -> 23 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  0.  1.  0.] 
cards in discard: [29. 14.  0.  0.  6.  6.  3. 11.  0.  1.  4.  6.  6. 11.  6. 15.  3.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29  3  6] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 27. 30. 27. 28.  8.  2.  9.  4.  2.  9.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [10.  8.  8.  8. 10.] 
adversary cards in discard: [25. 11. 10. 11. 11. 10.  8. 10. 11.  0. 10.  8. 10.] 
adversary owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10  8 10 10 10  8 10  8 10 10] -> size -> 23 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  0.  1.  0.] 
cards in discard: [29. 14.  0.  0.  6.  6.  3. 11.  0.  1.  4.  6.  6. 11.  6. 15.  3.  6.
 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29  3  6 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 27. 28.  8.  2.  9.  3.  2.  9.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [10.  8.  8.  8. 10.] 
adversary cards in discard: [25. 11. 10. 11. 11. 10.  8. 10. 11.  0. 10.  8. 10.] 
adversary owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10  8 10 10 10  8 10  8 10 10] -> size -> 23 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [10.  8.  8.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8.  8. 10.] 
expected returns: [[71.40626]
 [70.91694]
 [72.44865]
 [72.44865]
 [72.44865]
 [70.91694]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  8.  8. 10.] 
cards in discard: [25. 11. 10. 11. 11. 10.  8. 10. 11.  0. 10.  8. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 25 11 29  8 11  8 11  8 11  8 10  8 10 10 10  8 10  8 10 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 28.  8.  2.  9.  3.  2.  9.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [3. 0. 3. 4. 0.] 
adversary cards in discard: [29. 14.  0.  0.  6.  6.  3. 11.  0.  1.  4.  6.  6. 11.  6. 15.  3.  6.
 11. 16.  3.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29  3  6 11] -> size -> 35 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 60.54576110839844



action possibilites: [-1] 
expected returns: [[24.427847]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [25. 11. 10. 11. 11. 10.  8. 10. 11.  0. 10.  8. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 25 11 29 11 11  8 11  8  8 10 10  8 10  8 10 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 28.  8.  2.  9.  3.  2.  9.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [3. 0. 3. 4. 0.] 
adversary cards in discard: [29. 14.  0.  0.  6.  6.  3. 11.  0.  1.  4.  6.  6. 11.  6. 15.  3.  6.
 11. 16.  3.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29  3  6 11] -> size -> 35 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 75.1418685913086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[23.69451 ]
 [20.799753]
 [25.390085]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [25. 11. 10. 11. 11. 10.  8. 10. 11.  0. 10.  8. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 25 11 29 11 11  8 11  8  8 10 10  8 10  8 10 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 27. 30. 27. 28.  8.  2.  9.  3.  2.  9.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [3. 0. 3. 4. 0.] 
adversary cards in discard: [29. 14.  0.  0.  6.  6.  3. 11.  0.  1.  4.  6.  6. 11.  6. 15.  3.  6.
 11. 16.  3.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29  3  6 11] -> size -> 35 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 24.427846908569336






Player: 1 
cards in hand: [3. 0. 3. 4. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 4. 0.] 
cards in discard: [29. 14.  0.  0.  6.  6.  3. 11.  0.  1.  4.  6.  6. 11.  6. 15.  3.  6.
 11. 16.  3.  0.  1.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29  3  6 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 28.  8.  2.  9.  3.  2.  9.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 8.  8.  0.  0. 29.] 
adversary cards in discard: [25. 11. 10. 11. 11. 10.  8. 10. 11.  0. 10.  8. 10.  8.] 
adversary owned cards: [ 0  0  0 25 11 29 11 11  8 11  8  8 10 10  8 10  8 10 10] -> size -> 19 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 4. 0.] 
cards in discard: [29. 14.  0.  0.  6.  6.  3. 11.  0.  1.  4.  6.  6. 11.  6. 15.  3.  6.
 11. 16.  3.  0.  1.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29  3  6 11] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 27. 30. 27. 28.  8.  2.  9.  3.  2.  9.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 8.  8.  0.  0. 29.] 
adversary cards in discard: [25. 11. 10. 11. 11. 10.  8. 10. 11.  0. 10.  8. 10.  8.] 
adversary owned cards: [ 0  0  0 25 11 29 11 11  8 11  8  8 10 10  8 10  8 10 10] -> size -> 19 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 4. 0.] 
cards in discard: [29. 14.  0.  0.  6.  6.  3. 11.  0.  1.  4.  6.  6. 11.  6. 15.  3.  6.
 11. 16.  3.  0.  1.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29  3  6 11  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 27. 30. 27. 28.  8.  2.  9.  3.  2.  9.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 8.  8.  0.  0. 29.] 
adversary cards in discard: [25. 11. 10. 11. 11. 10.  8. 10. 11.  0. 10.  8. 10.  8.] 
adversary owned cards: [ 0  0  0 25 11 29 11 11  8 11  8  8 10 10  8 10  8 10 10] -> size -> 19 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 8.  8.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 29.] 
expected returns: [[41.088852]
 [41.7703  ]
 [41.7703  ]
 [44.604355]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  0.  0. 29.] 
cards in discard: [25. 11. 10. 11. 11. 10.  8. 10. 11.  0. 10.  8. 10.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 25 11 29 11 11  8 11  8  8 10 10  8 10  8 10 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 28.  8.  2.  9.  3.  2.  9.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [0. 1. 6. 6. 0.] 
adversary cards in discard: [29. 14.  0.  0.  6.  6.  3. 11.  0.  1.  4.  6.  6. 11.  6. 15.  3.  6.
 11. 16.  3.  0.  1.  0.  0.  3.  0.  3.  4.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29  3  6 11  0] -> size -> 36 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 25.390108108520508



action possibilites: [-1.  8.  8. 11.] 
expected returns: [[64.23153 ]
 [64.031746]
 [64.031746]
 [65.7146  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0 25 11 29 11 11  8 11  8  8 10 10  8 10  8 10 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 27. 28.  8.  2.  9.  3.  2.  9.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [0. 1. 6. 6. 0.] 
adversary cards in discard: [29. 14.  0.  0.  6.  6.  3. 11.  0.  1.  4.  6.  6. 11.  6. 15.  3.  6.
 11. 16.  3.  0.  1.  0.  0.  3.  0.  3.  4.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29  3  6 11  0] -> size -> 36 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 44.604347229003906



action possibilites: [-1] 
expected returns: [[55.286415]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0 25 11 29 11 11  8 11  8  8 10 10  8 10  8 10 10 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 27. 28.  8.  2.  9.  3.  2.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 1. 6. 6. 0.] 
adversary cards in discard: [29. 14.  0.  0.  6.  6.  3. 11.  0.  1.  4.  6.  6. 11.  6. 15.  3.  6.
 11. 16.  3.  0.  1.  0.  0.  3.  0.  3.  4.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29  3  6 11  0] -> size -> 36 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
   27    0] 
sum of rewards: -58 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 67.16583251953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[52.541817]
 [55.096973]
 [53.851376]
 [49.1215  ]
 [56.976643]
 [55.508278]
 [55.722363]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0. 0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0 25 11 29 11 11  8 11  8  8 10 10  8 10  8 10 10 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 27. 30. 27. 28.  8.  2.  9.  3.  2.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 1. 6. 6. 0.] 
adversary cards in discard: [29. 14.  0.  0.  6.  6.  3. 11.  0.  1.  4.  6.  6. 11.  6. 15.  3.  6.
 11. 16.  3.  0.  1.  0.  0.  3.  0.  3.  4.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29  3  6 11  0] -> size -> 36 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action -1
Learning step: 0
desired expected reward: 55.286415100097656



buy possibilites: [-1] 
expected returns: [[114.03187]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0. 0.] 
cards in discard: [10. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0 25 11 29 11 11  8 11  8  8 10 10  8 10  8 10 10 10 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 28.  8.  2.  9.  2.  2.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 1. 6. 6. 0.] 
adversary cards in discard: [29. 14.  0.  0.  6.  6.  3. 11.  0.  1.  4.  6.  6. 11.  6. 15.  3.  6.
 11. 16.  3.  0.  1.  0.  0.  3.  0.  3.  4.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29  3  6 11  0] -> size -> 36 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
   54    0] 
sum of rewards: -31 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 56.976661682128906






Player: 1 
cards in hand: [0. 1. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 6. 6. 0.] 
cards in discard: [29. 14.  0.  0.  6.  6.  3. 11.  0.  1.  4.  6.  6. 11.  6. 15.  3.  6.
 11. 16.  3.  0.  1.  0.  0.  3.  0.  3.  4.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29  3  6 11  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 28.  8.  2.  9.  2.  2.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 8. 10.  0. 10.  8.] 
adversary cards in discard: [10. 11. 29. 11.  8.  8.  0.  0.] 
adversary owned cards: [ 0  0  0 25 11 29 11 11  8 11  8  8 10 10  8 10  8 10 10 10 11] -> size -> 21 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 6. 0.] 
cards in discard: [29. 14.  0.  0.  6.  6.  3. 11.  0.  1.  4.  6.  6. 11.  6. 15.  3.  6.
 11. 16.  3.  0.  1.  0.  0.  3.  0.  3.  4.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29  3  6 11  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 27. 30. 27. 28.  8.  2.  9.  2.  2.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 8. 10.  0. 10.  8.] 
adversary cards in discard: [10. 11. 29. 11.  8.  8.  0.  0.] 
adversary owned cards: [ 0  0  0 25 11 29 11 11  8 11  8  8 10 10  8 10  8 10 10 10 11] -> size -> 21 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 6. 0.] 
cards in discard: [29. 14.  0.  0.  6.  6.  3. 11.  0.  1.  4.  6.  6. 11.  6. 15.  3.  6.
 11. 16.  3.  0.  1.  0.  0.  3.  0.  3.  4.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29  3  6 11  0  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 27. 28.  8.  2.  9.  2.  2.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 8. 10.  0. 10.  8.] 
adversary cards in discard: [10. 11. 29. 11.  8.  8.  0.  0.] 
adversary owned cards: [ 0  0  0 25 11 29 11 11  8 11  8  8 10 10  8 10  8 10 10 10 11] -> size -> 21 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 8. 10.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10.  8.] 
expected returns: [[24.350948]
 [25.023739]
 [23.391342]
 [23.391342]
 [25.023739]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0. 10.  8.] 
cards in discard: [10. 11. 29. 11.  8.  8.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 25 11 29 11 11  8 11  8  8 10 10  8 10  8 10 10 10 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 28.  8.  2.  9.  2.  2.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 1. 4. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29  3  6 11  0  1] -> size -> 37 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 114.03186798095703



action possibilites: [-1] 
expected returns: [[96.01747]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [10. 11. 29. 11.  8.  8.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 25 11 29 11 11 11  8  8 10  8 10  8 10 10 10 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 28.  8.  2.  9.  2.  2.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 1. 4. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29  3  6 11  0  1] -> size -> 37 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 28.445894241333008





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[95.38654 ]
 [92.754166]
 [96.86025 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [10. 11. 29. 11.  8.  8.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 25 11 29 11 11 11  8  8 10  8 10  8 10 10 10 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 26. 30. 27. 28.  8.  2.  9.  2.  2.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 1. 4. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29  3  6 11  0  1] -> size -> 37 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 96.01747131347656






Player: 1 
cards in hand: [0. 0. 1. 4. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 4. 3.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29  3  6 11  0  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 28.  8.  2.  9.  2.  2.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [11. 25.  8. 10. 11.] 
adversary cards in discard: [10. 11. 29. 11.  8.  8.  0.  0.  8. 10.] 
adversary owned cards: [ 0  0 25 11 29 11 11 11  8  8 10  8 10  8 10 10 10 11] -> size -> 18 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 4. 3.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29  3  6 11  0  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 26. 30. 27. 28.  8.  2.  9.  2.  2.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [11. 25.  8. 10. 11.] 
adversary cards in discard: [10. 11. 29. 11.  8.  8.  0.  0.  8. 10.] 
adversary owned cards: [ 0  0 25 11 29 11 11 11  8  8 10  8 10  8 10 10 10 11] -> size -> 18 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 4. 3.] 
cards in discard: [8.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29  3  6 11  0  1  8] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 26. 30. 27. 28.  8.  2.  9.  2.  1.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [11. 25.  8. 10. 11.] 
adversary cards in discard: [10. 11. 29. 11.  8.  8.  0.  0.  8. 10.] 
adversary owned cards: [ 0  0 25 11 29 11 11 11  8  8 10  8 10  8 10 10 10 11] -> size -> 18 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [11. 25.  8. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.  8. 10. 11.] 
expected returns: [[81.570045]
 [82.51958 ]
 [86.96676 ]
 [80.87513 ]
 [79.70165 ]
 [82.51958 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25.  8. 10. 11.] 
cards in discard: [10. 11. 29. 11.  8.  8.  0.  0.  8. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25 11 29 11 11 11  8  8 10  8 10  8 10 10 10 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 28.  8.  2.  9.  2.  1.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 6.  6. 11.  0.  0.] 
adversary cards in discard: [8. 0. 0. 1. 4. 3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29  3  6 11  0  1  8] -> size -> 38 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 96.8602523803711



action possibilites: [-1] 
expected returns: [[32.817375]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 10. 11. 10. 11.] 
cards in discard: [10. 11. 29. 11.  8.  8.  0.  0.  8. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 25 11 29 11 11 11  8  8 10  8 10  8 10 10 10 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 28.  8.  1.  9.  2.  1.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 6.  6. 11.  0.  0.] 
adversary cards in discard: [8. 0. 0. 1. 4. 3. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29  3  6 11  0  1  8  6] -> size -> 39 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 86.96675872802734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[30.094233]
 [27.313475]
 [32.75157 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8. 10. 11. 10. 11.] 
cards in discard: [10. 11. 29. 11.  8.  8.  0.  0.  8. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 25 11 29 11 11 11  8  8 10  8 10  8 10 10 10 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 26. 30. 27. 28.  8.  1.  9.  2.  1.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 6.  6. 11.  0.  0.] 
adversary cards in discard: [8. 0. 0. 1. 4. 3. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29  3  6 11  0  1  8  6] -> size -> 39 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 32.81737518310547






Player: 1 
cards in hand: [ 6.  6. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 11.  0.  0.] 
cards in discard: [8. 0. 0. 1. 4. 3. 6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29  3  6 11  0  1  8  6] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 28.  8.  1.  9.  2.  1.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [29.  0. 11.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 25 11 29 11 11 11  8  8 10  8 10  8 10 10 10 11] -> size -> 18 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 11.  0.  0.] 
cards in discard: [8. 0. 0. 1. 4. 3. 6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29  3  6 11  0  1  8  6] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 30. 27. 28.  8.  1.  9.  2.  1.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [29.  0. 11.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 25 11 29 11 11 11  8  8 10  8 10  8 10 10 10 11] -> size -> 18 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 11.  0.  0.] 
cards in discard: [8. 0. 0. 1. 4. 3. 6. 8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29  3  6 11  0  1  8  6  8] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 28.  8.  1.  9.  2.  0.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [29.  0. 11.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 25 11 29 11 11 11  8  8 10  8 10  8 10 10 10 11] -> size -> 18 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [29.  0. 11.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.  8. 10.] 
expected returns: [[ 96.84952]
 [100.15305]
 [ 98.7658 ]
 [ 97.09434]
 [ 95.7522 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 11.  8. 10.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25 11 29 11 11 11  8  8 10  8 10  8 10 10 10 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 28.  8.  1.  9.  2.  0.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 6.  0. 14. 29. 16.] 
adversary cards in discard: [ 8.  0.  0.  1.  4.  3.  6.  8.  6.  6. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29  3  6 11  0  1  8  6  8] -> size -> 40 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 32.75157165527344



action possibilites: [-1. 10. 11.] 
expected returns: [[33.708206]
 [32.459957]
 [35.123863]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.] 
cards in discard: [11.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 25 11 29 11 11 11  8  8 10  8 10  8 10 10 10 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 27. 28.  8.  1.  9.  2.  0.  9.  8.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 6.  0. 14. 29. 16.] 
adversary cards in discard: [ 8.  0.  0.  1.  4.  3.  6.  8.  6.  6. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29  3  6 11  0  1  8  6  8] -> size -> 40 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: discard_n_cards - action 8
Learning step: 0
desired expected reward: 96.7774429321289



action possibilites: [-1] 
expected returns: [[51.86177]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.] 
cards in discard: [11.  8. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0 25 11 29 11 11 11  8  8 10  8 10  8 10 10 10 11 15] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 27. 28.  8.  1.  9.  2.  0.  9.  8.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 6.  0. 14. 29. 16.] 
adversary cards in discard: [ 8.  0.  0.  1.  4.  3.  6.  8.  6.  6. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29  3  6 11  0  1  8  6  8] -> size -> 40 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 9 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 33.613189697265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[48.621723]
 [49.844566]
 [45.37189 ]
 [51.638477]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.] 
cards in discard: [11.  8. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0 25 11 29 11 11 11  8  8 10  8 10  8 10 10 10 11 15] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 30. 27. 28.  8.  1.  9.  2.  0.  9.  8.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 6.  0. 14. 29. 16.] 
adversary cards in discard: [ 8.  0.  0.  1.  4.  3.  6.  8.  6.  6. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29  3  6 11  0  1  8  6  8] -> size -> 40 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 51.86177062988281






Player: 1 
cards in hand: [ 6.  0. 14. 29. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 14. 29. 16.] 
cards in discard: [ 8.  0.  0.  1.  4.  3.  6.  8.  6.  6. 11.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3
 16  1  6  3 11 14  0 29  3  6 11  0  1  8  6  8] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 28.  8.  1.  9.  2.  0.  9.  8.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 8. 25. 10. 10.  0.] 
adversary cards in discard: [11.  8. 15. 29. 11.  0. 10.] 
adversary owned cards: [ 0  0 25 11 29 11 11 11  8  8 10  8 10  8 10 10 10 11 15] -> size -> 19 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14. 29.] 
cards in discard: [ 8.  0.  0.  1.  4.  3.  6.  8.  6.  6. 11.  0.  0.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3 16
  1  6  3 11 14  0 29  3  6 11  0  1  8  6  8  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 26. 28.  8.  1.  9.  2.  0.  9.  8.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 8. 25. 10. 10.  0.] 
adversary cards in discard: [11.  8. 15. 29. 11.  0. 10.] 
adversary owned cards: [ 0  0 25 11 29 11 11 11  8  8 10  8 10  8 10 10 10 11 15] -> size -> 19 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14. 29.] 
cards in discard: [ 8.  0.  0.  1.  4.  3.  6.  8.  6.  6. 11.  0.  0.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3 16
  1  6  3 11 14  0 29  3  6 11  0  1  8  6  8  3] -> size -> 40 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 26. 30. 26. 28.  8.  1.  9.  2.  0.  9.  8.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 8. 25. 10. 10.  0.] 
adversary cards in discard: [11.  8. 15. 29. 11.  0. 10.] 
adversary owned cards: [ 0  0 25 11 29 11 11 11  8  8 10  8 10  8 10 10 10 11 15] -> size -> 19 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14. 29.] 
cards in discard: [ 8.  0.  0.  1.  4.  3.  6.  8.  6.  6. 11.  0.  0.  3.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3 16
  1  6  3 11 14  0 29  3  6 11  0  1  8  6  8  3  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 28.  8.  1.  9.  2.  0.  9.  8.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 8. 25. 10. 10.  0.] 
adversary cards in discard: [11.  8. 15. 29. 11.  0. 10.] 
adversary owned cards: [ 0  0 25 11 29 11 11 11  8  8 10  8 10  8 10 10 10 11 15] -> size -> 19 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 8. 25. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 10. 10.] 
expected returns: [[31.574587]
 [31.887098]
 [35.42613 ]
 [31.061827]
 [31.061827]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25. 10. 10.  0.] 
cards in discard: [11.  8. 15. 29. 11.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25 11 29 11 11 11  8  8 10  8 10  8 10 10 10 11 15] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 28.  8.  1.  9.  2.  0.  9.  8.  9. 10.  0. 10.  8.] 
adversary cards in hand: [11.  6.  3.  6.  1.] 
adversary cards in discard: [ 8.  0.  0.  1.  4.  3.  6.  8.  6.  6. 11.  0.  0.  3.  0. 16.  6. 14.
 29.] 
adversary owned cards: [ 0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3 16
  1  6  3 11 14  0 29  3  6 11  0  1  8  6  8  3  0] -> size -> 41 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 51.638465881347656



Player 1 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 5 
Chapel: 8 
Witch: 1 
Poacher: 1 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 8. 10. 10.  0.  8. 11.] 
cards in discard: [11.  8. 15. 29. 11.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 25 11 29 11 11 11  8  8 10  8 10  8 10 10 10 11 15] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 28.  8.  0.  9.  2.  0.  9.  8.  9. 10.  0. 10.  8.] 
adversary cards in hand: [11.  6.  3.  6.  1.] 
adversary cards in discard: [ 8.  0.  0.  1.  4.  3.  6.  8.  6.  6. 11.  0.  0.  3.  0. 16.  6. 14.
 29.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  0  0  6  4  6 15  0  6  0  6  1  6  4 11  1  6  3 16
  1  6  3 11 14  0 29  3  6 11  0  1  8  6  8  3  0  6] -> size -> 42 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[      -5 -3000000        0     -120        0        0       20        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000105 

action type: take_action - action 25.0
Learning step: -120005.6171875
desired expected reward: -119970.1875



