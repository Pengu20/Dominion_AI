 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[23.279547]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0      -60        0        0        0        0
        0        0        0     -180        0     -300        0        0] 
sum of rewards: -3000545 

action type: buy - action 6.0
Learning step: -120021.46875
desired expected reward: -120029.6796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[19.722403]
 [24.26897 ]
 [23.006348]
 [15.767174]
 [22.424463]
 [26.922604]
 [23.353525]
 [28.242771]
 [19.375643]
 [22.090904]
 [23.922283]
 [22.831062]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 22.934194564819336



buy possibilites: [-1] 
expected returns: [[32.874977]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 28.242769241333008






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0. 0. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0. 0. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 0.  0.  3.  0.  3. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[22.83264]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 32.874977111816406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[19.578354]
 [24.25406 ]
 [22.970577]
 [15.568148]
 [26.690432]
 [23.298204]
 [22.01472 ]
 [23.065445]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 22.25095558166504



buy possibilites: [-1] 
expected returns: [[20.492092]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 26.690425872802734






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[24.428787]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 20.49209213256836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[21.336832]
 [25.534393]
 [24.21679 ]
 [18.097588]
 [23.726582]
 [28.039783]
 [24.550201]
 [29.404917]
 [21.1437  ]
 [23.358374]
 [25.225384]
 [24.85558 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 23.71388816833496



buy possibilites: [-1] 
expected returns: [[31.05475]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 29.40492057800293






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 0. 3. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  3. 11.  0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 0. 3. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  3. 11.  0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 0.  0.  3.  0.  0.  3. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  0 16] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  3. 11.  0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0. 29.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[37.58818 ]
 [44.76426 ]
 [42.875313]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3. 11.  0.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  3.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  0 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 31.054750442504883



action possibilites: [-1. 11.] 
expected returns: [[29.526777]
 [33.552505]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  0.  0.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  3.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  0 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 42.95762634277344



action possibilites: [-1] 
expected returns: [[36.907814]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 16.  3.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  0 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 38.38395690917969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[33.89054 ]
 [38.941124]
 [37.552147]
 [29.556719]
 [36.881813]
 [41.58155 ]
 [37.91993 ]
 [42.992775]
 [33.561836]
 [36.530945]
 [38.612495]
 [37.555756]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 16.  3.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  0 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 36.907814025878906



buy possibilites: [-1] 
expected returns: [[40.42868]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0. 10. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 16.  3.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  0 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 163 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 42.992767333984375






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [ 0. 16.  3.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  3.  0. 14.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  0 16] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0. 29.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  3.  0. 14.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  0 16] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0. 29.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29.  0. 29.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[28.642204]
 [34.311554]
 [34.311554]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29.  3.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 16.  3.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  0 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 40.428680419921875



action possibilites: [-1. 29. 11.] 
expected returns: [[32.690216]
 [38.13758 ]
 [36.357803]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  3. 11.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 16.  3.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  0 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 33.233184814453125



action possibilites: [-1. 11.] 
expected returns: [[24.808897]
 [28.794619]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 11.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 16.  3.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  0 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 38.1375732421875



action possibilites: [-1] 
expected returns: [[34.922447]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 16.  3.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  0 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 82 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 30.19980812072754





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[30.42106 ]
 [36.03894 ]
 [34.510895]
 [25.668781]
 [33.758537]
 [38.987434]
 [34.89763 ]
 [40.589554]
 [30.106081]
 [33.369583]
 [35.72403 ]
 [34.770508]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 16.  3.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  0 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 34.922447204589844



buy possibilites: [-1] 
expected returns: [[68.871475]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [10. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 16.  3.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  0 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 183 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 40.589569091796875






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0. 16.  3.  0. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  0 16] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29] -> size -> 17 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0. 16.  3.  0. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  0 16] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29] -> size -> 17 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0. 16.  3.  0. 14.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  0 16  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 5 
card supply: [28. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29] -> size -> 17 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[88.853424]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10. 29. 29. 29. 11.  0.  3.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  0 16  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 68.87147521972656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[83.79446 ]
 [91.28229 ]
 [89.275215]
 [77.611206]
 [88.18593 ]
 [95.24512 ]
 [89.76436 ]
 [97.43513 ]
 [83.54876 ]
 [87.75727 ]
 [91.03658 ]
 [90.05991 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10. 29. 29. 29. 11.  0.  3.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  6.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  0 16  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 88.27999114990234



buy possibilites: [-1] 
expected returns: [[150.6687]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10. 29. 29. 29. 11.  0.  3.  3.  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  0 16  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 97.43514251708984






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  0 16  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29. 11. 29. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29] -> size -> 18 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  0 16  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29. 11. 29. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29] -> size -> 18 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  0 16  0  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8. 10.  9.  9. 10. 10.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29. 11. 29. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29] -> size -> 18 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [29. 11. 29. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 29. 10.] 
expected returns: [[75.497444]
 [81.36243 ]
 [78.88044 ]
 [81.36243 ]
 [71.40977 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 29. 10.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10.  9.  9. 10. 10.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  0 16  0  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 150.668701171875



action possibilites: [-1. 11. 29. 10.] 
expected returns: [[60.914116]
 [63.818306]
 [65.916016]
 [57.49804 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8. 10.  9.  9. 10. 10.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  0 16  0  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 81.095703125



action possibilites: [-1. 11. 10.] 
expected returns: [[81.0548 ]
 [84.41674]
 [78.08842]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8. 10.  9.  9. 10. 10.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  0 16  0  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 65.91602325439453



action possibilites: [-1] 
expected returns: [[68.387474]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8. 10.  9.  9. 10. 10.  5.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  0 16  0  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0  27   0] 
sum of rewards: 52 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 86.1001968383789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[62.47171 ]
 [68.674515]
 [67.06127 ]
 [59.0979  ]
 [57.51011 ]
 [66.246635]
 [72.22387 ]
 [67.34947 ]
 [78.215996]
 [74.514915]
 [62.36238 ]
 [67.462425]
 [65.7362  ]
 [61.25962 ]
 [68.565216]
 [69.03204 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 30. 30. 29. 30.  8. 10.  9.  9. 10. 10.  5.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  0 16  0  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 68.3874740600586



buy possibilites: [-1] 
expected returns: [[59.804497]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [10. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10.  9.  9. 10.  9.  5.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  0 16  0  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 275 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 78.21600341796875






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3. 0. 0. 0. 3. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  0 16  0  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10.  9.  9. 10.  9.  5.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29.  0. 29.  0.] 
adversary cards in discard: [10. 25. 29. 29. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25] -> size -> 20 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3. 0. 0. 0. 3. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  0 16  0  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 30. 30. 29. 30.  8. 10.  9.  9. 10.  9.  5.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29.  0. 29.  0.] 
adversary cards in discard: [10. 25. 29. 29. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25] -> size -> 20 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3. 0. 0. 0. 3. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  0 16  0  3  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 5 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  9. 10.  9.  5.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29.  0. 29.  0.] 
adversary cards in discard: [10. 25. 29. 29. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25] -> size -> 20 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0. 29.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[175.0022 ]
 [185.13043]
 [185.13043]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 29.  0.] 
cards in discard: [10. 25. 29. 29. 11. 10.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  9. 10.  9.  5.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 16. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  0 16  0  3  0] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 59.80449676513672



action possibilites: [-1. 29.] 
expected returns: [[109.58623 ]
 [115.711525]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  3.] 
cards in discard: [10. 25. 29. 29. 11. 10.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  9. 10.  9.  5.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 16. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  0 16  0  3  0] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 183.5233154296875



action possibilites: [-1. 29.] 
expected returns: [[108.31732 ]
 [113.446526]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 29.] 
cards in discard: [10. 25. 29. 29. 11. 10.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25] -> size -> 20 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  9. 10.  9.  5.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 16. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  0 16  0  3  0] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 115.71151733398438



action possibilites: [-1.] 
expected returns: [[86.42591]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [10. 25. 29. 29. 11. 10.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25] -> size -> 20 
action values: 1 
buys: 0 
player value: 3 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  9. 10.  9.  5.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 16. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  0 16  0  3  0] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 113.446533203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[82.19151 ]
 [88.36918 ]
 [80.5565  ]
 [86.73418 ]
 [78.76843 ]
 [77.15949 ]
 [85.86752 ]
 [91.62472 ]
 [87.08206 ]
 [96.93573 ]
 [93.51263 ]
 [82.02395 ]
 [86.98708 ]
 [85.44706 ]
 [80.80941 ]
 [88.20163 ]
 [87.801186]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [10. 25. 29. 29. 11. 10.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25] -> size -> 20 
action values: 0 
buys: 1 
player value: 6 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  9. 10.  9.  5.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 16. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  0 16  0  3  0] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 86.42591094970703



buy possibilites: [-1] 
expected returns: [[93.608665]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [10. 25. 29. 29. 11. 10.  0.  0.  0. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  9. 10.  8.  5.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 16. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  0 16  0  3  0] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  -30.    0.    0.   60.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 87.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 96.93572235107422






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  3. 16. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 16. 14.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  0 16  0  3  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  9. 10.  8.  5.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25] -> size -> 21 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  8. 10.  8.  5.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25] -> size -> 21 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 29. 30.  8. 10.  9.  8. 10.  8.  5.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25] -> size -> 21 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [11.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 30. 30. 29. 30.  8. 10.  9.  8. 10.  8.  5.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25] -> size -> 21 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [29.  0. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[ 97.290344]
 [102.805565]
 [ 94.783806]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 30.  8. 10.  9.  8. 10.  8.  5.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [11.  0. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 93.6086654663086



action possibilites: [-1. 10.] 
expected returns: [[54.76792 ]
 [53.321953]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 29. 30.  8. 10.  9.  8. 10.  8.  5.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [11.  0. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 102.7586441040039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[51.973984]
 [57.502953]
 [55.999596]
 [47.29727 ]
 [55.266464]
 [60.404335]
 [56.37873 ]
 [62.00112 ]
 [51.67624 ]
 [54.87536 ]
 [57.20527 ]
 [56.321335]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 30. 30. 29. 30.  8. 10.  9.  8. 10.  8.  5.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [11.  0. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 54.767921447753906



buy possibilites: [-1] 
expected returns: [[68.59307]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.  0.] 
cards in discard: [29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 30.  8. 10.  9.  8. 10.  8.  4.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [11.  0. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 113 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 62.001121520996094






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [11.  0. 16.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 30.  8. 10.  9.  8. 10.  8.  4.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0. 11. 25. 10.] 
adversary cards in discard: [29. 29.  0. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29] -> size -> 22 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [11.  0. 16.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 29. 30.  8. 10.  9.  8. 10.  8.  4.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0. 11. 25. 10.] 
adversary cards in discard: [29. 29.  0. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29] -> size -> 22 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [11.  0. 16.  0.  0.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 28. 30.  8. 10.  9.  8. 10.  8.  4.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0. 11. 25. 10.] 
adversary cards in discard: [29. 29.  0. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29] -> size -> 22 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [29.  0. 11. 25. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 25. 10.] 
expected returns: [[114.66003 ]
 [124.244064]
 [122.4859  ]
 [128.80789 ]
 [115.126564]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 11. 25. 10.] 
cards in discard: [29. 29.  0. 10.  3.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8. 10.  9.  8. 10.  8.  4.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [11.  0. 16.  0.  0.  3.  3.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 68.59307098388672



action possibilites: [-1] 
expected returns: [[45.245857]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 11. 10.  0.  3.] 
cards in discard: [29. 29.  0. 10.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8.  9.  9.  8. 10.  8.  4.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [11.  0. 16.  0.  0.  3.  3.  0.  0.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 125.72577667236328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[41.623962]
 [45.627296]
 [37.347122]
 [45.99991 ]
 [45.854294]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 11. 10.  0.  3.] 
cards in discard: [29. 29.  0. 10.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 28. 30.  8.  9.  9.  8. 10.  8.  4.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [11.  0. 16.  0.  0.  3.  3.  0.  0.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 45.24585723876953



buy possibilites: [-1] 
expected returns: [[10.647657]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 11. 10.  0.  3.] 
cards in discard: [29. 29.  0. 10.  3.  0.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8.  9.  9.  8.  9.  8.  4.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [11.  0. 16.  0.  0.  3.  3.  0.  0.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -29 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 45.999916076660156






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.  0. 16.  0.  0.  3.  3.  0.  0.  0.  3.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8.  9.  9.  8.  9.  8.  4.  9. 10.  7. 10. 10.] 
adversary cards in hand: [25. 10.  0. 29. 29.] 
adversary cards in discard: [29. 29.  0. 10.  3.  0.  0.  8. 25. 29.  0. 11. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8] -> size -> 23 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.  0. 16.  0.  0.  3.  3.  0.  0.  0.  3.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 30. 30. 28. 30.  8.  9.  9.  8.  9.  8.  4.  9. 10.  7. 10. 10.] 
adversary cards in hand: [25. 10.  0. 29. 29.] 
adversary cards in discard: [29. 29.  0. 10.  3.  0.  0.  8. 25. 29.  0. 11. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8] -> size -> 23 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.  0. 16.  0.  0.  3.  3.  0.  0.  0.  3.  3.  6.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 28. 30.  8.  9.  9.  8.  9.  8.  4.  9. 10.  7. 10. 10.] 
adversary cards in hand: [25. 10.  0. 29. 29.] 
adversary cards in discard: [29. 29.  0. 10.  3.  0.  0.  8. 25. 29.  0. 11. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8] -> size -> 23 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [25. 10.  0. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 29. 29.] 
expected returns: [[106.23147 ]
 [113.8059  ]
 [105.375015]
 [111.07845 ]
 [111.07845 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10.  0. 29. 29.] 
cards in discard: [29. 29.  0. 10.  3.  0.  0.  8. 25. 29.  0. 11. 10.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  9.  9.  8.  9.  8.  4.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 10.64765739440918



action possibilites: [-1] 
expected returns: [[32.81984]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29. 29.  0.  3.] 
cards in discard: [29. 29.  0. 10.  3.  0.  0.  8. 25. 29.  0. 11. 10.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  8.  9.  8.  9.  8.  4.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1  6] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 113.2618179321289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[27.448814]
 [31.242216]
 [23.575111]
 [31.569632]
 [31.909697]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 29. 29.  0.  3.] 
cards in discard: [29. 29.  0. 10.  3.  0.  0.  8. 25. 29.  0. 11. 10.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8.  8.  9.  8.  9.  8.  4.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1  6] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 32.81983947753906






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  8.  9.  8.  9.  8.  4.  9. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0. 29.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8] -> size -> 23 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 29. 30. 28. 30.  8.  8.  9.  8.  9.  8.  4.  9. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0. 29.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8] -> size -> 23 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 6. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1  6 15] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 28. 30.  8.  8.  9.  8.  9.  8.  4.  9. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0. 29.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8] -> size -> 23 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [11.  0. 29.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 29.] 
expected returns: [[105.59646]
 [107.95124]
 [109.77139]
 [109.77139]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 29.  0. 29.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  8.  9.  8.  9.  8.  4.  9. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 3. 3. 3.] 
adversary cards in discard: [ 6. 15.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1  6 15] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 31.90968132019043



action possibilites: [-1. 11. 29. 29.] 
expected returns: [[56.725204]
 [59.868736]
 [61.87506 ]
 [61.87506 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 29. 29.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 28. 30.  8.  8.  9.  8.  9.  8.  4.  9. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 3. 3. 3.] 
adversary cards in discard: [ 6. 15.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1  6 15] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 107.77838897705078



action possibilites: [-1. 11. 29. 29.] 
expected returns: [[80.66967]
 [84.36378]
 [85.90635]
 [85.90635]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 29. 29.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8.  8.  9.  8.  9.  8.  4.  9. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 3. 3. 3.] 
adversary cards in discard: [ 6. 15.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1  6 15] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 61.87506103515625



action possibilites: [-1. 11. 29.] 
expected returns: [[76.8987  ]
 [80.5178  ]
 [81.907936]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 3 
card supply: [26. 29. 30. 28. 30.  8.  8.  9.  8.  9.  8.  4.  9. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 3. 3. 3.] 
adversary cards in discard: [ 6. 15.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1  6 15] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 85.9063491821289



action possibilites: [-1. 11.] 
expected returns: [[51.217674]
 [54.048027]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 4 
card supply: [26. 29. 30. 28. 30.  8.  8.  9.  8.  9.  8.  4.  9. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 3. 3. 3.] 
adversary cards in discard: [ 6. 15.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1  6 15] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 81.90792846679688



action possibilites: [-1] 
expected returns: [[26.87963]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 4 
card supply: [26. 29. 30. 28. 30.  8.  8.  9.  8.  9.  8.  4.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 3. 3. 3. 3.] 
adversary cards in discard: [ 6. 15.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1  6 15] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0 100   0   0   0   0   0   0   0  27   0] 
sum of rewards: 122 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 54.33061981201172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[25.335451]
 [29.116127]
 [24.285728]
 [28.066402]
 [23.08112 ]
 [22.050251]
 [27.59725 ]
 [31.074053]
 [28.3431  ]
 [34.385483]
 [32.13124 ]
 [25.03904 ]
 [28.073875]
 [27.293375]
 [24.293198]
 [28.819723]
 [27.959953]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 7 
card supply: [26. 29. 30. 28. 30.  8.  8.  9.  8.  9.  8.  4.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 3. 3. 3. 3.] 
adversary cards in discard: [ 6. 15.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1  6 15] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 26.879629135131836



buy possibilites: [-1] 
expected returns: [[35.979805]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10. 25.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8.  8.  9.  8.  9.  7.  4.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 3. 3. 3. 3.] 
adversary cards in discard: [ 6. 15.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1  6 15] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.    0.    0.    0.  100.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 157.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 34.38548278808594






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 3.] 
cards in discard: [ 6. 15.  0.  0.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1  6 15] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  8.  9.  8.  9.  7.  4.  9. 10.  6. 10.  9.] 
adversary cards in hand: [29. 10. 25.  0.  0.] 
adversary cards in discard: [10. 25. 29. 29. 29. 29. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25] -> size -> 25 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 3.] 
cards in discard: [ 6. 15.  0.  0.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1  6 15] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 28. 30.  8.  8.  9.  8.  9.  7.  4.  9. 10.  6. 10.  9.] 
adversary cards in hand: [29. 10. 25.  0.  0.] 
adversary cards in discard: [10. 25. 29. 29. 29. 29. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25] -> size -> 25 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 3.] 
cards in discard: [ 6. 15.  0.  0.  0.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1  6 15  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 28. 30.  8.  8.  9.  8.  9.  7.  4.  9. 10.  6. 10.  9.] 
adversary cards in hand: [29. 10. 25.  0.  0.] 
adversary cards in discard: [10. 25. 29. 29. 29. 29. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25] -> size -> 25 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [29. 10. 25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 25.] 
expected returns: [[50.04277 ]
 [56.317375]
 [48.39682 ]
 [59.77659 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 25.  0.  0.] 
cards in discard: [10. 25. 29. 29. 29. 29. 11.  0.  0.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8.  8.  9.  8.  9.  7.  4.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 16.  0.  1.  0.] 
adversary cards in discard: [ 6. 15.  0.  0.  0.  0.  0.  0.  0.  3.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1  6 15  0] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 35.97980499267578



action possibilites: [-1] 
expected returns: [[63.101204]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  0.  0. 25.  8.] 
cards in discard: [10. 25. 29. 29. 29. 29. 11.  0.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8.  7.  9.  8.  9.  7.  4.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 16.  0.  1.  0.] 
adversary cards in discard: [ 6. 15.  0.  0.  0.  0.  0.  0.  0.  3.  3.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1  6 15  0  6] -> size -> 24 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 59.776588439941406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[59.69583 ]
 [64.05813 ]
 [54.879883]
 [64.4392  ]
 [64.8604  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 10.  0.  0. 25.  8.] 
cards in discard: [10. 25. 29. 29. 29. 29. 11.  0.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 28. 30.  8.  7.  9.  8.  9.  7.  4.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 16.  0.  1.  0.] 
adversary cards in discard: [ 6. 15.  0.  0.  0.  0.  0.  0.  0.  3.  3.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1  6 15  0  6] -> size -> 24 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 63.10120391845703






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 3. 16.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  0.  1.  0.] 
cards in discard: [ 6. 15.  0.  0.  0.  0.  0.  0.  0.  3.  3.  3.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1  6 15  0  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8.  7.  9.  8.  9.  7.  4.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  3. 10. 29.  3.] 
adversary cards in discard: [10. 25. 29. 29. 29. 29. 11.  0.  0.  0.  3. 25. 29. 10.  0.  0. 25.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25] -> size -> 25 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  0.  1.  0.] 
cards in discard: [ 6. 15.  0.  0.  0.  0.  0.  0.  0.  3.  3.  3.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1  6 15  0  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 29. 30. 28. 30.  8.  7.  9.  8.  9.  7.  4.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  3. 10. 29.  3.] 
adversary cards in discard: [10. 25. 29. 29. 29. 29. 11.  0.  0.  0.  3. 25. 29. 10.  0.  0. 25.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25] -> size -> 25 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  0.  1.  0.] 
cards in discard: [ 6. 15.  0.  0.  0.  0.  0.  0.  0.  3.  3.  3.  3.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1  6 15  0  6
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 4 
card supply: [24. 29. 30. 28. 30.  8.  7.  9.  8.  9.  7.  4.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  3. 10. 29.  3.] 
adversary cards in discard: [10. 25. 29. 29. 29. 29. 11.  0.  0.  0.  3. 25. 29. 10.  0.  0. 25.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25] -> size -> 25 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 0.  3. 10. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[-0.06828046]
 [-0.7088225 ]
 [ 1.771719  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10. 29.  3.] 
cards in discard: [10. 25. 29. 29. 29. 29. 11.  0.  0.  0.  3. 25. 29. 10.  0.  0. 25.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 28. 30.  8.  7.  9.  8.  9.  7.  4.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 11.  6.  0.  0.] 
adversary cards in discard: [ 6. 15.  0.  0.  0.  0.  0.  0.  0.  3.  3.  3.  3.  6.  0.  3. 16.  0.
  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1  6 15  0  6
  0] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 64.86041259765625



action possibilites: [-1. 10.] 
expected returns: [[-5.5520625]
 [-5.7800694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  3.  0.] 
cards in discard: [10. 25. 29. 29. 29. 29. 11.  0.  0.  0.  3. 25. 29. 10.  0.  0. 25.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 28. 30.  8.  7.  9.  8.  9.  7.  4.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 11.  6.  0.  0.] 
adversary cards in discard: [ 6. 15.  0.  0.  0.  0.  0.  0.  0.  3.  3.  3.  3.  6.  0.  3. 16.  0.
  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1  6 15  0  6
  0] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 1.771721363067627





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-6.2155943]
 [-4.7171526]
 [-5.175908 ]
 [-6.9796143]
 [-3.9188406]
 [-5.0756683]
 [-5.534425 ]
 [-5.3064175]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  3.  0.] 
cards in discard: [10. 25. 29. 29. 29. 29. 11.  0.  0.  0.  3. 25. 29. 10.  0.  0. 25.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 29. 30. 28. 30.  8.  7.  9.  8.  9.  7.  4.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 11.  6.  0.  0.] 
adversary cards in discard: [ 6. 15.  0.  0.  0.  0.  0.  0.  0.  3.  3.  3.  3.  6.  0.  3. 16.  0.
  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1  6 15  0  6
  0] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -5.552065849304199



buy possibilites: [-1] 
expected returns: [[-8.3586035]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  3.  0.] 
cards in discard: [10. 25. 29. 29. 29. 29. 11.  0.  0.  0.  3. 25. 29. 10.  0.  0. 25.  8.
 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 28. 30.  8.  7.  9.  7.  9.  7.  4.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 11.  6.  0.  0.] 
adversary cards in discard: [ 6. 15.  0.  0.  0.  0.  0.  0.  0.  3.  3.  3.  3.  6.  0.  3. 16.  0.
  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1  6 15  0  6
  0] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 99 

action type: buy - action 11.0
Learning step: 0
desired expected reward: -3.91884183883667






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6.  0.  0.] 
cards in discard: [ 6. 15.  0.  0.  0.  0.  0.  0.  0.  3.  3.  3.  3.  6.  0.  3. 16.  0.
  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1  6 15  0  6
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 28. 30.  8.  7.  9.  7.  9.  7.  4.  9. 10.  6. 10.  9.] 
adversary cards in hand: [10. 29. 11.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11] -> size -> 26 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  6.  0.  0.] 
cards in discard: [ 6. 15.  0.  0.  0.  0.  0.  0.  0.  3.  3.  3.  3.  6.  0.  3. 16.  0.
  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1  6 15  0  6
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 29. 30. 28. 30.  8.  7.  9.  7.  9.  7.  4.  9. 10.  6. 10.  9.] 
adversary cards in hand: [10. 29. 11.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11] -> size -> 26 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10. 29. 11.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11. 10.] 
expected returns: [[75.786964]
 [73.516754]
 [80.53639 ]
 [78.85679 ]
 [73.516754]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 11.  0. 10.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 28. 30.  8.  7.  9.  7.  9.  7.  4.  9. 10.  6. 10.  9.] 
adversary cards in hand: [1. 6. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1  6 15  0  6
  0] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -8.358603477478027



action possibilites: [-1. 10. 11. 10.  8.] 
expected returns: [[45.281387]
 [44.076233]
 [48.111748]
 [44.076233]
 [45.171577]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0. 10.  8.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 28. 30.  8.  7.  9.  7.  9.  7.  4.  9. 10.  6. 10.  9.] 
adversary cards in hand: [1. 6. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1  6 15  0  6
  0] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 77.96705627441406



action possibilites: [-1] 
expected returns: [[43.2759]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  8.] 
cards in discard: [10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 28. 30.  8.  7.  9.  7.  9.  7.  4.  9. 10.  5. 10.  9.] 
adversary cards in hand: [1. 6. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1  6 15  0  6
  0] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 92 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 49.212928771972656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[39.716377]
 [43.108017]
 [36.29783 ]
 [43.404694]
 [43.58873 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  8.] 
cards in discard: [10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 28. 30.  8.  7.  9.  7.  9.  7.  4.  9. 10.  5. 10.  9.] 
adversary cards in hand: [1. 6. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1  6 15  0  6
  0] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 43.275901794433594






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [1. 6. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1  6 15  0  6
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 28. 30.  8.  7.  9.  7.  9.  7.  4.  9. 10.  5. 10.  9.] 
adversary cards in hand: [29. 29. 25. 25. 11.] 
adversary cards in discard: [10. 29. 11. 10.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10] -> size -> 27 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1  6 15  0  6
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 29. 30. 28. 30.  8.  7.  9.  7.  9.  7.  4.  9. 10.  5. 10.  9.] 
adversary cards in hand: [29. 29. 25. 25. 11.] 
adversary cards in discard: [10. 29. 11. 10.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10] -> size -> 27 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1  6 15  0  6
  0 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 28. 30.  8.  7.  9.  7.  9.  7.  4.  9. 10.  4. 10.  9.] 
adversary cards in hand: [29. 29. 25. 25. 11.] 
adversary cards in discard: [10. 29. 11. 10.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10] -> size -> 27 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [29. 29. 25. 25. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 25. 25. 11.] 
expected returns: [[21.551424]
 [26.401052]
 [26.401052]
 [29.467918]
 [29.467918]
 [25.05108 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 25. 25. 11.] 
cards in discard: [10. 29. 11. 10.  0. 10.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 28. 30.  8.  7.  9.  7.  9.  7.  4.  9. 10.  4. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [10.  1.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1  6 15  0  6
  0 10] -> size -> 26 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 43.58873748779297



action possibilites: [-1] 
expected returns: [[38.91001]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 25. 11.  0. 25.] 
cards in discard: [10. 29. 11. 10.  0. 10.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 28. 30.  8.  6.  9.  7.  9.  7.  4.  9. 10.  4. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [10.  1.  6.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1  6 15  0  6
  0 10  6] -> size -> 27 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 29.46792984008789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[35.851593]
 [32.098106]
 [37.047234]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29. 25. 11.  0. 25.] 
cards in discard: [10. 29. 11. 10.  0. 10.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 29. 30. 28. 30.  8.  6.  9.  7.  9.  7.  4.  9. 10.  4. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [10.  1.  6.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1  6 15  0  6
  0 10  6] -> size -> 27 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 38.910011291503906






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [10.  1.  6.  0.  0.  3.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1  6 15  0  6
  0 10  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 28. 30.  8.  6.  9.  7.  9.  7.  4.  9. 10.  4. 10.  9.] 
adversary cards in hand: [10. 29.  0.  0. 29.] 
adversary cards in discard: [10. 29. 11. 10.  0. 10.  8. 25. 29. 29. 25. 11.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10] -> size -> 27 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [10.  1.  6.  0.  0.  3.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1  6 15  0  6
  0 10  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 29. 30. 28. 30.  8.  6.  9.  7.  9.  7.  4.  9. 10.  4. 10.  9.] 
adversary cards in hand: [10. 29.  0.  0. 29.] 
adversary cards in discard: [10. 29. 11. 10.  0. 10.  8. 25. 29. 29. 25. 11.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10] -> size -> 27 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [10.  1.  6.  0.  0.  3.  6.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1  6 15  0  6
  0 10  6  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 29. 30. 28. 30.  8.  6.  9.  7.  9.  7.  4.  9. 10.  4. 10.  9.] 
adversary cards in hand: [10. 29.  0.  0. 29.] 
adversary cards in discard: [10. 29. 11. 10.  0. 10.  8. 25. 29. 29. 25. 11.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10] -> size -> 27 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [10. 29.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 29.] 
expected returns: [[67.79282]
 [65.2915 ]
 [72.18638]
 [72.18638]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  0.  0. 29.] 
cards in discard: [10. 29. 11. 10.  0. 10.  8. 25. 29. 29. 25. 11.  0. 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  6.  9.  7.  9.  7.  4.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  6. 16.  0.  0.] 
adversary cards in discard: [10.  1.  6.  0.  0.  3.  6.  0.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1  6 15  0  6
  0 10  6  0] -> size -> 28 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 37.0472412109375



action possibilites: [-1. 10. 29.] 
expected returns: [[135.76433]
 [133.55022]
 [141.78143]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 29.  3.] 
cards in discard: [10. 29. 11. 10.  0. 10.  8. 25. 29. 29. 25. 11.  0. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 28. 30.  8.  6.  9.  7.  9.  7.  4.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  6. 16.  0.  0.] 
adversary cards in discard: [10.  1.  6.  0.  0.  3.  6.  0.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1  6 15  0  6
  0 10  6  0] -> size -> 28 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 72.18636322021484



action possibilites: [-1. 10. 10.] 
expected returns: [[113.06934]
 [110.78731]
 [110.78731]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3. 10.] 
cards in discard: [10. 29. 11. 10.  0. 10.  8. 25. 29. 29. 25. 11.  0. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 2 
card supply: [23. 29. 30. 28. 30.  8.  6.  9.  7.  9.  7.  4.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  6. 16.  0.  0.] 
adversary cards in discard: [10.  1.  6.  0.  0.  3.  6.  0.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1  6 15  0  6
  0 10  6  0] -> size -> 28 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 141.78140258789062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[108.08803 ]
 [113.60521 ]
 [112.148476]
 [103.60605 ]
 [111.36287 ]
 [116.75781 ]
 [112.47189 ]
 [118.636154]
 [107.96681 ]
 [111.01516 ]
 [113.48399 ]
 [113.20252 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3. 10.] 
cards in discard: [10. 29. 11. 10.  0. 10.  8. 25. 29. 29. 25. 11.  0. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 29. 30. 28. 30.  8.  6.  9.  7.  9.  7.  4.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  6. 16.  0.  0.] 
adversary cards in discard: [10.  1.  6.  0.  0.  3.  6.  0.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1  6 15  0  6
  0 10  6  0] -> size -> 28 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 113.0693130493164



buy possibilites: [-1] 
expected returns: [[17.984062]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3. 10.] 
cards in discard: [10. 29. 11. 10.  0. 10.  8. 25. 29. 29. 25. 11.  0. 25. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  6.  9.  7.  9.  7.  3.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  6. 16.  0.  0.] 
adversary cards in discard: [10.  1.  6.  0.  0.  3.  6.  0.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1  6 15  0  6
  0 10  6  0] -> size -> 28 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 223 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 118.6361312866211






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 0.  6. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 16.  0.  0.] 
cards in discard: [10.  1.  6.  0.  0.  3.  6.  0.  3.  0.  0.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  6  1  6 15  0  6
  0 10  6  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  6.  9.  7.  9.  7.  3.  9. 10.  4. 10.  9.] 
adversary cards in hand: [29.  0.  3.  0.  0.] 
adversary cards in discard: [10. 29. 11. 10.  0. 10.  8. 25. 29. 29. 25. 11.  0. 25. 29. 29. 29. 10.
  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29] -> size -> 28 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [10.  1.  6.  0.  0.  3.  6.  0.  3.  0.  0.  0.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  6.  9.  7.  9.  7.  3.  9. 10.  4. 10.  9.] 
adversary cards in hand: [29.  0.  3.  0.  0.] 
adversary cards in discard: [10. 29. 11. 10.  0. 10.  8. 25. 29. 29. 25. 11.  0. 25. 29. 29. 29. 10.
  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29] -> size -> 28 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [10.  1.  6.  0.  0.  3.  6.  0.  3.  0.  0.  0.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 29. 30. 27. 30.  8.  6.  9.  7.  9.  7.  3.  9. 10.  4. 10.  9.] 
adversary cards in hand: [29.  0.  3.  0.  0.] 
adversary cards in discard: [10. 29. 11. 10.  0. 10.  8. 25. 29. 29. 25. 11.  0. 25. 29. 29. 29. 10.
  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29] -> size -> 28 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [10.  1.  6.  0.  0.  3.  6.  0.  3.  0.  0.  0.  3.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 29. 30. 27. 30.  8.  6.  9.  7.  9.  7.  3.  9. 10.  4. 10.  9.] 
adversary cards in hand: [29.  0.  3.  0.  0.] 
adversary cards in discard: [10. 29. 11. 10.  0. 10.  8. 25. 29. 29. 25. 11.  0. 25. 29. 29. 29. 10.
  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29] -> size -> 28 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [29.  0.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[24.13071 ]
 [26.460873]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  0.  0.] 
cards in discard: [10. 29. 11. 10.  0. 10.  8. 25. 29. 29. 25. 11.  0. 25. 29. 29. 29. 10.
  0.  0.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 30.  8.  6.  9.  7.  9.  7.  3.  9. 10.  4. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 6.] 
adversary cards in discard: [10.  1.  6.  0.  0.  3.  6.  0.  3.  0.  0.  0.  3.  3.  0. 16.  0.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0] -> size -> 29 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 17.98406219482422



action possibilites: [-1.] 
expected returns: [[16.451426]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [10. 29. 11. 10.  0. 10.  8. 25. 29. 29. 25. 11.  0. 25. 29. 29. 29. 10.
  0.  0.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 29. 30. 27. 30.  8.  6.  9.  7.  9.  7.  3.  9. 10.  4. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 6.] 
adversary cards in discard: [10.  1.  6.  0.  0.  3.  6.  0.  3.  0.  0.  0.  3.  3.  0. 16.  0.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0] -> size -> 29 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 26.460872650146484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[12.593005]
 [16.4298  ]
 [15.367254]
 [ 9.879974]
 [14.870132]
 [18.619204]
 [15.468498]
 [20.132154]
 [12.579982]
 [14.420025]
 [16.416027]
 [17.219805]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [10. 29. 11. 10.  0. 10.  8. 25. 29. 29. 25. 11.  0. 25. 29. 29. 29. 10.
  0.  0.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 29. 30. 27. 30.  8.  6.  9.  7.  9.  7.  3.  9. 10.  4. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 6.] 
adversary cards in discard: [10.  1.  6.  0.  0.  3.  6.  0.  3.  0.  0.  0.  3.  3.  0. 16.  0.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0] -> size -> 29 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 16.451425552368164



buy possibilites: [-1] 
expected returns: [[48.075188]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [10. 29. 11. 10.  0. 10.  8. 25. 29. 29. 25. 11.  0. 25. 29. 29. 29. 10.
  0.  0.  3. 10. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 30.  8.  6.  9.  7.  9.  7.  2.  9. 10.  4. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 6.] 
adversary cards in discard: [10.  1.  6.  0.  0.  3.  6.  0.  3.  0.  0.  0.  3.  3.  0. 16.  0.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0] -> size -> 29 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 20.13214683532715






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 6.] 
cards in discard: [10.  1.  6.  0.  0.  3.  6.  0.  3.  0.  0.  0.  3.  3.  0. 16.  0.  0.
  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 30.  8.  6.  9.  7.  9.  7.  2.  9. 10.  4. 10.  9.] 
adversary cards in hand: [10. 10. 29. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29] -> size -> 29 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 6.] 
cards in discard: [10.  1.  6.  0.  0.  3.  6.  0.  3.  0.  0.  0.  3.  3.  0. 16.  0.  0.
  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 29. 30. 27. 30.  8.  6.  9.  7.  9.  7.  2.  9. 10.  4. 10.  9.] 
adversary cards in hand: [10. 10. 29. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29] -> size -> 29 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 6.] 
cards in discard: [10.  1.  6.  0.  0.  3.  6.  0.  3.  0.  0.  0.  3.  3.  0. 16.  0.  0.
  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 29. 30. 27. 30.  8.  6.  9.  7.  9.  7.  2.  9. 10.  4. 10.  9.] 
adversary cards in hand: [10. 10. 29. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29] -> size -> 29 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [10. 10. 29. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 29. 29. 29.] 
expected returns: [[72.22274]
 [71.55732]
 [71.55732]
 [76.93617]
 [76.93617]
 [76.93617]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 29. 29. 29.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 30.  8.  6.  9.  7.  9.  7.  2.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 11. 15.  0.  0.] 
adversary cards in discard: [10.  1.  6.  0.  0.  3.  6.  0.  3.  0.  0.  0.  3.  3.  0. 16.  0.  0.
  0.  0.  0.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0] -> size -> 30 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 48.07518768310547



action possibilites: [-1. 10. 10. 29. 29.] 
expected returns: [[63.370438]
 [62.12754 ]
 [62.12754 ]
 [68.08474 ]
 [68.08474 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 29. 29.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 27. 30.  8.  6.  9.  7.  9.  7.  2.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 11. 15.  0.  0.] 
adversary cards in discard: [10.  1.  6.  0.  0.  3.  6.  0.  3.  0.  0.  0.  3.  3.  0. 16.  0.  0.
  0.  0.  0.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0] -> size -> 30 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 76.9361801147461



action possibilites: [-1. 10. 10. 29.] 
expected returns: [[28.934498]
 [28.058279]
 [28.058279]
 [32.241447]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 29.  0.  3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29] -> size -> 29 
action values: 1 
buys: 0 
player value: 2 
card supply: [21. 29. 30. 27. 30.  8.  6.  9.  7.  9.  7.  2.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 11. 15.  0.  0.] 
adversary cards in discard: [10.  1.  6.  0.  0.  3.  6.  0.  3.  0.  0.  0.  3.  3.  0. 16.  0.  0.
  0.  0.  0.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0] -> size -> 30 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 68.0847396850586



action possibilites: [-1. 10. 10. 25.] 
expected returns: [[19.133703]
 [18.308136]
 [18.308136]
 [24.611563]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  3. 25.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29] -> size -> 29 
action values: 1 
buys: 0 
player value: 3 
card supply: [21. 29. 30. 27. 30.  8.  6.  9.  7.  9.  7.  2.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 11. 15.  0.  0.] 
adversary cards in discard: [10.  1.  6.  0.  0.  3.  6.  0.  3.  0.  0.  0.  3.  3.  0. 16.  0.  0.
  0.  0.  0.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0] -> size -> 30 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 32.24144744873047



action possibilites: [-1] 
expected returns: [[10.365755]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  3.  3. 29.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 29. 30. 27. 30.  8.  5.  9.  7.  9.  7.  2.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 11. 15.  0.  0.] 
adversary cards in discard: [10.  1.  6.  0.  0.  3.  6.  0.  3.  0.  0.  0.  3.  3.  0. 16.  0.  0.
  0.  0.  0.  3.  0.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6] -> size -> 31 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 24.611570358276367





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 7.5621586]
 [10.450732 ]
 [ 9.702197 ]
 [ 5.2383413]
 [ 9.41147  ]
 [12.35911  ]
 [ 9.7906885]
 [13.51697  ]
 [ 7.4543304]
 [ 9.04215  ]
 [10.342904 ]
 [10.719667 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  3.  3. 29.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 29. 30. 27. 30.  8.  5.  9.  7.  9.  7.  2.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 11. 15.  0.  0.] 
adversary cards in discard: [10.  1.  6.  0.  0.  3.  6.  0.  3.  0.  0.  0.  3.  3.  0. 16.  0.  0.
  0.  0.  0.  3.  0.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6] -> size -> 31 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 10.365755081176758



buy possibilites: [-1] 
expected returns: [[8.832549]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  3.  3. 29.] 
cards in discard: [29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 30.  8.  5.  9.  7.  9.  7.  1.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 11. 15.  0.  0.] 
adversary cards in discard: [10.  1.  6.  0.  0.  3.  6.  0.  3.  0.  0.  0.  3.  3.  0. 16.  0.  0.
  0.  0.  0.  3.  0.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6] -> size -> 31 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  80   0   0   0   0   0   0   0 128   0] 
sum of rewards: 203 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 13.516976356506348






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 0. 11. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 15.  0.  0.] 
cards in discard: [10.  1.  6.  0.  0.  3.  6.  0.  3.  0.  0.  0.  3.  3.  0. 16.  0.  0.
  0.  0.  0.  3.  0.  3.  6.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 30.  8.  5.  9.  7.  9.  7.  1.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 11. 29.  3.  0.] 
adversary cards in discard: [29. 29. 29. 29. 25. 10. 10.  0.  3.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29] -> size -> 30 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 15.  0.  0.] 
cards in discard: [10.  1.  6.  0.  0.  3.  6.  0.  3.  0.  0.  0.  3.  3.  0. 16.  0.  0.
  0.  0.  0.  3.  0.  3.  6.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 29. 30. 27. 30.  8.  5.  9.  7.  9.  7.  1.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 11. 29.  3.  0.] 
adversary cards in discard: [29. 29. 29. 29. 25. 10. 10.  0.  3.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29] -> size -> 30 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 11. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[80.468445]
 [81.90418 ]
 [83.44017 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 29.  3.  0.] 
cards in discard: [29. 29. 29. 29. 25. 10. 10.  0.  3.  3. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 30.  8.  5.  9.  7.  9.  7.  1.  9. 10.  4. 10.  9.] 
adversary cards in hand: [0. 6. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6] -> size -> 31 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 8.832549095153809



action possibilites: [-1. 11. 10.] 
expected returns: [[90.25035]
 [94.10783]
 [88.18546]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0. 10.] 
cards in discard: [29. 29. 29. 29. 25. 10. 10.  0.  3.  3. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 27. 30.  8.  5.  9.  7.  9.  7.  1.  9. 10.  4. 10.  9.] 
adversary cards in hand: [0. 6. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6] -> size -> 31 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 83.4401626586914



action possibilites: [-1] 
expected returns: [[43.49154]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10.] 
cards in discard: [29. 29. 29. 29. 25. 10. 10.  0.  3.  3. 29. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 27. 30.  8.  5.  9.  7.  9.  7.  1.  9. 10.  3. 10.  9.] 
adversary cards in hand: [0. 6. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6] -> size -> 31 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 92 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 94.21417999267578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[41.636765]
 [44.352036]
 [43.648277]
 [39.46762 ]
 [45.754646]
 [43.74318 ]
 [43.039413]
 [44.543976]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.] 
cards in discard: [29. 29. 29. 29. 25. 10. 10.  0.  3.  3. 29. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 29. 30. 27. 30.  8.  5.  9.  7.  9.  7.  1.  9. 10.  3. 10.  9.] 
adversary cards in hand: [0. 6. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6] -> size -> 31 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 43.491539001464844



buy possibilites: [-1] 
expected returns: [[36.990646]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.] 
cards in discard: [29. 29. 29. 29. 25. 10. 10.  0.  3.  3. 29. 10. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 30.  8.  5.  9.  6.  9.  7.  1.  9. 10.  3. 10.  9.] 
adversary cards in hand: [0. 6. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6] -> size -> 31 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 119 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 45.754638671875






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [0. 6. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 30.  8.  5.  9.  6.  9.  7.  1.  9. 10.  3. 10.  9.] 
adversary cards in hand: [25. 10. 29. 11.  0.] 
adversary cards in discard: [29. 29. 29. 29. 25. 10. 10.  0.  3.  3. 29. 10. 11. 29. 11.  0.  3.  0.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11] -> size -> 32 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 29. 30. 27. 30.  8.  5.  9.  6.  9.  7.  1.  9. 10.  3. 10.  9.] 
adversary cards in hand: [25. 10. 29. 11.  0.] 
adversary cards in discard: [29. 29. 29. 29. 25. 10. 10.  0.  3.  3. 29. 10. 11. 29. 11.  0.  3.  0.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11] -> size -> 32 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 30.  8.  5.  9.  6.  9.  7.  1.  9. 10.  2. 10.  9.] 
adversary cards in hand: [25. 10. 29. 11.  0.] 
adversary cards in discard: [29. 29. 29. 29. 25. 10. 10.  0.  3.  3. 29. 10. 11. 29. 11.  0.  3.  0.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11] -> size -> 32 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [25. 10. 29. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 29. 11.] 
expected returns: [[30.959318]
 [34.296288]
 [28.201998]
 [32.50084 ]
 [31.278032]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10. 29. 11.  0.] 
cards in discard: [29. 29. 29. 29. 25. 10. 10.  0.  3.  3. 29. 10. 11. 29. 11.  0.  3.  0.
 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 30.  8.  5.  9.  6.  9.  7.  1.  9. 10.  2. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10] -> size -> 32 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 36.99064636230469



action possibilites: [-1] 
expected returns: [[83.85588]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 11.  0. 29.  0.] 
cards in discard: [29. 29. 29. 29. 25. 10. 10.  0.  3.  3. 29. 10. 11. 29. 11.  0.  3.  0.
 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 30.  8.  4.  9.  6.  9.  7.  1.  9. 10.  2. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10  6] -> size -> 33 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 34.296295166015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[78.987274]
 [82.32156 ]
 [75.484665]
 [82.489044]
 [83.90724 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29. 11.  0. 29.  0.] 
cards in discard: [29. 29. 29. 29. 25. 10. 10.  0.  3.  3. 29. 10. 11. 29. 11.  0.  3.  0.
 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 29. 30. 27. 30.  8.  4.  9.  6.  9.  7.  1.  9. 10.  2. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10  6] -> size -> 33 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 83.85588073730469






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [10.  0.  6.  0.  3.  0.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 30.  8.  4.  9.  6.  9.  7.  1.  9. 10.  2. 10.  9.] 
adversary cards in hand: [25.  8. 10.  0. 29.] 
adversary cards in discard: [29. 29. 29. 29. 25. 10. 10.  0.  3.  3. 29. 10. 11. 29. 11.  0.  3.  0.
 10. 25. 10. 29. 11.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11] -> size -> 32 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [10.  0.  6.  0.  3.  0.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10  6] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 29. 30. 27. 30.  8.  4.  9.  6.  9.  7.  1.  9. 10.  2. 10.  9.] 
adversary cards in hand: [25.  8. 10.  0. 29.] 
adversary cards in discard: [29. 29. 29. 29. 25. 10. 10.  0.  3.  3. 29. 10. 11. 29. 11.  0.  3.  0.
 10. 25. 10. 29. 11.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11] -> size -> 32 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10  6  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 26. 30.  8.  4.  9.  6.  9.  7.  1.  9. 10.  2. 10.  9.] 
adversary cards in hand: [25.  8. 10.  0. 29.] 
adversary cards in discard: [29. 29. 29. 29. 25. 10. 10.  0.  3.  3. 29. 10. 11. 29. 11.  0.  3.  0.
 10. 25. 10. 29. 11.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11] -> size -> 32 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [25.  8. 10.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8. 10. 29.] 
expected returns: [[21.378113]
 [27.726416]
 [21.58432 ]
 [20.526115]
 [25.476467]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8. 10.  0. 29.] 
cards in discard: [29. 29. 29. 29. 25. 10. 10.  0.  3.  3. 29. 10. 11. 29. 11.  0.  3.  0.
 10. 25. 10. 29. 11.  0. 29.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 26. 30.  8.  4.  9.  6.  9.  7.  1.  9. 10.  2. 10.  9.] 
adversary cards in hand: [6. 0. 0. 3. 6.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10  6  3] -> size -> 34 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 83.90721893310547



action possibilites: [-1] 
expected returns: [[17.203007]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0. 29. 10.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 26. 30.  8.  3.  9.  6.  9.  7.  1.  9. 10.  2. 10.  9.] 
adversary cards in hand: [6. 0. 0. 3. 6.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  3.  0.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10  6  3  6] -> size -> 35 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 27.72641944885254





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[12.607608]
 [15.553001]
 [ 9.340153]
 [15.741817]
 [16.489635]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  0. 29. 10.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 29. 30. 26. 30.  8.  3.  9.  6.  9.  7.  1.  9. 10.  2. 10.  9.] 
adversary cards in hand: [6. 0. 0. 3. 6.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  3.  0.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10  6  3  6] -> size -> 35 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 17.203006744384766






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [6. 0. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3. 6.] 
cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  3.  0.  0.  0.  3.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10  6  3  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 26. 30.  8.  3.  9.  6.  9.  7.  1.  9. 10.  2. 10.  9.] 
adversary cards in hand: [10. 29.  3. 29.  0.] 
adversary cards in discard: [25.  8. 10.  0. 29. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11] -> size -> 32 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 6.] 
cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  3.  0.  0.  0.  3.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10  6  3  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 29. 30. 26. 30.  8.  3.  9.  6.  9.  7.  1.  9. 10.  2. 10.  9.] 
adversary cards in hand: [10. 29.  3. 29.  0.] 
adversary cards in discard: [25.  8. 10.  0. 29. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11] -> size -> 32 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 6.] 
cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  3.  0.  0.  0.  3.  6.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10  6  3  6  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 26. 30.  8.  3.  9.  6.  8.  7.  1.  9. 10.  2. 10.  9.] 
adversary cards in hand: [10. 29.  3. 29.  0.] 
adversary cards in discard: [25.  8. 10.  0. 29. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11] -> size -> 32 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [10. 29.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 29.] 
expected returns: [[ 6.3398914]
 [ 6.5024643]
 [10.265926 ]
 [10.265926 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  3. 29.  0.] 
cards in discard: [25.  8. 10.  0. 29. 10.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 26. 30.  8.  3.  9.  6.  8.  7.  1.  9. 10.  2. 10.  9.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  3.  0.  0.  0.  3.  6.  8.  6.  0.  0.
  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10  6  3  6  8] -> size -> 36 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 16.489641189575195



action possibilites: [-1. 10. 29.] 
expected returns: [[-5.3773913]
 [-5.5840015]
 [-3.9786568]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 29.  0.  3.] 
cards in discard: [25.  8. 10.  0. 29. 10.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 26. 30.  8.  3.  9.  6.  8.  7.  1.  9. 10.  2. 10.  9.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  3.  0.  0.  0.  3.  6.  8.  6.  0.  0.
  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10  6  3  6  8] -> size -> 36 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 10.26593017578125



action possibilites: [-1. 10. 29.] 
expected returns: [[12.739588]
 [10.360693]
 [16.592264]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  3. 29.] 
cards in discard: [25.  8. 10.  0. 29. 10.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 2 
card supply: [21. 29. 30. 26. 30.  8.  3.  9.  6.  8.  7.  1.  9. 10.  2. 10.  9.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  3.  0.  0.  0.  3.  6.  8.  6.  0.  0.
  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10  6  3  6  8] -> size -> 36 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: -3.9786508083343506



action possibilites: [-1. 10.] 
expected returns: [[13.463879]
 [12.313942]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  3.  0.] 
cards in discard: [25.  8. 10.  0. 29. 10.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 3 
card supply: [21. 29. 30. 26. 30.  8.  3.  9.  6.  8.  7.  1.  9. 10.  2. 10.  9.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  3.  0.  0.  0.  3.  6.  8.  6.  0.  0.
  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10  6  3  6  8] -> size -> 36 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 16.592267990112305





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 8.434756 ]
 [12.35001  ]
 [11.289066 ]
 [ 6.1786385]
 [ 5.136049 ]
 [10.791345 ]
 [14.389673 ]
 [11.535362 ]
 [17.807093 ]
 [15.551039 ]
 [ 8.218251 ]
 [11.389488 ]
 [10.474415 ]
 [ 7.4742346]
 [12.133508 ]
 [11.6243515]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  3.  0.] 
cards in discard: [25.  8. 10.  0. 29. 10.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 29. 30. 26. 30.  8.  3.  9.  6.  8.  7.  1.  9. 10.  2. 10.  9.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  3.  0.  0.  0.  3.  6.  8.  6.  0.  0.
  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10  6  3  6  8] -> size -> 36 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 13.463871002197266



buy possibilites: [-1] 
expected returns: [[13.904896]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  3.  0.] 
cards in discard: [25.  8. 10.  0. 29. 10.  0. 25.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 26. 30.  8.  3.  9.  6.  8.  6.  1.  9. 10.  2. 10.  9.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  3.  0.  0.  0.  3.  6.  8.  6.  0.  0.
  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10  6  3  6  8] -> size -> 36 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 365 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 17.807083129882812






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [10.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  0.] 
cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  3.  0.  0.  0.  3.  6.  8.  6.  0.  0.
  3.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10  6  3  6  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 26. 30.  8.  3.  9.  6.  8.  6.  1.  9. 10.  2. 10.  9.] 
adversary cards in hand: [11. 25. 10. 10.  0.] 
adversary cards in discard: [25.  8. 10.  0. 29. 10.  0. 25. 29. 29. 29. 10.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25] -> size -> 33 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  3.  0.  0.  0.  3.  6.  8.  6.  0.  0.
  3.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10  6  3  6  8] -> size -> 36 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 26. 30.  8.  3.  9.  6.  8.  6.  1.  9. 10.  2. 10.  9.] 
adversary cards in hand: [11. 25. 10. 10.  0.] 
adversary cards in discard: [25.  8. 10.  0. 29. 10.  0. 25. 29. 29. 29. 10.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25] -> size -> 33 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  3.  0.  0.  0.  3.  6.  8.  6.  0.  0.
  3.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10  6  3  6  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 29. 30. 26. 30.  8.  3.  9.  6.  8.  6.  1.  9. 10.  2. 10.  9.] 
adversary cards in hand: [11. 25. 10. 10.  0.] 
adversary cards in discard: [25.  8. 10.  0. 29. 10.  0. 25. 29. 29. 29. 10.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25] -> size -> 33 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  3.  0.  0.  0.  3.  6.  8.  6.  0.  0.
  3.  6.  4.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10  6  3  6  8  4] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 26. 29.  8.  3.  9.  6.  8.  6.  1.  9. 10.  2. 10.  9.] 
adversary cards in hand: [11. 25. 10. 10.  0.] 
adversary cards in discard: [25.  8. 10.  0. 29. 10.  0. 25. 29. 29. 29. 10.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25] -> size -> 33 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [11. 25. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 10. 10.] 
expected returns: [[18.604883]
 [19.638859]
 [22.638042]
 [16.367838]
 [16.367838]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25. 10. 10.  0.] 
cards in discard: [25.  8. 10.  0. 29. 10.  0. 25. 29. 29. 29. 10.  3.  0.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 26. 29.  8.  3.  9.  6.  8.  6.  1.  9. 10.  2. 10.  9.] 
adversary cards in hand: [16.  0.  0. 15.  3.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  3.  0.  0.  0.  3.  6.  8.  6.  0.  0.
  3.  6.  4. 10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10  6  3  6  8  4] -> size -> 37 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 13.904895782470703



action possibilites: [-1] 
expected returns: [[5.695917]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 10.  0.  3. 25.] 
cards in discard: [25.  8. 10.  0. 29. 10.  0. 25. 29. 29. 29. 10.  3.  0.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 26. 29.  8.  2.  9.  6.  8.  6.  1.  9. 10.  2. 10.  9.] 
adversary cards in hand: [16.  0.  0. 15.  3.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  3.  0.  0.  0.  3.  6.  8.  6.  0.  0.
  3.  6.  4. 10.  0.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10  6  3  6  8  4  6] -> size -> 38 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 22.638029098510742





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[2.664876 ]
 [1.3120239]
 [5.65781  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 10.  0.  3. 25.] 
cards in discard: [25.  8. 10.  0. 29. 10.  0. 25. 29. 29. 29. 10.  3.  0.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 29. 30. 26. 29.  8.  2.  9.  6.  8.  6.  1.  9. 10.  2. 10.  9.] 
adversary cards in hand: [16.  0.  0. 15.  3.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  3.  0.  0.  0.  3.  6.  8.  6.  0.  0.
  3.  6.  4. 10.  0.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10  6  3  6  8  4  6] -> size -> 38 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 5.695917129516602






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [16.  0.  0. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0. 15.  3.] 
cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  3.  0.  0.  0.  3.  6.  8.  6.  0.  0.
  3.  6.  4. 10.  0.  0.  0.  0.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10  6  3  6  8  4  6] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 26. 29.  8.  2.  9.  6.  8.  6.  1.  9. 10.  2. 10.  9.] 
adversary cards in hand: [11. 29.  0. 29. 29.] 
adversary cards in discard: [25.  8. 10.  0. 29. 10.  0. 25. 29. 29. 29. 10.  3.  0.  3.  0. 25. 11.
 10. 10.  0.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25] -> size -> 33 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0. 15.  3.] 
cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  3.  0.  0.  0.  3.  6.  8.  6.  0.  0.
  3.  6.  4. 10.  0.  0.  0.  0.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10  6  3  6  8  4  6] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 29. 30. 26. 29.  8.  2.  9.  6.  8.  6.  1.  9. 10.  2. 10.  9.] 
adversary cards in hand: [11. 29.  0. 29. 29.] 
adversary cards in discard: [25.  8. 10.  0. 29. 10.  0. 25. 29. 29. 29. 10.  3.  0.  3.  0. 25. 11.
 10. 10.  0.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25] -> size -> 33 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0. 15.  3.] 
cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  3.  0.  0.  0.  3.  6.  8.  6.  0.  0.
  3.  6.  4. 10.  0.  0.  0.  0.  0.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10  6  3  6  8  4  6  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 29. 30. 26. 29.  8.  2.  9.  6.  8.  6.  1.  9. 10.  2. 10.  9.] 
adversary cards in hand: [11. 29.  0. 29. 29.] 
adversary cards in discard: [25.  8. 10.  0. 29. 10.  0. 25. 29. 29. 29. 10.  3.  0.  3.  0. 25. 11.
 10. 10.  0.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25] -> size -> 33 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [11. 29.  0. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 29. 29.] 
expected returns: [[27.882185]
 [28.7291  ]
 [29.441978]
 [29.441978]
 [29.441978]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  0. 29. 29.] 
cards in discard: [25.  8. 10.  0. 29. 10.  0. 25. 29. 29. 29. 10.  3.  0.  3.  0. 25. 11.
 10. 10.  0.  3. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 26. 29.  8.  2.  9.  6.  8.  6.  1.  9. 10.  2. 10.  9.] 
adversary cards in hand: [11.  1.  0.  6.  3.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  3.  0.  0.  0.  3.  6.  8.  6.  0.  0.
  3.  6.  4. 10.  0.  0.  0.  0.  0.  6.  0. 16.  0.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10  6  3  6  8  4  6  0] -> size -> 39 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 5.657812118530273



action possibilites: [-1. 11. 29. 29. 29.] 
expected returns: [[35.946075]
 [36.757263]
 [37.867744]
 [37.867744]
 [37.867744]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 29. 29. 29.] 
cards in discard: [25.  8. 10.  0. 29. 10.  0. 25. 29. 29. 29. 10.  3.  0.  3.  0. 25. 11.
 10. 10.  0.  3. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 29. 30. 26. 29.  8.  2.  9.  6.  8.  6.  1.  9. 10.  2. 10.  9.] 
adversary cards in hand: [11.  1.  0.  6.  3.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  3.  0.  0.  0.  3.  6.  8.  6.  0.  0.
  3.  6.  4. 10.  0.  0.  0.  0.  0.  6.  0. 16.  0.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10  6  3  6  8  4  6  0] -> size -> 39 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 29.441980361938477



action possibilites: [-1. 11. 29. 29.] 
expected returns: [[32.73123 ]
 [34.847687]
 [36.136497]
 [36.136497]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 29. 29.  0.] 
cards in discard: [25.  8. 10.  0. 29. 10.  0. 25. 29. 29. 29. 10.  3.  0.  3.  0. 25. 11.
 10. 10.  0.  3. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25] -> size -> 33 
action values: 1 
buys: 0 
player value: 2 
card supply: [20. 29. 30. 26. 29.  8.  2.  9.  6.  8.  6.  1.  9. 10.  2. 10.  9.] 
adversary cards in hand: [11.  1.  0.  6.  3.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  3.  0.  0.  0.  3.  6.  8.  6.  0.  0.
  3.  6.  4. 10.  0.  0.  0.  0.  0.  6.  0. 16.  0.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10  6  3  6  8  4  6  0] -> size -> 39 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 37.86773681640625



action possibilites: [-1. 11. 29. 10.] 
expected returns: [[71.50817]
 [73.62234]
 [75.26934]
 [68.75592]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 29.  0. 10.] 
cards in discard: [25.  8. 10.  0. 29. 10.  0. 25. 29. 29. 29. 10.  3.  0.  3.  0. 25. 11.
 10. 10.  0.  3. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25] -> size -> 33 
action values: 1 
buys: 0 
player value: 3 
card supply: [20. 29. 30. 26. 29.  8.  2.  9.  6.  8.  6.  1.  9. 10.  2. 10.  9.] 
adversary cards in hand: [11.  1.  0.  6.  3.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  3.  0.  0.  0.  3.  6.  8.  6.  0.  0.
  3.  6.  4. 10.  0.  0.  0.  0.  0.  6.  0. 16.  0.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10  6  3  6  8  4  6  0] -> size -> 39 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 36.136505126953125



action possibilites: [-1. 11. 10. 11.] 
expected returns: [[37.782585]
 [39.34223 ]
 [35.79979 ]
 [39.34223 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 10. 11.] 
cards in discard: [25.  8. 10.  0. 29. 10.  0. 25. 29. 29. 29. 10.  3.  0.  3.  0. 25. 11.
 10. 10.  0.  3. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25] -> size -> 33 
action values: 1 
buys: 0 
player value: 4 
card supply: [20. 29. 30. 26. 29.  8.  2.  9.  6.  8.  6.  1.  9. 10.  2. 10.  9.] 
adversary cards in hand: [11.  1.  0.  6.  3.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  3.  0.  0.  0.  3.  6.  8.  6.  0.  0.
  3.  6.  4. 10.  0.  0.  0.  0.  0.  6.  0. 16.  0.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10  6  3  6  8  4  6  0] -> size -> 39 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 75.26934051513672



action possibilites: [-1] 
expected returns: [[87.72994]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 11.] 
cards in discard: [25.  8. 10.  0. 29. 10.  0. 25. 29. 29. 29. 10.  3.  0.  3.  0. 25. 11.
 10. 10.  0.  3. 25. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10] -> size -> 34 
action values: 0 
buys: 0 
player value: 4 
card supply: [20. 29. 30. 26. 29.  8.  2.  9.  6.  8.  6.  1.  9. 10.  1. 10.  9.] 
adversary cards in hand: [11.  1.  0.  6.  3.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  3.  0.  0.  0.  3.  6.  8.  6.  0.  0.
  3.  6.  4. 10.  0.  0.  0.  0.  0.  6.  0. 16.  0.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10  6  3  6  8  4  6  0] -> size -> 39 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0 100   0   0   0   0   0   0   0  27   0] 
sum of rewards: 122 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 40.254676818847656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[83.83586 ]
 [88.776566]
 [82.509674]
 [87.45038 ]
 [81.04933 ]
 [79.74478 ]
 [86.768555]
 [91.3789  ]
 [87.76439 ]
 [96.0055  ]
 [92.85126 ]
 [83.651665]
 [87.59654 ]
 [86.43821 ]
 [82.65583 ]
 [88.59238 ]
 [88.028336]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 11.] 
cards in discard: [25.  8. 10.  0. 29. 10.  0. 25. 29. 29. 29. 10.  3.  0.  3.  0. 25. 11.
 10. 10.  0.  3. 25. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10] -> size -> 34 
action values: 0 
buys: 1 
player value: 6 
card supply: [20. 29. 30. 26. 29.  8.  2.  9.  6.  8.  6.  1.  9. 10.  1. 10.  9.] 
adversary cards in hand: [11.  1.  0.  6.  3.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  3.  0.  0.  0.  3.  6.  8.  6.  0.  0.
  3.  6.  4. 10.  0.  0.  0.  0.  0.  6.  0. 16.  0.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10  6  3  6  8  4  6  0] -> size -> 39 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 87.72994232177734



buy possibilites: [-1] 
expected returns: [[77.489456]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 11.] 
cards in discard: [25.  8. 10.  0. 29. 10.  0. 25. 29. 29. 29. 10.  3.  0.  3.  0. 25. 11.
 10. 10.  0.  3. 25. 10. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 29. 30. 26. 29.  8.  2.  9.  6.  8.  5.  1.  9. 10.  1. 10.  9.] 
adversary cards in hand: [11.  1.  0.  6.  3.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  3.  0.  0.  0.  3.  6.  8.  6.  0.  0.
  3.  6.  4. 10.  0.  0.  0.  0.  0.  6.  0. 16.  0.  0. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10  6  3  6  8  4  6  0] -> size -> 39 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.    0.    0.    0.  100.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 157.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 96.00547790527344






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [11.  1.  0.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  0.  6.  3.] 
cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  3.  0.  0.  0.  3.  6.  8.  6.  0.  0.
  3.  6.  4. 10.  0.  0.  0.  0.  0.  6.  0. 16.  0.  0. 15.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10  6  3  6  8  4  6  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 26. 29.  8.  2.  9.  6.  8.  5.  1.  9. 10.  1. 10.  9.] 
adversary cards in hand: [29. 25. 29. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25] -> size -> 35 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  0.  6.  3.] 
cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  3.  0.  0.  0.  3.  6.  8.  6.  0.  0.
  3.  6.  4. 10.  0.  0.  0.  0.  0.  6.  0. 16.  0.  0. 15.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10  6  3  6  8  4  6  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 29. 30. 26. 29.  8.  2.  9.  6.  8.  5.  1.  9. 10.  1. 10.  9.] 
adversary cards in hand: [29. 25. 29. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25] -> size -> 35 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29. 25. 29. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29. 10. 29.] 
expected returns: [[52.362732]
 [54.631073]
 [56.049316]
 [54.631073]
 [51.419266]
 [54.631073]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 29. 10. 29.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 26. 29.  8.  2.  9.  6.  8.  5.  1.  9. 10.  1. 10.  9.] 
adversary cards in hand: [6. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10  6  3  6  8  4  6  0] -> size -> 39 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 77.48945617675781



action possibilites: [-1] 
expected returns: [[20.791828]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 10. 29. 25. 10.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 26. 29.  8.  1.  9.  6.  8.  5.  1.  9. 10.  1. 10.  9.] 
adversary cards in hand: [6. 3. 3. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10  6  3  6  8  4  6  0  6] -> size -> 40 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 56.04931640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[19.158558]
 [17.21487 ]
 [20.500422]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29. 10. 29. 25. 10.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25] -> size -> 35 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 29. 30. 26. 29.  8.  1.  9.  6.  8.  5.  1.  9. 10.  1. 10.  9.] 
adversary cards in hand: [6. 3. 3. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10  6  3  6  8  4  6  0  6] -> size -> 40 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 20.791828155517578






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [6. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 3. 0.] 
cards in discard: [6.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10  6  3  6  8  4  6  0  6] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 26. 29.  8.  1.  9.  6.  8.  5.  1.  9. 10.  1. 10.  9.] 
adversary cards in hand: [10.  0.  0. 10.  3.] 
adversary cards in discard: [25. 29. 29. 10. 29. 25. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25] -> size -> 35 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 3. 0.] 
cards in discard: [6.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10  6  3  6  8  4  6  0  6] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 29. 30. 26. 29.  8.  1.  9.  6.  8.  5.  1.  9. 10.  1. 10.  9.] 
adversary cards in hand: [10.  0.  0. 10.  3.] 
adversary cards in discard: [25. 29. 29. 10. 29. 25. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25] -> size -> 35 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 3. 0.] 
cards in discard: [6. 0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10  6  3  6  8  4  6  0  6  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 29. 30. 26. 29.  8.  1.  9.  6.  8.  5.  1.  9. 10.  1. 10.  9.] 
adversary cards in hand: [10.  0.  0. 10.  3.] 
adversary cards in discard: [25. 29. 29. 10. 29. 25. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25] -> size -> 35 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [10.  0.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[34.539787]
 [33.731888]
 [33.731888]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 10.  3.] 
cards in discard: [25. 29. 29. 10. 29. 25. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 26. 29.  8.  1.  9.  6.  8.  5.  1.  9. 10.  1. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [6. 0. 6. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10  6  3  6  8  4  6  0  6  0] -> size -> 41 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 20.500417709350586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[30.411676]
 [32.56122 ]
 [28.16035 ]
 [32.7472  ]
 [32.746727]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 10.  3.] 
cards in discard: [25. 29. 29. 10. 29. 25. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 29. 30. 26. 29.  8.  1.  9.  6.  8.  5.  1.  9. 10.  1. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [6. 0. 6. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10  6  3  6  8  4  6  0  6  0] -> size -> 41 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 34.539794921875



buy possibilites: [-1] 
expected returns: [[40.38549]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 10.  3.] 
cards in discard: [25. 29. 29. 10. 29. 25. 10.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 26. 29.  8.  1.  9.  6.  7.  5.  1.  9. 10.  1. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [6. 0. 6. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10  6  3  6  8  4  6  0  6  0] -> size -> 41 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0   0   0   0   0   0 -10   0   0  16   0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 32.74720001220703






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 8.] 
cards in discard: [6. 0. 6. 3. 3. 3. 0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0
 10  6  0  3  0  0  6 10  6  3  6  8  4  6  0  6  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 26. 29.  8.  1.  9.  6.  7.  5.  1.  9. 10.  1. 10.  9.] 
adversary cards in hand: [11.  0. 11.  0. 29.] 
adversary cards in discard: [25. 29. 29. 10. 29. 25. 10.  8. 10.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8] -> size -> 36 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [6. 0. 6. 3. 3. 3. 0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0
  3  0  0  6 10  6  3  6  8  4  6  0  6  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 26. 29.  8.  1.  9.  6.  7.  5.  1.  9. 10.  1. 10.  9.] 
adversary cards in hand: [11.  0. 11.  0. 29.] 
adversary cards in discard: [25. 29. 29. 10. 29. 25. 10.  8. 10.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8] -> size -> 36 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [6. 0. 6. 3. 3. 3. 0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0
  3  0  0  6 10  6  3  6  8  4  6  0  6  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 29. 30. 26. 29.  8.  1.  9.  6.  7.  5.  1.  9. 10.  1. 10.  9.] 
adversary cards in hand: [11.  0. 11.  0. 29.] 
adversary cards in discard: [25. 29. 29. 10. 29. 25. 10.  8. 10.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8] -> size -> 36 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [6. 0. 6. 3. 3. 3. 0. 0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0
  3  0  0  6 10  6  3  6  8  4  6  0  6  0  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 29. 30. 26. 29.  8.  1.  9.  6.  7.  5.  1.  9. 10.  1. 10.  9.] 
adversary cards in hand: [11.  0. 11.  0. 29.] 
adversary cards in discard: [25. 29. 29. 10. 29. 25. 10.  8. 10.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8] -> size -> 36 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [11.  0. 11.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 29.] 
expected returns: [[71.482124]
 [74.983765]
 [74.983765]
 [76.50646 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11.  0. 29.] 
cards in discard: [25. 29. 29. 10. 29. 25. 10.  8. 10.  0.  0. 10.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 26. 29.  8.  1.  9.  6.  7.  5.  1.  9. 10.  1. 10.  9.] 
adversary cards in hand: [0. 6. 0. 6. 6.] 
adversary cards in discard: [6. 0. 6. 3. 3. 3. 0. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0
  3  0  0  6 10  6  3  6  8  4  6  0  6  0  0] -> size -> 39 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 40.38549041748047



action possibilites: [-1. 11. 11. 29.] 
expected returns: [[74.629036]
 [77.50245 ]
 [77.50245 ]
 [79.07606 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11.  0. 29.] 
cards in discard: [25. 29. 29. 10. 29. 25. 10.  8. 10.  0.  0. 10.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 29. 30. 26. 29.  8.  1.  9.  6.  7.  5.  1.  9. 10.  1. 10.  9.] 
adversary cards in hand: [0. 6. 0. 6. 6.] 
adversary cards in discard: [6. 0. 6. 3. 3. 3. 0. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0
  3  0  0  6 10  6  3  6  8  4  6  0  6  0  0] -> size -> 39 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 76.5064697265625



action possibilites: [-1. 11. 11.] 
expected returns: [[114.35203]
 [117.69665]
 [117.69665]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11.  0.  0.] 
cards in discard: [25. 29. 29. 10. 29. 25. 10.  8. 10.  0.  0. 10.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 2 
card supply: [18. 29. 30. 26. 29.  8.  1.  9.  6.  7.  5.  1.  9. 10.  1. 10.  9.] 
adversary cards in hand: [0. 6. 0. 6. 6.] 
adversary cards in discard: [6. 0. 6. 3. 3. 3. 0. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0
  3  0  0  6 10  6  3  6  8  4  6  0  6  0  0] -> size -> 39 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 79.07606506347656



action possibilites: [-1] 
expected returns: [[186.81259]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [25. 29. 29. 10. 29. 25. 10.  8. 10.  0.  0. 10.  3. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 29. 30. 26. 29.  8.  1.  9.  6.  7.  5.  1.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 6. 0. 6. 6.] 
adversary cards in discard: [6. 0. 6. 3. 3. 3. 0. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0
  3  0  0  6 10  6  3  6  8  4  6  0  6  0  0] -> size -> 39 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  60   0   0   0   0 -20   0   0  27   0] 
sum of rewards: 122 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 119.11844635009766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[182.83255]
 [188.35233]
 [186.86932]
 [179.73459]
 [178.27512]
 [186.01848]
 [191.36302]
 [187.2578 ]
 [197.60814]
 [193.14113]
 [182.67683]
 [186.95737]
 [181.43756]
 [188.19661]
 [187.3217 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [25. 29. 29. 10. 29. 25. 10.  8. 10.  0.  0. 10.  3. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10] -> size -> 37 
action values: 0 
buys: 1 
player value: 5 
card supply: [18. 29. 30. 26. 29.  8.  1.  9.  6.  7.  5.  1.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 6. 0. 6. 6.] 
adversary cards in discard: [6. 0. 6. 3. 3. 3. 0. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0
  3  0  0  6 10  6  3  6  8  4  6  0  6  0  0] -> size -> 39 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action -1
Learning step: 0
desired expected reward: 186.81259155273438



buy possibilites: [-1] 
expected returns: [[161.36885]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [25. 29. 29. 10. 29. 25. 10.  8. 10.  0.  0. 10.  3. 10. 25.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 26. 29.  8.  1.  9.  6.  7.  4.  1.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 6. 0. 6. 6.] 
adversary cards in discard: [6. 0. 6. 3. 3. 3. 0. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0
  3  0  0  6 10  6  3  6  8  4  6  0  6  0  0] -> size -> 39 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  60   0   0   0   0 -30   0   0 250   0] 
sum of rewards: 335 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 197.60812377929688






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [0. 6. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 6. 6.] 
cards in discard: [6. 0. 6. 3. 3. 3. 0. 0. 8. 0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0
  3  0  0  6 10  6  3  6  8  4  6  0  6  0  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 26. 29.  8.  1.  9.  6.  7.  4.  1.  9. 10.  0. 10.  9.] 
adversary cards in hand: [29.  8. 10.  3. 11.] 
adversary cards in discard: [25. 29. 29. 10. 29. 25. 10.  8. 10.  0.  0. 10.  3. 10. 25. 29. 29. 11.
  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25] -> size -> 38 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6. 6.] 
cards in discard: [6. 0. 6. 3. 3. 3. 0. 0. 8. 0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0
  3  0  0  6 10  6  3  6  8  4  6  0  6  0  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 29. 30. 26. 29.  8.  1.  9.  6.  7.  4.  1.  9. 10.  0. 10.  9.] 
adversary cards in hand: [29.  8. 10.  3. 11.] 
adversary cards in discard: [25. 29. 29. 10. 29. 25. 10.  8. 10.  0.  0. 10.  3. 10. 25. 29. 29. 11.
  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25] -> size -> 38 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6. 6.] 
cards in discard: [6. 0. 6. 3. 3. 3. 0. 0. 8. 0. 3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0
  3  0  0  6 10  6  3  6  8  4  6  0  6  0  0  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 25. 29.  8.  1.  9.  6.  7.  4.  1.  9. 10.  0. 10.  9.] 
adversary cards in hand: [29.  8. 10.  3. 11.] 
adversary cards in discard: [25. 29. 29. 10. 29. 25. 10.  8. 10.  0.  0. 10.  3. 10. 25. 29. 29. 11.
  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25] -> size -> 38 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [29.  8. 10.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 10. 11.] 
expected returns: [[55.585495]
 [57.479515]
 [53.072746]
 [52.35549 ]
 [56.034622]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8. 10.  3. 11.] 
cards in discard: [25. 29. 29. 10. 29. 25. 10.  8. 10.  0.  0. 10.  3. 10. 25. 29. 29. 11.
  0. 11.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 25. 29.  8.  1.  9.  6.  7.  4.  1.  9. 10.  0. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 4.] 
adversary cards in discard: [6. 0. 6. 3. 3. 3. 0. 0. 8. 0. 3. 0. 6. 0. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0
  3  0  0  6 10  6  3  6  8  4  6  0  6  0  0  3] -> size -> 40 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 161.3688507080078



action possibilites: [-1. 10. 11.] 
expected returns: [[69.89196 ]
 [67.560005]
 [72.18897 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 11.  0.] 
cards in discard: [25. 29. 29. 10. 29. 25. 10.  8. 10.  0.  0. 10.  3. 10. 25. 29. 29. 11.
  0. 11.  0.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 29. 30. 25. 29.  8.  1.  9.  6.  7.  4.  1.  9. 10.  0. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 4.] 
adversary cards in discard: [6. 0. 6. 3. 3. 3. 0. 0. 8. 0. 3. 0. 6. 0. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0
  3  0  0  6 10  6  3  6  8  4  6  0  6  0  0  3] -> size -> 40 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 53.9542236328125



action possibilites: [-1] 
expected returns: [[26.006842]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.] 
cards in discard: [25. 29. 29. 10. 29. 25. 10.  8. 10.  0.  0. 10.  3. 10. 25. 29. 29. 11.
  0. 11.  0.  0.  8. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 29. 30. 25. 29.  8.  1.  9.  6.  7.  4.  1.  9. 10.  0. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 4.] 
adversary cards in discard: [6. 0. 6. 3. 3. 3. 0. 0. 8. 0. 3. 0. 6. 0. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0
  3  0  0  6 10  6  3  6  8  4  6  0  6  0  0  3] -> size -> 40 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  40   0   0   0   0 -40   0   0  64   0] 
sum of rewards: 89 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 73.38716888427734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[20.525423]
 [23.424835]
 [17.555346]
 [23.592314]
 [25.01054 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.] 
cards in discard: [25. 29. 29. 10. 29. 25. 10.  8. 10.  0.  0. 10.  3. 10. 25. 29. 29. 11.
  0. 11.  0.  0.  8. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 29. 30. 25. 29.  8.  1.  9.  6.  7.  4.  1.  9. 10.  0. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 4.] 
adversary cards in discard: [6. 0. 6. 3. 3. 3. 0. 0. 8. 0. 3. 0. 6. 0. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0
  3  0  0  6 10  6  3  6  8  4  6  0  6  0  0  3] -> size -> 40 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 26.0068416595459






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 4.] 
cards in discard: [6. 0. 6. 3. 3. 3. 0. 0. 8. 0. 3. 0. 6. 0. 6. 6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0
  3  0  0  6 10  6  3  6  8  4  6  0  6  0  0  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 25. 29.  8.  1.  9.  6.  7.  4.  1.  9. 10.  0. 10.  8.] 
adversary cards in hand: [10. 25.  0. 29. 29.] 
adversary cards in discard: [25. 29. 29. 10. 29. 25. 10.  8. 10.  0.  0. 10.  3. 10. 25. 29. 29. 11.
  0. 11.  0.  0.  8. 15. 29. 11. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15] -> size -> 39 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 4.] 
cards in discard: [6. 0. 6. 3. 3. 3. 0. 0. 8. 0. 3. 0. 6. 0. 6. 6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0
  3  0  0  6 10  6  3  6  8  4  6  0  6  0  0  3] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 29. 30. 25. 29.  8.  1.  9.  6.  7.  4.  1.  9. 10.  0. 10.  8.] 
adversary cards in hand: [10. 25.  0. 29. 29.] 
adversary cards in discard: [25. 29. 29. 10. 29. 25. 10.  8. 10.  0.  0. 10.  3. 10. 25. 29. 29. 11.
  0. 11.  0.  0.  8. 15. 29. 11. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15] -> size -> 39 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 4.] 
cards in discard: [6. 0. 6. 3. 3. 3. 0. 0. 8. 0. 3. 0. 6. 0. 6. 6. 1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0
  3  0  0  6 10  6  3  6  8  4  6  0  6  0  0  3  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 25. 29.  8.  1.  9.  6.  7.  4.  1.  9. 10.  0. 10.  8.] 
adversary cards in hand: [10. 25.  0. 29. 29.] 
adversary cards in discard: [25. 29. 29. 10. 29. 25. 10.  8. 10.  0.  0. 10.  3. 10. 25. 29. 29. 11.
  0. 11.  0.  0.  8. 15. 29. 11. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15] -> size -> 39 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [10. 25.  0. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 29. 29.] 
expected returns: [[68.89395 ]
 [67.867744]
 [77.57612 ]
 [74.41706 ]
 [74.41706 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25.  0. 29. 29.] 
cards in discard: [25. 29. 29. 10. 29. 25. 10.  8. 10.  0.  0. 10.  3. 10. 25. 29. 29. 11.
  0. 11.  0.  0.  8. 15. 29. 11. 10.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 25. 29.  8.  1.  9.  6.  7.  4.  1.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 6. 10. 11.  6.  0.] 
adversary cards in discard: [6. 0. 6. 3. 3. 3. 0. 0. 8. 0. 3. 0. 6. 0. 6. 6. 1. 3. 0. 0. 0. 4.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0
  3  0  0  6 10  6  3  6  8  4  6  0  6  0  0  3  1] -> size -> 41 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 25.010541915893555



action possibilites: [-1] 
expected returns: [[152.66937]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29. 29.  3. 10.] 
cards in discard: [25. 29. 29. 10. 29. 25. 10.  8. 10.  0.  0. 10.  3. 10. 25. 29. 29. 11.
  0. 11.  0.  0.  8. 15. 29. 11. 10.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 25. 29.  8.  0.  9.  6.  7.  4.  1.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 6. 10. 11.  6.  0.] 
adversary cards in discard: [6. 0. 6. 3. 3. 3. 0. 0. 8. 0. 3. 0. 6. 0. 6. 6. 1. 3. 0. 0. 0. 4. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0
  3  0  0  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6] -> size -> 42 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 77.57613372802734





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[148.41525]
 [152.66937]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 29. 29.  3. 10.] 
cards in discard: [25. 29. 29. 10. 29. 25. 10.  8. 10.  0.  0. 10.  3. 10. 25. 29. 29. 11.
  0. 11.  0.  0.  8. 15. 29. 11. 10.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 28. 30. 25. 29.  8.  0.  9.  6.  7.  4.  1.  9. 10.  0. 10.  8.] 
adversary cards in hand: [ 6. 10. 11.  6.  0.] 
adversary cards in discard: [6. 0. 6. 3. 3. 3. 0. 0. 8. 0. 3. 0. 6. 0. 6. 6. 1. 3. 0. 0. 0. 4. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0
  3  0  0  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6] -> size -> 42 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 152.66937255859375






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 6. 10. 11.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10. 11.  6.  0.] 
cards in discard: [6. 0. 6. 3. 3. 3. 0. 0. 8. 0. 3. 0. 6. 0. 6. 6. 1. 3. 0. 0. 0. 4. 6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0
  3  0  0  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 25. 29.  8.  0.  9.  6.  7.  4.  1.  9. 10.  0. 10.  8.] 
adversary cards in hand: [25.  0. 25. 25. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15] -> size -> 39 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  6.  0.] 
cards in discard: [ 6.  0.  6.  3.  3.  3.  0.  0.  8.  0.  3.  0.  6.  0.  6.  6.  1.  3.
  0.  0.  0.  4.  6. 14.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0
  3  0  0  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 25. 29.  8.  0.  9.  6.  7.  4.  1.  8. 10.  0. 10.  8.] 
adversary cards in hand: [25.  0. 25. 25. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15] -> size -> 39 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  6.  0.] 
cards in discard: [ 6.  0.  6.  3.  3.  3.  0.  0.  8.  0.  3.  0.  6.  0.  6.  6.  1.  3.
  0.  0.  0.  4.  6. 14.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0
  3  0  0  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 28. 30. 25. 29.  8.  0.  9.  6.  7.  4.  1.  8. 10.  0. 10.  8.] 
adversary cards in hand: [25.  0. 25. 25. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15] -> size -> 39 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  6.  0.] 
cards in discard: [ 6.  0.  6.  3.  3.  3.  0.  0.  8.  0.  3.  0.  6.  0.  6.  6.  1.  3.
  0.  0.  0.  4.  6. 14.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0
  3  0  0  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 28. 30. 25. 29.  8.  0.  9.  6.  7.  4.  1.  8. 10.  0. 10.  8.] 
adversary cards in hand: [25.  0. 25. 25. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15] -> size -> 39 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [25.  0. 25. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 25. 29.] 
expected returns: [[108.50632]
 [111.96153]
 [111.96153]
 [111.96153]
 [110.34489]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 25. 25. 29.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 25. 29.  8.  0.  9.  6.  7.  4.  1.  8. 10.  0. 10.  8.] 
adversary cards in hand: [10.  0.  0. 15.  0.] 
adversary cards in discard: [ 6.  0.  6.  3.  3.  3.  0.  0.  8.  0.  3.  0.  6.  0.  6.  6.  1.  3.
  0.  0.  0.  4.  6. 14.  0. 11.  6. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0
  3  0  0  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0] -> size -> 44 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 152.66937255859375



action possibilites: [-1] 
expected returns: [[87.34123]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 25. 29. 10.  8.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 25. 29.  8.  0.  9.  6.  7.  4.  1.  8. 10.  0. 10.  8.] 
adversary cards in hand: [10.  0.  0. 15.  0.] 
adversary cards in discard: [ 6.  0.  6.  3.  3.  3.  0.  0.  8.  0.  3.  0.  6.  0.  6.  6.  1.  3.
  0.  0.  0.  4.  6. 14.  0. 11.  6. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0
  3  0  0  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0] -> size -> 44 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 111.9615249633789





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[80.524216]
 [84.93585 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25. 25. 29. 10.  8.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 28. 30. 25. 29.  8.  0.  9.  6.  7.  4.  1.  8. 10.  0. 10.  8.] 
adversary cards in hand: [10.  0.  0. 15.  0.] 
adversary cards in discard: [ 6.  0.  6.  3.  3.  3.  0.  0.  8.  0.  3.  0.  6.  0.  6.  6.  1.  3.
  0.  0.  0.  4.  6. 14.  0. 11.  6. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0
  3  0  0  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0] -> size -> 44 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 87.34123229980469






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [10.  0.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 15.  0.] 
cards in discard: [ 6.  0.  6.  3.  3.  3.  0.  0.  8.  0.  3.  0.  6.  0.  6.  6.  1.  3.
  0.  0.  0.  4.  6. 14.  0. 11.  6. 10.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0
  3  0  0  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 25. 29.  8.  0.  9.  6.  7.  4.  1.  8. 10.  0. 10.  8.] 
adversary cards in hand: [10. 29.  0. 29. 25.] 
adversary cards in discard: [25.  0. 25. 25. 29. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15] -> size -> 39 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  0.  6.] 
cards in discard: [ 6.  0.  6.  3.  3.  3.  0.  0.  8.  0.  3.  0.  6.  0.  6.  6.  1.  3.
  0.  0.  0.  4.  6. 14.  0. 11.  6. 10.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0
  3  0  0  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0] -> size -> 44 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 25. 29.  8.  0.  9.  6.  7.  4.  1.  8. 10.  0. 10.  8.] 
adversary cards in hand: [10. 29.  0. 29. 25.] 
adversary cards in discard: [25.  0. 25. 25. 29. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15] -> size -> 39 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6.] 
cards in discard: [ 6.  0.  6.  3.  3.  3.  0.  0.  8.  0.  3.  0.  6.  0.  6.  6.  1.  3.
  0.  0.  0.  4.  6. 14.  0. 11.  6. 10.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3
  0  0  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 3 
card supply: [17. 28. 30. 25. 29.  8.  0.  9.  6.  7.  4.  1.  8. 10.  0. 10.  8.] 
adversary cards in hand: [10. 29.  0. 29. 25.] 
adversary cards in discard: [25.  0. 25. 25. 29. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15] -> size -> 39 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [ 6.  0.  6.  3.  3.  3.  0.  0.  8.  0.  3.  0.  6.  0.  6.  6.  1.  3.
  0.  0.  0.  4.  6. 14.  0. 11.  6. 10.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3
  0  0  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0] -> size -> 43 
action values: 0 
buys: 1 
player value: 5 
card supply: [17. 28. 30. 25. 29.  8.  0.  9.  6.  7.  4.  1.  8. 10.  0. 10.  8.] 
adversary cards in hand: [10. 29.  0. 29. 25.] 
adversary cards in discard: [25.  0. 25. 25. 29. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15] -> size -> 39 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [ 6.  0.  6.  3.  3.  3.  0.  0.  8.  0.  3.  0.  6.  0.  6.  6.  1.  3.
  0.  0.  0.  4.  6. 14.  0. 11.  6. 10.  6.  0. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3
  0  0  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 28. 30. 25. 29.  8.  0.  9.  6.  7.  4.  1.  7. 10.  0. 10.  8.] 
adversary cards in hand: [10. 29.  0. 29. 25.] 
adversary cards in discard: [25.  0. 25. 25. 29. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15] -> size -> 39 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [10. 29.  0. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 29. 25.] 
expected returns: [[18.563831]
 [19.021036]
 [22.262337]
 [22.262337]
 [23.96531 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  0. 29. 25.] 
cards in discard: [25.  0. 25. 25. 29. 10.  8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 25. 29.  8.  0.  9.  6.  7.  4.  1.  7. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 16.  3.  0.  0.] 
adversary cards in discard: [ 6.  0.  6.  3.  3.  3.  0.  0.  8.  0.  3.  0.  6.  0.  6.  6.  1.  3.
  0.  0.  0.  4.  6. 14.  0. 11.  6. 10.  6.  0. 14. 10. 15.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3
  0  0  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14] -> size -> 44 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 84.93585968017578



action possibilites: [-1] 
expected returns: [[37.53106]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  0. 29.  3. 10.] 
cards in discard: [25.  0. 25. 25. 29. 10.  8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 25. 29.  8.  0.  9.  6.  7.  4.  1.  7. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 16.  3.  0.  0.] 
adversary cards in discard: [ 6.  0.  6.  3.  3.  3.  0.  0.  8.  0.  3.  0.  6.  0.  6.  6.  1.  3.
  0.  0.  0.  4.  6. 14.  0. 11.  6. 10.  6.  0. 14. 10. 15.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3
  0  0  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14] -> size -> 44 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 23.96531105041504





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[36.476105]
 [37.737595]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29.  0. 29.  3. 10.] 
cards in discard: [25.  0. 25. 25. 29. 10.  8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 28. 30. 25. 29.  8.  0.  9.  6.  7.  4.  1.  7. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 16.  3.  0.  0.] 
adversary cards in discard: [ 6.  0.  6.  3.  3.  3.  0.  0.  8.  0.  3.  0.  6.  0.  6.  6.  1.  3.
  0.  0.  0.  4.  6. 14.  0. 11.  6. 10.  6.  0. 14. 10. 15.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3
  0  0  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14] -> size -> 44 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 37.53105926513672






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 0. 16.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  3.  0.  0.] 
cards in discard: [ 6.  0.  6.  3.  3.  3.  0.  0.  8.  0.  3.  0.  6.  0.  6.  6.  1.  3.
  0.  0.  0.  4.  6. 14.  0. 11.  6. 10.  6.  0. 14. 10. 15.  0.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3
  0  0  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 25. 29.  8.  0.  9.  6.  7.  4.  1.  7. 10.  0. 10.  8.] 
adversary cards in hand: [10.  0. 11. 10.  0.] 
adversary cards in discard: [25.  0. 25. 25. 29. 10.  8. 25. 10. 29.  0. 29.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15] -> size -> 39 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  3.  0.  0.] 
cards in discard: [ 6.  0.  6.  3.  3.  3.  0.  0.  8.  0.  3.  0.  6.  0.  6.  6.  1.  3.
  0.  0.  0.  4.  6. 14.  0. 11.  6. 10.  6.  0. 14. 10. 15.  0.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3
  0  0  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14] -> size -> 44 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 28. 30. 25. 29.  8.  0.  9.  6.  7.  4.  1.  7. 10.  0. 10.  8.] 
adversary cards in hand: [10.  0. 11. 10.  0.] 
adversary cards in discard: [25.  0. 25. 25. 29. 10.  8. 25. 10. 29.  0. 29.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15] -> size -> 39 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  3.  0.  0.] 
cards in discard: [ 6.  0.  6.  3.  3.  3.  0.  0.  8.  0.  3.  0.  6.  0.  6.  6.  1.  3.
  0.  0.  0.  4.  6. 14.  0. 11.  6. 10.  6.  0. 14. 10. 15.  0.  0.  6.
  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3
  0  0  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 25. 29.  8.  0.  9.  6.  7.  4.  1.  7. 10.  0. 10.  8.] 
adversary cards in hand: [10.  0. 11. 10.  0.] 
adversary cards in discard: [25.  0. 25. 25. 29. 10.  8. 25. 10. 29.  0. 29.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15] -> size -> 39 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [10.  0. 11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.] 
expected returns: [[110.63859 ]
 [108.843796]
 [113.858315]
 [108.843796]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11. 10.  0.] 
cards in discard: [25.  0. 25. 25. 29. 10.  8. 25. 10. 29.  0. 29.  3. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 25. 29.  8.  0.  9.  6.  7.  4.  1.  7. 10.  0. 10.  8.] 
adversary cards in hand: [10.  0.  1.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3
  0  0  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1] -> size -> 45 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 37.73760986328125



action possibilites: [-1] 
expected returns: [[160.59412]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  0.] 
cards in discard: [25.  0. 25. 25. 29. 10.  8. 25. 10. 29.  0. 29.  3. 10.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 25. 29.  8.  0.  9.  6.  7.  4.  1.  7. 10.  0. 10.  8.] 
adversary cards in hand: [10.  0.  1.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3
  0  0  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1] -> size -> 45 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0 -50   0   0  27   0] 
sum of rewards: 52 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 111.19068145751953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[156.077  ]
 [160.36417]
 [160.80667]
 [160.58585]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  0.] 
cards in discard: [25.  0. 25. 25. 29. 10.  8. 25. 10. 29.  0. 29.  3. 10.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 26. 30. 25. 29.  8.  0.  9.  6.  7.  4.  1.  7. 10.  0. 10.  8.] 
adversary cards in hand: [10.  0.  1.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3
  0  0  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1] -> size -> 45 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 160.5941162109375



buy possibilites: [-1] 
expected returns: [[35.172806]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  0.] 
cards in discard: [25.  0. 25. 25. 29. 10.  8. 25. 10. 29.  0. 29.  3. 10.  1.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 25. 29.  8.  0.  9.  6.  6.  4.  1.  7. 10.  0. 10.  8.] 
adversary cards in hand: [10.  0.  1.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3
  0  0  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1] -> size -> 45 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0 -60   0   0  16   0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 160.80665588378906






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [10.  0.  1.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  1.  0.  3.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3
  0  0  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 25. 29.  8.  0.  9.  6.  6.  4.  1.  7. 10.  0. 10.  8.] 
adversary cards in hand: [29.  3. 25.  3. 15.] 
adversary cards in discard: [25.  0. 25. 25. 29. 10.  8. 25. 10. 29.  0. 29.  3. 10.  1.  8. 11. 10.
  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8] -> size -> 41 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 3. 8.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3
  0  0  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1] -> size -> 45 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 25. 29.  8.  0.  9.  6.  6.  4.  1.  7. 10.  0. 10.  8.] 
adversary cards in hand: [29.  3. 25.  3. 15.] 
adversary cards in discard: [25.  0. 25. 25. 29. 10.  8. 25. 10. 29.  0. 29.  3. 10.  1.  8. 11. 10.
  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8] -> size -> 41 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 25. 29.  8.  0.  9.  6.  6.  4.  1.  7. 10.  0. 10.  8.] 
adversary cards in hand: [29.  3. 25.  3. 15.] 
adversary cards in discard: [25.  0. 25. 25. 29. 10.  8. 25. 10. 29.  0. 29.  3. 10.  1.  8. 11. 10.
  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8] -> size -> 41 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 26. 30. 25. 29.  8.  0.  9.  6.  6.  4.  1.  7. 10.  0. 10.  8.] 
adversary cards in hand: [29.  3. 25.  3. 15.] 
adversary cards in discard: [25.  0. 25. 25. 29. 10.  8. 25. 10. 29.  0. 29.  3. 10.  1.  8. 11. 10.
  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8] -> size -> 41 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [29.  3. 25.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 15.] 
expected returns: [[102.30949]
 [104.27944]
 [106.05273]
 [101.13161]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 25.  3. 15.] 
cards in discard: [25.  0. 25. 25. 29. 10.  8. 25. 10. 29.  0. 29.  3. 10.  1.  8. 11. 10.
  0. 10.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 25. 29.  8.  0.  9.  6.  6.  4.  1.  7. 10.  0. 10.  8.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [10.  8.  1.  3.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1] -> size -> 43 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 35.17280578613281



action possibilites: [-1] 
expected returns: [[10.656601]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  3. 15.  0.  0.] 
cards in discard: [25.  0. 25. 25. 29. 10.  8. 25. 10. 29.  0. 29.  3. 10.  1.  8. 11. 10.
  0. 10.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 25. 29.  8.  0.  9.  6.  6.  4.  1.  7. 10.  0. 10.  8.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [10.  8.  1.  3.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1] -> size -> 43 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 106.05274200439453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[5.950841]
 [8.101964]
 [8.13493 ]
 [9.540182]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  3. 15.  0.  0.] 
cards in discard: [25.  0. 25. 25. 29. 10.  8. 25. 10. 29.  0. 29.  3. 10.  1.  8. 11. 10.
  0. 10.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 26. 30. 25. 29.  8.  0.  9.  6.  6.  4.  1.  7. 10.  0. 10.  8.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [10.  8.  1.  3.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1] -> size -> 43 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 10.656600952148438






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [6. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [10.  8.  1.  3.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 25. 29.  8.  0.  9.  6.  6.  4.  1.  7. 10.  0. 10.  8.] 
adversary cards in hand: [ 8. 10. 29. 10. 29.] 
adversary cards in discard: [25.  0. 25. 25. 29. 10.  8. 25. 10. 29.  0. 29.  3. 10.  1.  8. 11. 10.
  0. 10.  0. 25. 29.  3.  3. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8] -> size -> 41 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [10.  8.  1.  3.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1] -> size -> 43 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 26. 30. 25. 29.  8.  0.  9.  6.  6.  4.  1.  7. 10.  0. 10.  8.] 
adversary cards in hand: [ 8. 10. 29. 10. 29.] 
adversary cards in discard: [25.  0. 25. 25. 29. 10.  8. 25. 10. 29.  0. 29.  3. 10.  1.  8. 11. 10.
  0. 10.  0. 25. 29.  3.  3. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8] -> size -> 41 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [10.  8.  1.  3. 11.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 25. 29.  8.  0.  9.  5.  6.  4.  1.  7. 10.  0. 10.  8.] 
adversary cards in hand: [ 8. 10. 29. 10. 29.] 
adversary cards in discard: [25.  0. 25. 25. 29. 10.  8. 25. 10. 29.  0. 29.  3. 10.  1.  8. 11. 10.
  0. 10.  0. 25. 29.  3.  3. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8] -> size -> 41 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 8. 10. 29. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 29. 10. 29.] 
expected returns: [[39.02442 ]
 [38.0213  ]
 [37.363297]
 [40.861168]
 [37.363297]
 [40.861168]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 29. 10. 29.] 
cards in discard: [25.  0. 25. 25. 29. 10.  8. 25. 10. 29.  0. 29.  3. 10.  1.  8. 11. 10.
  0. 10.  0. 25. 29.  3.  3. 15.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 25. 29.  8.  0.  9.  5.  6.  4.  1.  7. 10.  0. 10.  8.] 
adversary cards in hand: [ 6. 14.  0.  3.  0.] 
adversary cards in discard: [10.  8.  1.  3. 11.  6.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11] -> size -> 44 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 9.540184020996094



action possibilites: [-1.  8. 10. 10.] 
expected returns: [[81.64843]
 [80.24795]
 [78.97507]
 [78.97507]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 10.] 
cards in discard: [25.  0. 25. 25. 29. 10.  8. 25. 10. 29.  0. 29.  3. 10.  1.  8. 11. 10.
  0. 10.  0. 25. 29.  3.  3. 15.  0.  0. 29. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 26. 30. 25. 29.  8.  0.  9.  5.  6.  4.  1.  7. 10.  0. 10.  8.] 
adversary cards in hand: [ 6. 14.  0.  3.  0.] 
adversary cards in discard: [10.  8.  1.  3. 11.  6.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11] -> size -> 44 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 38.613548278808594





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[76.6168 ]
 [81.64843]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 10.] 
cards in discard: [25.  0. 25. 25. 29. 10.  8. 25. 10. 29.  0. 29.  3. 10.  1.  8. 11. 10.
  0. 10.  0. 25. 29.  3.  3. 15.  0.  0. 29. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8] -> size -> 41 
action values: 1 
buys: 1 
player value: 1 
card supply: [17. 26. 30. 25. 29.  8.  0.  9.  5.  6.  4.  1.  7. 10.  0. 10.  8.] 
adversary cards in hand: [ 6. 14.  0.  3.  0.] 
adversary cards in discard: [10.  8.  1.  3. 11.  6.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11] -> size -> 44 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 81.64842987060547






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [ 6. 14.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.  0.  3.  0.] 
cards in discard: [10.  8.  1.  3. 11.  6.  0.  3.  0.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 25. 29.  8.  0.  9.  5.  6.  4.  1.  7. 10.  0. 10.  8.] 
adversary cards in hand: [25.  0. 10. 11. 29.] 
adversary cards in discard: [25.  0. 25. 25. 29. 10.  8. 25. 10. 29.  0. 29.  3. 10.  1.  8. 11. 10.
  0. 10.  0. 25. 29.  3.  3. 15.  0.  0. 29. 29. 29.  8. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8] -> size -> 41 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.  0.  3.  0.] 
cards in discard: [10.  8.  1.  3. 11.  6.  0.  3.  0.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 26. 30. 25. 29.  8.  0.  9.  5.  6.  4.  1.  7. 10.  0. 10.  8.] 
adversary cards in hand: [25.  0. 10. 11. 29.] 
adversary cards in discard: [25.  0. 25. 25. 29. 10.  8. 25. 10. 29.  0. 29.  3. 10.  1.  8. 11. 10.
  0. 10.  0. 25. 29.  3.  3. 15.  0.  0. 29. 29. 29.  8. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8] -> size -> 41 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.  0.  3.  0.] 
cards in discard: [10.  8.  1.  3. 11.  6.  0.  3.  0.  0.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 26. 30. 25. 29.  8.  0.  9.  5.  6.  4.  1.  7. 10.  0. 10.  8.] 
adversary cards in hand: [25.  0. 10. 11. 29.] 
adversary cards in discard: [25.  0. 25. 25. 29. 10.  8. 25. 10. 29.  0. 29.  3. 10.  1.  8. 11. 10.
  0. 10.  0. 25. 29.  3.  3. 15.  0.  0. 29. 29. 29.  8. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8] -> size -> 41 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [25.  0. 10. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 11. 29.] 
expected returns: [[58.24341 ]
 [64.78746 ]
 [56.9254  ]
 [61.154312]
 [62.38054 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 10. 11. 29.] 
cards in discard: [25.  0. 25. 25. 29. 10.  8. 25. 10. 29.  0. 29.  3. 10.  1.  8. 11. 10.
  0. 10.  0. 25. 29.  3.  3. 15.  0.  0. 29. 29. 29.  8. 10. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 25. 29.  8.  0.  9.  5.  6.  4.  1.  7. 10.  0. 10.  8.] 
adversary cards in hand: [10.  3.  6.  4. 11.] 
adversary cards in discard: [10.  8.  1.  3. 11.  6.  0.  3.  0.  0.  0.  6. 14.  0.  3.  0.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0] -> size -> 45 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 81.64842987060547



action possibilites: [-1] 
expected returns: [[46.959656]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 29. 29. 11.] 
cards in discard: [25.  0. 25. 25. 29. 10.  8. 25. 10. 29.  0. 29.  3. 10.  1.  8. 11. 10.
  0. 10.  0. 25. 29.  3.  3. 15.  0.  0. 29. 29. 29.  8. 10. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 25. 29.  8.  0.  9.  5.  6.  4.  1.  7. 10.  0. 10.  8.] 
adversary cards in hand: [10.  3.  6.  4. 11.] 
adversary cards in discard: [10.  8.  1.  3. 11.  6.  0.  3.  0.  0.  0.  6. 14.  0.  3.  0.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0] -> size -> 45 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 64.7874526977539





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[45.34723]
 [46.95964]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11. 29. 29. 11.] 
cards in discard: [25.  0. 25. 25. 29. 10.  8. 25. 10. 29.  0. 29.  3. 10.  1.  8. 11. 10.
  0. 10.  0. 25. 29.  3.  3. 15.  0.  0. 29. 29. 29.  8. 10. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 26. 30. 25. 29.  8.  0.  9.  5.  6.  4.  1.  7. 10.  0. 10.  8.] 
adversary cards in hand: [10.  3.  6.  4. 11.] 
adversary cards in discard: [10.  8.  1.  3. 11.  6.  0.  3.  0.  0.  0.  6. 14.  0.  3.  0.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0] -> size -> 45 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 46.95965576171875






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [10.  3.  6.  4. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  6.  4. 11.] 
cards in discard: [10.  8.  1.  3. 11.  6.  0.  3.  0.  0.  0.  6. 14.  0.  3.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 25. 29.  8.  0.  9.  5.  6.  4.  1.  7. 10.  0. 10.  8.] 
adversary cards in hand: [29. 25. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8] -> size -> 41 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  6.  4.] 
cards in discard: [10.  8.  1.  3. 11.  6.  0.  3.  0.  0.  0.  6. 14.  0.  3.  0. 14.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 25. 29.  8.  0.  9.  5.  6.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [29. 25. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8] -> size -> 41 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  6.  4.] 
cards in discard: [10.  8.  1.  3. 11.  6.  0.  3.  0.  0.  0.  6. 14.  0.  3.  0. 14.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14] -> size -> 46 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 26. 30. 25. 29.  8.  0.  9.  5.  6.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [29. 25. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8] -> size -> 41 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [29. 25. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 11.] 
expected returns: [[10.009021]
 [11.069172]
 [12.685926]
 [ 9.866732]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 25. 29.  8.  0.  9.  5.  6.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [6. 6. 0. 6. 0.] 
adversary cards in discard: [10.  8.  1.  3. 11.  6.  0.  3.  0.  0.  0.  6. 14.  0.  3.  0. 14. 11.
 10.  3.  6.  4.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14] -> size -> 46 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 46.95965576171875



action possibilites: [-1] 
expected returns: [[-5.11786]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  0.  3. 10.  0.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 25. 29.  8.  0.  9.  5.  6.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [6. 6. 0. 6. 0.] 
adversary cards in discard: [10.  8.  1.  3. 11.  6.  0.  3.  0.  0.  0.  6. 14.  0.  3.  0. 14. 11.
 10.  3.  6.  4.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14] -> size -> 46 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 12.685935974121094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-5.901119 ]
 [-5.5503416]
 [-5.5980263]
 [-4.9408417]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11.  0.  3. 10.  0.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 26. 30. 25. 29.  8.  0.  9.  5.  6.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [6. 6. 0. 6. 0.] 
adversary cards in discard: [10.  8.  1.  3. 11.  6.  0.  3.  0.  0.  0.  6. 14.  0.  3.  0. 14. 11.
 10.  3.  6.  4.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14] -> size -> 46 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: -5.117859840393066






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [6. 6. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 6. 0.] 
cards in discard: [10.  8.  1.  3. 11.  6.  0.  3.  0.  0.  0.  6. 14.  0.  3.  0. 14. 11.
 10.  3.  6.  4.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 25. 29.  8.  0.  9.  5.  6.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [ 8.  3. 25. 11.  3.] 
adversary cards in discard: [25. 29. 11.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8] -> size -> 41 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 6. 0.] 
cards in discard: [10.  8.  1.  3. 11.  6.  0.  3.  0.  0.  0.  6. 14.  0.  3.  0. 14. 11.
 10.  3.  6.  4.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 26. 30. 25. 29.  8.  0.  9.  5.  6.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [ 8.  3. 25. 11.  3.] 
adversary cards in discard: [25. 29. 11.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8] -> size -> 41 
adversary victory points: 3
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 8.  3. 25. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 11.] 
expected returns: [[22.121527]
 [23.02834 ]
 [24.230888]
 [23.48729 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 25. 11.  3.] 
cards in discard: [25. 29. 11.  0.  3. 10.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 25. 29.  8.  0.  9.  5.  6.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [ 1.  1.  0. 16.  0.] 
adversary cards in discard: [10.  8.  1.  3. 11.  6.  0.  3.  0.  0.  0.  6. 14.  0.  3.  0. 14. 11.
 10.  3.  6.  4.  6.  6.  0.  6.  0.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14] -> size -> 46 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -4.940831184387207



action possibilites: [-1] 
expected returns: [[54.286354]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 11.  3. 29. 10.] 
cards in discard: [25. 29. 11.  0.  3. 10.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 25. 29.  8.  0.  9.  5.  6.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [ 1.  1.  0. 16.  0.] 
adversary cards in discard: [10.  8.  1.  3. 11.  6.  0.  3.  0.  0.  0.  6. 14.  0.  3.  0. 14. 11.
 10.  3.  6.  4.  6.  6.  0.  6.  0.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14] -> size -> 46 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 24.23089027404785





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[52.429893]
 [54.806335]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 11.  3. 29. 10.] 
cards in discard: [25. 29. 11.  0.  3. 10.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8] -> size -> 41 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 26. 30. 25. 29.  8.  0.  9.  5.  6.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [ 1.  1.  0. 16.  0.] 
adversary cards in discard: [10.  8.  1.  3. 11.  6.  0.  3.  0.  0.  0.  6. 14.  0.  3.  0. 14. 11.
 10.  3.  6.  4.  6.  6.  0.  6.  0.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14] -> size -> 46 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 54.286354064941406






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [ 1.  1.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1.  0. 16.  0.] 
cards in discard: [10.  8.  1.  3. 11.  6.  0.  3.  0.  0.  0.  6. 14.  0.  3.  0. 14. 11.
 10.  3.  6.  4.  6.  6.  0.  6.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 25. 29.  8.  0.  9.  5.  6.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [15.  8. 10. 29. 29.] 
adversary cards in discard: [25. 29. 11.  0.  3. 10.  0. 25.  8.  3. 11.  3. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8] -> size -> 41 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1.  0. 16.  0.] 
cards in discard: [10.  8.  1.  3. 11.  6.  0.  3.  0.  0.  0.  6. 14.  0.  3.  0. 14. 11.
 10.  3.  6.  4.  6.  6.  0.  6.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14] -> size -> 46 
action values: 0 
buys: 1 
player value: 6 
card supply: [16. 26. 30. 25. 29.  8.  0.  9.  5.  6.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [15.  8. 10. 29. 29.] 
adversary cards in discard: [25. 29. 11.  0.  3. 10.  0. 25.  8.  3. 11.  3. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8] -> size -> 41 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1.  0. 16.  0.] 
cards in discard: [10.  8.  1.  3. 11.  6.  0.  3.  0.  0.  0.  6. 14.  0.  3.  0. 14. 11.
 10.  3.  6.  4.  6.  6.  0.  6.  0.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 25. 30. 25. 29.  8.  0.  9.  5.  6.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [15.  8. 10. 29. 29.] 
adversary cards in discard: [25. 29. 11.  0.  3. 10.  0. 25.  8.  3. 11.  3. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8] -> size -> 41 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [15.  8. 10. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 10. 29. 29.] 
expected returns: [[66.164986]
 [65.73635 ]
 [64.698814]
 [63.418037]
 [70.339325]
 [70.339325]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8. 10. 29. 29.] 
cards in discard: [25. 29. 11.  0.  3. 10.  0. 25.  8.  3. 11.  3. 29. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 25. 29.  8.  0.  9.  5.  6.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [0. 3. 6. 0. 6.] 
adversary cards in discard: [10.  8.  1.  3. 11.  6.  0.  3.  0.  0.  0.  6. 14.  0.  3.  0. 14. 11.
 10.  3.  6.  4.  6.  6.  0.  6.  0.  1.  1.  1.  0. 16.  0.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1] -> size -> 47 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 54.80634307861328



action possibilites: [-1. 15. 10. 29.] 
expected returns: [[12.625708]
 [11.620434]
 [10.821791]
 [13.022934]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 29.] 
cards in discard: [25. 29. 11.  0.  3. 10.  0. 25.  8.  3. 11.  3. 29. 10.  8. 25.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 25. 30. 25. 29.  8.  0.  9.  5.  6.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [0. 3. 6. 0. 6.] 
adversary cards in discard: [10.  8.  1.  3. 11.  6.  0.  3.  0.  0.  0.  6. 14.  0.  3.  0. 14. 11.
 10.  3.  6.  4.  6.  6.  0.  6.  0.  1.  1.  1.  0. 16.  0.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1] -> size -> 47 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 70.08704376220703



action possibilites: [-1. 15.] 
expected returns: [[42.380775]
 [42.700172]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.] 
cards in discard: [25. 29. 11.  0.  3. 10.  0. 25.  8.  3. 11.  3. 29. 10.  8. 25. 10. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 2 
card supply: [16. 25. 30. 25. 29.  8.  0.  9.  5.  6.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [0. 3. 6. 0. 6.] 
adversary cards in discard: [10.  8.  1.  3. 11.  6.  0.  3.  0.  0.  0.  6. 14.  0.  3.  0. 14. 11.
 10.  3.  6.  4.  6.  6.  0.  6.  0.  1.  1.  1.  0. 16.  0.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1] -> size -> 47 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 11.58681869506836



action possibilites: [-1] 
expected returns: [[80.311966]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [25. 29. 11.  0.  3. 10.  0. 25.  8.  3. 11.  3. 29. 10.  8. 25. 10. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 29. 15.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 25. 30. 25. 29.  8.  0.  9.  5.  6.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [0. 3. 6. 0. 6.] 
adversary cards in discard: [10.  8.  1.  3. 11.  6.  0.  3.  0.  0.  0.  6. 14.  0.  3.  0. 14. 11.
 10.  3.  6.  4.  6.  6.  0.  6.  0.  1.  1.  1.  0. 16.  0.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1] -> size -> 47 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 42.70014953613281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[77.02126]
 [80.4395 ]
 [80.73806]
 [81.0796 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [25. 29. 11.  0.  3. 10.  0. 25.  8.  3. 11.  3. 29. 10.  8. 25. 10. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 29. 15.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 25. 30. 25. 29.  8.  0.  9.  5.  6.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [0. 3. 6. 0. 6.] 
adversary cards in discard: [10.  8.  1.  3. 11.  6.  0.  3.  0.  0.  0.  6. 14.  0.  3.  0. 14. 11.
 10.  3.  6.  4.  6.  6.  0.  6.  0.  1.  1.  1.  0. 16.  0.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1] -> size -> 47 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action -1
Learning step: 0
desired expected reward: 80.31196594238281






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [0. 3. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 0. 6.] 
cards in discard: [10.  8.  1.  3. 11.  6.  0.  3.  0.  0.  0.  6. 14.  0.  3.  0. 14. 11.
 10.  3.  6.  4.  6.  6.  0.  6.  0.  1.  1.  1.  0. 16.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 25. 29.  8.  0.  9.  5.  6.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [ 1. 29.  0. 29. 25.] 
adversary cards in discard: [25. 29. 11.  0.  3. 10.  0. 25.  8.  3. 11.  3. 29. 10.  8. 25. 10. 10.
 29. 29. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8] -> size -> 41 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 6.] 
cards in discard: [10.  8.  1.  3. 11.  6.  0.  3.  0.  0.  0.  6. 14.  0.  3.  0. 14. 11.
 10.  3.  6.  4.  6.  6.  0.  6.  0.  1.  1.  1.  0. 16.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 25. 30. 25. 29.  8.  0.  9.  5.  6.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [ 1. 29.  0. 29. 25.] 
adversary cards in discard: [25. 29. 11.  0.  3. 10.  0. 25.  8.  3. 11.  3. 29. 10.  8. 25. 10. 10.
 29. 29. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8] -> size -> 41 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 6.] 
cards in discard: [10.  8.  1.  3. 11.  6.  0.  3.  0.  0.  0.  6. 14.  0.  3.  0. 14. 11.
 10.  3.  6.  4.  6.  6.  0.  6.  0.  1.  1.  1.  0. 16.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 25. 29.  8.  0.  9.  5.  5.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [ 1. 29.  0. 29. 25.] 
adversary cards in discard: [25. 29. 11.  0.  3. 10.  0. 25.  8.  3. 11.  3. 29. 10.  8. 25. 10. 10.
 29. 29. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8] -> size -> 41 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 1. 29.  0. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 25.] 
expected returns: [[87.22637]
 [92.71492]
 [92.71492]
 [95.97252]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  0. 29. 25.] 
cards in discard: [25. 29. 11.  0.  3. 10.  0. 25.  8.  3. 11.  3. 29. 10.  8. 25. 10. 10.
 29. 29. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 25. 29.  8.  0.  9.  5.  5.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [14.  0.  6.  3.  3.] 
adversary cards in discard: [10.  8.  1.  3. 11.  6.  0.  3.  0.  0.  0.  6. 14.  0.  3.  0. 14. 11.
 10.  3.  6.  4.  6.  6.  0.  6.  0.  1.  1.  1.  0. 16.  0.  8.  0.  3.
  6.  0.  6.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8] -> size -> 48 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 81.07960510253906



action possibilites: [-1] 
expected returns: [[52.82363]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  0. 29. 29. 25.] 
cards in discard: [25. 29. 11.  0.  3. 10.  0. 25.  8.  3. 11.  3. 29. 10.  8. 25. 10. 10.
 29. 29. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 25. 29.  8.  0.  9.  5.  5.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [14.  0.  6.  3.  3.] 
adversary cards in discard: [10.  8.  1.  3. 11.  6.  0.  3.  0.  0.  0.  6. 14.  0.  3.  0. 14. 11.
 10.  3.  6.  4.  6.  6.  0.  6.  0.  1.  1.  1.  0. 16.  0.  8.  0.  3.
  6.  0.  6.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8] -> size -> 48 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 95.97254180908203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
expected returns: [[47.80815 ]
 [50.71219 ]
 [49.910316]
 [52.19433 ]
 [50.09217 ]
 [49.8592  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.  0. 29. 29. 25.] 
cards in discard: [25. 29. 11.  0.  3. 10.  0. 25.  8.  3. 11.  3. 29. 10.  8. 25. 10. 10.
 29. 29. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 25. 30. 25. 29.  8.  0.  9.  5.  5.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [14.  0.  6.  3.  3.] 
adversary cards in discard: [10.  8.  1.  3. 11.  6.  0.  3.  0.  0.  0.  6. 14.  0.  3.  0. 14. 11.
 10.  3.  6.  4.  6.  6.  0.  6.  0.  1.  1.  1.  0. 16.  0.  8.  0.  3.
  6.  0.  6.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8] -> size -> 48 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 52.823631286621094



buy possibilites: [-1] 
expected returns: [[54.3739]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.  0. 29. 29. 25.] 
cards in discard: [25. 29. 11.  0.  3. 10.  0. 25.  8.  3. 11.  3. 29. 10.  8. 25. 10. 10.
 29. 29. 15. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 25. 29.  8.  0.  9.  4.  5.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [14.  0.  6.  3.  3.] 
adversary cards in discard: [10.  8.  1.  3. 11.  6.  0.  3.  0.  0.  0.  6. 14.  0.  3.  0. 14. 11.
 10.  3.  6.  4.  6.  6.  0.  6.  0.  1.  1.  1.  0. 16.  0.  8.  0.  3.
  6.  0.  6.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8] -> size -> 48 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0 -70   0   0  54   0] 
sum of rewards: 59 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 52.19434356689453






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [14.  0.  6.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  6.  3.  3.] 
cards in discard: [10.  8.  1.  3. 11.  6.  0.  3.  0.  0.  0.  6. 14.  0.  3.  0. 14. 11.
 10.  3.  6.  4.  6.  6.  0.  6.  0.  1.  1.  1.  0. 16.  0.  8.  0.  3.
  6.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 25. 29.  8.  0.  9.  4.  5.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [10. 10.  0.  0.  0.] 
adversary cards in discard: [25. 29. 11.  0.  3. 10.  0. 25.  8.  3. 11.  3. 29. 10.  8. 25. 10. 10.
 29. 29. 15. 11. 25.  1. 29.  0. 29. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11] -> size -> 42 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  6.  3.  3.] 
cards in discard: [10.  8.  1.  3. 11.  6.  0.  3.  0.  0.  0.  6. 14.  0.  3.  0. 14. 11.
 10.  3.  6.  4.  6.  6.  0.  6.  0.  1.  1.  1.  0. 16.  0.  8.  0.  3.
  6.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8] -> size -> 48 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 25. 30. 25. 29.  8.  0.  9.  4.  5.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [10. 10.  0.  0.  0.] 
adversary cards in discard: [25. 29. 11.  0.  3. 10.  0. 25.  8.  3. 11.  3. 29. 10.  8. 25. 10. 10.
 29. 29. 15. 11. 25.  1. 29.  0. 29. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11] -> size -> 42 
adversary victory points: 3
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[98.18165]
 [97.94088]
 [97.94088]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  0.  0.] 
cards in discard: [25. 29. 11.  0.  3. 10.  0. 25.  8.  3. 11.  3. 29. 10.  8. 25. 10. 10.
 29. 29. 15. 11. 25.  1. 29.  0. 29. 29. 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 25. 29.  8.  0.  9.  4.  5.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [ 3.  0.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8] -> size -> 48 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 54.3739013671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
expected returns: [[ 95.58335 ]
 [100.09256 ]
 [ 98.82165 ]
 [102.45009 ]
 [ 99.21179 ]
 [ 98.181656]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  0.  0.] 
cards in discard: [25. 29. 11.  0.  3. 10.  0. 25.  8.  3. 11.  3. 29. 10.  8. 25. 10. 10.
 29. 29. 15. 11. 25.  1. 29.  0. 29. 29. 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 25. 30. 25. 29.  8.  0.  9.  4.  5.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [ 3.  0.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8] -> size -> 48 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 98.18167877197266



buy possibilites: [-1] 
expected returns: [[70.258385]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  0.  0.] 
cards in discard: [25. 29. 11.  0.  3. 10.  0. 25.  8.  3. 11.  3. 29. 10.  8. 25. 10. 10.
 29. 29. 15. 11. 25.  1. 29.  0. 29. 29. 25. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 25. 29.  8.  0.  9.  3.  5.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [ 3.  0.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8] -> size -> 48 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0   0   0   0   0   0 -80   0   0  54   0] 
sum of rewards: 29 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 102.45010375976562






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 15.] 
cards in discard: [] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 25. 29.  8.  0.  9.  3.  5.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [29. 11. 10. 10. 25.] 
adversary cards in discard: [25. 29. 11.  0.  3. 10.  0. 25.  8.  3. 11.  3. 29. 10.  8. 25. 10. 10.
 29. 29. 15. 11. 25.  1. 29.  0. 29. 29. 25. 11. 10. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11] -> size -> 43 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 15.] 
cards in discard: [] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8] -> size -> 48 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 25. 30. 25. 29.  8.  0.  9.  3.  5.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [29. 11. 10. 10. 25.] 
adversary cards in discard: [25. 29. 11.  0.  3. 10.  0. 25.  8.  3. 11.  3. 29. 10.  8. 25. 10. 10.
 29. 29. 15. 11. 25.  1. 29.  0. 29. 29. 25. 11. 10. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11] -> size -> 43 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 15.] 
cards in discard: [1.] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 25. 29.  8.  0.  9.  3.  5.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [29. 11. 10. 10. 25.] 
adversary cards in discard: [25. 29. 11.  0.  3. 10.  0. 25.  8.  3. 11.  3. 29. 10.  8. 25. 10. 10.
 29. 29. 15. 11. 25.  1. 29.  0. 29. 29. 25. 11. 10. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11] -> size -> 43 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [29. 11. 10. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 10. 10. 25.] 
expected returns: [[42.841255]
 [45.850494]
 [44.720757]
 [41.178085]
 [41.178085]
 [47.817146]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 10. 10. 25.] 
cards in discard: [25. 29. 11.  0.  3. 10.  0. 25.  8.  3. 11.  3. 29. 10.  8. 25. 10. 10.
 29. 29. 15. 11. 25.  1. 29.  0. 29. 29. 25. 11. 10. 10.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 25. 29.  8.  0.  9.  3.  5.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [ 6.  0.  3. 11.  6.] 
adversary cards in discard: [ 1.  3.  0.  0.  0. 15.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1] -> size -> 49 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 70.25838470458984



action possibilites: [-1] 
expected returns: [[50.041092]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 10. 10.  8.  0.] 
cards in discard: [25. 29. 11.  0.  3. 10.  0. 25.  8.  3. 11.  3. 29. 10.  8. 25. 10. 10.
 29. 29. 15. 11. 25.  1. 29.  0. 29. 29. 25. 11. 10. 10.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 25. 29.  8.  0.  9.  3.  5.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [ 6.  0.  3. 11.  6.] 
adversary cards in discard: [ 1.  3.  0.  0.  0. 15.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1] -> size -> 49 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 47.81715393066406





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[46.393646]
 [50.041084]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11. 10. 10.  8.  0.] 
cards in discard: [25. 29. 11.  0.  3. 10.  0. 25.  8.  3. 11.  3. 29. 10.  8. 25. 10. 10.
 29. 29. 15. 11. 25.  1. 29.  0. 29. 29. 25. 11. 10. 10.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 24. 30. 25. 29.  8.  0.  9.  3.  5.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [ 6.  0.  3. 11.  6.] 
adversary cards in discard: [ 1.  3.  0.  0.  0. 15.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1] -> size -> 49 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 50.04109191894531






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [ 6.  0.  3. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3. 11.  6.] 
cards in discard: [ 1.  3.  0.  0.  0. 15.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 25. 29.  8.  0.  9.  3.  5.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 25.  0. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11] -> size -> 43 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 6.] 
cards in discard: [ 1.  3.  0.  0.  0. 15.  8.] 
cards in deck: 38 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 25. 29.  8.  0.  9.  3.  4.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 25.  0. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11] -> size -> 43 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 6.] 
cards in discard: [ 1.  3.  0.  0.  0. 15.  8.] 
cards in deck: 38 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8] -> size -> 50 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 24. 30. 25. 29.  8.  0.  9.  3.  4.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 25.  0. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11] -> size -> 43 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 6.] 
cards in discard: [ 1.  3.  0.  0.  0. 15.  8.  0.] 
cards in deck: 38 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0] -> size -> 51 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 24. 30. 25. 29.  8.  0.  9.  3.  4.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 25.  0. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11] -> size -> 43 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 0. 25.  0. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 29.] 
expected returns: [[ 9.388956]
 [12.399708]
 [11.27486 ]
 [11.27486 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0. 29. 29.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 25. 29.  8.  0.  9.  3.  4.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  8. 14.  3.  0.] 
adversary cards in discard: [ 1.  3.  0.  0.  0. 15.  8.  0. 11.  6.  0.  3.  6.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0] -> size -> 51 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 50.04109191894531



action possibilites: [-1] 
expected returns: [[-2.5718079]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 29. 10. 29.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 25. 29.  8.  0.  9.  3.  4.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  8. 14.  3.  0.] 
adversary cards in discard: [ 1.  3.  0.  0.  0. 15.  8.  0. 11.  6.  0.  3.  6.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0] -> size -> 51 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 12.39970588684082





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-5.975105 ]
 [-4.2656264]
 [-4.370162 ]
 [-1.9310305]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29. 29. 10. 29.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 24. 30. 25. 29.  8.  0.  9.  3.  4.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  8. 14.  3.  0.] 
adversary cards in discard: [ 1.  3.  0.  0.  0. 15.  8.  0. 11.  6.  0.  3.  6.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0] -> size -> 51 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: -2.571807861328125






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [ 0.  8. 14.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 14.  3.  0.] 
cards in discard: [ 1.  3.  0.  0.  0. 15.  8.  0. 11.  6.  0.  3.  6.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 25. 29.  8.  0.  9.  3.  4.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [11. 25. 25. 29. 29.] 
adversary cards in discard: [25.  0.  0. 29. 29. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11] -> size -> 43 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 14.  3.  0.] 
cards in discard: [ 1.  3.  0.  0.  0. 15.  8.  0. 11.  6.  0.  3.  6.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0] -> size -> 51 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 24. 30. 25. 29.  8.  0.  9.  3.  4.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [11. 25. 25. 29. 29.] 
adversary cards in discard: [25.  0.  0. 29. 29. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11] -> size -> 43 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 14.  3.  0.] 
cards in discard: [ 1.  3.  0.  0.  0. 15.  8.  0. 11.  6.  0.  3.  6.  3.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 24. 29.  8.  0.  9.  3.  4.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [11. 25. 25. 29. 29.] 
adversary cards in discard: [25.  0.  0. 29. 29. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11] -> size -> 43 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [11. 25. 25. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 25. 29. 29.] 
expected returns: [[37.86818 ]
 [40.80136 ]
 [43.517258]
 [43.517258]
 [41.62152 ]
 [41.62152 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25. 25. 29. 29.] 
cards in discard: [25.  0.  0. 29. 29. 10. 29.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 24. 29.  8.  0.  9.  3.  4.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [ 1.  6. 16.  8.  0.] 
adversary cards in discard: [ 1.  3.  0.  0.  0. 15.  8.  0. 11.  6.  0.  3.  6.  3.  0.  8. 14.  3.
  0.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3] -> size -> 52 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -1.9310221672058105



action possibilites: [-1] 
expected returns: [[25.820587]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25. 29. 29. 25.  3.] 
cards in discard: [25.  0.  0. 29. 29. 10. 29.] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 24. 29.  8.  0.  9.  3.  4.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [ 1.  6. 16.  8.  0.] 
adversary cards in discard: [ 1.  3.  0.  0.  0. 15.  8.  0. 11.  6.  0.  3.  6.  3.  0.  8. 14.  3.
  0.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3] -> size -> 52 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 43.51725769042969





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[21.436443]
 [26.151875]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 25. 29. 29. 25.  3.] 
cards in discard: [25.  0.  0. 29. 29. 10. 29.] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11] -> size -> 43 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 24. 30. 24. 29.  8.  0.  9.  3.  4.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [ 1.  6. 16.  8.  0.] 
adversary cards in discard: [ 1.  3.  0.  0.  0. 15.  8.  0. 11.  6.  0.  3.  6.  3.  0.  8. 14.  3.
  0.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3] -> size -> 52 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 25.820587158203125






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [ 1.  6. 16.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6. 16.  8.  0.] 
cards in discard: [ 1.  3.  0.  0.  0. 15.  8.  0. 11.  6.  0.  3.  6.  3.  0.  8. 14.  3.
  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 24. 29.  8.  0.  9.  3.  4.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  0. 25.  3. 11.] 
adversary cards in discard: [25.  0.  0. 29. 29. 10. 29. 25. 11. 25. 29. 29. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11] -> size -> 43 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6. 16.  8.  0.] 
cards in discard: [ 1.  3.  0.  0.  0. 15.  8.  0. 11.  6.  0.  3.  6.  3.  0.  8. 14.  3.
  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3] -> size -> 52 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 24. 30. 24. 29.  8.  0.  9.  3.  4.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  0. 25.  3. 11.] 
adversary cards in discard: [25.  0.  0. 29. 29. 10. 29. 25. 11. 25. 29. 29. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11] -> size -> 43 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  0. 25.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[ 97.28805]
 [104.77159]
 [100.50778]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.  3. 11.] 
cards in discard: [25.  0.  0. 29. 29. 10. 29. 25. 11. 25. 29. 29. 25.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 24. 29.  8.  0.  9.  3.  4.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [ 3.  6. 11.  3.  0.] 
adversary cards in discard: [ 1.  3.  0.  0.  0. 15.  8.  0. 11.  6.  0.  3.  6.  3.  0.  8. 14.  3.
  0.  1.  6. 16.  8.  0.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3] -> size -> 52 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 26.15190315246582



action possibilites: [-1] 
expected returns: [[39.492172]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 11.  0. 29.] 
cards in discard: [25.  0.  0. 29. 29. 10. 29. 25. 11. 25. 29. 29. 25.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 24. 29.  8.  0.  9.  3.  4.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [ 3.  6. 11.  3.  0.] 
adversary cards in discard: [ 1.  3.  0.  0.  0. 15.  8.  0. 11.  6.  0.  3.  6.  3.  0.  8. 14.  3.
  0.  1.  6. 16.  8.  0.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3] -> size -> 52 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 104.7715835571289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. -1.] 
expected returns: [[38.551323]
 [41.49785 ]
 [40.764755]
 [43.034782]
 [40.821342]
 [42.220192]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 11.  0. 29.] 
cards in discard: [25.  0.  0. 29. 29. 10. 29. 25. 11. 25. 29. 29. 25.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11] -> size -> 43 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 24. 30. 24. 29.  8.  0.  9.  3.  4.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [ 3.  6. 11.  3.  0.] 
adversary cards in discard: [ 1.  3.  0.  0.  0. 15.  8.  0. 11.  6.  0.  3.  6.  3.  0.  8. 14.  3.
  0.  1.  6. 16.  8.  0.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3] -> size -> 52 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 39.49217224121094



buy possibilites: [-1] 
expected returns: [[36.763702]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 11.  0. 29.] 
cards in discard: [25.  0.  0. 29. 29. 10. 29. 25. 11. 25. 29. 29. 25.  3. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 24. 29.  8.  0.  9.  2.  4.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [ 3.  6. 11.  3.  0.] 
adversary cards in discard: [ 1.  3.  0.  0.  0. 15.  8.  0. 11.  6.  0.  3.  6.  3.  0.  8. 14.  3.
  0.  1.  6. 16.  8.  0.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3] -> size -> 52 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0 -90   0   0  54   0] 
sum of rewards: 9 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 43.03479766845703






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [ 3.  6. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 11.  3.  0.] 
cards in discard: [ 1.  3.  0.  0.  0. 15.  8.  0. 11.  6.  0.  3.  6.  3.  0.  8. 14.  3.
  0.  1.  6. 16.  8.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 24. 29.  8.  0.  9.  2.  4.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [ 3. 10. 10. 10. 11.] 
adversary cards in discard: [25.  0.  0. 29. 29. 10. 29. 25. 11. 25. 29. 29. 25.  3. 11. 25.  0.  0.
  3. 11.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11] -> size -> 44 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 11.  3.  0.] 
cards in discard: [ 1.  3.  0.  0.  0. 15.  8.  0. 11.  6.  0.  3.  6.  3.  0.  8. 14.  3.
  0.  1.  6. 16.  8.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3] -> size -> 52 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 24. 30. 24. 29.  8.  0.  9.  2.  4.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [ 3. 10. 10. 10. 11.] 
adversary cards in discard: [25.  0.  0. 29. 29. 10. 29. 25. 11. 25. 29. 29. 25.  3. 11. 25.  0.  0.
  3. 11.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11] -> size -> 44 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3. 10. 10. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10. 11.] 
expected returns: [[2.3505025]
 [0.6926482]
 [0.6926482]
 [0.6926482]
 [3.0903087]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10. 10. 11.] 
cards in discard: [25.  0.  0. 29. 29. 10. 29. 25. 11. 25. 29. 29. 25.  3. 11. 25.  0.  0.
  3. 11.  0. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 24. 29.  8.  0.  9.  2.  4.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [ 3. 14.  6.  0.  0.] 
adversary cards in discard: [ 1.  3.  0.  0.  0. 15.  8.  0. 11.  6.  0.  3.  6.  3.  0.  8. 14.  3.
  0.  1.  6. 16.  8.  0.  3.  6. 11.  3.  0.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3] -> size -> 52 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 36.763702392578125



action possibilites: [-1] 
expected returns: [[24.797434]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10. 10.] 
cards in discard: [25.  0.  0. 29. 29. 10. 29. 25. 11. 25. 29. 29. 25.  3. 11. 25.  0.  0.
  3. 11.  0. 29.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 24. 29.  8.  0.  9.  2.  4.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [ 3. 14.  6.  0.  0.] 
adversary cards in discard: [ 1.  3.  0.  0.  0. 15.  8.  0. 11.  6.  0.  3.  6.  3.  0.  8. 14.  3.
  0.  1.  6. 16.  8.  0.  3.  6. 11.  3.  0.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3] -> size -> 52 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[  -5    0    0   30    0    0   20    0    0    0    0 -100    0    0
   27    0] 
sum of rewards: -28 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 1.8568758964538574





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[21.634748]
 [24.797438]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 10. 10.] 
cards in discard: [25.  0.  0. 29. 29. 10. 29. 25. 11. 25. 29. 29. 25.  3. 11. 25.  0.  0.
  3. 11.  0. 29.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1] -> size -> 45 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 23. 30. 24. 29.  8.  0.  9.  2.  4.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [ 3. 14.  6.  0.  0.] 
adversary cards in discard: [ 1.  3.  0.  0.  0. 15.  8.  0. 11.  6.  0.  3.  6.  3.  0.  8. 14.  3.
  0.  1.  6. 16.  8.  0.  3.  6. 11.  3.  0.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3] -> size -> 52 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 24.797433853149414






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [ 3. 14.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  6.  0.  0.] 
cards in discard: [ 1.  3.  0.  0.  0. 15.  8.  0. 11.  6.  0.  3.  6.  3.  0.  8. 14.  3.
  0.  1.  6. 16.  8.  0.  3.  6. 11.  3.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 24. 29.  8.  0.  9.  2.  4.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [ 8. 25. 11. 10. 10.] 
adversary cards in discard: [25.  0.  0. 29. 29. 10. 29. 25. 11. 25. 29. 29. 25.  3. 11. 25.  0.  0.
  3. 11.  0. 29.  1. 11.  3. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1] -> size -> 45 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 0.] 
cards in discard: [ 1.  3.  0.  0.  0. 15.  8.  0. 11.  6.  0.  3.  6.  3.  0.  8. 14.  3.
  0.  1.  6. 16.  8.  0.  3.  6. 11.  3.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3] -> size -> 52 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 23. 30. 24. 29.  8.  0.  9.  2.  4.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [25. 11. 10.] 
adversary cards in discard: [25.  0.  0. 29. 29. 10. 29. 25. 11. 25. 29. 29. 25.  3. 11. 25.  0.  0.
  3. 11.  0. 29.  1. 11.  3. 10. 10. 10.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1] -> size -> 45 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0.] 
cards in discard: [ 1.  3.  0.  0.  0. 15.  8.  0. 11.  6.  0.  3.  6.  3.  0.  8. 14.  3.
  0.  1.  6. 16.  8.  0.  3.  6. 11.  3.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3] -> size -> 52 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 23. 30. 24. 29.  8.  0.  9.  2.  4.  4.  1.  6. 10.  0. 10.  8.] 
adversary cards in hand: [25. 11. 10.] 
adversary cards in discard: [25.  0.  0. 29. 29. 10. 29. 25. 11. 25. 29. 29. 25.  3. 11. 25.  0.  0.
  3. 11.  0. 29.  1. 11.  3. 10. 10. 10.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1] -> size -> 45 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0.] 
cards in discard: [ 1.  3.  0.  0.  0. 15.  8.  0. 11.  6.  0.  3.  6.  3.  0.  8. 14.  3.
  0.  1.  6. 16.  8.  0.  3.  6. 11.  3.  0. 14.] 
cards in deck: 18 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3 14] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 24. 29.  8.  0.  9.  2.  4.  4.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [25. 11. 10.] 
adversary cards in discard: [25.  0.  0. 29. 29. 10. 29. 25. 11. 25. 29. 29. 25.  3. 11. 25.  0.  0.
  3. 11.  0. 29.  1. 11.  3. 10. 10. 10.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1] -> size -> 45 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [25. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 10.] 
expected returns: [[22.082106]
 [25.234842]
 [21.863785]
 [19.492628]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11. 10.] 
cards in discard: [25.  0.  0. 29. 29. 10. 29. 25. 11. 25. 29. 29. 25.  3. 11. 25.  0.  0.
  3. 11.  0. 29.  1. 11.  3. 10. 10. 10.  8. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 24. 29.  8.  0.  9.  2.  4.  4.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [0. 1. 6. 6. 1.] 
adversary cards in discard: [ 1.  3.  0.  0.  0. 15.  8.  0. 11.  6.  0.  3.  6.  3.  0.  8. 14.  3.
  0.  1.  6. 16.  8.  0.  3.  6. 11.  3.  0. 14. 14.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3 14] -> size -> 53 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -5.733921051025391



action possibilites: [-1] 
expected returns: [[56.469658]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  8. 11.] 
cards in discard: [25.  0.  0. 29. 29. 10. 29. 25. 11. 25. 29. 29. 25.  3. 11. 25.  0.  0.
  3. 11.  0. 29.  1. 11.  3. 10. 10. 10.  8. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 24. 29.  8.  0.  9.  2.  4.  4.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [0. 1. 6. 6. 1.] 
adversary cards in discard: [ 1.  3.  0.  0.  0. 15.  8.  0. 11.  6.  0.  3.  6.  3.  0.  8. 14.  3.
  0.  1.  6. 16.  8.  0.  3.  6. 11.  3.  0. 14. 14.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3 14] -> size -> 53 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 25.23484992980957





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[53.458908]
 [56.469627]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  8. 11.] 
cards in discard: [25.  0.  0. 29. 29. 10. 29. 25. 11. 25. 29. 29. 25.  3. 11. 25.  0.  0.
  3. 11.  0. 29.  1. 11.  3. 10. 10. 10.  8. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1] -> size -> 45 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 23. 30. 24. 29.  8.  0.  9.  2.  4.  4.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [0. 1. 6. 6. 1.] 
adversary cards in discard: [ 1.  3.  0.  0.  0. 15.  8.  0. 11.  6.  0.  3.  6.  3.  0.  8. 14.  3.
  0.  1.  6. 16.  8.  0.  3.  6. 11.  3.  0. 14. 14.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3 14] -> size -> 53 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 56.46965789794922






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [0. 1. 6. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 6. 6. 1.] 
cards in discard: [ 1.  3.  0.  0.  0. 15.  8.  0. 11.  6.  0.  3.  6.  3.  0.  8. 14.  3.
  0.  1.  6. 16.  8.  0.  3.  6. 11.  3.  0. 14. 14.  3.  6.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3 14] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 24. 29.  8.  0.  9.  2.  4.  4.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [10.  1. 29.  8.  0.] 
adversary cards in discard: [25.  0.  0. 29. 29. 10. 29. 25. 11. 25. 29. 29. 25.  3. 11. 25.  0.  0.
  3. 11.  0. 29.  1. 11.  3. 10. 10. 10.  8. 10. 25. 11. 10.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1] -> size -> 45 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 6. 1.] 
cards in discard: [ 1.  3.  0.  0.  0. 15.  8.  0. 11.  6.  0.  3.  6.  3.  0.  8. 14.  3.
  0.  1.  6. 16.  8.  0.  3.  6. 11.  3.  0. 14. 14.  3.  6.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3 14] -> size -> 53 
action values: 0 
buys: 1 
player value: 5 
card supply: [15. 23. 30. 24. 29.  8.  0.  9.  2.  4.  4.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [10.  1. 29.  8.  0.] 
adversary cards in discard: [25.  0.  0. 29. 29. 10. 29. 25. 11. 25. 29. 29. 25.  3. 11. 25.  0.  0.
  3. 11.  0. 29.  1. 11.  3. 10. 10. 10.  8. 10. 25. 11. 10.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1] -> size -> 45 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 6. 1.] 
cards in discard: [ 1.  3.  0.  0.  0. 15.  8.  0. 11.  6.  0.  3.  6.  3.  0.  8. 14.  3.
  0.  1.  6. 16.  8.  0.  3.  6. 11.  3.  0. 14. 14.  3.  6.  0.  0. 16.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3 14 16] -> size -> 54 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 23. 30. 24. 29.  8.  0.  8.  2.  4.  4.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [10.  1. 29.  8.  0.] 
adversary cards in discard: [25.  0.  0. 29. 29. 10. 29. 25. 11. 25. 29. 29. 25.  3. 11. 25.  0.  0.
  3. 11.  0. 29.  1. 11.  3. 10. 10. 10.  8. 10. 25. 11. 10.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1] -> size -> 45 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [10.  1. 29.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.  8.] 
expected returns: [[ 99.34267 ]
 [ 98.182175]
 [106.43131 ]
 [ 99.96023 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1. 29.  8.  0.] 
cards in discard: [25.  0.  0. 29. 29. 10. 29. 25. 11. 25. 29. 29. 25.  3. 11. 25.  0.  0.
  3. 11.  0. 29.  1. 11.  3. 10. 10. 10.  8. 10. 25. 11. 10.  8. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 24. 29.  8.  0.  8.  2.  4.  4.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [ 4.  6.  0. 10.  3.] 
adversary cards in discard: [ 1.  3.  0.  0.  0. 15.  8.  0. 11.  6.  0.  3.  6.  3.  0.  8. 14.  3.
  0.  1.  6. 16.  8.  0.  3.  6. 11.  3.  0. 14. 14.  3.  6.  0.  0. 16.
  0.  1.  6.  6.  1.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3 14 16] -> size -> 54 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 56.46965789794922



action possibilites: [-1. 10.  8.] 
expected returns: [[107.98513]
 [106.15539]
 [107.991  ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0.] 
cards in discard: [25.  0.  0. 29. 29. 10. 29. 25. 11. 25. 29. 29. 25.  3. 11. 25.  0.  0.
  3. 11.  0. 29.  1. 11.  3. 10. 10. 10.  8. 10. 25. 11. 10.  8. 11.  1.
 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 29 10 29 29 10 25 25 29  8 10
 25 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 1 
card supply: [15. 23. 30. 24. 29.  8.  0.  8.  2.  4.  4.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [ 4.  6.  0. 10.  3.] 
adversary cards in discard: [ 1.  3.  0.  0.  0. 15.  8.  0. 11.  6.  0.  3.  6.  3.  0.  8. 14.  3.
  0.  1.  6. 16.  8.  0.  3.  6. 11.  3.  0. 14. 14.  3.  6.  0.  0. 16.
  0.  1.  6.  6.  1.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3 14 16] -> size -> 54 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 106.48151397705078



action possibilites: [-1] 
expected returns: [[103.48225]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [25.  0.  0. 29. 29. 10. 29. 25. 11. 25. 29. 29. 25.  3. 11. 25.  0.  0.
  3. 11.  0. 29.  1. 11.  3. 10. 10. 10.  8. 10. 25. 11. 10.  8. 11.  1.
 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 29 10 25 25 29  8 10 25
 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 23. 30. 24. 29.  8.  0.  8.  2.  4.  4.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [ 4.  6.  0. 10.  3.] 
adversary cards in discard: [ 1.  3.  0.  0.  0. 15.  8.  0. 11.  6.  0.  3.  6.  3.  0.  8. 14.  3.
  0.  1.  6. 16.  8.  0.  3.  6. 11.  3.  0. 14. 14.  3.  6.  0.  0. 16.
  0.  1.  6.  6.  1.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3 14 16] -> size -> 54 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 109.34310150146484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 98.23453]
 [103.25329]
 [103.77468]
 [103.48225]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [25.  0.  0. 29. 29. 10. 29. 25. 11. 25. 29. 29. 25.  3. 11. 25.  0.  0.
  3. 11.  0. 29.  1. 11.  3. 10. 10. 10.  8. 10. 25. 11. 10.  8. 11.  1.
 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 29 10 25 25 29  8 10 25
 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 23. 30. 24. 29.  8.  0.  8.  2.  4.  4.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [ 4.  6.  0. 10.  3.] 
adversary cards in discard: [ 1.  3.  0.  0.  0. 15.  8.  0. 11.  6.  0.  3.  6.  3.  0.  8. 14.  3.
  0.  1.  6. 16.  8.  0.  3.  6. 11.  3.  0. 14. 14.  3.  6.  0.  0. 16.
  0.  1.  6.  6.  1.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3 14 16] -> size -> 54 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 103.48224639892578



buy possibilites: [-1] 
expected returns: [[112.554085]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [25.  0.  0. 29. 29. 10. 29. 25. 11. 25. 29. 29. 25.  3. 11. 25.  0.  0.
  3. 11.  0. 29.  1. 11.  3. 10. 10. 10.  8. 10. 25. 11. 10.  8. 11.  1.
 29.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 29 10 25 25 29  8 10 25
 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1  8] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 24. 29.  8.  0.  8.  2.  3.  4.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [ 4.  6.  0. 10.  3.] 
adversary cards in discard: [ 1.  3.  0.  0.  0. 15.  8.  0. 11.  6.  0.  3.  6.  3.  0.  8. 14.  3.
  0.  1.  6. 16.  8.  0.  3.  6. 11.  3.  0. 14. 14.  3.  6.  0.  0. 16.
  0.  1.  6.  6.  1.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3 14 16] -> size -> 54 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[  -5    0    0   30    0    0   40    0    0    0    0 -100    0    0
   16    0] 
sum of rewards: -19 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 103.77466583251953






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [ 4.  6.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4.  6.  0. 10.  3.] 
cards in discard: [ 1.  3.  0.  0.  0. 15.  8.  0. 11.  6.  0.  3.  6.  3.  0.  8. 14.  3.
  0.  1.  6. 16.  8.  0.  3.  6. 11.  3.  0. 14. 14.  3.  6.  0.  0. 16.
  0.  1.  6.  6.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3 14 16] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 24. 29.  8.  0.  8.  2.  3.  4.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [29. 15. 10. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 29 10 25 25 29  8 10 25
 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1  8] -> size -> 45 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 6. 0. 3. 6.] 
cards in discard: [ 1.  3.  0.  0.  0. 15.  8.  0. 11.  6.  0.  3.  6.  3.  0.  8. 14.  3.
  0.  1.  6. 16.  8.  0.  3.  6. 11.  3.  0. 14. 14.  3.  6.  0.  0. 16.
  0.  1.  6.  6.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3 14 16] -> size -> 54 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 24. 29.  8.  0.  8.  2.  3.  4.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [29. 15. 10. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 29 10 25 25 29  8 10 25
 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1  8] -> size -> 45 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 6. 0. 3. 6.] 
cards in discard: [ 1.  3.  0.  0.  0. 15.  8.  0. 11.  6.  0.  3.  6.  3.  0.  8. 14.  3.
  0.  1.  6. 16.  8.  0.  3.  6. 11.  3.  0. 14. 14.  3.  6.  0.  0. 16.
  0.  1.  6.  6.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3 14 16] -> size -> 54 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 23. 30. 24. 29.  8.  0.  8.  2.  3.  4.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [29. 15. 10. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 29 10 25 25 29  8 10 25
 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1  8] -> size -> 45 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 6. 0. 3. 6.] 
cards in discard: [ 1.  3.  0.  0.  0. 15.  8.  0. 11.  6.  0.  3.  6.  3.  0.  8. 14.  3.
  0.  1.  6. 16.  8.  0.  3.  6. 11.  3.  0. 14. 14.  3.  6.  0.  0. 16.
  0.  1.  6.  6.  1.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3 14 16  0] -> size -> 55 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 23. 30. 24. 29.  8.  0.  8.  2.  3.  4.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [29. 15. 10. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 29 10 25 25 29  8 10 25
 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1  8] -> size -> 45 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [29. 15. 10. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 10. 29.] 
expected returns: [[37.972046]
 [39.003166]
 [36.663963]
 [35.702606]
 [39.003166]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 15. 10. 29.  0.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 29 10 25 25 29  8 10 25
 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1  8] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 30. 24. 29.  8.  0.  8.  2.  3.  4.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  1.  0. 14.  0.] 
adversary cards in discard: [ 1.  3.  0.  0.  0. 15.  8.  0. 11.  6.  0.  3.  6.  3.  0.  8. 14.  3.
  0.  1.  6. 16.  8.  0.  3.  6. 11.  3.  0. 14. 14.  3.  6.  0.  0. 16.
  0.  1.  6.  6.  1.  0. 10.  4.  6.  0.  3.  6.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3 14 16  0] -> size -> 55 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 112.55408477783203



action possibilites: [-1. 15. 10.] 
expected returns: [[43.05507]
 [41.6532 ]
 [40.7922 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  0.] 
cards in discard: [29.  0.] 
cards in deck: 39 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 29 10 25 25 29  8 10 25
 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1  8] -> size -> 45 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 23. 30. 24. 29.  8.  0.  8.  2.  3.  4.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  1.  0. 14.  0.] 
adversary cards in discard: [ 1.  3.  0.  0.  0. 15.  8.  0. 11.  6.  0.  3.  6.  3.  0.  8. 14.  3.
  0.  1.  6. 16.  8.  0.  3.  6. 11.  3.  0. 14. 14.  3.  6.  0.  0. 16.
  0.  1.  6.  6.  1.  0. 10.  4.  6.  0.  3.  6.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3 14 16  0] -> size -> 55 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 36.61799621582031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[39.793266]
 [40.69654 ]
 [40.548492]
 [42.58902 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10.  0.] 
cards in discard: [29.  0.] 
cards in deck: 39 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 29 10 25 25 29  8 10 25
 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1  8] -> size -> 45 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 23. 30. 24. 29.  8.  0.  8.  2.  3.  4.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  1.  0. 14.  0.] 
adversary cards in discard: [ 1.  3.  0.  0.  0. 15.  8.  0. 11.  6.  0.  3.  6.  3.  0.  8. 14.  3.
  0.  1.  6. 16.  8.  0.  3.  6. 11.  3.  0. 14. 14.  3.  6.  0.  0. 16.
  0.  1.  6.  6.  1.  0. 10.  4.  6.  0.  3.  6.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3 14 16  0] -> size -> 55 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 43.05506896972656






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [ 0.  1.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0. 14.  0.] 
cards in discard: [ 1.  3.  0.  0.  0. 15.  8.  0. 11.  6.  0.  3.  6.  3.  0.  8. 14.  3.
  0.  1.  6. 16.  8.  0.  3.  6. 11.  3.  0. 14. 14.  3.  6.  0.  0. 16.
  0.  1.  6.  6.  1.  0. 10.  4.  6.  0.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3 14 16  0] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 30. 24. 29.  8.  0.  8.  2.  3.  4.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [11. 10. 25. 25. 25.] 
adversary cards in discard: [29.  0. 29. 15. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 29 10 25 25 29  8 10 25
 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1  8] -> size -> 45 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0.] 
cards in discard: [ 1.  3.  0.  0.  0. 15.  8.  0. 11.  6.  0.  3.  6.  3.  0.  8. 14.  3.
  0.  1.  6. 16.  8.  0.  3.  6. 11.  3.  0. 14. 14.  3.  6.  0.  0. 16.
  0.  1.  6.  6.  1.  0. 10.  4.  6.  0.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3 14 16  0] -> size -> 55 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 23. 30. 24. 29.  8.  0.  8.  2.  3.  4.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [11. 10. 25.] 
adversary cards in discard: [29.  0. 29. 15. 10.  0. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 29 10 25 25 29  8 10 25
 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1  8] -> size -> 45 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0.] 
cards in discard: [ 1.  3.  0.  0.  0. 15.  8.  0. 11.  6.  0.  3.  6.  3.  0.  8. 14.  3.
  0.  1.  6. 16.  8.  0.  3.  6. 11.  3.  0. 14. 14.  3.  6.  0.  0. 16.
  0.  1.  6.  6.  1.  0. 10.  4.  6.  0.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3 14 16  0] -> size -> 55 
action values: 0 
buys: 1 
player value: 7 
card supply: [14. 23. 30. 24. 29.  8.  0.  8.  2.  3.  4.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [11. 10. 25.] 
adversary cards in discard: [29.  0. 29. 15. 10.  0. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 29 10 25 25 29  8 10 25
 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1  8] -> size -> 45 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0.] 
cards in discard: [ 1.  3.  0.  0.  0. 15.  8.  0. 11.  6.  0.  3.  6.  3.  0.  8. 14.  3.
  0.  1.  6. 16.  8.  0.  3.  6. 11.  3.  0. 14. 14.  3.  6.  0.  0. 16.
  0.  1.  6.  6.  1.  0. 10.  4.  6.  0.  3.  6. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3 14 16  0 25] -> size -> 56 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 23. 30. 24. 29.  8.  0.  8.  2.  3.  3.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [11. 10. 25.] 
adversary cards in discard: [29.  0. 29. 15. 10.  0. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 29 10 25 25 29  8 10 25
 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1  8] -> size -> 45 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [11. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 25.] 
expected returns: [[-8.3586035]
 [-8.3586035]
 [-8.3586035]
 [-8.3586035]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 25.] 
cards in discard: [29.  0. 29. 15. 10.  0. 25. 25.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 29 10 25 25 29  8 10 25
 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1  8] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 30. 24. 29.  8.  0.  8.  2.  3.  3.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [14.  3.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3 14 16  0 25] -> size -> 56 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -6.6255903244018555





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-8.3586035]
 [-8.3586035]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 25.] 
cards in discard: [29.  0. 29. 15. 10.  0. 25. 25.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 29 10 25 25 29  8 10 25
 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1  8] -> size -> 45 
action values: 1 
buys: 1 
player value: 0 
card supply: [14. 23. 30. 24. 29.  8.  0.  8.  2.  3.  3.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [14.  3.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3 14 16  0 25] -> size -> 56 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -8.358603477478027



buy possibilites: [-1] 
expected returns: [[2.001327]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 25.] 
cards in discard: [29.  0. 29. 15. 10.  0. 25. 25.  0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 29 10 25 25 29  8 10 25
 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1  8  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 24. 29.  8.  0.  8.  2.  3.  3.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [14.  3.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3 14 16  0 25] -> size -> 56 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[  -5    0    0   30    0    0    0    0    0    0    0 -110    0    0
    0    0] 
sum of rewards: -85 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -8.358603477478027






         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [14.  3.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 51 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3 14 16  0 25] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 24. 29.  8.  0.  8.  2.  3.  3.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [29. 29.  0.  8. 11.] 
adversary cards in discard: [29.  0. 29. 15. 10.  0. 25. 25.  0. 11. 10. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 29 10 25 25 29  8 10 25
 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1  8  0] -> size -> 46 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1. 14. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 50 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3 14 16  0 25] -> size -> 56 
action values: 2 
buys: 0 
player value: 0 
card supply: [13. 23. 30. 24. 29.  8.  0.  8.  2.  3.  3.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [29. 29.  0.  8. 11.] 
adversary cards in discard: [29.  0. 29. 15. 10.  0. 25. 25.  0. 11. 10. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 29 10 25 25 29  8 10 25
 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1  8  0] -> size -> 46 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0.  0.] 
cards in discard: [1.] 
cards in deck: 50 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3 14 16  0 25  1] -> size -> 57 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 22. 30. 24. 29.  8.  0.  8.  2.  3.  3.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [29. 29.  0.  8. 11.] 
adversary cards in discard: [29.  0. 29. 15. 10.  0. 25. 25.  0. 11. 10. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 29 10 25 25 29  8 10 25
 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1  8  0] -> size -> 46 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [1.] 
cards in deck: 50 
card top of deck: [] 
played cards: [10. 11. 14.] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3 14 16  0 25  1] -> size -> 57 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 22. 30. 24. 29.  8.  0.  8.  2.  3.  3.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  8. 11.] 
adversary cards in discard: [29.  0. 29. 15. 10.  0. 25. 25.  0. 11. 10. 25. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 29 10 25 25 29  8 10 25
 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1  8  0] -> size -> 46 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [1.] 
cards in deck: 50 
card top of deck: [] 
played cards: [10. 11. 14.] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3 14 16  0 25  1] -> size -> 57 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 22. 30. 24. 29.  8.  0.  8.  2.  3.  3.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  8. 11.] 
adversary cards in discard: [29.  0. 29. 15. 10.  0. 25. 25.  0. 11. 10. 25. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 29 10 25 25 29  8 10 25
 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1  8  0] -> size -> 46 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [1. 3.] 
cards in deck: 50 
card top of deck: [] 
played cards: [10. 11. 14.] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3 14 16  0 25  1  3] -> size -> 58 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 22. 30. 23. 29.  8.  0.  8.  2.  3.  3.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  8. 11.] 
adversary cards in discard: [29.  0. 29. 15. 10.  0. 25. 25.  0. 11. 10. 25. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 29 10 25 25 29  8 10 25
 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1  8  0] -> size -> 46 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[3.243764 ]
 [3.2804585]
 [4.653119 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11.] 
cards in discard: [29.  0. 29. 15. 10.  0. 25. 25.  0. 11. 10. 25. 29. 29.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 29 10 25 25 29  8 10 25
 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1  8  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 22. 30. 23. 29.  8.  0.  8.  2.  3.  3.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [16.  0.  1.  3.  3.] 
adversary cards in discard: [ 1.  3. 10. 11. 14.  3.  0.  0.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3 14 16  0 25  1  3] -> size -> 58 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -7.643648624420166



action possibilites: [-1] 
expected returns: [[48.66062]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [29.  0. 29. 15. 10.  0. 25. 25.  0. 11. 10. 25. 29. 29.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 29 10 25 25 29  8 10 25
 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1  8  0  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 21. 30. 23. 29.  8.  0.  8.  2.  3.  3.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [16.  0.  1.  3.  3.] 
adversary cards in discard: [ 1.  3. 10. 11. 14.  3.  0.  0.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3 14 16  0 25  1  3] -> size -> 58 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0 -120    0    0
   27    0] 
sum of rewards: -78 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 3.7005724906921387





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[45.944855]
 [48.8985  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [29.  0. 29. 15. 10.  0. 25. 25.  0. 11. 10. 25. 29. 29.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 29 10 25 25 29  8 10 25
 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1  8  0  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 21. 30. 23. 29.  8.  0.  8.  2.  3.  3.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [16.  0.  1.  3.  3.] 
adversary cards in discard: [ 1.  3. 10. 11. 14.  3.  0.  0.] 
adversary owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3 14 16  0 25  1  3] -> size -> 58 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 48.660621643066406






         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [16.  0.  1.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  1.  3.  3.] 
cards in discard: [ 1.  3. 10. 11. 14.  3.  0.  0.] 
cards in deck: 45 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0
  6 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8
  1  8  0  3 14 16  0 25  1  3] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 21. 30. 23. 29.  8.  0.  8.  2.  3.  3.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [ 3.  0. 10. 25.  0.] 
adversary cards in discard: [29.  0. 29. 15. 10.  0. 25. 25.  0. 11. 10. 25. 29. 29.  1. 11.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 29 10 25 25 29  8 10 25
 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1  8  0  1] -> size -> 47 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3.] 
cards in discard: [ 1.  3. 10. 11. 14.  3.  0.  0.  8.] 
cards in deck: 45 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0  6
 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8  1
  8  0  3 14 16  0 25  1  3  8] -> size -> 58 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 21. 30. 23. 29.  8.  0.  8.  2.  2.  3.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [ 3.  0. 10. 25.  0.] 
adversary cards in discard: [29.  0. 29. 15. 10.  0. 25. 25.  0. 11. 10. 25. 29. 29.  1. 11.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 29 10 25 25 29  8 10 25
 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1  8  0  1] -> size -> 47 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3.] 
cards in discard: [ 1.  3. 10. 11. 14.  3.  0.  0.  8.] 
cards in deck: 45 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0  6
 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8  1
  8  0  3 14 16  0 25  1  3  8] -> size -> 58 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 21. 30. 23. 29.  8.  0.  8.  2.  2.  3.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [ 3.  0. 10. 25.  0.] 
adversary cards in discard: [29.  0. 29. 15. 10.  0. 25. 25.  0. 11. 10. 25. 29. 29.  1. 11.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 29 10 25 25 29  8 10 25
 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1  8  0  1] -> size -> 47 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3.] 
cards in discard: [ 1.  3. 10. 11. 14.  3.  0.  0.  8.  8.] 
cards in deck: 45 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0  6
 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8  1
  8  0  3 14 16  0 25  1  3  8  8] -> size -> 59 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 21. 30. 23. 29.  8.  0.  8.  2.  1.  3.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [ 3.  0. 10. 25.  0.] 
adversary cards in discard: [29.  0. 29. 15. 10.  0. 25. 25.  0. 11. 10. 25. 29. 29.  1. 11.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 29 10 25 25 29  8 10 25
 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1  8  0  1] -> size -> 47 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 3.  0. 10. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[77.169426]
 [74.407585]
 [84.98756 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10. 25.  0.] 
cards in discard: [29.  0. 29. 15. 10.  0. 25. 25.  0. 11. 10. 25. 29. 29.  1. 11.  0.  8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 29 10 25 25 29  8 10 25
 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1  8  0  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 21. 30. 23. 29.  8.  0.  8.  2.  1.  3.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [8. 4. 0. 0. 1.] 
adversary cards in discard: [ 1.  3. 10. 11. 14.  3.  0.  0.  8.  8. 16.  1.  3.  3.] 
adversary owned cards: [ 0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0  6
 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8  1
  8  0  3 14 16  0 25  1  3  8  8] -> size -> 59 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 48.89849853515625



action possibilites: [-1] 
expected returns: [[40.160263]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0. 29. 11.] 
cards in discard: [29.  0. 29. 15. 10.  0. 25. 25.  0. 11. 10. 25. 29. 29.  1. 11.  0.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 29 10 25 25 29  8 10 25
 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1  8  0  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 21. 30. 23. 29.  8.  0.  8.  2.  1.  3.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [8. 4. 0. 0. 1.] 
adversary cards in discard: [ 1.  3. 10. 11. 14.  3.  0.  0.  8.  8. 16.  1.  3.  3.] 
adversary owned cards: [ 0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0  6
 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8  1
  8  0  3 14 16  0 25  1  3  8  8] -> size -> 59 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 84.98757934570312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[35.737724]
 [37.82543 ]
 [37.77182 ]
 [40.160263]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  0. 29. 11.] 
cards in discard: [29.  0. 29. 15. 10.  0. 25. 25.  0. 11. 10. 25. 29. 29.  1. 11.  0.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 29 10 25 25 29  8 10 25
 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1  8  0  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 21. 30. 23. 29.  8.  0.  8.  2.  1.  3.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [8. 4. 0. 0. 1.] 
adversary cards in discard: [ 1.  3. 10. 11. 14.  3.  0.  0.  8.  8. 16.  1.  3.  3.] 
adversary owned cards: [ 0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0  6
 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8  1
  8  0  3 14 16  0 25  1  3  8  8] -> size -> 59 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 40.16026306152344






         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [8. 4. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 4. 0. 0. 1.] 
cards in discard: [ 1.  3. 10. 11. 14.  3.  0.  0.  8.  8. 16.  1.  3.  3.] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0 16  0  3  0 11  0  3  1  6 15  0  6  0 10  6  0  3  0  0  6
 10  6  3  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8  1
  8  0  3 14 16  0 25  1  3  8  8] -> size -> 59 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 21. 30. 23. 29.  8.  0.  8.  2.  1.  3.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  1. 25.  3. 29.] 
adversary cards in discard: [29.  0. 29. 15. 10.  0. 25. 25.  0. 11. 10. 25. 29. 29.  1. 11.  0.  8.
 25.  3.  0. 10.  0. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 29 10 25 25 29  8 10 25
 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1  8  0  1] -> size -> 47 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4.] 
cards in discard: [ 1.  3. 10. 11. 14.  3.  0.  0.  8.  8. 16.  1.  3.  3.] 
cards in deck: 40 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 16  0  3  0 11  0  3  6 15  0  6  0 10  6  0  3  0  0  6 10  6  3
  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8  1  8  0  3
 14 16  0 25  1  3  8  8] -> size -> 56 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 21. 30. 23. 29.  8.  0.  8.  2.  1.  3.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  1. 25.  3. 29.] 
adversary cards in discard: [29.  0. 29. 15. 10.  0. 25. 25.  0. 11. 10. 25. 29. 29.  1. 11.  0.  8.
 25.  3.  0. 10.  0. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 29 10 25 25 29  8 10 25
 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1  8  0  1] -> size -> 47 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4.] 
cards in discard: [ 1.  3. 10. 11. 14.  3.  0.  0.  8.  8. 16.  1.  3.  3.] 
cards in deck: 40 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 16  0  3  0 11  0  3  6 15  0  6  0 10  6  0  3  0  0  6 10  6  3
  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8  1  8  0  3
 14 16  0 25  1  3  8  8] -> size -> 56 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 21. 30. 23. 29.  8.  0.  8.  2.  1.  3.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  1. 25.  3. 29.] 
adversary cards in discard: [29.  0. 29. 15. 10.  0. 25. 25.  0. 11. 10. 25. 29. 29.  1. 11.  0.  8.
 25.  3.  0. 10.  0. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 29 10 25 25 29  8 10 25
 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1  8  0  1] -> size -> 47 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4.] 
cards in discard: [ 1.  3. 10. 11. 14.  3.  0.  0.  8.  8. 16.  1.  3.  3.  0.] 
cards in deck: 40 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 16  0  3  0 11  0  3  6 15  0  6  0 10  6  0  3  0  0  6 10  6  3
  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8  1  8  0  3
 14 16  0 25  1  3  8  8  0] -> size -> 57 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 23. 29.  8.  0.  8.  2.  1.  3.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  1. 25.  3. 29.] 
adversary cards in discard: [29.  0. 29. 15. 10.  0. 25. 25.  0. 11. 10. 25. 29. 29.  1. 11.  0.  8.
 25.  3.  0. 10.  0. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 29 10 25 25 29  8 10 25
 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1  8  0  1] -> size -> 47 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  1. 25.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[29.218012]
 [34.09088 ]
 [32.077568]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 25.  3. 29.] 
cards in discard: [29.  0. 29. 15. 10.  0. 25. 25.  0. 11. 10. 25. 29. 29.  1. 11.  0.  8.
 25.  3.  0. 10.  0. 29. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 29 10 25 25 29  8 10 25
 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1  8  0  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 23. 29.  8.  0.  8.  2.  1.  3.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [25. 16.  6.  3.  0.] 
adversary cards in discard: [ 1.  3. 10. 11. 14.  3.  0.  0.  8.  8. 16.  1.  3.  3.  0.  8.  4.] 
adversary owned cards: [ 3  3 16  0  3  0 11  0  3  6 15  0  6  0 10  6  0  3  0  0  6 10  6  3
  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8  1  8  0  3
 14 16  0 25  1  3  8  8  0] -> size -> 57 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 40.16026306152344



action possibilites: [-1] 
expected returns: [[54.628365]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3. 29.  8.  0.] 
cards in discard: [29.  0. 29. 15. 10.  0. 25. 25.  0. 11. 10. 25. 29. 29.  1. 11.  0.  8.
 25.  3.  0. 10.  0. 29. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 29 10 25 25 29  8 10 25
 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1  8  0  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 23. 29.  8.  0.  8.  2.  1.  3.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [25. 16.  6.  3.  0.] 
adversary cards in discard: [ 1.  3. 10. 11. 14.  3.  0.  0.  8.  8. 16.  1.  3.  3.  0.  8.  4.] 
adversary owned cards: [ 3  3 16  0  3  0 11  0  3  6 15  0  6  0 10  6  0  3  0  0  6 10  6  3
  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8  1  8  0  3
 14 16  0 25  1  3  8  8  0] -> size -> 57 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 34.09088134765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 15. -1.] 
expected returns: [[49.79976 ]
 [55.12169 ]
 [53.56894 ]
 [52.791595]
 [58.167366]
 [53.941048]
 [59.891525]
 [49.68376 ]
 [54.889793]
 [54.62835 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3. 29.  8.  0.] 
cards in discard: [29.  0. 29. 15. 10.  0. 25. 25.  0. 11. 10. 25. 29. 29.  1. 11.  0.  8.
 25.  3.  0. 10.  0. 29. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 29 10 25 25 29  8 10 25
 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1  8  0  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 21. 30. 23. 29.  8.  0.  8.  2.  1.  3.  1.  5. 10.  0. 10.  8.] 
adversary cards in hand: [25. 16.  6.  3.  0.] 
adversary cards in discard: [ 1.  3. 10. 11. 14.  3.  0.  0.  8.  8. 16.  1.  3.  3.  0.  8.  4.] 
adversary owned cards: [ 3  3 16  0  3  0 11  0  3  6 15  0  6  0 10  6  0  3  0  0  6 10  6  3
  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8  1  8  0  3
 14 16  0 25  1  3  8  8  0] -> size -> 57 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 54.62836456298828



Game is draw!



Player 0 bought cards:
Copper: 1 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 6 
Chapel: 4 
Witch: 6 
Poacher: 10 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 0.  1.  3. 29.  8.  0.] 
cards in discard: [29.  0. 29. 15. 10.  0. 25. 25.  0. 11. 10. 25. 29. 29.  1. 11.  0.  8.
 25.  3.  0. 10.  0. 29. 11. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 29 10 29 29 10 25 25 29  8 10 25
 11 10 29 29 29 10 11 25 10 25  8 10 25 15  1  8 11 11 11  1  8  0  1 29] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 23. 29.  8.  0.  8.  2.  1.  3.  0.  5. 10.  0. 10.  8.] 
adversary cards in hand: [25. 16.  6.  3.  0.] 
adversary cards in discard: [ 1.  3. 10. 11. 14.  3.  0.  0.  8.  8. 16.  1.  3.  3.  0.  8.  4.] 
adversary owned cards: [ 3  3 16  0  3  0 11  0  3  6 15  0  6  0 10  6  0  3  0  0  6 10  6  3
  6  8  4  6  0  6  0  0  3  1  6 14  0 14  1 11  0 14  1  8  1  8  0  3
 14 16  0 25  1  3  8  8  0] -> size -> 57 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0 -130    0    0
   64    0] 
sum of rewards: -51 

action type: buy - action 29.0
Learning step: -4.4356608390808105
desired expected reward: 55.45585632324219



