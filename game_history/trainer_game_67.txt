 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[315.42953]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    0  -40    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -545 

action type: buy - action -1
Learning step: -28.944442749023438
desired expected reward: 4.944423675537109





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[294.69034]
 [305.75482]
 [301.98273]
 [271.3479 ]
 [314.18295]
 [303.48294]
 [301.57083]
 [318.7106 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.157511711120605
desired expected reward: 310.0028381347656



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.  3.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.  3.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.  3.  0.  0.  0.  3. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[364.68073]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [3. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -7.825663089752197
desired expected reward: 310.8849182128906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[335.63144]
 [348.88593]
 [344.41296]
 [308.81424]
 [342.2432 ]
 [358.5608 ]
 [346.0196 ]
 [347.47678]
 [322.16772]
 [343.5633 ]
 [336.9387 ]
 [363.64377]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [3. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -10.50900936126709
desired expected reward: 354.3739318847656



buy possibilites: [-1] 
expected returns: [[290.2939]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 3.  0.  0.  3.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   3.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 2.5 

action type: buy - action 10.0
Learning step: -10.5215482711792
desired expected reward: 333.04168701171875






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  3.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[290.31287]
 [276.14606]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0. 10.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 10.  0. 14.  0.] 
adversary cards in discard: [16.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -8.191061019897461
desired expected reward: 282.10284423828125



action possibilites: [-1.] 
expected returns: [[306.9066]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 10.  0. 14.  0.] 
adversary cards in discard: [16.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action 10.0
Learning step: -6.007894039154053
desired expected reward: 270.2579345703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[279.76553]
 [287.66006]
 [254.46175]
 [289.6478 ]
 [304.3999 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 10.  0. 14.  0.] 
adversary cards in discard: [16.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1.0
Learning step: -7.929046630859375
desired expected reward: 298.9775390625



buy possibilites: [-1] 
expected returns: [[325.82657]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8.  9.  9. 10. 10. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 10.  0. 14.  0.] 
adversary cards in discard: [16.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -10.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -293.0 

action type: buy - action 6.0
Learning step: -20.041990280151367
desired expected reward: 234.4197235107422






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [ 3. 10.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0. 14.  0.] 
cards in discard: [16.  0.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9.  9. 10. 10. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 6. 10.  0.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6] -> size -> 12 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0. 14.  0.] 
cards in discard: [16.  0.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8.  9.  9. 10. 10. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 6. 10.  0.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6] -> size -> 12 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0. 14.  0.] 
cards in discard: [16.  0.  3.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8.  9.  9. 10. 10. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 6. 10.  0.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6] -> size -> 12 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[326.0417]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 6. 10.  0.  3.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9.  9. 10. 10. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -9.601560592651367
desired expected reward: 316.2250061035156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[297.45343]
 [311.81998]
 [307.01974]
 [279.26575]
 [270.30762]
 [304.53537]
 [323.17392]
 [308.61304]
 [334.90833]
 [310.18195]
 [284.10468]
 [292.58527]
 [306.1667 ]
 [278.00214]
 [299.04034]
 [328.35892]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 6. 10.  0.  3.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 30. 30.  8.  9.  9. 10. 10. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -9.937843322753906
desired expected reward: 316.2740783691406



buy possibilites: [-1] 
expected returns: [[280.533]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 6. 10.  0.  3.  3.  0.  3. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 25] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9.  9. 10. 10.  9. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0  50   0] 
sum of rewards: 37 

action type: buy - action 25.0
Learning step: -8.583426475524902
desired expected reward: 326.3249206542969






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [ 0. 16.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9.  9. 10. 10.  9. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 25] -> size -> 13 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8.  9.  9. 10. 10.  9. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 25] -> size -> 13 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  0.  3.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8.  9.  9. 10. 10.  9. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 25] -> size -> 13 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [ 3.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[312.87952]
 [294.90808]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 25] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9.  9. 10. 10.  9. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  0.  0.  3.  3.] 
adversary cards in discard: [ 0.  0. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -7.7741594314575195
desired expected reward: 272.7588195800781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[286.60974]
 [296.65912]
 [293.67926]
 [262.71295]
 [305.68192]
 [294.36023]
 [293.52625]
 [311.56985]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 25] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8.  9.  9. 10. 10.  9. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  0.  0.  3.  3.] 
adversary cards in discard: [ 0.  0. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -9.582869529724121
desired expected reward: 303.4870910644531



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [10.  0.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3.  3.] 
cards in discard: [ 0.  0. 16.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9.  9. 10. 10.  9. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [25.  0.  0.  0.  3.] 
adversary cards in discard: [ 3.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 25] -> size -> 13 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 0.  0. 16.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9.  9. 10. 10.  9. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [25.  0.  0.  0.  3.] 
adversary cards in discard: [ 3.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 25] -> size -> 13 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 0.  0. 16.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8.  9.  9. 10. 10.  9. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [25.  0.  0.  0.  3.] 
adversary cards in discard: [ 3.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 25] -> size -> 13 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 0.  0. 16.  0.  0.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9.  9. 10. 10.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [25.  0.  0.  0.  3.] 
adversary cards in discard: [ 3.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 25] -> size -> 13 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [25.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[303.9596]
 [308.9889]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.  0.  3.] 
cards in discard: [ 3.  0. 10.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 25] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9.  9. 10. 10.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0 10] -> size -> 16 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1.0
Learning step: -9.306069374084473
desired expected reward: 302.2637634277344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[278.2265 ]
 [290.2668 ]
 [286.60376]
 [251.9538 ]
 [299.24637]
 [287.4717 ]
 [285.6535 ]
 [303.46964]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0.  0.  3.] 
cards in discard: [ 3.  0. 10.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 25] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8.  9.  9. 10. 10.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0 10] -> size -> 16 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -9.324055671691895
desired expected reward: 295.03802490234375



buy possibilites: [-1] 
expected returns: [[295.69662]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0.  0.  3.] 
cards in discard: [ 3.  0. 10.  0.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 25  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8.  9.  9. 10.  9.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0 10] -> size -> 16 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -11.0 

action type: buy - action 8.0
Learning step: -7.868615627288818
desired expected reward: 279.6030578613281






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [10.  0.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0. 14.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9.  9. 10.  9.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 25  8] -> size -> 14 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0. 14.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8.  9.  9. 10.  9.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 25  8] -> size -> 14 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0. 14.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0 10  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 30. 30. 30. 30.  8.  9.  9. 10.  9.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 25  8] -> size -> 14 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [0. 8. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[311.41922]
 [295.30292]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 25  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8.  9.  9. 10.  9.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10. 16.  0.  0.] 
adversary cards in discard: [ 0. 10.  0.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0 10  0] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -8.561050415039062
desired expected reward: 287.13555908203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[289.94128]
 [296.94727]
 [269.33417]
 [297.6222 ]
 [313.97482]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 25  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 30. 30.  8.  9.  9. 10.  9.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10. 16.  0.  0.] 
adversary cards in discard: [ 0. 10.  0.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0 10  0] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -9.465749740600586
desired expected reward: 301.7351989746094



buy possibilites: [-1] 
expected returns: [[277.03906]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 3. 0.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 25  8  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 30. 30. 30. 30.  8.  9.  9. 10.  9.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10. 16.  0.  0.] 
adversary cards in discard: [ 0. 10.  0.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0 10  0] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -10.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -43.0 

action type: buy - action 0.0
Learning step: -10.41368579864502
desired expected reward: 279.527587890625






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [ 0. 10. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 16.  0.  0.] 
cards in discard: [ 0. 10.  0.  0.  0. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0 10  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 30.  8.  9.  9. 10.  9.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 25.  0.] 
adversary cards in discard: [0. 0. 8. 6. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 25  8  0] -> size -> 15 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 16.  0.  0.] 
cards in discard: [ 0. 10.  0.  0.  0. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0 10  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 30. 30.  8.  9.  9. 10.  9.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 25.  0.] 
adversary cards in discard: [0. 0. 8. 6. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 25  8  0] -> size -> 15 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 16.  0.  0.] 
cards in discard: [ 0. 10.  0.  0.  0. 14.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0 10  0  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8.  9.  9. 10.  9.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 25.  0.] 
adversary cards in discard: [0. 0. 8. 6. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 25  8  0] -> size -> 15 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [ 3.  3.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[259.6078 ]
 [263.77634]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 25.  0.] 
cards in discard: [0. 0. 8. 6. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 25  8  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8.  9.  9. 10.  9.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 0. 10.  0.  0.  0. 14.  1.  0. 10. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0 10  0  1] -> size -> 18 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -8.653005599975586
desired expected reward: 268.38604736328125



action possibilites: [-1] 
expected returns: [[299.53714]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0. 0.] 
cards in discard: [0. 0. 8. 6. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 25  8  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8.  8.  9. 10.  9.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 0. 10.  0.  0.  0. 14.  1.  0. 10. 16.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0 10  0  1  6] -> size -> 19 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   2] 
sum of rewards: 9 

action type: take_action - action 25.0
Learning step: -5.874917030334473
desired expected reward: 255.4151153564453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[277.57635]
 [288.15085]
 [284.07138]
 [254.88617]
 [282.81296]
 [295.2279 ]
 [286.00143]
 [286.96814]
 [266.3752 ]
 [283.41428]
 [278.06616]
 [298.83472]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0. 0.] 
cards in discard: [0. 0. 8. 6. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 25  8  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 30. 30.  8.  8.  9. 10.  9.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 0. 10.  0.  0.  0. 14.  1.  0. 10. 16.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0 10  0  1  6] -> size -> 19 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action -1
Learning step: -8.169231414794922
desired expected reward: 291.367919921875



buy possibilites: [-1] 
expected returns: [[300.74026]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0. 0.] 
cards in discard: [ 0.  0.  8.  6.  3.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 25  8  0 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 30. 30.  8.  8.  9.  9.  9.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 0. 10.  0.  0.  0. 14.  1.  0. 10. 16.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0 10  0  1  6] -> size -> 19 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5.    0.    2.  -10.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: 11.5 

action type: buy - action 11.0
Learning step: -7.419739723205566
desired expected reward: 287.80816650390625






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 0. 10.  0.  0.  0. 14.  1.  0. 10. 16.  0.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0 10  0  1  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8.  8.  9.  9.  9.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 25  8  0 11] -> size -> 16 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 0. 10.  0.  0.  0. 14.  1.  0. 10. 16.  0.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0 10  0  1  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 30. 30.  8.  8.  9.  9.  9.  9. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 25  8  0 11] -> size -> 16 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 0. 10.  0.  0.  0. 14.  1.  0. 10. 16.  0.  0.  6. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0 10  0  1  6 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8.  8.  9.  9.  9.  9. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 25  8  0 11] -> size -> 16 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [ 3.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[190.74591]
 [173.2714 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 25  8  0 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8.  8.  9.  9.  9.  9. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0 10  0  1  6 10] -> size -> 20 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: -11.070356369018555
desired expected reward: 289.669921875



action possibilites: [-1.  8.] 
expected returns: [[191.06601]
 [177.88828]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  6 25  8  0 11] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8.  8.  9.  9.  9.  9. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0 10  0  1  6 10] -> size -> 20 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action 10.0
Learning step: -3.5244710445404053
desired expected reward: 167.87777709960938



action possibilites: [-1.] 
expected returns: [[217.12361]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8.  8.  9.  9.  9.  9. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0 10  0  1  6 10] -> size -> 20 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 26 

action type: trash_cards_n_from_hand - action 1
Learning step: -3.655809164047241
desired expected reward: 193.16600036621094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[199.06894]
 [211.43636]
 [205.86697]
 [172.7084 ]
 [218.30786]
 [209.0232 ]
 [204.78468]
 [219.69025]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 30. 30.  8.  8.  9.  9.  9.  9. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0 10  0  1  6 10] -> size -> 20 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 26 

action type: take_action - action -1.0
Learning step: -4.841821670532227
desired expected reward: 212.2817840576172



buy possibilites: [-1] 
expected returns: [[173.61905]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8.  8.  9.  9.  9.  9. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0 10  0  1  6 10] -> size -> 20 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  40   0   0   0   0   0   0   0  18   0] 
sum of rewards: 44 

action type: buy - action 1.0
Learning step: -4.465388774871826
desired expected reward: 206.970947265625






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0 10  0  1  6 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8.  8.  9.  9.  9.  9. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11.  6.  0. 25.] 
adversary cards in discard: [ 1. 10.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1] -> size -> 16 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0 10  0  1  6 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 28. 30. 30. 30.  8.  8.  9.  9.  9.  9. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11.  6.  0. 25.] 
adversary cards in discard: [ 1. 10.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1] -> size -> 16 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0 10  0  1  6 10  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 28. 30. 29. 30.  8.  8.  9.  9.  9.  9. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11.  6.  0. 25.] 
adversary cards in discard: [ 1. 10.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1] -> size -> 16 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [ 0. 11.  6.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[227.67854]
 [223.80972]
 [231.5708 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6.  0. 25.] 
cards in discard: [ 1. 10.  8.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  8.  9.  9.  9.  9. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [10.  1.  0.  0. 10.] 
adversary cards in discard: [3. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0 10  0  1  6 10  3] -> size -> 21 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -4.84596586227417
desired expected reward: 168.77308654785156



action possibilites: [-1] 
expected returns: [[253.75156]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6.  0.  3.  0.] 
cards in discard: [ 1. 10.  8.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  7.  9.  9.  9.  9. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [10.  1.  0.  0. 10.] 
adversary cards in discard: [3. 0. 0. 0. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0 10  0  1  6 10  3  6] -> size -> 22 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -3 

action type: take_action - action 25.0
Learning step: -5.7648396492004395
desired expected reward: 220.7201385498047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[237.74353]
 [246.68637]
 [243.62434]
 [218.7374 ]
 [253.70538]
 [244.9105 ]
 [243.44055]
 [257.16794]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  6.  0.  3.  0.] 
cards in discard: [ 1. 10.  8.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 29. 30.  8.  7.  9.  9.  9.  9. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [10.  1.  0.  0. 10.] 
adversary cards in discard: [3. 0. 0. 0. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0 10  0  1  6 10  3  6] -> size -> 22 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1
Learning step: -7.3195648193359375
desired expected reward: 246.43199157714844



buy possibilites: [-1] 
expected returns: [[276.18924]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  6.  0.  3.  0.] 
cards in discard: [ 1. 10.  8.  0.  0.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  7.  9.  9.  9.  9. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [10.  1.  0.  0. 10.] 
adversary cards in discard: [3. 0. 0. 0. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0 10  0  1  6 10  3  6] -> size -> 22 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: 14 

action type: buy - action 1.0
Learning step: -4.834226131439209
desired expected reward: 230.1354522705078






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [10.  1.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  0.  0. 10.] 
cards in discard: [3. 0. 0. 0. 0. 3. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0 10  0  1  6 10  3  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  7.  9.  9.  9.  9. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1] -> size -> 17 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0. 10.  0.] 
cards in discard: [3. 0. 0. 0. 0. 3. 6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0 10  0  1  6 10  3  6] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  7.  9.  9.  9.  9. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1] -> size -> 17 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [3. 0. 0. 0. 0. 3. 6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0 10  0  1  6 10  3  6] -> size -> 22 
action values: 3 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  7.  9.  9.  9.  9. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1] -> size -> 17 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [3. 0. 0. 0. 0. 3. 6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0 10  0  1  6 10  3  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 27. 30. 29. 30.  8.  7.  9.  9.  9.  9. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1] -> size -> 17 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [ 3.  0.  0.  0.  0.  3.  6. 23.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0 10  0  1  6 10  3  6 23] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  7.  9.  9.  9.  9. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1] -> size -> 17 
adversary victory points: 1
player victory points: 2 





Player: 0 
cards in hand: [ 3. 10.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[159.31062]
 [144.12785]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  7.  9.  9.  9.  9. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 6.  0. 14. 10.  3.] 
adversary cards in discard: [ 3.  0.  0.  0.  0.  3.  6. 23. 10. 10.  1.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0 10  0  1  6 10  3  6 23] -> size -> 23 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1
Learning step: -11.046161651611328
desired expected reward: 265.14306640625



action possibilites: [-1. 11.] 
expected returns: [[176.1367 ]
 [171.86613]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8.  7.  9.  9.  9.  9. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 6.  0. 14. 10.  3.] 
adversary cards in discard: [ 3.  0.  0.  0.  0.  3.  6. 23. 10. 10.  1.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0 10  0  1  6 10  3  6 23] -> size -> 23 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: take_action - action 10.0
Learning step: -2.9720935821533203
desired expected reward: 141.0614776611328



action possibilites: [-1.] 
expected returns: [[187.69894]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 30.  8.  7.  9.  9.  9.  9. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 6.  0. 14. 10.  3.] 
adversary cards in discard: [ 3.  0.  0.  0.  0.  3.  6. 23. 10. 10.  1.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0 10  0  1  6 10  3  6 23] -> size -> 23 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 40  0  0  0  0  0  0  0  4  0] 
sum of rewards: 41 

action type: gain_card_n - action 2
Learning step: -1.070320963859558
desired expected reward: 145.8006134033203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[166.33463]
 [172.26672]
 [144.45421]
 [174.6132 ]
 [185.92891]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 28. 30.  8.  7.  9.  9.  9.  9. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 6.  0. 14. 10.  3.] 
adversary cards in discard: [ 3.  0.  0.  0.  0.  3.  6. 23. 10. 10.  1.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0 10  0  1  6 10  3  6 23] -> size -> 23 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: take_action - action -1.0
Learning step: -3.6214680671691895
desired expected reward: 184.0774688720703






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 6.  0. 14. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 14. 10.  3.] 
cards in discard: [ 3.  0.  0.  0.  0.  3.  6. 23. 10. 10.  1.  0.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0 10  0  1  6 10  3  6 23] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 30.  8.  7.  9.  9.  9.  9. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [25.  8.  6.  0.  0.] 
adversary cards in discard: [ 3. 10. 11.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3] -> size -> 18 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 14. 10.  3.] 
cards in discard: [ 3.  0.  0.  0.  0.  3.  6. 23. 10. 10.  1.  0.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0 10  0  1  6 10  3  6 23] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 27. 30. 28. 30.  8.  7.  9.  9.  9.  9. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [25.  8.  6.  0.  0.] 
adversary cards in discard: [ 3. 10. 11.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3] -> size -> 18 
adversary victory points: 2
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [25.  8.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[186.34732]
 [190.86916]
 [170.13303]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8.  6.  0.  0.] 
cards in discard: [ 3. 10. 11.  3.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 30.  8.  7.  9.  9.  9.  9. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0 10  0  1  6 10  3  6 23] -> size -> 23 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1.0
Learning step: -5.468767166137695
desired expected reward: 180.4601593017578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[158.31258]
 [167.3284 ]
 [135.41516]
 [167.22949]
 [184.68648]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  8.  6.  0.  0.] 
cards in discard: [ 3. 10. 11.  3.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 28. 30.  8.  7.  9.  9.  9.  9. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0 10  0  1  6 10  3  6 23] -> size -> 23 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -5.278087139129639
desired expected reward: 173.46249389648438



buy possibilites: [-1] 
expected returns: [[179.58795]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  8.  6.  0.  0.] 
cards in discard: [ 3. 10. 11.  3.  0.  3.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 30.  8.  7.  9.  9.  8.  9. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0 10  0  1  6 10  3  6 23] -> size -> 23 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 5 

action type: buy - action 8.0
Learning step: -4.070745944976807
desired expected reward: 163.15875244140625






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 3. 14.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  0.  0. 16.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 14 16  0  0 10  0  1  6 10  3  6 23] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 30.  8.  7.  9.  9.  8.  9. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [1. 0. 1. 0. 0.] 
adversary cards in discard: [ 3. 10. 11.  3.  0.  3.  0.  8. 25.  8.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3  8] -> size -> 19 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.] 
cards in discard: [3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  7.  9.  9.  8.  9. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [1. 0. 1. 0. 0.] 
adversary cards in discard: [ 3. 10. 11.  3.  0.  3.  0.  8. 25.  8.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3  8] -> size -> 19 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.] 
cards in discard: [3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 27. 30.  8.  7.  9.  9.  8.  9. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [1. 0. 1. 0. 0.] 
adversary cards in discard: [ 3. 10. 11.  3.  0.  3.  0.  8. 25.  8.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3  8] -> size -> 19 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.] 
cards in discard: [3. 3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 30.  8.  7.  9.  9.  8.  9. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [1. 0. 1. 0. 0.] 
adversary cards in discard: [ 3. 10. 11.  3.  0.  3.  0.  8. 25.  8.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3  8] -> size -> 19 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [1. 0. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[119.128944]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 1. 0. 0.] 
cards in discard: [ 3. 10. 11.  3.  0.  3.  0.  8. 25.  8.  6.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 30.  8.  7.  9.  9.  8.  9. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 0.] 
adversary cards in discard: [ 3.  3. 16. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3] -> size -> 24 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -7.007541179656982
desired expected reward: 172.58041381835938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[101.87527 ]
 [110.80741 ]
 [ 98.374886]
 [107.86396 ]
 [ 90.46942 ]
 [ 85.16137 ]
 [106.251274]
 [117.28746 ]
 [108.29767 ]
 [125.04747 ]
 [108.86891 ]
 [ 93.01565 ]
 [ 98.91683 ]
 [106.71934 ]
 [ 89.91527 ]
 [102.11278 ]
 [119.75664 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 0. 0.] 
cards in discard: [ 3. 10. 11.  3.  0.  3.  0.  8. 25.  8.  6.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 7 
card supply: [26. 27. 30. 26. 30.  8.  7.  9.  9.  8.  9. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 0.] 
adversary cards in discard: [ 3.  3. 16. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3] -> size -> 24 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -3.990370988845825
desired expected reward: 112.5365982055664



buy possibilites: [-1] 
expected returns: [[183.46664]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 0. 0.] 
cards in discard: [ 3. 10. 11.  3.  0.  3.  0.  8. 25.  8.  6.  0.  0. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3  8 25] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 27. 30. 26. 30.  8.  7.  9.  9.  8.  8. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 0.] 
adversary cards in discard: [ 3.  3. 16. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3] -> size -> 24 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5.    0.    2.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.   12.5   0. ] 
sum of rewards: -0.5 

action type: buy - action 25.0
Learning step: -2.149374008178711
desired expected reward: 122.8980941772461






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [0. 3. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 0. 0.] 
cards in discard: [ 3.  3. 16. 14.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 30.  8.  7.  9.  9.  8.  8. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3  8 25] -> size -> 20 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 0.] 
cards in discard: [ 3.  3. 16. 14.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 27. 30. 26. 30.  8.  7.  9.  9.  8.  8. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3  8 25] -> size -> 20 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 0.] 
cards in discard: [ 3.  3. 16. 14.  0.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 27. 30. 25. 30.  8.  7.  9.  9.  8.  8. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3  8 25] -> size -> 20 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[149.14432]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3  8 25] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 30.  8.  7.  9.  9.  8.  8. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 10. 10.] 
adversary cards in discard: [ 3.  3. 16. 14.  0.  0.  3.  0.  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3
  3] -> size -> 25 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -7.043872833251953
desired expected reward: 176.4227752685547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[142.1989 ]
 [149.15204]
 [145.95105]
 [127.02611]
 [145.56917]
 [153.46712]
 [147.95677]
 [148.55972]
 [134.58768]
 [145.71687]
 [142.2577 ]
 [154.966  ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3  8 25] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 27. 30. 25. 30.  8.  7.  9.  9.  8.  8. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 10. 10.] 
adversary cards in discard: [ 3.  3. 16. 14.  0.  0.  3.  0.  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3
  3] -> size -> 25 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -5.11065149307251
desired expected reward: 140.64309692382812



buy possibilites: [-1] 
expected returns: [[188.17258]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3  8 25  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 27. 30. 25. 30.  8.  7.  9.  9.  7.  8. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 10. 10.] 
adversary cards in discard: [ 3.  3. 16. 14.  0.  0.  3.  0.  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3
  3] -> size -> 25 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -20.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -21.0 

action type: buy - action 8.0
Learning step: -4.213956356048584
desired expected reward: 143.74282836914062






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10. 10.] 
cards in discard: [ 3.  3. 16. 14.  0.  0.  3.  0.  3.  1.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 30.  8.  7.  9.  9.  7.  8. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 3. 25.  3. 10.  8.] 
adversary cards in discard: [8. 0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3  8 25  8] -> size -> 21 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10. 10.] 
cards in discard: [ 3.  3. 16. 14.  0.  0.  3.  0.  3.  1.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 25. 30.  8.  7.  9.  9.  7.  8. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 3. 25.  3. 10.  8.] 
adversary cards in discard: [8. 0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3  8 25  8] -> size -> 21 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10. 10.] 
cards in discard: [ 3.  3. 16. 14.  0.  0.  3.  0.  3.  1.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3
  3  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 27. 30. 25. 30.  8.  7.  9.  9.  7.  8. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 3. 25.  3. 10.  8.] 
adversary cards in discard: [8. 0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3  8 25  8] -> size -> 21 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [ 3. 25.  3. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.  8.] 
expected returns: [[160.74057]
 [161.48727]
 [144.85571]
 [144.97267]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  3. 10.  8.] 
cards in discard: [8. 0. 3. 0. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3  8 25  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 25. 30.  8.  7.  9.  9.  7.  8. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [23.  3.  0.  0.  6.] 
adversary cards in discard: [ 3.  3. 16. 14.  0.  0.  3.  0.  3.  1.  0.  0.  0.  0.  3.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3
  3  0] -> size -> 26 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -7.094519138336182
desired expected reward: 181.07806396484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[135.10484]
 [116.68105]
 [157.70648]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25.  3. 10.  8.] 
cards in discard: [8. 0. 3. 0. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3  8 25  8] -> size -> 21 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 27. 30. 25. 30.  8.  7.  9.  9.  7.  8. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [23.  3.  0.  0.  6.] 
adversary cards in discard: [ 3.  3. 16. 14.  0.  0.  3.  0.  3.  1.  0.  0.  0.  0.  3.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3
  3  0] -> size -> 26 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -5.593912124633789
desired expected reward: 147.5991668701172



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [23.  3.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  3.  0.  0.  6.] 
cards in discard: [ 3.  3. 16. 14.  0.  0.  3.  0.  3.  1.  0.  0.  0.  0.  3.  0. 10. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3
  3  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 25. 30.  8.  7.  9.  9.  7.  8. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 0. 11.  8.  6.  1.] 
adversary cards in discard: [ 8.  0.  3.  0.  0.  0.  3. 25.  3. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3  8 25  8] -> size -> 21 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  3.  0.  0.  6.] 
cards in discard: [ 3.  3. 16. 14.  0.  0.  3.  0.  3.  1.  0.  0.  0.  0.  3.  0. 10. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3
  3  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 27. 30. 25. 30.  8.  7.  9.  9.  7.  8. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 0. 11.  8.  6.  1.] 
adversary cards in discard: [ 8.  0.  3.  0.  0.  0.  3. 25.  3. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3  8 25  8] -> size -> 21 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  3.  0.  0.  6.] 
cards in discard: [ 3.  3. 16. 14.  0.  0.  3.  0.  3.  1.  0.  0.  0.  0.  3.  0. 10. 10.
  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3
  3  0  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 25. 30.  8.  7.  9.  9.  6.  8. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 0. 11.  8.  6.  1.] 
adversary cards in discard: [ 8.  0.  3.  0.  0.  0.  3. 25.  3. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3  8 25  8] -> size -> 21 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [ 0. 11.  8.  6.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[108.43139 ]
 [105.47933 ]
 [ 96.877174]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8.  6.  1.] 
cards in discard: [ 8.  0.  3.  0.  0.  0.  3. 25.  3. 10.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3  8 25  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 25. 30.  8.  7.  9.  9.  6.  8. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3
  3  0  8] -> size -> 27 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1.0
Learning step: -6.671459197998047
desired expected reward: 151.03501892089844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 95.06682 ]
 [103.652435]
 [101.006775]
 [ 76.73862 ]
 [110.01403 ]
 [101.41188 ]
 [100.06305 ]
 [112.96608 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  8.  6.  1.] 
cards in discard: [ 8.  0.  3.  0.  0.  0.  3. 25.  3. 10.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3  8 25  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 27. 30. 25. 30.  8.  7.  9.  9.  6.  8. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3
  3  0  8] -> size -> 27 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -4.231395244598389
desired expected reward: 104.19996643066406



buy possibilites: [-1] 
expected returns: [[113.17326]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  8.  6.  1.] 
cards in discard: [ 8.  0.  3.  0.  0.  0.  3. 25.  3. 10.  8.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3  8 25  8  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 25. 30.  8.  7.  9.  9.  5.  8. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3
  3  0  8] -> size -> 27 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -20.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -21.0 

action type: buy - action 8.0
Learning step: -3.574195146560669
desired expected reward: 97.83767700195312






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  6. 10.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3
  3  0  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 25. 30.  8.  7.  9.  9.  5.  8. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 0. 25.  1.  0.  0.] 
adversary cards in discard: [ 8.  0.  3.  0.  0.  0.  3. 25.  3. 10.  8.  8.  0. 11.  8.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3  8 25  8  8] -> size -> 22 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  6. 10.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3
  3  0  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 27. 30. 25. 30.  8.  7.  9.  9.  5.  8. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 0. 25.  1.  0.  0.] 
adversary cards in discard: [ 8.  0.  3.  0.  0.  0.  3. 25.  3. 10.  8.  8.  0. 11.  8.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3  8 25  8  8] -> size -> 22 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  6. 10.] 
cards in discard: [0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3
  3  0  8  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 27. 30. 25. 30.  8.  7.  9.  9.  5.  8. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 0. 25.  1.  0.  0.] 
adversary cards in discard: [ 8.  0.  3.  0.  0.  0.  3. 25.  3. 10.  8.  8.  0. 11.  8.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3  8 25  8  8] -> size -> 22 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [ 0. 25.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[123.424095]
 [131.25786 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  1.  0.  0.] 
cards in discard: [ 8.  0.  3.  0.  0.  0.  3. 25.  3. 10.  8.  8.  0. 11.  8.  6.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3  8 25  8  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 25. 30.  8.  7.  9.  9.  5.  8. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  0. 10.  0.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3
  3  0  8  0] -> size -> 28 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -3.9167962074279785
desired expected reward: 109.2564697265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[100.62877 ]
 [110.72919 ]
 [106.846436]
 [ 86.31673 ]
 [ 79.24701 ]
 [105.699005]
 [116.92906 ]
 [108.54058 ]
 [125.7013  ]
 [109.15167 ]
 [ 89.68827 ]
 [ 96.419235]
 [105.90442 ]
 [ 85.26071 ]
 [100.62538 ]
 [118.89559 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  1.  0.  0.] 
cards in discard: [ 8.  0.  3.  0.  0.  0.  3. 25.  3. 10.  8.  8.  0. 11.  8.  6.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3  8 25  8  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 27. 30. 25. 30.  8.  7.  9.  9.  5.  8. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  0. 10.  0.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3
  3  0  8  0] -> size -> 28 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -4.850373268127441
desired expected reward: 118.5737075805664



buy possibilites: [-1] 
expected returns: [[65.66286]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  1.  0.  0.] 
cards in discard: [ 8.  0.  3.  0.  0.  0.  3. 25.  3. 10.  8.  8.  0. 11.  8.  6.  1. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3  8 25  8  8 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 27. 30. 25. 30.  8.  7.  9.  8.  5.  8. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  0. 10.  0.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3
  3  0  8  0] -> size -> 28 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5.    0.    2.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -18.5 

action type: buy - action 11.0
Learning step: -5.294038772583008
desired expected reward: 111.63502502441406






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 0.  0. 10.  0.  6. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3
  3  0  8  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 25. 30.  8.  7.  9.  8.  5.  8. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 25. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3  8 25  8  8 11] -> size -> 23 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 0.  0. 10.  0.  6. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3
  3  0  8  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 27. 30. 25. 30.  8.  7.  9.  8.  5.  8. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 25. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3  8 25  8  8 11] -> size -> 23 
adversary victory points: 2
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  0. 25. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[122.74556 ]
 [127.9024  ]
 [120.661125]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25. 11.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3  8 25  8  8 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 25. 30.  8.  7.  9.  8.  5.  8. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 0.  8.  3.  0. 16.] 
adversary cards in discard: [ 0.  0. 10.  0.  6. 10.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3
  3  0  8  0] -> size -> 28 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -1.6950763463974
desired expected reward: 63.96778106689453



action possibilites: [-1] 
expected returns: [[182.3473]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3  8 25  8  8 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 25. 30.  8.  6.  9.  8.  5.  8. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 0.  8.  3.  0. 16.] 
adversary cards in discard: [ 0.  0. 10.  0.  6. 10.  3.  3.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3
  3  0  8  0  6] -> size -> 29 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   2] 
sum of rewards: -1 

action type: take_action - action 25.0
Learning step: -2.176687717437744
desired expected reward: 122.41334533691406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[175.6578 ]
 [181.22221]
 [179.48766]
 [163.47438]
 [178.36766]
 [185.57973]
 [180.1366 ]
 [180.75723]
 [170.52464]
 [179.38518]
 [176.8115 ]
 [188.65166]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3  8 25  8  8 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 27. 30. 25. 30.  8.  6.  9.  8.  5.  8. 10.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 0.  8.  3.  0. 16.] 
adversary cards in discard: [ 0.  0. 10.  0.  6. 10.  3.  3.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3
  3  0  8  0  6] -> size -> 29 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: take_action - action -1
Learning step: -5.184467315673828
desired expected reward: 177.162841796875



buy possibilites: [-1] 
expected returns: [[95.30124]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3.  0.  0.] 
cards in discard: [10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3  8 25  8  8 11 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 25. 30.  8.  6.  9.  8.  5.  8. 10.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  8.  3.  0. 16.] 
adversary cards in discard: [ 0.  0. 10.  0.  6. 10.  3.  3.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3
  3  0  8  0  6] -> size -> 29 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5.    0.    2.  -20.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: 1.5 

action type: buy - action 10.0
Learning step: -6.749980926513672
desired expected reward: 172.63519287109375






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  3.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  3.  0. 16.] 
cards in discard: [ 0.  0. 10.  0.  6. 10.  3.  3.  0.  0.  0.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3
  3  0  8  0  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 25. 30.  8.  6.  9.  8.  5.  8. 10.  9.  9.  5. 10. 10.] 
adversary cards in hand: [8. 8. 0. 1. 3.] 
adversary cards in discard: [10. 25.  0.  0. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3  8 25  8  8 11 10] -> size -> 24 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0.] 
cards in discard: [ 0.  0. 10.  0.  6. 10.  3.  3.  0.  0.  0.  6. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 25. 30.  8.  6.  9.  8.  5.  8.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [8. 8. 0. 1. 3.] 
adversary cards in discard: [10. 25.  0.  0. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3  8 25  8  8 11 10] -> size -> 24 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [ 0.  0. 10.  0.  6. 10.  3.  3.  0.  0.  0.  6. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 27. 30. 25. 30.  8.  6.  9.  8.  5.  8.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [8. 8. 0. 1. 3.] 
adversary cards in discard: [10. 25.  0.  0. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3  8 25  8  8 11 10] -> size -> 24 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [ 0.  0. 10.  0.  6. 10.  3.  3.  0.  0.  0.  6. 29.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 25. 30.  8.  6.  9.  8.  4.  8.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [8. 8. 0. 1. 3.] 
adversary cards in discard: [10. 25.  0.  0. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3  8 25  8  8 11 10] -> size -> 24 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [8. 8. 0. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[71.1211  ]
 [58.454674]
 [58.454674]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 1. 3.] 
cards in discard: [10. 25.  0.  0. 11.  3.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  8  0 11  1  1  3  8 25  8  8 11 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 25. 30.  8.  6.  9.  8.  4.  8.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0. 14.  1.  3.  0.] 
adversary cards in discard: [ 0.  0. 10.  0.  6. 10.  3.  3.  0.  0.  0.  6. 29.  8. 16.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8] -> size -> 30 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: -3.4472815990448
desired expected reward: 91.85395812988281



action possibilites: [-1] 
expected returns: [[40.23154]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3.] 
cards in discard: [10. 25.  0.  0. 11.  3.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 25. 30.  8.  6.  9.  8.  4.  8.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0. 14.  1.  3.  0.] 
adversary cards in discard: [ 0.  0. 10.  0.  6. 10.  3.  3.  0.  0.  0.  6. 29.  8. 16.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8] -> size -> 30 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: trash_cards_n_from_hand - action 2
Learning step: -0.8714038729667664
desired expected reward: 51.66086959838867





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[27.256535]
 [32.631596]
 [32.370804]
 [17.212196]
 [38.469418]
 [30.925442]
 [31.957142]
 [41.94334 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3.] 
cards in discard: [10. 25.  0.  0. 11.  3.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 27. 30. 25. 30.  8.  6.  9.  8.  4.  8.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0. 14.  1.  3.  0.] 
adversary cards in discard: [ 0.  0. 10.  0.  6. 10.  3.  3.  0.  0.  0.  6. 29.  8. 16.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8] -> size -> 30 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1
Learning step: -0.38014814257621765
desired expected reward: 39.85139083862305



buy possibilites: [-1] 
expected returns: [[42.020786]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3.] 
cards in discard: [10. 25.  0.  0. 11.  3.  0.  0.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 25. 30.  8.  6.  9.  8.  3.  8.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0. 14.  1.  3.  0.] 
adversary cards in discard: [ 0.  0. 10.  0.  6. 10.  3.  3.  0.  0.  0.  6. 29.  8. 16.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8] -> size -> 30 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5.  0.  2.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 19.0 

action type: buy - action 8.0
Learning step: 0.35525208711624146
desired expected reward: 31.28070831298828






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 0. 14.  1.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  1.  3.  0.] 
cards in discard: [ 0.  0. 10.  0.  6. 10.  3.  3.  0.  0.  0.  6. 29.  8. 16.  0.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 25. 30.  8.  6.  9.  8.  3.  8.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0. 11.  1. 10.  6.] 
adversary cards in discard: [10. 25.  0.  0. 11.  3.  0.  0.  8.  8.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8] -> size -> 24 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 0.] 
cards in discard: [ 0.  0. 10.  0.  6. 10.  3.  3.  0.  0.  0.  6. 29.  8. 16.  0.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 27. 30. 25. 30.  8.  6.  9.  8.  3.  8.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [11.  1.  6.] 
adversary cards in discard: [10. 25.  0.  0. 11.  3.  0.  0.  8.  8.  0.  1.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8] -> size -> 24 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0.] 
cards in discard: [ 0.  0. 10.  0.  6. 10.  3.  3.  0.  0.  0.  6. 29.  8. 16.  0.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 6 
card supply: [24. 27. 30. 25. 30.  8.  6.  9.  8.  3.  8.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [11.  1.  6.] 
adversary cards in discard: [10. 25.  0.  0. 11.  3.  0.  0.  8.  8.  0.  1.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8] -> size -> 24 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0.] 
cards in discard: [ 0.  0. 10.  0.  6. 10.  3.  3.  0.  0.  0.  6. 29.  8. 16.  0.  8.  0.
  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 26. 30. 25. 30.  8.  6.  9.  8.  3.  8.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [11.  1.  6.] 
adversary cards in discard: [10. 25.  0.  0. 11.  3.  0.  0.  8.  8.  0.  1.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8] -> size -> 24 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [11.  1.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[101.110176]
 [ 98.69255 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  6.] 
cards in discard: [10. 25.  0.  0. 11.  3.  0.  0.  8.  8.  0.  1.  3.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 25. 30.  8.  6.  9.  8.  3.  8.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  6. 10.] 
adversary cards in discard: [ 0.  0. 10.  0.  6. 10.  3.  3.  0.  0.  0.  6. 29.  8. 16.  0.  8.  0.
  1. 14.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8  1] -> size -> 31 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: discard_down_to_3_cards - action 2
Learning step: 0.7946540713310242
desired expected reward: 27.021953582763672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 87.61838]
 [ 92.72038]
 [ 73.18931]
 [ 92.83572]
 [102.40247]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  6.] 
cards in discard: [10. 25.  0.  0. 11.  3.  0.  0.  8.  8.  0.  1.  3.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 30. 25. 30.  8.  6.  9.  8.  3.  8.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  6. 10.] 
adversary cards in discard: [ 0.  0. 10.  0.  6. 10.  3.  3.  0.  0.  0.  6. 29.  8. 16.  0.  8.  0.
  1. 14.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8  1] -> size -> 31 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -3.0998504161834717
desired expected reward: 98.01032257080078



buy possibilites: [-1] 
expected returns: [[94.58218]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  6.] 
cards in discard: [10. 25.  0.  0. 11.  3.  0.  0.  8.  8.  0.  1.  3.  0. 10.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 26. 30. 25. 30.  8.  6.  9.  8.  3.  8.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  6. 10.] 
adversary cards in discard: [ 0.  0. 10.  0.  6. 10.  3.  3.  0.  0.  0.  6. 29.  8. 16.  0.  8.  0.
  1. 14.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8  1] -> size -> 31 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -33.0 

action type: buy - action 0.0
Learning step: -3.902819871902466
desired expected reward: 83.7155532836914






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  6. 10.] 
cards in discard: [ 0.  0. 10.  0.  6. 10.  3.  3.  0.  0.  0.  6. 29.  8. 16.  0.  8.  0.
  1. 14.  0.  1.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 25. 30.  8.  6.  9.  8.  3.  8.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 8. 25.  8.  3.  0.] 
adversary cards in discard: [10. 25.  0.  0. 11.  3.  0.  0.  8.  8.  0.  1.  3.  0. 10.  0. 11.  1.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0] -> size -> 25 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  6. 10.] 
cards in discard: [ 0.  0. 10.  0.  6. 10.  3.  3.  0.  0.  0.  6. 29.  8. 16.  0.  8.  0.
  1. 14.  0.  1.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8  1] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 26. 30. 25. 30.  8.  6.  9.  8.  3.  8.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 8. 25.  8.  3.  0.] 
adversary cards in discard: [10. 25.  0.  0. 11.  3.  0.  0.  8.  8.  0.  1.  3.  0. 10.  0. 11.  1.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0] -> size -> 25 
adversary victory points: 2
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 8. 25.  8.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.  8.] 
expected returns: [[68.06968]
 [56.9768 ]
 [72.03111]
 [56.9768 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25.  8.  3.  0.] 
cards in discard: [10. 25.  0.  0. 11.  3.  0.  0.  8.  8.  0.  1.  3.  0. 10.  0. 11.  1.
  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 25. 30.  8.  6.  9.  8.  3.  8.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 6.  0. 10.  3. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8  1] -> size -> 31 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: -3.3920021057128906
desired expected reward: 91.19017028808594



action possibilites: [-1] 
expected returns: [[77.29678]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  3.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 25. 30.  8.  5.  9.  8.  3.  8.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 6.  0. 10.  3. 23.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8  1  6] -> size -> 32 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 18 

action type: take_action - action 25.0
Learning step: -0.9623781442642212
desired expected reward: 71.06873321533203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[77.282005]
 [79.141556]
 [67.194374]
 [81.38194 ]
 [83.93348 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8.  3.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 26. 30. 25. 30.  8.  5.  9.  8.  3.  8.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 6.  0. 10.  3. 23.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8  1  6] -> size -> 32 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1
Learning step: -1.2227458953857422
desired expected reward: 76.07403564453125






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 6.  0. 10.  3. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10.  3. 23.] 
cards in discard: [6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8  1  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 25. 30.  8.  5.  9.  8.  3.  8.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  8.  1.] 
adversary cards in discard: [25.  8.  8.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0] -> size -> 25 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 10.  3. 23.] 
cards in discard: [6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8  1  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 26. 30. 25. 30.  8.  5.  9.  8.  3.  8.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  8.  1.] 
adversary cards in discard: [25.  8.  8.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0] -> size -> 25 
adversary victory points: 2
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 11.  0.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[72.272896]
 [68.56405 ]
 [58.009018]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  8.  1.] 
cards in discard: [25.  8.  8.  3.  0. 10.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 25. 30.  8.  5.  9.  8.  3.  8.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  0. 16.] 
adversary cards in discard: [ 6.  6.  0. 10.  3. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8  1  6] -> size -> 32 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1.0
Learning step: -2.3144993782043457
desired expected reward: 81.6189956665039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[52.702473]
 [62.283653]
 [60.33497 ]
 [36.43286 ]
 [57.66796 ]
 [69.878746]
 [59.50268 ]
 [60.31808 ]
 [43.98992 ]
 [59.03125 ]
 [53.815983]
 [73.58759 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  8.  1.] 
cards in discard: [25.  8.  8.  3.  0. 10.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 26. 30. 25. 30.  8.  5.  9.  8.  3.  8.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  0. 16.] 
adversary cards in discard: [ 6.  6.  0. 10.  3. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8  1  6] -> size -> 32 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: take_action - action -1.0
Learning step: -1.8608436584472656
desired expected reward: 70.41204833984375



buy possibilites: [-1] 
expected returns: [[69.958244]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  8.  1.] 
cards in discard: [25.  8.  8.  3.  0. 10.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 26. 30. 24. 30.  8.  5.  9.  8.  3.  8.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  0. 16.] 
adversary cards in discard: [ 6.  6.  0. 10.  3. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8  1  6] -> size -> 32 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 20.0 

action type: buy - action 3.0
Learning step: -0.4426887631416321
desired expected reward: 59.892295837402344






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  3.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0. 16.] 
cards in discard: [ 6.  6.  0. 10.  3. 23.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8  1  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 30.  8.  5.  9.  8.  3.  8.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 1.  0.  6.  3. 11.] 
adversary cards in discard: [25.  8.  8.  3.  0. 10.  0.  3.  0. 11.  0.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3] -> size -> 26 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 16.  0.] 
cards in discard: [ 6.  6.  0. 10.  3. 23.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8  1  6] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 30.  8.  5.  9.  8.  3.  8.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 1.  0.  6.  3. 11.] 
adversary cards in discard: [25.  8.  8.  3.  0. 10.  0.  3.  0. 11.  0.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3] -> size -> 26 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 16.  0.] 
cards in discard: [ 6.  6.  0. 10.  3. 23.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8  1  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 26. 30. 24. 30.  8.  5.  9.  8.  3.  8.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 1.  0.  6.  3. 11.] 
adversary cards in discard: [25.  8.  8.  3.  0. 10.  0.  3.  0. 11.  0.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3] -> size -> 26 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 16.  0.] 
cards in discard: [ 6.  6.  0. 10.  3. 23.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8  1  6  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 26. 30. 24. 30.  8.  5.  9.  8.  3.  8.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 1.  0.  6.  3. 11.] 
adversary cards in discard: [25.  8.  8.  3.  0. 10.  0.  3.  0. 11.  0.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3] -> size -> 26 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 1.  0.  6.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[40.22356 ]
 [38.222645]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  6.  3. 11.] 
cards in discard: [25.  8.  8.  3.  0. 10.  0.  3.  0. 11.  0.  8.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8.  5.  9.  8.  3.  8.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  6.  3. 10.] 
adversary cards in discard: [ 6.  6.  0. 10.  3. 23.  0. 10.  0.  3.  0. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8  1  6  0] -> size -> 33 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: buy - action -1
Learning step: -1.7085739374160767
desired expected reward: 68.24967193603516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[30.302189]
 [34.155357]
 [33.142464]
 [23.768059]
 [38.166195]
 [33.02034 ]
 [32.7456  ]
 [40.167114]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  6.  3. 11.] 
cards in discard: [25.  8.  8.  3.  0. 10.  0.  3.  0. 11.  0.  8.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 26. 30. 24. 30.  8.  5.  9.  8.  3.  8.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  6.  3. 10.] 
adversary cards in discard: [ 6.  6.  0. 10.  3. 23.  0. 10.  0.  3.  0. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8  1  6  0] -> size -> 33 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1.0
Learning step: -0.3169548213481903
desired expected reward: 39.9066162109375



buy possibilites: [-1] 
expected returns: [[25.434387]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  6.  3. 11.] 
cards in discard: [25.  8.  8.  3.  0. 10.  0.  3.  0. 11.  0.  8.  1.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 26. 30. 23. 30.  8.  5.  9.  8.  3.  8.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  6.  3. 10.] 
adversary cards in discard: [ 6.  6.  0. 10.  3. 23.  0. 10.  0.  3.  0. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8  1  6  0] -> size -> 33 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4. 30.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 31.0 

action type: buy - action 3.0
Learning step: 0.46514949202537537
desired expected reward: 33.60763168334961






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  6.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6.  3. 10.] 
cards in discard: [ 6.  6.  0. 10.  3. 23.  0. 10.  0.  3.  0. 16.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8  1  6  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 23. 30.  8.  5.  9.  8.  3.  8.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 25.  8.] 
adversary cards in discard: [25.  8.  8.  3.  0. 10.  0.  3.  0. 11.  0.  8.  1.  3.  1.  0.  6.  3.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3] -> size -> 27 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 3. 0.] 
cards in discard: [ 6.  6.  0. 10.  3. 23.  0. 10.  0.  3.  0. 16.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8  1  6  0] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 23. 30.  8.  5.  9.  8.  3.  8.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 25.  8.] 
adversary cards in discard: [25.  8.  8.  3.  0. 10.  0.  3.  0. 11.  0.  8.  1.  3.  1.  0.  6.  3.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3] -> size -> 27 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 0.] 
cards in discard: [ 6.  6.  0. 10.  3. 23.  0. 10.  0.  3.  0. 16.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8  1  6  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 26. 30. 23. 30.  8.  5.  9.  8.  3.  8.  9.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 25.  8.] 
adversary cards in discard: [25.  8.  8.  3.  0. 10.  0.  3.  0. 11.  0.  8.  1.  3.  1.  0.  6.  3.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3] -> size -> 27 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 0.] 
cards in discard: [ 6.  6.  0. 10.  3. 23.  0. 10.  0.  3.  0. 16.  0. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8  1  6  0 10] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 23. 30.  8.  5.  9.  8.  3.  8.  9.  9.  9.  4. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 25.  8.] 
adversary cards in discard: [25.  8.  8.  3.  0. 10.  0.  3.  0. 11.  0.  8.  1.  3.  1.  0.  6.  3.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3] -> size -> 27 
adversary victory points: 4
player victory points: 1 





Player: 0 
cards in hand: [ 0.  3.  0. 25.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[60.419724]
 [66.82441 ]
 [49.21118 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 25.  8.] 
cards in discard: [25.  8.  8.  3.  0. 10.  0.  3.  0. 11.  0.  8.  1.  3.  1.  0.  6.  3.
 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 23. 30.  8.  5.  9.  8.  3.  8.  9.  9.  9.  4. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [ 6.  6.  0. 10.  3. 23.  0. 10.  0.  3.  0. 16.  0. 10. 10.  0.  0.  6.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8  1  6  0 10] -> size -> 34 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: buy - action -1
Learning step: 1.5562599897384644
desired expected reward: 26.990646362304688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[40.669495]
 [47.33043 ]
 [22.155579]
 [47.514988]
 [61.153877]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 25.  8.] 
cards in discard: [25.  8.  8.  3.  0. 10.  0.  3.  0. 11.  0.  8.  1.  3.  1.  0.  6.  3.
 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 26. 30. 23. 30.  8.  5.  9.  8.  3.  8.  9.  9.  9.  4. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [ 6.  6.  0. 10.  3. 23.  0. 10.  0.  3.  0. 16.  0. 10. 10.  0.  0.  6.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8  1  6  0 10] -> size -> 34 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: take_action - action -1.0
Learning step: -0.46776238083839417
desired expected reward: 59.951961517333984



buy possibilites: [-1] 
expected returns: [[43.179787]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 25.  8.] 
cards in discard: [25.  8.  8.  3.  0. 10.  0.  3.  0. 11.  0.  8.  1.  3.  1.  0.  6.  3.
 11.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 26. 30. 23. 30.  8.  5.  9.  8.  3.  8.  9.  9.  9.  4. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 6.] 
adversary cards in discard: [ 6.  6.  0. 10.  3. 23.  0. 10.  0.  3.  0. 16.  0. 10. 10.  0.  0.  6.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8  1  6  0 10] -> size -> 34 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4.  30.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -1.0 

action type: buy - action 0.0
Learning step: -1.090835690498352
desired expected reward: 39.57866287231445






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 6.] 
cards in discard: [ 6.  6.  0. 10.  3. 23.  0. 10.  0.  3.  0. 16.  0. 10. 10.  0.  0.  6.
  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8  1  6  0 10] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 23. 30.  8.  5.  9.  8.  3.  8.  9.  9.  9.  4. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0] -> size -> 28 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 6.] 
cards in discard: [ 6.  6.  0. 10.  3. 23.  0. 10.  0.  3.  0. 16.  0. 10. 10.  0.  0.  6.
  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8  1  6  0 10] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 26. 30. 23. 30.  8.  5.  9.  8.  3.  8.  9.  9.  9.  4. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0] -> size -> 28 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 6.] 
cards in discard: [ 6.  6.  0. 10.  3. 23.  0. 10.  0.  3.  0. 16.  0. 10. 10.  0.  0.  6.
  3.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8  1  6  0 10  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 26. 30. 23. 30.  8.  5.  9.  8.  3.  8.  9.  9.  9.  4. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0] -> size -> 28 
adversary victory points: 4
player victory points: 1 





Player: 0 
cards in hand: [11.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[46.862743]
 [45.93417 ]
 [39.658398]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 23. 30.  8.  5.  9.  8.  3.  8.  9.  9.  9.  4. 10. 10.] 
adversary cards in hand: [ 1.  3.  0.  8. 14.] 
adversary cards in discard: [ 6.  6.  0. 10.  3. 23.  0. 10.  0.  3.  0. 16.  0. 10. 10.  0.  0.  6.
  3.  0.  0.  0.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8  1  6  0 10  0] -> size -> 35 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: buy - action -1
Learning step: 0.3029020428657532
desired expected reward: 43.482688903808594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[39.906292]
 [45.60415 ]
 [43.434875]
 [28.591274]
 [48.091717]
 [44.312828]
 [42.80057 ]
 [48.835777]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 26. 30. 23. 30.  8.  5.  9.  8.  3.  8.  9.  9.  9.  4. 10. 10.] 
adversary cards in hand: [ 1.  3.  0.  8. 14.] 
adversary cards in discard: [ 6.  6.  0. 10.  3. 23.  0. 10.  0.  3.  0. 16.  0. 10. 10.  0.  0.  6.
  3.  0.  0.  0.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8  1  6  0 10  0] -> size -> 35 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: take_action - action -1.0
Learning step: 0.10938701778650284
desired expected reward: 46.972129821777344



buy possibilites: [-1] 
expected returns: [[5.131735]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0. 10.] 
cards in discard: [6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0  6] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 26. 30. 23. 30.  8.  4.  9.  8.  3.  8.  9.  9.  9.  4. 10. 10.] 
adversary cards in hand: [ 1.  3.  0.  8. 14.] 
adversary cards in discard: [ 6.  6.  0. 10.  3. 23.  0. 10.  0.  3.  0. 16.  0. 10. 10.  0.  0.  6.
  3.  0.  0.  0.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8  1  6  0 10  0] -> size -> 35 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    3.   20.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -282.0 

action type: buy - action 6.0
Learning step: -15.41409969329834
desired expected reward: 13.177178382873535






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 1.  3.  0.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0.  8. 14.] 
cards in discard: [ 6.  6.  0. 10.  3. 23.  0. 10.  0.  3.  0. 16.  0. 10. 10.  0.  0.  6.
  3.  0.  0.  0.  3.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8  1  6  0 10  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 23. 30.  8.  4.  9.  8.  3.  8.  9.  9.  9.  4. 10. 10.] 
adversary cards in hand: [ 1.  6. 25.  0.  8.] 
adversary cards in discard: [ 6. 11.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0  6] -> size -> 29 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 8.] 
cards in discard: [ 6.  6.  0. 10.  3. 23.  0. 10.  0.  3.  0. 16.  0. 10. 10.  0.  0.  6.
  3.  0.  0.  0.  3.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8  1  6  0 10  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 26. 30. 23. 30.  8.  4.  9.  8.  3.  8.  9.  9.  9.  4. 10. 10.] 
adversary cards in hand: [ 1.  6. 25.] 
adversary cards in discard: [ 6. 11.  0.  0.  0. 10.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0  6] -> size -> 29 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 8.] 
cards in discard: [ 6.  6.  0. 10.  3. 23.  0. 10.  0.  3.  0. 16.  0. 10. 10.  0.  0.  6.
  3.  0.  0.  0.  3.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8  1  6  0 10  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 26. 30. 23. 30.  8.  4.  9.  8.  3.  8.  9.  9.  9.  4. 10. 10.] 
adversary cards in hand: [ 1.  6. 25.] 
adversary cards in discard: [ 6. 11.  0.  0.  0. 10.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0  6] -> size -> 29 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 8.] 
cards in discard: [ 6.  6.  0. 10.  3. 23.  0. 10.  0.  3.  0. 16.  0. 10. 10.  0.  0.  6.
  3.  0.  0.  0.  3.  0.  0.  6. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8  1  6  0 10  0 25] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 23. 30.  8.  4.  9.  8.  3.  7.  9.  9.  9.  4. 10. 10.] 
adversary cards in hand: [ 1.  6. 25.] 
adversary cards in discard: [ 6. 11.  0.  0.  0. 10.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0  6] -> size -> 29 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 1.  6. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[113.01943]
 [115.61061]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6. 25.] 
cards in discard: [ 6. 11.  0.  0.  0. 10.  0.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 23. 30.  8.  4.  9.  8.  3.  7.  9.  9.  9.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  1.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8  1  6  0 10  0 25] -> size -> 36 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: discard_down_to_3_cards - action 7
Learning step: 0.5863065719604492
desired expected reward: 58.478538513183594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 98.11754 ]
 [103.558876]
 [ 84.4907  ]
 [103.21273 ]
 [114.065506]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6. 25.] 
cards in discard: [ 6. 11.  0.  0.  0. 10.  0.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 26. 30. 23. 30.  8.  4.  9.  8.  3.  7.  9.  9.  9.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  1.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8  1  6  0 10  0 25] -> size -> 36 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1.0
Learning step: -2.3943004608154297
desired expected reward: 110.62511444091797



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  1.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1.  8. 29.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8  1  6  0 10  0 25] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 23. 30.  8.  4.  9.  8.  3.  7.  9.  9.  9.  4. 10. 10.] 
adversary cards in hand: [ 3.  3. 25.  0. 11.] 
adversary cards in discard: [ 6. 11.  0.  0.  0. 10.  0.  8.  1.  6. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0  6] -> size -> 29 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 8. 6.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0  1  6 10  3  6 23  3  3  3
  0  8  0  6 29  8  1  6  0 10  0 25] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 26. 30. 23. 30.  8.  4.  9.  8.  3.  7.  9.  9.  9.  4. 10. 10.] 
adversary cards in hand: [ 3.  3. 25.  0. 11.] 
adversary cards in discard: [ 6. 11.  0.  0.  0. 10.  0.  8.  1.  6. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0  6] -> size -> 29 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0 10  3  6 23  3  3  3  0  8
  0  6 29  8  1  6  0 10  0 25] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 26. 30. 23. 30.  8.  4.  9.  8.  3.  7.  9.  9.  9.  4. 10. 10.] 
adversary cards in hand: [ 3.  3. 25.  0. 11.] 
adversary cards in discard: [ 6. 11.  0.  0.  0. 10.  0.  8.  1.  6. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0  6] -> size -> 29 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0 10  3  6 23  3  3  3  0  8
  0  6 29  8  1  6  0 10  0 25] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 26. 30. 23. 30.  8.  4.  9.  8.  3.  7.  9.  9.  9.  4. 10. 10.] 
adversary cards in hand: [ 3.  3. 25.  0. 11.] 
adversary cards in discard: [ 6. 11.  0.  0.  0. 10.  0.  8.  1.  6. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0  6] -> size -> 29 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [11.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0 10  3  6 23  3  3  3  0  8
  0  6 29  8  1  6  0 10  0 25 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 23. 30.  8.  4.  9.  7.  3.  7.  9.  9.  9.  4. 10. 10.] 
adversary cards in hand: [ 3.  3. 25.  0. 11.] 
adversary cards in discard: [ 6. 11.  0.  0.  0. 10.  0.  8.  1.  6. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0  6] -> size -> 29 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 3.  3. 25.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[13.923673]
 [15.889966]
 [12.331916]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 25.  0. 11.] 
cards in discard: [ 6. 11.  0.  0.  0. 10.  0.  8.  1.  6. 25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 23. 30.  8.  4.  9.  7.  3.  7.  9.  9.  9.  4. 10. 10.] 
adversary cards in hand: [10. 23. 14.  0.  6.] 
adversary cards in discard: [11. 29.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0 10  3  6 23  3  3  3  0  8
  0  6 29  8  1  6  0 10  0 25 11] -> size -> 35 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1.0
Learning step: -4.974632740020752
desired expected reward: 109.09085845947266



action possibilites: [-1] 
expected returns: [[20.925514]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 11.  3.  8.] 
cards in discard: [ 6. 11.  0.  0.  0. 10.  0.  8.  1.  6. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0  6] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 23. 30.  8.  3.  9.  7.  3.  7.  9.  9.  9.  4. 10. 10.] 
adversary cards in hand: [10. 23. 14.  0.  6.] 
adversary cards in discard: [11. 29.  8.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0 10  3  6 23  3  3  3  0  8
  0  6 29  8  1  6  0 10  0 25 11  6] -> size -> 36 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action 25.0
Learning step: 1.0763260126113892
desired expected reward: 16.966285705566406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[17.393244]
 [13.211523]
 [21.787619]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 11.  3.  8.] 
cards in discard: [ 6. 11.  0.  0.  0. 10.  0.  8.  1.  6. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 26. 30. 23. 30.  8.  3.  9.  7.  3.  7.  9.  9.  9.  4. 10. 10.] 
adversary cards in hand: [10. 23. 14.  0.  6.] 
adversary cards in discard: [11. 29.  8.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0 10  3  6 23  3  3  3  0  8
  0  6 29  8  1  6  0 10  0 25 11  6] -> size -> 36 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1
Learning step: 0.7761337161064148
desired expected reward: 21.701648712158203






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [10. 23. 14.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 23. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 23. 14.  0.  6.] 
cards in discard: [11. 29.  8.  0.  0.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0 10  3  6 23  3  3  3  0  8
  0  6 29  8  1  6  0 10  0 25 11  6] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 23. 30.  8.  3.  9.  7.  3.  7.  9.  9.  9.  4. 10. 10.] 
adversary cards in hand: [ 3. 10.  1.  0.  0.] 
adversary cards in discard: [ 6. 11.  0.  0.  0. 10.  0.  8.  1.  6. 25. 25.  3.  3.  0. 11.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0  6] -> size -> 29 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 23.  0.  6.] 
cards in discard: [11. 29.  8.  0.  0.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0 10  3  6 23  3  3  3  0  8
  0  6 29  8  1  6  0 10  0 25 11  6] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 26. 30. 23. 30.  8.  3.  9.  7.  3.  7.  9.  9.  9.  4. 10. 10.] 
adversary cards in hand: [10.  0.  0.] 
adversary cards in discard: [ 6. 11.  0.  0.  0. 10.  0.  8.  1.  6. 25. 25.  3.  3.  0. 11.  3.  8.
  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0  6] -> size -> 29 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 23.  0.  6.] 
cards in discard: [11. 29.  8.  0.  0.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0 10  3  6 23  3  3  3  0  8
  0  6 29  8  1  6  0 10  0 25 11  6] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 26. 30. 23. 30.  8.  3.  9.  7.  3.  7.  9.  9.  9.  4. 10. 10.] 
adversary cards in hand: [10.  0.  0.] 
adversary cards in discard: [ 6. 11.  0.  0.  0. 10.  0.  8.  1.  6. 25. 25.  3.  3.  0. 11.  3.  8.
  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0  6] -> size -> 29 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 23.  0.  6.] 
cards in discard: [11. 29.  8.  0.  0.  6. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0 10  3  6 23  3  3  3  0  8
  0  6 29  8  1  6  0 10  0 25 11  6 10] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 23. 30.  8.  3.  9.  7.  3.  7.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [10.  0.  0.] 
adversary cards in discard: [ 6. 11.  0.  0.  0. 10.  0.  8.  1.  6. 25. 25.  3.  3.  0. 11.  3.  8.
  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0  6] -> size -> 29 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[26.324423]
 [19.852736]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.] 
cards in discard: [ 6. 11.  0.  0.  0. 10.  0.  8.  1.  6. 25. 25.  3.  3.  0. 11.  3.  8.
  3.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 23. 30.  8.  3.  9.  7.  3.  7.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [0. 6. 3. 0. 0.] 
adversary cards in discard: [11. 29.  8.  0.  0.  6. 10. 14. 10. 23.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0 10  3  6 23  3  3  3  0  8
  0  6 29  8  1  6  0 10  0 25 11  6 10] -> size -> 37 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: discard_down_to_3_cards - action 1
Learning step: -0.5633449554443359
desired expected reward: 39.53449249267578



action possibilites: [-1.] 
expected returns: [[50.93769]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6. 11.  0.  0.  0. 10.  0.  8.  1.  6. 25. 25.  3.  3.  0. 11.  3.  8.
  3.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0  6] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 23. 30.  8.  3.  9.  7.  3.  7.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [0. 6. 3. 0. 0.] 
adversary cards in discard: [11. 29.  8.  0.  0.  6. 10. 14. 10. 23.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0 10  3  6 23  3  3  3  0  8
  0  6 29  8  1  6  0 10  0 25 11  6 10] -> size -> 37 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 39 

action type: take_action - action 10.0
Learning step: 2.1034610271453857
desired expected reward: 21.956199645996094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[40.39318 ]
 [44.65572 ]
 [43.866768]
 [31.825994]
 [48.625164]
 [43.455967]
 [43.473984]
 [51.24025 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6. 11.  0.  0.  0. 10.  0.  8.  1.  6. 25. 25.  3.  3.  0. 11.  3.  8.
  3.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 26. 30. 23. 30.  8.  3.  9.  7.  3.  7.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [0. 6. 3. 0. 0.] 
adversary cards in discard: [11. 29.  8.  0.  0.  6. 10. 14. 10. 23.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0 10  3  6 23  3  3  3  0  8
  0  6 29  8  1  6  0 10  0 25 11  6 10] -> size -> 37 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: take_action - action -1.0
Learning step: 0.3837112486362457
desired expected reward: 51.32140350341797






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [0. 6. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 0. 0.] 
cards in discard: [11. 29.  8.  0.  0.  6. 10. 14. 10. 23.  0.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0 10  3  6 23  3  3  3  0  8
  0  6 29  8  1  6  0 10  0 25 11  6 10] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 23. 30.  8.  3.  9.  7.  3.  7.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8. 8.] 
adversary cards in discard: [ 6. 11.  0.  0.  0. 10.  0.  8.  1.  6. 25. 25.  3.  3.  0. 11.  3.  8.
  3.  1. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0  6] -> size -> 29 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 0.] 
cards in discard: [11. 29.  8.  0.  0.  6. 10. 14. 10. 23.  0.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0 10  3  6 23  3  3  3  0  8
  0  6 29  8  1  6  0 10  0 25 11  6 10] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 26. 30. 23. 30.  8.  3.  9.  7.  3.  7.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8. 8.] 
adversary cards in discard: [ 6. 11.  0.  0.  0. 10.  0.  8.  1.  6. 25. 25.  3.  3.  0. 11.  3.  8.
  3.  1. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0  6] -> size -> 29 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 0.] 
cards in discard: [11. 29.  8.  0.  0.  6. 10. 14. 10. 23.  0.  6.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0 10  3  6 23  3  3  3  0  8
  0  6 29  8  1  6  0 10  0 25 11  6 10  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 26. 30. 23. 30.  8.  3.  9.  7.  3.  7.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8. 8.] 
adversary cards in discard: [ 6. 11.  0.  0.  0. 10.  0.  8.  1.  6. 25. 25.  3.  3.  0. 11.  3.  8.
  3.  1. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0  6] -> size -> 29 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [0. 0. 3. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[14.645209]
 [11.554344]
 [11.554344]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 8.] 
cards in discard: [ 6. 11.  0.  0.  0. 10.  0.  8.  1.  6. 25. 25.  3.  3.  0. 11.  3.  8.
  3.  1. 10.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 23. 30.  8.  3.  9.  7.  3.  7.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 0. 10. 25.  3.  3.] 
adversary cards in discard: [11. 29.  8.  0.  0.  6. 10. 14. 10. 23.  0.  6.  0.  0.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0 10  3  6 23  3  3  3  0  8
  0  6 29  8  1  6  0 10  0 25 11  6 10  0] -> size -> 38 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: buy - action -1.0
Learning step: -1.364814281463623
desired expected reward: 49.875431060791016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 6.7622976]
 [ 8.501438 ]
 [-1.2465777]
 [ 9.985951 ]
 [13.859544 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8. 8.] 
cards in discard: [ 6. 11.  0.  0.  0. 10.  0.  8.  1.  6. 25. 25.  3.  3.  0. 11.  3.  8.
  3.  1. 10.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 26. 30. 23. 30.  8.  3.  9.  7.  3.  7.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 0. 10. 25.  3.  3.] 
adversary cards in discard: [11. 29.  8.  0.  0.  6. 10. 14. 10. 23.  0.  6.  0.  0.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0 10  3  6 23  3  3  3  0  8
  0  6 29  8  1  6  0 10  0 25 11  6 10  0] -> size -> 38 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1.0
Learning step: 0.3809702396392822
desired expected reward: 15.0261812210083



buy possibilites: [-1] 
expected returns: [[24.997416]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8. 8.] 
cards in discard: [ 6. 11.  0.  0.  0. 10.  0.  8.  1.  6. 25. 25.  3.  3.  0. 11.  3.  8.
  3.  1. 10.  0.  0.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0  6  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 26. 30. 23. 30.  8.  2.  9.  7.  3.  7.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 0. 10. 25.  3.  3.] 
adversary cards in discard: [11. 29.  8.  0.  0.  6. 10. 14. 10. 23.  0.  6.  0.  0.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0 10  3  6 23  3  3  3  0  8
  0  6 29  8  1  6  0 10  0 25 11  6 10  0] -> size -> 38 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.   10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -293.0 

action type: buy - action 6.0
Learning step: -14.034468650817871
desired expected reward: -15.281042098999023






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [ 0. 10. 25.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 25.  3.  3.] 
cards in discard: [11. 29.  8.  0.  0.  6. 10. 14. 10. 23.  0.  6.  0.  0.  6.  3.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0 10  3  6 23  3  3  3  0  8
  0  6 29  8  1  6  0 10  0 25 11  6 10  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 23. 30.  8.  2.  9.  7.  3.  7.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [0. 1. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0  6  6] -> size -> 30 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  3.  0.  3.] 
cards in discard: [11. 29.  8.  0.  0.  6. 10. 14. 10. 23.  0.  6.  0.  0.  6.  3.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0 10  3  6 23  3  3  3  0  8
  0  6 29  8  1  6  0 10  0 25 11  6 10  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 23. 30.  8.  1.  9.  7.  3.  7.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [0. 1. 3. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0  6  6  6] -> size -> 31 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  3.  0.  3.] 
cards in discard: [11. 29.  8.  0.  0.  6. 10. 14. 10. 23.  0.  6.  0.  0.  6.  3.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0 10  3  6 23  3  3  3  0  8
  0  6 29  8  1  6  0 10  0 25 11  6 10  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 26. 30. 23. 30.  8.  1.  9.  7.  3.  7.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [0. 1. 3. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0  6  6  6] -> size -> 31 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [0. 1. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[25.692873]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 0. 0.] 
cards in discard: [6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0  6  6  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 23. 30.  8.  1.  9.  7.  3.  7.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [10.  6. 16.  0.  0.] 
adversary cards in discard: [11. 29.  8.  0.  0.  6. 10. 14. 10. 23.  0.  6.  0.  0.  6.  3.  0.  0.
 25.  0. 10.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0 10  3  6 23  3  3  3  0  8
  0  6 29  8  1  6  0 10  0 25 11  6 10  0] -> size -> 38 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[  -5    0    1    0    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -304 

action type: buy - action -1
Learning step: -15.871780395507812
desired expected reward: 9.125635147094727





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[20.712418]
 [23.146585]
 [23.362328]
 [17.998793]
 [16.160545]
 [21.980022]
 [26.30811 ]
 [22.28112 ]
 [27.202736]
 [22.8329  ]
 [19.492615]
 [21.028908]
 [23.221546]
 [18.270702]
 [21.938276]
 [28.55859 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0. 0.] 
cards in discard: [6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0  6  6  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 5 
card supply: [19. 26. 30. 23. 30.  8.  1.  9.  7.  3.  7.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [10.  6. 16.  0.  0.] 
adversary cards in discard: [11. 29.  8.  0.  0.  6. 10. 14. 10. 23.  0.  6.  0.  0.  6.  3.  0.  0.
 25.  0. 10.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0 10  3  6 23  3  3  3  0  8
  0  6 29  8  1  6  0 10  0 25 11  6 10  0] -> size -> 38 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: take_action - action -1.0
Learning step: -0.9424968957901001
desired expected reward: 24.750375747680664



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [10.  6. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6. 16.  0.  0.] 
cards in discard: [11. 29.  8.  0.  0.  6. 10. 14. 10. 23.  0.  6.  0.  0.  6.  3.  0.  0.
 25.  0. 10.  3.  3.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 10 14 16  0  0 10  0 10  3  6 23  3  3  3  0  8
  0  6 29  8  1  6  0 10  0 25 11  6 10  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 23. 30.  8.  1.  9.  7.  3.  7.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  8. 10.] 
adversary cards in discard: [6. 0. 1. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0  6  6  6] -> size -> 31 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  0.] 
cards in discard: [11. 29.  8.  0.  0.  6. 10. 14. 10. 23.  0.  6.  0.  0.  6.  3.  0.  0.
 25.  0. 10.  3.  3.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3 10 14 16  0  0 10  0 10  3  6 23  3  3  3  0  8  0
  6 29  8  1  6  0 10  0 25 11  6 10  0  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 23. 30.  8.  1.  9.  7.  3.  7.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  8. 10.] 
adversary cards in discard: [6. 0. 1. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0  6  6  6] -> size -> 31 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  0.] 
cards in discard: [11. 29.  8.  0.  0.  6. 10. 14. 10. 23.  0.  6.  0.  0.  6.  3.  0.  0.
 25.  0. 10.  3.  3.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3 10 14 16  0  0 10  0 10  3  6 23  3  3  3  0  8  0
  6 29  8  1  6  0 10  0 25 11  6 10  0  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 26. 30. 23. 30.  8.  1.  9.  7.  3.  7.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  8. 10.] 
adversary cards in discard: [6. 0. 1. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0  6  6  6] -> size -> 31 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  0.] 
cards in discard: [11. 29.  8.  0.  0.  6. 10. 14. 10. 23.  0.  6.  0.  0.  6.  3.  0.  0.
 25.  0. 10.  3.  3.  0.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3 10 14 16  0  0 10  0 10  3  6 23  3  3  3  0  8  0
  6 29  8  1  6  0 10  0 25 11  6 10  0  0  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 26. 30. 23. 30.  8.  1.  9.  7.  3.  7.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  8. 10.] 
adversary cards in discard: [6. 0. 1. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0  6  6  6] -> size -> 31 
adversary victory points: 1
player victory points: 1 





Player: 0 
cards in hand: [ 0. 11.  0.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 10.] 
expected returns: [[71.68857]
 [69.0497 ]
 [65.17287]
 [65.89528]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  8. 10.] 
cards in discard: [6. 0. 1. 3. 0. 0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0  6  6  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 23. 30.  8.  1.  9.  7.  3.  7.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [10.  0.  3.  0.  0.] 
adversary cards in discard: [11. 29.  8.  0.  0.  6. 10. 14. 10. 23.  0.  6.  0.  0.  6.  3.  0.  0.
 25.  0. 10.  3.  3.  0.  3.  0.  0. 16. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 10 14 16  0  0 10  0 10  3  6 23  3  3  3  0  8  0
  6 29  8  1  6  0 10  0 25 11  6 10  0  0  0] -> size -> 39 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1.0
Learning step: -0.07354898750782013
desired expected reward: 28.48503303527832





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[66.35106]
 [68.50482]
 [61.81416]
 [68.05046]
 [74.22826]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  8. 10.] 
cards in discard: [6. 0. 1. 3. 0. 0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0  6  6  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 26. 30. 23. 30.  8.  1.  9.  7.  3.  7.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [10.  0.  3.  0.  0.] 
adversary cards in discard: [11. 29.  8.  0.  0.  6. 10. 14. 10. 23.  0.  6.  0.  0.  6.  3.  0.  0.
 25.  0. 10.  3.  3.  0.  3.  0.  0. 16. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 10 14 16  0  0 10  0 10  3  6 23  3  3  3  0  8  0
  6 29  8  1  6  0 10  0 25 11  6 10  0  0  0] -> size -> 39 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: take_action - action -1.0
Learning step: -2.2152769565582275
desired expected reward: 69.47327423095703



buy possibilites: [-1] 
expected returns: [[83.02638]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  8. 10.] 
cards in discard: [6. 0. 1. 3. 0. 0. 0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0  6  6  6  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 26. 30. 23. 30.  8.  1.  9.  7.  3.  7.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [10.  0.  3.  0.  0.] 
adversary cards in discard: [11. 29.  8.  0.  0.  6. 10. 14. 10. 23.  0.  6.  0.  0.  6.  3.  0.  0.
 25.  0. 10.  3.  3.  0.  3.  0.  0. 16. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 10 14 16  0  0 10  0 10  3  6 23  3  3  3  0  8  0
  6 29  8  1  6  0 10  0 25 11  6 10  0  0  0] -> size -> 39 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -34.0 

action type: buy - action 0.0
Learning step: -3.1494596004486084
desired expected reward: 63.20159912109375






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [10.  0.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.  0.] 
cards in discard: [11. 29.  8.  0.  0.  6. 10. 14. 10. 23.  0.  6.  0.  0.  6.  3.  0.  0.
 25.  0. 10.  3.  3.  0.  3.  0.  0. 16. 10.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 10 14 16  0  0 10  0 10  3  6 23  3  3  3  0  8  0
  6 29  8  1  6  0 10  0 25 11  6 10  0  0  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 23. 30.  8.  1.  9.  7.  3.  7.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [3. 8. 8. 3. 3.] 
adversary cards in discard: [ 6.  0.  1.  3.  0.  0.  0.  0. 11.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0  6  6  6  0] -> size -> 32 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11. 29.  8.  0.  0.  6. 10. 14. 10. 23.  0.  6.  0.  0.  6.  3.  0.  0.
 25.  0. 10.  3.  3.  0.  3.  0.  0. 16. 10.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3 10 14 16  0  0 10  0 10  3  6 23  3  3  3  0  8  0
  6 29  8  1  6  0 10  0 25 11  6 10  0  0  0] -> size -> 39 
action values: 2 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 23. 30.  8.  1.  9.  7.  3.  7.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [3. 8. 8. 3. 3.] 
adversary cards in discard: [ 6.  0.  1.  3.  0.  0.  0.  0. 11.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0  6  6  6  0] -> size -> 32 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11. 29.  8.  0.  0.  6. 10. 14. 10. 23.  0.  6.  0.  0.  6.  3.  0.  0.
 25.  0. 10.  3.  3.  0.  3.  0.  0. 16. 10.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3 10 14 16  0  0 10  0 10  3  6 23  3  3  3  0  8  0
  6 29  8  1  6  0 10  0 25 11  6 10  0  0  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 26. 30. 23. 30.  8.  1.  9.  7.  3.  7.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [3. 8. 8. 3. 3.] 
adversary cards in discard: [ 6.  0.  1.  3.  0.  0.  0.  0. 11.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0  6  6  6  0] -> size -> 32 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11. 29.  8.  0.  0.  6. 10. 14. 10. 23.  0.  6.  0.  0.  6.  3.  0.  0.
 25.  0. 10.  3.  3.  0.  3.  0.  0. 16. 10.  6.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3 10 14 16  0  0 10  0 10  3  6 23  3  3  3  0  8  0
  6 29  8  1  6  0 10  0 25 11  6 10  0  0  0  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 4 
card supply: [15. 26. 30. 23. 30.  8.  1.  9.  7.  3.  7.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [3. 8. 8. 3. 3.] 
adversary cards in discard: [ 6.  0.  1.  3.  0.  0.  0.  0. 11.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0  6  6  6  0] -> size -> 32 
adversary victory points: 1
player victory points: 1 





Player: 0 
cards in hand: [3. 8. 8. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[102.671616]
 [ 95.50441 ]
 [ 95.50441 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 8. 3. 3.] 
cards in discard: [ 6.  0.  1.  3.  0.  0.  0.  0. 11.  0.  8. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8
  0  3  3  0  6  6  6  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 23. 30.  8.  1.  9.  7.  3.  7.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 6.  0. 10.  1.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 10 14 16  0  0 10  0 10  3  6 23  3  3  3  0  8  0
  6 29  8  1  6  0 10  0 25 11  6 10  0  0  0  0] -> size -> 40 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1
Learning step: -2.1161506175994873
desired expected reward: 80.91023254394531



action possibilites: [-1] 
expected returns: [[58.68708]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3.] 
cards in discard: [ 6.  0.  1.  3.  0.  0.  0.  0. 11.  0.  8. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0
  3  3  0  6  6  6  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 23. 30.  8.  1.  9.  7.  3.  7.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 6.  0. 10.  1.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 10 14 16  0  0 10  0 10  3  6 23  3  3  3  0  8  0
  6 29  8  1  6  0 10  0 25 11  6 10  0  0  0  0] -> size -> 40 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: trash_cards_n_from_hand - action 1
Learning step: -3.8006863594055176
desired expected reward: 103.62222290039062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[42.263542]
 [33.06072 ]
 [57.545   ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3.] 
cards in discard: [ 6.  0.  1.  3.  0.  0.  0.  0. 11.  0.  8. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0
  3  3  0  6  6  6  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 26. 30. 23. 30.  8.  1.  9.  7.  3.  7.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 6.  0. 10.  1.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 10 14 16  0  0 10  0 10  3  6 23  3  3  3  0  8  0
  6 29  8  1  6  0 10  0 25 11  6 10  0  0  0  0] -> size -> 40 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: -1.5974940061569214
desired expected reward: 57.0895881652832



buy possibilites: [-1] 
expected returns: [[62.32591]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3.] 
cards in discard: [ 6.  0.  1.  3.  0.  0.  0.  0. 11.  0.  8. 10.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0
  3  3  0  6  6  6  0  6] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 23. 30.  8.  0.  9.  7.  3.  7.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 6.  0. 10.  1.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 10 14 16  0  0 10  0 10  3  6 23  3  3  3  0  8  0
  6 29  8  1  6  0 10  0 25 11  6 10  0  0  0  0] -> size -> 40 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1  -20    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -306 

action type: buy - action 6.0
Learning step: -15.550702095031738
desired expected reward: 17.510009765625






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 6.  0. 10.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10.  1.  8.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 10 14 16  0  0 10  0 10  3  6 23  3  3  3  0  8  0
  6 29  8  1  6  0 10  0 25 11  6 10  0  0  0  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 23. 30.  8.  0.  9.  7.  3.  7.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 3. 11.  6. 10.  1.] 
adversary cards in discard: [ 6.  0.  1.  3.  0.  0.  0.  0. 11.  0.  8. 10.  6.  8.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0
  3  3  0  6  6  6  0  6] -> size -> 32 
adversary victory points: -1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 14 16  0  0 10  0 10  3 23  3  3  3  0  8  0  6 29
  8  1  6  0 10  0 25 11  6 10  0  0  0  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 23. 30.  8.  0.  9.  7.  3.  7.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 3. 11.  6. 10.  1.] 
adversary cards in discard: [ 6.  0.  1.  3.  0.  0.  0.  0. 11.  0.  8. 10.  6.  8.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0
  3  3  0  6  6  6  0  6] -> size -> 32 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 14 16  0  0 10  0 10  3 23  3  3  3  0  8  0  6 29
  8  1  6  0 10  0 25 11  6 10  0  0  0  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 26. 30. 23. 30.  8.  0.  9.  7.  3.  7.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 3. 11.  6. 10.  1.] 
adversary cards in discard: [ 6.  0.  1.  3.  0.  0.  0.  0. 11.  0.  8. 10.  6.  8.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0
  3  3  0  6  6  6  0  6] -> size -> 32 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1.] 
cards in discard: [3.] 
cards in deck: 35 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 14 16  0  0 10  0 10  3 23  3  3  3  0  8  0  6 29
  8  1  6  0 10  0 25 11  6 10  0  0  0  0  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 26. 30. 22. 30.  8.  0.  9.  7.  3.  7.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 3. 11.  6. 10.  1.] 
adversary cards in discard: [ 6.  0.  1.  3.  0.  0.  0.  0. 11.  0.  8. 10.  6.  8.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0
  3  3  0  6  6  6  0  6] -> size -> 32 
adversary victory points: -1
player victory points: 3 





Player: 0 
cards in hand: [ 3. 11.  6. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[52.64085]
 [55.48625]
 [49.87445]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  6. 10.  1.] 
cards in discard: [ 6.  0.  1.  3.  0.  0.  0.  0. 11.  0.  8. 10.  6.  8.  8.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0
  3  3  0  6  6  6  0  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 22. 30.  8.  0.  9.  7.  3.  7.  9.  9.  9.  3. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 25.  3.] 
adversary cards in discard: [3. 8. 0. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14 16  0  0 10  0 10  3 23  3  3  3  0  8  0  6 29
  8  1  6  0 10  0 25 11  6 10  0  0  0  0  3] -> size -> 39 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1
Learning step: -4.212070465087891
desired expected reward: 58.11383819580078



action possibilites: [-1] 
expected returns: [[73.1537]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 10.  1.] 
cards in discard: [ 6.  0.  1.  3.  0.  0.  0.  0. 11.  0.  8. 10.  6.  8.  8.  3.  3. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0
  3  3  0  6  6  6  0  6 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 22. 30.  8.  0.  9.  7.  3.  7.  9.  9.  9.  3. 10.  9.] 
adversary cards in hand: [ 0. 10.  0. 25.  3.] 
adversary cards in discard: [3. 8. 0. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14 16  0  0 10  0 10  3 23  3  3  3  0  8  0  6 29
  8  1  6  0 10  0 25 11  6 10  0  0  0  0  3] -> size -> 39 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -10 

action type: gain_card_n - action 9
Learning step: -1.796465516090393
desired expected reward: 57.05200958251953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[64.091354]
 [67.04332 ]
 [66.99849 ]
 [73.63272 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 10.  1.] 
cards in discard: [ 6.  0.  1.  3.  0.  0.  0.  0. 11.  0.  8. 10.  6.  8.  8.  3.  3. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0
  3  3  0  6  6  6  0  6 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 26. 30. 22. 30.  8.  0.  9.  7.  3.  7.  9.  9.  9.  3. 10.  9.] 
adversary cards in hand: [ 0. 10.  0. 25.  3.] 
adversary cards in discard: [3. 8. 0. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14 16  0  0 10  0 10  3 23  3  3  3  0  8  0  6 29
  8  1  6  0 10  0 25 11  6 10  0  0  0  0  3] -> size -> 39 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1
Learning step: -3.3902134895324707
desired expected reward: 69.76348876953125



buy possibilites: [-1] 
expected returns: [[19.111916]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 10.  1.] 
cards in discard: [ 6.  0.  1.  3.  0.  0.  0.  0. 11.  0.  8. 10.  6.  8.  8.  3.  3. 15.
  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0
  3  3  0  6  6  6  0  6 15  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 22. 30.  8.  0.  9.  7.  2.  7.  9.  9.  9.  3. 10.  9.] 
adversary cards in hand: [ 0. 10.  0. 25.  3.] 
adversary cards in discard: [3. 8. 0. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14 16  0  0 10  0 10  3 23  3  3  3  0  8  0  6 29
  8  1  6  0 10  0 25 11  6 10  0  0  0  0  3] -> size -> 39 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: -18 

action type: buy - action 8.0
Learning step: -3.819906234741211
desired expected reward: 63.17858123779297






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 25.  3.] 
cards in discard: [3. 8. 0. 1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14 16  0  0 10  0 10  3 23  3  3  3  0  8  0  6 29
  8  1  6  0 10  0 25 11  6 10  0  0  0  0  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 22. 30.  8.  0.  9.  7.  2.  7.  9.  9.  9.  3. 10.  9.] 
adversary cards in hand: [ 0. 25.  8.  0.  0.] 
adversary cards in discard: [ 6.  0.  1.  3.  0.  0.  0.  0. 11.  0.  8. 10.  6.  8.  8.  3.  3. 15.
  8. 11.  3.  6. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0
  3  3  0  6  6  6  0  6 15  8] -> size -> 34 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 25.  3.] 
cards in discard: [3. 8. 0. 1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14 16  0  0 10  0 10  3 23  3  3  3  0  8  0  6 29
  8  1  6  0 10  0 25 11  6 10  0  0  0  0  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 26. 30. 22. 30.  8.  0.  9.  7.  2.  7.  9.  9.  9.  3. 10.  9.] 
adversary cards in hand: [ 0. 25.  8.  0.  0.] 
adversary cards in discard: [ 6.  0.  1.  3.  0.  0.  0.  0. 11.  0.  8. 10.  6.  8.  8.  3.  3. 15.
  8. 11.  3.  6. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0
  3  3  0  6  6  6  0  6 15  8] -> size -> 34 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 25.  3.] 
cards in discard: [3. 8. 0. 1. 3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14 16  0  0 10  0 10  3 23  3  3  3  0  8  0  6 29
  8  1  6  0 10  0 25 11  6 10  0  0  0  0  3  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 21. 30.  8.  0.  9.  7.  2.  7.  9.  9.  9.  3. 10.  9.] 
adversary cards in hand: [ 0. 25.  8.  0.  0.] 
adversary cards in discard: [ 6.  0.  1.  3.  0.  0.  0.  0. 11.  0.  8. 10.  6.  8.  8.  3.  3. 15.
  8. 11.  3.  6. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0
  3  3  0  6  6  6  0  6 15  8] -> size -> 34 
adversary victory points: -1
player victory points: 4 





Player: 0 
cards in hand: [ 0. 25.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[16.704374]
 [25.594315]
 [16.603346]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  8.  0.  0.] 
cards in discard: [ 6.  0.  1.  3.  0.  0.  0.  0. 11.  0.  8. 10.  6.  8.  8.  3.  3. 15.
  8. 11.  3.  6. 10.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0
  3  3  0  6  6  6  0  6 15  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 21. 30.  8.  0.  9.  7.  2.  7.  9.  9.  9.  3. 10.  9.] 
adversary cards in hand: [ 3. 14.  6.  0.  0.] 
adversary cards in discard: [ 3.  8.  0.  1.  3.  0. 10.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14 16  0  0 10  0 10  3 23  3  3  3  0  8  0  6 29
  8  1  6  0 10  0 25 11  6 10  0  0  0  0  3  3] -> size -> 40 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -3.2732083797454834
desired expected reward: 15.838706970214844



action possibilites: [-1] 
expected returns: [[66.966415]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.] 
cards in discard: [ 6.  0.  1.  3.  0.  0.  0.  0. 11.  0.  8. 10.  6.  8.  8.  3.  3. 15.
  8. 11.  3.  6. 10.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3
  3  0  6  6  6  0  6 15  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 21. 30.  8.  0.  9.  7.  2.  7.  9.  9.  9.  3. 10.  9.] 
adversary cards in hand: [ 3. 14.  6.  0.  0.] 
adversary cards in discard: [ 3.  8.  0.  1.  3.  0. 10.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14 16  0  0 10  0 10  3 23  3  3  3  0  8  0  6 29
  8  1  6  0 10  0 25 11  6 10  0  0  0  0  3  3] -> size -> 40 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: trash_cards_n_from_hand - action 0
Learning step: -0.8671836256980896
desired expected reward: 10.611373901367188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[53.295616]
 [56.57322 ]
 [58.35475 ]
 [63.886322]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0.] 
cards in discard: [ 6.  0.  1.  3.  0.  0.  0.  0. 11.  0.  8. 10.  6.  8.  8.  3.  3. 15.
  8. 11.  3.  6. 10.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3
  3  0  6  6  6  0  6 15  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 26. 30. 21. 30.  8.  0.  9.  7.  2.  7.  9.  9.  9.  3. 10.  9.] 
adversary cards in hand: [ 3. 14.  6.  0.  0.] 
adversary cards in discard: [ 3.  8.  0.  1.  3.  0. 10.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14 16  0  0 10  0 10  3 23  3  3  3  0  8  0  6 29
  8  1  6  0 10  0 25 11  6 10  0  0  0  0  3  3] -> size -> 40 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1
Learning step: -3.802771806716919
desired expected reward: 63.16364288330078



buy possibilites: [-1] 
expected returns: [[50.79439]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0.] 
cards in discard: [ 6.  0.  1.  3.  0.  0.  0.  0. 11.  0.  8. 10.  6.  8.  8.  3.  3. 15.
  8. 11.  3.  6. 10.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3
  3  0  6  6  6  0  6 15  8  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 26. 30. 21. 30.  8.  0.  9.  7.  2.  7.  9.  9.  9.  3. 10.  9.] 
adversary cards in hand: [ 3. 14.  6.  0.  0.] 
adversary cards in discard: [ 3.  8.  0.  1.  3.  0. 10.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14 16  0  0 10  0 10  3 23  3  3  3  0  8  0  6 29
  8  1  6  0 10  0 25 11  6 10  0  0  0  0  3  3] -> size -> 40 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -50.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -66.0 

action type: buy - action 0.0
Learning step: -4.821906566619873
desired expected reward: 48.47370147705078






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 3. 14.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  6.  0.  0.] 
cards in discard: [ 3.  8.  0.  1.  3.  0. 10.  0. 25.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14 16  0  0 10  0 10  3 23  3  3  3  0  8  0  6 29
  8  1  6  0 10  0 25 11  6 10  0  0  0  0  3  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 21. 30.  8.  0.  9.  7.  2.  7.  9.  9.  9.  3. 10.  9.] 
adversary cards in hand: [ 0.  6.  0.  6. 25.] 
adversary cards in discard: [ 6.  0.  1.  3.  0.  0.  0.  0. 11.  0.  8. 10.  6.  8.  8.  3.  3. 15.
  8. 11.  3.  6. 10.  1.  0.  8. 25.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3
  3  0  6  6  6  0  6 15  8  0] -> size -> 34 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 0.] 
cards in discard: [ 3.  8.  0.  1.  3.  0. 10.  0. 25.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3 14 16  0  0 10  0 10  3 23  3  3  3  0  8  0  6 29
  8  1  6  0 10  0 25 11  6 10  0  0  0  0  3  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 26. 30. 21. 30.  8.  0.  9.  7.  2.  7.  9.  9.  9.  3. 10.  9.] 
adversary cards in hand: [ 0.  6. 25.] 
adversary cards in discard: [ 6.  0.  1.  3.  0.  0.  0.  0. 11.  0.  8. 10.  6.  8.  8.  3.  3. 15.
  8. 11.  3.  6. 10.  1.  0.  8. 25.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3
  3  0  6  6  6  0  6 15  8  0] -> size -> 34 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0.] 
cards in discard: [ 3.  8.  0.  1.  3.  0. 10.  0. 25.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3 14 16  0  0 10  0 10  3 23  3  3  3  0  8  0  6 29
  8  1  6  0 10  0 25 11  6 10  0  0  0  0  3  3] -> size -> 40 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 26. 30. 21. 30.  8.  0.  9.  7.  2.  7.  9.  9.  9.  3. 10.  9.] 
adversary cards in hand: [ 0.  6. 25.] 
adversary cards in discard: [ 6.  0.  1.  3.  0.  0.  0.  0. 11.  0.  8. 10.  6.  8.  8.  3.  3. 15.
  8. 11.  3.  6. 10.  1.  0.  8. 25.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3
  3  0  6  6  6  0  6 15  8  0] -> size -> 34 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0.] 
cards in discard: [ 3.  8.  0.  1.  3.  0. 10.  0. 25.  3.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3 14 16  0  0 10  0 10  3 23  3  3  3  0  8  0  6 29
  8  1  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 4 
card supply: [13. 26. 30. 21. 30.  8.  0.  9.  7.  2.  7.  9.  9.  9.  3. 10.  9.] 
adversary cards in hand: [ 0.  6. 25.] 
adversary cards in discard: [ 6.  0.  1.  3.  0.  0.  0.  0. 11.  0.  8. 10.  6.  8.  8.  3.  3. 15.
  8. 11.  3.  6. 10.  1.  0.  8. 25.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3
  3  0  6  6  6  0  6 15  8  0] -> size -> 34 
adversary victory points: -1
player victory points: 4 





Player: 0 
cards in hand: [ 0.  6. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[ 8.129406]
 [11.721584]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 25.] 
cards in discard: [ 6.  0.  1.  3.  0.  0.  0.  0. 11.  0.  8. 10.  6.  8.  8.  3.  3. 15.
  8. 11.  3.  6. 10.  1.  0.  8. 25.  0.  0.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3
  3  0  6  6  6  0  6 15  8  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 21. 30.  8.  0.  9.  7.  2.  7.  9.  9.  9.  3. 10.  9.] 
adversary cards in hand: [ 8.  0. 29. 10.  0.] 
adversary cards in discard: [ 3.  8.  0.  1.  3.  0. 10.  0. 25.  3.  0. 14.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14 16  0  0 10  0 10  3 23  3  3  3  0  8  0  6 29
  8  1  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0] -> size -> 41 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: discard_down_to_3_cards - action 1
Learning step: -2.870182752609253
desired expected reward: 3.2447707653045654



action possibilites: [-1] 
expected returns: [[0.08230305]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3
  3  0  6  6  6  0  6 15  8  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 21. 30.  8.  0.  9.  7.  2.  7.  9.  9.  9.  3. 10.  9.] 
adversary cards in hand: [ 8.  0. 29. 10.  0.] 
adversary cards in discard: [ 3.  8.  0.  1.  3.  0. 10.  0. 25.  3.  0. 14.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14 16  0  0 10  0 10  3 23  3  3  3  0  8  0  6 29
  8  1  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0] -> size -> 41 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -35 

action type: take_action - action 25.0
Learning step: -2.3342273235321045
desired expected reward: 9.38735294342041





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-4.51219  ]
 [-2.7439404]
 [-2.9742517]
 [ 3.7717252]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3
  3  0  6  6  6  0  6 15  8  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 26. 30. 21. 30.  8.  0.  9.  7.  2.  7.  9.  9.  9.  3. 10.  9.] 
adversary cards in hand: [ 8.  0. 29. 10.  0.] 
adversary cards in discard: [ 3.  8.  0.  1.  3.  0. 10.  0. 25.  3.  0. 14.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14 16  0  0 10  0 10  3 23  3  3  3  0  8  0  6 29
  8  1  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0] -> size -> 41 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1
Learning step: -1.8037344217300415
desired expected reward: -1.7214313745498657



buy possibilites: [-1] 
expected returns: [[27.34954]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0.] 
cards in discard: [3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3
  3  0  6  6  6  0  6 15  8  0  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 20. 30.  8.  0.  9.  7.  2.  7.  9.  9.  9.  3. 10.  9.] 
adversary cards in hand: [ 8.  0. 29. 10.  0.] 
adversary cards in discard: [ 3.  8.  0.  1.  3.  0. 10.  0. 25.  3.  0. 14.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14 16  0  0 10  0 10  3 23  3  3  3  0  8  0  6 29
  8  1  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0] -> size -> 41 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: -17 

action type: buy - action 3.0
Learning step: -0.09743857383728027
desired expected reward: -2.841374158859253






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [ 8.  0. 29. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 29. 10.  0.] 
cards in discard: [ 3.  8.  0.  1.  3.  0. 10.  0. 25.  3.  0. 14.  3.  6.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14 16  0  0 10  0 10  3 23  3  3  3  0  8  0  6 29
  8  1  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 20. 30.  8.  0.  9.  7.  2.  7.  9.  9.  9.  3. 10.  9.] 
adversary cards in hand: [0. 8. 8. 6. 0.] 
adversary cards in discard: [ 3. 25.  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3
  3  0  6  6  6  0  6 15  8  0  3] -> size -> 35 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 3.  8.  0.  1.  3.  0. 10.  0. 25.  3.  0. 14.  3.  6.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 20. 30.  8.  0.  9.  7.  2.  7.  9.  9.  9.  3. 10.  9.] 
adversary cards in hand: [0. 8. 8. 6. 0.] 
adversary cards in discard: [ 3. 25.  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3
  3  0  6  6  6  0  6 15  8  0  3] -> size -> 35 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 3.  8.  0.  1.  3.  0. 10.  0. 25.  3.  0. 14.  3.  6.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 26. 30. 20. 30.  8.  0.  9.  7.  2.  7.  9.  9.  9.  3. 10.  9.] 
adversary cards in hand: [0. 8. 8. 6. 0.] 
adversary cards in discard: [ 3. 25.  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3
  3  0  6  6  6  0  6 15  8  0  3] -> size -> 35 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 3.  8.  0.  1.  3.  0. 10.  0. 25.  3.  0. 14.  3.  6.  0.  0.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 20. 30.  8.  0.  9.  7.  1.  7.  9.  9.  9.  3. 10.  9.] 
adversary cards in hand: [0. 8. 8. 6. 0.] 
adversary cards in discard: [ 3. 25.  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3
  3  0  6  6  6  0  6 15  8  0  3] -> size -> 35 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [0. 8. 8. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[13.9543  ]
 [10.328629]
 [10.328629]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 6. 0.] 
cards in discard: [ 3. 25.  0.  6.  6.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3
  3  0  6  6  6  0  6 15  8  0  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 20. 30.  8.  0.  9.  7.  1.  7.  9.  9.  9.  3. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  0.  3.] 
adversary cards in discard: [ 3.  8.  0.  1.  3.  0. 10.  0. 25.  3.  0. 14.  3.  6.  0.  0.  8.  8.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8] -> size -> 40 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -3.341416597366333
desired expected reward: 24.00812339782715





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[10.310596]
 [12.328182]
 [11.589903]
 [15.215572]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8. 6. 0.] 
cards in discard: [ 3. 25.  0.  6.  6.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3
  3  0  6  6  6  0  6 15  8  0  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 26. 30. 20. 30.  8.  0.  9.  7.  1.  7.  9.  9.  9.  3. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  0.  3.] 
adversary cards in discard: [ 3.  8.  0.  1.  3.  0. 10.  0. 25.  3.  0. 14.  3.  6.  0.  0.  8.  8.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8] -> size -> 40 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -2.6501362323760986
desired expected reward: 11.30416202545166



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [ 3. 10.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.  3.] 
cards in discard: [ 3.  8.  0.  1.  3.  0. 10.  0. 25.  3.  0. 14.  3.  6.  0.  0.  8.  8.
  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 20. 30.  8.  0.  9.  7.  1.  7.  9.  9.  9.  3. 10.  9.] 
adversary cards in hand: [ 0. 11.  3. 10.  8.] 
adversary cards in discard: [ 3. 25.  0.  6.  6.  0.  0.  8.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3
  3  0  6  6  6  0  6 15  8  0  3] -> size -> 35 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.  3.] 
cards in discard: [ 3.  8.  0.  1.  3.  0. 10.  0. 25.  3.  0. 14.  3.  6.  0.  0.  8.  8.
  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 26. 30. 20. 30.  8.  0.  9.  7.  1.  7.  9.  9.  9.  3. 10.  9.] 
adversary cards in hand: [ 0. 11.  3. 10.  8.] 
adversary cards in discard: [ 3. 25.  0.  6.  6.  0.  0.  8.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3
  3  0  6  6  6  0  6 15  8  0  3] -> size -> 35 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.  3.] 
cards in discard: [ 3.  8.  0.  1.  3.  0. 10.  0. 25.  3.  0. 14.  3.  6.  0.  0.  8.  8.
  0.  0.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 20. 30.  8.  0.  9.  7.  0.  7.  9.  9.  9.  3. 10.  9.] 
adversary cards in hand: [ 0. 11.  3. 10.  8.] 
adversary cards in discard: [ 3. 25.  0.  6.  6.  0.  0.  8.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3
  3  0  6  6  6  0  6 15  8  0  3] -> size -> 35 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [ 0. 11.  3. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8.] 
expected returns: [[13.671574]
 [12.282906]
 [ 7.785011]
 [ 8.644009]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3. 10.  8.] 
cards in discard: [ 3. 25.  0.  6.  6.  0.  0.  8.  8.  6.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3
  3  0  6  6  6  0  6 15  8  0  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 20. 30.  8.  0.  9.  7.  0.  7.  9.  9.  9.  3. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 3.  8.  0.  1.  3.  0. 10.  0. 25.  3.  0. 14.  3.  6.  0.  0.  8.  8.
  0.  0.  8.  3. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8] -> size -> 41 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1.0
Learning step: -2.7514092922210693
desired expected reward: 12.464164733886719



action possibilites: [-1] 
expected returns: [[-4.0110536]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.] 
cards in discard: [ 3. 25.  0.  6.  6.  0.  0.  8.  8.  6.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3  3
  0  6  6  6  0  6 15  8  0  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 20. 30.  8.  0.  9.  7.  0.  7.  9.  9.  9.  3. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 3.  8.  0.  1.  3.  0. 10.  0. 25.  3.  0. 14.  3.  6.  0.  0.  8.  8.
  0.  0.  8.  3. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8] -> size -> 41 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: trash_cards_n_from_hand - action 1
Learning step: -2.267730474472046
desired expected reward: 5.2819013595581055





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-6.826472 ]
 [-5.7149982]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 10.] 
cards in discard: [ 3. 25.  0.  6.  6.  0.  0.  8.  8.  6.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3  3
  0  6  6  6  0  6 15  8  0  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 26. 30. 20. 30.  8.  0.  9.  7.  0.  7.  9.  9.  9.  3. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 3.  8.  0.  1.  3.  0. 10.  0. 25.  3.  0. 14.  3.  6.  0.  0.  8.  8.
  0.  0.  8.  3. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8] -> size -> 41 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1
Learning step: -1.7367511987686157
desired expected reward: -5.747804641723633



buy possibilites: [-1] 
expected returns: [[20.05405]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 10.] 
cards in discard: [ 3. 25.  0.  6.  6.  0.  0.  8.  8.  6.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3  3
  0  6  6  6  0  6 15  8  0  3  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 26. 30. 20. 30.  8.  0.  9.  7.  0.  7.  9.  9.  9.  3. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 3.  8.  0.  1.  3.  0. 10.  0. 25.  3.  0. 14.  3.  6.  0.  0.  8.  8.
  0.  0.  8.  3. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8] -> size -> 41 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -50.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -66.0 

action type: buy - action 0.0
Learning step: -2.4924705028533936
desired expected reward: -9.318948745727539






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 3.  8.  0.  1.  3.  0. 10.  0. 25.  3.  0. 14.  3.  6.  0.  0.  8.  8.
  0.  0.  8.  3. 10.  0.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 20. 30.  8.  0.  9.  7.  0.  7.  9.  9.  9.  3. 10.  9.] 
adversary cards in hand: [15.  8.  0.  0.  1.] 
adversary cards in discard: [ 3. 25.  0.  6.  6.  0.  0.  8.  8.  6.  0.  0.  8.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3  3
  0  6  6  6  0  6 15  8  0  3  0] -> size -> 35 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 3.  8.  0.  1.  3.  0. 10.  0. 25.  3.  0. 14.  3.  6.  0.  0.  8.  8.
  0.  0.  8.  3. 10.  0.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8] -> size -> 41 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 26. 30. 20. 30.  8.  0.  9.  7.  0.  7.  9.  9.  9.  3. 10.  9.] 
adversary cards in hand: [15.  8.  0.  0.  1.] 
adversary cards in discard: [ 3. 25.  0.  6.  6.  0.  0.  8.  8.  6.  0.  0.  8.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3  3
  0  6  6  6  0  6 15  8  0  3  0] -> size -> 35 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 3.  8.  0.  1.  3.  0. 10.  0. 25.  3.  0. 14.  3.  6.  0.  0.  8.  8.
  0.  0.  8.  3. 10.  0.  0.  3. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8 10] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 26. 30. 20. 30.  8.  0.  9.  7.  0.  7.  9.  9.  9.  2. 10.  9.] 
adversary cards in hand: [15.  8.  0.  0.  1.] 
adversary cards in discard: [ 3. 25.  0.  6.  6.  0.  0.  8.  8.  6.  0.  0.  8.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3  3
  0  6  6  6  0  6 15  8  0  3  0] -> size -> 35 
adversary victory points: -1
player victory points: 4 





Player: 0 
cards in hand: [15.  8.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[-1.7038547]
 [ 2.0788736]
 [ 0.8618822]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  0.  0.  1.] 
cards in discard: [ 3. 25.  0.  6.  6.  0.  0.  8.  8.  6.  0.  0.  8.  0. 11. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3  3
  0  6  6  6  0  6 15  8  0  3  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 20. 30.  8.  0.  9.  7.  0.  7.  9.  9.  9.  2. 10.  9.] 
adversary cards in hand: [ 6.  6. 23.  0.  0.] 
adversary cards in discard: [ 3.  8.  0.  1.  3.  0. 10.  0. 25.  3.  0. 14.  3.  6.  0.  0.  8.  8.
  0.  0.  8.  3. 10.  0.  0.  3. 10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8 10] -> size -> 42 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -3.782067060470581
desired expected reward: 16.271984100341797



action possibilites: [-1] 
expected returns: [[-6.7686477]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 1.] 
cards in discard: [ 3. 25.  0.  6.  6.  0.  0.  8.  8.  6.  0.  0.  8.  0. 11. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3  3  0
  6  6  6  0  6 15  8  0  3  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [12. 26. 30. 20. 30.  8.  0.  9.  7.  0.  7.  9.  9.  9.  2. 10.  9.] 
adversary cards in hand: [ 6.  6. 23.  0.  0.] 
adversary cards in discard: [ 3.  8.  0.  1.  3.  0. 10.  0. 25.  3.  0. 14.  3.  6.  0.  0.  8.  8.
  0.  0.  8.  3. 10.  0.  0.  3. 10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8 10] -> size -> 42 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action 15.0
Learning step: -2.0562384128570557
desired expected reward: 0.022637605667114258





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-2.2333024 ]
 [-2.9313567 ]
 [-1.6507316 ]
 [-2.3174279 ]
 [-0.9886564 ]
 [-2.7199419 ]
 [-2.3221273 ]
 [-3.0017536 ]
 [-2.5167577 ]
 [-0.56259704]
 [-1.3200263 ]
 [-1.8381212 ]
 [-0.6339736 ]
 [-1.2064631 ]
 [-2.033928  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 1.] 
cards in discard: [ 3. 25.  0.  6.  6.  0.  0.  8.  8.  6.  0.  0.  8.  0. 11. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3  3  0
  6  6  6  0  6 15  8  0  3  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 6 
card supply: [12. 26. 30. 20. 30.  8.  0.  9.  7.  0.  7.  9.  9.  9.  2. 10.  9.] 
adversary cards in hand: [ 6.  6. 23.  0.  0.] 
adversary cards in discard: [ 3.  8.  0.  1.  3.  0. 10.  0. 25.  3.  0. 14.  3.  6.  0.  0.  8.  8.
  0.  0.  8.  3. 10.  0.  0.  3. 10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8 10] -> size -> 42 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1
Learning step: -1.4949697256088257
desired expected reward: -8.263617515563965



buy possibilites: [-1] 
expected returns: [[70.84937]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 1.] 
cards in discard: [ 3. 25.  0.  6.  6.  0.  0.  8.  8.  6.  0.  0.  8.  0. 11. 10.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3  3  0
  6  6  6  0  6 15  8  0  3  0  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 6 
card supply: [11. 26. 30. 20. 30.  8.  0.  9.  7.  0.  7.  9.  9.  9.  2. 10.  9.] 
adversary cards in hand: [ 6.  6. 23.  0.  0.] 
adversary cards in discard: [ 3.  8.  0.  1.  3.  0. 10.  0. 25.  3.  0. 14.  3.  6.  0.  0.  8.  8.
  0.  0.  8.  3. 10.  0.  0.  3. 10.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8 10] -> size -> 42 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -50.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -66.0 

action type: buy - action 0.0
Learning step: -1.5942246913909912
desired expected reward: -3.827514886856079






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [ 6.  6. 23.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 23.  0.  0.] 
cards in discard: [ 3.  8.  0.  1.  3.  0. 10.  0. 25.  3.  0. 14.  3.  6.  0.  0.  8.  8.
  0.  0.  8.  3. 10.  0.  0.  3. 10.  3.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8 10] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 20. 30.  8.  0.  9.  7.  0.  7.  9.  9.  9.  2. 10.  9.] 
adversary cards in hand: [ 6.  8.  0.  0. 11.] 
adversary cards in discard: [ 3. 25.  0.  6.  6.  0.  0.  8.  8.  6.  0.  0.  8.  0. 11. 10.  0. 15.
  8.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3  3  0
  6  6  6  0  6 15  8  0  3  0  0] -> size -> 35 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0.  0. 16.] 
cards in discard: [ 3.  8.  0.  1.  3.  0. 10.  0. 25.  3.  0. 14.  3.  6.  0.  0.  8.  8.
  0.  0.  8.  3. 10.  0.  0.  3. 10.  3.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8 10] -> size -> 42 
action values: 1 
buys: 1 
player value: 1 
card supply: [11. 26. 30. 20. 30.  8.  0.  9.  7.  0.  7.  9.  9.  9.  2. 10.  9.] 
adversary cards in hand: [ 6.  8.  0.  0. 11.] 
adversary cards in discard: [ 3. 25.  0.  6.  6.  0.  0.  8.  8.  6.  0.  0.  8.  0. 11. 10.  0. 15.
  8.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3  3  0
  6  6  6  0  6 15  8  0  3  0  0] -> size -> 35 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0.  0. 16.] 
cards in discard: [ 3.  8.  0.  1.  3.  0. 10.  0. 25.  3.  0. 14.  3.  6.  0.  0.  8.  8.
  0.  0.  8.  3. 10.  0.  0.  3. 10.  3.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8 10] -> size -> 42 
action values: 0 
buys: 2 
player value: 3 
card supply: [11. 26. 30. 20. 30.  8.  0.  9.  7.  0.  7.  9.  9.  9.  2. 10.  9.] 
adversary cards in hand: [ 6.  8.  0.  0. 11.] 
adversary cards in discard: [ 3. 25.  0.  6.  6.  0.  0.  8.  8.  6.  0.  0.  8.  0. 11. 10.  0. 15.
  8.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3  3  0
  6  6  6  0  6 15  8  0  3  0  0] -> size -> 35 
adversary victory points: -1
player victory points: 4 


buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0.  0. 16.] 
cards in discard: [ 3.  8.  0.  1.  3.  0. 10.  0. 25.  3.  0. 14.  3.  6.  0.  0.  8.  8.
  0.  0.  8.  3. 10.  0.  0.  3. 10.  3.  0.  0.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8 10  3] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 26. 30. 19. 30.  8.  0.  9.  7.  0.  7.  9.  9.  9.  2. 10.  9.] 
adversary cards in hand: [ 6.  8.  0.  0. 11.] 
adversary cards in discard: [ 3. 25.  0.  6.  6.  0.  0.  8.  8.  6.  0.  0.  8.  0. 11. 10.  0. 15.
  8.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3  3  0
  6  6  6  0  6 15  8  0  3  0  0] -> size -> 35 
adversary victory points: -1
player victory points: 5 





Player: 0 
cards in hand: [ 6.  8.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[52.642544]
 [51.040268]
 [52.664265]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  0.  0. 11.] 
cards in discard: [ 3. 25.  0.  6.  6.  0.  0.  8.  8.  6.  0.  0.  8.  0. 11. 10.  0. 15.
  8.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3  3  0
  6  6  6  0  6 15  8  0  3  0  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 19. 30.  8.  0.  9.  7.  0.  7.  9.  9.  9.  2. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8 10  3] -> size -> 43 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: buy - action -1
Learning step: -5.6661272048950195
desired expected reward: 65.18324279785156



action possibilites: [-1] 
expected returns: [[40.68954]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0. 0.] 
cards in discard: [ 3. 25.  0.  6.  6.  0.  0.  8.  8.  6.  0.  0.  8.  0. 11. 10.  0. 15.
  8.  0.  1.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3  3  0
  6  6  6  0  6 15  8  0  3  0  0  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 25. 30. 19. 30.  8.  0.  9.  7.  0.  7.  9.  9.  9.  2. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8 10  3] -> size -> 43 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  20   0   0   0   0  -1   0   0   9   0] 
sum of rewards: -38 

action type: gain_card_n - action 1
Learning step: -3.554807662963867
desired expected reward: 47.85163879394531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[33.660336]
 [34.507587]
 [36.759853]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0. 0.] 
cards in discard: [ 3. 25.  0.  6.  6.  0.  0.  8.  8.  6.  0.  0.  8.  0. 11. 10.  0. 15.
  8.  0.  1.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3  3  0
  6  6  6  0  6 15  8  0  3  0  0  1] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 25. 30. 19. 30.  8.  0.  9.  7.  0.  7.  9.  9.  9.  2. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8 10  3] -> size -> 43 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1
Learning step: -3.535360336303711
desired expected reward: 37.15418243408203



buy possibilites: [-1] 
expected returns: [[-8.881819]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0. 0.] 
cards in discard: [ 3. 25.  0.  6.  6.  0.  0.  8.  8.  6.  0.  0.  8.  0. 11. 10.  0. 15.
  8.  0.  1.  1.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3  3  0
  6  6  6  0  6 15  8  0  3  0  0  1  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 25. 30. 18. 30.  8.  0.  9.  7.  0.  7.  9.  9.  9.  2. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8 10  3] -> size -> 43 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0  -2   0   0   8   0] 
sum of rewards: -29 

action type: buy - action 3.0
Learning step: -3.3752198219299316
desired expected reward: 31.132360458374023






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [ 3. 10.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8 10  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 25. 30. 18. 30.  8.  0.  9.  7.  0.  7.  9.  9.  9.  2. 10.  9.] 
adversary cards in hand: [ 1. 25.  0.  3.  3.] 
adversary cards in discard: [ 3. 25.  0.  6.  6.  0.  0.  8.  8.  6.  0.  0.  8.  0. 11. 10.  0. 15.
  8.  0.  1.  1.  3. 11.  6.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3  3  0
  6  6  6  0  6 15  8  0  3  0  0  1  3] -> size -> 37 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8 10  3] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 25. 30. 18. 30.  8.  0.  9.  7.  0.  7.  9.  9.  9.  2. 10.  9.] 
adversary cards in hand: [ 1. 25.  0.  3.  3.] 
adversary cards in discard: [ 3. 25.  0.  6.  6.  0.  0.  8.  8.  6.  0.  0.  8.  0. 11. 10.  0. 15.
  8.  0.  1.  1.  3. 11.  6.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3  3  0
  6  6  6  0  6 15  8  0  3  0  0  1  3] -> size -> 37 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0. 11.] 
cards in discard: [0.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8 10  3  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 25. 30. 18. 30.  8.  0.  9.  7.  0.  7.  9.  9.  9.  2. 10.  9.] 
adversary cards in hand: [ 1. 25.  0.  3.  3.] 
adversary cards in discard: [ 3. 25.  0.  6.  6.  0.  0.  8.  8.  6.  0.  0.  8.  0. 11. 10.  0. 15.
  8.  0.  1.  1.  3. 11.  6.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3  3  0
  6  6  6  0  6 15  8  0  3  0  0  1  3] -> size -> 37 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [ 1. 25.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[3.7559972]
 [3.096642 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25.  0.  3.  3.] 
cards in discard: [ 3. 25.  0.  6.  6.  0.  0.  8.  8.  6.  0.  0.  8.  0. 11. 10.  0. 15.
  8.  0.  1.  1.  3. 11.  6.  8.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3  3  0
  6  6  6  0  6 15  8  0  3  0  0  1  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 18. 30.  8.  0.  9.  7.  0.  7.  9.  9.  9.  2. 10.  9.] 
adversary cards in hand: [ 0.  0.  1.  0. 23.] 
adversary cards in discard: [ 0.  3. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8 10  3  0] -> size -> 44 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -2.2265701293945312
desired expected reward: -11.108388900756836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-3.1285028 ]
 [-0.16790247]
 [ 0.3376479 ]
 [ 0.4613154 ]
 [ 0.38417602]
 [ 0.7232313 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 25.  0.  3.  3.] 
cards in discard: [ 3. 25.  0.  6.  6.  0.  0.  8.  8.  6.  0.  0.  8.  0. 11. 10.  0. 15.
  8.  0.  1.  1.  3. 11.  6.  8.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3  3  0
  6  6  6  0  6 15  8  0  3  0  0  1  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 25. 30. 18. 30.  8.  0.  9.  7.  0.  7.  9.  9.  9.  2. 10.  9.] 
adversary cards in hand: [ 0.  0.  1.  0. 23.] 
adversary cards in discard: [ 0.  3. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8 10  3  0] -> size -> 44 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -2.936505079269409
desired expected reward: 0.8195068836212158



buy possibilites: [-1] 
expected returns: [[-10.204723]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 25.  0.  3.  3.] 
cards in discard: [ 3. 25.  0.  6.  6.  0.  0.  8.  8.  6.  0.  0.  8.  0. 11. 10.  0. 15.
  8.  0.  1.  1.  3. 11.  6.  8.  0.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3  3  0
  6  6  6  0  6 15  8  0  3  0  0  1  3 11] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 18. 30.  8.  0.  9.  6.  0.  7.  9.  9.  9.  2. 10.  9.] 
adversary cards in hand: [ 0.  0.  1.  0. 23.] 
adversary cards in discard: [ 0.  3. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8 10  3  0] -> size -> 44 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0  -3   0   0  18   0] 
sum of rewards: -40 

action type: buy - action 11.0
Learning step: -2.2526724338531494
desired expected reward: -1.791349172592163






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  1.  0. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1.  0. 23.] 
cards in discard: [ 0.  3. 10.  0.  0. 11.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8 10  3  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 18. 30.  8.  0.  9.  6.  0.  7.  9.  9.  9.  2. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3  3  0
  6  6  6  0  6 15  8  0  3  0  0  1  3 11] -> size -> 38 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [ 0.  3. 10.  0.  0. 11.] 
cards in deck: 32 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8 10  3  0] -> size -> 44 
action values: 1 
buys: 1 
player value: 1 
card supply: [10. 25. 30. 18. 30.  8.  0.  9.  6.  0.  7.  9.  9.  9.  2. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3  3  0
  6  6  6  0  6 15  8  0  3  0  0  1  3 11] -> size -> 38 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [ 0.  3. 10.  0.  0. 11.] 
cards in deck: 32 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8 10  3  0] -> size -> 44 
action values: 0 
buys: 2 
player value: 7 
card supply: [10. 25. 30. 18. 30.  8.  0.  9.  6.  0.  7.  9.  9.  9.  2. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3  3  0
  6  6  6  0  6 15  8  0  3  0  0  1  3 11] -> size -> 38 
adversary victory points: 0
player victory points: 5 


buy possibilites: [ 0.  1.  2.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [ 0.  3. 10.  0.  0. 11.  0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8 10  3  0  0] -> size -> 45 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 9. 25. 30. 18. 30.  8.  0.  9.  6.  0.  7.  9.  9.  9.  2. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3  3  0
  6  6  6  0  6 15  8  0  3  0  0  1  3 11] -> size -> 38 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [ 0.  3. 10.  0.  0. 11.  0. 16.] 
cards in deck: 32 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8 10  3  0  0 16] -> size -> 46 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 9. 25. 30. 18. 30.  8.  0.  8.  6.  0.  7.  9.  9.  9.  2. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3  3  0
  6  6  6  0  6 15  8  0  3  0  0  1  3 11] -> size -> 38 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [ 0.  3.  0.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[4.7227607]
 [1.6666255]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  6. 10.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3  3  0
  6  6  6  0  6 15  8  0  3  0  0  1  3 11] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 18. 30.  8.  0.  8.  6.  0.  7.  9.  9.  9.  2. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  0.  0.] 
adversary cards in discard: [ 0.  3. 10.  0.  0. 11.  0. 16. 23.  0.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8 10  3  0  0 16] -> size -> 46 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -2.157468795776367
desired expected reward: -12.362192153930664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[1.5622983]
 [1.9371758]
 [6.1156917]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  6. 10.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3  3  0
  6  6  6  0  6 15  8  0  3  0  0  1  3 11] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 25. 30. 18. 30.  8.  0.  8.  6.  0.  7.  9.  9.  9.  2. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  0.  0.] 
adversary cards in discard: [ 0.  3. 10.  0.  0. 11.  0. 16. 23.  0.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8 10  3  0  0 16] -> size -> 46 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -2.894186019897461
desired expected reward: 1.82855224609375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  0.] 
cards in discard: [ 0.  3. 10.  0.  0. 11.  0. 16. 23.  0.  0.  1.  0.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8 10  3  0  0 16] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 18. 30.  8.  0.  8.  6.  0.  7.  9.  9.  9.  2. 10.  9.] 
adversary cards in hand: [ 0.  8. 10.  8. 11.] 
adversary cards in discard: [ 0.  3.  0.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3  3  0
  6  6  6  0  6 15  8  0  3  0  0  1  3 11] -> size -> 38 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  0.] 
cards in discard: [ 0.  3. 10.  0.  0. 11.  0. 16. 23.  0.  0.  1.  0.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8 10  3  0  0 16] -> size -> 46 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 9. 25. 30. 18. 30.  8.  0.  8.  6.  0.  7.  9.  9.  9.  2. 10.  9.] 
adversary cards in hand: [ 0.  8. 10.  8. 11.] 
adversary cards in discard: [ 0.  3.  0.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3  3  0
  6  6  6  0  6 15  8  0  3  0  0  1  3 11] -> size -> 38 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  0.] 
cards in discard: [ 0.  3. 10.  0.  0. 11.  0. 16. 23.  0.  0.  1.  0.  0. 29.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8 10  3  0  0 16 29] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 18. 30.  8.  0.  8.  6.  0.  7.  8.  9.  9.  2. 10.  9.] 
adversary cards in hand: [ 0.  8. 10.  8. 11.] 
adversary cards in discard: [ 0.  3.  0.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3  3  0
  6  6  6  0  6 15  8  0  3  0  0  1  3 11] -> size -> 38 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [ 0.  8. 10.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8. 11.] 
expected returns: [[7.4972453]
 [6.4338603]
 [7.525307 ]
 [6.4338603]
 [6.857302 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.  8. 11.] 
cards in discard: [ 0.  3.  0.  6. 10.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3  3  0
  6  6  6  0  6 15  8  0  3  0  0  1  3 11] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 18. 30.  8.  0.  8.  6.  0.  7.  8.  9.  9.  2. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  6. 10.] 
adversary cards in discard: [ 0.  3. 10.  0.  0. 11.  0. 16. 23.  0.  0.  1.  0.  0. 29.  0.  0. 10.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8 10  3  0  0 16 29] -> size -> 47 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1.0
Learning step: -2.8954951763153076
desired expected reward: 3.2201755046844482



action possibilites: [-1] 
expected returns: [[20.832195]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.  8.] 
cards in discard: [ 0.  3.  0.  6. 10.  1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3  3  0
  6  6  6  0  6 15  8  0  3  0  0  1  3 11  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 24. 30. 18. 30.  8.  0.  8.  6.  0.  7.  8.  9.  9.  2. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  6. 10.] 
adversary cards in discard: [ 0.  3. 10.  0.  0. 11.  0. 16. 23.  0.  0.  1.  0.  0. 29.  0.  0. 10.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8 10  3  0  0 16 29] -> size -> 47 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0  -4   0   0   9   0] 
sum of rewards: -30 

action type: gain_card_n - action 1
Learning step: -1.1406333446502686
desired expected reward: 1.0465211868286133





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[15.629195]
 [19.716661]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10.  8.] 
cards in discard: [ 0.  3.  0.  6. 10.  1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3  3  0
  6  6  6  0  6 15  8  0  3  0  0  1  3 11  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 24. 30. 18. 30.  8.  0.  8.  6.  0.  7.  8.  9.  9.  2. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  6. 10.] 
adversary cards in discard: [ 0.  3. 10.  0.  0. 11.  0. 16. 23.  0.  0.  1.  0.  0. 29.  0.  0. 10.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8 10  3  0  0 16 29] -> size -> 47 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1
Learning step: -2.380039930343628
desired expected reward: 18.45215606689453



buy possibilites: [-1] 
expected returns: [[10.777002]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10.  8.] 
cards in discard: [ 0.  3.  0.  6. 10.  1.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3  3  0
  6  6  6  0  6 15  8  0  3  0  0  1  3 11  1  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 24. 30. 18. 30.  8.  0.  8.  6.  0.  7.  8.  9.  9.  2. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  6. 10.] 
adversary cards in discard: [ 0.  3. 10.  0.  0. 11.  0. 16. 23.  0.  0.  1.  0.  0. 29.  0.  0. 10.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8 10  3  0  0 16 29] -> size -> 47 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -50.   0.   0.  20. -30.   0.   0.   0.  -5.   0.   0.
   0.   0.] 
sum of rewards: -70.0 

action type: buy - action 0.0
Learning step: -4.038978576660156
desired expected reward: 11.590237617492676






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  3.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  6. 10.] 
cards in discard: [ 0.  3. 10.  0.  0. 11.  0. 16. 23.  0.  0.  1.  0.  0. 29.  0.  0. 10.
  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8 10  3  0  0 16 29] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 24. 30. 18. 30.  8.  0.  8.  6.  0.  7.  8.  9.  9.  2. 10.  9.] 
adversary cards in hand: [3. 1. 6. 8. 3.] 
adversary cards in discard: [ 0.  3.  0.  6. 10.  1.  0. 11.  0.  8. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3  3  0
  6  6  6  0  6 15  8  0  3  0  0  1  3 11  1  0] -> size -> 40 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  6. 10.] 
cards in discard: [ 0.  3. 10.  0.  0. 11.  0. 16. 23.  0.  0.  1.  0.  0. 29.  0.  0. 10.
  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8 10  3  0  0 16 29] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 24. 30. 18. 30.  8.  0.  8.  6.  0.  7.  8.  9.  9.  2. 10.  9.] 
adversary cards in hand: [3. 1. 6. 8. 3.] 
adversary cards in discard: [ 0.  3.  0.  6. 10.  1.  0. 11.  0.  8. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3  3  0
  6  6  6  0  6 15  8  0  3  0  0  1  3 11  1  0] -> size -> 40 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  6. 10.] 
cards in discard: [ 0.  3. 10.  0.  0. 11.  0. 16. 23.  0.  0.  1.  0.  0. 29.  0.  0. 10.
  0.  0.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 24. 30. 17. 30.  8.  0.  8.  6.  0.  7.  8.  9.  9.  2. 10.  9.] 
adversary cards in hand: [3. 1. 6. 8. 3.] 
adversary cards in discard: [ 0.  3.  0.  6. 10.  1.  0. 11.  0.  8. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3  3  0
  6  6  6  0  6 15  8  0  3  0  0  1  3 11  1  0] -> size -> 40 
adversary victory points: 0
player victory points: 6 





Player: 0 
cards in hand: [3. 1. 6. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-1.3556482]
 [-2.8256252]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 6. 8. 3.] 
cards in discard: [ 0.  3.  0.  6. 10.  1.  0. 11.  0.  8. 10.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10  6 25  0 11  1  1  3  8 25  8  8 11 10  8  0  3  3  0
  6  6  6  0  6 15  8  0  3  0  0  1  3 11  1  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 24. 30. 17. 30.  8.  0.  8.  6.  0.  7.  8.  9.  9.  2. 10.  9.] 
adversary cards in hand: [ 3. 14.  6.  0. 25.] 
adversary cards in discard: [ 0.  3. 10.  0.  0. 11.  0. 16. 23.  0.  0.  1.  0.  0. 29.  0.  0. 10.
  0.  0.  3.  0.  0.  3.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3] -> size -> 48 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: -3.8308799266815186
desired expected reward: 6.946122169494629



action possibilites: [-1] 
expected returns: [[44.93654]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 0.  3.  0.  6. 10.  1.  0. 11.  0.  8. 10.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 10 25  0 11  1  8 25  8  8 11 10  8  0  3  3  0  6  6  6
  0  6 15  8  0  3  0  0  1  3 11  1  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 24. 30. 17. 30.  8.  0.  8.  6.  0.  7.  8.  9.  9.  2. 10.  9.] 
adversary cards in hand: [ 3. 14.  6.  0. 25.] 
adversary cards in discard: [ 0.  3. 10.  0.  0. 11.  0. 16. 23.  0.  0.  1.  0.  0. 29.  0.  0. 10.
  0.  0.  3.  0.  0.  3.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3] -> size -> 48 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: trash_cards_n_from_hand - action 10
Learning step: -1.1666514873504639
desired expected reward: -2.6121816635131836





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[42.04069 ]
 [46.014008]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 0.  3.  0.  6. 10.  1.  0. 11.  0.  8. 10.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 10 25  0 11  1  8 25  8  8 11 10  8  0  3  3  0  6  6  6
  0  6 15  8  0  3  0  0  1  3 11  1  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 24. 30. 17. 30.  8.  0.  8.  6.  0.  7.  8.  9.  9.  2. 10.  9.] 
adversary cards in hand: [ 3. 14.  6.  0. 25.] 
adversary cards in discard: [ 0.  3. 10.  0.  0. 11.  0. 16. 23.  0.  0.  1.  0.  0. 29.  0.  0. 10.
  0.  0.  3.  0.  0.  3.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3] -> size -> 48 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: -3.4926717281341553
desired expected reward: 41.44386672973633






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [ 3. 14.  6.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  6.  0. 25.] 
cards in discard: [ 0.  3. 10.  0.  0. 11.  0. 16. 23.  0.  0.  1.  0.  0. 29.  0.  0. 10.
  0.  0.  3.  0.  0.  3.  6. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 24. 30. 17. 30.  8.  0.  8.  6.  0.  7.  8.  9.  9.  2. 10.  9.] 
adversary cards in hand: [ 6. 11.  0.  0.  0.] 
adversary cards in discard: [ 0.  3.  0.  6. 10.  1.  0. 11.  0.  8. 10.  8.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0 10 25  0 11  1  8 25  8  8 11 10  8  0  3  3  0  6  6  6
  0  6 15  8  0  3  0  0  1  3 11  1  0] -> size -> 37 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  6.  0. 25.] 
cards in discard: [ 0.  3. 10.  0.  0. 11.  0. 16. 23.  0.  0.  1.  0.  0. 29.  0.  0. 10.
  0.  0.  3.  0.  0.  3.  6. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3] -> size -> 48 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 24. 30. 17. 30.  8.  0.  8.  6.  0.  7.  8.  9.  9.  2. 10.  9.] 
adversary cards in hand: [ 6. 11.  0.  0.  0.] 
adversary cards in discard: [ 0.  3.  0.  6. 10.  1.  0. 11.  0.  8. 10.  8.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0 10 25  0 11  1  8 25  8  8 11 10  8  0  3  3  0  6  6  6
  0  6 15  8  0  3  0  0  1  3 11  1  0] -> size -> 37 
adversary victory points: 0
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  6.  0. 25.] 
cards in discard: [ 0.  3. 10.  0.  0. 11.  0. 16. 23.  0.  0.  1.  0.  0. 29.  0.  0. 10.
  0.  0.  3.  0.  0.  3.  6. 10.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3
  0] -> size -> 49 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 24. 30. 17. 30.  8.  0.  8.  6.  0.  7.  8.  9.  9.  2. 10.  9.] 
adversary cards in hand: [ 6. 11.  0.  0.  0.] 
adversary cards in discard: [ 0.  3.  0.  6. 10.  1.  0. 11.  0.  8. 10.  8.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0 10 25  0 11  1  8 25  8  8 11 10  8  0  3  3  0  6  6  6
  0  6 15  8  0  3  0  0  1  3 11  1  0] -> size -> 37 
adversary victory points: 0
player victory points: 6 





Player: 0 
cards in hand: [ 6. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[-10.742966]
 [-11.119346]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0.  0.  0.] 
cards in discard: [ 0.  3.  0.  6. 10.  1.  0. 11.  0.  8. 10.  8.  8.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 25  0 11  1  8 25  8  8 11 10  8  0  3  3  0  6  6  6
  0  6 15  8  0  3  0  0  1  3 11  1  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 17. 30.  8.  0.  8.  6.  0.  7.  8.  9.  9.  2. 10.  9.] 
adversary cards in hand: [8. 0. 8. 0. 0.] 
adversary cards in discard: [ 0.  3. 10.  0.  0. 11.  0. 16. 23.  0.  0.  1.  0.  0. 29.  0.  0. 10.
  0.  0.  3.  0.  0.  3.  6. 10.  0.  3. 14.  6.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3
  0] -> size -> 49 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: -5.7953691482543945
desired expected reward: 40.21863555908203



action possibilites: [-1] 
expected returns: [[13.373706]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [ 0.  3.  0.  6. 10.  1.  0. 11.  0.  8. 10.  8.  8.  3. 14.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0 10 25  0 11  1  8 25  8  8 11 10  8  0  3  3  0  6  6  6
  0  6 15  8  0  3  0  0  1  3 11  1  0 14] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 17. 30.  8.  0.  8.  6.  0.  7.  8.  8.  9.  2. 10.  9.] 
adversary cards in hand: [8. 0. 8. 0. 0.] 
adversary cards in discard: [ 0.  3. 10.  0.  0. 11.  0. 16. 23.  0.  0.  1.  0.  0. 29.  0.  0. 10.
  0.  0.  3.  0.  0.  3.  6. 10.  0.  3. 14.  6.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3
  0] -> size -> 49 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0  -3   0   0  16   0] 
sum of rewards: -32 

action type: gain_card_n - action 6
Learning step: -0.7655815482139587
desired expected reward: -11.435783386230469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[ 9.895262]
 [12.075418]
 [11.785538]
 [15.726659]
 [11.539802]
 [16.664942]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [ 0.  3.  0.  6. 10.  1.  0. 11.  0.  8. 10.  8.  8.  3. 14.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0 10 25  0 11  1  8 25  8  8 11 10  8  0  3  3  0  6  6  6
  0  6 15  8  0  3  0  0  1  3 11  1  0 14] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 24. 30. 17. 30.  8.  0.  8.  6.  0.  7.  8.  8.  9.  2. 10.  9.] 
adversary cards in hand: [8. 0. 8. 0. 0.] 
adversary cards in discard: [ 0.  3. 10.  0.  0. 11.  0. 16. 23.  0.  0.  1.  0.  0. 29.  0.  0. 10.
  0.  0.  3.  0.  0.  3.  6. 10.  0.  3. 14.  6.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3
  0] -> size -> 49 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: -2.6020238399505615
desired expected reward: 10.771681785583496



buy possibilites: [-1] 
expected returns: [[-14.785107]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [ 0.  3.  0.  6. 10.  1.  0. 11.  0.  8. 10.  8.  8.  3. 14.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0 10 25  0 11  1  8 25  8  8 11 10  8  0  3  3  0  6  6  6
  0  6 15  8  0  3  0  0  1  3 11  1  0 14  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 6. 24. 30. 17. 30.  8.  0.  8.  6.  0.  7.  8.  8.  9.  2. 10.  9.] 
adversary cards in hand: [8. 0. 8. 0. 0.] 
adversary cards in discard: [ 0.  3. 10.  0.  0. 11.  0. 16. 23.  0.  0.  1.  0.  0. 29.  0.  0. 10.
  0.  0.  3.  0.  0.  3.  6. 10.  0.  3. 14.  6.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3
  0] -> size -> 49 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.  20. -30.   0.   0.   0.  -4.   0.   0.
   0.   0.] 
sum of rewards: -79.0 

action type: buy - action 0.0
Learning step: -4.777427673339844
desired expected reward: 5.117827415466309






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [8. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 0. 0.] 
cards in discard: [ 0.  3. 10.  0.  0. 11.  0. 16. 23.  0.  0.  1.  0.  0. 29.  0.  0. 10.
  0.  0.  3.  0.  0.  3.  6. 10.  0.  3. 14.  6.  0. 25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  8  0  6  8  1
  6  0 10  0 25 11  6 10  0  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3
  0] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 24. 30. 17. 30.  8.  0.  8.  6.  0.  7.  8.  8.  9.  2. 10.  9.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [ 0.  3.  0.  6. 10.  1.  0. 11.  0.  8. 10.  8.  8.  3. 14.  0. 11.  6.
  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 10 25  0 11  1  8 25  8  8 11 10  8  0  3  3  0  6  6  6
  0  6 15  8  0  3  0  0  1  3 11  1  0 14  0] -> size -> 39 
adversary victory points: 0
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 0.  3. 10.  0.  0. 11.  0. 16. 23.  0.  0.  1.  0.  0. 29.  0.  0. 10.
  0.  0.  3.  0.  0.  3.  6. 10.  0.  3. 14.  6.  0. 25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  0  6  8  1  6  0 10  0
 25 11  6 10  0  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 24. 30. 17. 30.  8.  0.  8.  6.  0.  7.  8.  8.  9.  2. 10.  9.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [ 0.  3.  0.  6. 10.  1.  0. 11.  0.  8. 10.  8.  8.  3. 14.  0. 11.  6.
  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 10 25  0 11  1  8 25  8  8 11 10  8  0  3  3  0  6  6  6
  0  6 15  8  0  3  0  0  1  3 11  1  0 14  0] -> size -> 39 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0.  3. 10.  0.  0. 11.  0. 16. 23.  0.  0.  1.  0.  0. 29.  0.  0. 10.
  0.  0.  3.  0.  0.  3.  6. 10.  0.  3. 14.  6.  0. 25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  0  6  8  1  6  0 10  0
 25 11  6 10  0  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3  0] -> size -> 45 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 6. 24. 30. 17. 30.  8.  0.  8.  6.  0.  7.  8.  8.  9.  2. 10.  9.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [ 0.  3.  0.  6. 10.  1.  0. 11.  0.  8. 10.  8.  8.  3. 14.  0. 11.  6.
  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 10 25  0 11  1  8 25  8  8 11 10  8  0  3  3  0  6  6  6
  0  6 15  8  0  3  0  0  1  3 11  1  0 14  0] -> size -> 39 
adversary victory points: 0
player victory points: 6 





Player: 0 
cards in hand: [0. 0. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-2.9332347]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [ 0.  3.  0.  6. 10.  1.  0. 11.  0.  8. 10.  8.  8.  3. 14.  0. 11.  6.
  0.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 25  0 11  1  8 25  8  8 11 10  8  0  3  3  0  6  6  6
  0  6 15  8  0  3  0  0  1  3 11  1  0 14  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 24. 30. 17. 30.  8.  0.  8.  6.  0.  7.  8.  8.  9.  2. 10.  9.] 
adversary cards in hand: [ 3. 16.  3.  8.  0.] 
adversary cards in discard: [ 0.  3. 10.  0.  0. 11.  0. 16. 23.  0.  0.  1.  0.  0. 29.  0.  0. 10.
  0.  0.  3.  0.  0.  3.  6. 10.  0.  3. 14.  6.  0. 25.  8.] 
adversary owned cards: [ 0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  0  6  8  1  6  0 10  0
 25 11  6 10  0  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3  0] -> size -> 45 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: -2.57674241065979
desired expected reward: -17.361848831176758





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[-2.379806 ]
 [-2.8662608]
 [-2.6105645]
 [-2.6738307]
 [-2.9228249]
 [-2.7041965]
 [-1.5395342]
 [-2.4378808]
 [-2.1481962]
 [-3.0653923]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [ 0.  3.  0.  6. 10.  1.  0. 11.  0.  8. 10.  8.  8.  3. 14.  0. 11.  6.
  0.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 25  0 11  1  8 25  8  8 11 10  8  0  3  3  0  6  6  6
  0  6 15  8  0  3  0  0  1  3 11  1  0 14  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 6. 24. 30. 17. 30.  8.  0.  8.  6.  0.  7.  8.  8.  9.  2. 10.  9.] 
adversary cards in hand: [ 3. 16.  3.  8.  0.] 
adversary cards in discard: [ 0.  3. 10.  0.  0. 11.  0. 16. 23.  0.  0.  1.  0.  0. 29.  0.  0. 10.
  0.  0.  3.  0.  0.  3.  6. 10.  0.  3. 14.  6.  0. 25.  8.] 
adversary owned cards: [ 0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  0  6  8  1  6  0 10  0
 25 11  6 10  0  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3  0] -> size -> 45 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: -3.1535890102386475
desired expected reward: -6.086823463439941



buy possibilites: [-1] 
expected returns: [[-6.5525103]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [ 0.  3.  0.  6. 10.  1.  0. 11.  0.  8. 10.  8.  8.  3. 14.  0. 11.  6.
  0.  0.  0. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 25  0 11  1  8 25  8  8 11 10  8  0  3  3  0  6  6  6
  0  6 15  8  0  3  0  0  1  3 11  1  0 14  0 10] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 24. 30. 17. 30.  8.  0.  8.  6.  0.  7.  8.  8.  9.  1. 10.  9.] 
adversary cards in hand: [ 3. 16.  3.  8.  0.] 
adversary cards in discard: [ 0.  3. 10.  0.  0. 11.  0. 16. 23.  0.  0.  1.  0.  0. 29.  0.  0. 10.
  0.  0.  3.  0.  0.  3.  6. 10.  0.  3. 14.  6.  0. 25.  8.] 
adversary owned cards: [ 0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  0  6  8  1  6  0 10  0
 25 11  6 10  0  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3  0] -> size -> 45 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5.    0.    0.  -60.    0.    0.    0.    0.    0.    0.    0.   -5.
   0.    0.    4.5   0. ] 
sum of rewards: -65.5 

action type: buy - action 10.0
Learning step: -3.3005378246307373
desired expected reward: -5.738415241241455






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [ 3. 16.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  3.  8.  0.] 
cards in discard: [ 0.  3. 10.  0.  0. 11.  0. 16. 23.  0.  0.  1.  0.  0. 29.  0.  0. 10.
  0.  0.  3.  0.  0.  3.  6. 10.  0.  3. 14.  6.  0. 25.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 14 16  0  0  0 10  3 23  3  3  3  0  0  6  8  1  6  0 10  0
 25 11  6 10  0  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 24. 30. 17. 30.  8.  0.  8.  6.  0.  7.  8.  8.  9.  1. 10.  9.] 
adversary cards in hand: [ 3.  8. 11.  6.  0.] 
adversary cards in discard: [ 0.  3.  0.  6. 10.  1.  0. 11.  0.  8. 10.  8.  8.  3. 14.  0. 11.  6.
  0.  0.  0. 10.  0.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0 10 25  0 11  1  8 25  8  8 11 10  8  0  3  3  0  6  6  6
  0  6 15  8  0  3  0  0  1  3 11  1  0 14  0 10] -> size -> 40 
adversary victory points: 0
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 0.  3. 10.  0.  0. 11.  0. 16. 23.  0.  0.  1.  0.  0. 29.  0.  0. 10.
  0.  0.  3.  0.  0.  3.  6. 10.  0.  3. 14.  6.  0. 25.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 14  0  0  0 10  3 23  3  3  3  0  0  6  8  1  6  0 10  0 25 11  6
 10  0  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 24. 30. 17. 30.  8.  0.  8.  6.  0.  7.  8.  8.  9.  1. 10.  9.] 
adversary cards in hand: [ 3.  8. 11.  6.  0.] 
adversary cards in discard: [ 0.  3.  0.  6. 10.  1.  0. 11.  0.  8. 10.  8.  8.  3. 14.  0. 11.  6.
  0.  0.  0. 10.  0.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0 10 25  0 11  1  8 25  8  8 11 10  8  0  3  3  0  6  6  6
  0  6 15  8  0  3  0  0  1  3 11  1  0 14  0 10] -> size -> 40 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 0.  3. 10.  0.  0. 11.  0. 16. 23.  0.  0.  1.  0.  0. 29.  0.  0. 10.
  0.  0.  3.  0.  0.  3.  6. 10.  0.  3. 14.  6.  0. 25.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 14  0  0  0 10  3 23  3  3  3  0  0  6  8  1  6  0 10  0 25 11  6
 10  0  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 6. 24. 30. 17. 30.  8.  0.  8.  6.  0.  7.  8.  8.  9.  1. 10.  9.] 
adversary cards in hand: [ 3.  8. 11.  6.  0.] 
adversary cards in discard: [ 0.  3.  0.  6. 10.  1.  0. 11.  0.  8. 10.  8.  8.  3. 14.  0. 11.  6.
  0.  0.  0. 10.  0.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0 10 25  0 11  1  8 25  8  8 11 10  8  0  3  3  0  6  6  6
  0  6 15  8  0  3  0  0  1  3 11  1  0 14  0 10] -> size -> 40 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [ 3.  8. 11.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[ 2.6081693 ]
 [-0.34236836]
 [ 1.6909435 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 11.  6.  0.] 
cards in discard: [ 0.  3.  0.  6. 10.  1.  0. 11.  0.  8. 10.  8.  8.  3. 14.  0. 11.  6.
  0.  0.  0. 10.  0.  0.  0.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 25  0 11  1  8 25  8  8 11 10  8  0  3  3  0  6  6  6
  0  6 15  8  0  3  0  0  1  3 11  1  0 14  0 10] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 24. 30. 17. 30.  8.  0.  8.  6.  0.  7.  8.  8.  9.  1. 10.  9.] 
adversary cards in hand: [10.  3.  0.  8.  3.] 
adversary cards in discard: [ 0.  3. 10.  0.  0. 11.  0. 16. 23.  0.  0.  1.  0.  0. 29.  0.  0. 10.
  0.  0.  3.  0.  0.  3.  6. 10.  0.  3. 14.  6.  0. 25.  8.  8.  3.] 
adversary owned cards: [ 0  0 14  0  0  0 10  3 23  3  3  3  0  0  6  8  1  6  0 10  0 25 11  6
 10  0  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3  0] -> size -> 42 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -2.3839120864868164
desired expected reward: -8.936422348022461





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-4.52092  ]
 [ 3.1464837]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 11.  6.  0.] 
cards in discard: [ 0.  3.  0.  6. 10.  1.  0. 11.  0.  8. 10.  8.  8.  3. 14.  0. 11.  6.
  0.  0.  0. 10.  0.  0.  0.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 25  0 11  1  8 25  8  8 11 10  8  0  3  3  0  6  6  6
  0  6 15  8  0  3  0  0  1  3 11  1  0 14  0 10] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 24. 30. 17. 30.  8.  0.  8.  6.  0.  7.  8.  8.  9.  1. 10.  9.] 
adversary cards in hand: [10.  3.  0.  8.  3.] 
adversary cards in discard: [ 0.  3. 10.  0.  0. 11.  0. 16. 23.  0.  0.  1.  0.  0. 29.  0.  0. 10.
  0.  0.  3.  0.  0.  3.  6. 10.  0.  3. 14.  6.  0. 25.  8.  8.  3.] 
adversary owned cards: [ 0  0 14  0  0  0 10  3 23  3  3  3  0  0  6  8  1  6  0 10  0 25 11  6
 10  0  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3  0] -> size -> 42 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -2.8241775035858154
desired expected reward: -1.1273102760314941



buy possibilites: [-1] 
expected returns: [[1.087868]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 11.  6.  0.] 
cards in discard: [ 0.  3.  0.  6. 10.  1.  0. 11.  0.  8. 10.  8.  8.  3. 14.  0. 11.  6.
  0.  0.  0. 10.  0.  0.  0.  6.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 25  0 11  1  8 25  8  8 11 10  8  0  3  3  0  6  6  6
  0  6 15  8  0  3  0  0  1  3 11  1  0 14  0 10  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 24. 30. 17. 30.  8.  0.  8.  6.  0.  7.  8.  8.  9.  1. 10.  9.] 
adversary cards in hand: [10.  3.  0.  8.  3.] 
adversary cards in discard: [ 0.  3. 10.  0.  0. 11.  0. 16. 23.  0.  0.  1.  0.  0. 29.  0.  0. 10.
  0.  0.  3.  0.  0.  3.  6. 10.  0.  3. 14.  6.  0. 25.  8.  8.  3.] 
adversary owned cards: [ 0  0 14  0  0  0 10  3 23  3  3  3  0  0  6  8  1  6  0 10  0 25 11  6
 10  0  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3  0] -> size -> 42 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -50.   0.   0.   0. -30.   0.   0.   0.  -6.   0.   0.
   0.   0.] 
sum of rewards: -91.0 

action type: buy - action 0.0
Learning step: -4.299476146697998
desired expected reward: -8.820415496826172






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [10.  3.  0.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  8.  3.] 
cards in discard: [ 0.  3. 10.  0.  0. 11.  0. 16. 23.  0.  0.  1.  0.  0. 29.  0.  0. 10.
  0.  0.  3.  0.  0.  3.  6. 10.  0.  3. 14.  6.  0. 25.  8.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14  0  0  0 10  3 23  3  3  3  0  0  6  8  1  6  0 10  0 25 11  6
 10  0  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 24. 30. 17. 30.  8.  0.  8.  6.  0.  7.  8.  8.  9.  1. 10.  9.] 
adversary cards in hand: [ 3.  8. 25.  0.  1.] 
adversary cards in discard: [ 0.  3.  0.  6. 10.  1.  0. 11.  0.  8. 10.  8.  8.  3. 14.  0. 11.  6.
  0.  0.  0. 10.  0.  0.  0.  6.  0.  0.  3.  8. 11.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0 10 25  0 11  1  8 25  8  8 11 10  8  0  3  3  0  6  6  6
  0  6 15  8  0  3  0  0  1  3 11  1  0 14  0 10  0] -> size -> 41 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [ 0.  3. 10.  0.  0. 11.  0. 16. 23.  0.  0.  1.  0.  0. 29.  0.  0. 10.
  0.  0.  3.  0.  0.  3.  6. 10.  0.  3. 14.  6.  0. 25.  8.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 14  0  0  0 23  3  3  3  0  0  6  8  1  6  0 10  0 25 11  6 10  0
  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 24. 30. 17. 30.  8.  0.  8.  6.  0.  7.  8.  8.  9.  1. 10.  9.] 
adversary cards in hand: [ 3.  8. 25.  0.  1.] 
adversary cards in discard: [ 0.  3.  0.  6. 10.  1.  0. 11.  0.  8. 10.  8.  8.  3. 14.  0. 11.  6.
  0.  0.  0. 10.  0.  0.  0.  6.  0.  0.  3.  8. 11.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0 10 25  0 11  1  8 25  8  8 11 10  8  0  3  3  0  6  6  6
  0  6 15  8  0  3  0  0  1  3 11  1  0 14  0 10  0] -> size -> 41 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 0.  3. 10.  0.  0. 11.  0. 16. 23.  0.  0.  1.  0.  0. 29.  0.  0. 10.
  0.  0.  3.  0.  0.  3.  6. 10.  0.  3. 14.  6.  0. 25.  8.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 14  0  0  0 23  3  3  3  0  0  6  8  1  6  0 10  0 25 11  6 10  0
  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 24. 30. 17. 30.  8.  0.  8.  6.  0.  7.  8.  8.  9.  1. 10.  9.] 
adversary cards in hand: [ 3.  8. 25.  0.  1.] 
adversary cards in discard: [ 0.  3.  0.  6. 10.  1.  0. 11.  0.  8. 10.  8.  8.  3. 14.  0. 11.  6.
  0.  0.  0. 10.  0.  0.  0.  6.  0.  0.  3.  8. 11.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0 10 25  0 11  1  8 25  8  8 11 10  8  0  3  3  0  6  6  6
  0  6 15  8  0  3  0  0  1  3 11  1  0 14  0 10  0] -> size -> 41 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 0.  3. 10.  0.  0. 11.  0. 16. 23.  0.  0.  1.  0.  0. 29.  0.  0. 10.
  0.  0.  3.  0.  0.  3.  6. 10.  0.  3. 14.  6.  0. 25.  8.  8.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 14  0  0  0 23  3  3  3  0  0  6  8  1  6  0 10  0 25 11  6 10  0
  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3  0  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 24. 30. 17. 30.  8.  0.  8.  6.  0.  7.  8.  8.  9.  1. 10.  9.] 
adversary cards in hand: [ 3.  8. 25.  0.  1.] 
adversary cards in discard: [ 0.  3.  0.  6. 10.  1.  0. 11.  0.  8. 10.  8.  8.  3. 14.  0. 11.  6.
  0.  0.  0. 10.  0.  0.  0.  6.  0.  0.  3.  8. 11.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0 10 25  0 11  1  8 25  8  8 11 10  8  0  3  3  0  6  6  6
  0  6 15  8  0  3  0  0  1  3 11  1  0 14  0 10  0] -> size -> 41 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [ 3.  8. 25.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
expected returns: [[20.209208]
 [17.656847]
 [22.945557]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 25.  0.  1.] 
cards in discard: [ 0.  3.  0.  6. 10.  1.  0. 11.  0.  8. 10.  8.  8.  3. 14.  0. 11.  6.
  0.  0.  0. 10.  0.  0.  0.  6.  0.  0.  3.  8. 11.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10 25  0 11  1  8 25  8  8 11 10  8  0  3  3  0  6  6  6
  0  6 15  8  0  3  0  0  1  3 11  1  0 14  0 10  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 17. 30.  8.  0.  8.  6.  0.  7.  8.  8.  9.  1. 10.  9.] 
adversary cards in hand: [ 8.  3. 16.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 14  0  0  0 23  3  3  3  0  0  6  8  1  6  0 10  0 25 11  6 10  0
  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3  0  0] -> size -> 41 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -1.8300749063491821
desired expected reward: -0.7422069311141968



action possibilites: [-1] 
expected returns: [[-8.7072]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.] 
cards in discard: [ 0.  3.  0.  6. 10.  1.  0. 11.  0.  8. 10.  8.  8.  3. 14.  0. 11.  6.
  0.  0.  0. 10.  0.  0.  0.  6.  0.  0.  3.  8. 11.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 10 25  0 11  8 25  8  8 11 10  8  0  3  0  6  6  6  0  6 15
  8  0  3  0  0  1  3 11  1  0 14  0 10  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 17. 30.  8.  0.  8.  6.  0.  7.  8.  8.  9.  1. 10.  9.] 
adversary cards in hand: [ 8.  3. 16.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 14  0  0  0 23  3  3  3  0  0  6  8  1  6  0 10  0 25 11  6 10  0
  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3  0  0] -> size -> 41 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: trash_cards_n_from_hand - action 10
Learning step: -2.8390400409698486
desired expected reward: 14.023520469665527





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-17.238821]
 [ -8.707202]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.] 
cards in discard: [ 0.  3.  0.  6. 10.  1.  0. 11.  0.  8. 10.  8.  8.  3. 14.  0. 11.  6.
  0.  0.  0. 10.  0.  0.  0.  6.  0.  0.  3.  8. 11.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 10 25  0 11  8 25  8  8 11 10  8  0  3  0  6  6  6  0  6 15
  8  0  3  0  0  1  3 11  1  0 14  0 10  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 4. 24. 30. 17. 30.  8.  0.  8.  6.  0.  7.  8.  8.  9.  1. 10.  9.] 
adversary cards in hand: [ 8.  3. 16.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 14  0  0  0 23  3  3  3  0  0  6  8  1  6  0 10  0 25 11  6 10  0
  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3  0  0] -> size -> 41 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1
Learning step: -1.6274594068527222
desired expected reward: -10.334659576416016



buy possibilites: [-1] 
expected returns: [[-3.938416]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.] 
cards in discard: [ 0.  3.  0.  6. 10.  1.  0. 11.  0.  8. 10.  8.  8.  3. 14.  0. 11.  6.
  0.  0.  0. 10.  0.  0.  0.  6.  0.  0.  3.  8. 11.  6.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 10 25  0 11  8 25  8  8 11 10  8  0  3  0  6  6  6  0  6 15
  8  0  3  0  0  1  3 11  1  0 14  0 10  0  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 24. 30. 17. 30.  8.  0.  8.  6.  0.  7.  8.  8.  9.  1. 10.  9.] 
adversary cards in hand: [ 8.  3. 16.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 14  0  0  0 23  3  3  3  0  0  6  8  1  6  0 10  0 25 11  6 10  0
  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3  0  0] -> size -> 41 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20 -30   0   0   0  -4   0   0   0   0] 
sum of rewards: -70 

action type: buy - action 0.0
Learning step: -2.7266738414764404
desired expected reward: -19.965482711791992






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [ 8.  3. 16.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 16.  3.  6.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14  0  0  0 23  3  3  3  0  0  6  8  1  6  0 10  0 25 11  6 10  0
  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3  0  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 24. 30. 17. 30.  8.  0.  8.  6.  0.  7.  8.  8.  9.  1. 10.  9.] 
adversary cards in hand: [ 0.  0.  1. 15. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 10 25  0 11  8 25  8  8 11 10  8  0  3  0  6  6  6  0  6 15
  8  0  3  0  0  1  3 11  1  0 14  0 10  0  0] -> size -> 39 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 16.  3.  6.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14  0  0  0 23  3  3  3  0  0  6  8  1  6  0 10  0 25 11  6 10  0
  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3  0  0] -> size -> 41 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 3. 24. 30. 17. 30.  8.  0.  8.  6.  0.  7.  8.  8.  9.  1. 10.  9.] 
adversary cards in hand: [ 0.  0.  1. 15. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 10 25  0 11  8 25  8  8 11 10  8  0  3  0  6  6  6  0  6 15
  8  0  3  0  0  1  3 11  1  0 14  0 10  0  0] -> size -> 39 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 16.  3.  6.] 
cards in discard: [0.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14  0  0  0 23  3  3  3  0  0  6  8  1  6  0 10  0 25 11  6 10  0
  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3  0  0  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 24. 30. 17. 30.  8.  0.  8.  6.  0.  7.  8.  8.  9.  1. 10.  9.] 
adversary cards in hand: [ 0.  0.  1. 15. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 10 25  0 11  8 25  8  8 11 10  8  0  3  0  6  6  6  0  6 15
  8  0  3  0  0  1  3 11  1  0 14  0 10  0  0] -> size -> 39 
adversary victory points: -1
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0.  1. 15. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25.] 
expected returns: [[-12.489569]
 [-12.186669]
 [-12.940045]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 15. 25.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10 25  0 11  8 25  8  8 11 10  8  0  3  0  6  6  6  0  6 15
  8  0  3  0  0  1  3 11  1  0 14  0 10  0  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 24. 30. 17. 30.  8.  0.  8.  6.  0.  7.  8.  8.  9.  1. 10.  9.] 
adversary cards in hand: [ 8.  6.  0.  0. 29.] 
adversary cards in discard: [ 0.  8.  3. 16.  3.  6.] 
adversary owned cards: [ 0  0 14  0  0  0 23  3  3  3  0  0  6  8  1  6  0 10  0 25 11  6 10  0
  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3  0  0  0] -> size -> 42 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -2.8828017711639404
desired expected reward: -6.8212175369262695



action possibilites: [-1] 
expected returns: [[-1.492679]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 25.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0 10 25  0 11  8 25  8  8 11 10  8  0  3  0  6  6  6  0  6 15  8
  0  3  0  0  1  3 11  1  0 14  0 10  0  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 2. 24. 30. 17. 30.  8.  0.  8.  6.  0.  7.  8.  8.  9.  1. 10.  9.] 
adversary cards in hand: [ 8.  6.  0.  0. 29.] 
adversary cards in discard: [ 0.  8.  3. 16.  3.  6.] 
adversary owned cards: [ 0  0 14  0  0  0 23  3  3  3  0  0  6  8  1  6  0 10  0 25 11  6 10  0
  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3  0  0  0] -> size -> 42 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action 15.0
Learning step: -1.2242519855499268
desired expected reward: -13.410921096801758





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-2.169559 ]
 [-1.6852427]
 [-2.0373185]
 [-1.7160485]
 [-2.8083878]
 [-1.9878588]
 [-2.1435552]
 [-2.4610047]
 [-2.298657 ]
 [-2.9115744]
 [-2.4757156]
 [-2.095743 ]
 [-2.79699  ]
 [-2.5723827]
 [-3.625543 ]]
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 25.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0 10 25  0 11  8 25  8  8 11 10  8  0  3  0  6  6  6  0  6 15  8
  0  3  0  0  1  3 11  1  0 14  0 10  0  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 2. 24. 30. 17. 30.  8.  0.  8.  6.  0.  7.  8.  8.  9.  1. 10.  9.] 
adversary cards in hand: [ 8.  6.  0.  0. 29.] 
adversary cards in discard: [ 0.  8.  3. 16.  3.  6.] 
adversary owned cards: [ 0  0 14  0  0  0 23  3  3  3  0  0  6  8  1  6  0 10  0 25 11  6 10  0
  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3  0  0  0] -> size -> 42 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1
Learning step: -1.7742704153060913
desired expected reward: -3.266949415206909



buy possibilites: [-1] 
expected returns: [[-8.70428]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 25.] 
cards in discard: [23.] 
cards in deck: 34 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0 10 25  0 11  8 25  8  8 11 10  8  0  3  0  6  6  6  0  6 15  8
  0  3  0  0  1  3 11  1  0 14  0 10  0  0 23] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 24. 30. 17. 30.  8.  0.  8.  6.  0.  7.  8.  8.  8.  1. 10.  9.] 
adversary cards in hand: [ 8.  6.  0.  0. 29.] 
adversary cards in discard: [ 0.  8.  3. 16.  3.  6.] 
adversary owned cards: [ 0  0 14  0  0  0 23  3  3  3  0  0  6  8  1  6  0 10  0 25 11  6 10  0
  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3  0  0  0] -> size -> 42 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5.    0.   -1.  -50.    0.    0.   20.    0.    0.    0.    0.   -4.
   0.    0.   12.5   0. ] 
sum of rewards: -27.5 

action type: buy - action 23.0
Learning step: -1.4470605850219727
desired expected reward: -3.922773838043213






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [ 8.  6.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6.  0.  0. 29.] 
cards in discard: [ 0.  8.  3. 16.  3.  6.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14  0  0  0 23  3  3  3  0  0  6  8  1  6  0 10  0 25 11  6 10  0
  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3  0  0  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 24. 30. 17. 30.  8.  0.  8.  6.  0.  7.  8.  8.  8.  1. 10.  9.] 
adversary cards in hand: [ 6. 25.  8.  3.  0.] 
adversary cards in discard: [23. 15.  0.  1. 25.] 
adversary owned cards: [ 0  0  0 10 25  0 11  8 25  8  8 11 10  8  0  3  0  6  6  6  0  6 15  8
  0  3  0  0  1  3 11  1  0 14  0 10  0  0 23] -> size -> 39 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 1.] 
cards in discard: [ 0.  8.  3. 16.  3.  6.  8.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 14  0  0  0 23  3  3  3  0  0  6  8  1  6  0 10  0 25 11  6 10  0
  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3  0  0  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 2. 24. 30. 17. 30.  8.  0.  8.  6.  0.  7.  8.  8.  8.  1. 10.  9.] 
adversary cards in hand: [ 6. 25.  8.  3.  0.] 
adversary cards in discard: [23. 15.  0.  1. 25.] 
adversary owned cards: [ 0  0  0 10 25  0 11  8 25  8  8 11 10  8  0  3  0  6  6  6  0  6 15  8
  0  3  0  0  1  3 11  1  0 14  0 10  0  0 23] -> size -> 39 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1.] 
cards in discard: [ 0.  8.  3. 16.  3.  6.  8.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 14  0  0  0 23  3  3  3  0  0  6  8  1  6  0 10  0 25 11  6 10  0
  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3  0  0  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 2. 24. 30. 17. 30.  8.  0.  8.  6.  0.  7.  8.  8.  8.  1. 10.  9.] 
adversary cards in hand: [ 6. 25.  8.  3.  0.] 
adversary cards in discard: [23. 15.  0.  1. 25.] 
adversary owned cards: [ 0  0  0 10 25  0 11  8 25  8  8 11 10  8  0  3  0  6  6  6  0  6 15  8
  0  3  0  0  1  3 11  1  0 14  0 10  0  0 23] -> size -> 39 
adversary victory points: -1
player victory points: 4 





Player: 0 
cards in hand: [ 6. 25.  8.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[ 1.4725716 ]
 [ 1.3034246 ]
 [-0.01159549]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 25.  8.  3.  0.] 
cards in discard: [23. 15.  0.  1. 25.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10 25  0 11  8 25  8  8 11 10  8  0  3  0  6  6  6  0  6 15  8
  0  3  0  0  1  3 11  1  0 14  0 10  0  0 23] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 24. 30. 17. 30.  8.  0.  8.  6.  0.  7.  8.  8.  8.  1. 10.  9.] 
adversary cards in hand: [ 8.  0.  3. 10.  0.] 
adversary cards in discard: [ 0.  8.  3. 16.  3.  6.  8.  0. 29.  6.  0.  1.] 
adversary owned cards: [ 0  0 14  0  0  0 23  3  3  3  0  0  6  8  1  6  0 10  0 25 11  6 10  0
  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3  0  0  0] -> size -> 42 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -2.340296983718872
desired expected reward: -11.044576644897461



action possibilites: [-1] 
expected returns: [[-7.719495]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 3. 0. 0. 0.] 
cards in discard: [23. 15.  0.  1. 25.] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0 10 25  0 11  8 25  8  8 11 10  8  0  3  0  6  6  6  0  6 15  8
  0  3  0  0  1  3 11  1  0 14  0 10  0  0 23] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 24. 30. 17. 30.  8.  0.  8.  6.  0.  7.  8.  8.  8.  1. 10.  9.] 
adversary cards in hand: [ 8.  0.  3. 10.  0.] 
adversary cards in discard: [ 0.  8.  3. 16.  3.  6.  8.  0. 29.  6.  0.  1.] 
adversary owned cards: [ 0  0 14  0  0  0 23  3  3  3  0  0  6  8  1  6  0 10  0 25 11  6 10  0
  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3  0  0  0] -> size -> 42 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   2] 
sum of rewards: -34 

action type: take_action - action 25.0
Learning step: -1.9388599395751953
desired expected reward: -0.6354348659515381





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-5.452962 ]
 [-8.291998 ]
 [-6.7876625]
 [-9.324511 ]
 [-6.335758 ]
 [-9.032033 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 3. 0. 0. 0.] 
cards in discard: [23. 15.  0.  1. 25.] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0 10 25  0 11  8 25  8  8 11 10  8  0  3  0  6  6  6  0  6 15  8
  0  3  0  0  1  3 11  1  0 14  0 10  0  0 23] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 24. 30. 17. 30.  8.  0.  8.  6.  0.  7.  8.  8.  8.  1. 10.  9.] 
adversary cards in hand: [ 8.  0.  3. 10.  0.] 
adversary cards in discard: [ 0.  8.  3. 16.  3.  6.  8.  0. 29.  6.  0.  1.] 
adversary owned cards: [ 0  0 14  0  0  0 23  3  3  3  0  0  6  8  1  6  0 10  0 25 11  6 10  0
  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3  0  0  0] -> size -> 42 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1
Learning step: -1.5694118738174438
desired expected reward: -9.288907051086426



buy possibilites: [-1] 
expected returns: [[-8.736762]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 3. 0. 0. 0.] 
cards in discard: [23. 15.  0.  1. 25.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0 10 25  0 11  8 25  8  8 11 10  8  0  3  0  6  6  6  0  6 15  8
  0  3  0  0  1  3 11  1  0 14  0 10  0  0 23  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 24. 30. 16. 30.  8.  0.  8.  6.  0.  7.  8.  8.  8.  1. 10.  9.] 
adversary cards in hand: [ 8.  0.  3. 10.  0.] 
adversary cards in discard: [ 0.  8.  3. 16.  3.  6.  8.  0. 29.  6.  0.  1.] 
adversary owned cards: [ 0  0 14  0  0  0 23  3  3  3  0  0  6  8  1  6  0 10  0 25 11  6 10  0
  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3  0  0  0] -> size -> 42 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -40.   0.   0.  20.   0.   0.   0.   0.  -5.   0.   0.
   2.   0.] 
sum of rewards: -28.0 

action type: buy - action 3.0
Learning step: -1.257193922996521
desired expected reward: -8.044857025146484






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3. 10.  0.] 
cards in discard: [ 0.  8.  3. 16.  3.  6.  8.  0. 29.  6.  0.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14  0  0  0 23  3  3  3  0  0  6  8  1  6  0 10  0 25 11  6 10  0
  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3  0  0  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 24. 30. 16. 30.  8.  0.  8.  6.  0.  7.  8.  8.  8.  1. 10.  9.] 
adversary cards in hand: [ 1.  0. 11.  0.  3.] 
adversary cards in discard: [23. 15.  0.  1. 25.  3. 25.  6.  8.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0 10 25  0 11  8 25  8  8 11 10  8  0  3  0  6  6  6  0  6 15  8
  0  3  0  0  1  3 11  1  0 14  0 10  0  0 23  3] -> size -> 40 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [ 0.  8.  3. 16.  3.  6.  8.  0. 29.  6.  0.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0 14  0  0  0 23  3  3  3  0  0  6  8  1  6  0 10  0 25 11  6 10  0
  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3  0  0  0] -> size -> 42 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 2. 24. 30. 16. 30.  8.  0.  8.  6.  0.  7.  8.  8.  8.  1. 10.  9.] 
adversary cards in hand: [ 1.  0. 11.  0.  3.] 
adversary cards in discard: [23. 15.  0.  1. 25.  3. 25.  6.  8.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0 10 25  0 11  8 25  8  8 11 10  8  0  3  0  6  6  6  0  6 15  8
  0  3  0  0  1  3 11  1  0 14  0 10  0  0 23  3] -> size -> 40 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [ 0.  8.  3. 16.  3.  6.  8.  0. 29.  6.  0.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0 14  0  0  0 23  3  3  3  0  0  6  8  1  6  0 10  0 25 11  6 10  0
  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3  0  0  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 24. 30. 16. 30.  8.  0.  8.  6.  0.  7.  8.  8.  8.  1. 10.  9.] 
adversary cards in hand: [ 1.  0. 11.  0.  3.] 
adversary cards in discard: [23. 15.  0.  1. 25.  3. 25.  6.  8.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0 10 25  0 11  8 25  8  8 11 10  8  0  3  0  6  6  6  0  6 15  8
  0  3  0  0  1  3 11  1  0 14  0 10  0  0 23  3] -> size -> 40 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [ 0.  8.  3. 16.  3.  6.  8.  0. 29.  6.  0.  1.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0 14  0  0  0 23  3  3  3  0  0  6  8  1  6  0 10  0 25 11  6 10  0
  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3  0  0  0  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 23. 30. 16. 30.  8.  0.  8.  6.  0.  7.  8.  8.  8.  1. 10.  9.] 
adversary cards in hand: [ 1.  0. 11.  0.  3.] 
adversary cards in discard: [23. 15.  0.  1. 25.  3. 25.  6.  8.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0 10 25  0 11  8 25  8  8 11 10  8  0  3  0  6  6  6  0  6 15  8
  0  3  0  0  1  3 11  1  0 14  0 10  0  0 23  3] -> size -> 40 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [ 1.  0. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[-8.514737]
 [-8.457791]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 11.  0.  3.] 
cards in discard: [23. 15.  0.  1. 25.  3. 25.  6.  8.  3.  0.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10 25  0 11  8 25  8  8 11 10  8  0  3  0  6  6  6  0  6 15  8
  0  3  0  0  1  3 11  1  0 14  0 10  0  0 23  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 23. 30. 16. 30.  8.  0.  8.  6.  0.  7.  8.  8.  8.  1. 10.  9.] 
adversary cards in hand: [ 3.  0. 23.  3.  3.] 
adversary cards in discard: [ 0.  8.  3. 16.  3.  6.  8.  0. 29.  6.  0.  1.  1. 10.  8.  0.  3.  0.
  0.] 
adversary owned cards: [ 0  0 14  0  0  0 23  3  3  3  0  0  6  8  1  6  0 10  0 25 11  6 10  0
  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3  0  0  0  1] -> size -> 43 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -2.00390887260437
desired expected reward: -10.740671157836914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[-8.505661 ]
 [-8.633165 ]
 [-7.996797 ]
 [-8.601999 ]
 [-8.017244 ]
 [-8.858702 ]
 [-7.6926947]
 [-8.090935 ]
 [-8.126705 ]
 [-8.032137 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 11.  0.  3.] 
cards in discard: [23. 15.  0.  1. 25.  3. 25.  6.  8.  3.  0.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10 25  0 11  8 25  8  8 11 10  8  0  3  0  6  6  6  0  6 15  8
  0  3  0  0  1  3 11  1  0 14  0 10  0  0 23  3] -> size -> 40 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 2. 23. 30. 16. 30.  8.  0.  8.  6.  0.  7.  8.  8.  8.  1. 10.  9.] 
adversary cards in hand: [ 3.  0. 23.  3.  3.] 
adversary cards in discard: [ 0.  8.  3. 16.  3.  6.  8.  0. 29.  6.  0.  1.  1. 10.  8.  0.  3.  0.
  0.] 
adversary owned cards: [ 0  0 14  0  0  0 23  3  3  3  0  0  6  8  1  6  0 10  0 25 11  6 10  0
  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3  0  0  0  1] -> size -> 43 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -1.9859898090362549
desired expected reward: -10.9044828414917



buy possibilites: [-1] 
expected returns: [[0.0873754]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 11.  0.  3.] 
cards in discard: [23. 15.  0.  1. 25.  3. 25.  6.  8.  3.  0.  0.  0. 29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10 25  0 11  8 25  8  8 11 10  8  0  3  0  6  6  6  0  6 15  8
  0  3  0  0  1  3 11  1  0 14  0 10  0  0 23  3 29] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 23. 30. 16. 30.  8.  0.  8.  6.  0.  7.  7.  8.  8.  1. 10.  9.] 
adversary cards in hand: [ 3.  0. 23.  3.  3.] 
adversary cards in discard: [ 0.  8.  3. 16.  3.  6.  8.  0. 29.  6.  0.  1.  1. 10.  8.  0.  3.  0.
  0.] 
adversary owned cards: [ 0  0 14  0  0  0 23  3  3  3  0  0  6  8  1  6  0 10  0 25 11  6 10  0
  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3  0  0  0  1] -> size -> 43 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0  -6   0   0  32   0] 
sum of rewards: -19 

action type: buy - action 29.0
Learning step: -0.5050989389419556
desired expected reward: -9.363802909851074






         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 23.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 23.  3.  3.] 
cards in discard: [ 0.  8.  3. 16.  3.  6.  8.  0. 29.  6.  0.  1.  1. 10.  8.  0.  3.  0.
  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14  0  0  0 23  3  3  3  0  0  6  8  1  6  0 10  0 25 11  6 10  0
  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3  0  0  0  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 23. 30. 16. 30.  8.  0.  8.  6.  0.  7.  7.  8.  8.  1. 10.  9.] 
adversary cards in hand: [0. 8. 6. 3. 0.] 
adversary cards in discard: [23. 15.  0.  1. 25.  3. 25.  6.  8.  3.  0.  0.  0. 29.  1.  0. 11.  0.
  3.] 
adversary owned cards: [ 0  0  0 10 25  0 11  8 25  8  8 11 10  8  0  3  0  6  6  6  0  6 15  8
  0  3  0  0  1  3 11  1  0 14  0 10  0  0 23  3 29] -> size -> 41 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  3. 11.] 
cards in discard: [ 0.  8.  3. 16.  3.  6.  8.  0. 29.  6.  0.  1.  1. 10.  8.  0.  3.  0.
  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0 14  0  0  0 23  3  3  3  0  0  6  8  1  6  0 10  0 25 11  6 10  0
  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3  0  0  0  1] -> size -> 43 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 2. 23. 30. 16. 30.  8.  0.  8.  6.  0.  7.  7.  8.  8.  1. 10.  9.] 
adversary cards in hand: [0. 8. 6. 3. 0.] 
adversary cards in discard: [23. 15.  0.  1. 25.  3. 25.  6.  8.  3.  0.  0.  0. 29.  1.  0. 11.  0.
  3.] 
adversary owned cards: [ 0  0  0 10 25  0 11  8 25  8  8 11 10  8  0  3  0  6  6  6  0  6 15  8
  0  3  0  0  1  3 11  1  0 14  0 10  0  0 23  3 29] -> size -> 41 
adversary victory points: 0
player victory points: 4 


Player 1 won the game! 



Player 0 bought cards:
Copper: 11 
Silver: 2 
Gold: 0 
Estate: 5 
Duchy: 0 
Province: 0 
Curse: 4 

Remodel: 0 
Workshop: 3 
Chapel: 6 
Witch: 2 
Poacher: 1 
Militia: 0 
Market: 1 
Village: 3 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [0. 8. 6. 3. 0.] 
cards in discard: [23. 15.  0.  1. 25.  3. 25.  6.  8.  3.  0.  0.  0. 29.  1.  0. 11.  0.
  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10 25  0 11  8 25  8  8 11 10  8  0  3  0  6  6  6  0  6 15  8
  0  3  0  0  1  3 11  1  0 14  0 10  0  0 23  3 29] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 23. 30. 16. 30.  8.  0.  8.  6.  0.  7.  7.  8.  8.  0. 10.  9.] 
adversary cards in hand: [3. 0. 3. 3.] 
adversary cards in discard: [ 0.  8.  3. 16.  3.  6.  8.  0. 29.  6.  0.  1.  1. 10.  8.  0.  3.  0.
  0. 10.] 
adversary owned cards: [ 0  0 14  0  0  0 23  3  3  3  0  0  6  8  1  6  0 10  0 25 11  6 10  0
  0  0  0  3  3  0  8  8 10  3  0  0 16 29  3  0  0  0  1 10] -> size -> 44 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5 -500    0  -40    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -545 

action type: buy - action -1
Learning step: -27.254369735717773
desired expected reward: -27.166994094848633



