 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[86.39201]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -480        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000485 

action type: buy - action 0.0
Learning step: -120019.328125
desired expected reward: -120021.1484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[78.030945]
 [84.577675]
 [82.16408 ]
 [73.47075 ]
 [82.85038 ]
 [86.22852 ]
 [82.02033 ]
 [91.30767 ]
 [77.42206 ]
 [79.63507 ]
 [83.95171 ]
 [85.97155 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 88.33816528320312



buy possibilites: [-1] 
expected returns: [[99.12689]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 91.30767059326172






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[105.98088]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 99.12689208984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 98.19497]
 [105.08699]
 [102.57034]
 [ 93.37858]
 [106.79515]
 [102.41977]
 [ 99.90314]
 [106.5311 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 107.28515625



buy possibilites: [-1] 
expected returns: [[106.46329]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [29.  0.  0.  0.  0.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 106.79515075683594






Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [10.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [10.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [10.  0.  0.  0.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[80.01173]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 106.46328735351562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[74.067795]
 [80.65275 ]
 [78.24961 ]
 [69.44503 ]
 [78.92811 ]
 [82.28603 ]
 [78.10421 ]
 [87.301384]
 [73.452934]
 [75.701065]
 [80.03791 ]
 [82.042984]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 81.73828125



buy possibilites: [-1] 
expected returns: [[91.4536]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 93 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 87.30138397216797






Player: 1 
cards in hand: [ 0.  3.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3] -> size -> 12 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[102.29647]
 [102.54246]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0.  0.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 1. 10.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  1] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 91.45359802246094



action possibilites: [-1] 
expected returns: [[84.998825]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [29.  0.  3.  0.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 1. 10.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  1] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 104.83526611328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[79.41006 ]
 [86.06291 ]
 [83.61097 ]
 [74.94712 ]
 [87.727745]
 [83.46523 ]
 [81.01328 ]
 [87.47068 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [29.  0.  3.  0.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 1. 10.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  1] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 84.99882507324219



buy possibilites: [-1] 
expected returns: [[84.80148]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [29.  0.  3.  0.  0.  0. 10. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 1. 10.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  1] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 87.72773742675781






Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 1. 10.  0.  3.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  0. 11. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 1. 10.  0.  3.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  0. 11. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 1. 10.  0.  3.  0.  3.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  1  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  0. 11. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [10.  0. 11. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 29.] 
expected returns: [[70.33478]
 [64.56023]
 [70.55675]
 [75.25191]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11. 29.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  1. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  1  8] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 84.80148315429688



action possibilites: [-1. 10. 11.] 
expected returns: [[79.02619 ]
 [72.83467 ]
 [79.259766]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  1. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  1  8] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 76.39420318603516



action possibilites: [-1] 
expected returns: [[87.18068]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  1. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  1  8] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 81.58450317382812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[80.09088]
 [86.51083]
 [84.16743]
 [75.73577]
 [88.10638]
 [84.02659]
 [81.68317]
 [87.87307]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  1. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  1  8] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 87.18067932128906



buy possibilites: [-1] 
expected returns: [[99.16912]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [10. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  7.  9. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  1. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  1  8] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 59 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 88.10637664794922






Player: 1 
cards in hand: [ 3.  1. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  1  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  7.  9. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  3.  0.  3.  0.] 
adversary cards in discard: [10. 11. 29. 11. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11] -> size -> 17 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  1  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  7.  9. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  3.  0.  3.  0.] 
adversary cards in discard: [10. 11. 29. 11. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11] -> size -> 17 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 10.  3.  0.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  1  8  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  7.  9. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  3.  0.  3.  0.] 
adversary cards in discard: [10. 11. 29. 11. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11] -> size -> 17 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [11.  3.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[95.93215 ]
 [96.152885]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  3.  0.] 
cards in discard: [10. 11. 29. 11. 10.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  7.  9. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 8. 3. 0. 0.] 
adversary cards in discard: [ 3.  3.  1. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  1  8  3] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 99.16912078857422



action possibilites: [-1] 
expected returns: [[103.19226]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [10. 11. 29. 11. 10.  0.  3.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  7.  9. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 8. 3. 0. 0.] 
adversary cards in discard: [ 3.  3.  1. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  1  8  3] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -18 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 97.81065368652344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 98.363785]
 [102.59047 ]
 [ 94.038506]
 [102.444695]
 [106.49772 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [10. 11. 29. 11. 10.  0.  3.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  7.  9. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 8. 3. 0. 0.] 
adversary cards in discard: [ 3.  3.  1. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  1  8  3] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 103.1922607421875






Player: 1 
cards in hand: [3. 8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3. 0. 0.] 
cards in discard: [ 3.  3.  1. 10.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  1  8  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  7.  9. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10] -> size -> 18 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3. 0. 0.] 
cards in discard: [ 3.  3.  1. 10.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  1  8  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  7.  9. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10] -> size -> 18 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3. 0. 0.] 
cards in discard: [ 3.  3.  1. 10.  3.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  1  8  3  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  7.  8. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10] -> size -> 18 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [10. 29.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[70.55861 ]
 [65.019714]
 [75.20404 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  7.  8. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  1  8  3  8] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 106.49772644042969



action possibilites: [-1. 10. 11.] 
expected returns: [[87.25374 ]
 [81.839966]
 [87.4608  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  7.  8. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  1  8  3  8] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 75.50950622558594



action possibilites: [-1] 
expected returns: [[88.045105]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  7.  8. 10.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  1  8  3  8] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 2 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 89.51213836669922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[84.39201 ]
 [89.89574 ]
 [87.887825]
 [80.70444 ]
 [88.45383 ]
 [91.26346 ]
 [87.767654]
 [95.46201 ]
 [83.88137 ]
 [85.75973 ]
 [89.38507 ]
 [91.06357 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  7.  8. 10.  8. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  1  8  3  8] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 88.04510498046875



buy possibilites: [-1] 
expected returns: [[125.73134]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [10. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  7.  8. 10.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  1  8  3  8] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 103 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 95.46200561523438






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  1  8  3  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  7.  8. 10.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 11.  3. 29. 10.] 
adversary cards in discard: [10. 29. 29. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29] -> size -> 20 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  1  8  3  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  7.  8. 10.  7. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 11.  3. 29. 10.] 
adversary cards in discard: [10. 29. 29. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29] -> size -> 20 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  1  8  3  8 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  7.  8. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 11.  3. 29. 10.] 
adversary cards in discard: [10. 29. 29. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29] -> size -> 20 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  3. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10.] 
expected returns: [[115.06851]
 [115.30621]
 [120.0396 ]
 [109.12439]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3. 29. 10.] 
cards in discard: [10. 29. 29. 11. 10.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  7.  8. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10.  3.  0.  1.  8.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  1  8  3  8 29] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 125.73133850097656



action possibilites: [-1. 11. 10.] 
expected returns: [[153.40775]
 [153.65077]
 [147.3635 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3. 10.  0.] 
cards in discard: [10. 29. 29. 11. 10.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  7.  8. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10.  3.  0.  1.  8.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  1  8  3  8 29] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 118.29954528808594



action possibilites: [-1] 
expected returns: [[147.47678]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.  0.] 
cards in discard: [10. 29. 29. 11. 10.  0.  0.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  7.  8. 10.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10.  3.  0.  1.  8.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  1  8  3  8 29] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 2 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 156.017333984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[143.27713]
 [147.20128]
 [138.92424]
 [147.0677 ]
 [150.75412]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.  0.] 
cards in discard: [10. 29. 29. 11. 10.  0.  0.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  7.  8. 10.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10.  3.  0.  1.  8.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  1  8  3  8 29] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 147.47677612304688






Player: 1 
cards in hand: [10.  3.  0.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  1.  8.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  1  8  3  8 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  7.  8. 10.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [11.  0.  3. 10.  0.] 
adversary cards in discard: [10. 29. 29. 11. 10.  0.  0.  0. 10. 29. 11.  3.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10] -> size -> 21 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  1.  8.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  1  8  3  8 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  7.  8. 10.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [11.  0.  3. 10.  0.] 
adversary cards in discard: [10. 29. 29. 11. 10.  0.  0.  0. 10. 29. 11.  3.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10] -> size -> 21 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  1.  8.] 
cards in discard: [29.  3.  0.  0.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  1  8  3  8 29  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  7.  8. 10.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [11.  0.  3. 10.  0.] 
adversary cards in discard: [10. 29. 29. 11. 10.  0.  0.  0. 10. 29. 11.  3.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10] -> size -> 21 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [11.  0.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[116.32349 ]
 [116.57025 ]
 [110.505035]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3. 10.  0.] 
cards in discard: [10. 29. 29. 11. 10.  0.  0.  0. 10. 29. 11.  3.  3. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  7.  8. 10.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [3. 8. 0. 3. 3.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.  0. 10.  3.  0.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  1  8  3  8 29  0] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 150.75411987304688



action possibilites: [-1] 
expected returns: [[119.15759]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  0.] 
cards in discard: [10. 29. 29. 11. 10.  0.  0.  0. 10. 29. 11.  3.  3. 10.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  7.  8. 10.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [3. 8. 0. 3. 3.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.  0. 10.  3.  0.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  1  8  3  8 29  0] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -18 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 117.48442840576172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[111.71008 ]
 [115.98609 ]
 [106.970375]
 [115.83894 ]
 [120.00261 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0.] 
cards in discard: [10. 29. 29. 11. 10.  0.  0.  0. 10. 29. 11.  3.  3. 10.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  7.  8. 10.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [3. 8. 0. 3. 3.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.  0. 10.  3.  0.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  1  8  3  8 29  0] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 119.1575927734375






Player: 1 
cards in hand: [3. 8. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 3. 3.] 
cards in discard: [29.  3.  0.  0.  0.  0.  0. 10.  3.  0.  1.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  1  8  3  8 29  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  7.  8. 10.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10] -> size -> 22 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [29.  3.  0.  0.  0.  0.  0. 10.  3.  0.  1.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3  1  8  3  8 29  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  7.  8. 10.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10] -> size -> 22 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [29.  3.  0.  0.  0.  0.  0. 10.  3.  0.  1.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3  1  8  3  8 29  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  7.  8. 10.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10] -> size -> 22 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[91.96089 ]
 [86.119354]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  7.  8. 10.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 1.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3  1  8  3  8 29  0] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 120.00260925292969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[86.59773 ]
 [92.6051  ]
 [90.385735]
 [82.75905 ]
 [94.11597 ]
 [90.25258 ]
 [88.033226]
 [93.89424 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  7.  8. 10.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 1.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3  1  8  3  8 29  0] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 92.01280212402344



buy possibilites: [-1] 
expected returns: [[104.02932]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  0.  0.] 
cards in discard: [11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  6.  8. 10.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 1.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3  1  8  3  8 29  0] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0  54   0] 
sum of rewards: 19 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 94.115966796875






Player: 1 
cards in hand: [ 1.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3  1  8  3  8 29  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  6.  8. 10.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [10. 11. 10. 11.  3.] 
adversary cards in discard: [11.  3.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11] -> size -> 23 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3  1  8  3  8 29  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  6.  8. 10.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [10. 11. 10. 11.  3.] 
adversary cards in discard: [11.  3.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11] -> size -> 23 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 10.  0.  0.] 
cards in discard: [8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3  1  8  3  8 29  0  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  6.  7. 10.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [10. 11. 10. 11.  3.] 
adversary cards in discard: [11.  3.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11] -> size -> 23 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [10. 11. 10. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10. 11.] 
expected returns: [[133.99243]
 [127.92018]
 [134.23795]
 [127.92018]
 [134.23795]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10. 11.  3.] 
cards in discard: [11.  3.  0. 10.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  6.  7. 10.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [ 8.  1.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3  1  8  3  8 29  0  8] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 104.0293197631836



action possibilites: [-1] 
expected returns: [[127.248505]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11.  3.] 
cards in discard: [11.  3.  0. 10.  0.  0. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  6.  7. 10.  6. 10. 10.  2. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [ 8.  1.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3  1  8  3  8 29  0  8] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 134.6754913330078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[122.254745]
 [117.75939 ]
 [129.97397 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 11.  3.] 
cards in discard: [11.  3.  0. 10.  0.  0. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  6.  7. 10.  6. 10. 10.  2. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [ 8.  1.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3  1  8  3  8 29  0  8] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 127.24850463867188






Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 8.  1.  0. 10.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3  1  8  3  8 29  0  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  6.  7. 10.  6. 10. 10.  2. 10. 10.] 
adversary cards in hand: [10.  0. 10.  0. 29.] 
adversary cards in discard: [11.  3.  0. 10.  0.  0. 10. 11. 10. 10. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10] -> size -> 24 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 8.  1.  0. 10.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3  1  8  3  8 29  0  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  6.  7. 10.  6. 10. 10.  2. 10. 10.] 
adversary cards in hand: [10.  0. 10.  0. 29.] 
adversary cards in discard: [11.  3.  0. 10.  0.  0. 10. 11. 10. 10. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10] -> size -> 24 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 8.  1.  0. 10.  0.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3  1  8  3  8 29  0  8 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  5.  7. 10.  6. 10. 10.  2. 10. 10.] 
adversary cards in hand: [10.  0. 10.  0. 29.] 
adversary cards in discard: [11.  3.  0. 10.  0.  0. 10. 11. 10. 10. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10] -> size -> 24 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [10.  0. 10.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 29.] 
expected returns: [[107.01685]
 [100.0144 ]
 [100.0144 ]
 [112.85188]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  0. 29.] 
cards in discard: [11.  3.  0. 10.  0.  0. 10. 11. 10. 10. 11.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  5.  7. 10.  6. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  8.  8.] 
adversary cards in discard: [ 8.  1.  0. 10.  0.  0. 11.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3  1  8  3  8 29  0  8 11] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 129.97396850585938



action possibilites: [-1. 10. 10.] 
expected returns: [[124.88489]
 [117.8362 ]
 [117.8362 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  0.  0.] 
cards in discard: [11.  3.  0. 10.  0.  0. 10. 11. 10. 10. 11.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  5.  7. 10.  6. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  8.  8.] 
adversary cards in discard: [ 8.  1.  0. 10.  0.  0. 11.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3  1  8  3  8 29  0  8 11] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 111.25717163085938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[116.681   ]
 [124.00922 ]
 [121.333305]
 [111.521645]
 [122.09536 ]
 [125.82607 ]
 [121.17377 ]
 [131.41287 ]
 [115.99434 ]
 [118.49784 ]
 [123.32257 ]
 [125.546524]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  0.  0.] 
cards in discard: [11.  3.  0. 10.  0.  0. 10. 11. 10. 10. 11.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  5.  7. 10.  6. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  8.  8.] 
adversary cards in discard: [ 8.  1.  0. 10.  0.  0. 11.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3  1  8  3  8 29  0  8 11] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 124.8848876953125



buy possibilites: [-1] 
expected returns: [[122.52757]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  0.  0.] 
cards in discard: [11.  3.  0. 10.  0.  0. 10. 11. 10. 10. 11.  3. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  5.  7. 10.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  8.  8.] 
adversary cards in discard: [ 8.  1.  0. 10.  0.  0. 11.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  3  1  8  3  8 29  0  8 11] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 113 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 131.41287231445312






Player: 1 
cards in hand: [ 3. 29.  0.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  8.  8.] 
cards in discard: [ 8.  1.  0. 10.  0.  0. 11.  0.  3.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  3  1  8  3  8 29  0  8 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  5.  7. 10.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 3.  0. 10. 29. 11.] 
adversary cards in discard: [11.  3.  0. 10.  0.  0. 10. 11. 10. 10. 11.  3. 29. 29. 10.  0. 10.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29] -> size -> 25 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 8.  1.  0. 10.  0.  0. 11.  0.  3.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 10  3  1  3  8  0  8 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  5.  7. 10.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 3.  0. 10. 29. 11.] 
adversary cards in discard: [11.  3.  0. 10.  0.  0. 10. 11. 10. 10. 11.  3. 29. 29. 10.  0. 10.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29] -> size -> 25 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 8.  1.  0. 10.  0.  0. 11.  0.  3.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 10  3  1  3  8  0  8 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  5.  7. 10.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 3.  0. 10. 29. 11.] 
adversary cards in discard: [11.  3.  0. 10.  0.  0. 10. 11. 10. 10. 11.  3. 29. 29. 10.  0. 10.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29] -> size -> 25 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 8.  1.  0. 10.  0.  0. 11.  0.  3.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 10  3  1  3  8  0  8 11  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  5.  7. 10.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 3.  0. 10. 29. 11.] 
adversary cards in discard: [11.  3.  0. 10.  0.  0. 10. 11. 10. 10. 11.  3. 29. 29. 10.  0. 10.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29] -> size -> 25 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 10. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11.] 
expected returns: [[87.555374]
 [81.290085]
 [92.78671 ]
 [87.79636 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10. 29. 11.] 
cards in discard: [11.  3.  0. 10.  0.  0. 10. 11. 10. 10. 11.  3. 29. 29. 10.  0. 10.  0.
  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  5.  7. 10.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  3  1  3  8  0  8 11  0] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 122.52757263183594



action possibilites: [-1. 10. 11. 29.] 
expected returns: [[109.51961]
 [103.31706]
 [109.75823]
 [114.6941 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10. 11. 29.] 
cards in discard: [11.  3.  0. 10.  0.  0. 10. 11. 10. 10. 11.  3. 29. 29. 10.  0. 10.  0.
  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  5.  7. 10.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  3  1  3  8  0  8 11  0] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 92.78671264648438



action possibilites: [-1. 10. 11.] 
expected returns: [[113.33823]
 [108.02318]
 [113.55041]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10. 11.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  5.  7. 10.  5. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  3  1  3  8  0  8 11  0] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 114.69410705566406



action possibilites: [-1] 
expected returns: [[139.38661]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  5.  7. 10.  5. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  3  1  3  8  0  8 11  0] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0  27   0] 
sum of rewards: 52 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 115.60603332519531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[135.65276]
 [141.51439]
 [139.37314]
 [131.52452]
 [139.98668]
 [142.96736]
 [139.24698]
 [147.44168]
 [135.1027 ]
 [137.10573]
 [140.96431]
 [142.7396 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  0.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  5.  7. 10.  5. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  3  1  3  8  0  8 11  0] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 139.38661193847656



buy possibilites: [-1] 
expected returns: [[186.83038]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  0.] 
cards in discard: [10. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  5.  7. 10.  4. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  3  1  3  8  0  8 11  0] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 153 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 147.44166564941406






Player: 1 
cards in hand: [ 3. 11.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  3  1  3  8  0  8 11  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  5.  7. 10.  4. 10. 10.  1. 10. 10.] 
adversary cards in hand: [11. 11.  3.  0. 10.] 
adversary cards in discard: [10. 29. 29. 29. 11.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29] -> size -> 27 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 10  3  1  3  8  0  8 11  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8. 10. 10.  5.  7. 10.  4. 10. 10.  1. 10. 10.] 
adversary cards in hand: [11. 11.  3.  0. 10.] 
adversary cards in discard: [10. 29. 29. 29. 11.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29] -> size -> 27 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 10  3  1  3  8  0  8 11  0  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 28. 30.  8. 10. 10.  5.  7. 10.  4. 10. 10.  1. 10. 10.] 
adversary cards in hand: [11. 11.  3.  0. 10.] 
adversary cards in discard: [10. 29. 29. 29. 11.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29] -> size -> 27 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [11. 11.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10.] 
expected returns: [[140.60825]
 [140.85129]
 [140.85129]
 [134.564  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  3.  0. 10.] 
cards in discard: [10. 29. 29. 29. 11.  3.  0. 10.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8. 10. 10.  5.  7. 10.  4. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 3.  8. 10.  0.  0.] 
adversary cards in discard: [ 0. 11.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  3  1  3  8  0  8 11  0  0] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 186.83038330078125



action possibilites: [-1] 
expected returns: [[138.42194]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0. 10.] 
cards in discard: [10. 29. 29. 29. 11.  3.  0. 10.  0. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8. 10. 10.  5.  7. 10.  4. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 3.  8. 10.  0.  0.] 
adversary cards in discard: [ 0. 11.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  3  1  3  8  0  8 11  0  0] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 141.44363403320312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[130.87457]
 [126.12276]
 [139.03975]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0. 10.] 
cards in discard: [10. 29. 29. 29. 11.  3.  0. 10.  0. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8. 10. 10.  5.  7. 10.  4. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 3.  8. 10.  0.  0.] 
adversary cards in discard: [ 0. 11.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  3  1  3  8  0  8 11  0  0] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 138.42193603515625






Player: 1 
cards in hand: [ 3.  8. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 10.  0.  0.] 
cards in discard: [ 0. 11.  3.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  3  1  3  8  0  8 11  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8. 10. 10.  5.  7. 10.  4. 10. 10.  0. 10. 10.] 
adversary cards in hand: [10.  0.  3.  0. 11.] 
adversary cards in discard: [10. 29. 29. 29. 11.  3.  0. 10.  0. 10. 11. 11.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10] -> size -> 28 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 0. 11.  3.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  1  3  8  0  8 11  0  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8. 10. 10.  5.  7. 10.  4. 10. 10.  0. 10. 10.] 
adversary cards in hand: [10.  0.  3.  0. 11.] 
adversary cards in discard: [10. 29. 29. 29. 11.  3.  0. 10.  0. 10. 11. 11.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10] -> size -> 28 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0. 11.  3.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  1  3  8  0  8 11  0  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8. 10. 10.  5.  7. 10.  4. 10. 10.  0. 10. 10.] 
adversary cards in hand: [10.  0.  3.  0. 11.] 
adversary cards in discard: [10. 29. 29. 29. 11.  3.  0. 10.  0. 10. 11. 11.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10] -> size -> 28 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0. 11.  3.  0.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  1  3  8  0  8 11  0  0  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8. 10. 10.  5.  7. 10.  4. 10. 10.  0. 10. 10.] 
adversary cards in hand: [10.  0.  3.  0. 11.] 
adversary cards in discard: [10. 29. 29. 29. 11.  3.  0. 10.  0. 10. 11. 11.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10] -> size -> 28 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [10.  0.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[112.724846]
 [107.05174 ]
 [112.94972 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0. 11.] 
cards in discard: [10. 29. 29. 29. 11.  3.  0. 10.  0. 10. 11. 11.  3.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8. 10. 10.  5.  7. 10.  4. 10. 10.  0. 10. 10.] 
adversary cards in hand: [0. 3. 8. 1. 0.] 
adversary cards in discard: [ 0. 11.  3.  0.  0.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8  0  8 11  0  0  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 139.0397491455078



action possibilites: [-1] 
expected returns: [[124.65239]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [10. 29. 29. 29. 11.  3.  0. 10.  0. 10. 11. 11.  3.  0. 10. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8. 10. 10.  5.  7. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 3. 8. 1. 0.] 
adversary cards in discard: [ 0. 11.  3.  0.  0.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8  0  8 11  0  0  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 79 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 114.51468658447266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[117.18117 ]
 [121.76677 ]
 [112.096535]
 [121.60949 ]
 [125.92087 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [10. 29. 29. 29. 11.  3.  0. 10.  0. 10. 11. 11.  3.  0. 10. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8. 10. 10.  5.  7. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [0. 3. 8. 1. 0.] 
adversary cards in discard: [ 0. 11.  3.  0.  0.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8  0  8 11  0  0  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 124.65238952636719






Player: 1 
cards in hand: [0. 3. 8. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 1. 0.] 
cards in discard: [ 0. 11.  3.  0.  0.  3.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  3  8  0  8 11  0  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8. 10. 10.  5.  7. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [29. 10.  0.  0. 10.] 
adversary cards in discard: [10. 29. 29. 29. 11.  3.  0. 10.  0. 10. 11. 11.  3.  0. 10. 15. 11. 10.
  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15] -> size -> 29 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 1. 0.] 
cards in discard: [ 0. 11.  3.  0.  0.  3.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  3  8  0  8 11  0  0  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 28. 30.  8. 10. 10.  5.  7. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [29. 10.  0.  0. 10.] 
adversary cards in discard: [10. 29. 29. 29. 11.  3.  0. 10.  0. 10. 11. 11.  3.  0. 10. 15. 11. 10.
  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15] -> size -> 29 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 1. 0.] 
cards in discard: [ 0. 11.  3.  0.  0.  3.  0.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  3  8  0  8 11  0  0  0  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 4 
card supply: [25. 29. 30. 28. 30.  8. 10. 10.  5.  7. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [29. 10.  0.  0. 10.] 
adversary cards in discard: [10. 29. 29. 29. 11.  3.  0. 10.  0. 10. 11. 11.  3.  0. 10. 15. 11. 10.
  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15] -> size -> 29 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [29. 10.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10.] 
expected returns: [[89.311844]
 [93.75014 ]
 [84.02046 ]
 [84.02046 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  0.  0. 10.] 
cards in discard: [10. 29. 29. 29. 11.  3.  0. 10.  0. 10. 11. 11.  3.  0. 10. 15. 11. 10.
  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8. 10. 10.  5.  7. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  1  3  8  0  8 11  0  0  0  0] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 125.92086791992188



action possibilites: [-1. 10. 10.] 
expected returns: [[106.033325]
 [ 99.47217 ]
 [ 99.47217 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 10.] 
cards in discard: [10. 29. 29. 29. 11.  3.  0. 10.  0. 10. 11. 11.  3.  0. 10. 15. 11. 10.
  0.  3.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 28. 30.  8. 10. 10.  5.  7. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  1  3  8  0  8 11  0  0  0  0] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 88.14881896972656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[ 98.0923 ]
 [104.72519]
 [102.26371]
 [ 93.48221]
 [106.41989]
 [102.11999]
 [106.15945]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 10.] 
cards in discard: [10. 29. 29. 29. 11.  3.  0. 10.  0. 10. 11. 11.  3.  0. 10. 15. 11. 10.
  0.  3.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 28. 30.  8. 10. 10.  5.  7. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  1  3  8  0  8 11  0  0  0  0] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 106.0333251953125



buy possibilites: [-1] 
expected returns: [[101.62468]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 10.] 
cards in discard: [10. 29. 29. 29. 11.  3.  0. 10.  0. 10. 11. 11.  3.  0. 10. 15. 11. 10.
  0.  3.  0. 10. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8. 10. 10.  4.  7. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  1  3  8  0  8 11  0  0  0  0] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 106.41987609863281






Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  3  8  0  8 11  0  0  0  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 28. 30.  8. 10. 10.  4.  7. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  0. 10. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11] -> size -> 30 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  3  8  0  8 11  0  0  0  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 28. 30.  8. 10. 10.  4.  7. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  0. 10. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11] -> size -> 30 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  3  8  0  8 11  0  0  0  0  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 27. 30.  8. 10. 10.  4.  7. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [10.  0. 10. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11] -> size -> 30 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [10.  0. 10. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10. 29.] 
expected returns: [[118.69738]
 [113.687  ]
 [113.687  ]
 [113.687  ]
 [122.92711]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10. 10. 29.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8. 10. 10.  4.  7. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  1.  0.  8. 11.] 
adversary cards in discard: [3. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8  0  8 11  0  0  0  0  3] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 101.62467956542969



action possibilites: [-1. 10. 10.] 
expected returns: [[131.69829]
 [126.33162]
 [126.33162]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.  0.] 
cards in discard: [10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 27. 30.  8. 10. 10.  4.  7. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  1.  0.  8. 11.] 
adversary cards in discard: [3. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8  0  8 11  0  0  0  0  3] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 115.37385559082031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[127.58215]
 [133.15266]
 [131.11983]
 [123.66336]
 [134.54688]
 [130.99867]
 [134.33932]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.  0.] 
cards in discard: [10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 27. 30.  8. 10. 10.  4.  7. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  1.  0.  8. 11.] 
adversary cards in discard: [3. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8  0  8 11  0  0  0  0  3] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 131.69827270507812



buy possibilites: [-1] 
expected returns: [[167.68335]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.  0.] 
cards in discard: [10. 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8. 10. 10.  3.  7. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  1.  0.  8. 11.] 
adversary cards in discard: [3. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8  0  8 11  0  0  0  0  3] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 134.546875






Player: 1 
cards in hand: [ 0.  1.  0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0.  8. 11.] 
cards in discard: [3. 3. 3. 0. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  3  8  0  8 11  0  0  0  0  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8. 10. 10.  3.  7. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3. 10. 11. 29. 11.] 
adversary cards in discard: [10. 11. 29.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11] -> size -> 31 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0.] 
cards in discard: [3. 3. 3. 0. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 3 3 1 3 8 0 8 0 0 0 0 3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8. 10. 10.  3.  7. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3. 10. 11. 29. 11.] 
adversary cards in discard: [10. 11. 29.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11] -> size -> 31 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [3. 3. 3. 0. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 3 3 1 3 8 0 8 0 0 0 0 3] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 29. 30. 27. 30.  8. 10. 10.  3.  7. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3. 10. 11. 29. 11.] 
adversary cards in discard: [10. 11. 29.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11] -> size -> 31 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [ 3.  3.  3.  0.  0.  0. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  1  3  8  0  8  0  0  0  0  3 16] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8. 10.  9.  3.  7. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3. 10. 11. 29. 11.] 
adversary cards in discard: [10. 11. 29.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11] -> size -> 31 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 11. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 29. 11.] 
expected returns: [[133.96419]
 [128.03893]
 [134.20184]
 [138.9025 ]
 [134.20184]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11. 29. 11.] 
cards in discard: [10. 11. 29.  0. 10. 10.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8. 10.  9.  3.  7. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 0. 0. 8. 0.] 
adversary cards in discard: [ 3.  3.  3.  0.  0.  0. 16.  8.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8  0  8  0  0  0  0  3 16] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 167.683349609375



action possibilites: [-1. 10. 11. 11. 10.] 
expected returns: [[162.55154]
 [156.50732]
 [162.79459]
 [162.79459]
 [156.50732]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11. 10.] 
cards in discard: [10. 11. 29.  0. 10. 10.  0.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 27. 30.  8. 10.  9.  3.  7. 10.  4. 10. 10.  0. 10.  9.] 
adversary cards in hand: [3. 0. 0. 8. 0.] 
adversary cards in discard: [ 3.  3.  3.  0.  0.  0. 16.  8.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8  0  8  0  0  0  0  3 16] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 131.20526123046875



action possibilites: [-1] 
expected returns: [[158.76466]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10.] 
cards in discard: [10. 11. 29.  0. 10. 10.  0.  3. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 27. 30.  8. 10.  9.  3.  7. 10.  4. 10. 10.  0. 10.  8.] 
adversary cards in hand: [3. 0. 0. 8. 0.] 
adversary cards in discard: [ 3.  3.  3.  0.  0.  0. 16.  8.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8  0  8  0  0  0  0  3 16] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 69 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 165.10098266601562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[151.02023]
 [146.59265]
 [158.62305]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 10.] 
cards in discard: [10. 11. 29.  0. 10. 10.  0.  3. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 27. 30.  8. 10.  9.  3.  7. 10.  4. 10. 10.  0. 10.  8.] 
adversary cards in hand: [3. 0. 0. 8. 0.] 
adversary cards in discard: [ 3.  3.  3.  0.  0.  0. 16.  8.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  3  3  1  3  8  0  8  0  0  0  0  3 16] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 158.76466369628906






Player: 1 
cards in hand: [3. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 8. 0.] 
cards in discard: [ 3.  3.  3.  0.  0.  0. 16.  8.  0.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  3  8  0  8  0  0  0  0  3 16] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8. 10.  9.  3.  7. 10.  4. 10. 10.  0. 10.  8.] 
adversary cards in hand: [29. 29.  0. 10.  3.] 
adversary cards in discard: [10. 11. 29.  0. 10. 10.  0.  3. 15. 29. 11. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15] -> size -> 32 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 3.  3.  3.  0.  0.  0. 16.  8.  0.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  1  3  8  0  8  0  0  0  0  3 16] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8. 10.  9.  3.  7. 10.  4. 10. 10.  0. 10.  8.] 
adversary cards in hand: [29. 29.  0. 10.  3.] 
adversary cards in discard: [10. 11. 29.  0. 10. 10.  0.  3. 15. 29. 11. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15] -> size -> 32 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3.  3.  3.  0.  0.  0. 16.  8.  0.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  1  3  8  0  8  0  0  0  0  3 16] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8. 10.  9.  3.  7. 10.  4. 10. 10.  0. 10.  8.] 
adversary cards in hand: [29. 29.  0. 10.  3.] 
adversary cards in discard: [10. 11. 29.  0. 10. 10.  0.  3. 15. 29. 11. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15] -> size -> 32 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [29. 29.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 10.] 
expected returns: [[124.65523]
 [129.827  ]
 [129.827  ]
 [118.52388]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0. 10.  3.] 
cards in discard: [10. 11. 29.  0. 10. 10.  0.  3. 15. 29. 11. 10. 11. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8. 10.  9.  3.  7. 10.  4. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  3.  3. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  1  3  8  0  8  0  0  0  0  3 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 158.62306213378906



action possibilites: [-1. 29. 11.] 
expected returns: [[115.77228]
 [121.17402]
 [116.02313]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3. 11.] 
cards in discard: [10. 11. 29.  0. 10. 10.  0.  3. 15. 29. 11. 10. 11. 10. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 27. 30.  8. 10.  9.  3.  7. 10.  4. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  3.  3. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  1  3  8  0  8  0  0  0  0  3 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 122.96208190917969



action possibilites: [-1. 11.] 
expected returns: [[128.77641]
 [129.04507]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.] 
cards in discard: [10. 11. 29.  0. 10. 10.  0.  3. 15. 29. 11. 10. 11. 10. 10.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 27. 30.  8. 10.  9.  3.  7. 10.  4. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  3.  3. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  1  3  8  0  8  0  0  0  0  3 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 114.34585571289062



action possibilites: [-1] 
expected returns: [[145.28421]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [10. 11. 29.  0. 10. 10.  0.  3. 15. 29. 11. 10. 11. 10. 10.  3. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 27. 30.  8. 10.  9.  3.  7. 10.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  3.  3. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  1  3  8  0  8  0  0  0  0  3 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0 64  0] 
sum of rewards: 119 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 131.63633728027344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
expected returns: [[137.0336 ]
 [144.2865 ]
 [141.60222]
 [132.04079]
 [142.35931]
 [146.1457 ]
 [141.44377]
 [151.86333]
 [136.36078]
 [143.5908 ]
 [145.85875]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [10. 11. 29.  0. 10. 10.  0.  3. 15. 29. 11. 10. 11. 10. 10.  3. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 29. 30. 27. 30.  8. 10.  9.  3.  7. 10.  4. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  3.  3. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  1  3  8  0  8  0  0  0  0  3 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 145.28421020507812



buy possibilites: [-1] 
expected returns: [[142.60133]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [10. 11. 29.  0. 10. 10.  0.  3. 15. 29. 11. 10. 11. 10. 10.  3. 15. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8. 10.  9.  3.  7. 10.  3. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  3.  3. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  1  3  8  0  8  0  0  0  0  3 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 183 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 151.8633270263672






Player: 1 
cards in hand: [ 0.  3.  3. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 16.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1  3  8  0  8  0  0  0  0  3 16] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8. 10.  9.  3.  7. 10.  3. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  0.  0.  3. 15.] 
adversary cards in discard: [10. 11. 29.  0. 10. 10.  0.  3. 15. 29. 11. 10. 11. 10. 10.  3. 15. 29.
 29. 29. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29] -> size -> 34 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 16.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1  3  8  0  8  0  0  0  0  3 16] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 27. 30.  8. 10.  9.  3.  7. 10.  3. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  0.  0.  3. 15.] 
adversary cards in discard: [10. 11. 29.  0. 10. 10.  0.  3. 15. 29. 11. 10. 11. 10. 10.  3. 15. 29.
 29. 29. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29] -> size -> 34 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 16.  0.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1  3  8  0  8  0  0  0  0  3 16  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8. 10.  9.  3.  6. 10.  3. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  0.  0.  3. 15.] 
adversary cards in discard: [10. 11. 29.  0. 10. 10.  0.  3. 15. 29. 11. 10. 11. 10. 10.  3. 15. 29.
 29. 29. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29] -> size -> 34 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[118.02609]
 [116.10591]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 15.] 
cards in discard: [10. 11. 29.  0. 10. 10.  0.  3. 15. 29. 11. 10. 11. 10. 10.  3. 15. 29.
 29. 29. 11.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8. 10.  9.  3.  6. 10.  3. 10. 10.  0. 10.  7.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [ 8.  0.  3.  3. 16.  0.] 
adversary owned cards: [ 3  1  3  8  0  8  0  0  0  0  3 16  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 142.60133361816406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[110.03519 ]
 [116.37037 ]
 [114.056404]
 [105.57408 ]
 [117.9874  ]
 [113.91955 ]
 [117.73324 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 15.] 
cards in discard: [10. 11. 29.  0. 10. 10.  0.  3. 15. 29. 11. 10. 11. 10. 10.  3. 15. 29.
 29. 29. 11.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 27. 30.  8. 10.  9.  3.  6. 10.  3. 10. 10.  0. 10.  7.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [ 8.  0.  3.  3. 16.  0.] 
adversary owned cards: [ 3  1  3  8  0  8  0  0  0  0  3 16  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 118.02609252929688



buy possibilites: [-1] 
expected returns: [[108.763245]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 15.] 
cards in discard: [10. 11. 29.  0. 10. 10.  0.  3. 15. 29. 11. 10. 11. 10. 10.  3. 15. 29.
 29. 29. 11.  0.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8. 10.  9.  2.  6. 10.  3. 10. 10.  0. 10.  7.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [ 8.  0.  3.  3. 16.  0.] 
adversary owned cards: [ 3  1  3  8  0  8  0  0  0  0  3 16  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 117.98739624023438






Player: 1 
cards in hand: [8. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [ 8.  0.  3.  3. 16.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1  3  8  0  8  0  0  0  0  3 16  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8. 10.  9.  2.  6. 10.  3. 10. 10.  0. 10.  7.] 
adversary cards in hand: [29. 10. 10. 10. 11.] 
adversary cards in discard: [10. 11. 29.  0. 10. 10.  0.  3. 15. 29. 11. 10. 11. 10. 10.  3. 15. 29.
 29. 29. 11.  0.  0. 11.  0.  0.  0.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11] -> size -> 35 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [ 8.  0.  3.  3. 16.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  1  3  8  8  0  0  0  3 16  8] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8. 10.  9.  2.  6. 10.  3. 10. 10.  0. 10.  7.] 
adversary cards in hand: [29. 10. 10. 10. 11.] 
adversary cards in discard: [10. 11. 29.  0. 10. 10.  0.  3. 15. 29. 11. 10. 11. 10. 10.  3. 15. 29.
 29. 29. 11.  0.  0. 11.  0.  0.  0.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11] -> size -> 35 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 8.  0.  3.  3. 16.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  1  3  8  8  0  0  0  3 16  8] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 27. 30.  8. 10.  9.  2.  6. 10.  3. 10. 10.  0. 10.  7.] 
adversary cards in hand: [29. 10. 10. 10. 11.] 
adversary cards in discard: [10. 11. 29.  0. 10. 10.  0.  3. 15. 29. 11. 10. 11. 10. 10.  3. 15. 29.
 29. 29. 11.  0.  0. 11.  0.  0.  0.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11] -> size -> 35 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [29. 10. 10. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10. 10. 11.] 
expected returns: [[61.20132 ]
 [65.12231 ]
 [56.5559  ]
 [56.5559  ]
 [56.5559  ]
 [61.381218]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 10. 10. 11.] 
cards in discard: [10. 11. 29.  0. 10. 10.  0.  3. 15. 29. 11. 10. 11. 10. 10.  3. 15. 29.
 29. 29. 11.  0.  0. 11.  0.  0.  0.  3. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8. 10.  9.  2.  6. 10.  3. 10. 10.  0. 10.  7.] 
adversary cards in hand: [0. 3. 8. 8. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  1  3  8  8  0  0  0  3 16  8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 108.76324462890625



action possibilites: [-1. 10. 10. 11. 11.] 
expected returns: [[48.012527]
 [43.219112]
 [43.219112]
 [48.197926]
 [48.197926]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11. 11.] 
cards in discard: [10. 11. 29.  0. 10. 10.  0.  3. 15. 29. 11. 10. 11. 10. 10.  3. 15. 29.
 29. 29. 11.  0.  0. 11.  0.  0.  0.  3. 15. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 27. 30.  8. 10.  9.  2.  6. 10.  3. 10. 10.  0. 10.  7.] 
adversary cards in hand: [0. 3. 8. 8. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  1  3  8  8  0  0  0  3 16  8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 60.18413543701172



action possibilites: [-1] 
expected returns: [[47.436813]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11.] 
cards in discard: [10. 11. 29.  0. 10. 10.  0.  3. 15. 29. 11. 10. 11. 10. 10.  3. 15. 29.
 29. 29. 11.  0.  0. 11.  0.  0.  0.  3. 15. 10. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 27. 30.  8. 10.  9.  2.  6. 10.  3. 10. 10.  0. 10.  6.] 
adversary cards in hand: [0. 3. 8. 8. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  1  3  8  8  0  0  0  3 16  8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0 -10   0   0  64   0] 
sum of rewards: 89 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 50.015174865722656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[42.46157 ]
 [39.748955]
 [47.436817]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 11.] 
cards in discard: [10. 11. 29.  0. 10. 10.  0.  3. 15. 29. 11. 10. 11. 10. 10.  3. 15. 29.
 29. 29. 11.  0.  0. 11.  0.  0.  0.  3. 15. 10. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 27. 30.  8. 10.  9.  2.  6. 10.  3. 10. 10.  0. 10.  6.] 
adversary cards in hand: [0. 3. 8. 8. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  1  3  8  8  0  0  0  3 16  8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 47.43681335449219






Player: 1 
cards in hand: [0. 3. 8. 8. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 8. 1.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1  3  8  8  0  0  0  3 16  8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8. 10.  9.  2.  6. 10.  3. 10. 10.  0. 10.  6.] 
adversary cards in hand: [29. 10. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15] -> size -> 36 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8  0  0  0  3 16  8] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8. 10.  9.  2.  6. 10.  3. 10. 10.  0. 10.  6.] 
adversary cards in hand: [29. 10. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15] -> size -> 36 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8  0  0  0  3 16  8] -> size -> 8 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 27. 30.  8. 10.  9.  2.  6. 10.  3. 10. 10.  0. 10.  6.] 
adversary cards in hand: [29. 10. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15] -> size -> 36 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8  0  0  0  3 16  8  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 27. 30.  8. 10.  9.  2.  6. 10.  3. 10. 10.  0. 10.  6.] 
adversary cards in hand: [29. 10. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15] -> size -> 36 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [29. 10. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 11.] 
expected returns: [[174.85077]
 [179.96387]
 [168.72563]
 [175.09508]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8. 10.  9.  2.  6. 10.  3. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 8.  0.  0. 16.  3.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 3  8  0  0  0  3 16  8  0] -> size -> 9 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 47.43681335449219



action possibilites: [-1. 10. 11. 11.] 
expected returns: [[188.32587]
 [182.1052 ]
 [188.57095]
 [188.57095]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0. 11.] 
cards in discard: [0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 27. 30.  8. 10.  9.  2.  6. 10.  3. 10. 10.  0. 10.  6.] 
adversary cards in hand: [ 8.  0.  0. 16.  3.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 3  8  0  0  0  3 16  8  0] -> size -> 9 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 170.9581298828125



action possibilites: [-1] 
expected returns: [[195.1245]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.] 
cards in discard: [ 0. 15.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 27. 30.  8. 10.  9.  2.  6. 10.  3. 10. 10.  0. 10.  5.] 
adversary cards in hand: [ 8.  0.  0. 16.  3.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 3  8  0  0  0  3 16  8  0] -> size -> 9 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  40   0   0   0   0 -20   0   0  64   0] 
sum of rewards: 109 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 191.0013427734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[190.15538]
 [194.24518]
 [185.72777]
 [194.09862]
 [198.15822]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11.] 
cards in discard: [ 0. 15.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 27. 30.  8. 10.  9.  2.  6. 10.  3. 10. 10.  0. 10.  5.] 
adversary cards in hand: [ 8.  0.  0. 16.  3.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 3  8  0  0  0  3 16  8  0] -> size -> 9 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 195.12449645996094






Player: 1 
cards in hand: [ 8.  0.  0. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 16.  3.] 
cards in discard: [0. 8. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  0  0  0  3 16  8  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8. 10.  9.  2.  6. 10.  3. 10. 10.  0. 10.  5.] 
adversary cards in hand: [15. 29. 15. 10. 11.] 
adversary cards in discard: [ 0. 15. 29. 11. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15] -> size -> 37 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.] 
cards in discard: [0. 8. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  3 16  8  0] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8. 10.  9.  2.  6. 10.  3. 10. 10.  0. 10.  5.] 
adversary cards in hand: [15. 29. 15. 10. 11.] 
adversary cards in discard: [ 0. 15. 29. 11. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15] -> size -> 37 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.] 
cards in discard: [0. 8. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  3 16  8  0] -> size -> 6 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8. 10.  9.  2.  6. 10.  3. 10. 10.  0. 10.  5.] 
adversary cards in hand: [15. 29. 15. 10. 11.] 
adversary cards in discard: [ 0. 15. 29. 11. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15] -> size -> 37 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.] 
cards in discard: [0. 8. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  3 16  8  0  0] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8. 10.  9.  2.  6. 10.  3. 10. 10.  0. 10.  5.] 
adversary cards in hand: [15. 29. 15. 10. 11.] 
adversary cards in discard: [ 0. 15. 29. 11. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15] -> size -> 37 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [15. 29. 15. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29. 15. 10. 11.] 
expected returns: [[181.9784 ]
 [180.07307]
 [187.01704]
 [180.07307]
 [175.93416]
 [182.22147]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29. 15. 10. 11.] 
cards in discard: [ 0. 15. 29. 11. 10.  0. 11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8. 10.  9.  2.  6. 10.  3. 10. 10.  0. 10.  5.] 
adversary cards in hand: [16.  0.  8.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  3 16  8  0  0] -> size -> 7 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 198.158203125



action possibilites: [-1. 15. 15. 10. 11.] 
expected returns: [[214.03725]
 [211.98912]
 [211.98912]
 [207.54573]
 [214.29495]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 10. 11.] 
cards in discard: [ 0. 15. 29. 11. 10.  0. 11.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 27. 30.  8. 10.  9.  2.  6. 10.  3. 10. 10.  0. 10.  5.] 
adversary cards in hand: [16.  0.  8.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  3 16  8  0  0] -> size -> 7 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 178.51573181152344



action possibilites: [-1] 
expected returns: [[197.37247]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 10.] 
cards in discard: [ 0. 15. 29. 11. 10.  0. 11.  3. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 27. 30.  8. 10.  9.  2.  6. 10.  3. 10. 10.  0. 10.  4.] 
adversary cards in hand: [16.  0.  8.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  3 16  8  0  0] -> size -> 7 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  40   0   0   0   0 -30   0   0  64   0] 
sum of rewards: 129 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 216.76443481445312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[189.77216]
 [184.95258]
 [198.05374]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15. 10.] 
cards in discard: [ 0. 15. 29. 11. 10.  0. 11.  3. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 29. 30. 27. 30.  8. 10.  9.  2.  6. 10.  3. 10. 10.  0. 10.  4.] 
adversary cards in hand: [16.  0.  8.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  3 16  8  0  0] -> size -> 7 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 197.37246704101562






Player: 1 
cards in hand: [16.  0.  8.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  8.  0.  3.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  3 16  8  0  0] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8. 10.  9.  2.  6. 10.  3. 10. 10.  0. 10.  4.] 
adversary cards in hand: [11.  0.  0. 10. 29.] 
adversary cards in discard: [ 0. 15. 29. 11. 10.  0. 11.  3. 15. 29. 11. 15. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15] -> size -> 38 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0.] 
cards in discard: [1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8  0 16  8  0  0  1] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 27. 30.  8. 10.  9.  2.  6. 10.  3. 10. 10.  0. 10.  4.] 
adversary cards in hand: [11.  0.  0. 10. 29.] 
adversary cards in discard: [ 0. 15. 29. 11. 10.  0. 11.  3. 15. 29. 11. 15. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15] -> size -> 38 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8  0 16  8  0  0  1] -> size -> 7 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 28. 30. 27. 30.  8. 10.  9.  2.  6. 10.  3. 10. 10.  0. 10.  4.] 
adversary cards in hand: [11.  0.  0. 10. 29.] 
adversary cards in discard: [ 0. 15. 29. 11. 10.  0. 11.  3. 15. 29. 11. 15. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15] -> size -> 38 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [1. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8  0 16  8  0  0  1  8] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 27. 30.  8. 10.  9.  2.  5. 10.  3. 10. 10.  0. 10.  4.] 
adversary cards in hand: [11.  0.  0. 10. 29.] 
adversary cards in discard: [ 0. 15. 29. 11. 10.  0. 11.  3. 15. 29. 11. 15. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15] -> size -> 38 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [11.  0.  0. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29.] 
expected returns: [[152.00276]
 [152.27377]
 [145.16197]
 [157.69516]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 10. 29.] 
cards in discard: [ 0. 15. 29. 11. 10.  0. 11.  3. 15. 29. 11. 15. 15. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 27. 30.  8. 10.  9.  2.  5. 10.  3. 10. 10.  0. 10.  4.] 
adversary cards in hand: [8. 0. 1. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0 16  8  0  0  1  8] -> size -> 8 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 198.05374145507812



action possibilites: [-1. 11. 10. 10.] 
expected returns: [[163.49219]
 [163.75638]
 [156.80463]
 [156.80463]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10. 10.] 
cards in discard: [ 0. 15. 29. 11. 10.  0. 11.  3. 15. 29. 11. 15. 15. 10.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 27. 30.  8. 10.  9.  2.  5. 10.  3. 10. 10.  0. 10.  4.] 
adversary cards in hand: [8. 0. 1. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0 16  8  0  0  1  8] -> size -> 8 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 150.5107421875



action possibilites: [-1] 
expected returns: [[158.80963]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.] 
cards in discard: [ 0. 15. 29. 11. 10.  0. 11.  3. 15. 29. 11. 15. 15. 10.  0. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 27. 30.  8. 10.  9.  2.  5. 10.  3. 10. 10.  0. 10.  3.] 
adversary cards in hand: [8. 0. 1. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0 16  8  0  0  1  8] -> size -> 8 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0  40   0   0   0   0 -40   0   0  64   0] 
sum of rewards: 149 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 166.2946319580078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[150.18811]
 [154.60869]
 [145.33435]
 [154.45303]
 [158.71858]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.] 
cards in discard: [ 0. 15. 29. 11. 10.  0. 11.  3. 15. 29. 11. 15. 15. 10.  0. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 28. 30. 27. 30.  8. 10.  9.  2.  5. 10.  3. 10. 10.  0. 10.  3.] 
adversary cards in hand: [8. 0. 1. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0 16  8  0  0  1  8] -> size -> 8 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 158.80963134765625






Player: 1 
cards in hand: [8. 0. 1. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 1. 8. 0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 16  8  0  0  1  8] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 27. 30.  8. 10.  9.  2.  5. 10.  3. 10. 10.  0. 10.  3.] 
adversary cards in hand: [29.  0. 15.  0. 11.] 
adversary cards in discard: [ 0. 15. 29. 11. 10.  0. 11.  3. 15. 29. 11. 15. 15. 10.  0. 15. 29. 11.
  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15] -> size -> 39 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 16  8  0  1  8] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 27. 30.  8. 10.  9.  2.  5. 10.  3. 10. 10.  0. 10.  3.] 
adversary cards in hand: [29.  0. 15.  0. 11.] 
adversary cards in discard: [ 0. 15. 29. 11. 10.  0. 11.  3. 15. 29. 11. 15. 15. 10.  0. 15. 29. 11.
  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15] -> size -> 39 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 16  8  0  1  8] -> size -> 6 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 28. 30. 27. 30.  8. 10.  9.  2.  5. 10.  3. 10. 10.  0. 10.  3.] 
adversary cards in hand: [29.  0. 15.  0. 11.] 
adversary cards in discard: [ 0. 15. 29. 11. 10.  0. 11.  3. 15. 29. 11. 15. 15. 10.  0. 15. 29. 11.
  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15] -> size -> 39 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8.] 
cards in discard: [8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 16  8  0  1  8  8] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 27. 30.  8. 10.  9.  2.  4. 10.  3. 10. 10.  0. 10.  3.] 
adversary cards in hand: [29.  0. 15.  0. 11.] 
adversary cards in discard: [ 0. 15. 29. 11. 10.  0. 11.  3. 15. 29. 11. 15. 15. 10.  0. 15. 29. 11.
  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15] -> size -> 39 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [29.  0. 15.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 11.] 
expected returns: [[135.26837]
 [140.95808]
 [133.1083 ]
 [135.53748]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 15.  0. 11.] 
cards in discard: [ 0. 15. 29. 11. 10.  0. 11.  3. 15. 29. 11. 15. 15. 10.  0. 15. 29. 11.
  0. 10. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 27. 30.  8. 10.  9.  2.  4. 10.  3. 10. 10.  0. 10.  3.] 
adversary cards in hand: [ 1.  8.  8.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 16  8  0  1  8  8] -> size -> 7 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 158.71856689453125



action possibilites: [-1. 11. 10.] 
expected returns: [[128.47476]
 [128.70912]
 [122.25166]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 10.] 
cards in discard: [ 0. 15. 29. 11. 10.  0. 11.  3. 15. 29. 11. 15. 15. 10.  0. 15. 29. 11.
  0. 10. 10. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 27. 30.  8. 10.  9.  2.  4. 10.  3. 10. 10.  0. 10.  3.] 
adversary cards in hand: [ 1.  8.  8.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 16  8  0  1  8  8] -> size -> 7 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 133.77407836914062



action possibilites: [-1] 
expected returns: [[139.16544]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.] 
cards in discard: [ 0. 15. 29. 11. 10.  0. 11.  3. 15. 29. 11. 15. 15. 10.  0. 15. 29. 11.
  0. 10. 10. 15. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 27. 30.  8. 10.  9.  2.  4. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [ 1.  8.  8.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 16  8  0  1  8  8] -> size -> 7 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0  40   0   0   0   0 -50   0   0  64   0] 
sum of rewards: 139 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 131.06512451171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[129.74287]
 [136.20866]
 [133.84781]
 [125.19076]
 [137.81113]
 [133.70616]
 [137.56505]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [ 0. 15. 29. 11. 10.  0. 11.  3. 15. 29. 11. 15. 15. 10.  0. 15. 29. 11.
  0. 10. 10. 15. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 28. 30. 27. 30.  8. 10.  9.  2.  4. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [ 1.  8.  8.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 16  8  0  1  8  8] -> size -> 7 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 139.16543579101562



buy possibilites: [-1] 
expected returns: [[101.62597]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [ 0. 15. 29. 11. 10.  0. 11.  3. 15. 29. 11. 15. 15. 10.  0. 15. 29. 11.
  0. 10. 10. 15. 15. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 27. 30.  8. 10.  9.  1.  4. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [ 1.  8.  8.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 16  8  0  1  8  8] -> size -> 7 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0  40   0   0   0   0 -60   0   0  54   0] 
sum of rewards: 119 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 137.81112670898438






Player: 1 
cards in hand: [ 1.  8.  8.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  8.  0. 16.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 16  8  0  1  8  8] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 27. 30.  8. 10.  9.  1.  4. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [ 3.  0. 11. 15. 29.] 
adversary cards in discard: [ 0. 15. 29. 11. 10.  0. 11.  3. 15. 29. 11. 15. 15. 10.  0. 15. 29. 11.
  0. 10. 10. 15. 15. 11. 29. 11.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11] -> size -> 41 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 1 8 8] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 27. 30.  8. 10.  9.  1.  4. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [ 3.  0. 11. 15. 29.] 
adversary cards in discard: [ 0. 15. 29. 11. 10.  0. 11.  3. 15. 29. 11. 15. 15. 10.  0. 15. 29. 11.
  0. 10. 10. 15. 15. 11. 29. 11.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11] -> size -> 41 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 1 8 8] -> size -> 5 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 28. 30. 27. 30.  8. 10.  9.  1.  4. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [ 3.  0. 11. 15. 29.] 
adversary cards in discard: [ 0. 15. 29. 11. 10.  0. 11.  3. 15. 29. 11. 15. 15. 10.  0. 15. 29. 11.
  0. 10. 10. 15. 15. 11. 29. 11.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11] -> size -> 41 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 11. 15. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 29.] 
expected returns: [[58.58328 ]
 [58.77381 ]
 [57.017853]
 [62.81524 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11. 15. 29.] 
cards in discard: [ 0. 15. 29. 11. 10.  0. 11.  3. 15. 29. 11. 15. 15. 10.  0. 15. 29. 11.
  0. 10. 10. 15. 15. 11. 29. 11.  0.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 27. 30.  8. 10.  9.  1.  4. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [8. 8. 1. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 1 8 8] -> size -> 5 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 101.62596893310547



action possibilites: [-1. 15. 29.] 
expected returns: [[71.70492]
 [70.18689]
 [75.69151]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15. 29.] 
cards in discard: [ 0. 15. 29. 11. 10.  0. 11.  3. 15. 29. 11. 15. 15. 10.  0. 15. 29. 11.
  0. 10. 10. 15. 15. 11. 29. 11.  0.  0. 10. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 27. 30.  8. 10.  9.  1.  4. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [8. 8. 1. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 1 8 8] -> size -> 5 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 57.49038314819336



action possibilites: [-1. 15. 10.] 
expected returns: [[64.332535]
 [62.732452]
 [59.311493]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 10.] 
cards in discard: [ 0. 15. 29. 11. 10.  0. 11.  3. 15. 29. 11. 15. 15. 10.  0. 15. 29. 11.
  0. 10. 10. 15. 15. 11. 29. 11.  0.  0. 10. 11.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11] -> size -> 41 
action values: 1 
buys: 0 
player value: 2 
card supply: [23. 28. 30. 27. 30.  8. 10.  9.  1.  4. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [8. 8. 1. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 1 8 8] -> size -> 5 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 70.65272521972656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[58.03641 ]
 [63.226143]
 [61.302822]
 [54.415894]
 [64.53185 ]
 [61.18933 ]
 [64.33254 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 10.] 
cards in discard: [ 0. 15. 29. 11. 10.  0. 11.  3. 15. 29. 11. 15. 15. 10.  0. 15. 29. 11.
  0. 10. 10. 15. 15. 11. 29. 11.  0.  0. 10. 11.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 28. 30. 27. 30.  8. 10.  9.  1.  4. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [8. 8. 1. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 1 8 8] -> size -> 5 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 64.33253479003906



buy possibilites: [-1] 
expected returns: [[55.54106]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 10.] 
cards in discard: [ 0. 15. 29. 11. 10.  0. 11.  3. 15. 29. 11. 15. 15. 10.  0. 15. 29. 11.
  0. 10. 10. 15. 15. 11. 29. 11.  0.  0. 10. 11.  3. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 27. 30.  8. 10.  9.  0.  4. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [8. 8. 1. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 1 8 8] -> size -> 5 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0  40   0   0   0   0 -70   0   0  54   0] 
sum of rewards: 109 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 64.53185272216797






Player: 1 
cards in hand: [8. 8. 1. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 1. 8. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 1 8 8] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 27. 30.  8. 10.  9.  0.  4. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [10. 10.  3. 11. 10.] 
adversary cards in discard: [ 0. 15. 29. 11. 10.  0. 11.  3. 15. 29. 11. 15. 15. 10.  0. 15. 29. 11.
  0. 10. 10. 15. 15. 11. 29. 11.  0.  0. 10. 11.  3. 11. 29. 29.  0. 15.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11] -> size -> 42 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [1 8] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 27. 30.  8. 10.  9.  0.  4. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [10. 10.  3. 11. 10.] 
adversary cards in discard: [ 0. 15. 29. 11. 10.  0. 11.  3. 15. 29. 11. 15. 15. 10.  0. 15. 29. 11.
  0. 10. 10. 15. 15. 11. 29. 11.  0.  0. 10. 11.  3. 11. 29. 29.  0. 15.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11] -> size -> 42 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [1 8] -> size -> 2 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 28. 30. 27. 30.  8. 10.  9.  0.  4. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [10. 10.  3. 11. 10.] 
adversary cards in discard: [ 0. 15. 29. 11. 10.  0. 11.  3. 15. 29. 11. 15. 15. 10.  0. 15. 29. 11.
  0. 10. 10. 15. 15. 11. 29. 11.  0.  0. 10. 11.  3. 11. 29. 29.  0. 15.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11] -> size -> 42 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [1 8 8] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 27. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [10. 10.  3. 11. 10.] 
adversary cards in discard: [ 0. 15. 29. 11. 10.  0. 11.  3. 15. 29. 11. 15. 15. 10.  0. 15. 29. 11.
  0. 10. 10. 15. 15. 11. 29. 11.  0.  0. 10. 11.  3. 11. 29. 29.  0. 15.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11] -> size -> 42 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [10. 10.  3. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11. 10.] 
expected returns: [[106.55184 ]
 [101.112885]
 [101.112885]
 [106.76499 ]
 [101.112885]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3. 11. 10.] 
cards in discard: [ 0. 15. 29. 11. 10.  0. 11.  3. 15. 29. 11. 15. 15. 10.  0. 15. 29. 11.
  0. 10. 10. 15. 15. 11. 29. 11.  0.  0. 10. 11.  3. 11. 29. 29.  0. 15.
 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 27. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [1. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [1 8 8] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 55.54106140136719



action possibilites: [-1] 
expected returns: [[101.95087]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3. 10.] 
cards in discard: [ 0. 15. 29. 11. 10.  0. 11.  3. 15. 29. 11. 15. 15. 10.  0. 15. 29. 11.
  0. 10. 10. 15. 15. 11. 29. 11.  0.  0. 10. 11.  3. 11. 29. 29.  0. 15.
 10.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 27. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [1. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [1 8 8] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0 -80   0   0  27   0] 
sum of rewards: 52 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 105.35635375976562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 95.106125]
 [ 91.13423 ]
 [101.95087 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  3. 10.] 
cards in discard: [ 0. 15. 29. 11. 10.  0. 11.  3. 15. 29. 11. 15. 15. 10.  0. 15. 29. 11.
  0. 10. 10. 15. 15. 11. 29. 11.  0.  0. 10. 11.  3. 11. 29. 29.  0. 15.
 10.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1] -> size -> 43 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 27. 30. 27. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [1. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [1 8 8] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 101.95086669921875






Player: 1 
cards in hand: [1. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [1 8 8] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 27. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [ 0. 29. 15. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1] -> size -> 43 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 27. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [ 0. 29. 15. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1] -> size -> 43 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8] -> size -> 2 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 27. 30. 27. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [ 0. 29. 15. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1] -> size -> 43 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [ 0. 29. 15. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1] -> size -> 43 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 15. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 29. 11.] 
expected returns: [[206.68088]
 [211.56757]
 [204.83104]
 [211.56757]
 [206.91504]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 15. 29. 11.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 101.95086669921875



action possibilites: [-1. 15. 11. 15.] 
expected returns: [[208.19507]
 [206.3389 ]
 [208.42926]
 [206.3389 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11. 15.] 
cards in discard: [ 0. 29.] 
cards in deck: 37 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 27. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 202.84271240234375



action possibilites: [-1] 
expected returns: [[235.24948]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.] 
cards in discard: [ 0. 29.  1.] 
cards in deck: 37 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 26. 30. 27. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0  40   0   0   0   0 -90   0   0  27   0] 
sum of rewards: 62 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 206.96963500976562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[229.54048]
 [224.83333]
 [237.63116]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15.] 
cards in discard: [ 0. 29.  1.] 
cards in deck: 37 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1] -> size -> 44 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 27. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 235.24948120117188






Player: 1 
cards in hand: [8. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 27. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [15.  0. 10.  0.  3.] 
adversary cards in discard: [ 0. 29.  1. 29. 11. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1] -> size -> 44 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 27. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [15.  0. 10.  0.  3.] 
adversary cards in discard: [ 0. 29.  1. 29. 11. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1] -> size -> 44 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0] -> size -> 4 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 27. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [15.  0. 10.  0.  3.] 
adversary cards in discard: [ 0. 29.  1. 29. 11. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1] -> size -> 44 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [15.  0. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
expected returns: [[219.69586]
 [217.76135]
 [213.55911]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 10.  0.  3.] 
cards in discard: [ 0. 29.  1. 29. 11. 15. 15.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 27. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [0. 8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0] -> size -> 4 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 237.63116455078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[210.94797]
 [214.99991]
 [206.4526 ]
 [214.86198]
 [218.66718]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 10.  0.  3.] 
cards in discard: [ 0. 29.  1. 29. 11. 15. 15.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 26. 30. 27. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [0. 8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0] -> size -> 4 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 218.46109008789062



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 8. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 27. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [11. 11.  0. 15. 29.] 
adversary cards in discard: [ 0. 29.  1. 29. 11. 15. 15. 15.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1] -> size -> 44 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 26. 30. 27. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [11. 11.  0. 15. 29.] 
adversary cards in discard: [ 0. 29.  1. 29. 11. 15. 15. 15.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1] -> size -> 44 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8. 0.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 3] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 26. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [11. 11.  0. 15. 29.] 
adversary cards in discard: [ 0. 29.  1. 29. 11. 15. 15. 15.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1] -> size -> 44 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [11. 11.  0. 15. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 15. 29.] 
expected returns: [[176.57832]
 [176.82994]
 [176.82994]
 [174.60118]
 [181.97018]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0. 15. 29.] 
cards in discard: [ 0. 29.  1. 29. 11. 15. 15. 15.  0. 10.  0.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 26. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [0. 8. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 3] -> size -> 5 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 218.6671905517578



action possibilites: [-1. 11. 15.] 
expected returns: [[169.13922]
 [169.40408]
 [167.05806]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 15.] 
cards in discard: [ 0. 29.  1. 29. 11. 15. 15. 15.  0. 10.  0.  3. 11. 29.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1] -> size -> 44 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 26. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [0. 8. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 3] -> size -> 5 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 175.2130126953125



action possibilites: [-1] 
expected returns: [[197.6076]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.] 
cards in discard: [ 0. 29.  1. 29. 11. 15. 15. 15.  0. 10.  0.  3. 11. 29.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 25. 30. 26. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [0. 8. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 3] -> size -> 5 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[  -5    0    0   60    0    0   40    0    0    0    0 -100    0    0
   27    0] 
sum of rewards: 22 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 167.70236206054688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[187.60008]
 [192.25241]
 [182.44073]
 [192.09286]
 [196.46564]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.] 
cards in discard: [ 0. 29.  1. 29. 11. 15. 15. 15.  0. 10.  0.  3. 11. 29.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1  1] -> size -> 45 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 25. 30. 26. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [0. 8. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 3] -> size -> 5 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 197.60760498046875






Player: 1 
cards in hand: [0. 8. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 8. 3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 3] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 26. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [10. 11. 15. 29. 11.] 
adversary cards in discard: [ 0. 29.  1. 29. 11. 15. 15. 15.  0. 10.  0.  3. 11. 29.  1. 29. 11.  0.
 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1  1] -> size -> 45 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 26. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [10. 11. 15. 29. 11.] 
adversary cards in discard: [ 0. 29.  1. 29. 11. 15. 15. 15.  0. 10.  0.  3. 11. 29.  1. 29. 11.  0.
 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1  1] -> size -> 45 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 25. 30. 26. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [10. 11. 15. 29. 11.] 
adversary cards in discard: [ 0. 29.  1. 29. 11. 15. 15. 15.  0. 10.  0.  3. 11. 29.  1. 29. 11.  0.
 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1  1] -> size -> 45 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0 0] -> size -> 4 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 25. 30. 26. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [10. 11. 15. 29. 11.] 
adversary cards in discard: [ 0. 29.  1. 29. 11. 15. 15. 15.  0. 10.  0.  3. 11. 29.  1. 29. 11.  0.
 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1  1] -> size -> 45 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [10. 11. 15. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 15. 29. 11.] 
expected returns: [[120.36967]
 [114.27682]
 [120.62348]
 [118.37874]
 [125.63335]
 [120.62348]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 15. 29. 11.] 
cards in discard: [ 0. 29.  1. 29. 11. 15. 15. 15.  0. 10.  0.  3. 11. 29.  1. 29. 11.  0.
 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 26. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0] -> size -> 4 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 196.46560668945312



action possibilites: [-1. 10. 11.] 
expected returns: [[105.74707]
 [ 99.74924]
 [105.988  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  3.] 
cards in discard: [ 0. 29.  1. 29. 11. 15. 15. 15.  0. 10.  0.  3. 11. 29.  1. 29. 11.  0.
 15. 15. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 25. 30. 26. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0] -> size -> 4 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 118.99564361572266



action possibilites: [-1] 
expected returns: [[116.774475]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.] 
cards in discard: [ 0. 29.  1. 29. 11. 15. 15. 15.  0. 10.  0.  3. 11. 29.  1. 29. 11.  0.
 15. 15. 11.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1  1  1] -> size -> 46 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 24. 30. 26. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0] -> size -> 4 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[  -5    0    0   90    0    0   40    0    0    0    0 -110    0    0
   27    0] 
sum of rewards: 42 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 104.425537109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[109.061005]
 [104.68298 ]
 [116.774475]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.] 
cards in discard: [ 0. 29.  1. 29. 11. 15. 15. 15.  0. 10.  0.  3. 11. 29.  1. 29. 11.  0.
 15. 15. 11.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1  1  1] -> size -> 46 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 24. 30. 26. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0] -> size -> 4 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 116.77447509765625






Player: 1 
cards in hand: [8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 26. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [ 3. 15. 10. 10. 11.] 
adversary cards in discard: [ 0. 29.  1. 29. 11. 15. 15. 15.  0. 10.  0.  3. 11. 29.  1. 29. 11.  0.
 15. 15. 11.  1. 29. 11. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1  1  1] -> size -> 46 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0] -> size -> 4 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 24. 30. 26. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [ 3. 15. 10. 10. 11.] 
adversary cards in discard: [ 0. 29.  1. 29. 11. 15. 15. 15.  0. 10.  0.  3. 11. 29.  1. 29. 11.  0.
 15. 15. 11.  1. 29. 11. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1  1  1] -> size -> 46 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0 0] -> size -> 5 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 24. 30. 26. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [ 3. 15. 10. 10. 11.] 
adversary cards in discard: [ 0. 29.  1. 29. 11. 15. 15. 15.  0. 10.  0.  3. 11. 29.  1. 29. 11.  0.
 15. 15. 11.  1. 29. 11. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1  1  1] -> size -> 46 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 3. 15. 10. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 10. 11.] 
expected returns: [[59.824284]
 [58.39219 ]
 [55.291897]
 [55.291897]
 [60.011944]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 10. 10. 11.] 
cards in discard: [ 0. 29.  1. 29. 11. 15. 15. 15.  0. 10.  0.  3. 11. 29.  1. 29. 11.  0.
 15. 15. 11.  1. 29. 11. 10.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1  1  1] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 26. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0 0] -> size -> 5 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 116.77447509765625



action possibilites: [-1] 
expected returns: [[48.39972]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 10. 10.] 
cards in discard: [ 0. 29.  1. 29. 11. 15. 15. 15.  0. 10.  0.  3. 11. 29.  1. 29. 11.  0.
 15. 15. 11.  1. 29. 11. 10.  3.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1  1  1  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 26. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0 0] -> size -> 5 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[  -5    0    0   90    0    0   20    0    0    0    0 -120    0    0
   27    0] 
sum of rewards: 12 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 58.83898162841797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[42.380997]
 [38.90536 ]
 [48.399715]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15. 10. 10.] 
cards in discard: [ 0. 29.  1. 29. 11. 15. 15. 15.  0. 10.  0.  3. 11. 29.  1. 29. 11.  0.
 15. 15. 11.  1. 29. 11. 10.  3.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1  1  1  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 23. 30. 26. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0 0] -> size -> 5 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 48.39971923828125






Player: 1 
cards in hand: [0. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0 0] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 26. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [11. 10. 11. 10. 29.] 
adversary cards in discard: [ 0. 29.  1. 29. 11. 15. 15. 15.  0. 10.  0.  3. 11. 29.  1. 29. 11.  0.
 15. 15. 11.  1. 29. 11. 10.  3.  1. 11.  3. 15. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1  1  1  1] -> size -> 47 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 26. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [11. 10. 11. 10. 29.] 
adversary cards in discard: [ 0. 29.  1. 29. 11. 15. 15. 15.  0. 10.  0.  3. 11. 29.  1. 29. 11.  0.
 15. 15. 11.  1. 29. 11. 10.  3.  1. 11.  3. 15. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1  1  1  1] -> size -> 47 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 23. 30. 26. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [11. 10. 11. 10. 29.] 
adversary cards in discard: [ 0. 29.  1. 29. 11. 15. 15. 15.  0. 10.  0.  3. 11. 29.  1. 29. 11.  0.
 15. 15. 11.  1. 29. 11. 10.  3.  1. 11.  3. 15. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1  1  1  1] -> size -> 47 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0 3] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 25. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [11. 10. 11. 10. 29.] 
adversary cards in discard: [ 0. 29.  1. 29. 11. 15. 15. 15.  0. 10.  0.  3. 11. 29.  1. 29. 11.  0.
 15. 15. 11.  1. 29. 11. 10.  3.  1. 11.  3. 15. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1  1  1  1] -> size -> 47 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [11. 10. 11. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11. 10. 29.] 
expected returns: [[59.595516]
 [59.78362 ]
 [55.066772]
 [59.78362 ]
 [55.066772]
 [63.43463 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11. 10. 29.] 
cards in discard: [ 0. 29.  1. 29. 11. 15. 15. 15.  0. 10.  0.  3. 11. 29.  1. 29. 11.  0.
 15. 15. 11.  1. 29. 11. 10.  3.  1. 11.  3. 15. 10. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1  1  1  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 25. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [0. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 3] -> size -> 4 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 48.39971923828125



action possibilites: [-1. 11. 10. 10.] 
expected returns: [[56.244698]
 [56.42501 ]
 [51.70326 ]
 [51.70326 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 10.] 
cards in discard: [ 0. 29.  1. 29. 11. 15. 15. 15.  0. 10.  0.  3. 11. 29.  1. 29. 11.  0.
 15. 15. 11.  1. 29. 11. 10.  3.  1. 11.  3. 15. 10. 10. 10. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1  1  1  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 23. 30. 25. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [0. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 3] -> size -> 4 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 58.613182067871094



action possibilites: [-1] 
expected returns: [[53.468407]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.] 
cards in discard: [ 0. 29.  1. 29. 11. 15. 15. 15.  0. 10.  0.  3. 11. 29.  1. 29. 11.  0.
 15. 15. 11.  1. 29. 11. 10.  3.  1. 11.  3. 15. 10. 10. 10. 11.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1  1  1  1  1] -> size -> 48 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 22. 30. 25. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [0. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 3] -> size -> 4 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[  -5    0    0   60    0    0   40    0    0    0    0 -130    0    0
   27    0] 
sum of rewards: -8 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 55.24977111816406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[47.17829 ]
 [43.759094]
 [53.468403]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.] 
cards in discard: [ 0. 29.  1. 29. 11. 15. 15. 15.  0. 10.  0.  3. 11. 29.  1. 29. 11.  0.
 15. 15. 11.  1. 29. 11. 10.  3.  1. 11.  3. 15. 10. 10. 10. 11.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1  1  1  1  1] -> size -> 48 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 22. 30. 25. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [0. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 3] -> size -> 4 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 53.468406677246094






Player: 1 
cards in hand: [0. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 3] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 25. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [ 0. 10.  1. 15.  0.] 
adversary cards in discard: [ 0. 29.  1. 29. 11. 15. 15. 15.  0. 10.  0.  3. 11. 29.  1. 29. 11.  0.
 15. 15. 11.  1. 29. 11. 10.  3.  1. 11.  3. 15. 10. 10. 10. 11.  1. 29.
 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1  1  1  1  1] -> size -> 48 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 3] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 22. 30. 25. 30.  8. 10.  9.  0.  3. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [ 0. 10.  1. 15.  0.] 
adversary cards in discard: [ 0. 29.  1. 29. 11. 15. 15. 15.  0. 10.  0.  3. 11. 29.  1. 29. 11.  0.
 15. 15. 11.  1. 29. 11. 10.  3.  1. 11.  3. 15. 10. 10. 10. 11.  1. 29.
 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1  1  1  1  1] -> size -> 48 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 8.] 
cards in discard: [8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 3 8] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 25. 30.  8. 10.  9.  0.  2. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [ 0. 10.  1. 15.  0.] 
adversary cards in discard: [ 0. 29.  1. 29. 11. 15. 15. 15.  0. 10.  0.  3. 11. 29.  1. 29. 11.  0.
 15. 15. 11.  1. 29. 11. 10.  3.  1. 11.  3. 15. 10. 10. 10. 11.  1. 29.
 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1  1  1  1  1] -> size -> 48 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  1. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
expected returns: [[95.69731]
 [90.19326]
 [93.96362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  1. 15.  0.] 
cards in discard: [ 0. 29.  1. 29. 11. 15. 15. 15.  0. 10.  0.  3. 11. 29.  1. 29. 11.  0.
 15. 15. 11.  1. 29. 11. 10.  3.  1. 11.  3. 15. 10. 10. 10. 11.  1. 29.
 11. 10. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1  1  1  1  1] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 25. 30.  8. 10.  9.  0.  2. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [8. 3. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 3 8] -> size -> 5 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 53.468406677246094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
expected returns: [[ 88.77366 ]
 [ 94.50183 ]
 [ 92.40915 ]
 [ 84.74473 ]
 [ 93.009384]
 [ 92.28595 ]
 [100.29204 ]
 [ 88.23545 ]
 [ 93.963615]
 [ 95.69731 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  1. 15.  0.] 
cards in discard: [ 0. 29.  1. 29. 11. 15. 15. 15.  0. 10.  0.  3. 11. 29.  1. 29. 11.  0.
 15. 15. 11.  1. 29. 11. 10.  3.  1. 11.  3. 15. 10. 10. 10. 11.  1. 29.
 11. 10. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1  1  1  1  1] -> size -> 48 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 22. 30. 25. 30.  8. 10.  9.  0.  2. 10.  3. 10. 10.  0. 10.  2.] 
adversary cards in hand: [8. 3. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 3 8] -> size -> 5 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 95.69731140136719



buy possibilites: [-1] 
expected returns: [[70.41525]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  1. 15.  0.] 
cards in discard: [ 0. 29.  1. 29. 11. 15. 15. 15.  0. 10.  0.  3. 11. 29.  1. 29. 11.  0.
 15. 15. 11.  1. 29. 11. 10.  3.  1. 11.  3. 15. 10. 10. 10. 11.  1. 29.
 11. 10. 10. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1  1  1  1  1
 29] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 25. 30.  8. 10.  9.  0.  2. 10.  2. 10. 10.  0. 10.  2.] 
adversary cards in hand: [8. 3. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 3 8] -> size -> 5 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[  -5    0    0   60    0    0    0    0    0    0    0 -140    0    0
  128    0] 
sum of rewards: 43 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 100.29203033447266






Player: 1 
cards in hand: [8. 3. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 3 8] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 25. 30.  8. 10.  9.  0.  2. 10.  2. 10. 10.  0. 10.  2.] 
adversary cards in hand: [ 1. 11. 15. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1  1  1  1  1
 29] -> size -> 49 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0 8] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 25. 30.  8. 10.  9.  0.  2. 10.  2. 10. 10.  0. 10.  2.] 
adversary cards in hand: [ 1. 11. 15. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1  1  1  1  1
 29] -> size -> 49 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0 8] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 22. 30. 25. 30.  8. 10.  9.  0.  2. 10.  2. 10. 10.  0. 10.  2.] 
adversary cards in hand: [ 1. 11. 15. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1  1  1  1  1
 29] -> size -> 49 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 1. 11. 15. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 10.] 
expected returns: [[199.46947]
 [199.70361]
 [197.6196 ]
 [193.6035 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11. 15. 10.  0.] 
cards in discard: [] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1  1  1  1  1
 29] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 25. 30.  8. 10.  9.  0.  2. 10.  2. 10. 10.  0. 10.  2.] 
adversary cards in hand: [0. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8] -> size -> 4 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 70.41525268554688



action possibilites: [-1] 
expected returns: [[208.57346]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15. 10.  0.] 
cards in discard: [1.] 
cards in deck: 44 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1  1  1  1  1
 29  1] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 21. 30. 25. 30.  8. 10.  9.  0.  2. 10.  2. 10. 10.  0. 10.  2.] 
adversary cards in hand: [0. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8] -> size -> 4 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[  -5    0    0   90    0    0   20    0    0    0    0 -150    0    0
   27    0] 
sum of rewards: -18 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 196.495849609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[201.22148]
 [207.68723]
 [205.32646]
 [196.66988]
 [205.18623]
 [209.04613]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15. 10.  0.] 
cards in discard: [1.] 
cards in deck: 44 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1  1  1  1  1
 29  1] -> size -> 50 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 21. 30. 25. 30.  8. 10.  9.  0.  2. 10.  2. 10. 10.  0. 10.  2.] 
adversary cards in hand: [0. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8] -> size -> 4 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 208.57345581054688






Player: 1 
cards in hand: [0. 8. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 8] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 21. 30. 25. 30.  8. 10.  9.  0.  2. 10.  2. 10. 10.  0. 10.  2.] 
adversary cards in hand: [11. 29.  3. 10. 15.] 
adversary cards in discard: [ 1. 11.  1. 15. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1  1  1  1  1
 29  1] -> size -> 50 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 8] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 21. 30. 25. 30.  8. 10.  9.  0.  2. 10.  2. 10. 10.  0. 10.  2.] 
adversary cards in hand: [11. 29.  3. 10. 15.] 
adversary cards in discard: [ 1. 11.  1. 15. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1  1  1  1  1
 29  1] -> size -> 50 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 8.] 
cards in discard: [8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 8 8] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 21. 30. 25. 30.  8. 10.  9.  0.  1. 10.  2. 10. 10.  0. 10.  2.] 
adversary cards in hand: [11. 29.  3. 10. 15.] 
adversary cards in discard: [ 1. 11.  1. 15. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1  1  1  1  1
 29  1] -> size -> 50 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [11. 29.  3. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10. 15.] 
expected returns: [[189.22234]
 [189.45651]
 [194.12297]
 [183.33754]
 [187.36613]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  3. 10. 15.] 
cards in discard: [ 1. 11.  1. 15. 10.  0.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1  1  1  1  1
 29  1] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 21. 30. 25. 30.  8. 10.  9.  0.  1. 10.  2. 10. 10.  0. 10.  2.] 
adversary cards in hand: [0. 8. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8 8] -> size -> 5 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 209.04617309570312



action possibilites: [-1. 15. 10.] 
expected returns: [[180.84297]
 [178.81093]
 [174.40096]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 10.] 
cards in discard: [ 1. 11.  1. 15. 10.  0. 11. 10.] 
cards in deck: 38 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1  1  1  1  1
 29  1] -> size -> 50 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 21. 30. 25. 30.  8. 10.  9.  0.  1. 10.  2. 10. 10.  0. 10.  2.] 
adversary cards in hand: [0. 8. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8 8] -> size -> 5 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 187.93887329101562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[172.73267]
 [168.01686]
 [180.83548]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15. 10.] 
cards in discard: [ 1. 11.  1. 15. 10.  0. 11. 10.] 
cards in deck: 38 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1  1  1  1  1
 29  1] -> size -> 50 
action values: 1 
buys: 1 
player value: 1 
card supply: [19. 21. 30. 25. 30.  8. 10.  9.  0.  1. 10.  2. 10. 10.  0. 10.  2.] 
adversary cards in hand: [0. 8. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8 8] -> size -> 5 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 180.84295654296875






Player: 1 
cards in hand: [0. 8. 8. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 8 8] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 21. 30. 25. 30.  8. 10.  9.  0.  1. 10.  2. 10. 10.  0. 10.  2.] 
adversary cards in hand: [10. 10. 29. 29. 11.] 
adversary cards in discard: [ 1. 11.  1. 15. 10.  0. 11. 10. 29.  3. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1  1  1  1  1
 29  1] -> size -> 50 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 8 8] -> size -> 5 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 21. 30. 25. 30.  8. 10.  9.  0.  1. 10.  2. 10. 10.  0. 10.  2.] 
adversary cards in hand: [10. 10. 29. 29. 11.] 
adversary cards in discard: [ 1. 11.  1. 15. 10.  0. 11. 10. 29.  3. 15. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1  1  1  1  1
 29  1] -> size -> 50 
adversary victory points: 3
player victory points: 0 


Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 9 
Chapel: 0 
Witch: 0 
Poacher: 7 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [10. 10. 29. 29. 11.] 
cards in discard: [ 1. 11.  1. 15. 10.  0. 11. 10. 29.  3. 15. 10.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 10 11 10 11 10 10 29 10 10 11 10
 29 10 29 10 15 11 11 15 15 29 11 15 15 15 15 15 11 11  1  1  1  1  1  1
 29  1] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 21. 30. 25. 30.  8. 10.  9.  0.  0. 10.  2. 10. 10.  0. 10.  2.] 
adversary cards in hand: [0. 8. 8. 0. 8.] 
adversary cards in discard: [8.] 
adversary owned cards: [8 0 0 8 8 8] -> size -> 6 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0      90       0       0       0       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000085 

action type: buy - action -1.0
Learning step: 119996.1640625
desired expected reward: 120177.0



