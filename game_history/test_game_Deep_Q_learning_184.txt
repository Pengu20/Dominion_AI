 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[33.835712]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -150        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000155 

action type: buy - action -1.0
Learning step: -120000.125
desired expected reward: -120151.8359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 28.629333  ]
 [ 46.8956    ]
 [ 39.294945  ]
 [-48.981014  ]
 [ 48.581932  ]
 [ 46.822315  ]
 [ 35.566345  ]
 [ 55.483643  ]
 [  0.36394358]
 [ 41.446693  ]
 [ 34.28675   ]
 [ 33.129925  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 33.33540344238281



buy possibilites: [-1] 
expected returns: [[39.719086]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10.  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 55.48365020751953






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.  0.  3.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.  0.  3.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.  0.  3.  0.  3.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[22.118]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 39.719085693359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 16.473545]
 [ 34.373657]
 [ 28.509258]
 [-56.979145]
 [ 36.54419 ]
 [ 23.513119]
 [ 31.665554]
 [ 20.985544]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 21.93528175354004



buy possibilites: [-1] 
expected returns: [[30.862175]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 36.54419708251953






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [3. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 10  8] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 10  8] -> size -> 9 
action values: 0 
buys: 1 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 3. 29.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[29.767159]
 [52.684807]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 10.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 30.86217498779297



action possibilites: [-1.] 
expected returns: [[18.030218]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 10.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 51.967308044433594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 13.902077 ]
 [ 30.442623 ]
 [ 23.305536 ]
 [-49.55365  ]
 [ 33.579487 ]
 [ 31.006493 ]
 [ 19.906988 ]
 [ 39.8215   ]
 [ -7.3447046]
 [ 26.246807 ]
 [ 17.771816 ]
 [ 17.795513 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 10.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 18.03021812438965



buy possibilites: [-1] 
expected returns: [[28.49276]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 10.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 39.82150650024414






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 10.] 
cards in discard: [0. 8. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [29. 29.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0. 8. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0] -> size -> 10 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [29. 29.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0. 8. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [29. 29.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0. 8. 3. 8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0  8] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [29. 29.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[24.742434]
 [39.604565]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  0.] 
cards in discard: [29. 29.  3.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0  8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 28.492759704589844



action possibilites: [-1] 
expected returns: [[41.348095]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [29. 29.  3.  0.  0.  0.  3. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0  8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 5
Learning step: 0
desired expected reward: 41.3095588684082





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[38.55148  ]
 [55.93401  ]
 [49.21811  ]
 [-4.9652348]
 [60.0392   ]
 [58.448845 ]
 [46.80869  ]
 [64.81779  ]
 [15.707693 ]
 [53.488346 ]
 [42.996517 ]
 [42.268017 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [29. 29.  3.  0.  0.  0.  3. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0  8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 41.34809494018555



buy possibilites: [-1] 
expected returns: [[53.557922]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [29. 29.  3.  0.  0.  0.  3. 11. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  8. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0  8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 64.81780242919922






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [3. 8. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0  8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  8. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0  8] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  8. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 3.] 
cards in discard: [8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0  8  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  7. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [29.  3.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[18.248722]
 [38.838165]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  7. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  3.  0.  8.  0.] 
adversary cards in discard: [8. 3. 8. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0  8  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 53.55792236328125



action possibilites: [-1.] 
expected returns: [[39.44831]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  7. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  3.  0.  8.  0.] 
adversary cards in discard: [8. 3. 8. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0  8  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 38.380489349365234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[37.23688 ]
 [54.05304 ]
 [45.375885]
 [-7.44668 ]
 [52.642715]
 [49.465595]
 [41.853725]
 [58.56405 ]
 [15.081337]
 [45.04134 ]
 [40.45356 ]
 [39.943493]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  7. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  3.  0.  8.  0.] 
adversary cards in discard: [8. 3. 8. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0  8  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 39.44831085205078



buy possibilites: [-1] 
expected returns: [[43.556034]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  7. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  3.  0.  8.  0.] 
adversary cards in discard: [8. 3. 8. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 10  8  0  8  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 58.564048767089844






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [10.  3.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  8.  0.] 
cards in discard: [8. 3. 8. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 10  8  0  8  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  7. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  3.] 
adversary cards in discard: [29. 29.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [8. 3. 8. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 3 3 8 0 8 8] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  7. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  3.] 
adversary cards in discard: [29. 29.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [8. 3. 8. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 3 3 8 0 8 8] -> size -> 8 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  7. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  3.] 
adversary cards in discard: [29. 29.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [8. 3. 8. 0. 0. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 3 3 8 0 8 8 0] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8.  7. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  3.] 
adversary cards in discard: [29. 29.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 0. 11.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[50.326767]
 [66.39185 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  3.] 
cards in discard: [29. 29.  3.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8.  7. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 3 3 8 0 8 8 0] -> size -> 9 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 43.556034088134766



action possibilites: [-1] 
expected returns: [[78.94703]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [29. 29.  3.  0.  0.  3.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8.  7. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 3 3 8 0 8 8 0] -> size -> 9 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 66.42780303955078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[77.762566]
 [92.70443 ]
 [87.16704 ]
 [37.71814 ]
 [94.56    ]
 [83.16693 ]
 [89.72933 ]
 [79.1502  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [29. 29.  3.  0.  0.  3.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8.  7. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 3 3 8 0 8 8 0] -> size -> 9 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 78.94702911376953



buy possibilites: [-1] 
expected returns: [[54.539574]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [29. 29.  3.  0.  0.  3.  0. 10. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7.  7. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 3 3 8 0 8 8 0] -> size -> 9 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 99 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 94.55998992919922






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [0. 3. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 3. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 3 3 8 0 8 8 0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7.  7. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 11. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 8 0 8 8 0] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7.  7. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 11. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 8 0 8 8 0] -> size -> 6 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7.  7. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 11. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 8 0 8 8 0 0] -> size -> 7 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  7.  7. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 11. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [29. 11. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 29. 29.] 
expected returns: [[50.2223 ]
 [69.38877]
 [62.96084]
 [69.38877]
 [69.38877]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 29. 29.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  7.  7. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 8 0 8 8 0 0] -> size -> 7 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 54.539573669433594



action possibilites: [-1. 11. 29. 29.] 
expected returns: [[66.823524]
 [75.672844]
 [81.825226]
 [81.825226]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  7.  7. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 8 0 8 8 0 0] -> size -> 7 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 68.85906982421875



action possibilites: [-1. 11. 29.] 
expected returns: [[81.80636 ]
 [88.13717 ]
 [95.802345]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  7.  7. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 8 0 8 8 0 0] -> size -> 7 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 81.82524871826172



action possibilites: [-1. 11.] 
expected returns: [[72.20452]
 [79.93402]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 3 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  7.  7. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 8 0 8 8 0 0] -> size -> 7 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 95.8023681640625



action possibilites: [-1] 
expected returns: [[82.98327]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  7.  7. 10.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 8 0 8 8 0 0] -> size -> 7 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 80  0  0  0  0  0  0  0 27  0] 
sum of rewards: 192 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 85.40296173095703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 83.29041 ]
 [ 99.22719 ]
 [ 78.90717 ]
 [ 91.04687 ]
 [ 66.274216]
 [ 41.69739 ]
 [100.86266 ]
 [ 97.98918 ]
 [ 89.39405 ]
 [109.6874  ]
 [104.29937 ]
 [ 58.204506]
 [ 91.858696]
 [ 92.77663 ]
 [ 72.22845 ]
 [ 82.739815]
 [ 85.464096]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 7 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  7.  7. 10.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 8 0 8 8 0 0] -> size -> 7 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 82.98326873779297



buy possibilites: [-1] 
expected returns: [[104.48452]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  7.  7.  9.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 8 0 8 8 0 0] -> size -> 7 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.  90.   0.   0.  80.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 227.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 109.6874008178711






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 8.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 8 0 8 8 0 0] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  7.  7.  9.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  3. 29.] 
adversary cards in discard: [10. 25. 29. 29. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25] -> size -> 20 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  7.  7.  9.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  3. 29.] 
adversary cards in discard: [10. 25. 29. 29. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25] -> size -> 20 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  7.  7.  9.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  3. 29.] 
adversary cards in discard: [10. 25. 29. 29. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25] -> size -> 20 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 0.  0.  3.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[46.333218]
 [65.94968 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  3. 29.] 
cards in discard: [10. 25. 29. 29. 29. 11.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  7.  7.  9.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 104.4845199584961



action possibilites: [-1.] 
expected returns: [[45.149097]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [10. 25. 29. 29. 29. 11.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  7.  7.  9.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 66.04267120361328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[40.716476  ]
 [56.77432   ]
 [51.46781   ]
 [ 0.56362677]
 [60.14898   ]
 [59.68995   ]
 [47.187447  ]
 [64.95614   ]
 [18.873798  ]
 [54.185425  ]
 [44.40005   ]
 [43.91665   ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [10. 25. 29. 29. 29. 11.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  7.  7.  9.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 45.14909744262695



buy possibilites: [-1] 
expected returns: [[44.2514]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [10. 25. 29. 29. 29. 11.  0.  0.  0.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  7.  7.  9.  5. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 233 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 64.95612335205078






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [8. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  7.  7.  9.  5. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10. 11. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29] -> size -> 21 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  7.  7.  9.  5. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10. 11. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29] -> size -> 21 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  7.  7.  9.  5. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10. 11. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29] -> size -> 21 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 30. 30.  8. 10. 10.  7.  7.  9.  5. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10. 11. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29] -> size -> 21 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 0. 10. 11. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11.] 
expected returns: [[63.70392 ]
 [70.12017 ]
 [75.259514]
 [75.259514]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 11.  3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 30.  8. 10. 10.  7.  7.  9.  5. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 44.251399993896484



action possibilites: [-1] 
expected returns: [[73.784706]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  3.] 
cards in discard: [10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 30.  8. 10. 10.  7.  7.  9.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 132 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 78.59471893310547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[73.8597  ]
 [26.626625]
 [75.78773 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11.  3.] 
cards in discard: [10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 30. 30.  8. 10. 10.  7.  7.  9.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 73.78470611572266






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 30.  8. 10. 10.  7.  7.  9.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 25. 29.] 
adversary cards in discard: [10. 11.  0. 10. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10] -> size -> 22 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 30.  8. 10. 10.  7.  7.  9.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 25. 29.] 
adversary cards in discard: [10. 11.  0. 10. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10] -> size -> 22 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 30. 30. 30. 30.  8. 10. 10.  7.  7.  9.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 25. 29.] 
adversary cards in discard: [10. 11.  0. 10. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10] -> size -> 22 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 0.  0. 29. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29.] 
expected returns: [[75.361084]
 [93.68502 ]
 [98.065216]
 [93.68502 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 25. 29.] 
cards in discard: [10. 11.  0. 10. 11.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 30.  8. 10. 10.  7.  7.  9.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 75.7877197265625



action possibilites: [-1] 
expected returns: [[78.07923]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 29. 29.  0.] 
cards in discard: [10. 11.  0. 10. 11.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 30.  8.  9. 10.  7.  7.  9.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 96.48363494873047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[78.74316 ]
 [88.21601 ]
 [82.51114 ]
 [22.174772]
 [86.50861 ]
 [81.11103 ]
 [84.11125 ]
 [80.79221 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29. 29. 29.  0.] 
cards in discard: [10. 11.  0. 10. 11.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 30. 30.  8.  9. 10.  7.  7.  9.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 78.07923126220703



buy possibilites: [-1] 
expected returns: [[53.27038]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29. 29. 29.  0.] 
cards in discard: [10. 11.  0. 10. 11.  3.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8.  9. 10.  7.  7.  9.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 159 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 88.21602630615234






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8.  9. 10.  7.  7.  9.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 11. 29.] 
adversary cards in discard: [10. 11.  0. 10. 11.  3.  1. 25.  0.  0. 29. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1] -> size -> 23 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8.  9. 10.  7.  7.  9.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 11. 29.] 
adversary cards in discard: [10. 11.  0. 10. 11.  3.  1. 25.  0.  0. 29. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1] -> size -> 23 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6] -> size -> 2 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8.  9. 10.  7.  7.  9.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 11. 29.] 
adversary cards in discard: [10. 11.  0. 10. 11.  3.  1. 25.  0.  0. 29. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1] -> size -> 23 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [6. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8.  9. 10.  7.  7.  9.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 11. 29.] 
adversary cards in discard: [10. 11.  0. 10. 11.  3.  1. 25.  0.  0. 29. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1] -> size -> 23 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [ 0.  0. 29. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 29.] 
expected returns: [[48.413795]
 [60.29396 ]
 [53.75373 ]
 [60.29396 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 11. 29.] 
cards in discard: [10. 11.  0. 10. 11.  3.  1. 25.  0.  0. 29. 29. 29.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8.  9. 10.  7.  7.  9.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 53.27037811279297



action possibilites: [-1. 11. 29. 10.] 
expected returns: [[48.990005]
 [58.310394]
 [63.0643  ]
 [55.83587 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 29. 10.] 
cards in discard: [10. 11.  0. 10. 11.  3.  1. 25.  0.  0. 29. 29. 29.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 30. 30.  8.  9. 10.  7.  7.  9.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 63.380714416503906



action possibilites: [-1. 11. 10.] 
expected returns: [[58.157738]
 [64.26467 ]
 [62.458702]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 10.  3.] 
cards in discard: [10. 11.  0. 10. 11.  3.  1. 25.  0.  0. 29. 29. 29.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 30. 30.  8.  9. 10.  7.  7.  9.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 63.064308166503906



action possibilites: [-1] 
expected returns: [[65.902824]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3.] 
cards in discard: [10. 11.  0. 10. 11.  3.  1. 25.  0.  0. 29. 29. 29.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 28. 30. 30. 30.  8.  9. 10.  7.  7.  9.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0  27   0] 
sum of rewards: 202 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 65.90647888183594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[62.95955 ]
 [76.91116 ]
 [70.90185 ]
 [18.602198]
 [78.51173 ]
 [76.870514]
 [67.713196]
 [83.60855 ]
 [41.936802]
 [72.312386]
 [64.87739 ]
 [66.30399 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.] 
cards in discard: [10. 11.  0. 10. 11.  3.  1. 25.  0.  0. 29. 29. 29.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 28. 30. 30. 30.  8.  9. 10.  7.  7.  9.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1
Learning step: 0
desired expected reward: 65.90282440185547



buy possibilites: [-1] 
expected returns: [[69.22794]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.] 
cards in discard: [10. 11.  0. 10. 11.  3.  1. 25.  0.  0. 29. 29. 29.  0.  1. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 30.  8.  9. 10.  7.  7.  9.  4. 10. 10.  6. 10. 10.] 
adversary cards in hand: [6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 303 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 83.60856628417969






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 30.  8.  9. 10.  7.  7.  9.  4. 10. 10.  6. 10. 10.] 
adversary cards in hand: [29. 29. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29] -> size -> 25 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 30.  8.  9. 10.  7.  7.  9.  4. 10. 10.  6. 10. 10.] 
adversary cards in hand: [29. 29. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29] -> size -> 25 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 30. 30.  8.  9. 10.  7.  7.  9.  4. 10. 10.  6. 10. 10.] 
adversary cards in hand: [29. 29. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29] -> size -> 25 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 30. 30.  8.  9. 10.  7.  7.  9.  4. 10. 10.  6. 10. 10.] 
adversary cards in hand: [29. 29. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29] -> size -> 25 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [29. 29. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 11.] 
expected returns: [[ 99.807335]
 [114.24877 ]
 [114.24877 ]
 [107.66221 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 30. 30.  8.  9. 10.  7.  7.  9.  4. 10. 10.  6. 10. 10.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 69.22794342041016



action possibilites: [-1. 29. 11. 11.] 
expected returns: [[101.38117]
 [118.28801]
 [109.81207]
 [109.81207]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 30. 30.  8.  9. 10.  7.  7.  9.  4. 10. 10.  6. 10. 10.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 112.67525482177734



action possibilites: [-1. 11. 11. 29.] 
expected returns: [[139.88258]
 [152.01428]
 [152.01428]
 [158.13579]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0. 11. 29.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 2 
card supply: [24. 28. 30. 30. 30.  8.  9. 10.  7.  7.  9.  4. 10. 10.  6. 10. 10.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 118.28800964355469



action possibilites: [-1. 11. 11.] 
expected returns: [[135.18745]
 [142.93306]
 [142.93306]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0. 11.  3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 3 
card supply: [24. 28. 30. 30. 30.  8.  9. 10.  7.  7.  9.  4. 10. 10.  6. 10. 10.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 158.13580322265625



action possibilites: [-1] 
expected returns: [[122.59757]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  3.] 
cards in discard: [10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 28. 30. 30. 30.  8.  9. 10.  7.  7.  9.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 80  0  0  0  0  0  0  0 27  0] 
sum of rewards: 192 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 147.88706970214844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[121.02316 ]
 [135.39072 ]
 [126.35294 ]
 [ 51.938976]
 [135.39374 ]
 [133.0239  ]
 [126.80364 ]
 [138.6463  ]
 [ 96.42835 ]
 [128.05058 ]
 [118.59489 ]
 [123.2846  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  3.] 
cards in discard: [10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 28. 30. 30. 30.  8.  9. 10.  7.  7.  9.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 122.59757232666016



buy possibilites: [-1] 
expected returns: [[109.13319]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  3.] 
cards in discard: [10. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 30. 30.  8.  9. 10.  7.  7.  9.  3. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0  80   0   0   0   0   0   0   0 128   0] 
sum of rewards: 293 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 138.64633178710938






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 30. 30.  8.  9. 10.  7.  7.  9.  3. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 1.  0.  1. 10.  0.] 
adversary cards in discard: [10. 29. 29. 29. 29. 11.  3.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29] -> size -> 27 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 30. 30.  8.  9. 10.  7.  7.  9.  3. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 1.  0.  1. 10.  0.] 
adversary cards in discard: [10. 29. 29. 29. 29. 11.  3.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29] -> size -> 27 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 1.  0.  1. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[34.128376]
 [45.356823]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  1. 10.  0.] 
cards in discard: [10. 29. 29. 29. 29. 11.  3.  0. 11.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 30. 30.  8.  9. 10.  7.  7.  9.  3. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 109.13318634033203



action possibilites: [-1. 11.] 
expected returns: [[26.407211]
 [44.371635]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  1.  0. 11.] 
cards in discard: [10. 29. 29. 29. 29. 11.  3.  0. 11.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 30. 30.  8.  9. 10.  7.  7.  9.  3. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 44.16154479980469



action possibilites: [-1.] 
expected returns: [[42.01973]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 1. 0.] 
cards in discard: [10. 29. 29. 29. 29. 11.  3.  0. 11.  3. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 30. 30.  8.  9. 10.  7.  7.  9.  3. 10. 10.  4. 10. 10.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 152 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 43.54853820800781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[43.13883 ]
 [57.166428]
 [43.003666]
 [54.759552]
 [29.099037]
 [ 8.119526]
 [60.190575]
 [62.022446]
 [47.5328  ]
 [72.72636 ]
 [63.948273]
 [24.468119]
 [56.809727]
 [55.999813]
 [38.791183]
 [46.823887]
 [46.876713]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 0.] 
cards in discard: [10. 29. 29. 29. 29. 11.  3.  0. 11.  3. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 6 
card supply: [24. 28. 30. 30. 30.  8.  9. 10.  7.  7.  9.  3. 10. 10.  4. 10. 10.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 42.01972961425781



buy possibilites: [-1] 
expected returns: [[43.165733]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 0.] 
cards in discard: [10. 29. 29. 29. 29. 11.  3.  0. 11.  3. 10. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 30. 30.  8.  9. 10.  7.  7.  8.  3. 10. 10.  4. 10. 10.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.  90.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 187.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 72.72634887695312






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 30. 30.  8.  9. 10.  7.  7.  8.  3. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10. 25. 29.  0.  0.] 
adversary cards in discard: [10. 29. 29. 29. 29. 11.  3.  0. 11.  3. 10. 25. 10. 11.  1.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25] -> size -> 29 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 30. 30.  8.  9. 10.  7.  7.  8.  3. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10. 25. 29.  0.  0.] 
adversary cards in discard: [10. 29. 29. 29. 29. 11.  3.  0. 11.  3. 10. 25. 10. 11.  1.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25] -> size -> 29 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10. 25. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 29.] 
expected returns: [[ 84.17187]
 [ 89.62406]
 [103.75025]
 [ 99.94678]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25. 29.  0.  0.] 
cards in discard: [10. 29. 29. 29. 29. 11.  3.  0. 11.  3. 10. 25. 10. 11.  1.  0.  1.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 30. 30.  8.  9. 10.  7.  7.  8.  3. 10. 10.  4. 10. 10.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 43.165733337402344



action possibilites: [-1] 
expected returns: [[52.907936]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  0.  0. 10. 29.] 
cards in discard: [10. 29. 29. 29. 29. 11.  3.  0. 11.  3. 10. 25. 10. 11.  1.  0.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 30. 30.  8.  8. 10.  7.  7.  8.  3. 10. 10.  4. 10. 10.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 0 0 6] -> size -> 4 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 105.30850982666016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[53.975094 ]
 [62.86651  ]
 [11.3987465]
 [58.065678 ]
 [58.872375 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29.  0.  0. 10. 29.] 
cards in discard: [10. 29. 29. 29. 29. 11.  3.  0. 11.  3. 10. 25. 10. 11.  1.  0.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 30. 30.  8.  8. 10.  7.  7.  8.  3. 10. 10.  4. 10. 10.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 0 0 6] -> size -> 4 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 52.907936096191406



buy possibilites: [-1] 
expected returns: [[55.818207]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29.  0.  0. 10. 29.] 
cards in discard: [10. 29. 29. 29. 29. 11.  3.  0. 11.  3. 10. 25. 10. 11.  1.  0.  1.  0.
  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  8. 10.  7.  7.  8.  3. 10. 10.  4. 10. 10.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 0 0 6] -> size -> 4 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 151 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 62.86652374267578






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 6] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  8. 10.  7.  7.  8.  3. 10. 10.  4. 10. 10.] 
adversary cards in hand: [29.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3] -> size -> 30 
adversary victory points: 4
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 6] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  8. 10.  7.  7.  8.  3. 10. 10.  4. 10. 10.] 
adversary cards in hand: [29.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3] -> size -> 30 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 6] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 28. 30. 29. 30.  8.  8. 10.  7.  7.  8.  3. 10. 10.  4. 10. 10.] 
adversary cards in hand: [29.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3] -> size -> 30 
adversary victory points: 4
player victory points: -1 





Player: 0 
cards in hand: [29.  3. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[107.30079]
 [122.21177]
 [122.21177]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  8. 10.  7.  7.  8.  3. 10. 10.  4. 10. 10.] 
adversary cards in hand: [8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6] -> size -> 3 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 55.818206787109375



action possibilites: [-1. 29.] 
expected returns: [[106.186615]
 [123.27308 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 29. 30.  8.  8. 10.  7.  7.  8.  3. 10. 10.  4. 10. 10.] 
adversary cards in hand: [8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6] -> size -> 3 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 119.86617279052734



action possibilites: [-1. 29.] 
expected returns: [[113.51372]
 [130.55545]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 2 
card supply: [24. 28. 30. 29. 30.  8.  8. 10.  7.  7.  8.  3. 10. 10.  4. 10. 10.] 
adversary cards in hand: [8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6] -> size -> 3 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 123.2730941772461



action possibilites: [-1. 25.] 
expected returns: [[110.37057 ]
 [126.341194]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 3 
card supply: [24. 28. 30. 29. 30.  8.  8. 10.  7.  7.  8.  3. 10. 10.  4. 10. 10.] 
adversary cards in hand: [8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 6] -> size -> 3 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 130.55548095703125



action possibilites: [-1] 
expected returns: [[89.23905]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 11.  3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 28. 30. 29. 30.  8.  7. 10.  7.  7.  8.  3. 10. 10.  4. 10. 10.] 
adversary cards in hand: [8. 0. 6.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 0 6 6] -> size -> 4 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 126.34119415283203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 89.24323 ]
 [104.299095]
 [ 84.13905 ]
 [ 95.01908 ]
 [ 75.09842 ]
 [ 52.00303 ]
 [104.548775]
 [100.96    ]
 [ 95.386765]
 [112.75727 ]
 [109.27056 ]
 [ 67.045425]
 [ 96.78676 ]
 [ 96.68579 ]
 [ 78.7037  ]
 [ 89.69518 ]
 [ 90.79236 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 11.  3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 6 
card supply: [24. 28. 30. 29. 30.  8.  7. 10.  7.  7.  8.  3. 10. 10.  4. 10. 10.] 
adversary cards in hand: [8. 0. 6.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 0 6 6] -> size -> 4 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 89.23905181884766



buy possibilites: [-1] 
expected returns: [[77.610245]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 11.  3.] 
cards in discard: [25.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 29. 30.  8.  7. 10.  7.  7.  7.  3. 10. 10.  4. 10. 10.] 
adversary cards in hand: [8. 0. 6.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 0 6 6] -> size -> 4 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5.    0.    0.  150.    0.    0.   80.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 287.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 112.7572250366211






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [8. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6.] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 6 6] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  7. 10.  7.  7.  7.  3. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10. 29.  1.  0.  1.] 
adversary cards in discard: [25. 29. 29. 29. 25.  3.  0.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25] -> size -> 31 
adversary victory points: 4
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 6] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  7. 10.  7.  7.  7.  3. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10. 29.  1.  0.  1.] 
adversary cards in discard: [25. 29. 29. 29. 25.  3.  0.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25] -> size -> 31 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 6] -> size -> 3 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  7. 10.  7.  7.  7.  3. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10. 29.  1.  0.  1.] 
adversary cards in discard: [25. 29. 29. 29. 25.  3.  0.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25] -> size -> 31 
adversary victory points: 4
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [6. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 6 0] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 29. 30.  8.  7. 10.  7.  7.  7.  3. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10. 29.  1.  0.  1.] 
adversary cards in discard: [25. 29. 29. 29. 25.  3.  0.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25] -> size -> 31 
adversary victory points: 4
player victory points: -2 





Player: 0 
cards in hand: [10. 29.  1.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[46.20081 ]
 [54.282578]
 [62.21749 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  1.  0.  1.] 
cards in discard: [25. 29. 29. 29. 25.  3.  0.  0.  0. 11.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 29. 30.  8.  7. 10.  7.  7.  7.  3. 10. 10.  4. 10. 10.] 
adversary cards in hand: [8. 6. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 0] -> size -> 4 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 77.61024475097656



action possibilites: [-1. 10.] 
expected returns: [[17.462162]
 [30.026192]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  0.  1.  3.] 
cards in discard: [25. 29. 29. 29. 25.  3.  0.  0.  0. 11.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 29. 30.  8.  7. 10.  7.  7.  7.  3. 10. 10.  4. 10. 10.] 
adversary cards in hand: [8. 6. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 0] -> size -> 4 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 62.90174102783203



action possibilites: [-1. 29.] 
expected returns: [[25.880386]
 [38.28129 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  1.  3. 29.] 
cards in discard: [25. 29. 29. 29. 25.  3.  0.  0.  0. 11.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25] -> size -> 31 
action values: 2 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 29. 30.  8.  7. 10.  7.  7.  7.  3. 10. 10.  4. 10. 10.] 
adversary cards in hand: [8. 6. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 0] -> size -> 4 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 30.026187896728516



action possibilites: [-1. 10.] 
expected returns: [[49.524574]
 [59.302017]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  1.  3. 10.] 
cards in discard: [25. 29. 29. 29. 25.  3.  0.  0.  0. 11.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25] -> size -> 31 
action values: 2 
buys: 0 
player value: 2 
card supply: [23. 28. 30. 29. 30.  8.  7. 10.  7.  7.  7.  3. 10. 10.  4. 10. 10.] 
adversary cards in hand: [8. 6. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 0] -> size -> 4 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 38.28131103515625



action possibilites: [-1. 10.] 
expected returns: [[64.03804]
 [72.49435]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  1.  3. 10.] 
cards in discard: [25. 29. 29. 29. 25.  3.  0.  0.  0. 11.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 10. 29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25] -> size -> 31 
action values: 3 
buys: 0 
player value: 2 
card supply: [23. 28. 30. 29. 30.  8.  7. 10.  7.  7.  7.  3. 10. 10.  4. 10. 10.] 
adversary cards in hand: [8. 6. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 0] -> size -> 4 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 59.30200958251953



action possibilites: [-1.] 
expected returns: [[59.937973]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 1. 3. 0.] 
cards in discard: [25. 29. 29. 29. 25.  3.  0.  0.  0. 11.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 10. 29. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25] -> size -> 31 
action values: 4 
buys: 0 
player value: 2 
card supply: [23. 28. 30. 29. 30.  8.  7. 10.  7.  7.  7.  3. 10. 10.  4. 10. 10.] 
adversary cards in hand: [8. 6. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 0] -> size -> 4 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 72.49433898925781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[53.03569 ]
 [68.46271 ]
 [51.253704]
 [62.37722 ]
 [39.370987]
 [70.84053 ]
 [14.656792]
 [74.21246 ]
 [70.37614 ]
 [60.463737]
 [84.150505]
 [79.83763 ]
 [33.869507]
 [69.62844 ]
 [66.83246 ]
 [49.750916]
 [58.236397]
 [57.701565]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 3. 0.] 
cards in discard: [25. 29. 29. 29. 25.  3.  0.  0.  0. 11.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 10. 29. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25] -> size -> 31 
action values: 0 
buys: 1 
player value: 8 
card supply: [23. 28. 30. 29. 30.  8.  7. 10.  7.  7.  7.  3. 10. 10.  4. 10. 10.] 
adversary cards in hand: [8. 6. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 0] -> size -> 4 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 59.93797302246094



buy possibilites: [-1] 
expected returns: [[101.84547]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 3. 0.] 
cards in discard: [25. 29. 29. 29. 25.  3.  0.  0.  0. 11.  3. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 10. 29. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25] -> size -> 32 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 28. 30. 29. 30.  8.  7. 10.  7.  7.  6.  3. 10. 10.  4. 10. 10.] 
adversary cards in hand: [8. 6. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 0] -> size -> 4 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5.    0.    0.  180.    0.    0.  100.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 337.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 84.15052032470703






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [8. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0. 6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 29. 30.  8.  7. 10.  7.  7.  6.  3. 10. 10.  4. 10. 10.] 
adversary cards in hand: [11. 10. 29.  0. 29.] 
adversary cards in discard: [25. 29. 29. 29. 25.  3.  0.  0.  0. 11.  3. 25. 29. 10. 29. 10. 10.  1.
  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25] -> size -> 32 
adversary victory points: 4
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 29. 30.  8.  7. 10.  7.  7.  6.  3. 10. 10.  4. 10. 10.] 
adversary cards in hand: [11. 10. 29.  0. 29.] 
adversary cards in discard: [25. 29. 29. 29. 25.  3.  0.  0.  0. 11.  3. 25. 29. 10. 29. 10. 10.  1.
  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25] -> size -> 32 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6] -> size -> 2 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 28. 30. 29. 30.  8.  7. 10.  7.  7.  6.  3. 10. 10.  4. 10. 10.] 
adversary cards in hand: [11. 10. 29.  0. 29.] 
adversary cards in discard: [25. 29. 29. 29. 25.  3.  0.  0.  0. 11.  3. 25. 29. 10. 29. 10. 10.  1.
  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25] -> size -> 32 
adversary victory points: 4
player victory points: -1 





Player: 0 
cards in hand: [11. 10. 29.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29. 29.] 
expected returns: [[84.08717 ]
 [92.481575]
 [88.21666 ]
 [98.76035 ]
 [98.76035 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 29.  0. 29.] 
cards in discard: [25. 29. 29. 29. 25.  3.  0.  0.  0. 11.  3. 25. 29. 10. 29. 10. 10.  1.
  0.  1.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 29. 30.  8.  7. 10.  7.  7.  6.  3. 10. 10.  4. 10. 10.] 
adversary cards in hand: [6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 101.84546661376953



action possibilites: [-1. 11. 10. 29. 11.] 
expected returns: [[122.098145]
 [131.20914 ]
 [126.68928 ]
 [137.20049 ]
 [131.20914 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0. 29. 11.] 
cards in discard: [25. 29. 29. 29. 25.  3.  0.  0.  0. 11.  3. 25. 29. 10. 29. 10. 10.  1.
  0.  1.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 29. 30.  8.  7. 10.  7.  7.  6.  3. 10. 10.  4. 10. 10.] 
adversary cards in hand: [6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 99.1301498413086



action possibilites: [-1. 11. 10. 11. 10.] 
expected returns: [[118.27223 ]
 [126.859474]
 [122.81902 ]
 [126.859474]
 [122.81902 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0. 11. 10.] 
cards in discard: [25. 29. 29. 29. 25.  3.  0.  0.  0. 11.  3. 25. 29. 10. 29. 10. 10.  1.
  0.  1.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 2 
card supply: [23. 28. 30. 29. 30.  8.  7. 10.  7.  7.  6.  3. 10. 10.  4. 10. 10.] 
adversary cards in hand: [6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 137.2004852294922



action possibilites: [-1] 
expected returns: [[125.23148]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11. 10.] 
cards in discard: [25. 29. 29. 29. 25.  3.  0.  0.  0. 11.  3. 25. 29. 10. 29. 10. 10.  1.
  0.  1.  3.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 28. 30. 29. 30.  8.  7. 10.  7.  7.  6.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  60   0   0   0   0   0   0   0  27   0] 
sum of rewards: 232 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 128.47154235839844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[119.36618 ]
 [132.86154 ]
 [126.9291  ]
 [ 84.28227 ]
 [131.91576 ]
 [123.743935]
 [127.48101 ]
 [125.64811 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11. 10.] 
cards in discard: [25. 29. 29. 29. 25.  3.  0.  0.  0. 11.  3. 25. 29. 10. 29. 10. 10.  1.
  0.  1.  3.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 28. 30. 29. 30.  8.  7. 10.  7.  7.  6.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: take_action - action -1
Learning step: 0
desired expected reward: 125.23148345947266



buy possibilites: [-1] 
expected returns: [[124.21606]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11. 10.] 
cards in discard: [25. 29. 29. 29. 25.  3.  0.  0.  0. 11.  3. 25. 29. 10. 29. 10. 10.  1.
  0.  1.  3.  0. 10.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 29. 30.  8.  7. 10.  7.  7.  6.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  60   0   0   0   0   0   0   0  54   0] 
sum of rewards: 259 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 132.86155700683594






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 29. 30.  8.  7. 10.  7.  7.  6.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [25.  3. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1] -> size -> 34 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6] -> size -> 2 
action values: 1 
buys: 1 
player value: 0 
card supply: [23. 27. 30. 29. 30.  8.  7. 10.  7.  7.  6.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [25.  3. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1] -> size -> 34 
adversary victory points: 4
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [25.  3. 25.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[ 82.60068]
 [103.37055]
 [103.37055]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3. 25.  3.  0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 29. 30.  8.  7. 10.  7.  7.  6.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 124.21605682373047



action possibilites: [-1] 
expected returns: [[93.033104]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  3.  0. 25.  3.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 29. 30.  8.  6. 10.  7.  7.  6.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [8. 6.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 6 6] -> size -> 3 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 101.987548828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[91.33439 ]
 [44.148006]
 [93.367195]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25.  3.  0. 25.  3.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 27. 30. 29. 30.  8.  6. 10.  7.  7.  6.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [8. 6.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 6 6] -> size -> 3 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 93.0331039428711






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6.] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 29. 30.  8.  6. 10.  7.  7.  6.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 1.  0. 10. 29.  0.] 
adversary cards in discard: [25.  3. 25.  3.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1] -> size -> 34 
adversary victory points: 4
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 29. 30.  8.  6. 10.  7.  7.  6.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 1.  0. 10. 29.  0.] 
adversary cards in discard: [25.  3. 25.  3.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1] -> size -> 34 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6] -> size -> 2 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 27. 30. 29. 30.  8.  6. 10.  7.  7.  6.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 1.  0. 10. 29.  0.] 
adversary cards in discard: [25.  3. 25.  3.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1] -> size -> 34 
adversary victory points: 4
player victory points: -1 





Player: 0 
cards in hand: [ 1.  0. 10. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[66.71771]
 [73.54621]
 [84.25843]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 10. 29.  0.] 
cards in discard: [25.  3. 25.  3.  0. 25.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 29. 30.  8.  6. 10.  7.  7.  6.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 93.36722564697266



action possibilites: [-1. 10. 10.] 
expected returns: [[91.03915]
 [95.14729]
 [95.14729]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 10.  0. 10.] 
cards in discard: [25.  3. 25.  3.  0. 25.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 29. 30.  8.  6. 10.  7.  7.  6.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 83.8327865600586



action possibilites: [-1. 10. 29.] 
expected returns: [[83.69894 ]
 [89.51607 ]
 [99.526505]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0. 10. 29.] 
cards in discard: [25.  3. 25.  3.  0. 25.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1] -> size -> 34 
action values: 2 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 29. 30.  8.  6. 10.  7.  7.  6.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 95.1473159790039



action possibilites: [-1. 10. 29.] 
expected returns: [[ 91.983406]
 [ 97.86737 ]
 [107.88397 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0. 10. 29.] 
cards in discard: [25.  3. 25.  3.  0. 25.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1] -> size -> 34 
action values: 2 
buys: 0 
player value: 2 
card supply: [23. 27. 30. 29. 30.  8.  6. 10.  7.  7.  6.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 99.52650451660156



action possibilites: [-1. 10. 10.] 
expected returns: [[ 97.638596]
 [103.42058 ]
 [103.42058 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0. 10. 10.] 
cards in discard: [25.  3. 25.  3.  0. 25.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 10. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1] -> size -> 34 
action values: 2 
buys: 0 
player value: 3 
card supply: [23. 27. 30. 29. 30.  8.  6. 10.  7.  7.  6.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 107.88397216796875



action possibilites: [-1. 10. 10.] 
expected returns: [[102.773094]
 [108.042534]
 [108.042534]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0. 10. 10.] 
cards in discard: [25.  3. 25.  3.  0. 25.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 10. 29. 29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1] -> size -> 34 
action values: 3 
buys: 0 
player value: 3 
card supply: [23. 27. 30. 29. 30.  8.  6. 10.  7.  7.  6.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 103.42058563232422



action possibilites: [-1. 10.] 
expected returns: [[114.08105]
 [119.68432]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0. 10.  0.] 
cards in discard: [25.  3. 25.  3.  0. 25.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 10. 29. 29. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1] -> size -> 34 
action values: 4 
buys: 0 
player value: 3 
card supply: [23. 27. 30. 29. 30.  8.  6. 10.  7.  7.  6.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0 120   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 108.04253387451172



action possibilites: [-1. 10.] 
expected returns: [[115.07555]
 [120.90269]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0.  0. 10.] 
cards in discard: [25.  3. 25.  3.  0. 25.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 10. 29. 29. 10. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1] -> size -> 34 
action values: 5 
buys: 0 
player value: 3 
card supply: [23. 27. 30. 29. 30.  8.  6. 10.  7.  7.  6.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0 140   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 119.68431854248047



action possibilites: [-1.] 
expected returns: [[126.05294]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 1.] 
cards in discard: [25.  3. 25.  3.  0. 25.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 10. 29. 29. 10. 10. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1] -> size -> 34 
action values: 6 
buys: 0 
player value: 3 
card supply: [23. 27. 30. 29. 30.  8.  6. 10.  7.  7.  6.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0 160   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 120.90265655517578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[122.86198 ]
 [137.14648 ]
 [120.9241  ]
 [132.25204 ]
 [108.173584]
 [136.02017 ]
 [ 85.61134 ]
 [140.37631 ]
 [138.8636  ]
 [127.86161 ]
 [149.08356 ]
 [143.93251 ]
 [102.31419 ]
 [135.19316 ]
 [133.773   ]
 [116.9627  ]
 [124.83199 ]
 [127.92704 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 1.] 
cards in discard: [25.  3. 25.  3.  0. 25.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 10. 29. 29. 10. 10. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 10 
card supply: [23. 27. 30. 29. 30.  8.  6. 10.  7.  7.  6.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0 160   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 126.05294036865234



buy possibilites: [-1] 
expected returns: [[93.01981]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 1.] 
cards in discard: [25.  3. 25.  3.  0. 25.  3. 25.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 10. 29. 29. 10. 10. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25] -> size -> 35 
action values: 0 
buys: 0 
player value: 5 
card supply: [23. 27. 30. 29. 30.  8.  6. 10.  7.  7.  5.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5.    0.    0.  150.    0.    0.  160.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 367.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 149.0835723876953






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 29. 30.  8.  6. 10.  7.  7.  5.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [29. 29.  1. 29.  3.] 
adversary cards in discard: [25.  3. 25.  3.  0. 25.  3. 25. 29. 10. 29. 29. 10. 10. 10. 10.  1.  0.
  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25] -> size -> 35 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6] -> size -> 2 
action values: 1 
buys: 1 
player value: 0 
card supply: [23. 27. 30. 29. 30.  8.  6. 10.  7.  7.  5.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [29. 29.  1. 29.  3.] 
adversary cards in discard: [25.  3. 25.  3.  0. 25.  3. 25. 29. 10. 29. 29. 10. 10. 10. 10.  1.  0.
  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25] -> size -> 35 
adversary victory points: 4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 29. 30.  8.  6. 10.  7.  7.  5.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [29. 29.  1. 29.  3.] 
adversary cards in discard: [25.  3. 25.  3.  0. 25.  3. 25. 29. 10. 29. 29. 10. 10. 10. 10.  1.  0.
  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25] -> size -> 35 
adversary victory points: 4
player victory points: -1 





Player: 0 
cards in hand: [29. 29.  1. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[103.76557]
 [117.63272]
 [117.63272]
 [117.63272]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  1. 29.  3.] 
cards in discard: [25.  3. 25.  3.  0. 25.  3. 25. 29. 10. 29. 29. 10. 10. 10. 10.  1.  0.
  0.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 29. 30.  8.  6. 10.  7.  7.  5.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 93.01981353759766



action possibilites: [-1. 29. 29.] 
expected returns: [[123.537895]
 [143.12067 ]
 [143.12067 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1. 29.  3.  0.] 
cards in discard: [25.  3. 25.  3.  0. 25.  3. 25. 29. 10. 29. 29. 10. 10. 10. 10.  1.  0.
  0.  0.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 29. 30.  8.  6. 10.  7.  7.  5.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 117.63272857666016



action possibilites: [-1. 29.] 
expected returns: [[140.18802]
 [157.5798 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  3.  0.  0.] 
cards in discard: [25.  3. 25.  3.  0. 25.  3. 25. 29. 10. 29. 29. 10. 10. 10. 10.  1.  0.
  0.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25] -> size -> 35 
action values: 1 
buys: 0 
player value: 2 
card supply: [22. 27. 30. 29. 30.  8.  6. 10.  7.  7.  5.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 143.1207275390625



action possibilites: [-1. 25.] 
expected returns: [[139.84702]
 [156.05322]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0.  0. 25.] 
cards in discard: [25.  3. 25.  3.  0. 25.  3. 25. 29. 10. 29. 29. 10. 10. 10. 10.  1.  0.
  0.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25] -> size -> 35 
action values: 1 
buys: 0 
player value: 3 
card supply: [22. 27. 30. 29. 30.  8.  6. 10.  7.  7.  5.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 157.57984924316406



action possibilites: [-1] 
expected returns: [[159.21724]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0.  0. 11.  0.] 
cards in discard: [25.  3. 25.  3.  0. 25.  3. 25. 29. 10. 29. 29. 10. 10. 10. 10.  1.  0.
  0.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25] -> size -> 35 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 27. 30. 29. 30.  8.  5. 10.  7.  7.  5.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [8. 0. 6.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 6 0 6] -> size -> 4 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 156.0532684326172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[152.65894]
 [165.7536 ]
 [149.56396]
 [160.13496]
 [137.24644]
 [162.76643]
 [114.57533]
 [169.17667]
 [166.58348]
 [157.38654]
 [176.54948]
 [171.94547]
 [131.40834]
 [162.15779]
 [161.65576]
 [145.1199 ]
 [152.18674]
 [161.34122]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0.  0. 11.  0.] 
cards in discard: [25.  3. 25.  3.  0. 25.  3. 25. 29. 10. 29. 29. 10. 10. 10. 10.  1.  0.
  0.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25] -> size -> 35 
action values: 0 
buys: 1 
player value: 8 
card supply: [22. 27. 30. 29. 30.  8.  5. 10.  7.  7.  5.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [8. 0. 6.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 6 0 6] -> size -> 4 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 159.2172393798828



buy possibilites: [-1] 
expected returns: [[225.79034]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0.  0. 11.  0.] 
cards in discard: [25.  3. 25.  3.  0. 25.  3. 25. 29. 10. 29. 29. 10. 10. 10. 10.  1.  0.
  0.  0.  1. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25] -> size -> 36 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 27. 30. 29. 30.  8.  5. 10.  7.  7.  4.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [8. 0. 6.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 6 0 6] -> size -> 4 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5.    0.    0.  150.    0.    0.   80.    0.    0.    0.    0.  -10.
   0.    0.   62.5   0. ] 
sum of rewards: 277.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 176.54945373535156






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [8. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6.] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0 6] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 29. 30.  8.  5. 10.  7.  7.  4.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 10. 29. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25] -> size -> 36 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6.] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0 6] -> size -> 4 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 27. 30. 29. 30.  8.  5. 10.  7.  7.  4.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 10. 29. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25] -> size -> 36 
adversary victory points: 4
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 10. 29. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11. 11.] 
expected returns: [[84.66752 ]
 [89.297226]
 [98.40135 ]
 [91.12523 ]
 [91.12523 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 29. 11. 11.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 29. 30.  8.  5. 10.  7.  7.  4.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [8. 6. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 6] -> size -> 4 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 225.79034423828125



action possibilites: [-1. 10. 11. 11. 29.] 
expected returns: [[ 99.60018]
 [101.88731]
 [103.71909]
 [103.71909]
 [112.42724]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 11. 29.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 29. 30.  8.  5. 10.  7.  7.  4.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [8. 6. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 6] -> size -> 4 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 97.550537109375



action possibilites: [-1. 10. 11. 11. 25.] 
expected returns: [[ 95.460556]
 [102.46077 ]
 [107.41028 ]
 [107.41028 ]
 [116.096085]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 11. 25.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25] -> size -> 36 
action values: 1 
buys: 0 
player value: 2 
card supply: [22. 27. 30. 29. 30.  8.  5. 10.  7.  7.  4.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [8. 6. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 6] -> size -> 4 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 112.42723083496094



action possibilites: [-1] 
expected returns: [[64.80265]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 11. 29. 25.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 27. 30. 29. 30.  8.  4. 10.  7.  7.  4.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [8. 6. 6. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 6 0 6 6] -> size -> 5 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 116.09607696533203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[67.85909 ]
 [81.58381 ]
 [73.28241 ]
 [30.922516]
 [78.82028 ]
 [72.95786 ]
 [74.32211 ]
 [68.148094]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11. 11. 29. 25.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 27. 30. 29. 30.  8.  4. 10.  7.  7.  4.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [8. 6. 6. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 6 0 6 6] -> size -> 5 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action -1
Learning step: 0
desired expected reward: 64.80265045166016



buy possibilites: [-1] 
expected returns: [[67.138756]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11. 11. 29. 25.] 
cards in discard: [1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 29. 30.  8.  4. 10.  7.  7.  4.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [8. 6. 6. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 6 0 6 6] -> size -> 5 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  60   0   0   0   0 -20   0   0  54   0] 
sum of rewards: 269 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 81.58382415771484






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [8. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 6. 0.] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0 6 6] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 29. 30.  8.  4. 10.  7.  7.  4.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 3. 10.  3. 11. 29.] 
adversary cards in discard: [ 1. 29. 29. 25.  0. 10. 11. 11. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1] -> size -> 37 
adversary victory points: 4
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 6. 0.] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0 6 6] -> size -> 5 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 29. 30.  8.  4. 10.  7.  7.  4.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 3. 10.  3. 11. 29.] 
adversary cards in discard: [ 1. 29. 29. 25.  0. 10. 11. 11. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1] -> size -> 37 
adversary victory points: 4
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 6. 0.] 
cards in discard: [6. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0 6 6 0] -> size -> 6 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 29. 30.  8.  4. 10.  7.  7.  4.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 3. 10.  3. 11. 29.] 
adversary cards in discard: [ 1. 29. 29. 25.  0. 10. 11. 11. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1] -> size -> 37 
adversary victory points: 4
player victory points: -3 





Player: 0 
cards in hand: [ 3. 10.  3. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 29.] 
expected returns: [[62.79013]
 [67.43165]
 [71.71574]
 [77.85993]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3. 11. 29.] 
cards in discard: [ 1. 29. 29. 25.  0. 10. 11. 11. 29. 25.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 29. 30.  8.  4. 10.  7.  7.  4.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [0. 6. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 6 6 0] -> size -> 6 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 67.13875579833984



action possibilites: [-1. 10. 11. 25.] 
expected returns: [[60.527542]
 [66.6345  ]
 [71.54053 ]
 [80.46978 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3. 11. 25.] 
cards in discard: [ 1. 29. 29. 25.  0. 10. 11. 11. 29. 25.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 29. 30.  8.  4. 10.  7.  7.  4.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [0. 6. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 6 6 0] -> size -> 6 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 77.90959930419922



action possibilites: [-1] 
expected returns: [[20.789381]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3. 11.  0. 29.] 
cards in discard: [ 1. 29. 29. 25.  0. 10. 11. 11. 29. 25.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 29. 30.  8.  3. 10.  7.  7.  4.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [0. 6. 0. 6. 6.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 6 0 6 6 0 6] -> size -> 7 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 80.46978759765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 21.805878]
 [ 27.650547]
 [-18.067486]
 [ 26.228502]
 [ 26.357658]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3. 11.  0. 29.] 
cards in discard: [ 1. 29. 29. 25.  0. 10. 11. 11. 29. 25.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 26. 30. 29. 30.  8.  3. 10.  7.  7.  4.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [0. 6. 0. 6. 6.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 6 0 6 6 0 6] -> size -> 7 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action -1
Learning step: 0
desired expected reward: 20.78938102722168



buy possibilites: [-1] 
expected returns: [[124.84229]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3. 11.  0. 29.] 
cards in discard: [ 1. 29. 29. 25.  0. 10. 11. 11. 29. 25.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 28. 30.  8.  3. 10.  7.  7.  4.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [0. 6. 0. 6. 6.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 6 0 6 6 0 6] -> size -> 7 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0 -30   0   0  16   0] 
sum of rewards: 261 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 27.650508880615234






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [0. 6. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 6. 6.] 
cards in discard: [6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0 6 6 0 6] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 28. 30.  8.  3. 10.  7.  7.  4.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0. 25. 10.  0.] 
adversary cards in discard: [ 1. 29. 29. 25.  0. 10. 11. 11. 29. 25.  3. 29. 25.  3. 10.  3. 11.  0.
 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3] -> size -> 38 
adversary victory points: 5
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6. 6.] 
cards in discard: [6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0 6 6 0 6] -> size -> 7 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 26. 30. 28. 30.  8.  3. 10.  7.  7.  4.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0. 25. 10.  0.] 
adversary cards in discard: [ 1. 29. 29. 25.  0. 10. 11. 11. 29. 25.  3. 29. 25.  3. 10.  3. 11.  0.
 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3] -> size -> 38 
adversary victory points: 5
player victory points: -4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  0. 25. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
expected returns: [[ 86.391914]
 [102.07212 ]
 [ 88.67636 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25. 10.  0.] 
cards in discard: [ 1. 29. 29. 25.  0. 10. 11. 11. 29. 25.  3. 29. 25.  3. 10.  3. 11.  0.
 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 28. 30.  8.  3. 10.  7.  7.  4.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 0. 0. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 6 6 0 6] -> size -> 7 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 124.84229278564453



action possibilites: [-1] 
expected returns: [[58.448006]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0. 10. 25.] 
cards in discard: [ 1. 29. 29. 25.  0. 10. 11. 11. 29. 25.  3. 29. 25.  3. 10.  3. 11.  0.
 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 28. 30.  8.  2. 10.  7.  7.  4.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 0. 0. 6. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 6 0 6 6 0 6 6] -> size -> 8 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 102.07212829589844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[58.077286]
 [69.447685]
 [62.28685 ]
 [26.218815]
 [67.165245]
 [62.59993 ]
 [63.86467 ]
 [62.565407]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0. 10. 25.] 
cards in discard: [ 1. 29. 29. 25.  0. 10. 11. 11. 29. 25.  3. 29. 25.  3. 10.  3. 11.  0.
 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 26. 30. 28. 30.  8.  2. 10.  7.  7.  4.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 0. 0. 6. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 6 0 6 6 0 6 6] -> size -> 8 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 58.44800567626953



buy possibilites: [-1] 
expected returns: [[97.710304]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0. 10. 25.] 
cards in discard: [ 1. 29. 29. 25.  0. 10. 11. 11. 29. 25.  3. 29. 25.  3. 10.  3. 11.  0.
 29.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 28. 30.  8.  2. 10.  7.  7.  4.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 0. 0. 6. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 6 0 6 6 0 6 6] -> size -> 8 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0 -40   0   0  54   0] 
sum of rewards: 299 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 69.44766998291016






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [6. 0. 0. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 6. 8.] 
cards in discard: [6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0 6 6 0 6 6] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 28. 30.  8.  2. 10.  7.  7.  4.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [29.  1.  0.  3.  1.] 
adversary cards in discard: [ 1. 29. 29. 25.  0. 10. 11. 11. 29. 25.  3. 29. 25.  3. 10.  3. 11.  0.
 29.  1. 25.  0.  0. 10.  0. 10. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1] -> size -> 39 
adversary victory points: 5
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 6 6 6] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 28. 30.  8.  2. 10.  7.  7.  4.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [29.  1.  0.  3.  1.] 
adversary cards in discard: [ 1. 29. 29. 25.  0. 10. 11. 11. 29. 25.  3. 29. 25.  3. 10.  3. 11.  0.
 29.  1. 25.  0.  0. 10.  0. 10. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1] -> size -> 39 
adversary victory points: 5
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 6 6 6] -> size -> 5 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 25. 30. 28. 30.  8.  2. 10.  7.  7.  4.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [29.  1.  0.  3.  1.] 
adversary cards in discard: [ 1. 29. 29. 25.  0. 10. 11. 11. 29. 25.  3. 29. 25.  3. 10.  3. 11.  0.
 29.  1. 25.  0.  0. 10.  0. 10. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1] -> size -> 39 
adversary victory points: 5
player victory points: -4 





Player: 0 
cards in hand: [29.  1.  0.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[115.85476 ]
 [126.868904]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  0.  3.  1.] 
cards in discard: [ 1. 29. 29. 25.  0. 10. 11. 11. 29. 25.  3. 29. 25.  3. 10.  3. 11.  0.
 29.  1. 25.  0.  0. 10.  0. 10. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 28. 30.  8.  2. 10.  7.  7.  4.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 8. 6. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 6 6] -> size -> 5 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 97.7103042602539



action possibilites: [-1.] 
expected returns: [[160.19423]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 1. 1.] 
cards in discard: [ 1. 29. 29. 25.  0. 10. 11. 11. 29. 25.  3. 29. 25.  3. 10.  3. 11.  0.
 29.  1. 25.  0.  0. 10.  0. 10. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 25. 30. 28. 30.  8.  2. 10.  7.  7.  4.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 8. 6. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 6 6] -> size -> 5 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 126.8689193725586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[145.13506 ]
 [163.00723 ]
 [138.9916  ]
 [153.15576 ]
 [120.64878 ]
 [156.26398 ]
 [ 89.841324]
 [170.91537 ]
 [168.05887 ]
 [155.33076 ]
 [181.48383 ]
 [176.39108 ]
 [115.070915]
 [159.13072 ]
 [162.0676  ]
 [135.29012 ]
 [143.85875 ]
 [160.3429  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 1. 1.] 
cards in discard: [ 1. 29. 29. 25.  0. 10. 11. 11. 29. 25.  3. 29. 25.  3. 10.  3. 11.  0.
 29.  1. 25.  0.  0. 10.  0. 10. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 8 
card supply: [21. 25. 30. 28. 30.  8.  2. 10.  7.  7.  4.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 8. 6. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 6 6] -> size -> 5 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 160.19422912597656



buy possibilites: [-1] 
expected returns: [[133.79979]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 1. 1.] 
cards in discard: [ 1. 29. 29. 25.  0. 10. 11. 11. 29. 25.  3. 29. 25.  3. 10.  3. 11.  0.
 29.  1. 25.  0.  0. 10.  0. 10. 25. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25] -> size -> 40 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 25. 30. 28. 30.  8.  2. 10.  7.  7.  3.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 8. 6. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 6 6] -> size -> 5 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5.    0.    0.  270.    0.    0.   20.    0.    0.    0.    0.  -50.
   0.    0.   62.5   0. ] 
sum of rewards: 297.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 181.48379516601562






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [6. 8. 6. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 6. 6. 6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 6 6] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 28. 30.  8.  2. 10.  7.  7.  3.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [29.  3.  0. 10. 10.] 
adversary cards in discard: [ 1. 29. 29. 25.  0. 10. 11. 11. 29. 25.  3. 29. 25.  3. 10.  3. 11.  0.
 29.  1. 25.  0.  0. 10.  0. 10. 25. 25. 29.  1.  0.  3.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25] -> size -> 40 
adversary victory points: 5
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 6. 6. 6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 6 6] -> size -> 5 
action values: 1 
buys: 1 
player value: 0 
card supply: [21. 25. 30. 28. 30.  8.  2. 10.  7.  7.  3.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [29.  3.  0. 10. 10.] 
adversary cards in discard: [ 1. 29. 29. 25.  0. 10. 11. 11. 29. 25.  3. 29. 25.  3. 10.  3. 11.  0.
 29.  1. 25.  0.  0. 10.  0. 10. 25. 25. 29.  1.  0.  3.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25] -> size -> 40 
adversary victory points: 5
player victory points: -4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29.  3.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10.] 
expected returns: [[ 95.84464 ]
 [109.04374 ]
 [ 97.970604]
 [ 97.970604]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0. 10. 10.] 
cards in discard: [ 1. 29. 29. 25.  0. 10. 11. 11. 29. 25.  3. 29. 25.  3. 10.  3. 11.  0.
 29.  1. 25.  0.  0. 10.  0. 10. 25. 25. 29.  1.  0.  3.  1.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 28. 30.  8.  2. 10.  7.  7.  3.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 6. 8. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 6 6] -> size -> 5 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 133.79978942871094



action possibilites: [-1. 10. 10. 25.] 
expected returns: [[ 90.840324]
 [ 93.40322 ]
 [ 93.40322 ]
 [104.48348 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10. 10. 25.] 
cards in discard: [ 1. 29. 29. 25.  0. 10. 11. 11. 29. 25.  3. 29. 25.  3. 10.  3. 11.  0.
 29.  1. 25.  0.  0. 10.  0. 10. 25. 25. 29.  1.  0.  3.  1.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 25. 30. 28. 30.  8.  2. 10.  7.  7.  3.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 6. 8. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 6 6] -> size -> 5 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 109.0437240600586



action possibilites: [-1] 
expected returns: [[65.73346]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10. 10. 29.  1.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 25. 30. 28. 30.  8.  1. 10.  7.  7.  3.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 6. 8. 6. 6.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 6 6 6 6 6] -> size -> 6 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 104.48347473144531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[64.22765 ]
 [77.94138 ]
 [69.840096]
 [19.531723]
 [78.54316 ]
 [75.501465]
 [69.31754 ]
 [80.70316 ]
 [41.298183]
 [70.83856 ]
 [62.125877]
 [64.65324 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10. 10. 29.  1.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25] -> size -> 40 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 25. 30. 28. 30.  8.  1. 10.  7.  7.  3.  3. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 6. 8. 6. 6.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 6 6 6 6 6] -> size -> 6 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action -1
Learning step: 0
desired expected reward: 65.73345947265625



buy possibilites: [-1] 
expected returns: [[32.296875]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10. 10. 29.  1.] 
cards in discard: [29.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 28. 30.  8.  1. 10.  7.  7.  3.  2. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 6. 8. 6. 6.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 6 6 6 6 6] -> size -> 6 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0 -60   0   0 128   0] 
sum of rewards: 373 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 80.70317077636719






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [6. 6. 8. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 8. 6. 6.] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 6 6 6] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 28. 30.  8.  1. 10.  7.  7.  3.  2. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 3. 10. 25.  1. 29.] 
adversary cards in discard: [29. 29. 25.  3.  0. 10. 10. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29] -> size -> 41 
adversary victory points: 5
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 8. 6. 6.] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 6 6 6] -> size -> 6 
action values: 1 
buys: 1 
player value: 0 
card supply: [21. 25. 30. 28. 30.  8.  1. 10.  7.  7.  3.  2. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 3. 10. 25.  1. 29.] 
adversary cards in discard: [29. 29. 25.  3.  0. 10. 10. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29] -> size -> 41 
adversary victory points: 5
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 8. 6. 6.] 
cards in discard: [6. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 6 6 6 0] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 28. 30.  8.  1. 10.  7.  7.  3.  2. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 3. 10. 25.  1. 29.] 
adversary cards in discard: [29. 29. 25.  3.  0. 10. 10. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29] -> size -> 41 
adversary victory points: 5
player victory points: -5 





Player: 0 
cards in hand: [ 3. 10. 25.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 29.] 
expected returns: [[47.492485]
 [50.01246 ]
 [62.00953 ]
 [59.12719 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 25.  1. 29.] 
cards in discard: [29. 29. 25.  3.  0. 10. 10. 29.  1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 28. 30.  8.  1. 10.  7.  7.  3.  2. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 6. 8. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 6 6 6 0] -> size -> 7 
adversary victory points: -5
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 32.296875



action possibilites: [-1] 
expected returns: [[43.16719]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  1. 29. 25. 25.] 
cards in discard: [29. 29. 25.  3.  0. 10. 10. 29.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 28. 30.  8.  0. 10.  7.  7.  3.  2. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 6. 8. 6. 6.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 6 6 6 6 6 0 6] -> size -> 8 
adversary victory points: -5
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 62.22615051269531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[39.53435 ]
 [45.06849 ]
 [43.425056]
 [43.78731 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  1. 29. 25. 25.] 
cards in discard: [29. 29. 25.  3.  0. 10. 10. 29.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 25. 30. 28. 30.  8.  0. 10.  7.  7.  3.  2. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 6. 8. 6. 6.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 6 6 6 6 6 0 6] -> size -> 8 
adversary victory points: -5
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: 43.16719055175781



buy possibilites: [-1] 
expected returns: [[49.447598]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  1. 29. 25. 25.] 
cards in discard: [29. 29. 25.  3.  0. 10. 10. 29.  1.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 27. 30.  8.  0. 10.  7.  7.  3.  2. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 6. 8. 6. 6.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 6 6 6 6 6 0 6] -> size -> 8 
adversary victory points: -5
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0 -70   0   0  16   0] 
sum of rewards: 291 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 45.0684700012207






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [6. 6. 8. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 8. 6. 6.] 
cards in discard: [6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 6 6 6 0 6] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 27. 30.  8.  0. 10.  7.  7.  3.  2. 10. 10.  3. 10. 10.] 
adversary cards in hand: [29.  3. 11.  3.  3.] 
adversary cards in discard: [29. 29. 25.  3.  0. 10. 10. 29.  1.  3. 25.  3. 10.  1. 29. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3] -> size -> 42 
adversary victory points: 6
player victory points: -6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 0 6] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 27. 30.  8.  0. 10.  7.  7.  3.  2. 10. 10.  3. 10. 10.] 
adversary cards in hand: [29.  3. 11.  3.  3.] 
adversary cards in discard: [29. 29. 25.  3.  0. 10. 10. 29.  1.  3. 25.  3. 10.  1. 29. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3] -> size -> 42 
adversary victory points: 6
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 0 6] -> size -> 4 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 25. 30. 27. 30.  8.  0. 10.  7.  7.  3.  2. 10. 10.  3. 10. 10.] 
adversary cards in hand: [29.  3. 11.  3.  3.] 
adversary cards in discard: [29. 29. 25.  3.  0. 10. 10. 29.  1.  3. 25.  3. 10.  1. 29. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3] -> size -> 42 
adversary victory points: 6
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [6. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 0 6 0] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 27. 30.  8.  0. 10.  7.  7.  3.  2. 10. 10.  3. 10. 10.] 
adversary cards in hand: [29.  3. 11.  3.  3.] 
adversary cards in discard: [29. 29. 25.  3.  0. 10. 10. 29.  1.  3. 25.  3. 10.  1. 29. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3] -> size -> 42 
adversary victory points: 6
player victory points: -2 





Player: 0 
cards in hand: [29.  3. 11.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[56.39741]
 [68.66674]
 [62.82263]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 11.  3.  3.] 
cards in discard: [29. 29. 25.  3.  0. 10. 10. 29.  1.  3. 25.  3. 10.  1. 29. 25. 25.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 27. 30.  8.  0. 10.  7.  7.  3.  2. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 0. 8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 6 0] -> size -> 5 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 49.44759750366211



action possibilites: [-1. 11.] 
expected returns: [[43.757294]
 [53.56096 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3.  3.] 
cards in discard: [29. 29. 25.  3.  0. 10. 10. 29.  1.  3. 25.  3. 10.  1. 29. 25. 25.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 25. 30. 27. 30.  8.  0. 10.  7.  7.  3.  2. 10. 10.  3. 10. 10.] 
adversary cards in hand: [6. 0. 8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 6 0] -> size -> 5 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 63.307518005371094



action possibilites: [-1] 
expected returns: [[2.5546298]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3.] 
cards in discard: [29. 29. 25.  3.  0. 10. 10. 29.  1.  3. 25.  3. 10.  1. 29. 25. 25.  0.
 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 25. 30. 27. 30.  8.  0. 10.  7.  7.  3.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [6. 0. 8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 6 0] -> size -> 5 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0 -80   0   0  64   0] 
sum of rewards: 259 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 54.31267166137695





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-9.0000305]
 [ 2.580008 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3.] 
cards in discard: [29. 29. 25.  3.  0. 10. 10. 29.  1.  3. 25.  3. 10.  1. 29. 25. 25.  0.
 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 25. 30. 27. 30.  8.  0. 10.  7.  7.  3.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [6. 0. 8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 6 0] -> size -> 5 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1
Learning step: 0
desired expected reward: 2.5546298027038574






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [6. 0. 8. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 0. 6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0 6 0] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 27. 30.  8.  0. 10.  7.  7.  3.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0. 29. 10.  1.] 
adversary cards in discard: [29. 29. 25.  3.  0. 10. 10. 29.  1.  3. 25.  3. 10.  1. 29. 25. 25.  0.
 15. 29. 11.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15] -> size -> 43 
adversary victory points: 6
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 0. 6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0 6 0] -> size -> 5 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 25. 30. 27. 30.  8.  0. 10.  7.  7.  3.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0. 29. 10.  1.] 
adversary cards in discard: [29. 29. 25.  3.  0. 10. 10. 29.  1.  3. 25.  3. 10.  1. 29. 25. 25.  0.
 15. 29. 11.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15] -> size -> 43 
adversary victory points: 6
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 0. 6.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0 6 0 3] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 26. 30.  8.  0. 10.  7.  7.  3.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0. 29. 10.  1.] 
adversary cards in discard: [29. 29. 25.  3.  0. 10. 10. 29.  1.  3. 25.  3. 10.  1. 29. 25. 25.  0.
 15. 29. 11.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15] -> size -> 43 
adversary victory points: 6
player victory points: -1 





Player: 0 
cards in hand: [ 0.  0. 29. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[118.76434]
 [131.06151]
 [120.31316]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 10.  1.] 
cards in discard: [29. 29. 25.  3.  0. 10. 10. 29.  1.  3. 25.  3. 10.  1. 29. 25. 25.  0.
 15. 29. 11.  3.  3.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 26. 30.  8.  0. 10.  7.  7.  3.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [6. 8. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 6 0 3] -> size -> 6 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 2.5800509452819824



action possibilites: [-1. 10. 25.] 
expected returns: [[101.40197]
 [102.69152]
 [117.03586]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 25.] 
cards in discard: [29. 29. 25.  3.  0. 10. 10. 29.  1.  3. 25.  3. 10.  1. 29. 25. 25.  0.
 15. 29. 11.  3.  3.  3.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15] -> size -> 43 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 25. 30. 26. 30.  8.  0. 10.  7.  7.  3.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [6. 8. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 6 0 3] -> size -> 6 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 125.6483383178711



action possibilites: [-1] 
expected returns: [[107.174545]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 29. 29.] 
cards in discard: [29. 29. 25.  3.  0. 10. 10. 29.  1.  3. 25.  3. 10.  1. 29. 25. 25.  0.
 15. 29. 11.  3.  3.  3.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 25. 30. 26. 30.  8.  0. 10.  7.  7.  3.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [6. 8. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 6 0 3] -> size -> 6 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 117.0358657836914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[ 98.21026]
 [109.46436]
 [102.82578]
 [108.45153]
 [103.38119]
 [106.51135]
 [107.17456]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 29. 29.] 
cards in discard: [29. 29. 25.  3.  0. 10. 10. 29.  1.  3. 25.  3. 10.  1. 29. 25. 25.  0.
 15. 29. 11.  3.  3.  3.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15] -> size -> 43 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 25. 30. 26. 30.  8.  0. 10.  7.  7.  3.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [6. 8. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 6 0 3] -> size -> 6 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action -1
Learning step: 0
desired expected reward: 107.17454528808594



buy possibilites: [-1] 
expected returns: [[123.43073]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 29. 29.] 
cards in discard: [29. 29. 25.  3.  0. 10. 10. 29.  1.  3. 25.  3. 10.  1. 29. 25. 25.  0.
 15. 29. 11.  3.  3.  3.  1.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 26. 30.  8.  0. 10.  7.  7.  3.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [6. 8. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 6 0 3] -> size -> 6 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0 -90   0   0  54   0] 
sum of rewards: 209 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 109.4643325805664






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [6. 8. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 3. 6. 0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0 6 0 3] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 26. 30.  8.  0. 10.  7.  7.  3.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [11.  0. 11. 25. 10.] 
adversary cards in discard: [29. 29. 25.  3.  0. 10. 10. 29.  1.  3. 25.  3. 10.  1. 29. 25. 25.  0.
 15. 29. 11.  3.  3.  3.  1.  1. 29. 25.  0.  0. 10. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1] -> size -> 44 
adversary victory points: 6
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 26. 30.  8.  0. 10.  7.  7.  3.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [11.  0. 11. 25. 10.] 
adversary cards in discard: [29. 29. 25.  3.  0. 10. 10. 29.  1.  3. 25.  3. 10.  1. 29. 25. 25.  0.
 15. 29. 11.  3.  3.  3.  1.  1. 29. 25.  0.  0. 10. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1] -> size -> 44 
adversary victory points: 6
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 24. 30. 26. 30.  8.  0. 10.  7.  7.  3.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [11.  0. 11. 25. 10.] 
adversary cards in discard: [29. 29. 25.  3.  0. 10. 10. 29.  1.  3. 25.  3. 10.  1. 29. 25. 25.  0.
 15. 29. 11.  3.  3.  3.  1.  1. 29. 25.  0.  0. 10. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1] -> size -> 44 
adversary victory points: 6
player victory points: -1 





Player: 0 
cards in hand: [11.  0. 11. 25. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 25. 10.] 
expected returns: [[66.47657 ]
 [75.02204 ]
 [75.02204 ]
 [84.42401 ]
 [71.901566]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11. 25. 10.] 
cards in discard: [29. 29. 25.  3.  0. 10. 10. 29.  1.  3. 25.  3. 10.  1. 29. 25. 25.  0.
 15. 29. 11.  3.  3.  3.  1.  1. 29. 25.  0.  0. 10. 29. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 26. 30.  8.  0. 10.  7.  7.  3.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 123.43073272705078



action possibilites: [-1] 
expected returns: [[88.57922]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11. 10. 25. 10.] 
cards in discard: [29. 29. 25.  3.  0. 10. 10. 29.  1.  3. 25.  3. 10.  1. 29. 25. 25.  0.
 15. 29. 11.  3.  3.  3.  1.  1. 29. 25.  0.  0. 10. 29. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 26. 30.  8.  0. 10.  7.  7.  3.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 84.42400360107422





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[82.3409]
 [88.5792]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 11. 10. 25. 10.] 
cards in discard: [29. 29. 25.  3.  0. 10. 10. 29.  1.  3. 25.  3. 10.  1. 29. 25. 25.  0.
 15. 29. 11.  3.  3.  3.  1.  1. 29. 25.  0.  0. 10. 29. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1] -> size -> 44 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 24. 30. 26. 30.  8.  0. 10.  7.  7.  3.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 88.5792236328125






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 26. 30.  8.  0. 10.  7.  7.  3.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [29.  1.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1] -> size -> 44 
adversary victory points: 6
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 24. 30. 26. 30.  8.  0. 10.  7.  7.  3.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [29.  1.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1] -> size -> 44 
adversary victory points: 6
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29.  1.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[26.261234]
 [42.38048 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  1.  0.  0.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 26. 30.  8.  0. 10.  7.  7.  3.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 88.5792236328125



action possibilites: [-1.] 
expected returns: [[4.8377995]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 38 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1] -> size -> 44 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 24. 30. 26. 30.  8.  0. 10.  7.  7.  3.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 37.27593994140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 7.6155267]
 [17.393074 ]
 [ 7.0552077]
 [14.517813 ]
 [-4.084735 ]
 [23.818874 ]
 [23.378242 ]
 [13.958479 ]
 [32.63487  ]
 [30.972095 ]
 [-5.0628195]
 [21.980652 ]
 [21.075657 ]
 [ 5.3456635]
 [15.185526 ]
 [11.847826 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 38 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1] -> size -> 44 
action values: 0 
buys: 1 
player value: 6 
card supply: [19. 24. 30. 26. 30.  8.  0. 10.  7.  7.  3.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 4.837799549102783



buy possibilites: [-1] 
expected returns: [[42.29932]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0.] 
cards in discard: [ 1. 25.] 
cards in deck: 38 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25] -> size -> 45 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 24. 30. 26. 30.  8.  0. 10.  7.  7.  2.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[  -5.     0.     0.   210.     0.     0.    20.     0.     0.     0.
    0.  -100.     0.     0.    62.5    0. ] 
sum of rewards: 187.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 32.63489532470703






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 26. 30.  8.  0. 10.  7.  7.  2.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [25.  1. 25. 29. 25.] 
adversary cards in discard: [ 1. 25. 29.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25] -> size -> 45 
adversary victory points: 6
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 24. 30. 26. 30.  8.  0. 10.  7.  7.  2.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [25.  1. 25. 29. 25.] 
adversary cards in discard: [ 1. 25. 29.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25] -> size -> 45 
adversary victory points: 6
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [25.  1. 25. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 29. 25.] 
expected returns: [[64.589775]
 [78.34649 ]
 [78.34649 ]
 [76.53473 ]
 [78.34649 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1. 25. 29. 25.] 
cards in discard: [ 1. 25. 29.  1.  0.  0.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 26. 30.  8.  0. 10.  7.  7.  2.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [8. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 42.299320220947266



action possibilites: [-1] 
expected returns: [[22.302345]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25. 29. 25. 10. 10.] 
cards in discard: [ 1. 25. 29.  1.  0.  0.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 26. 30.  8.  0. 10.  7.  7.  2.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [8. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 78.90235137939453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[15.873495]
 [23.00471 ]
 [20.654024]
 [22.879927]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 25. 29. 25. 10. 10.] 
cards in discard: [ 1. 25. 29.  1.  0.  0.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25] -> size -> 45 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 24. 30. 26. 30.  8.  0. 10.  7.  7.  2.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [8. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 22.302345275878906



buy possibilites: [-1] 
expected returns: [[59.784737]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 25. 29. 25. 10. 10.] 
cards in discard: [ 1. 25. 29.  1.  0.  0.  0.  3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 25. 30.  8.  0. 10.  7.  7.  2.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [8. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  240    0    0   20    0    0    0    0 -110    0    0
   16    0] 
sum of rewards: 161 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 23.004764556884766






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [8. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 25. 30.  8.  0. 10.  7.  7.  2.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [25.  1.  0. 25. 11.] 
adversary cards in discard: [ 1. 25. 29.  1.  0.  0.  0.  3. 25.  1. 25. 29. 25. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3] -> size -> 46 
adversary victory points: 7
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 24. 30. 25. 30.  8.  0. 10.  7.  7.  2.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [25.  1.  0. 25. 11.] 
adversary cards in discard: [ 1. 25. 29.  1.  0.  0.  0.  3. 25.  1. 25. 29. 25. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3] -> size -> 46 
adversary victory points: 7
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [25.  1.  0. 25. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 11.] 
expected returns: [[39.606857]
 [58.650574]
 [58.650574]
 [43.204887]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  0. 25. 11.] 
cards in discard: [ 1. 25. 29.  1.  0.  0.  0.  3. 25.  1. 25. 29. 25. 10. 10.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 25. 30.  8.  0. 10.  7.  7.  2.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 59.78473663330078



action possibilites: [-1] 
expected returns: [[78.86799]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 25. 11.  3. 11.] 
cards in discard: [ 1. 25. 29.  1.  0.  0.  0.  3. 25.  1. 25. 29. 25. 10. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 25. 30.  8.  0. 10.  7.  7.  2.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 58.650596618652344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[72.15065 ]
 [84.79282 ]
 [77.06867 ]
 [82.88008 ]
 [76.964264]
 [78.61349 ]
 [79.03514 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 25. 11.  3. 11.] 
cards in discard: [ 1. 25. 29.  1.  0.  0.  0.  3. 25.  1. 25. 29. 25. 10. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3] -> size -> 46 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 24. 30. 25. 30.  8.  0. 10.  7.  7.  2.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 78.86798858642578



buy possibilites: [-1] 
expected returns: [[20.479122]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 25. 11.  3. 11.] 
cards in discard: [ 1. 25. 29.  1.  0.  0.  0.  3. 25.  1. 25. 29. 25. 10. 10.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 25. 30.  8.  0. 10.  7.  7.  2.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  240    0    0   20    0    0    0    0 -120    0    0
   54    0] 
sum of rewards: 189 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 84.7928237915039






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 25. 30.  8.  0. 10.  7.  7.  2.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [29.  0. 29. 10.  1.] 
adversary cards in discard: [ 1. 25. 29.  1.  0.  0.  0.  3. 25.  1. 25. 29. 25. 10. 10.  1. 25.  1.
  0. 25. 11.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1] -> size -> 47 
adversary victory points: 7
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 23. 30. 25. 30.  8.  0. 10.  7.  7.  2.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [29.  0. 29. 10.  1.] 
adversary cards in discard: [ 1. 25. 29.  1.  0.  0.  0.  3. 25.  1. 25. 29. 25. 10. 10.  1. 25.  1.
  0. 25. 11.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1] -> size -> 47 
adversary victory points: 7
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29.  0. 29. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 10.] 
expected returns: [[103.85007]
 [119.70779]
 [119.70779]
 [110.1156 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29. 10.  1.] 
cards in discard: [ 1. 25. 29.  1.  0.  0.  0.  3. 25.  1. 25. 29. 25. 10. 10.  1. 25.  1.
  0. 25. 11.  3. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 25. 30.  8.  0. 10.  7.  7.  2.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 20.479122161865234



action possibilites: [-1. 29. 10. 11.] 
expected returns: [[140.5387 ]
 [150.90546]
 [140.04758]
 [143.74585]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10. 11.] 
cards in discard: [ 1. 25. 29.  1.  0.  0.  0.  3. 25.  1. 25. 29. 25. 10. 10.  1. 25.  1.
  0. 25. 11.  3. 11.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 23. 30. 25. 30.  8.  0. 10.  7.  7.  2.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 114.04035186767578



action possibilites: [-1. 10.] 
expected returns: [[93.66117 ]
 [95.643654]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.] 
cards in discard: [ 1. 25. 29.  1.  0.  0.  0.  3. 25.  1. 25. 29. 25. 10. 10.  1. 25.  1.
  0. 25. 11.  3. 11.  1. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 2 
card supply: [19. 23. 30. 25. 30.  8.  0. 10.  7.  7.  2.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 146.2227783203125



action possibilites: [-1. 25.] 
expected returns: [[106.19363]
 [123.07499]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.] 
cards in discard: [ 1. 25. 29.  1.  0.  0.  0.  3. 25.  1. 25. 29. 25. 10. 10.  1. 25.  1.
  0. 25. 11.  3. 11.  1. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1] -> size -> 47 
action values: 2 
buys: 0 
player value: 2 
card supply: [19. 23. 30. 25. 30.  8.  0. 10.  7.  7.  2.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 95.6436538696289



action possibilites: [-1.] 
expected returns: [[133.5877]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 1.] 
cards in discard: [ 1. 25. 29.  1.  0.  0.  0.  3. 25.  1. 25. 29. 25. 10. 10.  1. 25.  1.
  0. 25. 11.  3. 11.  1. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29. 10. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 2 
card supply: [19. 23. 30. 25. 30.  8.  0. 10.  7.  7.  2.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 123.07501983642578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[127.54981 ]
 [139.80386 ]
 [122.94041 ]
 [131.96967 ]
 [114.33327 ]
 [140.83765 ]
 [136.74474 ]
 [132.06157 ]
 [146.42497 ]
 [144.09601 ]
 [107.4319  ]
 [133.27887 ]
 [133.14622 ]
 [117.863144]
 [126.32903 ]
 [133.5877  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1.] 
cards in discard: [ 1. 25. 29.  1.  0.  0.  0.  3. 25.  1. 25. 29. 25. 10. 10.  1. 25.  1.
  0. 25. 11.  3. 11.  1. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29. 10. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 6 
card supply: [19. 23. 30. 25. 30.  8.  0. 10.  7.  7.  2.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 133.58770751953125



buy possibilites: [-1] 
expected returns: [[137.05003]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1.] 
cards in discard: [ 1. 25. 29.  1.  0.  0.  0.  3. 25.  1. 25. 29. 25. 10. 10.  1. 25.  1.
  0. 25. 11.  3. 11.  1. 11. 25.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29. 10. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25] -> size -> 48 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 23. 30. 25. 30.  8.  0. 10.  7.  7.  1.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0] -> size -> 3 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[  -5.     0.     0.   240.     0.     0.    80.     0.     0.     0.
    0.  -130.     0.     0.    62.5    0. ] 
sum of rewards: 247.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 146.42495727539062






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 25. 30.  8.  0. 10.  7.  7.  1.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 29. 25. 29.  3.] 
adversary cards in discard: [ 1. 25. 29.  1.  0.  0.  0.  3. 25.  1. 25. 29. 25. 10. 10.  1. 25.  1.
  0. 25. 11.  3. 11.  1. 11. 25. 29. 29. 10. 25.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25] -> size -> 48 
adversary victory points: 7
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 23. 30. 25. 30.  8.  0. 10.  7.  7.  1.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 29. 25. 29.  3.] 
adversary cards in discard: [ 1. 25. 29.  1.  0.  0.  0.  3. 25.  1. 25. 29. 25. 10. 10.  1. 25.  1.
  0. 25. 11.  3. 11.  1. 11. 25. 29. 29. 10. 25.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25] -> size -> 48 
adversary victory points: 7
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0 0] -> size -> 4 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 23. 30. 25. 30.  8.  0. 10.  7.  7.  1.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 29. 25. 29.  3.] 
adversary cards in discard: [ 1. 25. 29.  1.  0.  0.  0.  3. 25.  1. 25. 29. 25. 10. 10.  1. 25.  1.
  0. 25. 11.  3. 11.  1. 11. 25. 29. 29. 10. 25.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25] -> size -> 48 
adversary victory points: 7
player victory points: -1 





Player: 0 
cards in hand: [ 0. 29. 25. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29.] 
expected returns: [[ 95.80783 ]
 [107.79359 ]
 [112.631325]
 [107.79359 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 25. 29.  3.] 
cards in discard: [ 1. 25. 29.  1.  0.  0.  0.  3. 25.  1. 25. 29. 25. 10. 10.  1. 25.  1.
  0. 25. 11.  3. 11.  1. 11. 25. 29. 29. 10. 25.  0.  0.  3.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 25. 30.  8.  0. 10.  7.  7.  1.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [0. 0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 0] -> size -> 4 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 137.05003356933594



action possibilites: [-1] 
expected returns: [[32.37729]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29.  3. 29. 10.] 
cards in discard: [ 1. 25. 29.  1.  0.  0.  0.  3. 25.  1. 25. 29. 25. 10. 10.  1. 25.  1.
  0. 25. 11.  3. 11.  1. 11. 25. 29. 29. 10. 25.  0.  0.  3.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 25. 30.  8.  0. 10.  7.  7.  1.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [0. 0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 0] -> size -> 4 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 112.63129425048828





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[26.838032]
 [32.37729 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 29.  3. 29. 10.] 
cards in discard: [ 1. 25. 29.  1.  0.  0.  0.  3. 25.  1. 25. 29. 25. 10. 10.  1. 25.  1.
  0. 25. 11.  3. 11.  1. 11. 25. 29. 29. 10. 25.  0.  0.  3.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25] -> size -> 48 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 23. 30. 25. 30.  8.  0. 10.  7.  7.  1.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [0. 0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 0] -> size -> 4 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 32.377288818359375






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0 0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 25. 30.  8.  0. 10.  7.  7.  1.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 3. 29. 10. 10. 15.] 
adversary cards in discard: [ 1. 25. 29.  1.  0.  0.  0.  3. 25.  1. 25. 29. 25. 10. 10.  1. 25.  1.
  0. 25. 11.  3. 11.  1. 11. 25. 29. 29. 10. 25.  0.  0.  3.  1. 25.  0.
 29. 29.  3. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25] -> size -> 48 
adversary victory points: 7
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0 0] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 23. 30. 25. 30.  8.  0. 10.  7.  7.  1.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 3. 29. 10. 10. 15.] 
adversary cards in discard: [ 1. 25. 29.  1.  0.  0.  0.  3. 25.  1. 25. 29. 25. 10. 10.  1. 25.  1.
  0. 25. 11.  3. 11.  1. 11. 25. 29. 29. 10. 25.  0.  0.  3.  1. 25.  0.
 29. 29.  3. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25] -> size -> 48 
adversary victory points: 7
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 6.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0 0 3] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 24. 30.  8.  0. 10.  7.  7.  1.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 3. 29. 10. 10. 15.] 
adversary cards in discard: [ 1. 25. 29.  1.  0.  0.  0.  3. 25.  1. 25. 29. 25. 10. 10.  1. 25.  1.
  0. 25. 11.  3. 11.  1. 11. 25. 29. 29. 10. 25.  0.  0.  3.  1. 25.  0.
 29. 29.  3. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25] -> size -> 48 
adversary victory points: 7
player victory points: 0 





Player: 0 
cards in hand: [ 3. 29. 10. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10. 15.] 
expected returns: [[ 93.52426 ]
 [105.530846]
 [ 93.636536]
 [ 93.636536]
 [ 85.149315]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 10. 10. 15.] 
cards in discard: [ 1. 25. 29.  1.  0.  0.  0.  3. 25.  1. 25. 29. 25. 10. 10.  1. 25.  1.
  0. 25. 11.  3. 11.  1. 11. 25. 29. 29. 10. 25.  0.  0.  3.  1. 25.  0.
 29. 29.  3. 29. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 24. 30.  8.  0. 10.  7.  7.  1.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [3. 0. 0. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 0 3] -> size -> 5 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 32.377288818359375



action possibilites: [-1. 10. 10.] 
expected returns: [[ 97.23609 ]
 [103.209816]
 [103.209816]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10.  3.] 
cards in discard: [ 1. 25. 29.  1.  0.  0.  0.  3. 25.  1. 25. 29. 25. 10. 10.  1. 25.  1.
  0. 25. 11.  3. 11.  1. 11. 25. 29. 29. 10. 25.  0.  0.  3.  1. 25.  0.
 29. 29.  3. 29. 10. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25] -> size -> 48 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 23. 30. 24. 30.  8.  0. 10.  7.  7.  1.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [3. 0. 0. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 0 3] -> size -> 5 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 97.3701400756836



action possibilites: [-1. 10.] 
expected returns: [[90.98688 ]
 [97.087654]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  3.] 
cards in discard: [ 1. 25. 29.  1.  0.  0.  0.  3. 25.  1. 25. 29. 25. 10. 10.  1. 25.  1.
  0. 25. 11.  3. 11.  1. 11. 25. 29. 29. 10. 25.  0.  0.  3.  1. 25.  0.
 29. 29.  3. 29. 10. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25] -> size -> 48 
action values: 2 
buys: 0 
player value: 1 
card supply: [18. 23. 30. 24. 30.  8.  0. 10.  7.  7.  1.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [3. 0. 0. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 0 3] -> size -> 5 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 103.20985412597656



action possibilites: [-1.] 
expected returns: [[21.557686]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [29. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25] -> size -> 48 
action values: 3 
buys: 0 
player value: 1 
card supply: [18. 23. 30. 24. 30.  8.  0. 10.  7.  7.  1.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [3. 0. 0. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 0 3] -> size -> 5 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 97.08767700195312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[15.44054 ]
 [19.935513]
 [20.434444]
 [21.273338]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [29. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25] -> size -> 48 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 23. 30. 24. 30.  8.  0. 10.  7.  7.  1.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [3. 0. 0. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 0 3] -> size -> 5 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 21.55768585205078






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 6. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 0 0 3] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 24. 30.  8.  0. 10.  7.  7.  1.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [29. 10.  3.  0. 29.] 
adversary cards in discard: [29. 10. 10.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25] -> size -> 48 
adversary victory points: 7
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 24. 30.  8.  0. 10.  7.  7.  1.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [29. 10.  3.  0. 29.] 
adversary cards in discard: [29. 10. 10.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25] -> size -> 48 
adversary victory points: 7
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6] -> size -> 2 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 23. 30. 24. 30.  8.  0. 10.  7.  7.  1.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [29. 10.  3.  0. 29.] 
adversary cards in discard: [29. 10. 10.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25] -> size -> 48 
adversary victory points: 7
player victory points: -1 





Player: 0 
cards in hand: [29. 10.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 29.] 
expected returns: [[69.684456]
 [80.952805]
 [72.77964 ]
 [80.952805]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  3.  0. 29.] 
cards in discard: [29. 10. 10.  3.  3.  3.  0.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 24. 30.  8.  0. 10.  7.  7.  1.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 21.27333641052246



action possibilites: [-1. 29.] 
expected returns: [[ 97.21479]
 [110.42596]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  1.] 
cards in discard: [29. 10. 10.  3.  3.  3.  0. 10.] 
cards in deck: 35 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25] -> size -> 48 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 23. 30. 24. 30.  8.  0. 10.  7.  7.  1.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 77.70513153076172



action possibilites: [-1. 11.] 
expected returns: [[ 98.67748]
 [108.99082]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.] 
cards in discard: [29. 10. 10.  3.  3.  3.  0. 10.  1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25] -> size -> 48 
action values: 1 
buys: 0 
player value: 2 
card supply: [18. 23. 30. 24. 30.  8.  0. 10.  7.  7.  1.  2. 10. 10.  3. 10.  9.] 
adversary cards in hand: [8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 108.72332763671875



action possibilites: [-1] 
expected returns: [[102.23804]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [29. 10. 10.  3.  3.  3.  0. 10.  1. 15.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15] -> size -> 49 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 23. 30. 24. 30.  8.  0. 10.  7.  7.  1.  2. 10. 10.  3. 10.  8.] 
adversary cards in hand: [8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  240    0    0   60    0    0    0    0 -140    0    0
   64    0] 
sum of rewards: 219 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 110.41350555419922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[ 99.37209 ]
 [111.47385 ]
 [104.43643 ]
 [109.36938 ]
 [103.58809 ]
 [105.81508 ]
 [102.706245]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [29. 10. 10.  3.  3.  3.  0. 10.  1. 15.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15] -> size -> 49 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 23. 30. 24. 30.  8.  0. 10.  7.  7.  1.  2. 10. 10.  3. 10.  8.] 
adversary cards in hand: [8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: take_action - action -1
Learning step: 0
desired expected reward: 102.238037109375



buy possibilites: [-1] 
expected returns: [[64.331055]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [29. 10. 10.  3.  3.  3.  0. 10.  1. 15.  1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 24. 30.  8.  0. 10.  7.  7.  1.  2. 10. 10.  3. 10.  8.] 
adversary cards in hand: [8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  240    0    0   60    0    0    0    0 -150    0    0
   54    0] 
sum of rewards: 199 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 111.47383117675781






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 24. 30.  8.  0. 10.  7.  7.  1.  2. 10. 10.  3. 10.  8.] 
adversary cards in hand: [25. 10. 11. 15. 25.] 
adversary cards in discard: [29. 10. 10.  3.  3.  3.  0. 10.  1. 15.  1. 29. 29. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1] -> size -> 50 
adversary victory points: 7
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6] -> size -> 2 
action values: 1 
buys: 1 
player value: 0 
card supply: [18. 22. 30. 24. 30.  8.  0. 10.  7.  7.  1.  2. 10. 10.  3. 10.  8.] 
adversary cards in hand: [25. 10. 11. 15. 25.] 
adversary cards in discard: [29. 10. 10.  3.  3.  3.  0. 10.  1. 15.  1. 29. 29. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1] -> size -> 50 
adversary victory points: 7
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [25. 10. 11. 15. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 11. 15. 25.] 
expected returns: [[73.96165 ]
 [88.08782 ]
 [73.483795]
 [78.26546 ]
 [64.21661 ]
 [88.08782 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10. 11. 15. 25.] 
cards in discard: [29. 10. 10.  3.  3.  3.  0. 10.  1. 15.  1. 29. 29. 11.  3.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 24. 30.  8.  0. 10.  7.  7.  1.  2. 10. 10.  3. 10.  8.] 
adversary cards in hand: [8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 64.3310546875



action possibilites: [-1] 
expected returns: [[88.87219]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 15. 25. 29.  3.] 
cards in discard: [29. 10. 10.  3.  3.  3.  0. 10.  1. 15.  1. 29. 29. 11.  3.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 24. 30.  8.  0. 10.  7.  7.  1.  2. 10. 10.  3. 10.  8.] 
adversary cards in hand: [8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 88.08783721923828





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[82.82406]
 [88.8722 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 15. 25. 29.  3.] 
cards in discard: [29. 10. 10.  3.  3.  3.  0. 10.  1. 15.  1. 29. 29. 11.  3.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1] -> size -> 50 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 22. 30. 24. 30.  8.  0. 10.  7.  7.  1.  2. 10. 10.  3. 10.  8.] 
adversary cards in hand: [8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6] -> size -> 2 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 88.8721923828125






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 24. 30.  8.  0. 10.  7.  7.  1.  2. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 1.  0. 11. 29.  0.] 
adversary cards in discard: [29. 10. 10.  3.  3.  3.  0. 10.  1. 15.  1. 29. 29. 11.  3.  0. 25. 10.
 11. 15. 25. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1] -> size -> 50 
adversary victory points: 7
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 24. 30.  8.  0. 10.  7.  7.  1.  2. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 1.  0. 11. 29.  0.] 
adversary cards in discard: [29. 10. 10.  3.  3.  3.  0. 10.  1. 15.  1. 29. 29. 11.  3.  0. 25. 10.
 11. 15. 25. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1] -> size -> 50 
adversary victory points: 7
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 22. 30. 24. 30.  8.  0. 10.  7.  7.  1.  2. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 1.  0. 11. 29.  0.] 
adversary cards in discard: [29. 10. 10.  3.  3.  3.  0. 10.  1. 15.  1. 29. 29. 11.  3.  0. 25. 10.
 11. 15. 25. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1] -> size -> 50 
adversary victory points: 7
player victory points: -1 





Player: 0 
cards in hand: [ 1.  0. 11. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[108.93624]
 [116.08824]
 [121.99654]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 11. 29.  0.] 
cards in discard: [29. 10. 10.  3.  3.  3.  0. 10.  1. 15.  1. 29. 29. 11.  3.  0. 25. 10.
 11. 15. 25. 29.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 24. 30.  8.  0. 10.  7.  7.  1.  2. 10. 10.  3. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 88.8721923828125



action possibilites: [-1. 11. 25.] 
expected returns: [[85.47855]
 [89.0971 ]
 [99.66409]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 25.] 
cards in discard: [29. 10. 10.  3.  3.  3.  0. 10.  1. 15.  1. 29. 29. 11.  3.  0. 25. 10.
 11. 15. 25. 29.  3.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1] -> size -> 50 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 22. 30. 24. 30.  8.  0. 10.  7.  7.  1.  2. 10. 10.  3. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 113.51641082763672



action possibilites: [-1] 
expected returns: [[141.84798]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0. 29.] 
cards in discard: [29. 10. 10.  3.  3.  3.  0. 10.  1. 15.  1. 29. 29. 11.  3.  0. 25. 10.
 11. 15. 25. 29.  3.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1] -> size -> 50 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 22. 30. 24. 30.  8.  0. 10.  7.  7.  1.  2. 10. 10.  3. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 99.66412353515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[135.5432 ]
 [147.92953]
 [140.26917]
 [148.83917]
 [145.05069]
 [139.83534]
 [151.91248]
 [115.10776]
 [141.29793]
 [134.19212]
 [141.84796]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0. 29.] 
cards in discard: [29. 10. 10.  3.  3.  3.  0. 10.  1. 15.  1. 29. 29. 11.  3.  0. 25. 10.
 11. 15. 25. 29.  3.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1] -> size -> 50 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 22. 30. 24. 30.  8.  0. 10.  7.  7.  1.  2. 10. 10.  3. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action -1
Learning step: 0
desired expected reward: 141.8479766845703



buy possibilites: [-1] 
expected returns: [[101.70319]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0. 29.] 
cards in discard: [29. 10. 10.  3.  3.  3.  0. 10.  1. 15.  1. 29. 29. 11.  3.  0. 25. 10.
 11. 15. 25. 29.  3.  1. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 24. 30.  8.  0. 10.  7.  7.  1.  1. 10. 10.  3. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  210    0    0   40    0    0    0    0 -160    0    0
  128    0] 
sum of rewards: 213 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 151.91250610351562






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 24. 30.  8.  0. 10.  7.  7.  1.  1. 10. 10.  3. 10.  8.] 
adversary cards in hand: [25. 29. 25.  1. 25.] 
adversary cards in discard: [29. 10. 10.  3.  3.  3.  0. 10.  1. 15.  1. 29. 29. 11.  3.  0. 25. 10.
 11. 15. 25. 29.  3.  1. 29. 29. 25.  0. 11.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29] -> size -> 51 
adversary victory points: 7
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 24. 30.  8.  0. 10.  7.  7.  1.  1. 10. 10.  3. 10.  8.] 
adversary cards in hand: [25. 29. 25.  1. 25.] 
adversary cards in discard: [29. 10. 10.  3.  3.  3.  0. 10.  1. 15.  1. 29. 29. 11.  3.  0. 25. 10.
 11. 15. 25. 29.  3.  1. 29. 29. 25.  0. 11.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29] -> size -> 51 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 22. 30. 24. 30.  8.  0. 10.  7.  7.  1.  1. 10. 10.  3. 10.  8.] 
adversary cards in hand: [25. 29. 25.  1. 25.] 
adversary cards in discard: [29. 10. 10.  3.  3.  3.  0. 10.  1. 15.  1. 29. 29. 11.  3.  0. 25. 10.
 11. 15. 25. 29.  3.  1. 29. 29. 25.  0. 11.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29] -> size -> 51 
adversary victory points: 7
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 22. 30. 24. 30.  8.  0. 10.  7.  7.  1.  1. 10. 10.  3. 10.  8.] 
adversary cards in hand: [25. 29. 25.  1. 25.] 
adversary cards in discard: [29. 10. 10.  3.  3.  3.  0. 10.  1. 15.  1. 29. 29. 11.  3.  0. 25. 10.
 11. 15. 25. 29.  3.  1. 29. 29. 25.  0. 11.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29] -> size -> 51 
adversary victory points: 7
player victory points: 0 





Player: 0 
cards in hand: [25. 29. 25.  1. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25. 25.] 
expected returns: [[82.77446]
 [96.71069]
 [93.88248]
 [96.71069]
 [96.71069]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 25.  1. 25.] 
cards in discard: [29. 10. 10.  3.  3.  3.  0. 10.  1. 15.  1. 29. 29. 11.  3.  0. 25. 10.
 11. 15. 25. 29.  3.  1. 29. 29. 25.  0. 11.  0.  0. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 22. 30. 24. 30.  8.  0. 10.  7.  7.  1.  1. 10. 10.  3. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 101.70319366455078



action possibilites: [-1] 
expected returns: [[54.341743]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  1. 25. 29.  0.] 
cards in discard: [29. 10. 10.  3.  3.  3.  0. 10.  1. 15.  1. 29. 29. 11.  3.  0. 25. 10.
 11. 15. 25. 29.  3.  1. 29. 29. 25.  0. 11.  0.  0. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 22. 30. 24. 30.  8.  0. 10.  7.  7.  1.  1. 10. 10.  3. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 96.71074676513672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[48.9424  ]
 [63.75721 ]
 [59.634926]
 [65.338806]
 [55.369827]
 [62.38951 ]
 [54.34176 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 25.  1. 25. 29.  0.] 
cards in discard: [29. 10. 10.  3.  3.  3.  0. 10.  1. 15.  1. 29. 29. 11.  3.  0. 25. 10.
 11. 15. 25. 29.  3.  1. 29. 29. 25.  0. 11.  0.  0. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29] -> size -> 51 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 22. 30. 24. 30.  8.  0. 10.  7.  7.  1.  1. 10. 10.  3. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 54.34174346923828



buy possibilites: [-1] 
expected returns: [[89.871635]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 25.  1. 25. 29.  0.] 
cards in discard: [29. 10. 10.  3.  3.  3.  0. 10.  1. 15.  1. 29. 29. 11.  3.  0. 25. 10.
 11. 15. 25. 29.  3.  1. 29. 29. 25.  0. 11.  0.  0. 29. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29 11] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 22. 30. 24. 30.  8.  0. 10.  6.  7.  1.  1. 10. 10.  3. 10.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  210    0    0   20    0    0    0    0 -170    0    0
   54    0] 
sum of rewards: 109 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 65.33880615234375






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 22. 30. 24. 30.  8.  0. 10.  6.  7.  1.  1. 10. 10.  3. 10.  8.] 
adversary cards in hand: [25.  3.  1.  1. 10.] 
adversary cards in discard: [29. 10. 10.  3.  3.  3.  0. 10.  1. 15.  1. 29. 29. 11.  3.  0. 25. 10.
 11. 15. 25. 29.  3.  1. 29. 29. 25.  0. 11.  0.  0. 29. 11. 25. 29. 25.
  1. 25. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29 11] -> size -> 52 
adversary victory points: 7
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 22. 30. 24. 30.  8.  0. 10.  6.  7.  1.  1. 10. 10.  3. 10.  8.] 
adversary cards in hand: [25.  3.  1.  1. 10.] 
adversary cards in discard: [29. 10. 10.  3.  3.  3.  0. 10.  1. 15.  1. 29. 29. 11.  3.  0. 25. 10.
 11. 15. 25. 29.  3.  1. 29. 29. 25.  0. 11.  0.  0. 29. 11. 25. 29. 25.
  1. 25. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29 11] -> size -> 52 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 22. 30. 24. 30.  8.  0. 10.  6.  7.  1.  1. 10. 10.  3. 10.  8.] 
adversary cards in hand: [25.  3.  1.  1. 10.] 
adversary cards in discard: [29. 10. 10.  3.  3.  3.  0. 10.  1. 15.  1. 29. 29. 11.  3.  0. 25. 10.
 11. 15. 25. 29.  3.  1. 29. 29. 25.  0. 11.  0.  0. 29. 11. 25. 29. 25.
  1. 25. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29 11] -> size -> 52 
adversary victory points: 7
player victory points: 0 





Player: 0 
cards in hand: [25.  3.  1.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
expected returns: [[110.48018]
 [126.94875]
 [113.31985]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  1.  1. 10.] 
cards in discard: [29. 10. 10.  3.  3.  3.  0. 10.  1. 15.  1. 29. 29. 11.  3.  0. 25. 10.
 11. 15. 25. 29.  3.  1. 29. 29. 25.  0. 11.  0.  0. 29. 11. 25. 29. 25.
  1. 25. 29.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29 11] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 22. 30. 24. 30.  8.  0. 10.  6.  7.  1.  1. 10. 10.  3. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 89.87163543701172



action possibilites: [-1] 
expected returns: [[137.9803]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  1. 10.  1.  0.] 
cards in discard: [29. 10. 10.  3.  3.  3.  0. 10.  1. 15.  1. 29. 29. 11.  3.  0. 25. 10.
 11. 15. 25. 29.  3.  1. 29. 29. 25.  0. 11.  0.  0. 29. 11. 25. 29. 25.
  1. 25. 29.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29 11] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 22. 30. 24. 30.  8.  0. 10.  6.  7.  1.  1. 10. 10.  3. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 126.94879913330078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[131.91975 ]
 [144.3364  ]
 [128.89528 ]
 [138.0011  ]
 [119.02751 ]
 [148.32033 ]
 [144.3958  ]
 [137.62637 ]
 [155.53801 ]
 [152.38489 ]
 [113.566345]
 [142.22351 ]
 [141.30156 ]
 [125.936   ]
 [133.46614 ]
 [137.98032 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  1. 10.  1.  0.] 
cards in discard: [29. 10. 10.  3.  3.  3.  0. 10.  1. 15.  1. 29. 29. 11.  3.  0. 25. 10.
 11. 15. 25. 29.  3.  1. 29. 29. 25.  0. 11.  0.  0. 29. 11. 25. 29. 25.
  1. 25. 29.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29 11] -> size -> 52 
action values: 0 
buys: 1 
player value: 7 
card supply: [17. 22. 30. 24. 30.  8.  0. 10.  6.  7.  1.  1. 10. 10.  3. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 137.9803009033203



buy possibilites: [-1] 
expected returns: [[147.2423]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  1. 10.  1.  0.] 
cards in discard: [29. 10. 10.  3.  3.  3.  0. 10.  1. 15.  1. 29. 29. 11.  3.  0. 25. 10.
 11. 15. 25. 29.  3.  1. 29. 29. 25.  0. 11.  0.  0. 29. 11. 25. 29. 25.
  1. 25. 29.  0. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29 11 25] -> size -> 53 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 22. 30. 24. 30.  8.  0. 10.  6.  7.  0.  1. 10. 10.  3. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[  -5.     0.     0.   210.     0.     0.    20.     0.     0.     0.
    0.  -180.     0.     0.    62.5    0. ] 
sum of rewards: 107.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 155.53805541992188






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 22. 30. 24. 30.  8.  0. 10.  6.  7.  0.  1. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 1. 25.  3. 25. 10.] 
adversary cards in discard: [29. 10. 10.  3.  3.  3.  0. 10.  1. 15.  1. 29. 29. 11.  3.  0. 25. 10.
 11. 15. 25. 29.  3.  1. 29. 29. 25.  0. 11.  0.  0. 29. 11. 25. 29. 25.
  1. 25. 29.  0. 25. 25.  3.  1.  1. 10.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29 11 25] -> size -> 53 
adversary victory points: 7
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 22. 30. 24. 30.  8.  0. 10.  6.  7.  0.  1. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 1. 25.  3. 25. 10.] 
adversary cards in discard: [29. 10. 10.  3.  3.  3.  0. 10.  1. 15.  1. 29. 29. 11.  3.  0. 25. 10.
 11. 15. 25. 29.  3.  1. 29. 29. 25.  0. 11.  0.  0. 29. 11. 25. 29. 25.
  1. 25. 29.  0. 25. 25.  3.  1.  1. 10.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29 11 25] -> size -> 53 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 22. 30. 24. 30.  8.  0. 10.  6.  7.  0.  1. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 1. 25.  3. 25. 10.] 
adversary cards in discard: [29. 10. 10.  3.  3.  3.  0. 10.  1. 15.  1. 29. 29. 11.  3.  0. 25. 10.
 11. 15. 25. 29.  3.  1. 29. 29. 25.  0. 11.  0.  0. 29. 11. 25. 29. 25.
  1. 25. 29.  0. 25. 25.  3.  1.  1. 10.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29 11 25] -> size -> 53 
adversary victory points: 7
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 22. 30. 24. 30.  8.  0. 10.  6.  7.  0.  1. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 1. 25.  3. 25. 10.] 
adversary cards in discard: [29. 10. 10.  3.  3.  3.  0. 10.  1. 15.  1. 29. 29. 11.  3.  0. 25. 10.
 11. 15. 25. 29.  3.  1. 29. 29. 25.  0. 11.  0.  0. 29. 11. 25. 29. 25.
  1. 25. 29.  0. 25. 25.  3.  1.  1. 10.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29 11 25] -> size -> 53 
adversary victory points: 7
player victory points: 0 





Player: 0 
cards in hand: [ 1. 25.  3. 25. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 10.] 
expected returns: [[67.81958]
 [92.05038]
 [92.05038]
 [70.53641]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25.  3. 25. 10.] 
cards in discard: [29. 10. 10.  3.  3.  3.  0. 10.  1. 15.  1. 29. 29. 11.  3.  0. 25. 10.
 11. 15. 25. 29.  3.  1. 29. 29. 25.  0. 11.  0.  0. 29. 11. 25. 29. 25.
  1. 25. 29.  0. 25. 25.  3.  1.  1. 10.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29 11 25] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 22. 30. 24. 30.  8.  0. 10.  6.  7.  0.  1. 10. 10.  3. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 147.24229431152344



action possibilites: [-1] 
expected returns: [[74.40926]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 25. 10. 15.  3.] 
cards in discard: [] 
cards in deck: 46 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29 11 25] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 22. 30. 24. 30.  8.  0. 10.  6.  7.  0.  1. 10. 10.  3. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 92.05036163330078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[71.42187 ]
 [77.86387 ]
 [77.216   ]
 [75.340034]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 25. 10. 15.  3.] 
cards in discard: [] 
cards in deck: 46 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29 11 25] -> size -> 53 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 22. 30. 24. 30.  8.  0. 10.  6.  7.  0.  1. 10. 10.  3. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 74.40926361083984



buy possibilites: [-1] 
expected returns: [[83.99041]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 25. 10. 15.  3.] 
cards in discard: [3.] 
cards in deck: 46 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29 11 25  3] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 22. 30. 23. 30.  8.  0. 10.  6.  7.  0.  1. 10. 10.  3. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[  -5    0    0  240    0    0   20    0    0    0    0 -190    0    0
   16    0] 
sum of rewards: 81 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 77.86387634277344






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 22. 30. 23. 30.  8.  0. 10.  6.  7.  0.  1. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 0.  0. 10.  3. 29.] 
adversary cards in discard: [ 3. 25.  1.  3. 25. 10. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29 11 25  3] -> size -> 54 
adversary victory points: 8
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 22. 30. 23. 30.  8.  0. 10.  6.  7.  0.  1. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 0.  0. 10.  3. 29.] 
adversary cards in discard: [ 3. 25.  1.  3. 25. 10. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29 11 25  3] -> size -> 54 
adversary victory points: 8
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 22. 30. 23. 30.  8.  0. 10.  6.  7.  0.  1. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 0.  0. 10.  3. 29.] 
adversary cards in discard: [ 3. 25.  1.  3. 25. 10. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29 11 25  3] -> size -> 54 
adversary victory points: 8
player victory points: 0 





Player: 0 
cards in hand: [ 0.  0. 10.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[56.046364]
 [58.94815 ]
 [68.959694]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3. 29.] 
cards in discard: [ 3. 25.  1.  3. 25. 10. 15.  3.] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29 11 25  3] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 22. 30. 23. 30.  8.  0. 10.  6.  7.  0.  1. 10. 10.  3. 10.  8.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 83.99040985107422



action possibilites: [-1. 10. 25.] 
expected returns: [[56.41019 ]
 [60.054848]
 [73.85376 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 25.] 
cards in discard: [ 3. 25.  1.  3. 25. 10. 15.  3.  0.  0.] 
cards in deck: 40 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29 11 25  3] -> size -> 54 
action values: 1 
buys: 0 
player value: 1 
card supply: [15. 22. 30. 23. 30.  8.  0. 10.  6.  7.  0.  1. 10. 10.  3. 10.  8.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 62.795753479003906



action possibilites: [-1] 
expected returns: [[105.75675]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 29. 29.] 
cards in discard: [ 3. 25.  1.  3. 25. 10. 15.  3.  0.  0.] 
cards in deck: 38 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29 11 25  3] -> size -> 54 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 22. 30. 23. 30.  8.  0. 10.  6.  7.  0.  1. 10. 10.  3. 10.  8.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 73.85379028320312





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 99.35113]
 [106.10091]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 29. 29.] 
cards in discard: [ 3. 25.  1.  3. 25. 10. 15.  3.  0.  0.] 
cards in deck: 38 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29 11 25  3] -> size -> 54 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 22. 30. 23. 30.  8.  0. 10.  6.  7.  0.  1. 10. 10.  3. 10.  8.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1
Learning step: 0
desired expected reward: 105.75675201416016






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 22. 30. 23. 30.  8.  0. 10.  6.  7.  0.  1. 10. 10.  3. 10.  8.] 
adversary cards in hand: [29.  1.  0.  0. 10.] 
adversary cards in discard: [ 3. 25.  1.  3. 25. 10. 15.  3.  0.  0. 29. 25. 10.  3. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29 11 25  3] -> size -> 54 
adversary victory points: 8
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 22. 30. 23. 30.  8.  0. 10.  6.  7.  0.  1. 10. 10.  3. 10.  8.] 
adversary cards in hand: [29.  1.  0.  0. 10.] 
adversary cards in discard: [ 3. 25.  1.  3. 25. 10. 15.  3.  0.  0. 29. 25. 10.  3. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29 11 25  3] -> size -> 54 
adversary victory points: 8
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 8] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 22. 30. 23. 30.  8.  0. 10.  6.  6.  0.  1. 10. 10.  3. 10.  8.] 
adversary cards in hand: [29.  1.  0.  0. 10.] 
adversary cards in discard: [ 3. 25.  1.  3. 25. 10. 15.  3.  0.  0. 29. 25. 10.  3. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29 11 25  3] -> size -> 54 
adversary victory points: 8
player victory points: 0 





Player: 0 
cards in hand: [29.  1.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[111.640274]
 [123.16772 ]
 [113.41457 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  0.  0. 10.] 
cards in discard: [ 3. 25.  1.  3. 25. 10. 15.  3.  0.  0. 29. 25. 10.  3. 29. 29.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29 11 25  3] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 22. 30. 23. 30.  8.  0. 10.  6.  6.  0.  1. 10. 10.  3. 10.  8.] 
adversary cards in hand: [0. 8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8] -> size -> 4 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 106.10093688964844



action possibilites: [-1. 10. 29.] 
expected returns: [[105.20718 ]
 [107.705894]
 [117.78835 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10. 29.] 
cards in discard: [ 3. 25.  1.  3. 25. 10. 15.  3.  0.  0. 29. 25. 10.  3. 29. 29.  0.  0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29 11 25  3] -> size -> 54 
action values: 1 
buys: 0 
player value: 1 
card supply: [15. 22. 30. 23. 30.  8.  0. 10.  6.  6.  0.  1. 10. 10.  3. 10.  8.] 
adversary cards in hand: [0. 8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8] -> size -> 4 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 119.0843734741211



action possibilites: [-1. 10.] 
expected returns: [[159.04012]
 [160.5491 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [ 3. 25.  1.  3. 25. 10. 15.  3.  0.  0. 29. 25. 10.  3. 29. 29.  0.  0.
  1. 10.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29 11 25  3] -> size -> 54 
action values: 1 
buys: 0 
player value: 2 
card supply: [15. 22. 30. 23. 30.  8.  0. 10.  6.  6.  0.  1. 10. 10.  3. 10.  8.] 
adversary cards in hand: [0. 8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8] -> size -> 4 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 110.66080474853516



action possibilites: [-1. 11.] 
expected returns: [[157.84404]
 [163.84227]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [ 3. 25.  1.  3. 25. 10. 15.  3.  0.  0. 29. 25. 10.  3. 29. 29.  0.  0.
  1. 10.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29. 29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29 11 25  3] -> size -> 54 
action values: 2 
buys: 0 
player value: 2 
card supply: [15. 22. 30. 23. 30.  8.  0. 10.  6.  6.  0.  1. 10. 10.  3. 10.  8.] 
adversary cards in hand: [0. 8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8] -> size -> 4 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 160.5491180419922



action possibilites: [-1.] 
expected returns: [[151.68976]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 3. 25.  1.  3. 25. 10. 15.  3.  0.  0. 29. 25. 10.  3. 29. 29.  0.  0.
  1. 10. 15.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29. 29. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29 11 25  3 15] -> size -> 55 
action values: 1 
buys: 0 
player value: 2 
card supply: [15. 22. 30. 23. 30.  8.  0. 10.  6.  6.  0.  1. 10. 10.  3. 10.  7.] 
adversary cards in hand: [0. 8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8] -> size -> 4 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[  -5    0    0  240    0    0   80    0    0    0    0 -200    0    0
   64    0] 
sum of rewards: 179 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 166.53228759765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[146.8671 ]
 [152.95917]
 [151.25839]
 [151.68979]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3. 25.  1.  3. 25. 10. 15.  3.  0.  0. 29. 25. 10.  3. 29. 29.  0.  0.
  1. 10. 15.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29. 29. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29 11 25  3 15] -> size -> 55 
action values: 1 
buys: 1 
player value: 2 
card supply: [15. 22. 30. 23. 30.  8.  0. 10.  6.  6.  0.  1. 10. 10.  3. 10.  7.] 
adversary cards in hand: [0. 8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8] -> size -> 4 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 151.68975830078125



buy possibilites: [-1] 
expected returns: [[54.08557]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3. 25.  1.  3. 25. 10. 15.  3.  0.  0. 29. 25. 10.  3. 29. 29.  0.  0.
  1. 10. 15.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29. 29. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29 11 25  3 15  3] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 22. 30. 22. 30.  8.  0. 10.  6.  6.  0.  1. 10. 10.  3. 10.  7.] 
adversary cards in hand: [0. 8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 8] -> size -> 4 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  270    0    0   80    0    0    0    0 -210    0    0
   16    0] 
sum of rewards: 151 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 152.95916748046875






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [0. 8. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 8] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 22. 30. 22. 30.  8.  0. 10.  6.  6.  0.  1. 10. 10.  3. 10.  7.] 
adversary cards in hand: [ 0.  1.  1.  3. 11.] 
adversary cards in discard: [ 3. 25.  1.  3. 25. 10. 15.  3.  0.  0. 29. 25. 10.  3. 29. 29.  0.  0.
  1. 10. 15.  3. 29. 29. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29 11 25  3 15  3] -> size -> 56 
adversary victory points: 9
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 8] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 22. 30. 22. 30.  8.  0. 10.  6.  6.  0.  1. 10. 10.  3. 10.  7.] 
adversary cards in hand: [ 0.  1.  1.  3. 11.] 
adversary cards in discard: [ 3. 25.  1.  3. 25. 10. 15.  3.  0.  0. 29. 25. 10.  3. 29. 29.  0.  0.
  1. 10. 15.  3. 29. 29. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29 11 25  3 15  3] -> size -> 56 
adversary victory points: 9
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 8] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 22. 30. 22. 30.  8.  0. 10.  6.  6.  0.  1. 10. 10.  3. 10.  7.] 
adversary cards in hand: [ 0.  1.  1.  3. 11.] 
adversary cards in discard: [ 3. 25.  1.  3. 25. 10. 15.  3.  0.  0. 29. 25. 10.  3. 29. 29.  0.  0.
  1. 10. 15.  3. 29. 29. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29 11 25  3 15  3] -> size -> 56 
adversary victory points: 9
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 8 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 22. 30. 22. 30.  8.  0. 10.  6.  6.  0.  1. 10. 10.  3. 10.  7.] 
adversary cards in hand: [ 0.  1.  1.  3. 11.] 
adversary cards in discard: [ 3. 25.  1.  3. 25. 10. 15.  3.  0.  0. 29. 25. 10.  3. 29. 29.  0.  0.
  1. 10. 15.  3. 29. 29. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29 11 25  3 15  3] -> size -> 56 
adversary victory points: 9
player victory points: 0 





Player: 0 
cards in hand: [ 0.  1.  1.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[101.20762]
 [105.71896]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  1.  3. 11.] 
cards in discard: [ 3. 25.  1.  3. 25. 10. 15.  3.  0.  0. 29. 25. 10.  3. 29. 29.  0.  0.
  1. 10. 15.  3. 29. 29. 10. 11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29 11 25  3 15  3] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 22. 30. 22. 30.  8.  0. 10.  6.  6.  0.  1. 10. 10.  3. 10.  7.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 8 0] -> size -> 3 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 54.0855712890625



action possibilites: [-1] 
expected returns: [[125.04746]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 1. 3.] 
cards in discard: [ 3. 25.  1.  3. 25. 10. 15.  3.  0.  0. 29. 25. 10.  3. 29. 29.  0.  0.
  1. 10. 15.  3. 29. 29. 10. 11. 15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29 11 25  3 15  3 15] -> size -> 57 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 22. 30. 22. 30.  8.  0. 10.  6.  6.  0.  1. 10. 10.  3. 10.  6.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 8 0] -> size -> 3 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  270    0    0   20    0    0    0    0 -220    0    0
   64    0] 
sum of rewards: 129 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 108.75891876220703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[118.70383]
 [130.26787]
 [125.08468]
 [107.01757]
 [133.51732]
 [129.8916 ]
 [122.87496]
 [137.54239]
 [101.10454]
 [129.1175 ]
 [127.38145]
 [112.95802]
 [120.93618]
 [125.04746]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1. 3.] 
cards in discard: [ 3. 25.  1.  3. 25. 10. 15.  3.  0.  0. 29. 25. 10.  3. 29. 29.  0.  0.
  1. 10. 15.  3. 29. 29. 10. 11. 15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29 11 25  3 15  3 15] -> size -> 57 
action values: 0 
buys: 1 
player value: 5 
card supply: [14. 22. 30. 22. 30.  8.  0. 10.  6.  6.  0.  1. 10. 10.  3. 10.  6.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 8 0] -> size -> 3 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 125.0474624633789



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 7 
Gold: 0 
Estate: 6 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 3 
Chapel: 0 
Witch: 10 
Poacher: 10 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [0. 1. 1. 3.] 
cards in discard: [ 3. 25.  1.  3. 25. 10. 15.  3.  0.  0. 29. 25. 10.  3. 29. 29.  0.  0.
  1. 10. 15.  3. 29. 29. 10. 11. 15. 29.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 29 10 11 10 25 29 10  1  1
 29 10 29 10 25  3 25 25 10  1 25 25  1  3  1 25 29  3 15  1 25  3  1 25
 15  1 29 11 25  3 15  3 15 29] -> size -> 58 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 22. 30. 22. 30.  8.  0. 10.  6.  6.  0.  0. 10. 10.  3. 10.  6.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 8 0] -> size -> 3 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[     -5 3000000       0     270       0       0      20       0       0
       0       0    -230       0       0      64       0] 
sum of rewards: 3000119 

action type: buy - action 29.0
Learning step: 119999.2578125
desired expected reward: 120136.796875



