 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[33.261562]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0      -30        0        0        0        0
        0        0        0     -100        0        0        8        0] 
sum of rewards: -3000127 

action type: buy - action 8.0
Learning step: -119998.8046875
desired expected reward: -120155.59375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 27.698887]
 [ 46.222115]
 [ 39.099495]
 [-40.78505 ]
 [ 46.177956]
 [ 33.651623]
 [ 40.382164]
 [ 32.193165]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 33.0817756652832



buy possibilites: [-1] 
expected returns: [[34.201115]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 46.22212600708008






Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [1. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [1. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [1. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[37.77852]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [1. 0. 0. 0. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [3. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 34.201114654541016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 32.17957 ]
 [ 51.04886 ]
 [ 44.804703]
 [-41.172318]
 [ 50.599655]
 [ 52.14942 ]
 [ 37.60575 ]
 [ 59.72072 ]
 [ 11.590311]
 [ 46.205605]
 [ 40.43309 ]
 [ 36.069157]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [1. 0. 0. 0. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [3. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 37.323829650878906



buy possibilites: [-1] 
expected returns: [[19.069399]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 1.  0.  0.  0.  3.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [3. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 93 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 59.720733642578125






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [3. 3. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [3. 3. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[33.532555]
 [61.033127]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 29.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 19.069398880004883



action possibilites: [-1.] 
expected returns: [[21.745472]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 60.210166931152344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 15.008213 ]
 [ 33.06749  ]
 [ 25.107693 ]
 [ -8.4647875]
 [-65.08113  ]
 [ 33.98021  ]
 [ 33.373497 ]
 [ 21.384068 ]
 [ 46.07185  ]
 [ 41.123222 ]
 [-15.672924 ]
 [ 29.204796 ]
 [ 27.225353 ]
 [  3.362492 ]
 [ 19.563902 ]
 [ 20.650335 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 21.745471954345703



buy possibilites: [-1] 
expected returns: [[35.525345]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 235 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 46.07185363769531






Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 1.] 
adversary cards in discard: [25. 29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 1.] 
adversary cards in discard: [25. 29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 1.] 
adversary cards in discard: [25. 29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[15.93203]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 1.] 
cards in discard: [25. 29.  0.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [1. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 1] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 35.52534484863281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 10.651861]
 [ 31.813889]
 [ 21.754805]
 [-44.162666]
 [ 35.955826]
 [ 33.756348]
 [ 21.933405]
 [ 44.13427 ]
 [ -7.82272 ]
 [ 29.678871]
 [ 22.268538]
 [ 19.161304]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 1.] 
cards in discard: [25. 29.  0.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [1. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 1] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 15.604501724243164



buy possibilites: [-1] 
expected returns: [[23.506283]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 1.] 
cards in discard: [25. 29.  0.  0.  3.  0.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10. 10.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [1. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 1] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 93 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 44.13426208496094






Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [1. 3. 0. 0. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10. 10.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29] -> size -> 14 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [1. 3. 0. 0. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 1] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10. 10.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29] -> size -> 14 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [1. 3. 0. 0. 3. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 1 3] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 28. 30.  8. 10. 10. 10. 10.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29] -> size -> 14 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [25.  3. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[13.485804]
 [36.449028]
 [36.248314]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8. 10. 10. 10. 10.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 1 3] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 23.506282806396484



action possibilites: [-1] 
expected returns: [[51.889782]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  9. 10. 10. 10.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 1. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 1 3 6] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 36.64936828613281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 46.126328]
 [ 63.790955]
 [ 55.50076 ]
 [-19.073856]
 [ 59.581093]
 [ 50.615364]
 [ 54.811565]
 [ 49.078304]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  0.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 28. 30.  8.  9. 10. 10. 10.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 1. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 1 3 6] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 51.8897819519043



buy possibilites: [-1] 
expected returns: [[45.441532]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  0.  0. 29.  0.] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 28. 30.  8.  9. 10. 10. 10.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 1. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 1 3 6] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 9 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 63.790977478027344






Player: 1 
cards in hand: [0. 3. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 1. 0.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 1 3 6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 28. 30.  8.  9. 10. 10. 10.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 1. 25.  3. 29.  0.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 1. 0.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 1 3 6] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 27. 30. 28. 30.  8.  9. 10. 10. 10.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 1. 25.  3. 29.  0.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1] -> size -> 15 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 1. 0.] 
cards in discard: [ 6. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  6 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 28. 30.  8.  9. 10. 10. 10.  9.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 1. 25.  3. 29.  0.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1] -> size -> 15 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-1.278708]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 1. 25.  3. 29.  0.  0. 29.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 28. 30.  8.  9. 10. 10. 10.  9.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 6. 29.  0.  3.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  6 29] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 45.441532135009766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ -3.5011132]
 [ 14.580975 ]
 [  6.821567 ]
 [-65.09     ]
 [ 17.170208 ]
 [  4.3737483]
 [ 11.429951 ]
 [  0.1754098]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 1. 25.  3. 29.  0.  0. 29.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 27. 30. 28. 30.  8.  9. 10. 10. 10.  9.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 6. 29.  0.  3.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  6 29] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -4.812116622924805



buy possibilites: [-1] 
expected returns: [[35.54831]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 1. 25.  3. 29.  0.  0. 29.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 28. 30.  8.  9. 10.  9. 10.  9.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 6. 29.  0.  3.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  6 29] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0  54   0] 
sum of rewards: 19 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 17.170217514038086






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 6. 29.  0.  3.  3.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  6 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 28. 30.  8.  9. 10.  9. 10.  9.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  1.  3.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11] -> size -> 16 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 6. 29.  0.  3.  3.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  6 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 27. 30. 28. 30.  8.  9. 10.  9. 10.  9.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  1.  3.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11] -> size -> 16 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 6. 29.  0.  3.  3.  1.  0. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  6 29 14] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 28. 30.  8.  9. 10.  9. 10.  9.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [29.  1.  3.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11] -> size -> 16 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [29.  1.  3.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 1.0497184]
 [22.049053 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  3.  1.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 28. 30.  8.  9. 10.  9. 10.  9.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 6. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  6 29 14] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 35.548309326171875



action possibilites: [-1.] 
expected returns: [[-2.0359793]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 28. 30.  8.  9. 10.  9. 10.  9.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 6. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  6 29 14] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 22.470977783203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ -4.920529  ]
 [  9.811687  ]
 [ -9.62977   ]
 [  1.9190888 ]
 [-19.727722  ]
 [-71.422615  ]
 [ 11.456949  ]
 [  8.675091  ]
 [  0.94203424]
 [ 21.42676   ]
 [ 17.887653  ]
 [-26.368393  ]
 [  6.2322955 ]
 [  4.2830005 ]
 [-13.118237  ]
 [ -2.8419044 ]
 [ -0.97430086]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 7 
card supply: [30. 27. 30. 28. 30.  8.  9. 10.  9. 10.  9.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 6. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  6 29 14] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -2.0359792709350586



buy possibilites: [-1] 
expected returns: [[18.11567]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1. 0. 0.] 
cards in discard: [25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 27. 30. 28. 30.  8.  9. 10.  9. 10.  8.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 6. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  6 29 14] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  -30.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 47.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 21.426776885986328






Player: 1 
cards in hand: [0. 6. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  6 29 14] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 28. 30.  8.  9. 10.  9. 10.  8.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  3. 11.] 
adversary cards in discard: [25. 29.  1.  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25] -> size -> 17 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  6 29 14] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 27. 30. 28. 30.  8.  9. 10.  9. 10.  8.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  3. 11.] 
adversary cards in discard: [25. 29.  1.  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25] -> size -> 17 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 3. 0.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  6 29 14  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 27. 30. 28. 30.  8.  9. 10.  9. 10.  8.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  3. 11.] 
adversary cards in discard: [25. 29.  1.  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25] -> size -> 17 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 25.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[45.111816]
 [70.121704]
 [62.07994 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.  3. 11.] 
cards in discard: [25. 29.  1.  3.  1.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8.  9. 10.  9. 10.  8.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 29.  3.] 
adversary cards in discard: [0. 0. 6. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  6 29 14  0] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 18.11566925048828



action possibilites: [-1] 
expected returns: [[0.2183342]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 11.  0.  0.] 
cards in discard: [25. 29.  1.  3.  1.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8.  8. 10.  9. 10.  8.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 29.  3.] 
adversary cards in discard: [0. 0. 6. 3. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  6 29 14  0  6] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 69.60382080078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[  0.35728502]
 [ 14.880484  ]
 [  7.0194755 ]
 [-71.836205  ]
 [ 16.183613  ]
 [ 14.36875   ]
 [  5.4127746 ]
 [ 22.24438   ]
 [-26.204657  ]
 [ 10.14222   ]
 [  3.212153  ]
 [  1.5943427 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 11.  0.  0.] 
cards in discard: [25. 29.  1.  3.  1.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 27. 30. 28. 30.  8.  8. 10.  9. 10.  8.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 29.  3.] 
adversary cards in discard: [0. 0. 6. 3. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  6 29 14  0  6] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 0.21833419799804688



buy possibilites: [-1] 
expected returns: [[33.04035]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 11.  0.  0.] 
cards in discard: [25. 29.  1.  3.  1.  0.  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8.  8. 10.  9. 10.  8.  6.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 29.  3.] 
adversary cards in discard: [0. 0. 6. 3. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  6 29 14  0  6] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 113 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 22.244369506835938






Player: 1 
cards in hand: [ 0.  3.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 29.  3.] 
cards in discard: [0. 0. 6. 3. 3. 0. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  6 29 14  0  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8.  8. 10.  9. 10.  8.  6.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 25. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29] -> size -> 18 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 29.  3.] 
cards in discard: [0. 0. 6. 3. 3. 0. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  6 29 14  0  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 27. 30. 28. 30.  8.  8. 10.  9. 10.  8.  6.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 25. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29] -> size -> 18 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 29.  3.] 
cards in discard: [0. 0. 6. 3. 3. 0. 6. 8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  6 29 14  0  6  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8.  8. 10.  9.  9.  8.  6.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 25. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29] -> size -> 18 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 0. 25. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[-2.283782]
 [17.616085]
 [15.70714 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8.  8. 10.  9.  9.  8.  6.  9. 10. 10. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  0.  6.  3.  3.  0.  6.  8.  0.  3.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  6 29 14  0  6  8] -> size -> 19 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 33.04035186767578



action possibilites: [-1] 
expected returns: [[8.313398]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  0. 29. 25.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8.  7. 10.  9.  9.  8.  6.  9. 10. 10. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  0.  6.  3.  3.  0.  6.  8.  0.  3.  0. 29.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  6 29 14  0  6  8  6] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 17.462657928466797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[  7.3013263]
 [ 13.95956  ]
 [-72.966385 ]
 [ 13.154268 ]
 [ 10.189953 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3.  0. 29. 25.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 27. 30. 28. 30.  8.  7. 10.  9.  9.  8.  6.  9. 10. 10. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  0.  6.  3.  3.  0.  6.  8.  0.  3.  0. 29.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  6 29 14  0  6  8  6] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 8.313398361206055



buy possibilites: [-1] 
expected returns: [[26.091394]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3.  0. 29. 25.] 
cards in discard: [3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8.  7. 10.  9.  9.  8.  6.  9. 10. 10. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 0.] 
adversary cards in discard: [ 0.  0.  6.  3.  3.  0.  6.  8.  0.  3.  0. 29.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  6 29 14  0  6  8  6] -> size -> 20 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 61 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 13.959562301635742






Player: 1 
cards in hand: [1. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 0. 0.] 
cards in discard: [ 0.  0.  6.  3.  3.  0.  6.  8.  0.  3.  0. 29.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  6 29 14  0  6  8  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8.  7. 10.  9.  9.  8.  6.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 11.  3.] 
adversary cards in discard: [ 3. 25.  0. 29.  3.  0. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3] -> size -> 19 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 0.] 
cards in discard: [ 0.  0.  6.  3.  3.  0.  6.  8.  0.  3.  0. 29.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  6 29 14  0  6  8  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 27. 30. 27. 30.  8.  7. 10.  9.  9.  8.  6.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 11.  3.] 
adversary cards in discard: [ 3. 25.  0. 29.  3.  0. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3] -> size -> 19 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 0.] 
cards in discard: [ 0.  0.  6.  3.  3.  0.  6.  8.  0.  3.  0. 29.  3.  6.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  6 29 14  0  6  8  6  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 27. 30. 26. 30.  8.  7. 10.  9.  9.  8.  6.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 11.  3.] 
adversary cards in discard: [ 3. 25.  0. 29.  3.  0. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3] -> size -> 19 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 29. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[19.95561 ]
 [43.856903]
 [35.839592]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 11.  3.] 
cards in discard: [ 3. 25.  0. 29.  3.  0. 29. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 26. 30.  8.  7. 10.  9.  9.  8.  6.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  8.  0. 29. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  6 29 14  0  6  8  6  3] -> size -> 21 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 26.091394424438477



action possibilites: [-1. 11.] 
expected returns: [[22.417448]
 [37.308563]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.  0.] 
cards in discard: [ 3. 25.  0. 29.  3.  0. 29. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 27. 30. 26. 30.  8.  7. 10.  9.  9.  8.  6.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  8.  0. 29. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  6 29 14  0  6  8  6  3] -> size -> 21 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 41.80052185058594



action possibilites: [-1] 
expected returns: [[0.02357817]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 3. 25.  0. 29.  3.  0. 29. 25. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 27. 30. 26. 30.  8.  7. 10.  9.  9.  8.  6.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  8.  0. 29. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  6 29 14  0  6  8  6  3] -> size -> 21 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 92 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 36.196529388427734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ -1.5295272 ]
 [ 11.22649   ]
 [  4.929527  ]
 [-35.035805  ]
 [ 13.304699  ]
 [ 10.623898  ]
 [  2.3852    ]
 [ 18.29412   ]
 [-18.529512  ]
 [  7.473045  ]
 [  1.6301718 ]
 [ -0.39314127]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 3. 25.  0. 29.  3.  0. 29. 25. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 27. 30. 26. 30.  8.  7. 10.  9.  9.  8.  6.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  8.  0. 29. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  6 29 14  0  6  8  6  3] -> size -> 21 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 0.023578166961669922



buy possibilites: [-1] 
expected returns: [[55.50476]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 3. 25.  0. 29.  3.  0. 29. 25. 10. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 26. 30.  8.  7. 10.  9.  9.  8.  5.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  8.  0. 29. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  6 29 14  0  6  8  6  3] -> size -> 21 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  30   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 193 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 18.294132232666016






Player: 1 
cards in hand: [ 3.  8.  0. 29. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0. 29. 14.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1  3  6 29 14  0  6  8  6  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 26. 30.  8.  7. 10.  9.  9.  8.  5.  9. 10.  9. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 1.] 
adversary cards in discard: [ 3. 25.  0. 29.  3.  0. 29. 25. 10. 29. 29. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29] -> size -> 21 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 26. 30.  8.  7. 10.  9.  9.  8.  5.  9. 10.  9. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 1.] 
adversary cards in discard: [ 3. 25.  0. 29.  3.  0. 29. 25. 10. 29. 29. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29] -> size -> 21 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 27. 30. 26. 30.  8.  7. 10.  9.  9.  8.  5.  9. 10.  9. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 1.] 
adversary cards in discard: [ 3. 25.  0. 29.  3.  0. 29. 25. 10. 29. 29. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29] -> size -> 21 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.] 
cards in discard: [0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 26. 30.  8.  7. 10.  9.  9.  8.  5.  9. 10.  9. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 1.] 
adversary cards in discard: [ 3. 25.  0. 29.  3.  0. 29. 25. 10. 29. 29. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29] -> size -> 21 
adversary victory points: 4
player victory points: 2 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [1. 3. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[37.364964]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 0. 1.] 
cards in discard: [ 3. 25.  0. 29.  3.  0. 29. 25. 10. 29. 29. 11.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 26. 30.  8.  7. 10.  9.  9.  8.  5.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 1. 6. 0.] 
adversary cards in discard: [ 0.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0] -> size -> 19 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 55.5047607421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 32.455067 ]
 [ 48.95281  ]
 [ 28.331108 ]
 [ 41.497997 ]
 [ 14.040045 ]
 [-16.652039 ]
 [ 52.36979  ]
 [ 50.213753 ]
 [ 41.832554 ]
 [ 59.173355 ]
 [ 56.65655  ]
 [  9.3200035]
 [ 48.246975 ]
 [ 46.435974 ]
 [ 27.936306 ]
 [ 36.273262 ]
 [ 40.450836 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 1.] 
cards in discard: [ 3. 25.  0. 29.  3.  0. 29. 25. 10. 29. 29. 11.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29] -> size -> 21 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 27. 30. 26. 30.  8.  7. 10.  9.  9.  8.  5.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 1. 6. 0.] 
adversary cards in discard: [ 0.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0] -> size -> 19 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 37.40327072143555



buy possibilites: [-1] 
expected returns: [[58.05562]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 1.] 
cards in discard: [ 3. 25.  0. 29.  3.  0. 29. 25. 10. 29. 29. 11.  0.  0.  3.  0. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 26. 30.  8.  7. 10.  9.  9.  7.  5.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 1. 6. 0.] 
adversary cards in discard: [ 0.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0] -> size -> 19 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5.   0.   0.  60.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 117.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 59.17335510253906






Player: 1 
cards in hand: [3. 3. 1. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 1. 6. 0.] 
cards in discard: [ 0.  8. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 26. 30.  8.  7. 10.  9.  9.  7.  5.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25] -> size -> 22 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 6. 0.] 
cards in discard: [ 0.  8. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 27. 30. 26. 30.  8.  7. 10.  9.  9.  7.  5.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25] -> size -> 22 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 6. 0.] 
cards in discard: [ 0.  8. 29. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 26. 30.  8.  7. 10.  9.  9.  7.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25] -> size -> 22 
adversary victory points: 4
player victory points: 2 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[28.39159]
 [48.33726]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 26. 30.  8.  7. 10.  9.  9.  7.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 6. 3. 0.] 
adversary cards in discard: [ 0.  8. 29. 10.  3.  3.  1.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10] -> size -> 20 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 58.05561828613281



action possibilites: [-1] 
expected returns: [[22.20317]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3. 1.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 26. 30.  8.  6. 10.  9.  9.  7.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 6. 3. 0.] 
adversary cards in discard: [ 0.  8. 29. 10.  3.  3.  1.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6] -> size -> 21 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 48.05353546142578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 22.72751 ]
 [ 38.773495]
 [ 18.052109]
 [ 30.808746]
 [  8.940954]
 [-22.246923]
 [ 38.57612 ]
 [ 37.159664]
 [ 28.338207]
 [ 48.092678]
 [ 43.717934]
 [  2.367352]
 [ 32.538315]
 [ 31.493977]
 [ 14.271746]
 [ 23.941505]
 [ 26.102818]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3. 1.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25] -> size -> 22 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 27. 30. 26. 30.  8.  6. 10.  9.  9.  7.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 6. 3. 0.] 
adversary cards in discard: [ 0.  8. 29. 10.  3.  3.  1.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6] -> size -> 21 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 22.203170776367188



buy possibilites: [-1] 
expected returns: [[19.891443]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3. 1.] 
cards in discard: [25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 26. 30.  8.  6. 10.  9.  9.  6.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 6. 3. 0.] 
adversary cards in discard: [ 0.  8. 29. 10.  3.  3.  1.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6] -> size -> 21 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5.   0.   0.  60.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 137.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 48.0926628112793






Player: 1 
cards in hand: [3. 0. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 3. 0.] 
cards in discard: [ 0.  8. 29. 10.  3.  3.  1.  6.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 26. 30.  8.  6. 10.  9.  9.  6.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29. 10. 29.  3.  3.] 
adversary cards in discard: [25. 25.  0.  0.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25] -> size -> 23 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3. 0.] 
cards in discard: [ 0.  8. 29. 10.  3.  3.  1.  6.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 27. 30. 26. 30.  8.  6. 10.  9.  9.  6.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29. 10. 29.  3.  3.] 
adversary cards in discard: [25. 25.  0.  0.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25] -> size -> 23 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3. 0.] 
cards in discard: [ 0.  8. 29. 10.  3.  3.  1.  6.  0.  6.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 25. 30.  8.  6. 10.  9.  9.  6.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29. 10. 29.  3.  3.] 
adversary cards in discard: [25. 25.  0.  0.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25] -> size -> 23 
adversary victory points: 4
player victory points: 2 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [29. 10. 29.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 29.] 
expected returns: [[40.3635 ]
 [60.68357]
 [50.89955]
 [60.68357]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 29.  3.  3.] 
cards in discard: [25. 25.  0.  0.  0.  0.  3.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 25. 30.  8.  6. 10.  9.  9.  6.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 6. 0. 3.] 
adversary cards in discard: [ 0.  8. 29. 10.  3.  3.  1.  6.  0.  6.  3.  3.  0.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3] -> size -> 22 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 19.891443252563477



action possibilites: [-1. 10. 29.] 
expected returns: [[46.388035]
 [57.5552  ]
 [65.776764]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  3.  3.  0.] 
cards in discard: [25. 25.  0.  0.  0.  0.  3.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 25. 30.  8.  6. 10.  9.  9.  6.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 6. 0. 3.] 
adversary cards in discard: [ 0.  8. 29. 10.  3.  3.  1.  6.  0.  6.  3.  3.  0.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3] -> size -> 22 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 60.27783966064453



action possibilites: [-1. 10.] 
expected returns: [[50.04754 ]
 [60.618332]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3.  0.  0.] 
cards in discard: [25. 25.  0.  0.  0.  0.  3.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 27. 30. 25. 30.  8.  6. 10.  9.  9.  6.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 6. 0. 3.] 
adversary cards in discard: [ 0.  8. 29. 10.  3.  3.  1.  6.  0.  6.  3.  3.  0.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3] -> size -> 22 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 65.7767562866211



action possibilites: [-1.] 
expected returns: [[42.7759]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 1.] 
cards in discard: [25. 25.  0.  0.  0.  0.  3.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25] -> size -> 23 
action values: 2 
buys: 0 
player value: 2 
card supply: [28. 27. 30. 25. 30.  8.  6. 10.  9.  9.  6.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 6. 0. 3.] 
adversary cards in discard: [ 0.  8. 29. 10.  3.  3.  1.  6.  0.  6.  3.  3.  0.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3] -> size -> 22 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 60.61834716796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[42.176613]
 [56.092358]
 [39.701195]
 [50.691196]
 [29.625912]
 [ 5.067076]
 [57.70217 ]
 [56.661484]
 [46.828136]
 [66.425354]
 [63.21673 ]
 [24.39806 ]
 [54.978195]
 [52.33513 ]
 [37.035202]
 [45.79442 ]
 [44.807022]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 1.] 
cards in discard: [25. 25.  0.  0.  0.  0.  3.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25] -> size -> 23 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 27. 30. 25. 30.  8.  6. 10.  9.  9.  6.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 6. 0. 3.] 
adversary cards in discard: [ 0.  8. 29. 10.  3.  3.  1.  6.  0.  6.  3.  3.  0.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3] -> size -> 22 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 42.775901794433594



buy possibilites: [-1] 
expected returns: [[80.84036]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 1.] 
cards in discard: [25. 25.  0.  0.  0.  0.  3.  1. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 25. 30.  8.  6. 10.  9.  9.  5.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 6. 0. 3.] 
adversary cards in discard: [ 0.  8. 29. 10.  3.  3.  1.  6.  0.  6.  3.  3.  0.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3] -> size -> 22 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5.   0.   0.  60.   0.   0.  60.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 177.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 66.42536163330078






Player: 1 
cards in hand: [0. 0. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 3.] 
cards in discard: [ 0.  8. 29. 10.  3.  3.  1.  6.  0.  6.  3.  3.  0.  6.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 25. 30.  8.  6. 10.  9.  9.  5.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [25. 11.  0. 25. 29.] 
adversary cards in discard: [25. 25.  0.  0.  0.  0.  3.  1. 25. 29. 29. 10.  3.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25] -> size -> 24 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 3.] 
cards in discard: [ 0.  8. 29. 10.  3.  3.  1.  6.  0.  6.  3.  3.  0.  6.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 27. 30. 25. 30.  8.  6. 10.  9.  9.  5.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [25. 11.  0. 25. 29.] 
adversary cards in discard: [25. 25.  0.  0.  0.  0.  3.  1. 25. 29. 29. 10.  3.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25] -> size -> 24 
adversary victory points: 4
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [25. 11.  0. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 25. 29.] 
expected returns: [[76.63414]
 [94.64543]
 [85.49217]
 [94.64543]
 [91.96222]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11.  0. 25. 29.] 
cards in discard: [25. 25.  0.  0.  0.  0.  3.  1. 25. 29. 29. 10.  3.  3.  0.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 25. 30.  8.  6. 10.  9.  9.  5.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 6. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3] -> size -> 22 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 80.84036254882812



action possibilites: [-1] 
expected returns: [[88.45477]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 25. 29. 29.  3.] 
cards in discard: [25. 25.  0.  0.  0.  0.  3.  1. 25. 29. 29. 10.  3.  3.  0.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 25. 30.  8.  5. 10.  9.  9.  5.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 6. 0. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6] -> size -> 23 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 94.64540100097656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[86.165436]
 [32.763863]
 [89.86909 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 25. 29. 29.  3.] 
cards in discard: [25. 25.  0.  0.  0.  0.  3.  1. 25. 29. 29. 10.  3.  3.  0.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 27. 30. 25. 30.  8.  5. 10.  9.  9.  5.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 6. 0. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6] -> size -> 23 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 88.45477294921875






Player: 1 
cards in hand: [3. 6. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 3. 0.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 25. 30.  8.  5. 10.  9.  9.  5.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 29.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25] -> size -> 24 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 3. 0.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 27. 30. 25. 30.  8.  5. 10.  9.  9.  5.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 29.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25] -> size -> 24 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 3. 0.] 
cards in discard: [6. 8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 25. 30.  8.  5. 10.  9.  8.  5.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 29.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25] -> size -> 24 
adversary victory points: 4
player victory points: 1 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 29.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[21.009808]
 [35.954872]
 [35.954872]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29.  1.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 25. 30.  8.  5. 10.  9.  8.  5.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [6. 8. 3. 6. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8] -> size -> 24 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 89.86910247802734



action possibilites: [-1. 29.] 
expected returns: [[48.216866]
 [62.65399 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  1.  0.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 25. 30.  8.  5. 10.  9.  8.  5.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [6. 8. 3. 6. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8] -> size -> 24 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 35.22476577758789



action possibilites: [-1. 25.] 
expected returns: [[56.95468]
 [77.41135]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0.  3. 25.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 27. 30. 25. 30.  8.  5. 10.  9.  8.  5.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [6. 8. 3. 6. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8] -> size -> 24 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 62.65399169921875



action possibilites: [-1] 
expected returns: [[67.06202]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 27. 30. 25. 30.  8.  4. 10.  9.  8.  5.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [6. 8. 3. 6. 0. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6] -> size -> 25 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 77.41133880615234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[71.45876 ]
 [87.2885  ]
 [69.751884]
 [81.74734 ]
 [60.92846 ]
 [37.922092]
 [86.00099 ]
 [85.84565 ]
 [75.05068 ]
 [94.28216 ]
 [93.70884 ]
 [54.622025]
 [87.18749 ]
 [81.41078 ]
 [67.189735]
 [78.72033 ]
 [74.46066 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25] -> size -> 24 
action values: 0 
buys: 1 
player value: 7 
card supply: [28. 27. 30. 25. 30.  8.  4. 10.  9.  8.  5.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [6. 8. 3. 6. 0. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6] -> size -> 25 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: take_action - action -1
Learning step: 0
desired expected reward: 67.06201934814453



buy possibilites: [-1] 
expected returns: [[37.160675]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 3. 0.] 
cards in discard: [25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 27. 30. 25. 30.  8.  4. 10.  9.  8.  4.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [6. 8. 3. 6. 0. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6] -> size -> 25 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5.   0.   0.  90.   0.   0.  60.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 207.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 94.28215789794922






Player: 1 
cards in hand: [ 0.  0. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  3.] 
cards in discard: [6. 8. 3. 6. 0. 3. 0. 6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 25. 30.  8.  4. 10.  9.  8.  4.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 25. 25. 25.  3.] 
adversary cards in discard: [25. 29. 29. 25.  0.  1.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25] -> size -> 25 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  0.  3.] 
cards in discard: [6. 8. 3. 6. 0. 3. 0. 6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 27. 30. 25. 30.  8.  4. 10.  9.  8.  4.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 25. 25. 25.  3.] 
adversary cards in discard: [25. 29. 29. 25.  0.  1.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25] -> size -> 25 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  0.  3.] 
cards in discard: [6. 8. 3. 6. 0. 3. 0. 6. 8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 25. 30.  8.  4. 10.  9.  7.  4.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 25. 25. 25.  3.] 
adversary cards in discard: [25. 29. 29. 25.  0.  1.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25] -> size -> 25 
adversary victory points: 4
player victory points: 0 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 3. 25. 25. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 25.] 
expected returns: [[57.78787]
 [78.76017]
 [78.76017]
 [78.76017]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 25. 25.  3.] 
cards in discard: [25. 29. 29. 25.  0.  1.  0.  3.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 25. 30.  8.  4. 10.  9.  7.  4.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  6.  8.  0.] 
adversary cards in discard: [ 6.  8.  3.  6.  0.  3.  0.  6.  8.  0.  0. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6  8] -> size -> 26 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 37.160675048828125



action possibilites: [-1] 
expected returns: [[51.109787]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 25.  3.  0. 29.] 
cards in discard: [25. 29. 29. 25.  0.  1.  0.  3.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 25. 30.  8.  3. 10.  9.  7.  4.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  6.  8.  0.] 
adversary cards in discard: [ 6.  8.  3.  6.  0.  3.  0.  6.  8.  0.  0. 29.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6  8  6] -> size -> 27 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 78.76017761230469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[52.677025]
 [17.987156]
 [52.219193]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25. 25.  3.  0. 29.] 
cards in discard: [25. 29. 29. 25.  0.  1.  0.  3.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 27. 30. 25. 30.  8.  3. 10.  9.  7.  4.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  6.  8.  0.] 
adversary cards in discard: [ 6.  8.  3.  6.  0.  3.  0.  6.  8.  0.  0. 29.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6  8  6] -> size -> 27 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 51.10978698730469



buy possibilites: [-1] 
expected returns: [[33.031166]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25. 25.  3.  0. 29.] 
cards in discard: [25. 29. 29. 25.  0.  1.  0.  3.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 25. 30.  8.  3. 10.  9.  7.  4.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  6.  8.  0.] 
adversary cards in discard: [ 6.  8.  3.  6.  0.  3.  0.  6.  8.  0.  0. 29.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6  8  6] -> size -> 27 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   0. 120.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 135.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 52.67703628540039






Player: 1 
cards in hand: [ 0. 10.  6.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  6.  8.  0.] 
cards in discard: [ 6.  8.  3.  6.  0.  3.  0.  6.  8.  0.  0. 29.  0.  3.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6  8  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 25. 30.  8.  3. 10.  9.  7.  4.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10. 29. 11.  0. 25.] 
adversary cards in discard: [25. 29. 29. 25.  0.  1.  0.  3.  3.  0.  0. 25.  3. 25. 25.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0] -> size -> 26 
adversary victory points: 4
player victory points: -1 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8. 0. 0.] 
cards in discard: [ 6.  8.  3.  6.  0.  3.  0.  6.  8.  0.  0. 29.  0.  3.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6  8  6] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 25. 30.  8.  3. 10.  9.  7.  4.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10. 29. 11.  0. 25.] 
adversary cards in discard: [25. 29. 29. 25.  0.  1.  0.  3.  3.  0.  0. 25.  3. 25. 25.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0] -> size -> 26 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8. 0. 0.] 
cards in discard: [ 6.  8.  3.  6.  0.  3.  0.  6.  8.  0.  0. 29.  0.  3.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6  8  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 27. 30. 25. 30.  8.  3. 10.  9.  7.  4.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10. 29. 11.  0. 25.] 
adversary cards in discard: [25. 29. 29. 25.  0.  1.  0.  3.  3.  0.  0. 25.  3. 25. 25.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0] -> size -> 26 
adversary victory points: 4
player victory points: -1 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [10. 29. 11.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11. 25.] 
expected returns: [[73.92338 ]
 [80.561966]
 [90.80922 ]
 [84.34373 ]
 [91.76115 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 11.  0. 25.] 
cards in discard: [25. 29. 29. 25.  0.  1.  0.  3.  3.  0.  0. 25.  3. 25. 25.  3.  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 25. 30.  8.  3. 10.  9.  7.  4.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [6. 3. 3. 3. 6.] 
adversary cards in discard: [ 6.  8.  3.  6.  0.  3.  0.  6.  8.  0.  0. 29.  0.  3.  6. 10.  0.  6.
  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6  8  6] -> size -> 27 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 33.031166076660156



action possibilites: [-1] 
expected returns: [[13.878357]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 11.  0.  0.  1.] 
cards in discard: [25. 29. 29. 25.  0.  1.  0.  3.  3.  0.  0. 25.  3. 25. 25.  3.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 25. 30.  8.  2. 10.  9.  7.  4.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [6. 3. 3. 3. 6.] 
adversary cards in discard: [ 6.  8.  3.  6.  0.  3.  0.  6.  8.  0.  0. 29.  0.  3.  6. 10.  0.  6.
  8.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6  8  6  6] -> size -> 28 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 91.76113891601562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 16.430092 ]
 [ 30.48743  ]
 [ 21.618206 ]
 [-26.415232 ]
 [ 35.439816 ]
 [ 31.026382 ]
 [ 24.421198 ]
 [ 40.816322 ]
 [ -7.4805574]
 [ 27.712101 ]
 [ 16.51577  ]
 [ 18.324594 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29. 11.  0.  0.  1.] 
cards in discard: [25. 29. 29. 25.  0.  1.  0.  3.  3.  0.  0. 25.  3. 25. 25.  3.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 27. 30. 25. 30.  8.  2. 10.  9.  7.  4.  5.  9. 10.  8. 10. 10.] 
adversary cards in hand: [6. 3. 3. 3. 6.] 
adversary cards in discard: [ 6.  8.  3.  6.  0.  3.  0.  6.  8.  0.  0. 29.  0.  3.  6. 10.  0.  6.
  8.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6  8  6  6] -> size -> 28 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 13.87835693359375



buy possibilites: [-1] 
expected returns: [[2.5452085]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29. 11.  0.  0.  1.] 
cards in discard: [25. 29. 29. 25.  0.  1.  0.  3.  3.  0.  0. 25.  3. 25. 25.  3.  0. 29.
 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 25. 30.  8.  2. 10.  9.  7.  4.  4.  9. 10.  8. 10. 10.] 
adversary cards in hand: [6. 3. 3. 3. 6.] 
adversary cards in discard: [ 6.  8.  3.  6.  0.  3.  0.  6.  8.  0.  0. 29.  0.  3.  6. 10.  0.  6.
  8.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6  8  6  6] -> size -> 28 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 293 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 40.81633377075195






Player: 1 
cards in hand: [6. 3. 3. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 3. 6.] 
cards in discard: [ 6.  8.  3.  6.  0.  3.  0.  6.  8.  0.  0. 29.  0.  3.  6. 10.  0.  6.
  8.  0.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6  8  6  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 25. 30.  8.  2. 10.  9.  7.  4.  4.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  1. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29] -> size -> 27 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 3. 6.] 
cards in discard: [ 6.  8.  3.  6.  0.  3.  0.  6.  8.  0.  0. 29.  0.  3.  6. 10.  0.  6.
  8.  0.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6  8  6  6] -> size -> 28 
action values: 1 
buys: 1 
player value: 0 
card supply: [27. 27. 30. 25. 30.  8.  2. 10.  9.  7.  4.  4.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  1. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29] -> size -> 27 
adversary victory points: 4
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 3. 6.] 
cards in discard: [ 6.  8.  3.  6.  0.  3.  0.  6.  8.  0.  0. 29.  0.  3.  6. 10.  0.  6.
  8.  0.  0.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6  8  6  6  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 30.  8.  2. 10.  9.  7.  4.  4.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  1. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29] -> size -> 27 
adversary victory points: 4
player victory points: -2 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 0.  1. 25.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[15.162422]
 [36.54378 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 25.  3.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 30.  8.  2. 10.  9.  7.  4.  4.  9. 10.  8. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6  8  6  6  0] -> size -> 29 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 2.54520845413208



action possibilites: [-1] 
expected returns: [[4.167825]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3.  0. 25. 25.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 30.  8.  1. 10.  9.  7.  4.  4.  9. 10.  8. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6  8  6  6  0  6] -> size -> 30 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 35.16234588623047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[  2.4462514]
 [ 14.169165 ]
 [  8.031239 ]
 [-32.347137 ]
 [ 16.304037 ]
 [ 13.4636135]
 [  6.63195  ]
 [ 20.43556  ]
 [-15.667484 ]
 [ 10.380611 ]
 [  3.03715  ]
 [  5.5068345]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3.  0. 25. 25.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 27. 30. 25. 30.  8.  1. 10.  9.  7.  4.  4.  9. 10.  8. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6  8  6  6  0  6] -> size -> 30 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 4.167825222015381



buy possibilites: [-1] 
expected returns: [[-13.41158]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3.  0. 25. 25.] 
cards in discard: [29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 30.  8.  1. 10.  9.  7.  4.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6  8  6  6  0  6] -> size -> 30 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 323 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 20.4355411529541






Player: 1 
cards in hand: [8. 3. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 1.] 
cards in discard: [6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6  8  6  6  0  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 30.  8.  1. 10.  9.  7.  4.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  1.  0.  3. 25.] 
adversary cards in discard: [29. 25.  0.  1.  3.  0. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29] -> size -> 28 
adversary victory points: 4
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 1.] 
cards in discard: [6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6  8  6  6  0  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 27. 30. 25. 30.  8.  1. 10.  9.  7.  4.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  1.  0.  3. 25.] 
adversary cards in discard: [29. 25.  0.  1.  3.  0. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29] -> size -> 28 
adversary victory points: 4
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 1.] 
cards in discard: [6. 0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6  8  6  6  0  6  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 4 
card supply: [25. 27. 30. 25. 30.  8.  1. 10.  9.  7.  4.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  1.  0.  3. 25.] 
adversary cards in discard: [29. 25.  0.  1.  3.  0. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29] -> size -> 28 
adversary victory points: 4
player victory points: -3 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 0.  1.  0.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[ 3.6195407]
 [22.225714 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0.  3. 25.] 
cards in discard: [29. 25.  0.  1.  3.  0. 25. 25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 25. 30.  8.  1. 10.  9.  7.  4.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10.  0.] 
adversary cards in discard: [6. 0. 8. 3. 0. 0. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6  8  6  6  0  6  0] -> size -> 31 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: -13.411580085754395



action possibilites: [-1] 
expected returns: [[15.462408]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 3. 0. 0.] 
cards in discard: [29. 25.  0.  1.  3.  0. 25. 25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 25. 30.  8.  0. 10.  9.  7.  4.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10.  0.] 
adversary cards in discard: [6. 0. 8. 3. 0. 0. 1. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6  8  6  6  0  6  0  6] -> size -> 32 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 22.225730895996094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[15.791182 ]
 [27.803448 ]
 [12.951233 ]
 [22.797863 ]
 [-5.9756904]
 [29.131706 ]
 [28.34114  ]
 [19.69368  ]
 [36.57289  ]
 [32.822563 ]
 [-7.2577586]
 [24.946426 ]
 [24.115662 ]
 [ 7.9735723]
 [16.906866 ]
 [17.344923 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 0. 0.] 
cards in discard: [29. 25.  0.  1.  3.  0. 25. 25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29] -> size -> 28 
action values: 0 
buys: 1 
player value: 6 
card supply: [25. 27. 30. 25. 30.  8.  0. 10.  9.  7.  4.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10.  0.] 
adversary cards in discard: [6. 0. 8. 3. 0. 0. 1. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6  8  6  6  0  6  0  6] -> size -> 32 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 15.462408065795898



buy possibilites: [-1] 
expected returns: [[50.629753]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 0. 0.] 
cards in discard: [29. 25.  0.  1.  3.  0. 25. 25. 25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 25. 30.  8.  0. 10.  9.  7.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10.  0.] 
adversary cards in discard: [6. 0. 8. 3. 0. 0. 1. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6  8  6  6  0  6  0  6] -> size -> 32 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5.    0.    0.  210.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 287.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 36.57289123535156






Player: 1 
cards in hand: [ 3.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10.  0.] 
cards in discard: [6. 0. 8. 3. 0. 0. 1. 6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6  8  6  6  0  6  0  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 25. 30.  8.  0. 10.  9.  7.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29. 25. 10. 29.  0.] 
adversary cards in discard: [29. 25.  0.  1.  3.  0. 25. 25. 25. 25.  0.  1.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25] -> size -> 29 
adversary victory points: 4
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.  0.] 
cards in discard: [6. 0. 8. 3. 0. 0. 1. 6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6  8  6  6  0  6  0  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 27. 30. 25. 30.  8.  0. 10.  9.  7.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29. 25. 10. 29.  0.] 
adversary cards in discard: [29. 25.  0.  1.  3.  0. 25. 25. 25. 25.  0.  1.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25] -> size -> 29 
adversary victory points: 4
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.  0.] 
cards in discard: [6. 0. 8. 3. 0. 0. 1. 6. 0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6  8  6  6  0  6  0  6  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 27. 30. 25. 30.  8.  0. 10.  9.  7.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29. 25. 10. 29.  0.] 
adversary cards in discard: [29. 25.  0.  1.  3.  0. 25. 25. 25. 25.  0.  1.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25] -> size -> 29 
adversary victory points: 4
player victory points: -4 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [29. 25. 10. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 10. 29.] 
expected returns: [[67.723625]
 [87.22974 ]
 [86.87738 ]
 [75.12991 ]
 [87.22974 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 10. 29.  0.] 
cards in discard: [29. 25.  0.  1.  3.  0. 25. 25. 25. 25.  0.  1.  0.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 25. 30.  8.  0. 10.  9.  7.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [ 6.  0.  8.  3.  0.  0.  1.  6.  0.  3.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6  8  6  6  0  6  0  6  0] -> size -> 33 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 50.62975311279297



action possibilites: [-1. 25. 10. 29.] 
expected returns: [[62.354874]
 [79.23906 ]
 [66.72737 ]
 [76.65927 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10.  0. 29.] 
cards in discard: [29. 25.  0.  1.  3.  0. 25. 25. 25. 25.  0.  1.  0.  3.  0.  0. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 25. 30.  8.  0. 10.  9.  7.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [ 6.  0.  8.  3.  0.  0.  1.  6.  0.  3.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6  8  6  6  0  6  0  6  0] -> size -> 33 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 60.197174072265625



action possibilites: [-1] 
expected returns: [[99.13896]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29.  3. 11.] 
cards in discard: [29. 25.  0.  1.  3.  0. 25. 25. 25. 25.  0.  1.  0.  3.  0.  0. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 25. 30.  8.  0. 10.  9.  7.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [ 6.  0.  8.  3.  0.  0.  1.  6.  0.  3.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6  8  6  6  0  6  0  6  0] -> size -> 33 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 79.23905181884766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 91.20401 ]
 [ 99.74919 ]
 [ 97.443695]
 [100.22485 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 29.  3. 11.] 
cards in discard: [29. 25.  0.  1.  3.  0. 25. 25. 25. 25.  0.  1.  0.  3.  0.  0. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 27. 30. 25. 30.  8.  0. 10.  9.  7.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [ 6.  0.  8.  3.  0.  0.  1.  6.  0.  3.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6  8  6  6  0  6  0  6  0] -> size -> 33 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1
Learning step: 0
desired expected reward: 99.13896179199219






Player: 1 
cards in hand: [3. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [ 6.  0.  8.  3.  0.  0.  1.  6.  0.  3.  0.  0. 10.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6  8  6  6  0  6  0  6  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 25. 30.  8.  0. 10.  9.  7.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 29. 25. 29.] 
adversary cards in discard: [29. 25.  0.  1.  3.  0. 25. 25. 25. 25.  0.  1.  0.  3.  0.  0. 29. 29.
 25. 10.  0. 29.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25] -> size -> 29 
adversary victory points: 4
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [ 6.  0.  8.  3.  0.  0.  1.  6.  0.  3.  0.  0. 10.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6  8  6  6  0  6  0  6  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 27. 30. 25. 30.  8.  0. 10.  9.  7.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 29. 25. 29.] 
adversary cards in discard: [29. 25.  0.  1.  3.  0. 25. 25. 25. 25.  0.  1.  0.  3.  0.  0. 29. 29.
 25. 10.  0. 29.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25] -> size -> 29 
adversary victory points: 4
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [ 6.  0.  8.  3.  0.  0.  1.  6.  0.  3.  0.  0. 10.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6  8  6  6  0  6  0  6  0  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 24. 30.  8.  0. 10.  9.  7.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 29. 25. 29.] 
adversary cards in discard: [29. 25.  0.  1.  3.  0. 25. 25. 25. 25.  0.  1.  0.  3.  0.  0. 29. 29.
 25. 10.  0. 29.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25] -> size -> 29 
adversary victory points: 4
player victory points: -3 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 29. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29.] 
expected returns: [[74.66872 ]
 [87.727615]
 [88.66394 ]
 [87.727615]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29. 25. 29.] 
cards in discard: [29. 25.  0.  1.  3.  0. 25. 25. 25. 25.  0.  1.  0.  3.  0.  0. 29. 29.
 25. 10.  0. 29.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 24. 30.  8.  0. 10.  9.  7.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  3.  6.  6. 29.] 
adversary cards in discard: [ 6.  0.  8.  3.  0.  0.  1.  6.  0.  3.  0.  0. 10.  0.  3.  3.  3.  3.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6  8  6  6  0  6  0  6  0  3] -> size -> 34 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 100.22483825683594



action possibilites: [-1] 
expected returns: [[9.604626]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29. 29. 10.  3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 24. 30.  8.  0. 10.  9.  7.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  3.  6.  6. 29.] 
adversary cards in discard: [ 6.  0.  8.  3.  0.  0.  1.  6.  0.  3.  0.  0. 10.  0.  3.  3.  3.  3.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6  8  6  6  0  6  0  6  0  3] -> size -> 34 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 88.6639404296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 4.8975444]
 [10.307678 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29. 29. 10.  3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 27. 30. 24. 30.  8.  0. 10.  9.  7.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  3.  6.  6. 29.] 
adversary cards in discard: [ 6.  0.  8.  3.  0.  0.  1.  6.  0.  3.  0.  0. 10.  0.  3.  3.  3.  3.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6  8  6  6  0  6  0  6  0  3] -> size -> 34 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 9.604625701904297






Player: 1 
cards in hand: [ 8.  3.  6.  6. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  6.  6. 29.] 
cards in discard: [ 6.  0.  8.  3.  0.  0.  1.  6.  0.  3.  0.  0. 10.  0.  3.  3.  3.  3.
  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6  8  6  6  0  6  0  6  0  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 24. 30.  8.  0. 10.  9.  7.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [25. 25.  3. 11.  0.] 
adversary cards in discard: [25.  3.  0. 29. 29. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25] -> size -> 29 
adversary victory points: 4
player victory points: -3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 6.] 
cards in discard: [ 6.  0.  8.  3.  0.  0.  1.  6.  0.  3.  0.  0. 10.  0.  3.  3.  3.  3.
  0.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6  8  6  6  0  6  0  6  0  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 24. 30.  8.  0. 10.  9.  7.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [25. 25.  3. 11.  0.] 
adversary cards in discard: [25.  3.  0. 29. 29. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25] -> size -> 29 
adversary victory points: 4
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 6.] 
cards in discard: [ 6.  0.  8.  3.  0.  0.  1.  6.  0.  3.  0.  0. 10.  0.  3.  3.  3.  3.
  0.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6  8  6  6  0  6  0  6  0  3] -> size -> 34 
action values: 1 
buys: 1 
player value: 1 
card supply: [24. 27. 30. 24. 30.  8.  0. 10.  9.  7.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [25. 25.  3. 11.  0.] 
adversary cards in discard: [25.  3.  0. 29. 29. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25] -> size -> 29 
adversary victory points: 4
player victory points: -3 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [25. 25.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 11.] 
expected returns: [[-16.386087]
 [  1.27004 ]
 [  1.27004 ]
 [ -6.480356]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25.  3. 11.  0.] 
cards in discard: [25.  3.  0. 29. 29. 10.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 24. 30.  8.  0. 10.  9.  7.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [6. 6. 6. 8. 0.] 
adversary cards in discard: [ 6.  0.  8.  3.  0.  0.  1.  6.  0.  3.  0.  0. 10.  0.  3.  3.  3.  3.
  0.  0.  8. 29.  3.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6  8  6  6  0  6  0  6  0  3] -> size -> 34 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 10.307682037353516



action possibilites: [-1] 
expected returns: [[-8.323307]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3. 11.  0.  0.  0.] 
cards in discard: [25.  3.  0. 29. 29. 10.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 24. 30.  8.  0. 10.  9.  7.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [6. 6. 6. 8. 0.] 
adversary cards in discard: [ 6.  0.  8.  3.  0.  0.  1.  6.  0.  3.  0.  0. 10.  0.  3.  3.  3.  3.
  0.  0.  8. 29.  3.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6  8  6  6  0  6  0  6  0  3] -> size -> 34 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 1.2700252532958984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-12.545234 ]
 [ -2.3579826]
 [ -8.119451 ]
 [  7.338736 ]
 [ -3.8419971]
 [  9.54718  ]
 [ -7.752247 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3. 11.  0.  0.  0.] 
cards in discard: [25.  3.  0. 29. 29. 10.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 27. 30. 24. 30.  8.  0. 10.  9.  7.  3.  3.  9. 10.  8. 10. 10.] 
adversary cards in hand: [6. 6. 6. 8. 0.] 
adversary cards in discard: [ 6.  0.  8.  3.  0.  0.  1.  6.  0.  3.  0.  0. 10.  0.  3.  3.  3.  3.
  0.  0.  8. 29.  3.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6  8  6  6  0  6  0  6  0  3] -> size -> 34 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: -8.323307037353516



buy possibilites: [-1] 
expected returns: [[44.28853]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3. 11.  0.  0.  0.] 
cards in discard: [25.  3.  0. 29. 29. 10.  3. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 24. 30.  8.  0. 10.  9.  7.  3.  3.  9. 10.  7. 10. 10.] 
adversary cards in hand: [6. 6. 6. 8. 0.] 
adversary cards in discard: [ 6.  0.  8.  3.  0.  0.  1.  6.  0.  3.  0.  0. 10.  0.  3.  3.  3.  3.
  0.  0.  8. 29.  3.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6  8  6  6  0  6  0  6  0  3] -> size -> 34 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 279 

action type: buy - action 10.0
Learning step: 0
desired expected reward: 9.547204971313477






Player: 1 
cards in hand: [6. 6. 6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6. 8. 0.] 
cards in discard: [ 6.  0.  8.  3.  0.  0.  1.  6.  0.  3.  0.  0. 10.  0.  3.  3.  3.  3.
  0.  0.  8. 29.  3.  6.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1  3  6 29  0  6  8  6  3  0 10  6  3  6  8
  6  8  6  6  0  6  0  6  0  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 24. 30.  8.  0. 10.  9.  7.  3.  3.  9. 10.  7. 10. 10.] 
adversary cards in hand: [25.  1. 25.  0. 25.] 
adversary cards in discard: [25.  3.  0. 29. 29. 10.  3. 10. 25. 25.  3. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10] -> size -> 30 
adversary victory points: 4
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6.] 
cards in discard: [ 6.  0.  8.  3.  0.  0.  1.  6.  0.  3.  0.  0. 10.  0.  3.  3.  3.  3.
  0.  0.  8. 29.  3.  6.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3 29  0  6  8  6  3  0 10  6  3  6  8  6  8
  6  6  0  6  0  6  0  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 24. 30.  8.  0. 10.  9.  7.  3.  3.  9. 10.  7. 10. 10.] 
adversary cards in hand: [25.  1. 25.  0. 25.] 
adversary cards in discard: [25.  3.  0. 29. 29. 10.  3. 10. 25. 25.  3. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10] -> size -> 30 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6.] 
cards in discard: [ 6.  0.  8.  3.  0.  0.  1.  6.  0.  3.  0.  0. 10.  0.  3.  3.  3.  3.
  0.  0.  8. 29.  3.  6.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3 29  0  6  8  6  3  0 10  6  3  6  8  6  8
  6  6  0  6  0  6  0  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 27. 30. 24. 30.  8.  0. 10.  9.  7.  3.  3.  9. 10.  7. 10. 10.] 
adversary cards in hand: [25.  1. 25.  0. 25.] 
adversary cards in discard: [25.  3.  0. 29. 29. 10.  3. 10. 25. 25.  3. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10] -> size -> 30 
adversary victory points: 4
player victory points: -2 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [25.  1. 25.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 25.] 
expected returns: [[52.455547]
 [74.06801 ]
 [74.06801 ]
 [74.06801 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1. 25.  0. 25.] 
cards in discard: [25.  3.  0. 29. 29. 10.  3. 10. 25. 25.  3. 11.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 24. 30.  8.  0. 10.  9.  7.  3.  3.  9. 10.  7. 10. 10.] 
adversary cards in hand: [3. 3. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 29  0  6  8  6  3  0 10  6  3  6  8  6  8
  6  6  0  6  0  6  0  3] -> size -> 32 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 44.28852844238281



action possibilites: [-1] 
expected returns: [[49.308525]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25.  0. 25.  3. 29.] 
cards in discard: [25.  3.  0. 29. 29. 10.  3. 10. 25. 25.  3. 11.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 24. 30.  8.  0. 10.  9.  7.  3.  3.  9. 10.  7. 10. 10.] 
adversary cards in hand: [3. 3. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 29  0  6  8  6  3  0 10  6  3  6  8  6  8
  6  6  0  6  0  6  0  3] -> size -> 32 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 74.06806182861328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[29.102005]
 [42.206245]
 [30.90147 ]
 [58.07103 ]
 [48.07414 ]
 [60.30098 ]
 [54.020214]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 25.  0. 25.  3. 29.] 
cards in discard: [25.  3.  0. 29. 29. 10.  3. 10. 25. 25.  3. 11.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 27. 30. 24. 30.  8.  0. 10.  9.  7.  3.  3.  9. 10.  7. 10. 10.] 
adversary cards in hand: [3. 3. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 29  0  6  8  6  3  0 10  6  3  6  8  6  8
  6  6  0  6  0  6  0  3] -> size -> 32 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 49.30852508544922



buy possibilites: [-1] 
expected returns: [[59.1679]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 25.  0. 25.  3. 29.] 
cards in discard: [25.  3.  0. 29. 29. 10.  3. 10. 25. 25.  3. 11.  0.  0.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 24. 30.  8.  0. 10.  9.  7.  3.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [3. 3. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 29  0  6  8  6  3  0 10  6  3  6  8  6  8
  6  6  0  6  0  6  0  3] -> size -> 32 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 249 

action type: buy - action 10.0
Learning step: 0
desired expected reward: 60.300987243652344






Player: 1 
cards in hand: [3. 3. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 6. 6.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3 29  0  6  8  6  3  0 10  6  3  6  8  6  8
  6  6  0  6  0  6  0  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 24. 30.  8.  0. 10.  9.  7.  3.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 1. 25.  0. 29.  0.] 
adversary cards in discard: [25.  3.  0. 29. 29. 10.  3. 10. 25. 25.  3. 11.  0.  0.  0. 10. 25.  1.
 25.  0. 25.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10] -> size -> 31 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 6. 6.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3 29  0  6  8  6  3  0 10  6  3  6  8  6  8
  6  6  0  6  0  6  0  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 27. 30. 24. 30.  8.  0. 10.  9.  7.  3.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 1. 25.  0. 29.  0.] 
adversary cards in discard: [25.  3.  0. 29. 29. 10.  3. 10. 25. 25.  3. 11.  0.  0.  0. 10. 25.  1.
 25.  0. 25.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10] -> size -> 31 
adversary victory points: 4
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 6. 6.] 
cards in discard: [0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3 29  0  6  8  6  3  0 10  6  3  6  8  6  8
  6  6  0  6  0  6  0  3  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 24. 30.  8.  0. 10.  9.  7.  3.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 1. 25.  0. 29.  0.] 
adversary cards in discard: [25.  3.  0. 29. 29. 10.  3. 10. 25. 25.  3. 11.  0.  0.  0. 10. 25.  1.
 25.  0. 25.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10] -> size -> 31 
adversary victory points: 4
player victory points: -2 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 1. 25.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[63.855133]
 [77.65831 ]
 [76.365204]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25.  0. 29.  0.] 
cards in discard: [25.  3.  0. 29. 29. 10.  3. 10. 25. 25.  3. 11.  0.  0.  0. 10. 25.  1.
 25.  0. 25.  3. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 24. 30.  8.  0. 10.  9.  7.  3.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0.  8.  6. 10.] 
adversary cards in discard: [0. 3. 3. 0. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 29  0  6  8  6  3  0 10  6  3  6  8  6  8
  6  6  0  6  0  6  0  3  0] -> size -> 33 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 59.16790008544922



action possibilites: [-1] 
expected returns: [[37.061783]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 29.  0.  0. 29.] 
cards in discard: [25.  3.  0. 29. 29. 10.  3. 10. 25. 25.  3. 11.  0.  0.  0. 10. 25.  1.
 25.  0. 25.  3. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 24. 30.  8.  0. 10.  9.  7.  3.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0.  8.  6. 10.] 
adversary cards in discard: [0. 3. 3. 0. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 29  0  6  8  6  3  0 10  6  3  6  8  6  8
  6  6  0  6  0  6  0  3  0] -> size -> 33 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 77.6583023071289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[37.057648]
 [51.641167]
 [49.46276 ]
 [25.393642]
 [59.67189 ]
 [57.563244]
 [45.006695]
 [72.14564 ]
 [67.120186]
 [23.268837]
 [59.032013]
 [53.727577]
 [39.007763]
 [47.1085  ]
 [45.966255]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 29.  0.  0. 29.] 
cards in discard: [25.  3.  0. 29. 29. 10.  3. 10. 25. 25.  3. 11.  0.  0.  0. 10. 25.  1.
 25.  0. 25.  3. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 27. 30. 24. 30.  8.  0. 10.  9.  7.  3.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0.  8.  6. 10.] 
adversary cards in discard: [0. 3. 3. 0. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 29  0  6  8  6  3  0 10  6  3  6  8  6  8
  6  6  0  6  0  6  0  3  0] -> size -> 33 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 37.06178283691406



buy possibilites: [-1] 
expected returns: [[71.15253]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 29.  0.  0. 29.] 
cards in discard: [25.  3.  0. 29. 29. 10.  3. 10. 25. 25.  3. 11.  0.  0.  0. 10. 25.  1.
 25.  0. 25.  3. 29. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 24. 30.  8.  0. 10.  9.  7.  2.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0.  8.  6. 10.] 
adversary cards in discard: [0. 3. 3. 0. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1  3 29  0  6  8  6  3  0 10  6  3  6  8  6  8
  6  6  0  6  0  6  0  3  0] -> size -> 33 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 445 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 72.14561462402344






Player: 1 
cards in hand: [ 3.  0.  8.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8.  6. 10.] 
cards in discard: [0. 3. 3. 0. 6. 6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1  3 29  0  6  8  6  3  0 10  6  3  6  8  6  8
  6  6  0  6  0  6  0  3  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 24. 30.  8.  0. 10.  9.  7.  2.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 29. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25] -> size -> 32 
adversary victory points: 4
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.] 
cards in discard: [0. 3. 3. 0. 6. 6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  1  3 29  0  6  8  6  3  0 10  6  3  6  8  6  8  6  6
  0  6  0  6  0  3  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 24. 30.  8.  0. 10.  9.  7.  2.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 29. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25] -> size -> 32 
adversary victory points: 4
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.] 
cards in discard: [0. 3. 3. 0. 6. 6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  1  3 29  0  6  8  6  3  0 10  6  3  6  8  6  8  6  6
  0  6  0  6  0  3  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 27. 30. 24. 30.  8.  0. 10.  9.  7.  2.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 29. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25] -> size -> 32 
adversary victory points: 4
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.] 
cards in discard: [0. 3. 3. 0. 6. 6. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  1  3 29  0  6  8  6  3  0 10  6  3  6  8  6  8  6  6
  0  6  0  6  0  3  0  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 24. 30.  8.  0. 10.  9.  7.  2.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 29. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25] -> size -> 32 
adversary victory points: 4
player victory points: -3 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 29. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[32.68358 ]
 [47.256035]
 [47.256035]
 [47.256035]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29. 29. 29.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 24. 30.  8.  0. 10.  9.  7.  2.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [6. 0. 6. 6. 0.] 
adversary cards in discard: [ 0.  3.  3.  0.  6.  6.  0.  8.  6. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3 29  0  6  8  6  3  0 10  6  3  6  8  6  8  6  6
  0  6  0  6  0  3  0  0] -> size -> 32 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 71.15252685546875



action possibilites: [-1. 29.] 
expected returns: [[39.03343 ]
 [54.172146]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  3.] 
cards in discard: [29.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 24. 30.  8.  0. 10.  9.  7.  2.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [6. 0. 6. 6. 0.] 
adversary cards in discard: [ 0.  3.  3.  0.  6.  6.  0.  8.  6. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3 29  0  6  8  6  3  0 10  6  3  6  8  6  8  6  6
  0  6  0  6  0  3  0  0] -> size -> 32 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 41.602134704589844



action possibilites: [-1.] 
expected returns: [[65.55341]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [29.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 2 
card supply: [22. 27. 30. 24. 30.  8.  0. 10.  9.  7.  2.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [6. 0. 6. 6. 0.] 
adversary cards in discard: [ 0.  3.  3.  0.  6.  6.  0.  8.  6. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3 29  0  6  8  6  3  0 10  6  3  6  8  6  8  6  6
  0  6  0  6  0  3  0  0] -> size -> 32 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 48.59495544433594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[62.03602 ]
 [73.76334 ]
 [67.124306]
 [73.50037 ]
 [67.05337 ]
 [69.9796  ]
 [66.22696 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [29.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 27. 30. 24. 30.  8.  0. 10.  9.  7.  2.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [6. 0. 6. 6. 0.] 
adversary cards in discard: [ 0.  3.  3.  0.  6.  6.  0.  8.  6. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3 29  0  6  8  6  3  0 10  6  3  6  8  6  8  6  6
  0  6  0  6  0  3  0  0] -> size -> 32 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 65.55341339111328



buy possibilites: [-1] 
expected returns: [[36.154705]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [29.  3.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8.  0. 10.  9.  7.  2.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [6. 0. 6. 6. 0.] 
adversary cards in discard: [ 0.  3.  3.  0.  6.  6.  0.  8.  6. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3 29  0  6  8  6  3  0 10  6  3  6  8  6  8  6  6
  0  6  0  6  0  3  0  0] -> size -> 32 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 299 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 73.76333618164062






Player: 1 
cards in hand: [6. 0. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 6. 0.] 
cards in discard: [ 0.  3.  3.  0.  6.  6.  0.  8.  6. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  3 29  0  6  8  6  3  0 10  6  3  6  8  6  8  6  6
  0  6  0  6  0  3  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8.  0. 10.  9.  7.  2.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [29.  3. 29.  0. 10.] 
adversary cards in discard: [29.  3.  1. 29. 29.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1] -> size -> 33 
adversary victory points: 4
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 6. 0.] 
cards in discard: [ 0.  3.  3.  0.  6.  6.  0.  8.  6. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  3 29  0  6  8  6  3  0 10  6  3  6  8  6  8  6  6
  0  6  0  6  0  3  0  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 26. 30. 24. 30.  8.  0. 10.  9.  7.  2.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [29.  3. 29.  0. 10.] 
adversary cards in discard: [29.  3.  1. 29. 29.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1] -> size -> 33 
adversary victory points: 4
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 6. 0.] 
cards in discard: [ 0.  3.  3.  0.  6.  6.  0.  8.  6. 10.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  3 29  0  6  8  6  3  0 10  6  3  6  8  6  8  6  6
  0  6  0  6  0  3  0  0  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8.  0. 10.  9.  6.  2.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [29.  3. 29.  0. 10.] 
adversary cards in discard: [29.  3.  1. 29. 29.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1] -> size -> 33 
adversary victory points: 4
player victory points: -3 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [29.  3. 29.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 10.] 
expected returns: [[-2.524467]
 [23.019434]
 [23.019434]
 [ 5.581225]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 29.  0. 10.] 
cards in discard: [29.  3.  1. 29. 29.  0.  3.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8.  0. 10.  9.  6.  2.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 8. 6. 0. 6.] 
adversary cards in discard: [ 0.  3.  3.  0.  6.  6.  0.  8.  6. 10.  8.  6.  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3 29  0  6  8  6  3  0 10  6  3  6  8  6  8  6  6
  0  6  0  6  0  3  0  0  8] -> size -> 33 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 36.15470504760742



action possibilites: [-1. 10.] 
expected returns: [[28.270283]
 [33.40039 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0.] 
cards in discard: [29.  3.  1. 29. 29.  0.  3.  3. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 26. 30. 24. 30.  8.  0. 10.  9.  6.  2.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 8. 6. 0. 6.] 
adversary cards in discard: [ 0.  3.  3.  0.  6.  6.  0.  8.  6. 10.  8.  6.  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3 29  0  6  8  6  3  0 10  6  3  6  8  6  8  6  6
  0  6  0  6  0  3  0  0  8] -> size -> 33 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 3.4810423851013184



action possibilites: [-1.] 
expected returns: [[17.81656]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 1.] 
cards in discard: [29.  3.  1. 29. 29.  0.  3.  3. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1] -> size -> 33 
action values: 2 
buys: 0 
player value: 1 
card supply: [22. 26. 30. 24. 30.  8.  0. 10.  9.  6.  2.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 8. 6. 0. 6.] 
adversary cards in discard: [ 0.  3.  3.  0.  6.  6.  0.  8.  6. 10.  8.  6.  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3 29  0  6  8  6  3  0 10  6  3  6  8  6  8  6  6
  0  6  0  6  0  3  0  0  8] -> size -> 33 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 33.400386810302734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[15.106241 ]
 [26.787842 ]
 [21.123068 ]
 [ 1.1086588]
 [29.180542 ]
 [27.484905 ]
 [19.704676 ]
 [36.874588 ]
 [32.397045 ]
 [-3.901567 ]
 [23.009205 ]
 [23.262764 ]
 [ 7.512155 ]
 [14.658489 ]
 [18.816004 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1.] 
cards in discard: [29.  3.  1. 29. 29.  0.  3.  3. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1] -> size -> 33 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 26. 30. 24. 30.  8.  0. 10.  9.  6.  2.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 8. 6. 0. 6.] 
adversary cards in discard: [ 0.  3.  3.  0.  6.  6.  0.  8.  6. 10.  8.  6.  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3 29  0  6  8  6  3  0 10  6  3  6  8  6  8  6  6
  0  6  0  6  0  3  0  0  8] -> size -> 33 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 17.816560745239258



buy possibilites: [-1] 
expected returns: [[84.]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1.] 
cards in discard: [29.  3.  1. 29. 29.  0.  3.  3. 29. 25.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8.  0. 10.  9.  6.  1.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 8. 6. 0. 6.] 
adversary cards in discard: [ 0.  3.  3.  0.  6.  6.  0.  8.  6. 10.  8.  6.  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  1  3 29  0  6  8  6  3  0 10  6  3  6  8  6  8  6  6
  0  6  0  6  0  3  0  0  8] -> size -> 33 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 495 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 36.87458038330078






Player: 1 
cards in hand: [0. 8. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 0. 6.] 
cards in discard: [ 0.  3.  3.  0.  6.  6.  0.  8.  6. 10.  8.  6.  0.  6.  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  3 29  0  6  8  6  3  0 10  6  3  6  8  6  8  6  6
  0  6  0  6  0  3  0  0  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8.  0. 10.  9.  6.  1.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [25.  0.  0. 10. 25.] 
adversary cards in discard: [29.  3.  1. 29. 29.  0.  3.  3. 29. 25. 29. 10.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25] -> size -> 34 
adversary victory points: 4
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 0.  3.  3.  0.  6.  6.  0.  8.  6. 10.  8.  6.  0.  6.  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  1  3 29  0  8  6  3  0 10  6  3  6  8  6  8  6  6  0  6  0
  6  0  3  0  0  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8.  0. 10.  9.  6.  1.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [25.  0.  0. 10. 25.] 
adversary cards in discard: [29.  3.  1. 29. 29.  0.  3.  3. 29. 25. 29. 10.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25] -> size -> 34 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 0.  3.  3.  0.  6.  6.  0.  8.  6. 10.  8.  6.  0.  6.  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  1  3 29  0  8  6  3  0 10  6  3  6  8  6  8  6  6  0  6  0
  6  0  3  0  0  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8.  0. 10.  9.  6.  1.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [25.  0.  0. 10. 25.] 
adversary cards in discard: [29.  3.  1. 29. 29.  0.  3.  3. 29. 25. 29. 10.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25] -> size -> 34 
adversary victory points: 4
player victory points: -2 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [25.  0.  0. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 25.] 
expected returns: [[114.41032]
 [130.6681 ]
 [117.62571]
 [130.6681 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0. 10. 25.] 
cards in discard: [29.  3.  1. 29. 29.  0.  3.  3. 29. 25. 29. 10.  3.  0.  0.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8.  0. 10.  9.  6.  1.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  0.  0.] 
adversary cards in discard: [ 0.  3.  3.  0.  6.  6.  0.  8.  6. 10.  8.  6.  0.  6.  6.  0.  8.  6.] 
adversary owned cards: [ 0  0  3  3  1  3 29  0  8  6  3  0 10  6  3  6  8  6  8  6  6  0  6  0
  6  0  3  0  0  8] -> size -> 30 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 84.0



action possibilites: [-1] 
expected returns: [[102.18533]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 25. 29.  0.] 
cards in discard: [29.  3.  1. 29. 29.  0.  3.  3. 29. 25. 29. 10.  3.  0.  0.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8.  0. 10.  9.  6.  1.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  0.  0.] 
adversary cards in discard: [ 0.  3.  3.  0.  6.  6.  0.  8.  6. 10.  8.  6.  0.  6.  6.  0.  8.  6.] 
adversary owned cards: [ 0  0  3  3  1  3 29  0  8  6  3  0 10  6  3  6  8  6  8  6  6  0  6  0
  6  0  3  0  0  8] -> size -> 30 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 130.6680908203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[ 97.97664 ]
 [111.38436 ]
 [104.84543 ]
 [110.25456 ]
 [103.70331 ]
 [106.450455]
 [104.71262 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 25. 29.  0.] 
cards in discard: [29.  3.  1. 29. 29.  0.  3.  3. 29. 25. 29. 10.  3.  0.  0.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 26. 30. 24. 30.  8.  0. 10.  9.  6.  1.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  0.  0.] 
adversary cards in discard: [ 0.  3.  3.  0.  6.  6.  0.  8.  6. 10.  8.  6.  0.  6.  6.  0.  8.  6.] 
adversary owned cards: [ 0  0  3  3  1  3 29  0  8  6  3  0 10  6  3  6  8  6  8  6  6  0  6  0
  6  0  3  0  0  8] -> size -> 30 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 102.18533325195312



buy possibilites: [-1] 
expected returns: [[125.07762]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 25. 29.  0.] 
cards in discard: [29.  3.  1. 29. 29.  0.  3.  3. 29. 25. 29. 10.  3.  0.  0.  1.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 24. 30.  8.  0. 10.  9.  6.  1.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  0.  0.] 
adversary cards in discard: [ 0.  3.  3.  0.  6.  6.  0.  8.  6. 10.  8.  6.  0.  6.  6.  0.  8.  6.] 
adversary owned cards: [ 0  0  3  3  1  3 29  0  8  6  3  0 10  6  3  6  8  6  8  6  6  0  6  0
  6  0  3  0  0  8] -> size -> 30 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 249 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 111.38436126708984






Player: 1 
cards in hand: [ 3. 29.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3.  0.  0.] 
cards in discard: [ 0.  3.  3.  0.  6.  6.  0.  8.  6. 10.  8.  6.  0.  6.  6.  0.  8.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  3 29  0  8  6  3  0 10  6  3  6  8  6  8  6  6  0  6  0
  6  0  3  0  0  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 24. 30.  8.  0. 10.  9.  6.  1.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [25. 25. 25. 25. 25.] 
adversary cards in discard: [29.  3.  1. 29. 29.  0.  3.  3. 29. 25. 29. 10.  3.  0.  0.  1.  1. 25.
  0.  0. 10. 25. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1] -> size -> 35 
adversary victory points: 4
player victory points: -2 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 8.] 
cards in discard: [ 0.  3.  3.  0.  6.  6.  0.  8.  6. 10.  8.  6.  0.  6.  6.  0.  8.  6.
  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3  1  3 29  0  8  6  3  0 10  6  3  6  8  6  8  6  6  0  6  0
  6  0  3  0  0  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 25. 30. 24. 30.  8.  0. 10.  9.  6.  1.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [25. 25. 25. 25. 25.] 
adversary cards in discard: [29.  3.  1. 29. 29.  0.  3.  3. 29. 25. 29. 10.  3.  0.  0.  1.  1. 25.
  0.  0. 10. 25. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1] -> size -> 35 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8.] 
cards in discard: [ 0.  3.  3.  0.  6.  6.  0.  8.  6. 10.  8.  6.  0.  6.  6.  0.  8.  6.
  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3  1  3 29  0  8  6  3  0 10  6  3  6  8  6  8  6  6  0  6  0
  6  0  3  0  0  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 25. 30. 24. 30.  8.  0. 10.  9.  6.  1.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [25. 25. 25. 25. 25.] 
adversary cards in discard: [29.  3.  1. 29. 29.  0.  3.  3. 29. 25. 29. 10.  3.  0.  0.  1.  1. 25.
  0.  0. 10. 25. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1] -> size -> 35 
adversary victory points: 4
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8.] 
cards in discard: [ 0.  3.  3.  0.  6.  6.  0.  8.  6. 10.  8.  6.  0.  6.  6.  0.  8.  6.
  3.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3  1  3 29  0  8  6  3  0 10  6  3  6  8  6  8  6  6  0  6  0
  6  0  3  0  0  8  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 25. 30. 24. 30.  8.  0. 10.  9.  5.  1.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [25. 25. 25. 25. 25.] 
adversary cards in discard: [29.  3.  1. 29. 29.  0.  3.  3. 29. 25. 29. 10.  3.  0.  0.  1.  1. 25.
  0.  0. 10. 25. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1] -> size -> 35 
adversary victory points: 4
player victory points: -2 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [25. 25. 25. 25. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 25. 25. 25.] 
expected returns: [[ 84.64639]
 [106.21812]
 [106.21812]
 [106.21812]
 [106.21812]
 [106.21812]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25. 25. 25. 25.] 
cards in discard: [29.  3.  1. 29. 29.  0.  3.  3. 29. 25. 29. 10.  3.  0.  0.  1.  1. 25.
  0.  0. 10. 25. 29.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 24. 30.  8.  0. 10.  9.  5.  1.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 1. 3. 3. 0.] 
adversary cards in discard: [ 0.  3.  3.  0.  6.  6.  0.  8.  6. 10.  8.  6.  0.  6.  6.  0.  8.  6.
  3.  8. 29.  3.  0.  0.  8.] 
adversary owned cards: [ 0  0  3  3  1  3 29  0  8  6  3  0 10  6  3  6  8  6  8  6  6  0  6  0
  6  0  3  0  0  8  8] -> size -> 31 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 125.07762145996094



action possibilites: [-1] 
expected returns: [[80.00153]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25. 25. 25. 11.  0.] 
cards in discard: [29.  3.  1. 29. 29.  0.  3.  3. 29. 25. 29. 10.  3.  0.  0.  1.  1. 25.
  0.  0. 10. 25. 29.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 24. 30.  8.  0. 10.  9.  5.  1.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 1. 3. 3. 0.] 
adversary cards in discard: [ 0.  3.  3.  0.  6.  6.  0.  8.  6. 10.  8.  6.  0.  6.  6.  0.  8.  6.
  3.  8. 29.  3.  0.  0.  8.] 
adversary owned cards: [ 0  0  3  3  1  3 29  0  8  6  3  0 10  6  3  6  8  6  8  6  6  0  6  0
  6  0  3  0  0  8  8] -> size -> 31 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 106.21810913085938





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[76.16924]
 [81.40938]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 25. 25. 25. 11.  0.] 
cards in discard: [29.  3.  1. 29. 29.  0.  3.  3. 29. 25. 29. 10.  3.  0.  0.  1.  1. 25.
  0.  0. 10. 25. 29.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 25. 30. 24. 30.  8.  0. 10.  9.  5.  1.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 1. 3. 3. 0.] 
adversary cards in discard: [ 0.  3.  3.  0.  6.  6.  0.  8.  6. 10.  8.  6.  0.  6.  6.  0.  8.  6.
  3.  8. 29.  3.  0.  0.  8.] 
adversary owned cards: [ 0  0  3  3  1  3 29  0  8  6  3  0 10  6  3  6  8  6  8  6  6  0  6  0
  6  0  3  0  0  8  8] -> size -> 31 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 80.00153350830078






Player: 1 
cards in hand: [0. 1. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 3. 0.] 
cards in discard: [ 0.  3.  3.  0.  6.  6.  0.  8.  6. 10.  8.  6.  0.  6.  6.  0.  8.  6.
  3.  8. 29.  3.  0.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  3 29  0  8  6  3  0 10  6  3  6  8  6  8  6  6  0  6  0
  6  0  3  0  0  8  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 24. 30.  8.  0. 10.  9.  5.  1.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [11.  1. 25. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1] -> size -> 35 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 3. 0.] 
cards in discard: [ 0.  3.  3.  0.  6.  6.  0.  8.  6. 10.  8.  6.  0.  6.  6.  0.  8.  6.
  3.  8. 29.  3.  0.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  3 29  0  8  6  3  0 10  6  3  6  8  6  8  6  6  0  6  0
  6  0  3  0  0  8  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 25. 30. 24. 30.  8.  0. 10.  9.  5.  1.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [11.  1. 25. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1] -> size -> 35 
adversary victory points: 4
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 3. 0.] 
cards in discard: [ 0.  3.  3.  0.  6.  6.  0.  8.  6. 10.  8.  6.  0.  6.  6.  0.  8.  6.
  3.  8. 29.  3.  0.  0.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  3 29  0  8  6  3  0 10  6  3  6  8  6  8  6  6  0  6  0
  6  0  3  0  0  8  8  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 4 
card supply: [21. 25. 30. 24. 30.  8.  0. 10.  9.  5.  1.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [11.  1. 25. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1] -> size -> 35 
adversary victory points: 4
player victory points: -2 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [11.  1. 25. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 10.] 
expected returns: [[47.69034 ]
 [54.90458 ]
 [65.68475 ]
 [50.571365]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1. 25. 10.  0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 24. 30.  8.  0. 10.  9.  5.  1.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [3. 8. 8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  1  3 29  0  8  6  3  0 10  6  3  6  8  6  8  6  6  0  6  0
  6  0  3  0  0  8  8  0] -> size -> 32 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 81.40937042236328



action possibilites: [-1] 
expected returns: [[20.895267]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1. 10.  0. 25. 25.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 24. 30.  8.  0. 10.  9.  5.  1.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [3. 8. 8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  1  3 29  0  8  6  3  0 10  6  3  6  8  6  8  6  6  0  6  0
  6  0  3  0  0  8  8  0] -> size -> 32 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 65.68473052978516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[18.067474]
 [28.667381]
 [23.06056 ]
 [28.664639]
 [22.350428]
 [26.288548]
 [22.506227]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1. 10.  0. 25. 25.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 25. 30. 24. 30.  8.  0. 10.  9.  5.  1.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [3. 8. 8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  1  3 29  0  8  6  3  0 10  6  3  6  8  6  8  6  6  0  6  0
  6  0  3  0  0  8  8  0] -> size -> 32 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 20.895267486572266



buy possibilites: [-1] 
expected returns: [[41.5334]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1. 10.  0. 25. 25.] 
cards in discard: [1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 24. 30. 24. 30.  8.  0. 10.  9.  5.  1.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [3. 8. 8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  1  3 29  0  8  6  3  0 10  6  3  6  8  6  8  6  6  0  6  0
  6  0  3  0  0  8  8  0] -> size -> 32 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0 -10   0   0  54   0] 
sum of rewards: 239 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 28.667381286621094






Player: 1 
cards in hand: [3. 8. 8. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 8. 0. 6.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  3 29  0  8  6  3  0 10  6  3  6  8  6  8  6  6  0  6  0
  6  0  3  0  0  8  8  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 24. 30. 24. 30.  8.  0. 10.  9.  5.  1.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [29.  3.  0. 25. 25.] 
adversary cards in discard: [ 1. 25. 11.  1. 10.  0. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1] -> size -> 36 
adversary victory points: 4
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  1  3 29  0  8  3  0 10  6  3  6  8  6  8  6  6  0  6  0  6
  0  3  0  0  8  8  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 24. 30. 24. 30.  8.  0. 10.  9.  5.  1.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [29.  3.  0. 25. 25.] 
adversary cards in discard: [ 1. 25. 11.  1. 10.  0. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1] -> size -> 36 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  1  3 29  0  8  3  0 10  6  3  6  8  6  8  6  6  0  6  0  6
  0  3  0  0  8  8  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 24. 30. 24. 30.  8.  0. 10.  9.  5.  1.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [29.  3.  0. 25. 25.] 
adversary cards in discard: [ 1. 25. 11.  1. 10.  0. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1] -> size -> 36 
adversary victory points: 4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0.] 
cards in discard: [0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  1  3 29  0  8  3  0 10  6  3  6  8  6  8  6  6  0  6  0  6
  0  3  0  0  8  8  0  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 24. 30. 24. 30.  8.  0. 10.  9.  5.  1.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [29.  3.  0. 25. 25.] 
adversary cards in discard: [ 1. 25. 11.  1. 10.  0. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1] -> size -> 36 
adversary victory points: 4
player victory points: -1 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [29.  3.  0. 25. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 25.] 
expected returns: [[39.7405  ]
 [52.484642]
 [56.433327]
 [56.433327]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0. 25. 25.] 
cards in discard: [ 1. 25. 11.  1. 10.  0. 25. 25.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 24. 30.  8.  0. 10.  9.  5.  1.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [0. 8. 3. 8. 0.] 
adversary owned cards: [ 0  0  3  3  1  3 29  0  8  3  0 10  6  3  6  8  6  8  6  6  0  6  0  6
  0  3  0  0  8  8  0  0] -> size -> 32 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 41.53340148925781



action possibilites: [-1] 
expected returns: [[58.490677]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0. 25.  0.  0.] 
cards in discard: [ 1. 25. 11.  1. 10.  0. 25. 25.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 24. 30.  8.  0. 10.  9.  5.  1.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [0. 8. 3. 8. 0.] 
adversary owned cards: [ 0  0  3  3  1  3 29  0  8  3  0 10  6  3  6  8  6  8  6  6  0  6  0  6
  0  3  0  0  8  8  0  0] -> size -> 32 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 56.433319091796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[54.841484]
 [67.49197 ]
 [60.21588 ]
 [70.09291 ]
 [59.206123]
 [65.86924 ]
 [58.97148 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0. 25.  0.  0.] 
cards in discard: [ 1. 25. 11.  1. 10.  0. 25. 25.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 24. 30. 24. 30.  8.  0. 10.  9.  5.  1.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [0. 8. 3. 8. 0.] 
adversary owned cards: [ 0  0  3  3  1  3 29  0  8  3  0 10  6  3  6  8  6  8  6  6  0  6  0  6
  0  3  0  0  8  8  0  0] -> size -> 32 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 58.49067687988281



buy possibilites: [-1] 
expected returns: [[71.36443]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0. 25.  0.  0.] 
cards in discard: [ 1. 25. 11.  1. 10.  0. 25. 25. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 24. 30.  8.  0. 10.  8.  5.  1.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [0. 8. 3. 8. 0.] 
adversary owned cards: [ 0  0  3  3  1  3 29  0  8  3  0 10  6  3  6  8  6  8  6  6  0  6  0  6
  0  3  0  0  8  8  0  0] -> size -> 32 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0 -20   0   0  54   0] 
sum of rewards: 199 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 70.09291076660156






Player: 1 
cards in hand: [6. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [0. 8. 3. 8. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  3 29  0  8  3  0 10  6  3  6  8  6  8  6  6  0  6  0  6
  0  3  0  0  8  8  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 24. 30.  8.  0. 10.  8.  5.  1.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 29.  1. 25. 29.] 
adversary cards in discard: [ 1. 25. 11.  1. 10.  0. 25. 25. 11. 25. 29.  3.  0. 25.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11] -> size -> 37 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [0. 8. 3. 8. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  3 29  0  8  3  0 10  6  3  6  8  6  8  6  6  0  6  0  6
  0  3  0  0  8  8  0  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 24. 30. 24. 30.  8.  0. 10.  8.  5.  1.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 29.  1. 25. 29.] 
adversary cards in discard: [ 1. 25. 11.  1. 10.  0. 25. 25. 11. 25. 29.  3.  0. 25.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11] -> size -> 37 
adversary victory points: 4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [0. 8. 3. 8. 0. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  3 29  0  8  3  0 10  6  3  6  8  6  8  6  6  0  6  0  6
  0  3  0  0  8  8  0  0  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 24. 30. 24. 30.  8.  0. 10.  8.  5.  1.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 29.  1. 25. 29.] 
adversary cards in discard: [ 1. 25. 11.  1. 10.  0. 25. 25. 11. 25. 29.  3.  0. 25.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11] -> size -> 37 
adversary victory points: 4
player victory points: -1 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  1. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29.] 
expected returns: [[127.65492]
 [139.99861]
 [142.7823 ]
 [139.99861]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  1. 25. 29.] 
cards in discard: [ 1. 25. 11.  1. 10.  0. 25. 25. 11. 25. 29.  3.  0. 25.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 24. 30.  8.  0. 10.  8.  5.  1.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  3.  8.  1. 10.] 
adversary cards in discard: [0. 8. 3. 8. 0. 0. 6. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  3  3  1  3 29  0  8  3  0 10  6  3  6  8  6  8  6  6  0  6  0  6
  0  3  0  0  8  8  0  0  0] -> size -> 33 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 71.36443328857422



action possibilites: [-1] 
expected returns: [[63.97818]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  1. 29. 10. 10.] 
cards in discard: [ 1. 25. 11.  1. 10.  0. 25. 25. 11. 25. 29.  3.  0. 25.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 24. 30.  8.  0. 10.  8.  5.  1.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  3.  8.  1. 10.] 
adversary cards in discard: [0. 8. 3. 8. 0. 0. 6. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  3  3  1  3 29  0  8  3  0 10  6  3  6  8  6  8  6  6  0  6  0  6
  0  3  0  0  8  8  0  0  0] -> size -> 33 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 142.7822723388672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[58.20006 ]
 [77.209564]
 [69.77987 ]
 [78.59235 ]
 [66.3721  ]
 [77.25006 ]
 [65.02229 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  1. 29. 10. 10.] 
cards in discard: [ 1. 25. 11.  1. 10.  0. 25. 25. 11. 25. 29.  3.  0. 25.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 24. 30. 24. 30.  8.  0. 10.  8.  5.  1.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  3.  8.  1. 10.] 
adversary cards in discard: [0. 8. 3. 8. 0. 0. 6. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  3  3  1  3 29  0  8  3  0 10  6  3  6  8  6  8  6  6  0  6  0  6
  0  3  0  0  8  8  0  0  0] -> size -> 33 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 63.978179931640625



buy possibilites: [-1] 
expected returns: [[47.300117]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  1. 29. 10. 10.] 
cards in discard: [ 1. 25. 11.  1. 10.  0. 25. 25. 11. 25. 29.  3.  0. 25.  0.  0. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 24. 30.  8.  0. 10.  7.  5.  1.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  3.  8.  1. 10.] 
adversary cards in discard: [0. 8. 3. 8. 0. 0. 6. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  3  3  1  3 29  0  8  3  0 10  6  3  6  8  6  8  6  6  0  6  0  6
  0  3  0  0  8  8  0  0  0] -> size -> 33 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0 -30   0   0  54   0] 
sum of rewards: 189 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 78.59239959716797






Player: 1 
cards in hand: [ 0.  3.  8.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8.  1. 10.] 
cards in discard: [0. 8. 3. 8. 0. 0. 6. 0. 3. 0. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  3 29  0  8  3  0 10  6  3  6  8  6  8  6  6  0  6  0  6
  0  3  0  0  8  8  0  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 24. 30.  8.  0. 10.  7.  5.  1.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  1. 25.] 
adversary cards in discard: [ 1. 25. 11.  1. 10.  0. 25. 25. 11. 25. 29.  3.  0. 25.  0.  0. 11. 25.
  0. 29.  1. 29. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11] -> size -> 38 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  8.  1. 10.] 
cards in discard: [0. 8. 3. 8. 0. 0. 6. 0. 3. 0. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  3 29  0  8  3  0 10  6  3  6  8  6  8  6  6  0  6  0  6
  0  3  0  0  8  8  0  0  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 24. 30. 24. 30.  8.  0. 10.  7.  5.  1.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  1. 25.] 
adversary cards in discard: [ 1. 25. 11.  1. 10.  0. 25. 25. 11. 25. 29.  3.  0. 25.  0.  0. 11. 25.
  0. 29.  1. 29. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11] -> size -> 38 
adversary victory points: 4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  8.  1. 10.] 
cards in discard: [0. 8. 3. 8. 0. 0. 6. 0. 3. 0. 0. 1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  3 29  0  8  3  0 10  6  3  6  8  6  8  6  6  0  6  0  6
  0  3  0  0  8  8  0  0  0  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 24. 30.  8.  0. 10.  7.  5.  1.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  1. 25.] 
adversary cards in discard: [ 1. 25. 11.  1. 10.  0. 25. 25. 11. 25. 29.  3.  0. 25.  0.  0. 11. 25.
  0. 29.  1. 29. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11] -> size -> 38 
adversary victory points: 4
player victory points: -1 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0.  1. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[63.60118]
 [76.12167]
 [77.74025]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  1. 25.] 
cards in discard: [ 1. 25. 11.  1. 10.  0. 25. 25. 11. 25. 29.  3.  0. 25.  0.  0. 11. 25.
  0. 29.  1. 29. 10. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 24. 30.  8.  0. 10.  7.  5.  1.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 8. 0. 6. 6.] 
adversary cards in discard: [ 0.  8.  3.  8.  0.  0.  6.  0.  3.  0.  0.  1.  0.  3.  8.  1. 10.] 
adversary owned cards: [ 0  0  3  3  1  3 29  0  8  3  0 10  6  3  6  8  6  8  6  6  0  6  0  6
  0  3  0  0  8  8  0  0  0  1] -> size -> 34 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 47.30011749267578



action possibilites: [-1] 
expected returns: [[59.921234]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  1.  3. 29.] 
cards in discard: [ 1. 25. 11.  1. 10.  0. 25. 25. 11. 25. 29.  3.  0. 25.  0.  0. 11. 25.
  0. 29.  1. 29. 10. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 24. 30.  8.  0. 10.  7.  5.  1.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 8. 0. 6. 6.] 
adversary cards in discard: [ 0.  8.  3.  8.  0.  0.  6.  0.  3.  0.  0.  1.  0.  3.  8.  1. 10.] 
adversary owned cards: [ 0  0  3  3  1  3 29  0  8  3  0 10  6  3  6  8  6  8  6  6  0  6  0  6
  0  3  0  0  8  8  0  0  0  1] -> size -> 34 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 77.74028015136719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[55.060966]
 [65.04761 ]
 [56.994274]
 [71.003105]
 [63.14074 ]
 [59.863853]
 [75.97696 ]
 [35.820522]
 [61.488304]
 [52.699593]
 [64.03216 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  1.  3. 29.] 
cards in discard: [ 1. 25. 11.  1. 10.  0. 25. 25. 11. 25. 29.  3.  0. 25.  0.  0. 11. 25.
  0. 29.  1. 29. 10. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11] -> size -> 38 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 23. 30. 24. 30.  8.  0. 10.  7.  5.  1.  3.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 8. 0. 6. 6.] 
adversary cards in discard: [ 0.  8.  3.  8.  0.  0.  6.  0.  3.  0.  0.  1.  0.  3.  8.  1. 10.] 
adversary owned cards: [ 0  0  3  3  1  3 29  0  8  3  0 10  6  3  6  8  6  8  6  6  0  6  0  6
  0  3  0  0  8  8  0  0  0  1] -> size -> 34 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 59.921234130859375



buy possibilites: [-1] 
expected returns: [[80.31227]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  1.  3. 29.] 
cards in discard: [ 1. 25. 11.  1. 10.  0. 25. 25. 11. 25. 29.  3.  0. 25.  0.  0. 11. 25.
  0. 29.  1. 29. 10. 10. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 24. 30.  8.  0. 10.  7.  5.  1.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 8. 0. 6. 6.] 
adversary cards in discard: [ 0.  8.  3.  8.  0.  0.  6.  0.  3.  0.  0.  1.  0.  3.  8.  1. 10.] 
adversary owned cards: [ 0  0  3  3  1  3 29  0  8  3  0 10  6  3  6  8  6  8  6  6  0  6  0  6
  0  3  0  0  8  8  0  0  0  1] -> size -> 34 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0 -40   0   0 128   0] 
sum of rewards: 253 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 75.97698974609375






Player: 1 
cards in hand: [0. 8. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 6. 6.] 
cards in discard: [ 0.  8.  3.  8.  0.  0.  6.  0.  3.  0.  0.  1.  0.  3.  8.  1. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  3 29  0  8  3  0 10  6  3  6  8  6  8  6  6  0  6  0  6
  0  3  0  0  8  8  0  0  0  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 24. 30.  8.  0. 10.  7.  5.  1.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [25.  3.  0. 29. 25.] 
adversary cards in discard: [ 1. 25. 11.  1. 10.  0. 25. 25. 11. 25. 29.  3.  0. 25.  0.  0. 11. 25.
  0. 29.  1. 29. 10. 10. 29. 25.  0. 29.  0.  1.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29] -> size -> 39 
adversary victory points: 4
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6.] 
cards in discard: [ 0.  8.  3.  8.  0.  0.  6.  0.  3.  0.  0.  1.  0.  3.  8.  1. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  1  3 29  0  8  3  0 10  6  3  6  8  6  8  6  6  0  6  0  6  0
  3  0  0  8  8  0  0  0  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 24. 30.  8.  0. 10.  7.  5.  1.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [25.  3.  0. 29. 25.] 
adversary cards in discard: [ 1. 25. 11.  1. 10.  0. 25. 25. 11. 25. 29.  3.  0. 25.  0.  0. 11. 25.
  0. 29.  1. 29. 10. 10. 29. 25.  0. 29.  0.  1.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29] -> size -> 39 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6.] 
cards in discard: [ 0.  8.  3.  8.  0.  0.  6.  0.  3.  0.  0.  1.  0.  3.  8.  1. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  1  3 29  0  8  3  0 10  6  3  6  8  6  8  6  6  0  6  0  6  0
  3  0  0  8  8  0  0  0  1] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 23. 30. 24. 30.  8.  0. 10.  7.  5.  1.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [25.  3.  0. 29. 25.] 
adversary cards in discard: [ 1. 25. 11.  1. 10.  0. 25. 25. 11. 25. 29.  3.  0. 25.  0.  0. 11. 25.
  0. 29.  1. 29. 10. 10. 29. 25.  0. 29.  0.  1.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29] -> size -> 39 
adversary victory points: 4
player victory points: -1 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [25.  3.  0. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25.] 
expected returns: [[69.230064]
 [83.97984 ]
 [82.8487  ]
 [83.97984 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0. 29. 25.] 
cards in discard: [ 1. 25. 11.  1. 10.  0. 25. 25. 11. 25. 29.  3.  0. 25.  0.  0. 11. 25.
  0. 29.  1. 29. 10. 10. 29. 25.  0. 29.  0.  1.  3. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 24. 30.  8.  0. 10.  7.  5.  1.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [6. 6. 3. 0. 0.] 
adversary cards in discard: [ 0.  8.  3.  8.  0.  0.  6.  0.  3.  0.  0.  1.  0.  3.  8.  1. 10.  8.
  0.  6.  6.] 
adversary owned cards: [ 0  3  3  1  3 29  0  8  3  0 10  6  3  6  8  6  8  6  6  0  6  0  6  0
  3  0  0  8  8  0  0  0  1] -> size -> 33 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 80.31227111816406



action possibilites: [-1] 
expected returns: [[70.93599]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29. 25.  3.  1.] 
cards in discard: [ 1. 25. 11.  1. 10.  0. 25. 25. 11. 25. 29.  3.  0. 25.  0.  0. 11. 25.
  0. 29.  1. 29. 10. 10. 29. 25.  0. 29.  0.  1.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 24. 30.  8.  0. 10.  7.  5.  1.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [6. 6. 3. 0. 0.] 
adversary cards in discard: [ 0.  8.  3.  8.  0.  0.  6.  0.  3.  0.  0.  1.  0.  3.  8.  1. 10.  8.
  0.  6.  6.] 
adversary owned cards: [ 0  3  3  1  3 29  0  8  3  0 10  6  3  6  8  6  8  6  6  0  6  0  6  0
  3  0  0  8  8  0  0  0  1] -> size -> 33 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 83.9798355102539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[66.71176 ]
 [78.28495 ]
 [72.17317 ]
 [78.06452 ]
 [71.095894]
 [74.46611 ]
 [70.936005]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29. 25.  3.  1.] 
cards in discard: [ 1. 25. 11.  1. 10.  0. 25. 25. 11. 25. 29.  3.  0. 25.  0.  0. 11. 25.
  0. 29.  1. 29. 10. 10. 29. 25.  0. 29.  0.  1.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 23. 30. 24. 30.  8.  0. 10.  7.  5.  1.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [6. 6. 3. 0. 0.] 
adversary cards in discard: [ 0.  8.  3.  8.  0.  0.  6.  0.  3.  0.  0.  1.  0.  3.  8.  1. 10.  8.
  0.  6.  6.] 
adversary owned cards: [ 0  3  3  1  3 29  0  8  3  0 10  6  3  6  8  6  8  6  6  0  6  0  6  0
  3  0  0  8  8  0  0  0  1] -> size -> 33 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 70.93598937988281



buy possibilites: [-1] 
expected returns: [[86.08026]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29. 25.  3.  1.] 
cards in discard: [ 1. 25. 11.  1. 10.  0. 25. 25. 11. 25. 29.  3.  0. 25.  0.  0. 11. 25.
  0. 29.  1. 29. 10. 10. 29. 25.  0. 29.  0.  1.  3. 29.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 24. 30.  8.  0. 10.  7.  5.  1.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [6. 6. 3. 0. 0.] 
adversary cards in discard: [ 0.  8.  3.  8.  0.  0.  6.  0.  3.  0.  0.  1.  0.  3.  8.  1. 10.  8.
  0.  6.  6.] 
adversary owned cards: [ 0  3  3  1  3 29  0  8  3  0 10  6  3  6  8  6  8  6  6  0  6  0  6  0
  3  0  0  8  8  0  0  0  1] -> size -> 33 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0 -50   0   0  54   0] 
sum of rewards: 169 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 78.2849349975586






Player: 1 
cards in hand: [6. 6. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 3. 0. 0.] 
cards in discard: [ 0.  8.  3.  8.  0.  0.  6.  0.  3.  0.  0.  1.  0.  3.  8.  1. 10.  8.
  0.  6.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  1  3 29  0  8  3  0 10  6  3  6  8  6  8  6  6  0  6  0  6  0
  3  0  0  8  8  0  0  0  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 24. 30.  8.  0. 10.  7.  5.  1.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [29.  0.  0.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1] -> size -> 40 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3. 0. 0.] 
cards in discard: [ 0.  8.  3.  8.  0.  0.  6.  0.  3.  0.  0.  1.  0.  3.  8.  1. 10.  8.
  0.  6.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  1  3 29  0  8  3  0 10  6  3  6  8  6  8  6  6  0  6  0  6  0
  3  0  0  8  8  0  0  0  1] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 22. 30. 24. 30.  8.  0. 10.  7.  5.  1.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [29.  0.  0.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1] -> size -> 40 
adversary victory points: 4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3. 0. 0.] 
cards in discard: [ 0.  8.  3.  8.  0.  0.  6.  0.  3.  0.  0.  1.  0.  3.  8.  1. 10.  8.
  0.  6.  6.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  1  3 29  0  8  3  0 10  6  3  6  8  6  8  6  6  0  6  0  6  0
  3  0  0  8  8  0  0  0  1  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 24. 30.  8.  0. 10.  7.  4.  1.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [29.  0.  0.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1] -> size -> 40 
adversary victory points: 4
player victory points: -1 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [29.  0.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[29.546738]
 [42.85894 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  1.  0.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 24. 30.  8.  0. 10.  7.  4.  1.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  6.  8.  3. 29.] 
adversary cards in discard: [ 0.  8.  3.  8.  0.  0.  6.  0.  3.  0.  0.  1.  0.  3.  8.  1. 10.  8.
  0.  6.  6.  8.  6.  6.  3.  0.  0.] 
adversary owned cards: [ 0  3  3  1  3 29  0  8  3  0 10  6  3  6  8  6  8  6  6  0  6  0  6  0
  3  0  0  8  8  0  0  0  1  8] -> size -> 34 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 86.08026123046875



action possibilites: [-1. 25.] 
expected returns: [[54.481125]
 [73.19888 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 25.] 
cards in discard: [1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 22. 30. 24. 30.  8.  0. 10.  7.  4.  1.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  6.  8.  3. 29.] 
adversary cards in discard: [ 0.  8.  3.  8.  0.  0.  6.  0.  3.  0.  0.  1.  0.  3.  8.  1. 10.  8.
  0.  6.  6.  8.  6.  6.  3.  0.  0.] 
adversary owned cards: [ 0  3  3  1  3 29  0  8  3  0 10  6  3  6  8  6  8  6  6  0  6  0  6  0
  3  0  0  8  8  0  0  0  1  8] -> size -> 34 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 35.90936279296875



action possibilites: [-1] 
expected returns: [[27.634747]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 25. 11.] 
cards in discard: [1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 22. 30. 24. 30.  8.  0. 10.  7.  4.  1.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  6.  8.  3. 29.] 
adversary cards in discard: [ 0.  8.  3.  8.  0.  0.  6.  0.  3.  0.  0.  1.  0.  3.  8.  1. 10.  8.
  0.  6.  6.  8.  6.  6.  3.  0.  0.] 
adversary owned cards: [ 0  3  3  1  3 29  0  8  3  0 10  6  3  6  8  6  8  6  6  0  6  0  6  0
  3  0  0  8  8  0  0  0  1  8] -> size -> 34 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 73.19886779785156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[24.489359 ]
 [37.428284 ]
 [30.562317 ]
 [38.807983 ]
 [37.121902 ]
 [29.439953 ]
 [43.34944  ]
 [ 4.0710015]
 [32.59819  ]
 [24.457874 ]
 [28.736443 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 25. 11.] 
cards in discard: [1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 22. 30. 24. 30.  8.  0. 10.  7.  4.  1.  2.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  6.  8.  3. 29.] 
adversary cards in discard: [ 0.  8.  3.  8.  0.  0.  6.  0.  3.  0.  0.  1.  0.  3.  8.  1. 10.  8.
  0.  6.  6.  8.  6.  6.  3.  0.  0.] 
adversary owned cards: [ 0  3  3  1  3 29  0  8  3  0 10  6  3  6  8  6  8  6  6  0  6  0  6  0
  3  0  0  8  8  0  0  0  1  8] -> size -> 34 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: 27.634746551513672



buy possibilites: [-1] 
expected returns: [[48.800156]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 25. 11.] 
cards in discard: [ 1. 29.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 24. 30.  8.  0. 10.  7.  4.  1.  1.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  6.  8.  3. 29.] 
adversary cards in discard: [ 0.  8.  3.  8.  0.  0.  6.  0.  3.  0.  0.  1.  0.  3.  8.  1. 10.  8.
  0.  6.  6.  8.  6.  6.  3.  0.  0.] 
adversary owned cards: [ 0  3  3  1  3 29  0  8  3  0 10  6  3  6  8  6  8  6  6  0  6  0  6  0
  3  0  0  8  8  0  0  0  1  8] -> size -> 34 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0 -60   0   0 128   0] 
sum of rewards: 253 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 43.34941101074219






Player: 1 
cards in hand: [ 6.  6.  8.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  8.  3. 29.] 
cards in discard: [ 0.  8.  3.  8.  0.  0.  6.  0.  3.  0.  0.  1.  0.  3.  8.  1. 10.  8.
  0.  6.  6.  8.  6.  6.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  1  3 29  0  8  3  0 10  6  3  6  8  6  8  6  6  0  6  0  6  0
  3  0  0  8  8  0  0  0  1  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 24. 30.  8.  0. 10.  7.  4.  1.  1.  9. 10.  6. 10. 10.] 
adversary cards in hand: [11. 29.  3.  1.  0.] 
adversary cards in discard: [ 1. 29. 29. 25.  0.  0.  0. 25. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29] -> size -> 41 
adversary victory points: 4
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.] 
cards in discard: [ 0.  8.  3.  8.  0.  0.  6.  0.  3.  0.  0.  1.  0.  3.  8.  1. 10.  8.
  0.  6.  6.  8.  6.  6.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  1  3 29  0  8  3  0 10  3  8  6  8  6  6  0  6  0  6  0  3  0  0
  8  8  0  0  0  1  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 24. 30.  8.  0. 10.  7.  4.  1.  1.  9. 10.  6. 10. 10.] 
adversary cards in hand: [11. 29.  3.  1.  0.] 
adversary cards in discard: [ 1. 29. 29. 25.  0.  0.  0. 25. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29] -> size -> 41 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.] 
cards in discard: [ 0.  8.  3.  8.  0.  0.  6.  0.  3.  0.  0.  1.  0.  3.  8.  1. 10.  8.
  0.  6.  6.  8.  6.  6.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  1  3 29  0  8  3  0 10  3  8  6  8  6  6  0  6  0  6  0  3  0  0
  8  8  0  0  0  1  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 22. 30. 24. 30.  8.  0. 10.  7.  4.  1.  1.  9. 10.  6. 10. 10.] 
adversary cards in hand: [11. 29.  3.  1.  0.] 
adversary cards in discard: [ 1. 29. 29. 25.  0.  0.  0. 25. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29] -> size -> 41 
adversary victory points: 4
player victory points: 0 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [11. 29.  3.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[87.0237]
 [95.6132]
 [98.7303]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  3.  1.  0.] 
cards in discard: [ 1. 29. 29. 25.  0.  0.  0. 25. 11.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 24. 30.  8.  0. 10.  7.  4.  1.  1.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  1  3 29  0  8  3  0 10  3  8  6  8  6  6  0  6  0  6  0  3  0  0
  8  8  0  0  0  1  8] -> size -> 31 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 48.80015563964844



action possibilites: [-1. 11.] 
expected returns: [[61.849655]
 [79.27732 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  1.] 
cards in discard: [ 1. 29. 29. 25.  0.  0.  0. 25. 11.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 22. 30. 24. 30.  8.  0. 10.  7.  4.  1.  1.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  1  3 29  0  8  3  0 10  3  8  6  8  6  6  0  6  0  6  0  3  0  0
  8  8  0  0  0  1  8] -> size -> 31 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 93.45635986328125



action possibilites: [-1] 
expected returns: [[96.528564]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1.] 
cards in discard: [ 1. 29. 29. 25.  0.  0.  0. 25. 11.  1. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 22. 30. 24. 30.  8.  0. 10.  7.  4.  1.  1.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  1  3 29  0  8  3  0 10  3  8  6  8  6  6  0  6  0  6  0  3  0  0
  8  8  0  0  0  1  8] -> size -> 31 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0 -70   0   0  64   0] 
sum of rewards: 149 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 74.8828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 94.015785]
 [107.850494]
 [107.94344 ]
 [110.376564]
 [114.52027 ]
 [ 97.620964]
 [117.802765]
 [ 82.08679 ]
 [109.4816  ]
 [104.63633 ]
 [ 95.469376]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1.] 
cards in discard: [ 1. 29. 29. 25.  0.  0.  0. 25. 11.  1. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15] -> size -> 42 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 22. 30. 24. 30.  8.  0. 10.  7.  4.  1.  1.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  1  3 29  0  8  3  0 10  3  8  6  8  6  6  0  6  0  6  0  3  0  0
  8  8  0  0  0  1  8] -> size -> 31 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: 96.528564453125



buy possibilites: [-1] 
expected returns: [[106.80401]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1.] 
cards in discard: [ 1. 29. 29. 25.  0.  0.  0. 25. 11.  1. 15. 29.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15 29] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 24. 30.  8.  0. 10.  7.  4.  1.  0.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  1  3 29  0  8  3  0 10  3  8  6  8  6  6  0  6  0  6  0  3  0  0
  8  8  0  0  0  1  8] -> size -> 31 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0 -80   0   0 128   0] 
sum of rewards: 203 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 117.802734375






Player: 1 
cards in hand: [0. 8. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  1  3 29  0  8  3  0 10  3  8  6  8  6  6  0  6  0  6  0  3  0  0
  8  8  0  0  0  1  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 24. 30.  8.  0. 10.  7.  4.  1.  0.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 10. 29.  0. 29.] 
adversary cards in discard: [ 1. 29. 29. 25.  0.  0.  0. 25. 11.  1. 15. 29. 29. 11.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15 29] -> size -> 43 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  1  3 29  0  8  3  0 10  3  8  6  8  6  6  0  6  0  6  0  3  0  0
  8  8  0  0  0  1  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 22. 30. 24. 30.  8.  0. 10.  7.  4.  1.  0.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 10. 29.  0. 29.] 
adversary cards in discard: [ 1. 29. 29. 25.  0.  0.  0. 25. 11.  1. 15. 29. 29. 11.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15 29] -> size -> 43 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  1  3 29  0  8  3  0 10  3  8  6  8  6  6  0  6  0  6  0  3  0  0
  8  8  0  0  0  1  8 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 24. 30.  8.  0. 10.  6.  4.  1.  0.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 10. 29.  0. 29.] 
adversary cards in discard: [ 1. 29. 29. 25.  0.  0.  0. 25. 11.  1. 15. 29. 29. 11.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15 29] -> size -> 43 
adversary victory points: 4
player victory points: 0 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 29.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 29.] 
expected returns: [[77.441185]
 [80.16292 ]
 [89.25023 ]
 [89.25023 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 29.  0. 29.] 
cards in discard: [ 1. 29. 29. 25.  0.  0.  0. 25. 11.  1. 15. 29. 29. 11.  3.  0.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15 29] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 24. 30.  8.  0. 10.  6.  4.  1.  0.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  8.  1. 10.  6.] 
adversary cards in discard: [11.  0.  8.  0.  0.  3.] 
adversary owned cards: [ 0  3  1  3 29  0  8  3  0 10  3  8  6  8  6  6  0  6  0  6  0  3  0  0
  8  8  0  0  0  1  8 11] -> size -> 32 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 106.80400848388672



action possibilites: [-1.] 
expected returns: [[93.11205]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1.] 
cards in discard: [ 1. 29. 29. 25.  0.  0.  0. 25. 11.  1. 15. 29. 29. 11.  3.  0.  1. 10.
 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15 29] -> size -> 43 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 22. 30. 24. 30.  8.  0. 10.  6.  4.  1.  0.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  8.  1. 10.  6.] 
adversary cards in discard: [11.  0.  8.  0.  0.  3.] 
adversary owned cards: [ 0  3  1  3 29  0  8  3  0 10  3  8  6  8  6  6  0  6  0  6  0  3  0  0
  8  8  0  0  0  1  8 11] -> size -> 32 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 83.86454010009766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[ 89.51144 ]
 [101.63276 ]
 [ 96.1226  ]
 [103.709366]
 [101.97693 ]
 [ 93.686714]
 [ 71.152176]
 [ 97.89771 ]
 [ 90.28936 ]
 [ 94.98974 ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1.] 
cards in discard: [ 1. 29. 29. 25.  0.  0.  0. 25. 11.  1. 15. 29. 29. 11.  3.  0.  1. 10.
 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15 29] -> size -> 43 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 22. 30. 24. 30.  8.  0. 10.  6.  4.  1.  0.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  8.  1. 10.  6.] 
adversary cards in discard: [11.  0.  8.  0.  0.  3.] 
adversary owned cards: [ 0  3  1  3 29  0  8  3  0 10  3  8  6  8  6  6  0  6  0  6  0  3  0  0
  8  8  0  0  0  1  8 11] -> size -> 32 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 93.11205291748047



buy possibilites: [-1] 
expected returns: [[160.38991]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1.] 
cards in discard: [ 1. 29. 29. 25.  0.  0.  0. 25. 11.  1. 15. 29. 29. 11.  3.  0.  1. 10.
 29. 16.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15 29 16] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 24. 30.  8.  0.  9.  6.  4.  1.  0.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  8.  1. 10.  6.] 
adversary cards in discard: [11.  0.  8.  0.  0.  3.] 
adversary owned cards: [ 0  3  1  3 29  0  8  3  0 10  3  8  6  8  6  6  0  6  0  6  0  3  0  0
  8  8  0  0  0  1  8 11] -> size -> 32 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0 -90   0   0 128   0] 
sum of rewards: 173 

action type: buy - action 16.0
Learning step: 0
desired expected reward: 103.70940399169922






Player: 1 
cards in hand: [ 8.  8.  1. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  1. 10.  6.] 
cards in discard: [11.  0.  8.  0.  0.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  1  3 29  0  8  3  0 10  3  8  6  8  6  6  0  6  0  6  0  3  0  0
  8  8  0  0  0  1  8 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 24. 30.  8.  0.  9.  6.  4.  1.  0.  9. 10.  6. 10.  9.] 
adversary cards in hand: [25.  0. 29. 25.  3.] 
adversary cards in discard: [ 1. 29. 29. 25.  0.  0.  0. 25. 11.  1. 15. 29. 29. 11.  3.  0.  1. 10.
 29. 16. 29.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15 29 16] -> size -> 44 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 1. 6. 6.] 
cards in discard: [11.  0.  8.  0.  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  1  3 29  0  8  3  0 10  3  8  6  8  6  6  0  6  0  6  0  3  0  0
  8  8  0  0  0  1  8 11] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 24. 30.  8.  0.  9.  6.  4.  1.  0.  9. 10.  6. 10.  9.] 
adversary cards in hand: [25.  0. 29. 25.  3.] 
adversary cards in discard: [ 1. 29. 29. 25.  0.  0.  0. 25. 11.  1. 15. 29. 29. 11.  3.  0.  1. 10.
 29. 16. 29.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15 29 16] -> size -> 44 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 6.] 
cards in discard: [11.  0.  8.  0.  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  3  1  3 29  0  8  3  0 10  3  8  8  6  6  0  6  0  6  0  3  0  0  8
  8  0  0  0  1  8 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 24. 30.  8.  0.  9.  6.  4.  1.  0.  9. 10.  6. 10.  9.] 
adversary cards in hand: [25.  0. 29. 25.  3.] 
adversary cards in discard: [ 1. 29. 29. 25.  0.  0.  0. 25. 11.  1. 15. 29. 29. 11.  3.  0.  1. 10.
 29. 16. 29.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15 29 16] -> size -> 44 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 6.] 
cards in discard: [11.  0.  8.  0.  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  3  1  3 29  0  8  3  0 10  3  8  8  6  6  0  6  0  6  0  3  0  0  8
  8  0  0  0  1  8 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 22. 30. 24. 30.  8.  0.  9.  6.  4.  1.  0.  9. 10.  6. 10.  9.] 
adversary cards in hand: [25.  0. 29. 25.  3.] 
adversary cards in discard: [ 1. 29. 29. 25.  0.  0.  0. 25. 11.  1. 15. 29. 29. 11.  3.  0.  1. 10.
 29. 16. 29.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15 29 16] -> size -> 44 
adversary victory points: 4
player victory points: 1 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [25.  0. 29. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25.] 
expected returns: [[ 88.768845]
 [104.265976]
 [101.56647 ]
 [104.265976]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 29. 25.  3.] 
cards in discard: [ 1. 29. 29. 25.  0.  0.  0. 25. 11.  1. 15. 29. 29. 11.  3.  0.  1. 10.
 29. 16. 29.  3.  0.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15 29 16] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 24. 30.  8.  0.  9.  6.  4.  1.  0.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 1. 0. 0. 8.] 
adversary cards in discard: [11.  0.  8.  0.  0.  3. 10.  8.  8.  1.  6.] 
adversary owned cards: [ 0  3  1  3 29  0  8  3  0 10  3  8  8  6  6  0  6  0  6  0  3  0  0  8
  8  0  0  0  1  8 11] -> size -> 31 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 160.38990783691406



action possibilites: [-1] 
expected returns: [[117.35719]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 25.  3.  0. 11.] 
cards in discard: [ 1. 29. 29. 25.  0.  0.  0. 25. 11.  1. 15. 29. 29. 11.  3.  0.  1. 10.
 29. 16. 29.  3.  0.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15 29 16] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 24. 30.  8.  0.  9.  6.  4.  1.  0.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 1. 0. 0. 8.] 
adversary cards in discard: [11.  0.  8.  0.  0.  3. 10.  8.  8.  1.  6.] 
adversary owned cards: [ 0  3  1  3 29  0  8  3  0 10  3  8  8  6  6  0  6  0  6  0  3  0  0  8
  8  0  0  0  1  8 11] -> size -> 31 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 104.26596069335938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[111.91518 ]
 [118.88754 ]
 [116.133224]
 [117.35719 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 25.  3.  0. 11.] 
cards in discard: [ 1. 29. 29. 25.  0.  0.  0. 25. 11.  1. 15. 29. 29. 11.  3.  0.  1. 10.
 29. 16. 29.  3.  0.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15 29 16] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 22. 30. 24. 30.  8.  0.  9.  6.  4.  1.  0.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 1. 0. 0. 8.] 
adversary cards in discard: [11.  0.  8.  0.  0.  3. 10.  8.  8.  1.  6.] 
adversary owned cards: [ 0  3  1  3 29  0  8  3  0 10  3  8  8  6  6  0  6  0  6  0  3  0  0  8
  8  0  0  0  1  8 11] -> size -> 31 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 117.35719299316406



buy possibilites: [-1] 
expected returns: [[100.61536]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 25.  3.  0. 11.] 
cards in discard: [ 1. 29. 29. 25.  0.  0.  0. 25. 11.  1. 15. 29. 29. 11.  3.  0.  1. 10.
 29. 16. 29.  3.  0.  1.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15 29 16  3] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 23. 30.  8.  0.  9.  6.  4.  1.  0.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 1. 0. 0. 8.] 
adversary cards in discard: [11.  0.  8.  0.  0.  3. 10.  8.  8.  1.  6.] 
adversary owned cards: [ 0  3  1  3 29  0  8  3  0 10  3  8  8  6  6  0  6  0  6  0  3  0  0  8
  8  0  0  0  1  8 11] -> size -> 31 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[  -5    0    0  120    0    0   20    0    0    0    0 -100    0    0
   16    0] 
sum of rewards: 51 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 118.88755798339844






Player: 1 
cards in hand: [0. 1. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0. 8.] 
cards in discard: [11.  0.  8.  0.  0.  3. 10.  8.  8.  1.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  1  3 29  0  8  3  0 10  3  8  8  6  6  0  6  0  6  0  3  0  0  8
  8  0  0  0  1  8 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 23. 30.  8.  0.  9.  6.  4.  1.  0.  9. 10.  6. 10.  9.] 
adversary cards in hand: [29. 25.  1. 25. 25.] 
adversary cards in discard: [ 1. 29. 29. 25.  0.  0.  0. 25. 11.  1. 15. 29. 29. 11.  3.  0.  1. 10.
 29. 16. 29.  3.  0.  1.  3. 25.  0. 29. 25.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15 29 16  3] -> size -> 45 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 8.] 
cards in discard: [11.  0.  8.  0.  0.  3. 10.  8.  8.  1.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  1  3 29  0  8  3  0 10  3  8  8  6  6  0  6  0  6  0  3  0  0  8
  8  0  0  0  1  8 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 5 
card supply: [19. 22. 30. 23. 30.  8.  0.  9.  6.  4.  1.  0.  9. 10.  6. 10.  9.] 
adversary cards in hand: [29. 25.  1. 25. 25.] 
adversary cards in discard: [ 1. 29. 29. 25.  0.  0.  0. 25. 11.  1. 15. 29. 29. 11.  3.  0.  1. 10.
 29. 16. 29.  3.  0.  1.  3. 25.  0. 29. 25.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15 29 16  3] -> size -> 45 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 8.] 
cards in discard: [11.  0.  8.  0.  0.  3. 10.  8.  8.  1.  6.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  1  3 29  0  8  3  0 10  3  8  8  6  6  0  6  0  6  0  3  0  0  8
  8  0  0  0  1  8 11  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 5 
card supply: [18. 22. 30. 23. 30.  8.  0.  9.  6.  4.  1.  0.  9. 10.  6. 10.  9.] 
adversary cards in hand: [29. 25.  1. 25. 25.] 
adversary cards in discard: [ 1. 29. 29. 25.  0.  0.  0. 25. 11.  1. 15. 29. 29. 11.  3.  0.  1. 10.
 29. 16. 29.  3.  0.  1.  3. 25.  0. 29. 25.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15 29 16  3] -> size -> 45 
adversary victory points: 5
player victory points: 1 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [29. 25.  1. 25. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 25. 25.] 
expected returns: [[40.019104]
 [46.49973 ]
 [47.725742]
 [47.725742]
 [47.725742]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  1. 25. 25.] 
cards in discard: [ 1. 29. 29. 25.  0.  0.  0. 25. 11.  1. 15. 29. 29. 11.  3.  0.  1. 10.
 29. 16. 29.  3.  0.  1.  3. 25.  0. 29. 25.  3.  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15 29 16  3] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 23. 30.  8.  0.  9.  6.  4.  1.  0.  9. 10.  6. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [11.  0.  8.  0.  0.  3. 10.  8.  8.  1.  6.  0.  0.  1.  0.  0.  8.] 
adversary owned cards: [ 0  3  1  3 29  0  8  3  0 10  3  8  8  6  6  0  6  0  6  0  3  0  0  8
  8  0  0  0  1  8 11  0] -> size -> 32 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 100.6153564453125



action possibilites: [-1] 
expected returns: [[25.00314]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1. 25. 25. 10. 25.] 
cards in discard: [ 1. 29. 29. 25.  0.  0.  0. 25. 11.  1. 15. 29. 29. 11.  3.  0.  1. 10.
 29. 16. 29.  3.  0.  1.  3. 25.  0. 29. 25.  3.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15 29 16  3] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 23. 30.  8.  0.  9.  6.  4.  1.  0.  9. 10.  6. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [11.  0.  8.  0.  0.  3. 10.  8.  8.  1.  6.  0.  0.  1.  0.  0.  8.] 
adversary owned cards: [ 0  3  1  3 29  0  8  3  0 10  3  8  8  6  6  0  6  0  6  0  3  0  0  8
  8  0  0  0  1  8 11  0] -> size -> 32 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 47.72574234008789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[21.076275]
 [24.964561]
 [28.026901]
 [25.0031  ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1. 25. 25. 10. 25.] 
cards in discard: [ 1. 29. 29. 25.  0.  0.  0. 25. 11.  1. 15. 29. 29. 11.  3.  0.  1. 10.
 29. 16. 29.  3.  0.  1.  3. 25.  0. 29. 25.  3.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15 29 16  3] -> size -> 45 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 22. 30. 23. 30.  8.  0.  9.  6.  4.  1.  0.  9. 10.  6. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [11.  0.  8.  0.  0.  3. 10.  8.  8.  1.  6.  0.  0.  1.  0.  0.  8.] 
adversary owned cards: [ 0  3  1  3 29  0  8  3  0 10  3  8  8  6  6  0  6  0  6  0  3  0  0  8
  8  0  0  0  1  8 11  0] -> size -> 32 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 25.00313949584961



buy possibilites: [-1] 
expected returns: [[27.045017]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1. 25. 25. 10. 25.] 
cards in discard: [ 1. 29. 29. 25.  0.  0.  0. 25. 11.  1. 15. 29. 29. 11.  3.  0.  1. 10.
 29. 16. 29.  3.  0.  1.  3. 25.  0. 29. 25.  3.  0. 11.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15 29 16  3  8] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 23. 30.  8.  0.  9.  6.  3.  1.  0.  9. 10.  6. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [11.  0.  8.  0.  0.  3. 10.  8.  8.  1.  6.  0.  0.  1.  0.  0.  8.] 
adversary owned cards: [ 0  3  1  3 29  0  8  3  0 10  3  8  8  6  6  0  6  0  6  0  3  0  0  8
  8  0  0  0  1  8 11  0] -> size -> 32 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[  -5    0    0  120    0    0   20    0    0    0    0 -110    0    0
   16    0] 
sum of rewards: 41 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 28.026935577392578






Player: 1 
cards in hand: [8. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 3.] 
cards in discard: [11.  0.  8.  0.  0.  3. 10.  8.  8.  1.  6.  0.  0.  1.  0.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  1  3 29  0  8  3  0 10  3  8  8  6  6  0  6  0  6  0  3  0  0  8
  8  0  0  0  1  8 11  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 23. 30.  8.  0.  9.  6.  3.  1.  0.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 29.  0. 10.  1.] 
adversary cards in discard: [ 1. 29. 29. 25.  0.  0.  0. 25. 11.  1. 15. 29. 29. 11.  3.  0.  1. 10.
 29. 16. 29.  3.  0.  1.  3. 25.  0. 29. 25.  3.  0. 11.  8. 25. 29.  1.
 25. 25. 10. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15 29 16  3  8] -> size -> 46 
adversary victory points: 5
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [11.  0.  8.  0.  0.  3. 10.  8.  8.  1.  6.  0.  0.  1.  0.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  3 29  8  3  0 10  3  8  8  6  6  0  6  0  6  0  3  0  0  8  8  0  0
  0  1  8 11  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 23. 30.  8.  0.  9.  6.  3.  1.  0.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 29.  0. 10.  1.] 
adversary cards in discard: [ 1. 29. 29. 25.  0.  0.  0. 25. 11.  1. 15. 29. 29. 11.  3.  0.  1. 10.
 29. 16. 29.  3.  0.  1.  3. 25.  0. 29. 25.  3.  0. 11.  8. 25. 29.  1.
 25. 25. 10. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15 29 16  3  8] -> size -> 46 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [11.  0.  8.  0.  0.  3. 10.  8.  8.  1.  6.  0.  0.  1.  0.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  3 29  8  3  0 10  3  8  8  6  6  0  6  0  6  0  3  0  0  8  8  0  0
  0  1  8 11  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 22. 30. 23. 30.  8.  0.  9.  6.  3.  1.  0.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 29.  0. 10.  1.] 
adversary cards in discard: [ 1. 29. 29. 25.  0.  0.  0. 25. 11.  1. 15. 29. 29. 11.  3.  0.  1. 10.
 29. 16. 29.  3.  0.  1.  3. 25.  0. 29. 25.  3.  0. 11.  8. 25. 29.  1.
 25. 25. 10. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15 29 16  3  8] -> size -> 46 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 3. 29.  0. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[ 95.21565]
 [108.13777]
 [ 95.31686]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0. 10.  1.] 
cards in discard: [ 1. 29. 29. 25.  0.  0.  0. 25. 11.  1. 15. 29. 29. 11.  3.  0.  1. 10.
 29. 16. 29.  3.  0.  1.  3. 25.  0. 29. 25.  3.  0. 11.  8. 25. 29.  1.
 25. 25. 10. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15 29 16  3  8] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 23. 30.  8.  0.  9.  6.  3.  1.  0.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 6.  0.  0. 29.  8.] 
adversary cards in discard: [11.  0.  8.  0.  0.  3. 10.  8.  8.  1.  6.  0.  0.  1.  0.  0.  8.  8.
  3.] 
adversary owned cards: [ 1  3 29  8  3  0 10  3  8  8  6  6  0  6  0  6  0  3  0  0  8  8  0  0
  0  1  8 11  0] -> size -> 29 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 27.04501724243164



action possibilites: [-1. 10.] 
expected returns: [[88.185486]
 [92.05778 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.] 
cards in discard: [ 1. 29. 29. 25.  0.  0.  0. 25. 11.  1. 15. 29. 29. 11.  3.  0.  1. 10.
 29. 16. 29.  3.  0.  1.  3. 25.  0. 29. 25.  3.  0. 11.  8. 25. 29.  1.
 25. 25. 10. 25.  1. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15 29 16  3  8] -> size -> 46 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 22. 30. 23. 30.  8.  0.  9.  6.  3.  1.  0.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 6.  0.  0. 29.  8.] 
adversary cards in discard: [11.  0.  8.  0.  0.  3. 10.  8.  8.  1.  6.  0.  0.  1.  0.  0.  8.  8.
  3.] 
adversary owned cards: [ 1  3 29  8  3  0 10  3  8  8  6  6  0  6  0  6  0  3  0  0  8  8  0  0
  0  1  8 11  0] -> size -> 29 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 99.79056549072266



action possibilites: [-1. 29.] 
expected returns: [[77.80111]
 [92.02285]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15 29 16  3  8] -> size -> 46 
action values: 2 
buys: 0 
player value: 1 
card supply: [18. 22. 30. 23. 30.  8.  0.  9.  6.  3.  1.  0.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 6.  0.  0. 29.  8.] 
adversary cards in discard: [11.  0.  8.  0.  0.  3. 10.  8.  8.  1.  6.  0.  0.  1.  0.  0.  8.  8.
  3.] 
adversary owned cards: [ 1  3 29  8  3  0 10  3  8  8  6  6  0  6  0  6  0  3  0  0  8  8  0  0
  0  1  8 11  0] -> size -> 29 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 92.05780029296875



action possibilites: [-1.] 
expected returns: [[64.81981]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [0. 1.] 
cards in deck: 40 
card top of deck: [] 
played cards: [29. 10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15 29 16  3  8] -> size -> 46 
action values: 2 
buys: 0 
player value: 2 
card supply: [18. 22. 30. 23. 30.  8.  0.  9.  6.  3.  1.  0.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 6.  0.  0. 29.  8.] 
adversary cards in discard: [11.  0.  8.  0.  0.  3. 10.  8.  8.  1.  6.  0.  0.  1.  0.  0.  8.  8.
  3.] 
adversary owned cards: [ 1  3 29  8  3  0 10  3  8  8  6  6  0  6  0  6  0  3  0  0  8  8  0  0
  0  1  8 11  0] -> size -> 29 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 86.88455200195312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[60.380356]
 [63.990738]
 [62.823112]
 [64.417366]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [0. 1.] 
cards in deck: 40 
card top of deck: [] 
played cards: [29. 10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15 29 16  3  8] -> size -> 46 
action values: 2 
buys: 1 
player value: 2 
card supply: [18. 22. 30. 23. 30.  8.  0.  9.  6.  3.  1.  0.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 6.  0.  0. 29.  8.] 
adversary cards in discard: [11.  0.  8.  0.  0.  3. 10.  8.  8.  1.  6.  0.  0.  1.  0.  0.  8.  8.
  3.] 
adversary owned cards: [ 1  3 29  8  3  0 10  3  8  8  6  6  0  6  0  6  0  3  0  0  8  8  0  0
  0  1  8 11  0] -> size -> 29 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 64.81980895996094






Player: 1 
cards in hand: [ 6.  0.  0. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 29.  8.] 
cards in discard: [11.  0.  8.  0.  0.  3. 10.  8.  8.  1.  6.  0.  0.  1.  0.  0.  8.  8.
  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  3 29  8  3  0 10  3  8  8  6  6  0  6  0  6  0  3  0  0  8  8  0  0
  0  1  8 11  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 23. 30.  8.  0.  9.  6.  3.  1.  0.  9. 10.  6. 10.  9.] 
adversary cards in hand: [25.  0. 11. 25.  0.] 
adversary cards in discard: [ 0.  1. 29. 10. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15 29 16  3  8] -> size -> 46 
adversary victory points: 5
player victory points: 0 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 3.] 
cards in discard: [11.  0.  8.  0.  0.  3. 10.  8.  8.  1.  6.  0.  0.  1.  0.  0.  8.  8.
  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 1  3 29  8  3  0 10  3  8  8  6  6  0  6  0  6  0  3  0  0  8  8  0  0
  0  1  8 11  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 22. 30. 23. 30.  8.  0.  9.  6.  3.  1.  0.  9. 10.  6. 10.  9.] 
adversary cards in hand: [25.  0. 11. 25.  0.] 
adversary cards in discard: [ 0.  1. 29. 10. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15 29 16  3  8] -> size -> 46 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 3.] 
cards in discard: [11.  0.  8.  0.  0.  3. 10.  8.  8.  1.  6.  0.  0.  1.  0.  0.  8.  8.
  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 1  3 29  8  3  0 10  3  8  8  6  6  0  6  0  6  0  3  0  0  8  8  0  0
  0  1  8 11  0] -> size -> 29 
action values: 1 
buys: 1 
player value: 1 
card supply: [18. 22. 30. 23. 30.  8.  0.  9.  6.  3.  1.  0.  9. 10.  6. 10.  9.] 
adversary cards in hand: [25.  0. 11. 25.  0.] 
adversary cards in discard: [ 0.  1. 29. 10. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15 29 16  3  8] -> size -> 46 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 3.] 
cards in discard: [11.  0.  8.  0.  0.  3. 10.  8.  8.  1.  6.  0.  0.  1.  0.  0.  8.  8.
  3.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 1  3 29  8  3  0 10  3  8  8  6  6  0  6  0  6  0  3  0  0  8  8  0  0
  0  1  8 11  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 22. 30. 23. 30.  8.  0.  9.  6.  3.  1.  0.  9. 10.  6. 10.  9.] 
adversary cards in hand: [25.  0. 11. 25.  0.] 
adversary cards in discard: [ 0.  1. 29. 10. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15 29 16  3  8] -> size -> 46 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [25.  0. 11. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 25.] 
expected returns: [[65.93405 ]
 [81.997475]
 [72.01529 ]
 [81.997475]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 11. 25.  0.] 
cards in discard: [ 0.  1. 29. 10. 29.  3.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15 29 16  3  8] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 22. 30. 23. 30.  8.  0.  9.  6.  3.  1.  0.  9. 10.  6. 10.  9.] 
adversary cards in hand: [6. 0. 3. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  3 29  8  3  0 10  3  8  8  6  6  0  6  0  6  0  3  0  0  8  8  0  0
  0  1  8 11  0  0] -> size -> 30 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 64.41736602783203



action possibilites: [-1] 
expected returns: [[81.70125]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 25.  0. 29. 11.] 
cards in discard: [ 0.  1. 29. 10. 29.  3.] 
cards in deck: 33 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15 29 16  3  8] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 22. 30. 23. 30.  8.  0.  9.  6.  3.  1.  0.  9. 10.  6. 10.  9.] 
adversary cards in hand: [6. 0. 3. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  3 29  8  3  0 10  3  8  8  6  6  0  6  0  6  0  3  0  0  8  8  0  0
  0  1  8 11  0  0] -> size -> 30 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 81.99745178222656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[79.98498 ]
 [88.10065 ]
 [83.938736]
 [81.38879 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 25.  0. 29. 11.] 
cards in discard: [ 0.  1. 29. 10. 29.  3.] 
cards in deck: 33 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15 29 16  3  8] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 22. 30. 23. 30.  8.  0.  9.  6.  3.  1.  0.  9. 10.  6. 10.  9.] 
adversary cards in hand: [6. 0. 3. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  3 29  8  3  0 10  3  8  8  6  6  0  6  0  6  0  3  0  0  8  8  0  0
  0  1  8 11  0  0] -> size -> 30 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 81.70124816894531



buy possibilites: [-1] 
expected returns: [[70.17042]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 25.  0. 29. 11.] 
cards in discard: [ 0.  1. 29. 10. 29.  3.  3.] 
cards in deck: 33 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15 29 16  3  8  3] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 22. 30. 22. 30.  8.  0.  9.  6.  3.  1.  0.  9. 10.  6. 10.  9.] 
adversary cards in hand: [6. 0. 3. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  3 29  8  3  0 10  3  8  8  6  6  0  6  0  6  0  3  0  0  8  8  0  0
  0  1  8 11  0  0] -> size -> 30 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[  -5    0    0  180    0    0   20    0    0    0    0 -120    0    0
   16    0] 
sum of rewards: 91 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 88.10064697265625






Player: 1 
cards in hand: [6. 0. 3. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 6. 6.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  3 29  8  3  0 10  3  8  8  6  6  0  6  0  6  0  3  0  0  8  8  0  0
  0  1  8 11  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 22. 30. 22. 30.  8.  0.  9.  6.  3.  1.  0.  9. 10.  6. 10.  9.] 
adversary cards in hand: [25.  1. 29.  3.  1.] 
adversary cards in discard: [ 0.  1. 29. 10. 29.  3.  3. 25.  0. 11. 25.  0. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15 29 16  3  8  3] -> size -> 47 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 6. 6.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  3 29  8  3  0 10  3  8  8  6  6  0  6  0  6  0  3  0  0  8  8  0  0
  0  1  8 11  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 22. 30. 22. 30.  8.  0.  9.  6.  3.  1.  0.  9. 10.  6. 10.  9.] 
adversary cards in hand: [25.  1. 29.  3.  1.] 
adversary cards in discard: [ 0.  1. 29. 10. 29.  3.  3. 25.  0. 11. 25.  0. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15 29 16  3  8  3] -> size -> 47 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 6. 6.] 
cards in discard: [0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  3 29  8  3  0 10  3  8  8  6  6  0  6  0  6  0  3  0  0  8  8  0  0
  0  1  8 11  0  0  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 22. 30. 22. 30.  8.  0.  9.  6.  3.  1.  0.  9. 10.  6. 10.  9.] 
adversary cards in hand: [25.  1. 29.  3.  1.] 
adversary cards in discard: [ 0.  1. 29. 10. 29.  3.  3. 25.  0. 11. 25.  0. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15 29 16  3  8  3] -> size -> 47 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [25.  1. 29.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[33.259323]
 [55.14157 ]
 [51.783478]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1. 29.  3.  1.] 
cards in discard: [ 0.  1. 29. 10. 29.  3.  3. 25.  0. 11. 25.  0. 29. 11.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15 29 16  3  8  3] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 22. 30. 22. 30.  8.  0.  9.  6.  3.  1.  0.  9. 10.  6. 10.  9.] 
adversary cards in hand: [3. 8. 8. 0. 0.] 
adversary cards in discard: [0. 6. 0. 3. 6. 6.] 
adversary owned cards: [ 1  3 29  8  3  0 10  3  8  8  6  6  0  6  0  6  0  3  0  0  8  8  0  0
  0  1  8 11  0  0  0] -> size -> 31 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 70.17041778564453



action possibilites: [-1] 
expected returns: [[108.925186]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  3.  1.  0. 10.] 
cards in discard: [ 0.  1. 29. 10. 29.  3.  3. 25.  0. 11. 25.  0. 29. 11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15 29 16  3  8  3] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 22. 30. 22. 30.  8.  0.  9.  6.  3.  1.  0.  9. 10.  6. 10.  9.] 
adversary cards in hand: [3. 8. 8. 0. 0.] 
adversary cards in discard: [0. 6. 0. 3. 6. 6.] 
adversary owned cards: [ 1  3 29  8  3  0 10  3  8  8  6  6  0  6  0  6  0  3  0  0  8  8  0  0
  0  1  8 11  0  0  0] -> size -> 31 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 55.141571044921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[108.7758 ]
 [121.96526]
 [114.08354]
 [ 94.28665]
 [124.30228]
 [119.65991]
 [113.83932]
 [131.25446]
 [ 85.33823]
 [119.12772]
 [116.80797]
 [100.26281]
 [109.94024]
 [113.51171]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.  3.  1.  0. 10.] 
cards in discard: [ 0.  1. 29. 10. 29.  3.  3. 25.  0. 11. 25.  0. 29. 11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15 29 16  3  8  3] -> size -> 47 
action values: 0 
buys: 1 
player value: 5 
card supply: [16. 22. 30. 22. 30.  8.  0.  9.  6.  3.  1.  0.  9. 10.  6. 10.  9.] 
adversary cards in hand: [3. 8. 8. 0. 0.] 
adversary cards in discard: [0. 6. 0. 3. 6. 6.] 
adversary owned cards: [ 1  3 29  8  3  0 10  3  8  8  6  6  0  6  0  6  0  3  0  0  8  8  0  0
  0  1  8 11  0  0  0] -> size -> 31 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 108.92518615722656



Player 0 won the game! 



Player 0 bought cards:
Copper: 1 
Silver: 6 
Gold: 0 
Estate: 3 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 1 
Workshop: 3 
Chapel: 1 
Witch: 10 
Poacher: 9 
Militia: 0 
Market: 0 
Village: 2 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 1. 29.  3.  1.  0. 10.] 
cards in discard: [ 0.  1. 29. 10. 29.  3.  3. 25.  0. 11. 25.  0. 29. 11. 25.] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25 29  1 11 25 29  3 10 29 25 25 25
 25  0 29 29 25 10 10 25  1 25  1  1 11 11 29  1 29 15 29 16  3  8  3 25] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 22. 30. 22. 30.  8.  0.  9.  6.  3.  0.  0.  9. 10.  6. 10.  9.] 
adversary cards in hand: [3. 8. 8. 0. 0.] 
adversary cards in discard: [0. 6. 0. 3. 6. 6.] 
adversary owned cards: [ 1  3 29  8  3  0 10  3  8  8  6  6  0  6  0  6  0  3  0  0  8  8  0  0
  0  1  8 11  0  0  0] -> size -> 31 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[     -5 3000000       0     180       0       0      20       0       0
       0       0    -130       0       0     125       0] 
sum of rewards: 3000190 

action type: buy - action 25.0
Learning step: 120002.34375
desired expected reward: 120133.6015625



