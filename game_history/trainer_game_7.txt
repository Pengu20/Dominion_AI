 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[24.223063]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [15.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    0    0    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -505 

action type: buy - action -1.0
Learning step: -16.22780990600586
desired expected reward: 19.699172973632812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[23.387407]
 [23.664305]
 [23.641378]
 [23.3047  ]
 [24.166336]
 [23.912361]
 [23.889437]
 [24.51365 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [15.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6339683532714844
desired expected reward: 23.88105010986328



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [15.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [15.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[24.160105]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6293901801109314
desired expected reward: 23.884260177612305





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[23.033533]
 [23.310432]
 [23.287508]
 [22.950825]
 [23.152573]
 [23.812464]
 [23.55849 ]
 [23.894651]
 [23.475784]
 [23.535566]
 [23.752684]
 [24.159777]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6334012746810913
desired expected reward: 23.749391555786133



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[24.572245]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [15.  3.  0.  3.  0.] 
adversary cards in discard: [3. 0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6139846444129944
desired expected reward: 23.545791625976562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[23.813604]
 [24.090502]
 [24.06758 ]
 [23.730898]
 [23.932648]
 [24.592535]
 [24.33856 ]
 [24.674723]
 [24.255857]
 [24.315638]
 [24.532757]
 [24.93985 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [15.  3.  0.  3.  0.] 
adversary cards in discard: [3. 0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6388939619064331
desired expected reward: 24.20001792907715



buy possibilites: [-1] 
expected returns: [[24.978767]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [15.  3.  0.  3.  0.] 
adversary cards in discard: [3. 0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 10.0
Learning step: -0.4821920394897461
desired expected reward: 23.833446502685547






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [15.  3.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0.  3.  0.] 
cards in discard: [3. 0. 0. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [3. 0. 0. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [3. 0. 0. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 3.  0.  0.  0.  0.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [10.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[26.034021]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [10.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 11] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6237260103225708
desired expected reward: 24.35504150390625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[25.468586]
 [25.745485]
 [25.722559]
 [25.38588 ]
 [26.247517]
 [25.993544]
 [25.970617]
 [26.59483 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [10.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 11] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6641998291015625
desired expected reward: 25.58694839477539



buy possibilites: [-1] 
expected returns: [[27.424738]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [10.  0.  0.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 11] -> size -> 12 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: -3.0 

action type: buy - action 3.0
Learning step: -0.5737170577049255
desired expected reward: 25.14884376525879






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3] -> size -> 12 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3] -> size -> 12 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 11  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3] -> size -> 12 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[27.066061]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 15. 11.] 
adversary cards in discard: [1. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 11  1] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6862249374389648
desired expected reward: 26.738513946533203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[26.10957 ]
 [26.386469]
 [26.363543]
 [26.026865]
 [26.8885  ]
 [26.634527]
 [26.6116  ]
 [27.235815]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 15. 11.] 
adversary cards in discard: [1. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 11  1] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6885555982589722
desired expected reward: 26.598798751831055



buy possibilites: [-1] 
expected returns: [[27.61878]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 15. 11.] 
adversary cards in discard: [1. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 11  1] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: -3.0 

action type: buy - action 8.0
Learning step: -0.5990386009216309
desired expected reward: 26.03548812866211






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 15. 11.] 
cards in discard: [1. 0. 3. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 11  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [8. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8] -> size -> 13 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 15. 11.] 
cards in discard: [1. 0. 3. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 11  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [8. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8] -> size -> 13 
adversary victory points: 4
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[27.106949]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [8. 3. 3. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [15.  0. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 11  1] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6923659443855286
desired expected reward: 26.926414489746094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[26.028269]
 [26.305166]
 [26.282246]
 [25.945566]
 [26.807203]
 [26.553228]
 [26.530302]
 [27.154514]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [8. 3. 3. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [15.  0. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 11  1] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6884957551956177
desired expected reward: 26.56840705871582



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [15.  0. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3 11  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8] -> size -> 13 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  3 11  1] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8] -> size -> 13 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  3 11  1] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8] -> size -> 13 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 15  3 11  1  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8] -> size -> 13 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [ 3.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[26.589287]
 [25.965075]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 3. 1.] 
adversary cards in discard: [ 0. 15. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  3 11  1  0] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6857313513755798
desired expected reward: 26.468782424926758





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[25.865255]
 [26.142153]
 [26.11923 ]
 [25.78255 ]
 [26.644188]
 [26.390215]
 [26.367289]
 [26.991499]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 3. 1.] 
adversary cards in discard: [ 0. 15. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  3 11  1  0] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6768596768379211
desired expected reward: 26.135116577148438



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 1.] 
cards in discard: [ 0. 15. 11.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  3 11  1  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [ 3.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8] -> size -> 13 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 1.] 
cards in discard: [ 0. 15. 11.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  3 11  1  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [ 3.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8] -> size -> 13 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 1.] 
cards in discard: [ 0. 15. 11.  3.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  3 11  1  0  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [ 3.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8] -> size -> 13 
adversary victory points: 4
player victory points: 5 





Player: 0 
cards in hand: [8. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[27.059887]
 [26.474333]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 3.] 
cards in discard: [ 3.  0.  0. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  1.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  3 11  1  0  3] -> size -> 14 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6561716794967651
desired expected reward: 25.658241271972656



action possibilites: [-1] 
expected returns: [[26.59381]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 3.  0.  0. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 10  3  8] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  1.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  3 11  1  0  3] -> size -> 14 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 7
Learning step: -0.08157943189144135
desired expected reward: 26.945568084716797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[25.50012 ]
 [25.417013]
 [26.60419 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3.  0.  0. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 10  3  8] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  1.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  3 11  1  0  3] -> size -> 14 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.07488572597503662
desired expected reward: 26.518922805786133






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [11.  1.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  3 11  1  0  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  3  8] -> size -> 10 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  3 11  1  0  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  3  8] -> size -> 10 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  0.  0.  0.] 
cards in discard: [14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  3 11  1  0  3 14] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [8. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 10  3  8] -> size -> 10 
adversary victory points: 2
player victory points: 5 





Player: 0 
cards in hand: [8. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[25.05143 ]
 [24.465876]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 10  3  8] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0. 15.  3.  3.] 
adversary cards in discard: [14. 11.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  3 11  1  0  3 14] -> size -> 15 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6852209568023682
desired expected reward: 25.91897201538086



action possibilites: [-1] 
expected returns: [[24.538681]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0 10  3  8] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0. 15.  3.  3.] 
adversary cards in discard: [14. 11.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  3 11  1  0  3 14] -> size -> 15 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 1
Learning step: -0.023438872769474983
desired expected reward: 24.34639549255371





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[23.820004]
 [24.069324]
 [23.736895]
 [24.338518]
 [24.924072]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0 10  3  8] -> size -> 9 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0. 15.  3.  3.] 
adversary cards in discard: [14. 11.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  3 11  1  0  3 14] -> size -> 15 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.03072669915854931
desired expected reward: 24.507953643798828






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 15.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15.  3.  3.] 
cards in discard: [14. 11.  1.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  3 11  1  0  3 14] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [8. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0 10  3  8] -> size -> 9 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 15.  3.  3.] 
cards in discard: [14. 11.  1.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  3 11  1  0  3 14] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [8. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0 10  3  8] -> size -> 9 
adversary victory points: 1
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[29.878586]
 [29.269201]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [8. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 10  3  8] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  3 11  1  0  3 14] -> size -> 15 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5842912197113037
desired expected reward: 24.339780807495117



action possibilites: [-1.] 
expected returns: [[25.277765]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0 10  3  8] -> size -> 9 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  3 11  1  0  3 14] -> size -> 15 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -0.16913160681724548
desired expected reward: 29.315805435180664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[24.242088]
 [24.51524 ]
 [24.49141 ]
 [24.1822  ]
 [24.15898 ]
 [24.358454]
 [25.009926]
 [24.760603]
 [25.15012 ]
 [25.088966]
 [24.675623]
 [24.546621]
 [24.736774]
 [24.273472]
 [24.948772]
 [25.346155]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0 10  3  8] -> size -> 9 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  3 11  1  0  3 14] -> size -> 15 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.048001211136579514
desired expected reward: 25.229764938354492



buy possibilites: [-1] 
expected returns: [[28.218584]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0 10  3  8 16] -> size -> 10 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 27. 30.  8. 10.  9.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  3 11  1  0  3 14] -> size -> 15 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  8.  0.] 
sum of rewards: 23.0 

action type: buy - action 16.0
Learning step: 0.25554147362709045
desired expected reward: 24.613994598388672






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  3 11  1  0  3 14] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8. 10.  9.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 10  3  8 16] -> size -> 10 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  3 11  1  0  3 14] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 27. 30.  8. 10.  9.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 10  3  8 16] -> size -> 10 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  3 11  1  0  3 14  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 27. 30.  8. 10.  9.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 10  3  8 16] -> size -> 10 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [0. 0. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[25.168484]
 [24.582932]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 10  3  8 16] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8. 10.  9.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  1. 15.  0. 14.] 
adversary cards in discard: [0. 3. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  3 11  1  0  3 14  0] -> size -> 16 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7324139475822449
desired expected reward: 27.486169815063477





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[24.315855]
 [24.589003]
 [24.565172]
 [24.232746]
 [25.08369 ]
 [24.83437 ]
 [24.81054 ]
 [25.419922]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 10  3  8 16] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 27. 30.  8. 10.  9.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  1. 15.  0. 14.] 
adversary cards in discard: [0. 3. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  3 11  1  0  3 14  0] -> size -> 16 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6505969166755676
desired expected reward: 24.740156173706055



buy possibilites: [-1] 
expected returns: [[27.829885]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 3. 0.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 10  3  8 16  6] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 29. 30. 27. 30.  8.  9.  9.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  1. 15.  0. 14.] 
adversary cards in discard: [0. 3. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15  3 11  1  0  3 14  0] -> size -> 16 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.584769248962402
desired expected reward: 14.647978782653809






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 0.  1. 15.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 15.  0. 14.] 
cards in discard: [0. 3. 3. 0. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15  3 11  1  0  3 14  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8.  9.  9.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [10. 16.  0.  0.  0.] 
adversary cards in discard: [6. 0. 0. 8. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0 10  3  8 16  6] -> size -> 11 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 14.] 
cards in discard: [0. 3. 3. 0. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 15  3 11  1  0  3 14  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 29. 30. 27. 30.  8.  9.  9.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [10. 16.  0.  0.  0.] 
adversary cards in discard: [6. 0. 0. 8. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0 10  3  8 16  6] -> size -> 11 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 14.] 
cards in discard: [0. 3. 3. 0. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 15  3 11  1  0  3 14  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 29. 30. 27. 30.  8.  9.  9.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [10. 16.  0.  0.  0.] 
adversary cards in discard: [6. 0. 0. 8. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0 10  3  8 16  6] -> size -> 11 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 14.] 
cards in discard: [0. 3. 3. 0. 3. 0. 1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 15  3 11  1  0  3 14  0  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 28. 30. 27. 30.  8.  9.  9.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [10. 16.  0.  0.  0.] 
adversary cards in discard: [6. 0. 0. 8. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0 10  3  8 16  6] -> size -> 11 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [10. 16.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
expected returns: [[28.572096]
 [27.962713]
 [27.58439 ]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 16.  0.  0.  0.] 
cards in discard: [6. 0. 0. 8. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 10  3  8 16  6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  9.  9.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  3.  0.] 
adversary cards in discard: [ 0.  3.  3.  0.  3.  0.  1. 15.  1.  0. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3 11  1  0  3 14  0  1] -> size -> 16 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6876696944236755
desired expected reward: 27.142215728759766



action possibilites: [-1] 
expected returns: [[22.609962]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6.  0.  0.  8.  3.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  8 16  6 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  9.  9.  9.  9. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  3.  0.] 
adversary cards in discard: [ 0.  3.  3.  0.  3.  0.  1. 15.  1.  0. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3 11  1  0  3 14  0  1] -> size -> 16 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 9
Learning step: 0.36263391375541687
desired expected reward: 27.188323974609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[21.960966]
 [22.22995 ]
 [22.206055]
 [21.879406]
 [22.716402]
 [22.471315]
 [22.447414]
 [23.043575]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6.  0.  0.  8.  3.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  8 16  6 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 27. 30.  8.  9.  9.  9.  9. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  3.  0.] 
adversary cards in discard: [ 0.  3.  3.  0.  3.  0.  1. 15.  1.  0. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3 11  1  0  3 14  0  1] -> size -> 16 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.007995471358299255
desired expected reward: 22.617958068847656






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  3.  0.] 
cards in discard: [ 0.  3.  3.  0.  3.  0.  1. 15.  1.  0. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  3 11  1  0  3 14  0  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  9.  9.  9.  9. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  8.  6. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  8 16  6 29] -> size -> 11 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  3.  0.] 
cards in discard: [ 0.  3.  3.  0.  3.  0.  1. 15.  1.  0. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  3 11  1  0  3 14  0  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 27. 30.  8.  9.  9.  9.  9. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  8.  6. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  8 16  6 29] -> size -> 11 
adversary victory points: 0
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  8.  6. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
expected returns: [[24.944988]
 [24.372725]
 [23.976437]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  6. 16.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  8 16  6 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  9.  9.  9.  9. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  1.  0. 15. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3 11  1  0  3 14  0  1] -> size -> 16 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5815602540969849
desired expected reward: 22.46201515197754



action possibilites: [-1] 
expected returns: [[22.019096]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0.] 
cards in discard: [3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  8 16  6 29  3] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 26. 30.  8.  9.  9.  9.  9. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  1.  0. 15. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3 11  1  0  3 14  0  1] -> size -> 16 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 19 

action type: gain_card_n - action 1
Learning step: 0.15904150903224945
desired expected reward: 21.564342498779297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[20.983301]
 [20.901743]
 [22.06591 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0.] 
cards in discard: [3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  8 16  6 29  3] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 28. 30. 26. 30.  8.  9.  9.  9.  9. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  1.  0. 15. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 15  3 11  1  0  3 14  0  1] -> size -> 16 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.01482822373509407
desired expected reward: 22.033924102783203






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 0.  1.  0. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0. 15. 11.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15  3 11  1  0  3 14  0  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 26. 30.  8.  9.  9.  9.  9. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  0. 29.] 
adversary cards in discard: [ 3. 16.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8 16  6 29  3] -> size -> 11 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 11.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 28. 30. 26. 30.  8.  9.  9.  9.  9. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  0. 29.] 
adversary cards in discard: [ 3. 16.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8 16  6 29  3] -> size -> 11 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 11.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 28. 30. 26. 30.  8.  9.  9.  9.  9. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  0. 29.] 
adversary cards in discard: [ 3. 16.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8 16  6 29  3] -> size -> 11 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 11.] 
cards in discard: [22.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 26. 30.  8.  9.  9.  9.  9. 10.  9.  9. 10.  9.  9.  9.] 
adversary cards in hand: [ 0.  0.  3.  0. 29.] 
adversary cards in discard: [ 3. 16.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  8 16  6 29  3] -> size -> 11 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [ 0.  0.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[28.68046 ]
 [28.429768]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 29.] 
cards in discard: [ 3. 16.  8.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8 16  6 29  3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 26. 30.  8.  9.  9.  9.  9. 10.  9.  9. 10.  9.  9.  9.] 
adversary cards in hand: [14.  3.  3.  0.  0.] 
adversary cards in discard: [22. 15.  1.  0. 11.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22] -> size -> 16 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5102967619895935
desired expected reward: 21.555614471435547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[28.004398]
 [28.273384]
 [28.249489]
 [27.922842]
 [28.759834]
 [28.514748]
 [28.490849]
 [29.08701 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 29.] 
cards in discard: [ 3. 16.  8.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8 16  6 29  3] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 26. 30.  8.  9.  9.  9.  9. 10.  9.  9. 10.  9.  9.  9.] 
adversary cards in hand: [14.  3.  3.  0.  0.] 
adversary cards in discard: [22. 15.  1.  0. 11.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22] -> size -> 16 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7152023315429688
desired expected reward: 28.11655616760254



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [14.  3.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  3.  0.  0.] 
cards in discard: [22. 15.  1.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 26. 30.  8.  9.  9.  9.  9. 10.  9.  9. 10.  9.  9.  9.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8 16  6 29  3] -> size -> 11 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  3.  0.  0.] 
cards in discard: [22. 15.  1.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 26. 30.  8.  9.  9.  9.  9. 10.  9.  9. 10.  9.  9.  9.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8 16  6 29  3] -> size -> 11 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  3.  0.  0.] 
cards in discard: [22. 15.  1.  0. 11.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 26. 30.  8.  9.  9.  9.  9. 10.  9.  9. 10.  9.  9.  9.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8 16  6 29  3] -> size -> 11 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [6. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[27.525969]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8 16  6 29  3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8.  9.  9.  9.  9. 10.  9.  9. 10.  9.  9.  9.] 
adversary cards in hand: [3. 3. 0. 0. 1.] 
adversary cards in discard: [22. 15.  1.  0. 11.  0. 14.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0] -> size -> 17 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.7313408851623535
desired expected reward: 28.355667114257812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[26.857359]
 [27.126343]
 [27.102446]
 [26.7758  ]
 [27.612793]
 [27.367704]
 [27.343807]
 [27.93997 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8 16  6 29  3] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 26. 30.  8.  9.  9.  9.  9. 10.  9.  9. 10.  9.  9.  9.] 
adversary cards in hand: [3. 3. 0. 0. 1.] 
adversary cards in discard: [22. 15.  1.  0. 11.  0. 14.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0] -> size -> 17 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6944915056228638
desired expected reward: 27.045440673828125



buy possibilites: [-1] 
expected returns: [[28.569977]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8 16  6 29  3  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 25. 30.  8.  9.  9.  9.  9. 10.  9.  9. 10.  9.  9.  9.] 
adversary cards in hand: [3. 3. 0. 0. 1.] 
adversary cards in discard: [22. 15.  1.  0. 11.  0. 14.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: -3.0 

action type: buy - action 3.0
Learning step: -0.6030886173248291
desired expected reward: 26.499359130859375






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 1.] 
cards in discard: [22. 15.  1.  0. 11.  0. 14.  3.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  9.  9.  9.  9. 10.  9.  9. 10.  9.  9.  9.] 
adversary cards in hand: [ 3.  8. 29.  0.  0.] 
adversary cards in discard: [3. 6. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  8 16  6 29  3  3] -> size -> 12 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 1.] 
cards in discard: [22. 15.  1.  0. 11.  0. 14.  3.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 28. 30. 25. 30.  8.  9.  9.  9.  9. 10.  9.  9. 10.  9.  9.  9.] 
adversary cards in hand: [ 3.  8. 29.  0.  0.] 
adversary cards in discard: [3. 6. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  8 16  6 29  3  3] -> size -> 12 
adversary victory points: 2
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3.  8. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[32.878555]
 [32.306297]
 [32.627865]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 29.  0.  0.] 
cards in discard: [3. 6. 0. 3. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8 16  6 29  3  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  9.  9.  9.  9. 10.  9.  9. 10.  9.  9.  9.] 
adversary cards in hand: [ 0. 15.  1.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6622809171676636
desired expected reward: 27.907695770263672



action possibilites: [-1.  8. 16.] 
expected returns: [[33.11964 ]
 [32.554295]
 [32.159107]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0.  0. 16.] 
cards in discard: [3. 6. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  8 16  6 29  3  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 25. 30.  8.  9.  9.  9.  9. 10.  9.  9. 10.  9.  9.  9.] 
adversary cards in hand: [ 0. 15.  1.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: -0.18819259107112885
desired expected reward: 32.62041473388672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[31.890955]
 [32.159214]
 [32.134888]
 [31.809458]
 [32.642857]
 [32.398922]
 [32.3746  ]
 [32.964268]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  0.  0. 16.] 
cards in discard: [3. 6. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  8 16  6 29  3  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 25. 30.  8.  9.  9.  9.  9. 10.  9.  9. 10.  9.  9.  9.] 
adversary cards in hand: [ 0. 15.  1.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.20307031273841858
desired expected reward: 32.916568756103516



buy possibilites: [-1] 
expected returns: [[27.537487]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  0.  0. 16.] 
cards in discard: [ 3.  6.  0.  3.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  8 16  6 29  3  3 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  9.  9.  9.  9. 10.  9.  9. 10.  8.  9.  9.] 
adversary cards in hand: [ 0. 15.  1.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0] -> size -> 17 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 10.0
Learning step: 0.30790579319000244
desired expected reward: 32.68250274658203






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 0. 15.  1.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  1.  1.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  9.  9.  9.  9. 10.  9.  9. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  0.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8 16  6 29  3  3 10] -> size -> 13 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  1.  1.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 28. 30. 25. 30.  8.  9.  9.  9.  9. 10.  9.  9. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  0.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8 16  6 29  3  3 10] -> size -> 13 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  1.  1.  3.] 
cards in discard: [14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 25. 30.  8.  9.  9.  9.  9. 10.  9.  8. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  0.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8 16  6 29  3  3 10] -> size -> 13 
adversary victory points: 2
player victory points: 5 





Player: 0 
cards in hand: [ 0.  0.  0.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[26.241367]
 [25.676025]
 [25.651703]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  8. 10.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8 16  6 29  3  3 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  9.  9.  9.  9. 10.  9.  8. 10.  8.  9.  9.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [14.  0. 15.  1.  1.  3.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14] -> size -> 18 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7023165822029114
desired expected reward: 26.83517074584961



action possibilites: [-1.  8. 29.] 
expected returns: [[27.425594]
 [26.860249]
 [27.179111]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  8. 29.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  8 16  6 29  3  3 10] -> size -> 13 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  9.  9.  9.  9. 10.  9.  8. 10.  8.  9.  9.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [14.  0. 15.  1.  1.  3.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14] -> size -> 18 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -0.038163185119628906
desired expected reward: 25.757129669189453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[26.276445]
 [26.544706]
 [26.52038 ]
 [26.19495 ]
 [27.028353]
 [26.784412]
 [26.76009 ]
 [27.349758]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  8. 29.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  8 16  6 29  3  3 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 25. 30.  8.  9.  9.  9.  9. 10.  9.  8. 10.  8.  9.  9.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [14.  0. 15.  1.  1.  3.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14] -> size -> 18 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.0912012830376625
desired expected reward: 27.334392547607422



buy possibilites: [-1] 
expected returns: [[28.408894]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  8. 29.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  8 16  6 29  3  3 10  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 28. 30. 25. 30.  8.  8.  9.  9.  9. 10.  9.  8. 10.  8.  9.  9.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [14.  0. 15.  1.  1.  3.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14] -> size -> 18 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -285.0 

action type: buy - action 6.0
Learning step: -9.037554740905762
desired expected reward: 17.157394409179688






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 3. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.  0.] 
cards in discard: [14.  0. 15.  1.  1.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  8.  9.  9.  9. 10.  9.  8. 10.  8.  9.  9.] 
adversary cards in hand: [3. 0. 6. 3. 0.] 
adversary cards in discard: [ 6. 10.  0.  0.  0.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  8 16  6 29  3  3 10  6] -> size -> 14 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [14.  0. 15.  1.  1.  3. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  8.  9.  9.  9. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [3. 0. 6. 3. 0.] 
adversary cards in discard: [ 6. 10.  0.  0.  0.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  8 16  6 29  3  3 10  6] -> size -> 14 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [14.  0. 15.  1.  1.  3. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 25. 30.  8.  8.  9.  9.  9. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [3. 0. 6. 3. 0.] 
adversary cards in discard: [ 6. 10.  0.  0.  0.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  8 16  6 29  3  3 10  6] -> size -> 14 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [14.  0. 15.  1.  1.  3. 10. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14 10 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  8.  9.  8.  9. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [3. 0. 6. 3. 0.] 
adversary cards in discard: [ 6. 10.  0.  0.  0.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  8 16  6 29  3  3 10  6] -> size -> 14 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [3. 0. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[30.202145]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 3. 0.] 
cards in discard: [ 6. 10.  0.  0.  0.  8. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8 16  6 29  3  3 10  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  8.  9.  8.  9. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [14. 22.  3.  0.  3.] 
adversary cards in discard: [14.  0. 15.  1.  1.  3. 10. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14 10 11] -> size -> 20 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6836313605308533
desired expected reward: 27.725261688232422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[29.448826]
 [29.692762]
 [29.36733 ]
 [29.956793]
 [30.522139]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3. 0.] 
cards in discard: [ 6. 10.  0.  0.  0.  8. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8 16  6 29  3  3 10  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 25. 30.  8.  8.  9.  8.  9. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [14. 22.  3.  0.  3.] 
adversary cards in discard: [14.  0. 15.  1.  1.  3. 10. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14 10 11] -> size -> 20 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7459907531738281
desired expected reward: 29.600238800048828



buy possibilites: [-1] 
expected returns: [[27.109915]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3. 0.] 
cards in discard: [ 6. 10.  0.  0.  0.  8. 29.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8 16  6 29  3  3 10  6  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 24. 30.  8.  8.  9.  8.  9. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [14. 22.  3.  0.  3.] 
adversary cards in discard: [14.  0. 15.  1.  1.  3. 10. 11. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14 10 11] -> size -> 20 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 3.0
Learning step: -0.5161287784576416
desired expected reward: 29.176633834838867






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [14. 22.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 22.  3.  0.  3.] 
cards in discard: [14.  0. 15.  1.  1.  3. 10. 11. 11.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14 10 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 24. 30.  8.  8.  9.  8.  9. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [ 6.  3.  0.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8 16  6 29  3  3 10  6  3] -> size -> 15 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 22.  3.  0.  3.] 
cards in discard: [14.  0. 15.  1.  1.  3. 10. 11. 11.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14 10 11] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 24. 30.  8.  8.  9.  8.  9. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [ 6.  3.  0.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  8 16  6 29  3  3 10  6  3] -> size -> 15 
adversary victory points: 2
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 6.  3.  0.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[26.793303]
 [25.83277 ]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  0.  3. 16.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  8 16  6 29  3  3 10  6  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 24. 30.  8.  8.  9.  8.  9. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [14.  3.  1.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14 10 11] -> size -> 20 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6840881109237671
desired expected reward: 26.425827026367188



action possibilites: [-1] 
expected returns: [[26.010477]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  8 16  6 29  3  3 10  6  3  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 24. 30.  8.  8.  9.  8.  8. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [14.  3.  1.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14 10 11] -> size -> 20 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 19 

action type: gain_card_n - action 6
Learning step: 0.1271217167377472
desired expected reward: 23.993398666381836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[24.902452]
 [24.82096 ]
 [25.975767]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  8 16  6 29  3  3 10  6  3  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 24. 30.  8.  8.  9.  8.  8. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [14.  3.  1.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14 10 11] -> size -> 20 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.06380750238895416
desired expected reward: 25.94666862487793



buy possibilites: [-1] 
expected returns: [[23.81638]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3.] 
cards in discard: [8. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  8 16  6 29  3  3 10  6  3  8  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 24. 30.  8.  8.  9.  8.  8. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [14.  3.  1.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14 10 11] -> size -> 20 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: -0.047001685947179794
desired expected reward: 24.855453491210938






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [14.  3.  1.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  1.  0.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14 10 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 24. 30.  8.  8.  9.  8.  8. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  0. 10.  8.  0.] 
adversary cards in discard: [ 8.  0. 16.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  8 16  6 29  3  3 10  6  3  8  0] -> size -> 16 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  1.  0.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14 10 11] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 24. 30.  8.  8.  9.  8.  8. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  0. 10.  8.  0.] 
adversary cards in discard: [ 8.  0. 16.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  8 16  6 29  3  3 10  6  3  8  0] -> size -> 16 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  1.  0.  3.] 
cards in discard: [0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14 10 11  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 28. 30. 24. 30.  8.  8.  9.  8.  8. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  0. 10.  8.  0.] 
adversary cards in discard: [ 8.  0. 16.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  8 16  6 29  3  3 10  6  3  8  0] -> size -> 16 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [ 0.  0. 10.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[29.10167 ]
 [28.512001]
 [28.536324]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  8.  0.] 
cards in discard: [ 8.  0. 16.  6.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8 16  6 29  3  3 10  6  3  8  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8.  8.  9.  8.  8. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [14.  0.  3.  3.  0.] 
adversary cards in discard: [ 0. 14.  3.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14 10 11  0] -> size -> 21 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5601712465286255
desired expected reward: 23.256208419799805



action possibilites: [-1] 
expected returns: [[22.457653]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 8.  0. 16.  6.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  8 16  6 29  3  3  6  3  8  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8.  8.  9.  8.  8. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [14.  0.  3.  3.  0.] 
adversary cards in discard: [ 0. 14.  3.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14 10 11  0] -> size -> 21 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 8
Learning step: -0.1618729531764984
desired expected reward: 28.094072341918945





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[21.649504]
 [21.568266]
 [22.70703 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 8.  0. 16.  6.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  8 16  6 29  3  3  6  3  8  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8.  8.  9.  8.  8. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [14.  0.  3.  3.  0.] 
adversary cards in discard: [ 0. 14.  3.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14 10 11  0] -> size -> 21 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.008544616401195526
desired expected reward: 22.466197967529297



buy possibilites: [-1] 
expected returns: [[24.549559]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 8.  0. 16.  6.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  8 16  6 29  3  3  6  3  8  0  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 24. 30.  8.  8.  9.  8.  8. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [14.  0.  3.  3.  0.] 
adversary cards in discard: [ 0. 14.  3.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14 10 11  0] -> size -> 21 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: buy - action 0.0
Learning step: 0.05828527361154556
desired expected reward: 21.707788467407227






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [14.  0.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  3.  3.  0.] 
cards in discard: [ 0. 14.  3.  1.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14 10 11  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 24. 30.  8.  8.  9.  8.  8. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [ 3.  3. 29.  6.  0.] 
adversary cards in discard: [ 8.  0. 16.  6.  0.  3.  0.  8.] 
adversary owned cards: [ 0  0  8 16  6 29  3  3  6  3  8  0  0] -> size -> 13 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  3.  3.  0.] 
cards in discard: [ 0. 14.  3.  1.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14 10 11  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 24. 30.  8.  8.  9.  8.  8. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [ 3.  3. 29.  6.  0.] 
adversary cards in discard: [ 8.  0. 16.  6.  0.  3.  0.  8.] 
adversary owned cards: [ 0  0  8 16  6 29  3  3  6  3  8  0  0] -> size -> 13 
adversary victory points: 1
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3.  3. 29.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[32.88902]
 [32.64905]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29.  6.  0.] 
cards in discard: [ 8.  0. 16.  6.  0.  3.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8 16  6 29  3  3  6  3  8  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 24. 30.  8.  8.  9.  8.  8. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [10.  0.  0. 11.  0.] 
adversary cards in discard: [ 0. 14.  3.  1.  0.  3. 14.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14 10 11  0] -> size -> 21 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5402836799621582
desired expected reward: 24.009275436401367





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[32.017796]
 [31.93656 ]
 [33.075325]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 29.  6.  0.] 
cards in discard: [ 8.  0. 16.  6.  0.  3.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8 16  6 29  3  3  6  3  8  0  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 28. 30. 24. 30.  8.  8.  9.  8.  8. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [10.  0.  0. 11.  0.] 
adversary cards in discard: [ 0. 14.  3.  1.  0.  3. 14.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14 10 11  0] -> size -> 21 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.8008899092674255
desired expected reward: 32.26681900024414



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [10.  0.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 11.  0.] 
cards in discard: [ 0. 14.  3.  1.  0.  3. 14.  0.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14 10 11  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 24. 30.  8.  8.  9.  8.  8. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [0. 0. 8. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8 16  6 29  3  3  6  3  8  0  0] -> size -> 13 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [ 0. 14.  3.  1.  0.  3. 14.  0.  3.  3.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14 10 11  0  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 24. 30.  8.  7.  9.  8.  8. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [0. 0. 8. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8 16  6 29  3  3  6  3  8  0  0] -> size -> 13 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [ 0. 14.  3.  1.  0.  3. 14.  0.  3.  3.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14 10 11  0  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 28. 30. 24. 30.  8.  7.  9.  8.  8. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [0. 0. 8. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8 16  6 29  3  3  6  3  8  0  0] -> size -> 13 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [ 0. 14.  3.  1.  0.  3. 14.  0.  3.  3.  0.  6.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14 10 11  0  6  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 24. 30.  8.  7.  9.  8.  7. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [0. 0. 8. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8 16  6 29  3  3  6  3  8  0  0] -> size -> 13 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 8. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[27.127876]
 [26.574034]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 6. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8 16  6 29  3  3  6  3  8  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 24. 30.  8.  7.  9.  8.  7. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [15.  1.  3. 11. 22.] 
adversary cards in discard: [ 0. 14.  3.  1.  0.  3. 14.  0.  3.  3.  0.  6.  8. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14 10 11  0  6  8] -> size -> 23 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.8578636646270752
desired expected reward: 32.21746063232422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[26.42763 ]
 [26.693823]
 [26.669018]
 [26.346392]
 [27.1727  ]
 [26.931316]
 [26.906507]
 [27.485155]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 6. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8 16  6 29  3  3  6  3  8  0  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 28. 30. 24. 30.  8.  7.  9.  8.  7. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [15.  1.  3. 11. 22.] 
adversary cards in discard: [ 0. 14.  3.  1.  0.  3. 14.  0.  3.  3.  0.  6.  8. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14 10 11  0  6  8] -> size -> 23 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6861233711242676
desired expected reward: 26.620756149291992



buy possibilites: [-1] 
expected returns: [[23.961626]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 6. 0.] 
cards in discard: [11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8 16  6 29  3  3  6  3  8  0  0 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 24. 30.  8.  7.  9.  7.  7. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [15.  1.  3. 11. 22.] 
adversary cards in discard: [ 0. 14.  3.  1.  0.  3. 14.  0.  3.  3.  0.  6.  8. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14 10 11  0  6  8] -> size -> 23 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: -0.17358392477035522
desired expected reward: 26.999116897583008






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [15.  1.  3. 11. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 22.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1.  3. 11. 22.] 
cards in discard: [ 0. 14.  3.  1.  0.  3. 14.  0.  3.  3.  0.  6.  8. 11. 10.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14 10 11  0  6  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 24. 30.  8.  7.  9.  7.  7. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [29.  6.  3.  3.  3.] 
adversary cards in discard: [11.  0.  0.  8.  6.  0.] 
adversary owned cards: [ 0  0  8 16  6 29  3  3  6  3  8  0  0 11] -> size -> 14 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1.  3. 22.] 
cards in discard: [ 0. 14.  3.  1.  0.  3. 14.  0.  3.  3.  0.  6.  8. 11. 10.  0.  0.  0.
  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14 10 11  0  6  8  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 24. 30.  8.  7.  9.  7.  7. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [29.  6.  3.  3.  3.] 
adversary cards in discard: [11.  0.  0.  8.  6.  0.] 
adversary owned cards: [ 0  0  8 16  6 29  3  3  6  3  8  0  0 11] -> size -> 14 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1.  3. 22.] 
cards in discard: [ 0. 14.  3.  1.  0.  3. 14.  0.  3.  3.  0.  6.  8. 11. 10.  0.  0.  0.
  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14 10 11  0  6  8  1] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 27. 30. 24. 30.  8.  7.  9.  7.  7. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [29.  6.  3.  3.  3.] 
adversary cards in discard: [11.  0.  0.  8.  6.  0.] 
adversary owned cards: [ 0  0  8 16  6 29  3  3  6  3  8  0  0 11] -> size -> 14 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [29.  6.  3.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[24.274115]
 [24.034147]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6.  3.  3.  3.] 
cards in discard: [11.  0.  0.  8.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8 16  6 29  3  3  6  3  8  0  0 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 24. 30.  8.  7.  9.  7.  7. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  0. 11. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14 10 11  0  6  8  1] -> size -> 24 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6134158968925476
desired expected reward: 23.348209381103516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[23.316525]
 [23.235285]
 [24.374048]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6.  3.  3.  3.] 
cards in discard: [11.  0.  0.  8.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8 16  6 29  3  3  6  3  8  0  0 11] -> size -> 14 
action values: 1 
buys: 1 
player value: 0 
card supply: [24. 27. 30. 24. 30.  8.  7.  9.  7.  7. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  0. 11. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14 10 11  0  6  8  1] -> size -> 24 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6329100728034973
desired expected reward: 23.790021896362305



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 11. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 14.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14 10 11  0  6  8  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 24. 30.  8.  7.  9.  7.  7. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  8.  0.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8 16  6 29  3  3  6  3  8  0  0 11] -> size -> 14 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14 10 11  0  6  8  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 27. 30. 24. 30.  8.  7.  9.  7.  7. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [8. 0. 8.] 
adversary cards in discard: [ 0. 16.] 
adversary owned cards: [ 0  0  8 16  6 29  3  3  6  3  8  0  0 11] -> size -> 14 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14 10 11  0  6  8  1] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 27. 30. 24. 30.  8.  7.  9.  7.  7. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [8. 0. 8.] 
adversary cards in discard: [ 0. 16.] 
adversary owned cards: [ 0  0  8 16  6 29  3  3  6  3  8  0  0 11] -> size -> 14 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.] 
cards in discard: [1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14 10 11  0  6  8  1
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 26. 30. 24. 30.  8.  7.  9.  7.  7. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [8. 0. 8.] 
adversary cards in discard: [ 0. 16.] 
adversary owned cards: [ 0  0  8 16  6 29  3  3  6  3  8  0  0 11] -> size -> 14 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [8. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[28.693422]
 [28.139582]
 [28.139582]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8.] 
cards in discard: [ 0. 16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8 16  6 29  3  3  6  3  8  0  0 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 24. 30.  8.  7.  9.  7.  7. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [ 8. 15.  3. 11.  3.] 
adversary cards in discard: [ 1. 14.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14 10 11  0  6  8  1
  1] -> size -> 25 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 1
Learning step: -0.6675101518630981
desired expected reward: 26.57491111755371



action possibilites: [-1] 
expected returns: [[28.091602]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0. 16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 24. 30.  8.  7.  9.  7.  7. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [ 8. 15.  3. 11.  3.] 
adversary cards in discard: [ 1. 14.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14 10 11  0  6  8  1
  1] -> size -> 25 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 1
Learning step: -0.09267671406269073
desired expected reward: 27.828609466552734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[27.098776]
 [27.017542]
 [28.156301]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0. 16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 24. 30.  8.  7.  9.  7.  7. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [ 8. 15.  3. 11.  3.] 
adversary cards in discard: [ 1. 14.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14 10 11  0  6  8  1
  1] -> size -> 25 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.10325649380683899
desired expected reward: 27.988346099853516






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 8. 15.  3. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  3. 11.  3.] 
cards in discard: [ 1. 14.  0.  0. 11.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15  3 11  1  0  3 14  0  1 22  0 14 10 11  0  6  8  1
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 24. 30.  8.  7.  9.  7.  7. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [ 6.  3. 11.  0.  3.] 
adversary cards in discard: [ 0. 16.  8.  0.] 
adversary owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11] -> size -> 13 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.] 
cards in discard: [ 1. 14.  0.  0. 11.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 15  3  1  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 24. 30.  8.  7.  9.  7.  7. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [ 6.  3. 11.  0.  3.] 
adversary cards in discard: [ 0. 16.  8.  0.] 
adversary owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11] -> size -> 13 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.] 
cards in discard: [ 1. 14.  0.  0. 11.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 15  3  1  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 26. 30. 24. 30.  8.  7.  9.  7.  7. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [ 6.  3. 11.  0.  3.] 
adversary cards in discard: [ 0. 16.  8.  0.] 
adversary owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11] -> size -> 13 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.] 
cards in discard: [ 1. 14.  0.  0. 11.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 15  3  1  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 30.  8.  7.  9.  7.  7. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [ 6.  3. 11.  0.  3.] 
adversary cards in discard: [ 0. 16.  8.  0.] 
adversary owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11] -> size -> 13 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [ 6.  3. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[23.278946]
 [22.974874]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 11.  0.  3.] 
cards in discard: [ 0. 16.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 30.  8.  7.  9.  7.  7. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [ 3.  1.  0.  1. 14.] 
adversary cards in discard: [ 1. 14.  0.  0. 11.  0.  0.  8. 15.  3.] 
adversary owned cards: [ 0  0  0  3  3 15  3  1  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0] -> size -> 24 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.7396474480628967
desired expected reward: 27.070716857910156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[22.520292]
 [22.43945 ]
 [23.561731]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 11.  0.  3.] 
cards in discard: [ 0. 16.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 26. 30. 24. 30.  8.  7.  9.  7.  7. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [ 3.  1.  0.  1. 14.] 
adversary cards in discard: [ 1. 14.  0.  0. 11.  0.  0.  8. 15.  3.] 
adversary owned cards: [ 0  0  0  3  3 15  3  1  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0] -> size -> 24 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6113476157188416
desired expected reward: 22.811565399169922



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 3.  1.  0.  1. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  0.  1. 14.] 
cards in discard: [ 1. 14.  0.  0. 11.  0.  0.  8. 15.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15  3  1  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 30.  8.  7.  9.  7.  7. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  0.  3.  6. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11] -> size -> 13 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 1.] 
cards in discard: [ 1. 14.  0.  0. 11.  0.  0.  8. 15.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3 15  3  1  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 26. 30. 24. 30.  8.  7.  9.  7.  7. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  6. 29.] 
adversary cards in discard: [0. 3.] 
adversary owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11] -> size -> 13 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 1.] 
cards in discard: [ 1. 14.  0.  0. 11.  0.  0.  8. 15.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3 15  3  1  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 7 
card supply: [23. 26. 30. 24. 30.  8.  7.  9.  7.  7. 10.  9.  8. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  6. 29.] 
adversary cards in discard: [0. 3.] 
adversary owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11] -> size -> 13 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 1.] 
cards in discard: [ 1. 14.  0.  0. 11.  0.  0.  8. 15.  3. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3 15  3  1  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0
 14] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 26. 30. 24. 30.  8.  7.  9.  7.  7. 10.  9.  7. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  6. 29.] 
adversary cards in discard: [0. 3.] 
adversary owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11] -> size -> 13 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [ 0.  6. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[20.25087 ]
 [20.016619]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 29.] 
cards in discard: [0. 3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 30.  8.  7.  9.  7.  7. 10.  9.  7. 10.  7.  9.  9.] 
adversary cards in hand: [10.  3.  3.  6.  0.] 
adversary cards in discard: [ 1. 14.  0.  0. 11.  0.  0.  8. 15.  3. 14. 14.  3.  1.  0.  1.] 
adversary owned cards: [ 0  0  0  3  3 15  3  1  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0
 14] -> size -> 25 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 2
Learning step: -0.6290364861488342
desired expected reward: 22.445804595947266



action possibilites: [-1.] 
expected returns: [[21.808146]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6.] 
cards in discard: [0. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 24. 30.  8.  7.  9.  7.  7. 10.  9.  7. 10.  7.  9.  9.] 
adversary cards in hand: [10.  3.  3.  6.  0.] 
adversary cards in discard: [ 1. 14.  0.  0. 11.  0.  0.  8. 15.  3. 14. 14.  3.  1.  0.  1.] 
adversary owned cards: [ 0  0  0  3  3 15  3  1  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0
 14] -> size -> 25 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0.07403434813022614
desired expected reward: 20.239072799682617





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[20.700783]
 [20.93953 ]
 [20.619936]
 [21.199402]
 [21.742222]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6.] 
cards in discard: [0. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 26. 30. 24. 30.  8.  7.  9.  7.  7. 10.  9.  7. 10.  7.  9.  9.] 
adversary cards in hand: [10.  3.  3.  6.  0.] 
adversary cards in discard: [ 1. 14.  0.  0. 11.  0.  0.  8. 15.  3. 14. 14.  3.  1.  0.  1.] 
adversary owned cards: [ 0  0  0  3  3 15  3  1  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0
 14] -> size -> 25 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.0181534755975008
desired expected reward: 21.8262996673584



buy possibilites: [-1] 
expected returns: [[30.933289]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6.] 
cards in discard: [0. 3. 8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 30.  8.  7.  9.  7.  6. 10.  9.  7. 10.  7.  9.  9.] 
adversary cards in hand: [10.  3.  3.  6.  0.] 
adversary cards in discard: [ 1. 14.  0.  0. 11.  0.  0.  8. 15.  3. 14. 14.  3.  1.  0.  1.] 
adversary owned cards: [ 0  0  0  3  3 15  3  1  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0
 14] -> size -> 25 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 23 

action type: buy - action 8.0
Learning step: 0.3788175582885742
desired expected reward: 21.578216552734375






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [10.  3.  3.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3.  6.  0.] 
cards in discard: [ 1. 14.  0.  0. 11.  0.  0.  8. 15.  3. 14. 14.  3.  1.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15  3  1  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0
 14] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 30.  8.  7.  9.  7.  6. 10.  9.  7. 10.  7.  9.  9.] 
adversary cards in hand: [16.  8.  3.  0. 11.] 
adversary cards in discard: [ 0.  3.  8. 29.  0.  6.  6.] 
adversary owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11  8] -> size -> 14 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3.  6.  0.] 
cards in discard: [ 1. 14.  0.  0. 11.  0.  0.  8. 15.  3. 14. 14.  3.  1.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15  3  1  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0
 14] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 26. 30. 24. 30.  8.  7.  9.  7.  6. 10.  9.  7. 10.  7.  9.  9.] 
adversary cards in hand: [16.  8.  3.  0. 11.] 
adversary cards in discard: [ 0.  3.  8. 29.  0.  6.  6.] 
adversary owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11  8] -> size -> 14 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3.  6.  0.] 
cards in discard: [ 1. 14.  0.  0. 11.  0.  0.  8. 15.  3. 14. 14.  3.  1.  0.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15  3  1  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0
 14  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 26. 30. 24. 30.  8.  7.  9.  7.  6. 10.  9.  7. 10.  7.  9.  9.] 
adversary cards in hand: [16.  8.  3.  0. 11.] 
adversary cards in discard: [ 0.  3.  8. 29.  0.  6.  6.] 
adversary owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11  8] -> size -> 14 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [16.  8.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 11.] 
expected returns: [[27.211271]
 [26.278175]
 [26.668453]
 [26.9072  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8.  3.  0. 11.] 
cards in discard: [ 0.  3.  8. 29.  0.  6.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8.  7.  9.  7.  6. 10.  9.  7. 10.  7.  9.  9.] 
adversary cards in hand: [ 1.  0.  0.  1. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 15  3  1  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0
 14  0] -> size -> 26 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7945302724838257
desired expected reward: 30.138757705688477





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[26.31757 ]
 [26.236725]
 [27.359009]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  8.  3.  0. 11.] 
cards in discard: [ 0.  3.  8. 29.  0.  6.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 24. 30.  8.  7.  9.  7.  6. 10.  9.  7. 10.  7.  9.  9.] 
adversary cards in hand: [ 1.  0.  0.  1. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 15  3  1  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0
 14  0] -> size -> 26 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6893784403800964
desired expected reward: 26.66360855102539



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 1.  0.  0.  1. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0.  1. 22.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15  3  1  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0
 14  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8.  7.  9.  7.  6. 10.  9.  7. 10.  7.  9.  9.] 
adversary cards in hand: [ 6.  3. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11  8] -> size -> 14 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0.  1. 22.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15  3  1  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0
 14  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 6 
card supply: [22. 26. 30. 24. 30.  8.  7.  9.  7.  6. 10.  9.  7. 10.  7.  9.  9.] 
adversary cards in hand: [ 6.  3. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11  8] -> size -> 14 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0.  1. 22.] 
cards in discard: [14.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15  3  1  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0
 14  0 14] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 26. 30. 24. 30.  8.  7.  9.  7.  6. 10.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [ 6.  3. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11  8] -> size -> 14 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [ 6.  3. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[20.99984 ]
 [20.695768]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8.  7.  9.  7.  6. 10.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [ 0. 11.  0. 10. 14.] 
adversary cards in discard: [14.  1.  0.  0.  1. 22.] 
adversary owned cards: [ 0  0  0  3  3 15  3  1  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0
 14  0 14] -> size -> 27 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.750037431716919
desired expected reward: 26.608970642089844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[20.091875]
 [20.01103 ]
 [21.133312]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 24. 30.  8.  7.  9.  7.  6. 10.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [ 0. 11.  0. 10. 14.] 
adversary cards in discard: [14.  1.  0.  0.  1. 22.] 
adversary owned cards: [ 0  0  0  3  3 15  3  1  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0
 14  0 14] -> size -> 27 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5684727430343628
desired expected reward: 20.57533073425293



buy possibilites: [-1] 
expected returns: [[26.025007]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 11.  0.  3.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11  8  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 24. 30.  8.  7.  9.  7.  6. 10.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [ 0. 11.  0. 10. 14.] 
adversary cards in discard: [14.  1.  0.  0.  1. 22.] 
adversary owned cards: [ 0  0  0  3  3 15  3  1  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0
 14  0 14] -> size -> 27 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.4794936776161194
desired expected reward: 19.612380981445312






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  0. 10. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 10. 14.] 
cards in discard: [14.  1.  0.  0.  1. 22.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15  3  1  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0
 14  0 14] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 24. 30.  8.  7.  9.  7.  6. 10.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [ 0.  0. 16.  3.  0.] 
adversary cards in discard: [ 0.  6.  3. 11.  0.  3.] 
adversary owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11  8  0] -> size -> 15 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 10.] 
cards in discard: [14.  1.  0.  0.  1. 22.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3 15  3  1  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0
 14  0 14] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 26. 30. 24. 30.  8.  7.  9.  7.  6. 10.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 0.  6.  3. 11.  0.  3. 16.  3.] 
adversary owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11  8  0] -> size -> 15 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 10.] 
cards in discard: [14.  1.  0.  0.  1. 22.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3 15  3  1  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0
 14  0 14] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 26. 30. 24. 30.  8.  7.  9.  7.  6. 10.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 0.  6.  3. 11.  0.  3. 16.  3.] 
adversary owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11  8  0] -> size -> 15 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 10.] 
cards in discard: [14.  1.  0.  0.  1. 22. 16.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3 15  3  1  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0
 14  0 14 16] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 24. 30.  8.  7.  8.  7.  6. 10.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 0.  6.  3. 11.  0.  3. 16.  3.] 
adversary owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11  8  0] -> size -> 15 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[24.559578]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0.  6.  3. 11.  0.  3. 16.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11  8  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 24. 30.  8.  7.  8.  7.  6. 10.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [1. 0. 8. 0. 3.] 
adversary cards in discard: [14.  1.  0.  0.  1. 22. 16. 14.  0. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  3  3 15  3  1  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0
 14  0 14 16] -> size -> 28 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 3
Learning step: -0.7774174213409424
desired expected reward: 28.778589248657227





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[23.966223]
 [24.229717]
 [24.20497 ]
 [23.885376]
 [24.703587]
 [24.464842]
 [24.440096]
 [25.007662]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0.  6.  3. 11.  0.  3. 16.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11  8  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 26. 30. 24. 30.  8.  7.  8.  7.  6. 10.  9.  6. 10.  7.  9.  9.] 
adversary cards in hand: [1. 0. 8. 0. 3.] 
adversary cards in discard: [14.  1.  0.  0.  1. 22. 16. 14.  0. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  3  3 15  3  1  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0
 14  0 14 16] -> size -> 28 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.633587121963501
desired expected reward: 24.058107376098633



buy possibilites: [-1] 
expected returns: [[22.9749]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0.  6.  3. 11.  0.  3. 16.  3. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11  8  0 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 24. 30.  8.  7.  8.  7.  6. 10.  9.  6. 10.  6.  9.  9.] 
adversary cards in hand: [1. 0. 8. 0. 3.] 
adversary cards in discard: [14.  1.  0.  0.  1. 22. 16. 14.  0. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  3  3 15  3  1  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0
 14  0 14 16] -> size -> 28 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 10.0
Learning step: -0.09666526317596436
desired expected reward: 24.343433380126953






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [1. 0. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 8. 0. 3.] 
cards in discard: [14.  1.  0.  0.  1. 22. 16. 14.  0. 11.  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 15  3  1  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0
 14  0 14 16] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 24. 30.  8.  7.  8.  7.  6. 10.  9.  6. 10.  6.  9.  9.] 
adversary cards in hand: [11.  8.  8.  6. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11  8  0 10] -> size -> 16 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [14.  1.  0.  0.  1. 22. 16. 14.  0. 11.  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 15  3  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0 14  0 14 16] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 24. 30.  8.  7.  8.  7.  6. 10.  9.  6. 10.  6.  9.  9.] 
adversary cards in hand: [11.  8.  8.  6. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11  8  0 10] -> size -> 16 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [14.  1.  0.  0.  1. 22. 16. 14.  0. 11.  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 15  3  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0 14  0 14 16] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 26. 30. 24. 30.  8.  7.  8.  7.  6. 10.  9.  6. 10.  6.  9.  9.] 
adversary cards in hand: [11.  8.  8.  6. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11  8  0 10] -> size -> 16 
adversary victory points: 1
player victory points: 2 





Player: 0 
cards in hand: [11.  8.  8.  6. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8. 29.] 
expected returns: [[20.649984]
 [20.35494 ]
 [20.120615]
 [20.120615]
 [20.42271 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  8.  6. 29.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11  8  0 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 24. 30.  8.  7.  8.  7.  6. 10.  9.  6. 10.  6.  9.  9.] 
adversary cards in hand: [14.  3.  1.  6.  0.] 
adversary cards in discard: [14.  1.  0.  0.  1. 22. 16. 14.  0. 11.  0. 10.  8.] 
adversary owned cards: [ 0  3 15  3  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0 14  0 14 16] -> size -> 24 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6236079931259155
desired expected reward: 22.35129165649414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[19.64693 ]
 [19.56707 ]
 [20.667921]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  8.  6. 29.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11  8  0 10] -> size -> 16 
action values: 1 
buys: 1 
player value: 0 
card supply: [21. 26. 30. 24. 30.  8.  7.  8.  7.  6. 10.  9.  6. 10.  6.  9.  9.] 
adversary cards in hand: [14.  3.  1.  6.  0.] 
adversary cards in discard: [14.  1.  0.  0.  1. 22. 16. 14.  0. 11.  0. 10.  8.] 
adversary owned cards: [ 0  3 15  3  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0 14  0 14 16] -> size -> 24 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5626283288002014
desired expected reward: 20.227384567260742



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [14.  3.  1.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  1.  6.  0.] 
cards in discard: [14.  1.  0.  0.  1. 22. 16. 14.  0. 11.  0. 10.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 15  3  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0 14  0 14 16] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 24. 30.  8.  7.  8.  7.  6. 10.  9.  6. 10.  6.  9.  9.] 
adversary cards in hand: [16.  0.  3.  6. 10.] 
adversary cards in discard: [11.  8.  8.  6. 29.] 
adversary owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11  8  0 10] -> size -> 16 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 6. 0.] 
cards in discard: [14.  1.  0.  0.  1. 22. 16. 14.  0. 11.  0. 10.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3 15  3  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0 14  0 14 16] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 26. 30. 24. 30.  8.  7.  8.  7.  6. 10.  9.  6. 10.  6.  9.  9.] 
adversary cards in hand: [ 0.  6. 10.] 
adversary cards in discard: [11.  8.  8.  6. 29. 16.  3.] 
adversary owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11  8  0 10] -> size -> 16 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 6. 0.] 
cards in discard: [14.  1.  0.  0.  1. 22. 16. 14.  0. 11.  0. 10.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3 15  3  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0 14  0 14 16] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 26. 30. 24. 30.  8.  7.  8.  7.  6. 10.  9.  6. 10.  6.  9.  9.] 
adversary cards in hand: [ 0.  6. 10.] 
adversary cards in discard: [11.  8.  8.  6. 29. 16.  3.] 
adversary owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11  8  0 10] -> size -> 16 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 6. 0.] 
cards in discard: [14.  1.  0.  0.  1. 22. 16. 14.  0. 11.  0. 10.  8. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3 15  3  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0 14  0 14 16
 15] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 24. 30.  8.  7.  8.  7.  6. 10.  9.  6. 10.  6.  9.  8.] 
adversary cards in hand: [ 0.  6. 10.] 
adversary cards in discard: [11.  8.  8.  6. 29. 16.  3.] 
adversary owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11  8  0 10] -> size -> 16 
adversary victory points: 1
player victory points: 2 





Player: 0 
cards in hand: [ 0.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[27.656734]
 [27.102272]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 10.] 
cards in discard: [11.  8.  8.  6. 29. 16.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11  8  0 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 24. 30.  8.  7.  8.  7.  6. 10.  9.  6. 10.  6.  9.  8.] 
adversary cards in hand: [ 0. 15.  0.  3. 14.] 
adversary cards in discard: [14.  1.  0.  0.  1. 22. 16. 14.  0. 11.  0. 10.  8. 15. 14.  3.  1.  6.
  0.] 
adversary owned cards: [ 0  3 15  3  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0 14  0 14 16
 15] -> size -> 25 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 3
Learning step: -0.7411491274833679
desired expected reward: 28.616111755371094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[26.792591]
 [26.71273 ]
 [27.813583]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 10.] 
cards in discard: [11.  8.  8.  6. 29. 16.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11  8  0 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 26. 30. 24. 30.  8.  7.  8.  7.  6. 10.  9.  6. 10.  6.  9.  8.] 
adversary cards in hand: [ 0. 15.  0.  3. 14.] 
adversary cards in discard: [14.  1.  0.  0.  1. 22. 16. 14.  0. 11.  0. 10.  8. 15. 14.  3.  1.  6.
  0.] 
adversary owned cards: [ 0  3 15  3  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0 14  0 14 16
 15] -> size -> 25 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.697891116142273
desired expected reward: 27.101863861083984



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 0. 15.  0.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.  3. 14.] 
cards in discard: [14.  1.  0.  0.  1. 22. 16. 14.  0. 11.  0. 10.  8. 15. 14.  3.  1.  6.
  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 15  3  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0 14  0 14 16
 15] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 24. 30.  8.  7.  8.  7.  6. 10.  9.  6. 10.  6.  9.  8.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [11.  8.  8.  6. 29. 16.  3.  0.  6. 10.] 
adversary owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11  8  0 10] -> size -> 16 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.  3.] 
cards in discard: [14.  1.  0.  0.  1. 22. 16. 14.  0. 11.  0. 10.  8. 15. 14.  3.  1.  6.
  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3 15  3  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0 14  0 14 16
 15] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 26. 30. 24. 30.  8.  7.  8.  7.  6. 10.  9.  6. 10.  6.  9.  8.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [11.  8.  8.  6. 29. 16.  3.  0.  6. 10.  3.  0.] 
adversary owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11  8  0 10] -> size -> 16 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0.  3.] 
cards in discard: [14.  1.  0.  0.  1. 22. 16. 14.  0. 11.  0. 10.  8. 15. 14.  3.  1.  6.
  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3 15  3  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0 14  0 14 16
 15] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 26. 30. 24. 30.  8.  7.  8.  7.  6. 10.  9.  6. 10.  6.  9.  8.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [11.  8.  8.  6. 29. 16.  3.  0.  6. 10.  3.  0.] 
adversary owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11  8  0 10] -> size -> 16 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0.  3.] 
cards in discard: [14.  1.  0.  0.  1. 22. 16. 14.  0. 11.  0. 10.  8. 15. 14.  3.  1.  6.
  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3 15  3  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0 14  0 14 16
 15  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 26. 30. 23. 30.  8.  7.  8.  7.  6. 10.  9.  6. 10.  6.  9.  8.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [11.  8.  8.  6. 29. 16.  3.  0.  6. 10.  3.  0.] 
adversary owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11  8  0 10] -> size -> 16 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[27.627405]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [11.  8.  8.  6. 29. 16.  3.  0.  6. 10.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11  8  0 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 23. 30.  8.  7.  8.  7.  6. 10.  9.  6. 10.  6.  9.  8.] 
adversary cards in hand: [11.  6. 14.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 15  3  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0 14  0 14 16
 15  3] -> size -> 26 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 2
Learning step: -0.8253698348999023
desired expected reward: 31.387798309326172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[26.860733]
 [27.095055]
 [26.780872]
 [27.352358]
 [27.881727]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [11.  8.  8.  6. 29. 16.  3.  0.  6. 10.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11  8  0 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 26. 30. 23. 30.  8.  7.  8.  7.  6. 10.  9.  6. 10.  6.  9.  8.] 
adversary cards in hand: [11.  6. 14.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 15  3  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0 14  0 14 16
 15  3] -> size -> 26 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6945180892944336
desired expected reward: 27.022167205810547



buy possibilites: [-1] 
expected returns: [[34.026493]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [11.  8.  8.  6. 29. 16.  3.  0.  6. 10.  3.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11  8  0 10  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 23. 30.  8.  7.  8.  7.  5. 10.  9.  6. 10.  6.  9.  8.] 
adversary cards in hand: [11.  6. 14.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 15  3  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0 14  0 14 16
 15  3] -> size -> 26 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 8.0
Learning step: -0.37329262495040894
desired expected reward: 26.979066848754883






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [11.  6. 14.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6. 14.  8.  3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 15  3  0  3 14  0  1 22  0 14 10 11  0  6  8  1  1  0 14  0 14 16
 15  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 23. 30.  8.  7.  8.  7.  5. 10.  9.  6. 10.  6.  9.  8.] 
adversary cards in hand: [0. 6. 8. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11  8  0 10  8] -> size -> 17 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 23. 30.  8.  7.  8.  7.  5. 10.  9.  6. 10.  6.  9.  8.] 
adversary cards in hand: [0. 6. 8. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11  8  0 10  8] -> size -> 17 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 26. 30. 23. 30.  8.  7.  8.  7.  5. 10.  9.  6. 10.  6.  9.  8.] 
adversary cards in hand: [0. 6. 8. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11  8  0 10  8] -> size -> 17 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [0. 6. 8. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[19.907246]
 [19.377876]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8. 6. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16  6 29  3  3  6  3  8  0  0 11  8  0 10  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 23. 30.  8.  7.  8.  7.  5. 10.  9.  6. 10.  6.  9.  8.] 
adversary cards in hand: [ 0. 14.  1. 22. 15.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3] -> size -> 22 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.9624619483947754
desired expected reward: 33.064029693603516



action possibilites: [-1] 
expected returns: [[25.260485]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 16 29  3  3  6  3  8  0  0 11  8  0 10  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 23. 30.  8.  7.  8.  7.  5. 10.  9.  6. 10.  6.  9.  8.] 
adversary cards in hand: [ 0. 14.  1. 22. 15.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 1
Learning step: 0.13418415188789368
desired expected reward: 19.502548217773438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[24.236816]
 [24.471142]
 [24.156958]
 [24.728443]
 [25.257809]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 16 29  3  3  6  3  8  0  0 11  8  0 10  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 26. 30. 23. 30.  8.  7.  8.  7.  5. 10.  9.  6. 10.  6.  9.  8.] 
adversary cards in hand: [ 0. 14.  1. 22. 15.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.04838315770030022
desired expected reward: 25.212100982666016



buy possibilites: [-1] 
expected returns: [[26.356127]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0.] 
cards in discard: [3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 16 29  3  3  6  3  8  0  0 11  8  0 10  8  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 22. 30.  8.  7.  8.  7.  5. 10.  9.  6. 10.  6.  9.  8.] 
adversary cards in hand: [ 0. 14.  1. 22. 15.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 23 

action type: buy - action 3.0
Learning step: 0.23260505497455597
desired expected reward: 24.703746795654297






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [ 0. 14.  1. 22. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 22. 15.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  1. 22. 15.] 
cards in discard: [8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 22. 30.  8.  7.  8.  7.  5. 10.  9.  6. 10.  6.  9.  8.] 
adversary cards in hand: [ 3.  0.  8.  0. 11.] 
adversary cards in discard: [3. 8. 0. 6. 0.] 
adversary owned cards: [ 0  0 16 29  3  3  6  3  8  0  0 11  8  0 10  8  3] -> size -> 17 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 22. 15.] 
cards in discard: [8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 26. 30. 22. 30.  8.  7.  8.  7.  5. 10.  9.  6. 10.  6.  9.  8.] 
adversary cards in hand: [ 3.  8. 11.] 
adversary cards in discard: [3. 8. 0. 6. 0. 0. 0.] 
adversary owned cards: [ 0  0 16 29  3  3  6  3  8  0  0 11  8  0 10  8  3] -> size -> 17 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 22. 15.] 
cards in discard: [8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 26. 30. 22. 30.  8.  7.  8.  7.  5. 10.  9.  6. 10.  6.  9.  8.] 
adversary cards in hand: [ 3.  8. 11.] 
adversary cards in discard: [3. 8. 0. 6. 0. 0. 0.] 
adversary owned cards: [ 0  0 16 29  3  3  6  3  8  0  0 11  8  0 10  8  3] -> size -> 17 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 3.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[22.438974]
 [21.909607]
 [22.14393 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 11.] 
cards in discard: [3. 8. 0. 6. 0. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16 29  3  3  6  3  8  0  0 11  8  0 10  8  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 22. 30.  8.  7.  8.  7.  5. 10.  9.  6. 10.  6.  9.  8.] 
adversary cards in hand: [ 1.  0.  3.  3. 16.] 
adversary cards in discard: [ 8. 14.  0.  1. 22. 15.] 
adversary owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 1
Learning step: -0.6033768057823181
desired expected reward: 22.33682632446289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[21.408987]
 [21.329512]
 [22.421896]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 11.] 
cards in discard: [3. 8. 0. 6. 0. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16 29  3  3  6  3  8  0  0 11  8  0 10  8  3] -> size -> 17 
action values: 1 
buys: 1 
player value: 0 
card supply: [21. 26. 30. 22. 30.  8.  7.  8.  7.  5. 10.  9.  6. 10.  6.  9.  8.] 
adversary cards in hand: [ 1.  0.  3.  3. 16.] 
adversary cards in discard: [ 8. 14.  0.  1. 22. 15.] 
adversary owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5914100408554077
desired expected reward: 21.77342987060547



buy possibilites: [-1] 
expected returns: [[24.856436]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 11.] 
cards in discard: [3. 8. 0. 6. 0. 0. 0. 6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16 29  3  3  6  3  8  0  0 11  8  0 10  8  3  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 22. 30.  8.  6.  8.  7.  5. 10.  9.  6. 10.  6.  9.  8.] 
adversary cards in hand: [ 1.  0.  3.  3. 16.] 
adversary cards in discard: [ 8. 14.  0.  1. 22. 15.] 
adversary owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -305 

action type: buy - action 6.0
Learning step: -9.528891563415527
desired expected reward: 11.800618171691895






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 1.  0.  3.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3.  3. 16.] 
cards in discard: [ 8. 14.  0.  1. 22. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 22. 30.  8.  6.  8.  7.  5. 10.  9.  6. 10.  6.  9.  8.] 
adversary cards in hand: [ 8. 10. 16. 29.  0.] 
adversary cards in discard: [ 3.  8.  0.  6.  0.  0.  0.  6.  3.  8. 11.] 
adversary owned cards: [ 0  0 16 29  3  3  6  3  8  0  0 11  8  0 10  8  3  6] -> size -> 18 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3.  3. 16.] 
cards in discard: [ 8. 14.  0.  1. 22. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 26. 30. 22. 30.  8.  6.  8.  7.  5. 10.  9.  6. 10.  6.  9.  8.] 
adversary cards in hand: [ 8. 10. 16. 29.  0.] 
adversary cards in discard: [ 3.  8.  0.  6.  0.  0.  0.  6.  3.  8. 11.] 
adversary owned cards: [ 0  0 16 29  3  3  6  3  8  0  0 11  8  0 10  8  3  6] -> size -> 18 
adversary victory points: 2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 8. 10. 16. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 16. 29.] 
expected returns: [[26.720009]
 [26.195162]
 [26.170074]
 [25.812141]
 [26.495087]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 16. 29.  0.] 
cards in discard: [ 3.  8.  0.  6.  0.  0.  0.  6.  3.  8. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16 29  3  3  6  3  8  0  0 11  8  0 10  8  3  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 22. 30.  8.  6.  8.  7.  5. 10.  9.  6. 10.  6.  9.  8.] 
adversary cards in hand: [10.  0.  0. 15.  0.] 
adversary cards in discard: [ 8. 14.  0.  1. 22. 15.  1.  0.  3.  3. 16.] 
adversary owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6179825663566589
desired expected reward: 24.238452911376953



action possibilites: [-1.  8. 10. 16.] 
expected returns: [[30.061192]
 [29.53634 ]
 [29.51126 ]
 [29.153326]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 16.  0.  3.] 
cards in discard: [ 3.  8.  0.  6.  0.  0.  0.  6.  3.  8. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 16 29  3  3  6  3  8  0  0 11  8  0 10  8  3  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 22. 30.  8.  6.  8.  7.  5. 10.  9.  6. 10.  6.  9.  8.] 
adversary cards in hand: [10.  0.  0. 15.  0.] 
adversary cards in discard: [ 8. 14.  0.  1. 22. 15.  1.  0.  3.  3. 16.] 
adversary owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: -0.035828303545713425
desired expected reward: 26.54108238220215



action possibilites: [-1] 
expected returns: [[29.537142]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.] 
cards in discard: [ 3.  8.  0.  6.  0.  0.  0.  6.  3.  8. 11.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0  0 16 29  3  6  3  8  0  0 11  8  0 10  8  3  6  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 21. 30.  8.  6.  8.  7.  5. 10.  9.  6. 10.  6.  9.  8.] 
adversary cards in hand: [10.  0.  0. 15.  0.] 
adversary cards in discard: [ 8. 14.  0.  1. 22. 15.  1.  0.  3.  3. 16.] 
adversary owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  4  0] 
sum of rewards: 39 

action type: gain_card_n - action 2
Learning step: 0.6281282305717468
desired expected reward: 29.02851676940918





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[28.787584]
 [29.019918]
 [28.708107]
 [29.275646]
 [29.800493]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  0.] 
cards in discard: [ 3.  8.  0.  6.  0.  0.  0.  6.  3.  8. 11.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0  0 16 29  3  6  3  8  0  0 11  8  0 10  8  3  6  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 26. 30. 21. 30.  8.  6.  8.  7.  5. 10.  9.  6. 10.  6.  9.  8.] 
adversary cards in hand: [10.  0.  0. 15.  0.] 
adversary cards in discard: [ 8. 14.  0.  1. 22. 15.  1.  0.  3.  3. 16.] 
adversary owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.47106096148490906
desired expected reward: 30.008203506469727



buy possibilites: [-1] 
expected returns: [[31.671438]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  0.] 
cards in discard: [ 3.  8.  0.  6.  0.  0.  0.  6.  3.  8. 11.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0  0 16 29  3  6  3  8  0  0 11  8  0 10  8  3  6  3  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 26. 30. 21. 30.  8.  6.  8.  7.  5. 10.  9.  6. 10.  6.  9.  8.] 
adversary cards in hand: [10.  0.  0. 15.  0.] 
adversary cards in discard: [ 8. 14.  0.  1. 22. 15.  1.  0.  3.  3. 16.] 
adversary owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 40.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 35.0 

action type: buy - action 0.0
Learning step: 0.5189225673675537
desired expected reward: 29.306507110595703






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [10.  0.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 15.  0.] 
cards in discard: [ 8. 14.  0.  1. 22. 15.  1.  0.  3.  3. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 21. 30.  8.  6.  8.  7.  5. 10.  9.  6. 10.  6.  9.  8.] 
adversary cards in hand: [ 0.  3. 16.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 16 29  3  6  3  8  0  0 11  8  0 10  8  3  6  3  0] -> size -> 19 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  0.  0.] 
cards in discard: [ 8. 14.  0.  1. 22. 15.  1.  0.  3.  3. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 21. 30.  8.  6.  8.  7.  5. 10.  9.  6. 10.  6.  9.  8.] 
adversary cards in hand: [ 0.  3. 16.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 16 29  3  6  3  8  0  0 11  8  0 10  8  3  6  3  0] -> size -> 19 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  0.  0.] 
cards in discard: [ 8. 14.  0.  1. 22. 15.  1.  0.  3.  3. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 26. 30. 21. 30.  8.  6.  8.  7.  5. 10.  9.  6. 10.  6.  9.  8.] 
adversary cards in hand: [ 0.  3. 16.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 16 29  3  6  3  8  0  0 11  8  0 10  8  3  6  3  0] -> size -> 19 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  0.  0.] 
cards in discard: [ 8. 14.  0.  1. 22. 15.  1.  0.  3.  3. 16.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 26. 30. 20. 30.  8.  6.  8.  7.  5. 10.  9.  6. 10.  6.  9.  8.] 
adversary cards in hand: [ 0.  3. 16.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 16 29  3  6  3  8  0  0 11  8  0 10  8  3  6  3  0] -> size -> 19 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [ 0.  3. 16.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[24.24056 ]
 [23.332693]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 16.  0.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16 29  3  6  3  8  0  0 11  8  0 10  8  3  6  3  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 20. 30.  8.  6.  8.  7.  5. 10.  9.  6. 10.  6.  9.  8.] 
adversary cards in hand: [ 0. 14.  3. 14.  1.] 
adversary cards in discard: [ 8. 14.  0.  1. 22. 15.  1.  0.  3.  3. 16.  3. 10.  0.  0. 15.  0.  0.] 
adversary owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3] -> size -> 23 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.8476620316505432
desired expected reward: 30.823776245117188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[23.264257]
 [23.496595]
 [23.184782]
 [23.752317]
 [24.277166]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 16.  0.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16 29  3  6  3  8  0  0 11  8  0 10  8  3  6  3  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 26. 30. 20. 30.  8.  6.  8.  7.  5. 10.  9.  6. 10.  6.  9.  8.] 
adversary cards in hand: [ 0. 14.  3. 14.  1.] 
adversary cards in discard: [ 8. 14.  0.  1. 22. 15.  1.  0.  3.  3. 16.  3. 10.  0.  0. 15.  0.  0.] 
adversary owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3] -> size -> 23 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6330887675285339
desired expected reward: 23.77587890625



buy possibilites: [-1] 
expected returns: [[20.458584]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 16.  0.  3.] 
cards in discard: [3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16 29  3  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 19. 30.  8.  6.  8.  7.  5. 10.  9.  6. 10.  6.  9.  8.] 
adversary cards in hand: [ 0. 14.  3. 14.  1.] 
adversary cards in discard: [ 8. 14.  0.  1. 22. 15.  1.  0.  3.  3. 16.  3. 10.  0.  0. 15.  0.  0.] 
adversary owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3] -> size -> 23 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 3.0
Learning step: -0.40008270740509033
desired expected reward: 23.096511840820312






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [ 0. 14.  3. 14.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3. 14.  1.] 
cards in discard: [ 8. 14.  0.  1. 22. 15.  1.  0.  3.  3. 16.  3. 10.  0.  0. 15.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 19. 30.  8.  6.  8.  7.  5. 10.  9.  6. 10.  6.  9.  8.] 
adversary cards in hand: [6. 3. 3. 0. 0.] 
adversary cards in discard: [ 3.  0.  3. 16.  0.  3.] 
adversary owned cards: [ 0  0 16 29  3  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3] -> size -> 20 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 14.  1.] 
cards in discard: [ 8. 14.  0.  1. 22. 15.  1.  0.  3.  3. 16.  3. 10.  0.  0. 15.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 26. 30. 19. 30.  8.  6.  8.  7.  5. 10.  9.  6. 10.  6.  9.  8.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [ 3.  0.  3. 16.  0.  3.  6.  3.] 
adversary owned cards: [ 0  0 16 29  3  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3] -> size -> 20 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 14.  1.] 
cards in discard: [ 8. 14.  0.  1. 22. 15.  1.  0.  3.  3. 16.  3. 10.  0.  0. 15.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 26. 30. 19. 30.  8.  6.  8.  7.  5. 10.  9.  6. 10.  6.  9.  8.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [ 3.  0.  3. 16.  0.  3.  6.  3.] 
adversary owned cards: [ 0  0 16 29  3  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3] -> size -> 20 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 14.  1.] 
cards in discard: [ 8. 14.  0.  1. 22. 15.  1.  0.  3.  3. 16.  3. 10.  0.  0. 15.  0.  0.
 23.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 19. 30.  8.  6.  8.  7.  5. 10.  9.  6.  9.  6.  9.  8.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [ 3.  0.  3. 16.  0.  3.  6.  3.] 
adversary owned cards: [ 0  0 16 29  3  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3] -> size -> 20 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[23.084875]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [ 3.  0.  3. 16.  0.  3.  6.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16 29  3  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 19. 30.  8.  6.  8.  7.  5. 10.  9.  6.  9.  6.  9.  8.] 
adversary cards in hand: [ 0.  0. 14.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 4
Learning step: -0.8047856092453003
desired expected reward: 29.14445686340332





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[22.314007]
 [22.546345]
 [22.234533]
 [22.802069]
 [23.326916]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 3.  0.  3. 16.  0.  3.  6.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16 29  3  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 26. 30. 19. 30.  8.  6.  8.  7.  5. 10.  9.  6.  9.  6.  9.  8.] 
adversary cards in hand: [ 0.  0. 14.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6070592999458313
desired expected reward: 22.60167121887207



buy possibilites: [-1] 
expected returns: [[27.612598]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 3.  0.  3. 16.  0.  3.  6.  3.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16 29  3  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 26. 30. 19. 30.  8.  5.  8.  7.  5. 10.  9.  6.  9.  6.  9.  8.] 
adversary cards in hand: [ 0.  0. 14.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23] -> size -> 24 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.523563385009766
desired expected reward: 12.710969924926758






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 14.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  0.  1.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 19. 30.  8.  5.  8.  7.  5. 10.  9.  6.  9.  6.  9.  8.] 
adversary cards in hand: [ 8. 11.  8. 10.  6.] 
adversary cards in discard: [ 3.  0.  3. 16.  0.  3.  6.  3.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0 16 29  3  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6] -> size -> 21 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 26. 30. 19. 30.  8.  5.  8.  7.  5. 10.  9.  6.  9.  6.  9.  8.] 
adversary cards in hand: [8. 8. 6.] 
adversary cards in discard: [ 3.  0.  3. 16.  0.  3.  6.  3.  6.  3.  0.  0. 11. 10.] 
adversary owned cards: [ 0  0 16 29  3  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6] -> size -> 21 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23] -> size -> 24 
action values: 0 
buys: 1 
player value: 7 
card supply: [20. 26. 30. 19. 30.  8.  5.  8.  7.  5. 10.  9.  6.  9.  6.  9.  8.] 
adversary cards in hand: [8. 8. 6.] 
adversary cards in discard: [ 3.  0.  3. 16.  0.  3.  6.  3.  6.  3.  0.  0. 11. 10.] 
adversary owned cards: [ 0  0 16 29  3  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6] -> size -> 21 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1.] 
cards in discard: [4.] 
cards in deck: 19 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23
  4] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 26. 30. 19. 29.  8.  5.  8.  7.  5. 10.  9.  6.  9.  6.  9.  8.] 
adversary cards in hand: [8. 8. 6.] 
adversary cards in discard: [ 3.  0.  3. 16.  0.  3.  6.  3.  6.  3.  0.  0. 11. 10.] 
adversary owned cards: [ 0  0 16 29  3  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6] -> size -> 21 
adversary victory points: 2
player victory points: 7 





Player: 0 
cards in hand: [8. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[27.664717]
 [27.142597]
 [27.142597]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 6.] 
cards in discard: [ 3.  0.  3. 16.  0.  3.  6.  3.  6.  3.  0.  0. 11. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16 29  3  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 19. 29.  8.  5.  8.  7.  5. 10.  9.  6.  9.  6.  9.  8.] 
adversary cards in hand: [ 0. 23.  1.  3.  3.] 
adversary cards in discard: [ 4. 14.  0.  0.  0.  1.] 
adversary owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23
  4] -> size -> 25 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 1
Learning step: -0.7268891930580139
desired expected reward: 28.087644577026367





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[26.684706]
 [26.604921]
 [27.691856]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 6.] 
cards in discard: [ 3.  0.  3. 16.  0.  3.  6.  3.  6.  3.  0.  0. 11. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16 29  3  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6] -> size -> 21 
action values: 1 
buys: 1 
player value: 0 
card supply: [20. 26. 30. 19. 29.  8.  5.  8.  7.  5. 10.  9.  6.  9.  6.  9.  8.] 
adversary cards in hand: [ 0. 23.  1.  3.  3.] 
adversary cards in discard: [ 4. 14.  0.  0.  0.  1.] 
adversary owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23
  4] -> size -> 25 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6950149536132812
desired expected reward: 26.968852996826172



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [ 0. 23.  1.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 23.  1.  3.  3.] 
cards in discard: [ 4. 14.  0.  0.  0.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23
  4] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 19. 29.  8.  5.  8.  7.  5. 10.  9.  6.  9.  6.  9.  8.] 
adversary cards in hand: [ 6.  0.  8.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 16 29  3  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6] -> size -> 21 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 23.  1.  3.  3.] 
cards in discard: [ 4. 14.  0.  0.  0.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23
  4] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 26. 30. 19. 29.  8.  5.  8.  7.  5. 10.  9.  6.  9.  6.  9.  8.] 
adversary cards in hand: [ 6.  0.  8.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 16 29  3  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6] -> size -> 21 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 23.  1.  3.  3.] 
cards in discard: [ 4. 14.  0.  0.  0.  1. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23
  4 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 19. 29.  8.  5.  8.  6.  5. 10.  9.  6.  9.  6.  9.  8.] 
adversary cards in hand: [ 6.  0.  8.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 16 29  3  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6] -> size -> 21 
adversary victory points: 2
player victory points: 7 





Player: 0 
cards in hand: [ 6.  0.  8.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[26.693018]
 [26.170898]
 [26.469131]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  8.  0. 29.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16 29  3  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 19. 29.  8.  5.  8.  6.  5. 10.  9.  6.  9.  6.  9.  8.] 
adversary cards in hand: [ 3.  8. 10.  0. 14.] 
adversary cards in discard: [ 4. 14.  0.  0.  0.  1. 11.  0. 23.  1.  3.  3.] 
adversary owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23
  4 11] -> size -> 26 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.7011971473693848
desired expected reward: 26.99066162109375



action possibilites: [-1.  8.] 
expected returns: [[26.671398]
 [26.149279]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 16 29  3  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 26. 30. 19. 29.  8.  5.  8.  6.  5. 10.  9.  6.  9.  6.  9.  8.] 
adversary cards in hand: [ 3.  8. 10.  0. 14.] 
adversary cards in discard: [ 4. 14.  0.  0.  0.  1. 11.  0. 23.  1.  3.  3.] 
adversary owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23
  4 11] -> size -> 26 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: -0.07013339549303055
desired expected reward: 26.529539108276367





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[25.915344]
 [26.171179]
 [26.146732]
 [25.83556 ]
 [26.631765]
 [26.400375]
 [26.375937]
 [26.922497]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 16 29  3  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 26. 30. 19. 29.  8.  5.  8.  6.  5. 10.  9.  6.  9.  6.  9.  8.] 
adversary cards in hand: [ 3.  8. 10.  0. 14.] 
adversary cards in discard: [ 4. 14.  0.  0.  0.  1. 11.  0. 23.  1.  3.  3.] 
adversary owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23
  4 11] -> size -> 26 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.07268531620502472
desired expected reward: 26.598712921142578






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [ 3.  8. 10.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 14.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 10.  0. 14.] 
cards in discard: [ 4. 14.  0.  0.  0.  1. 11.  0. 23.  1.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23
  4 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 19. 29.  8.  5.  8.  6.  5. 10.  9.  6.  9.  6.  9.  8.] 
adversary cards in hand: [ 0. 11.  8.  0.  6.] 
adversary cards in discard: [29.  6.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0 16 29  3  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6] -> size -> 21 
adversary victory points: 2
player victory points: 7 


action possibilites: [-1.  8. 14. 15.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0. 14. 15.] 
cards in discard: [ 4. 14.  0.  0.  0.  1. 11.  0. 23.  1.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23
  4 11] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 19. 29.  8.  5.  8.  6.  5. 10.  9.  6.  9.  6.  9.  8.] 
adversary cards in hand: [ 0. 11.  8.  0.  6.] 
adversary cards in discard: [29.  6.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0 16 29  3  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6] -> size -> 21 
adversary victory points: 2
player victory points: 7 


action possibilites: [-1.  8. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0. 15.] 
cards in discard: [ 4. 14.  0.  0.  0.  1. 11.  0. 23.  1.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23
  4 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 2 
card supply: [20. 26. 30. 19. 29.  8.  5.  8.  6.  5. 10.  9.  6.  9.  6.  9.  8.] 
adversary cards in hand: [11.  0.  6.] 
adversary cards in discard: [29.  6.  0.  8.  0.  3.  0.  8.] 
adversary owned cards: [ 0  0 16 29  3  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6] -> size -> 21 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  0. 15.] 
cards in discard: [ 4. 14.  0.  0.  0.  1. 11.  0. 23.  1.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23
  4 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 26. 30. 19. 29.  8.  5.  8.  6.  5. 10.  9.  6.  9.  6.  9.  8.] 
adversary cards in hand: [11.  0.  6.] 
adversary cards in discard: [29.  6.  0.  8.  0.  3.  0.  8.] 
adversary owned cards: [ 0  0 16 29  3  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6] -> size -> 21 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  0. 15.] 
cards in discard: [ 4. 14.  0.  0.  0.  1. 11.  0. 23.  1.  3.  3. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23
  4 11 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 19. 29.  8.  5.  8.  5.  5. 10.  9.  6.  9.  6.  9.  8.] 
adversary cards in hand: [11.  0.  6.] 
adversary cards in discard: [29.  6.  0.  8.  0.  3.  0.  8.] 
adversary owned cards: [ 0  0 16 29  3  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6] -> size -> 21 
adversary victory points: 2
player victory points: 7 





Player: 0 
cards in hand: [11.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[23.70551 ]
 [23.414778]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6.] 
cards in discard: [29.  6.  0.  8.  0.  3.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16 29  3  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 19. 29.  8.  5.  8.  5.  5. 10.  9.  6.  9.  6.  9.  8.] 
adversary cards in hand: [22.  0. 15. 14.  0.] 
adversary cards in discard: [ 4. 14.  0.  0.  0.  1. 11.  0. 23.  1.  3.  3. 11. 10. 14.  3.  8.  0.
 15.] 
adversary owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23
  4 11 11] -> size -> 27 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 8
Learning step: -0.6327052712440491
desired expected reward: 23.729766845703125



action possibilites: [-1] 
expected returns: [[24.382431]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6.] 
cards in discard: [29.  6.  0.  8.  0.  3.  0.  8. 16.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 16 29  3  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 19. 29.  8.  5.  7.  5.  5. 10.  9.  6.  9.  6.  9.  8.] 
adversary cards in hand: [22.  0. 15. 14.  0.] 
adversary cards in discard: [ 4. 14.  0.  0.  0.  1. 11.  0. 23.  1.  3.  3. 11. 10. 14.  3.  8.  0.
 15.] 
adversary owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23
  4 11 11] -> size -> 27 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 4
Learning step: 0.5054385662078857
desired expected reward: 23.19133758544922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[23.605743]
 [23.525959]
 [24.612894]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [29.  6.  0.  8.  0.  3.  0.  8. 16.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 16 29  3  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 26. 30. 19. 29.  8.  5.  7.  5.  5. 10.  9.  6.  9.  6.  9.  8.] 
adversary cards in hand: [22.  0. 15. 14.  0.] 
adversary cards in discard: [ 4. 14.  0.  0.  0.  1. 11.  0. 23.  1.  3.  3. 11. 10. 14.  3.  8.  0.
 15.] 
adversary owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23
  4 11 11] -> size -> 27 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.02890096604824066
desired expected reward: 24.353530883789062



buy possibilites: [-1] 
expected returns: [[31.145224]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [29.  6.  0.  8.  0.  3.  0.  8. 16.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 16 29  3  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 26. 30. 19. 29.  8.  4.  7.  5.  5. 10.  9.  6.  9.  6.  9.  8.] 
adversary cards in hand: [22.  0. 15. 14.  0.] 
adversary cards in discard: [ 4. 14.  0.  0.  0.  1. 11.  0. 23.  1.  3.  3. 11. 10. 14.  3.  8.  0.
 15.] 
adversary owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23
  4 11 11] -> size -> 27 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -285.0 

action type: buy - action 6.0
Learning step: -8.928754806518555
desired expected reward: 14.597204208374023






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [22.  0. 15. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 15. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  0. 15. 14.  0.] 
cards in discard: [ 4. 14.  0.  0.  0.  1. 11.  0. 23.  1.  3.  3. 11. 10. 14.  3.  8.  0.
 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23
  4 11 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 19. 29.  8.  4.  7.  5.  5. 10.  9.  6.  9.  6.  9.  8.] 
adversary cards in hand: [ 3.  0. 16.  8.  3.] 
adversary cards in discard: [29.  6.  0.  8.  0.  3.  0.  8. 16.  6. 11.  0.  6.] 
adversary owned cards: [ 0  0 16 29  3  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6] -> size -> 23 
adversary victory points: 1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  0. 15.  0.] 
cards in discard: [ 4. 14.  0.  0.  0.  1. 11.  0. 23.  1.  3.  3. 11. 10. 14.  3.  8.  0.
 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23
  4 11 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 26. 30. 19. 29.  8.  4.  7.  5.  5. 10.  9.  6.  9.  6.  9.  8.] 
adversary cards in hand: [ 3. 16.  3.] 
adversary cards in discard: [29.  6.  0.  8.  0.  3.  0.  8. 16.  6. 11.  0.  6.  0.  8.] 
adversary owned cards: [ 0  0 16 29  3  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6] -> size -> 23 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  0. 15.  0.] 
cards in discard: [ 4. 14.  0.  0.  0.  1. 11.  0. 23.  1.  3.  3. 11. 10. 14.  3.  8.  0.
 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23
  4 11 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 26. 30. 19. 29.  8.  4.  7.  5.  5. 10.  9.  6.  9.  6.  9.  8.] 
adversary cards in hand: [ 3. 16.  3.] 
adversary cards in discard: [29.  6.  0.  8.  0.  3.  0.  8. 16.  6. 11.  0.  6.  0.  8.] 
adversary owned cards: [ 0  0 16 29  3  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6] -> size -> 23 
adversary victory points: 1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  0. 15.  0.] 
cards in discard: [ 4. 14.  0.  0.  0.  1. 11.  0. 23.  1.  3.  3. 11. 10. 14.  3.  8.  0.
 15. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23
  4 11 11 14] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 19. 29.  8.  4.  7.  5.  5. 10.  9.  5.  9.  6.  9.  8.] 
adversary cards in hand: [ 3. 16.  3.] 
adversary cards in discard: [29.  6.  0.  8.  0.  3.  0.  8. 16.  6. 11.  0.  6.  0.  8.] 
adversary owned cards: [ 0  0 16 29  3  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6] -> size -> 23 
adversary victory points: 1
player victory points: 7 





Player: 0 
cards in hand: [ 3. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[24.38207 ]
 [23.479393]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  3.] 
cards in discard: [29.  6.  0.  8.  0.  3.  0.  8. 16.  6. 11.  0.  6.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16 29  3  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 19. 29.  8.  4.  7.  5.  5. 10.  9.  5.  9.  6.  9.  8.] 
adversary cards in hand: [14.  0.  3. 16.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23
  4 11 11 14] -> size -> 28 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 9
Learning step: -0.6208244562149048
desired expected reward: 23.48067283630371



action possibilites: [-1] 
expected returns: [[25.930946]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [29.  6.  0.  8.  0.  3.  0.  8. 16.  6. 11.  0.  6.  0.  8. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 19. 29.  8.  4.  7.  5.  5. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [14.  0.  3. 16.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23
  4 11 11 14] -> size -> 28 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 8
Learning step: 0.3568962514400482
desired expected reward: 28.53618621826172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[25.035563]
 [24.954214]
 [26.054365]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [29.  6.  0.  8.  0.  3.  0.  8. 16.  6. 11.  0.  6.  0.  8. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 26. 30. 19. 29.  8.  4.  7.  5.  5. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [14.  0.  3. 16.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23
  4 11 11 14] -> size -> 28 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.0602906197309494
desired expected reward: 25.870655059814453






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [14.  0.  3. 16.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  3. 16.  1.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23
  4 11 11 14] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 19. 29.  8.  4.  7.  5.  5. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 6. 10.  0.  3.  3.] 
adversary cards in discard: [29.  6.  0.  8.  0.  3.  0.  8. 16.  6. 11.  0.  6.  0.  8. 14. 16.  3.] 
adversary owned cards: [ 0  0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14] -> size -> 23 
adversary victory points: 0
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  1.] 
cards in discard: [0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [16.] 
owned cards: [15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4
 11 11 14  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 19. 29.  8.  4.  7.  5.  5. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 6. 10.  0.  3.  3.] 
adversary cards in discard: [29.  6.  0.  8.  0.  3.  0.  8. 16.  6. 11.  0.  6.  0.  8. 14. 16.  3.] 
adversary owned cards: [ 0  0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14] -> size -> 23 
adversary victory points: 0
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  1.] 
cards in discard: [0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [16.] 
owned cards: [15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4
 11 11 14  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 26. 30. 19. 29.  8.  4.  7.  5.  5. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 6. 10.  0.  3.  3.] 
adversary cards in discard: [29.  6.  0.  8.  0.  3.  0.  8. 16.  6. 11.  0.  6.  0.  8. 14. 16.  3.] 
adversary owned cards: [ 0  0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14] -> size -> 23 
adversary victory points: 0
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  1.] 
cards in discard: [0. 8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [16.] 
owned cards: [15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4
 11 11 14  0  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 19. 29.  8.  4.  7.  5.  4. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 6. 10.  0.  3.  3.] 
adversary cards in discard: [29.  6.  0.  8.  0.  3.  0.  8. 16.  6. 11.  0.  6.  0.  8. 14. 16.  3.] 
adversary owned cards: [ 0  0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14] -> size -> 23 
adversary victory points: 0
player victory points: 7 





Player: 0 
cards in hand: [ 6. 10.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[29.2833  ]
 [28.728798]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.  3.  3.] 
cards in discard: [29.  6.  0.  8.  0.  3.  0.  8. 16.  6. 11.  0.  6.  0.  8. 14. 16.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 19. 29.  8.  4.  7.  5.  4. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 1. 14.  8.  0.  1.] 
adversary cards in discard: [ 0.  8. 16. 14.  3.  1.] 
adversary owned cards: [15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4
 11 11 14  0  8] -> size -> 29 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.626485288143158
desired expected reward: 25.427881240844727





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[28.277529]
 [28.19618 ]
 [29.296331]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0.  3.  3.] 
cards in discard: [29.  6.  0.  8.  0.  3.  0.  8. 16.  6. 11.  0.  6.  0.  8. 14. 16.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 26. 30. 19. 29.  8.  4.  7.  5.  4. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 1. 14.  8.  0.  1.] 
adversary cards in discard: [ 0.  8. 16. 14.  3.  1.] 
adversary owned cards: [15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4
 11 11 14  0  8] -> size -> 29 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7268205285072327
desired expected reward: 28.55647850036621



buy possibilites: [-1] 
expected returns: [[27.103487]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0.  3.  3.] 
cards in discard: [29.  6.  0.  8.  0.  3.  0.  8. 16.  6. 11.  0.  6.  0.  8. 14. 16.  3.
  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 26. 30. 19. 29.  8.  3.  7.  5.  4. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 1. 14.  8.  0.  1.] 
adversary cards in discard: [ 0.  8. 16. 14.  3.  1.] 
adversary owned cards: [15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4
 11 11 14  0  8] -> size -> 29 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.711298942565918
desired expected reward: 18.484882354736328






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [ 1. 14.  8.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 14.  8.  0.  1.] 
cards in discard: [ 0.  8. 16. 14.  3.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4
 11 11 14  0  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 19. 29.  8.  3.  7.  5.  4. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 6. 11.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6] -> size -> 24 
adversary victory points: -1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 0. 1.] 
cards in discard: [ 0.  8. 16. 14.  3.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [14.] 
owned cards: [15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4
 11 11 14  0  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 26. 30. 19. 29.  8.  3.  7.  5.  4. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 6.  3. 10.] 
adversary cards in discard: [11.  0.] 
adversary owned cards: [ 0  0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6] -> size -> 24 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8. 0. 1.] 
cards in discard: [ 0.  8. 16. 14.  3.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [14.] 
owned cards: [15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4
 11 11 14  0  8] -> size -> 29 
action values: 0 
buys: 1 
player value: 7 
card supply: [19. 26. 30. 19. 29.  8.  3.  7.  5.  4. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 6.  3. 10.] 
adversary cards in discard: [11.  0.] 
adversary owned cards: [ 0  0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6] -> size -> 24 
adversary victory points: -1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8. 0. 1.] 
cards in discard: [ 0.  8. 16. 14.  3.  1.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [14.] 
owned cards: [15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4
 11 11 14  0  8  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 5 
card supply: [19. 26. 30. 18. 29.  8.  3.  7.  5.  4. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 6.  3. 10.] 
adversary cards in discard: [11.  0.] 
adversary owned cards: [ 0  0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6] -> size -> 24 
adversary victory points: -1
player victory points: 8 





Player: 0 
cards in hand: [ 6.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[28.046118]
 [27.491617]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 10.] 
cards in discard: [11.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 18. 29.  8.  3.  7.  5.  4. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 3.  3.  0.  0. 14.] 
adversary cards in discard: [ 0.  8. 16. 14.  3.  1.  3. 14.  1.  8.  0.  1.] 
adversary owned cards: [15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4
 11 11 14  0  8  3] -> size -> 30 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 2
Learning step: -0.7720248103141785
desired expected reward: 29.715797424316406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[27.103008]
 [27.021658]
 [28.121813]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 10.] 
cards in discard: [11.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6] -> size -> 24 
action values: 1 
buys: 1 
player value: 0 
card supply: [19. 26. 30. 18. 29.  8.  3.  7.  5.  4. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 3.  3.  0.  0. 14.] 
adversary cards in discard: [ 0.  8. 16. 14.  3.  1.  3. 14.  1.  8.  0.  1.] 
adversary owned cards: [15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4
 11 11 14  0  8  3] -> size -> 30 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7033359408378601
desired expected reward: 27.38606071472168



buy possibilites: [-1] 
expected returns: [[24.151144]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 10.] 
cards in discard: [11.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 18. 29.  8.  3.  7.  5.  4. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 3.  3.  0.  0. 14.] 
adversary cards in discard: [ 0.  8. 16. 14.  3.  1.  3. 14.  1.  8.  0.  1.] 
adversary owned cards: [15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4
 11 11 14  0  8  3] -> size -> 30 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action 0.0
Learning step: -0.7095032334327698
desired expected reward: 26.393505096435547






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  0. 14.] 
cards in discard: [ 0.  8. 16. 14.  3.  1.  3. 14.  1.  8.  0.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4
 11 11 14  0  8  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 18. 29.  8.  3.  7.  5.  4. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 6.  3.  8. 29.  0.] 
adversary cards in discard: [11.  0.  0.  6.  3. 10.] 
adversary owned cards: [ 0  0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6
  0] -> size -> 25 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  0. 14.] 
cards in discard: [ 0.  8. 16. 14.  3.  1.  3. 14.  1.  8.  0.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4
 11 11 14  0  8  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 26. 30. 18. 29.  8.  3.  7.  5.  4. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 6.  3.  8. 29.  0.] 
adversary cards in discard: [11.  0.  0.  6.  3. 10.] 
adversary owned cards: [ 0  0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6
  0] -> size -> 25 
adversary victory points: -1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  0. 14.] 
cards in discard: [ 0.  8. 16. 14.  3.  1.  3. 14.  1.  8.  0.  1.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4
 11 11 14  0  8  3  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 18. 29.  8.  3.  7.  5.  3. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 6.  3.  8. 29.  0.] 
adversary cards in discard: [11.  0.  0.  6.  3. 10.] 
adversary owned cards: [ 0  0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6
  0] -> size -> 25 
adversary victory points: -1
player victory points: 8 





Player: 0 
cards in hand: [ 6.  3.  8. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[25.801504]
 [25.27011 ]
 [25.572182]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  8. 29.  0.] 
cards in discard: [11.  0.  0.  6.  3. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 18. 29.  8.  3.  7.  5.  3. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [15. 23. 22.  4.  0.] 
adversary cards in discard: [ 0.  8. 16. 14.  3.  1.  3. 14.  1.  8.  0.  1.  8.  3.  3.  0.  0. 14.] 
adversary owned cards: [15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4
 11 11 14  0  8  3  8] -> size -> 31 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6057485342025757
desired expected reward: 23.545394897460938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[24.74165 ]
 [24.6603  ]
 [25.760454]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  8. 29.  0.] 
cards in discard: [11.  0.  0.  6.  3. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 26. 30. 18. 29.  8.  3.  7.  5.  3. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [15. 23. 22.  4.  0.] 
adversary cards in discard: [ 0.  8. 16. 14.  3.  1.  3. 14.  1.  8.  0.  1.  8.  3.  3.  0.  0. 14.] 
adversary owned cards: [15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4
 11 11 14  0  8  3  8] -> size -> 31 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6594934463500977
desired expected reward: 25.142013549804688



buy possibilites: [-1] 
expected returns: [[31.636887]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  8. 29.  0.] 
cards in discard: [11.  0.  0.  6.  3. 10.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 26. 30. 18. 29.  8.  3.  7.  5.  3. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [15. 23. 22.  4.  0.] 
adversary cards in discard: [ 0.  8. 16. 14.  3.  1.  3. 14.  1.  8.  0.  1.  8.  3.  3.  0.  0. 14.] 
adversary owned cards: [15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4
 11 11 14  0  8  3  8] -> size -> 31 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.5600621104240417
desired expected reward: 24.18158531188965






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [15. 23. 22.  4.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 23. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 23. 22.  4.  0.] 
cards in discard: [ 0.  8. 16. 14.  3.  1.  3. 14.  1.  8.  0.  1.  8.  3.  3.  0.  0. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4
 11 11 14  0  8  3  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 18. 29.  8.  3.  7.  5.  3. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 0.  8.  0.  3. 14.] 
adversary cards in discard: [11.  0.  0.  6.  3. 10.  0.  6.  3.  8. 29.  0.] 
adversary owned cards: [ 0  0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6
  0  0] -> size -> 26 
adversary victory points: -1
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 23.  4.  0. 15.  0.  3.] 
cards in discard: [ 0.  8. 16. 14.  3.  1.  3. 14.  1.  8.  0.  1.  8.  3.  3.  0.  0. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [22. 11. 11. 10.] 
owned cards: [15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4
 11 11 14  0  8  3  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 18. 29.  8.  3.  7.  5.  3. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 0.  8.  0.  3. 14.] 
adversary cards in discard: [11.  0.  0.  6.  3. 10.  0.  6.  3.  8. 29.  0.] 
adversary owned cards: [ 0  0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6
  0  0] -> size -> 26 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 23.  4.  0. 15.  0.  3.] 
cards in discard: [ 0.  8. 16. 14.  3.  1.  3. 14.  1.  8.  0.  1.  8.  3.  3.  0.  0. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [22. 11. 11. 10.] 
owned cards: [15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4
 11 11 14  0  8  3  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 26. 30. 18. 29.  8.  3.  7.  5.  3. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 0.  8.  0.  3. 14.] 
adversary cards in discard: [11.  0.  0.  6.  3. 10.  0.  6.  3.  8. 29.  0.] 
adversary owned cards: [ 0  0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6
  0  0] -> size -> 26 
adversary victory points: -1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 23.  4.  0. 15.  0.  3.] 
cards in discard: [ 0.  8. 16. 14.  3.  1.  3. 14.  1.  8.  0.  1.  8.  3.  3.  0.  0. 14.
  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [22. 11. 11. 10.] 
owned cards: [15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4
 11 11 14  0  8  3  8  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 18. 29.  8.  3.  7.  5.  2. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 0.  8.  0.  3. 14.] 
adversary cards in discard: [11.  0.  0.  6.  3. 10.  0.  6.  3.  8. 29.  0.] 
adversary owned cards: [ 0  0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6
  0  0] -> size -> 26 
adversary victory points: -1
player victory points: 8 





Player: 0 
cards in hand: [ 0.  8.  0.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
expected returns: [[33.08895 ]
 [32.557556]
 [32.47342 ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0.  3. 14.] 
cards in discard: [11.  0.  0.  6.  3. 10.  0.  6.  3.  8. 29.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 18. 29.  8.  3.  7.  5.  2. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [15.  8.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4
 11 11 14  0  8  3  8  8] -> size -> 32 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7548840045928955
desired expected reward: 30.882001876831055



action possibilites: [-1] 
expected returns: [[28.646685]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 3.] 
cards in discard: [11.  0.  0.  6.  3. 10.  0.  6.  3.  8. 29.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 26. 30. 18. 29.  8.  3.  7.  5.  2. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [15. 14.] 
adversary owned cards: [15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4
 11 11 14  0  8  3  8  8] -> size -> 32 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: -0.22341246902942657
desired expected reward: 32.2500114440918





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[27.767027]
 [28.024218]
 [28.001116]
 [27.685677]
 [27.872936]
 [28.488525]
 [28.254435]
 [28.556505]
 [28.170301]
 [28.231333]
 [28.427494]
 [28.785831]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 3.] 
cards in discard: [11.  0.  0.  6.  3. 10.  0.  6.  3.  8. 29.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 26. 30. 18. 29.  8.  3.  7.  5.  2. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [15. 14.] 
adversary owned cards: [15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4
 11 11 14  0  8  3  8  8] -> size -> 32 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.11216451227664948
desired expected reward: 28.53451919555664



buy possibilites: [-1] 
expected returns: [[26.660599]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 3.] 
cards in discard: [11.  0.  0.  6.  3. 10.  0.  6.  3.  8. 29.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6
  0  0  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 26. 30. 18. 29.  8.  3.  7.  5.  1. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [15. 14.] 
adversary owned cards: [15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4
 11 11 14  0  8  3  8  8] -> size -> 32 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 17.0 

action type: buy - action 8.0
Learning step: -0.05459610000252724
desired expected reward: 28.199838638305664






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [15. 14.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  0  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4
 11 11 14  0  8  3  8  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 18. 29.  8.  3.  7.  5.  1. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 0.  6.  3. 16. 16.] 
adversary cards in discard: [11.  0.  0.  6.  3. 10.  0.  6.  3.  8. 29.  0.  8. 14.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6
  0  0  8] -> size -> 27 
adversary victory points: -1
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [15. 14.] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  3  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4 11
 11 14  0  8  3  8  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 18. 29.  8.  3.  7.  5.  1. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 0.  6.  3. 16. 16.] 
adversary cards in discard: [11.  0.  0.  6.  3. 10.  0.  6.  3.  8. 29.  0.  8. 14.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6
  0  0  8] -> size -> 27 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [15. 14.] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  3  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4 11
 11 14  0  8  3  8  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 26. 30. 18. 29.  8.  3.  7.  5.  1. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 0.  6.  3. 16. 16.] 
adversary cards in discard: [11.  0.  0.  6.  3. 10.  0.  6.  3.  8. 29.  0.  8. 14.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6
  0  0  8] -> size -> 27 
adversary victory points: -1
player victory points: 8 





Player: 0 
cards in hand: [ 0.  6.  3. 16. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.] 
expected returns: [[31.222315]
 [30.299482]
 [30.299482]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3. 16. 16.] 
cards in discard: [11.  0.  0.  6.  3. 10.  0.  6.  3.  8. 29.  0.  8. 14.  0.  8.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6
  0  0  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 18. 29.  8.  3.  7.  5.  1. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 3. 22.  0.  0.  1.] 
adversary cards in discard: [15. 14.  8.  0.] 
adversary owned cards: [15  3  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4 11
 11 14  0  8  3  8  8] -> size -> 31 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6271515488624573
desired expected reward: 26.033447265625



action possibilites: [-1] 
expected returns: [[26.302465]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 16.] 
cards in discard: [11.  0.  0.  6.  3. 10.  0.  6.  3.  8. 29.  0.  8. 14.  0.  8.  0.  3.
  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0
  0  8  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 17. 29.  8.  3.  7.  5.  1. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 3. 22.  0.  0.  1.] 
adversary cards in discard: [15. 14.  8.  0.] 
adversary owned cards: [15  3  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4 11
 11 14  0  8  3  8  8] -> size -> 31 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 19 

action type: gain_card_n - action 1
Learning step: 0.09058931469917297
desired expected reward: 25.276809692382812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[25.204397]
 [25.123041]
 [26.2345  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 16.] 
cards in discard: [11.  0.  0.  6.  3. 10.  0.  6.  3.  8. 29.  0.  8. 14.  0.  8.  0.  3.
  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0
  0  8  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 26. 30. 17. 29.  8.  3.  7.  5.  1. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 3. 22.  0.  0.  1.] 
adversary cards in discard: [15. 14.  8.  0.] 
adversary owned cards: [15  3  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4 11
 11 14  0  8  3  8  8] -> size -> 31 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.06960805505514145
desired expected reward: 26.23285675048828






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [ 3. 22.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 22.  0.  0.  1.] 
cards in discard: [15. 14.  8.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4 11
 11 14  0  8  3  8  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 17. 29.  8.  3.  7.  5.  1. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [0. 8. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0
  0  8  3] -> size -> 27 
adversary victory points: 0
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  1.  0. 15.  0.] 
cards in discard: [15. 14.  8.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [22.] 
owned cards: [15  3  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4 11
 11 14  0  8  3  8  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 17. 29.  8.  3.  7.  5.  1. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [0. 8. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0
  0  8  3] -> size -> 27 
adversary victory points: 0
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  1.  0. 15.  0.] 
cards in discard: [15. 14.  8.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [22.] 
owned cards: [15  3  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4 11
 11 14  0  8  3  8  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 6 
card supply: [17. 26. 30. 17. 29.  8.  3.  7.  5.  1. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [0. 8. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0
  0  8  3] -> size -> 27 
adversary victory points: 0
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  1.  0. 15.  0.] 
cards in discard: [15. 14.  8.  0.  4.] 
cards in deck: 19 
card top of deck: [] 
played cards: [22.] 
owned cards: [15  3  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4 11
 11 14  0  8  3  8  8  4] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 26. 30. 17. 28.  8.  3.  7.  5.  1. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [0. 8. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0
  0  8  3] -> size -> 27 
adversary victory points: 0
player victory points: 11 





Player: 0 
cards in hand: [0. 8. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[24.819963]
 [24.279247]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 6. 6.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0
  0  8  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 17. 28.  8.  3.  7.  5.  1. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 1. 14. 16. 11.  8.] 
adversary cards in discard: [15. 14.  8.  0.  4. 22.  3.  0.  0.  1.  0. 15.  0.] 
adversary owned cards: [15  3  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4 11
 11 14  0  8  3  8  8  4] -> size -> 32 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6786965131759644
desired expected reward: 25.55580711364746





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[23.870298]
 [24.106586]
 [23.788942]
 [24.359686]
 [24.9004  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 6. 6.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0
  0  8  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 26. 30. 17. 28.  8.  3.  7.  5.  1. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 1. 14. 16. 11.  8.] 
adversary cards in discard: [15. 14.  8.  0.  4. 22.  3.  0.  0.  1.  0. 15.  0.] 
adversary owned cards: [15  3  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4 11
 11 14  0  8  3  8  8  4] -> size -> 32 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6389845013618469
desired expected reward: 24.180978775024414



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [ 1. 14. 16. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16. 11.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 14. 16. 11.  8.] 
cards in discard: [15. 14.  8.  0.  4. 22.  3.  0.  0.  1.  0. 15.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4 11
 11 14  0  8  3  8  8  4] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 17. 28.  8.  3.  7.  5.  1. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [11.  8.  0.  6. 14.] 
adversary cards in discard: [0. 8. 0. 6. 6.] 
adversary owned cards: [ 0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0
  0  8  3] -> size -> 27 
adversary victory points: 0
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 16. 11.  8.] 
cards in discard: [15. 14.  8.  0.  4. 22.  3.  0.  0.  1.  0. 15.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [15  3  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4 11
 11 14  0  8  3  8  8  4] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 26. 30. 17. 28.  8.  3.  7.  5.  1. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 8.  0. 14.] 
adversary cards in discard: [ 0.  8.  0.  6.  6. 11.  6.] 
adversary owned cards: [ 0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0
  0  8  3] -> size -> 27 
adversary victory points: 0
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 16. 11.  8.] 
cards in discard: [15. 14.  8.  0.  4. 22.  3.  0.  0.  1.  0. 15.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [15  3  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4 11
 11 14  0  8  3  8  8  4] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 26. 30. 17. 28.  8.  3.  7.  5.  1. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 8.  0. 14.] 
adversary cards in discard: [ 0.  8.  0.  6.  6. 11.  6.] 
adversary owned cards: [ 0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0
  0  8  3] -> size -> 27 
adversary victory points: 0
player victory points: 11 





Player: 0 
cards in hand: [ 8.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
expected returns: [[24.630335]
 [24.089617]
 [24.00826 ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 14.] 
cards in discard: [ 0.  8.  0.  6.  6. 11.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0
  0  8  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 17. 28.  8.  3.  7.  5.  1. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [10.  1. 14.  3.  0.] 
adversary cards in discard: [15. 14.  8.  0.  4. 22.  3.  0.  0.  1.  0. 15.  0. 14.  1. 16. 11.  8.] 
adversary owned cards: [15  3  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4 11
 11 14  0  8  3  8  8  4] -> size -> 32 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 5
Learning step: -0.9564592838287354
desired expected reward: 34.43760681152344



action possibilites: [-1] 
expected returns: [[32.90511]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [ 0.  8.  0.  6.  6. 11.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0
  0  8  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 26. 30. 17. 28.  8.  3.  7.  5.  1. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [10.  1.  3.] 
adversary cards in discard: [15. 14.  8.  0.  4. 22.  3.  0.  0.  1.  0. 15.  0. 14.  1. 16. 11.  8.
 14.  0.] 
adversary owned cards: [15  3  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4 11
 11 14  0  8  3  8  8  4] -> size -> 32 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: 0.07525583356618881
desired expected reward: 24.08351707458496





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[31.939144]
 [32.19729 ]
 [32.175438]
 [31.857792]
 [32.66482 ]
 [32.42853 ]
 [32.40668 ]
 [32.969246]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [ 0.  8.  0.  6.  6. 11.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0
  0  8  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 26. 30. 17. 28.  8.  3.  7.  5.  1. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [10.  1.  3.] 
adversary cards in discard: [15. 14.  8.  0.  4. 22.  3.  0.  0.  1.  0. 15.  0. 14.  1. 16. 11.  8.
 14.  0.] 
adversary owned cards: [15  3  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4 11
 11 14  0  8  3  8  8  4] -> size -> 32 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.1963469684123993
desired expected reward: 32.708763122558594



buy possibilites: [-1] 
expected returns: [[28.167616]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [ 0.  8.  0.  6.  6. 11.  6. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0
  0  8  3 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 17. 28.  8.  3.  7.  4.  1. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [10.  1.  3.] 
adversary cards in discard: [15. 14.  8.  0.  4. 22.  3.  0.  0.  1.  0. 15.  0. 14.  1. 16. 11.  8.
 14.  0.] 
adversary owned cards: [15  3  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4 11
 11 14  0  8  3  8  8  4] -> size -> 32 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 11.0
Learning step: 0.305815190076828
desired expected reward: 32.97064208984375






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [10.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  3.] 
cards in discard: [15. 14.  8.  0.  4. 22.  3.  0.  0.  1.  0. 15.  0. 14.  1. 16. 11.  8.
 14.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4 11
 11 14  0  8  3  8  8  4] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 17. 28.  8.  3.  7.  4.  1. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [10. 16.  8.  8.  0.] 
adversary cards in discard: [ 0.  8.  0.  6.  6. 11.  6. 11. 14.  8.  0.] 
adversary owned cards: [ 0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0
  0  8  3 11] -> size -> 28 
adversary victory points: 0
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  3.] 
cards in discard: [15. 14.  8.  0.  4. 22.  3.  0.  0.  1.  0. 15.  0. 14.  1. 16. 11.  8.
 14.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4 11
 11 14  0  8  3  8  8  4] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 26. 30. 17. 28.  8.  3.  7.  4.  1. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [10. 16.  8.  8.  0.] 
adversary cards in discard: [ 0.  8.  0.  6.  6. 11.  6. 11. 14.  8.  0.] 
adversary owned cards: [ 0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0
  0  8  3 11] -> size -> 28 
adversary victory points: 0
player victory points: 11 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10. 16.  8.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.  8.  8.] 
expected returns: [[29.056599]
 [28.494032]
 [28.133768]
 [28.51588 ]
 [28.51588 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 16.  8.  8.  0.] 
cards in discard: [ 0.  8.  0.  6.  6. 11.  6. 11. 14.  8.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0
  0  8  3 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 17. 28.  8.  3.  7.  4.  1. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [14.  8.  4.  3. 11.] 
adversary cards in discard: [15. 14.  8.  0.  4. 22.  3.  0.  0.  1.  0. 15.  0. 14.  1. 16. 11.  8.
 14.  0. 10.  1.  3.] 
adversary owned cards: [15  3  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4 11
 11 14  0  8  3  8  8  4] -> size -> 32 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6942464113235474
desired expected reward: 27.473369598388672



action possibilites: [-1. 16.  8.  8.] 
expected returns: [[29.104315]
 [28.181482]
 [28.563597]
 [28.563597]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8.  8.  0.  6.] 
cards in discard: [ 0.  8.  0.  6.  6. 11.  6. 11. 14.  8.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0 16 29  6  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0
  0  8  3 11] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 17. 28.  8.  3.  7.  4.  1. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [14.  8.  4.  3. 11.] 
adversary cards in discard: [15. 14.  8.  0.  4. 22.  3.  0.  0.  1.  0. 15.  0. 14.  1. 16. 11.  8.
 14.  0. 10.  1.  3.] 
adversary owned cards: [15  3  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4 11
 11 14  0  8  3  8  8  4] -> size -> 32 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -0.10343456268310547
desired expected reward: 28.390594482421875



action possibilites: [-1.  8.  8.] 
expected returns: [[30.05703 ]
 [29.512905]
 [29.512905]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0.] 
cards in discard: [ 0.  8.  0.  6.  6. 11.  6. 11. 14.  8.  0.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0 16 29  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0
  8  3 11  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 17. 28.  8.  3.  7.  4.  0. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [14.  8.  4.  3. 11.] 
adversary cards in discard: [15. 14.  8.  0.  4. 22.  3.  0.  0.  1.  0. 15.  0. 14.  1. 16. 11.  8.
 14.  0. 10.  1.  3.] 
adversary owned cards: [15  3  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4 11
 11 14  0  8  3  8  8  4] -> size -> 32 
adversary victory points: 11
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  4  0] 
sum of rewards: 39 

action type: gain_card_n - action 3
Learning step: 0.7111541032791138
desired expected reward: 26.424406051635742





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[29.042664]
 [28.963526]
 [30.076214]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0.] 
cards in discard: [ 0.  8.  0.  6.  6. 11.  6. 11. 14.  8.  0.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0 16 29  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0
  8  3 11  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 26. 30. 17. 28.  8.  3.  7.  4.  0. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [14.  8.  4.  3. 11.] 
adversary cards in discard: [15. 14.  8.  0.  4. 22.  3.  0.  0.  1.  0. 15.  0. 14.  1. 16. 11.  8.
 14.  0. 10.  1.  3.] 
adversary owned cards: [15  3  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4 11
 11 14  0  8  3  8  8  4] -> size -> 32 
adversary victory points: 11
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.45807981491088867
desired expected reward: 30.515111923217773



buy possibilites: [-1] 
expected returns: [[32.324856]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0.] 
cards in discard: [ 0.  8.  0.  6.  6. 11.  6. 11. 14.  8.  0.  8.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0 16 29  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0
  8  3 11  8  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 26. 30. 17. 28.  8.  3.  7.  4.  0. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [14.  8.  4.  3. 11.] 
adversary cards in discard: [15. 14.  8.  0.  4. 22.  3.  0.  0.  1.  0. 15.  0. 14.  1. 16. 11.  8.
 14.  0. 10.  1.  3.] 
adversary owned cards: [15  3  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4 11
 11 14  0  8  3  8  8  4] -> size -> 32 
adversary victory points: 11
player victory points: 1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 40.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 35.0 

action type: buy - action 0.0
Learning step: 0.5181310176849365
desired expected reward: 29.560794830322266






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [14.  8.  4.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8.  4.  3. 11.] 
cards in discard: [15. 14.  8.  0.  4. 22.  3.  0.  0.  1.  0. 15.  0. 14.  1. 16. 11.  8.
 14.  0. 10.  1.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23  4 11
 11 14  0  8  3  8  8  4] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 17. 28.  8.  3.  7.  4.  0. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [29.  3.  3.  3.  0.] 
adversary cards in discard: [ 0.  8.  0.  6.  6. 11.  6. 11. 14.  8.  0.  8.  0. 10. 16.  8.  8.  0.] 
adversary owned cards: [ 0 16 29  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0
  8  3 11  8  0] -> size -> 29 
adversary victory points: 1
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 11.] 
cards in discard: [15. 14.  8.  0.  4. 22.  3.  0.  0.  1.  0. 15.  0. 14.  1. 16. 11.  8.
 14.  0. 10.  1.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14
  0  8  3  8  8  4] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 17. 28.  8.  3.  7.  4.  0. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [29.  3.  3.  3.  0.] 
adversary cards in discard: [ 0.  8.  0.  6.  6. 11.  6. 11. 14.  8.  0.  8.  0. 10. 16.  8.  8.  0.] 
adversary owned cards: [ 0 16 29  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0
  8  3 11  8  0] -> size -> 29 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 11.] 
cards in discard: [15. 14.  8.  0.  4. 22.  3.  0.  0.  1.  0. 15.  0. 14.  1. 16. 11.  8.
 14.  0. 10.  1.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14
  0  8  3  8  8  4] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 26. 30. 17. 28.  8.  3.  7.  4.  0. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [29.  3.  3.  3.  0.] 
adversary cards in discard: [ 0.  8.  0.  6.  6. 11.  6. 11. 14.  8.  0.  8.  0. 10. 16.  8.  8.  0.] 
adversary owned cards: [ 0 16 29  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0
  8  3 11  8  0] -> size -> 29 
adversary victory points: 1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 11.] 
cards in discard: [15. 14.  8.  0.  4. 22.  3.  0.  0.  1.  0. 15.  0. 14.  1. 16. 11.  8.
 14.  0. 10.  1.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14
  0  8  3  8  8  4  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 17. 28.  8.  3.  7.  4.  0. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [29.  3.  3.  3.  0.] 
adversary cards in discard: [ 0.  8.  0.  6.  6. 11.  6. 11. 14.  8.  0.  8.  0. 10. 16.  8.  8.  0.] 
adversary owned cards: [ 0 16 29  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0
  8  3 11  8  0] -> size -> 29 
adversary victory points: 1
player victory points: 7 





Player: 0 
cards in hand: [29.  3.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[24.799324]
 [24.561577]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  3.  3.  0.] 
cards in discard: [ 0.  8.  0.  6.  6. 11.  6. 11. 14.  8.  0.  8.  0. 10. 16.  8.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16 29  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0
  8  3 11  8  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 17. 28.  8.  3.  7.  4.  0. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [11.  8.  3. 23.  3.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14
  0  8  3  8  8  4  0] -> size -> 31 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.8603513240814209
desired expected reward: 31.46450424194336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[23.769053]
 [23.689915]
 [24.8026  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  3.  3.  0.] 
cards in discard: [ 0.  8.  0.  6.  6. 11.  6. 11. 14.  8.  0.  8.  0. 10. 16.  8.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16 29  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0
  8  3 11  8  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 26. 30. 17. 28.  8.  3.  7.  4.  0. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [11.  8.  3. 23.  3.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14
  0  8  3  8  8  4  0] -> size -> 31 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6395618915557861
desired expected reward: 24.159761428833008



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [11.  8.  3. 23.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  3. 23.  3.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14
  0  8  3  8  8  4  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 17. 28.  8.  3.  7.  4.  0. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 0.  0.  3.  3. 16.] 
adversary cards in discard: [ 0.  8.  0.  6.  6. 11.  6. 11. 14.  8.  0.  8.  0. 10. 16.  8.  8.  0.
 29.  3.  3.  3.  0.] 
adversary owned cards: [ 0 16 29  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0
  8  3 11  8  0] -> size -> 29 
adversary victory points: 1
player victory points: 7 


action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  3.  3.  4.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [23.] 
owned cards: [15  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14
  0  8  3  8  8  4  0] -> size -> 31 
action values: 1 
buys: 1 
player value: 1 
card supply: [15. 26. 30. 17. 28.  8.  3.  7.  4.  0. 10.  9.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 0.  0.  3.  3. 16.] 
adversary cards in discard: [ 0.  8.  0.  6.  6. 11.  6. 11. 14.  8.  0.  8.  0. 10. 16.  8.  8.  0.
 29.  3.  3.  3.  0.] 
adversary owned cards: [ 0 16 29  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0
  8  3 11  8  0] -> size -> 29 
adversary victory points: 1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 4.] 
cards in discard: [29.] 
cards in deck: 25 
card top of deck: [] 
played cards: [23. 11.] 
owned cards: [15  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14
  0  8  3  8  8  4  0 29] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 26. 30. 17. 28.  8.  3.  7.  4.  0. 10.  8.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 0.  0.  3.  3. 16.] 
adversary cards in discard: [ 0.  8.  0.  6.  6. 11.  6. 11. 14.  8.  0.  8.  0. 10. 16.  8.  8.  0.
 29.  3.  3.  3.  0.] 
adversary owned cards: [ 0 16 29  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0
  8  3 11  8  0] -> size -> 29 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 4.] 
cards in discard: [29.] 
cards in deck: 25 
card top of deck: [] 
played cards: [23. 11.] 
owned cards: [15  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14
  0  8  3  8  8  4  0 29] -> size -> 32 
action values: 0 
buys: 2 
player value: 1 
card supply: [15. 26. 30. 17. 28.  8.  3.  7.  4.  0. 10.  8.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 0.  0.  3.  3. 16.] 
adversary cards in discard: [ 0.  8.  0.  6.  6. 11.  6. 11. 14.  8.  0.  8.  0. 10. 16.  8.  8.  0.
 29.  3.  3.  3.  0.] 
adversary owned cards: [ 0 16 29  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0
  8  3 11  8  0] -> size -> 29 
adversary victory points: 1
player victory points: 7 





Player: 0 
cards in hand: [ 0.  0.  3.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[27.265783]
 [26.339615]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  3. 16.] 
cards in discard: [ 0.  8.  0.  6.  6. 11.  6. 11. 14.  8.  0.  8.  0. 10. 16.  8.  8.  0.
 29.  3.  3.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16 29  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0
  8  3 11  8  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 17. 28.  8.  3.  7.  4.  0. 10.  8.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 0. 14. 11.  3.  3.] 
adversary cards in discard: [29. 23. 11.  8.  3.  3.  4.] 
adversary owned cards: [15  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14
  0  8  3  8  8  4  0 29] -> size -> 32 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6116772890090942
desired expected reward: 24.190927505493164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[26.298714]
 [26.53577 ]
 [26.219576]
 [27.332264]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  3. 16.] 
cards in discard: [ 0.  8.  0.  6.  6. 11.  6. 11. 14.  8.  0.  8.  0. 10. 16.  8.  8.  0.
 29.  3.  3.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16 29  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0
  8  3 11  8  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 26. 30. 17. 28.  8.  3.  7.  4.  0. 10.  8.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 0. 14. 11.  3.  3.] 
adversary cards in discard: [29. 23. 11.  8.  3.  3.  4.] 
adversary owned cards: [15  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14
  0  8  3  8  8  4  0 29] -> size -> 32 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6871643662452698
desired expected reward: 26.578617095947266



buy possibilites: [-1] 
expected returns: [[25.181501]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  3. 16.] 
cards in discard: [ 0.  8.  0.  6.  6. 11.  6. 11. 14.  8.  0.  8.  0. 10. 16.  8.  8.  0.
 29.  3.  3.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16 29  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0
  8  3 11  8  0  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 16. 28.  8.  3.  7.  4.  0. 10.  8.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 0. 14. 11.  3.  3.] 
adversary cards in discard: [29. 23. 11.  8.  3.  3.  4.] 
adversary owned cards: [15  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14
  0  8  3  8  8  4  0 29] -> size -> 32 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 3.0
Learning step: -0.4416673481464386
desired expected reward: 26.09410285949707






         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [ 0. 14. 11.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 11.  3.  3.] 
cards in discard: [29. 23. 11.  8.  3.  3.  4.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14
  0  8  3  8  8  4  0 29] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 16. 28.  8.  3.  7.  4.  0. 10.  8.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 6. 29.  0.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16 29  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0
  8  3 11  8  0  3] -> size -> 30 
adversary victory points: 2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3.  3.] 
cards in discard: [29. 23. 11.  8.  3.  3.  4.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [15  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14
  0  8  3  8  8  4  0 29  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 15. 28.  8.  3.  7.  4.  0. 10.  8.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 6. 29.  0.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16 29  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0
  8  3 11  8  0  3] -> size -> 30 
adversary victory points: 2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  3.  3.] 
cards in discard: [29. 23. 11.  8.  3.  3.  4.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [15  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14
  0  8  3  8  8  4  0 29  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 26. 30. 15. 28.  8.  3.  7.  4.  0. 10.  8.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 6. 29.  0.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16 29  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0
  8  3 11  8  0  3] -> size -> 30 
adversary victory points: 2
player victory points: 8 





Player: 0 
cards in hand: [ 6. 29.  0.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[25.147112]
 [24.909363]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29.  0.  6.  6.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16 29  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0
  8  3 11  8  0  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 15. 28.  8.  3.  7.  4.  0. 10.  8.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 0.  1.  8.  1. 14.] 
adversary cards in discard: [29. 23. 11.  8.  3.  3.  4.  3. 11.  0. 14.  3.  3.] 
adversary owned cards: [15  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14
  0  8  3  8  8  4  0 29  3] -> size -> 33 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6423988938331604
desired expected reward: 24.53910255432129





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[24.16449]
 [24.08535]
 [25.19804]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 29.  0.  6.  6.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16 29  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0
  8  3 11  8  0  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 26. 30. 15. 28.  8.  3.  7.  4.  0. 10.  8.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 0.  1.  8.  1. 14.] 
adversary cards in discard: [29. 23. 11.  8.  3.  3.  4.  3. 11.  0. 14.  3.  3.] 
adversary owned cards: [15  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14
  0  8  3  8  8  4  0 29  3] -> size -> 33 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6458433270454407
desired expected reward: 24.501266479492188



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [ 0.  1.  8.  1. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  8.  1. 14.] 
cards in discard: [29. 23. 11.  8.  3.  3.  4.  3. 11.  0. 14.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  0  1 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14
  0  8  3  8  8  4  0 29  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 15. 28.  8.  3.  7.  4.  0. 10.  8.  4.  9.  6.  9.  8.] 
adversary cards in hand: [16.  0. 11.  8. 16.] 
adversary cards in discard: [ 6. 29.  0.  6.  6.] 
adversary owned cards: [ 0 16 29  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0
  8  3 11  8  0  3] -> size -> 30 
adversary victory points: 2
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 14.] 
cards in discard: [29. 23. 11.  8.  3.  3.  4.  3. 11.  0. 14.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  3  0 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0
  8  3  8  8  4  0 29  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 15. 28.  8.  3.  7.  4.  0. 10.  8.  4.  9.  6.  9.  8.] 
adversary cards in hand: [16.  0. 11.  8. 16.] 
adversary cards in discard: [ 6. 29.  0.  6.  6.] 
adversary owned cards: [ 0 16 29  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0
  8  3 11  8  0  3] -> size -> 30 
adversary victory points: 2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 14.] 
cards in discard: [29. 23. 11.  8.  3.  3.  4.  3. 11.  0. 14.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  3  0 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0
  8  3  8  8  4  0 29  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 26. 30. 15. 28.  8.  3.  7.  4.  0. 10.  8.  4.  9.  6.  9.  8.] 
adversary cards in hand: [16.  0. 11.  8. 16.] 
adversary cards in discard: [ 6. 29.  0.  6.  6.] 
adversary owned cards: [ 0 16 29  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0
  8  3 11  8  0  3] -> size -> 30 
adversary victory points: 2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 14.] 
cards in discard: [29. 23. 11.  8.  3.  3.  4.  3. 11.  0. 14.  3.  3.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  3  0 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0
  8  3  8  8  4  0 29  3  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 15. 28.  8.  3.  7.  4.  0. 10.  8.  4.  9.  6.  9.  8.] 
adversary cards in hand: [16.  0. 11.  8. 16.] 
adversary cards in discard: [ 6. 29.  0.  6.  6.] 
adversary owned cards: [ 0 16 29  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0
  8  3 11  8  0  3] -> size -> 30 
adversary victory points: 2
player victory points: 8 





Player: 0 
cards in hand: [16.  0. 11.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.  8. 16.] 
expected returns: [[24.55607 ]
 [23.629906]
 [24.248997]
 [24.011944]
 [23.629906]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 11.  8. 16.] 
cards in discard: [ 6. 29.  0.  6.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16 29  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0
  8  3 11  8  0  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 15. 28.  8.  3.  7.  4.  0. 10.  8.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 1. 15.  0. 16.  0.] 
adversary cards in discard: [29. 23. 11.  8.  3.  3.  4.  3. 11.  0. 14.  3.  3.  1.  8.  0.  1. 14.] 
adversary owned cards: [15  3  0 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0
  8  3  8  8  4  0 29  3  1] -> size -> 33 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6526443958282471
desired expected reward: 24.545394897460938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[23.549395]
 [23.470257]
 [24.582947]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0. 11.  8. 16.] 
cards in discard: [ 6. 29.  0.  6.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16 29  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0
  8  3 11  8  0  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 25. 30. 15. 28.  8.  3.  7.  4.  0. 10.  8.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 1. 15.  0. 16.  0.] 
adversary cards in discard: [29. 23. 11.  8.  3.  3.  4.  3. 11.  0. 14.  3.  3.  1.  8.  0.  1. 14.] 
adversary owned cards: [15  3  0 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0
  8  3  8  8  4  0 29  3  1] -> size -> 33 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6345707178115845
desired expected reward: 23.92150115966797



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [ 1. 15.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15.  0. 16.  0.] 
cards in discard: [29. 23. 11.  8.  3.  3.  4.  3. 11.  0. 14.  3.  3.  1.  8.  0.  1. 14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  0 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0
  8  3  8  8  4  0 29  3  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 15. 28.  8.  3.  7.  4.  0. 10.  8.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 3.  3.  0. 14.  8.] 
adversary cards in discard: [ 6. 29.  0.  6.  6. 16.  0. 11.  8. 16.] 
adversary owned cards: [ 0 16 29  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0
  8  3 11  8  0  3] -> size -> 30 
adversary victory points: 2
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 16.  0.] 
cards in discard: [29. 23. 11.  8.  3.  3.  4.  3. 11.  0. 14.  3.  3.  1.  8.  0.  1. 14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  3 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8
  3  8  8  4  0 29  3  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 3 
card supply: [15. 25. 30. 15. 28.  8.  3.  7.  4.  0. 10.  8.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 3.  3.  0. 14.  8.] 
adversary cards in discard: [ 6. 29.  0.  6.  6. 16.  0. 11.  8. 16.] 
adversary owned cards: [ 0 16 29  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0
  8  3 11  8  0  3] -> size -> 30 
adversary victory points: 2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 16.  0.] 
cards in discard: [29. 23. 11.  8.  3.  3.  4.  3. 11.  0. 14.  3.  3.  1.  8.  0.  1. 14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  3 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8
  3  8  8  4  0 29  3  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 6 
card supply: [15. 25. 30. 15. 28.  8.  3.  7.  4.  0. 10.  8.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 3.  3.  0. 14.  8.] 
adversary cards in discard: [ 6. 29.  0.  6.  6. 16.  0. 11.  8. 16.] 
adversary owned cards: [ 0 16 29  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0
  8  3 11  8  0  3] -> size -> 30 
adversary victory points: 2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 16.  0.] 
cards in discard: [29. 23. 11.  8.  3.  3.  4.  3. 11.  0. 14.  3.  3.  1.  8.  0.  1. 14.
  4.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  3 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8
  3  8  8  4  0 29  3  1  4] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 25. 30. 15. 27.  8.  3.  7.  4.  0. 10.  8.  4.  9.  6.  9.  8.] 
adversary cards in hand: [ 3.  3.  0. 14.  8.] 
adversary cards in discard: [ 6. 29.  0.  6.  6. 16.  0. 11.  8. 16.] 
adversary owned cards: [ 0 16 29  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0
  8  3 11  8  0  3] -> size -> 30 
adversary victory points: 2
player victory points: 11 





Player: 0 
cards in hand: [ 3.  3.  0. 14.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
expected returns: [[27.64765 ]
 [27.024384]
 [27.103521]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 14.  8.] 
cards in discard: [ 6. 29.  0.  6.  6. 16.  0. 11.  8. 16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16 29  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0
  8  3 11  8  0  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 15. 27.  8.  3.  7.  4.  0. 10.  8.  4.  9.  6.  9.  8.] 
adversary cards in hand: [14. 15. 14.  8.  0.] 
adversary cards in discard: [29. 23. 11.  8.  3.  3.  4.  3. 11.  0. 14.  3.  3.  1.  8.  0.  1. 14.
  4. 15.  1. 16.  0.] 
adversary owned cards: [15  3 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8
  3  8  8  4  0 29  3  1  4] -> size -> 33 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6004567742347717
desired expected reward: 23.98249053955078



action possibilites: [-1] 
expected returns: [[24.883904]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 8.] 
cards in discard: [ 6. 29.  0.  6.  6. 16.  0. 11.  8. 16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 16 29  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0
  8  3 11  8  0  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 25. 30. 15. 27.  8.  3.  7.  4.  0. 10.  8.  4.  9.  6.  9.  8.] 
adversary cards in hand: [15. 14.  8.] 
adversary cards in discard: [29. 23. 11.  8.  3.  3.  4.  3. 11.  0. 14.  3.  3.  1.  8.  0.  1. 14.
  4. 15.  1. 16.  0. 14.  0.] 
adversary owned cards: [15  3 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8
  3  8  8  4  0 29  3  1  4] -> size -> 33 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: -0.09945052862167358
desired expected reward: 26.9249324798584





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[23.882772]
 [24.140368]
 [24.119827]
 [23.803633]
 [24.609251]
 [24.351656]
 [24.916325]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 8.] 
cards in discard: [ 6. 29.  0.  6.  6. 16.  0. 11.  8. 16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 16 29  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0
  8  3 11  8  0  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 25. 30. 15. 27.  8.  3.  7.  4.  0. 10.  8.  4.  9.  6.  9.  8.] 
adversary cards in hand: [15. 14.  8.] 
adversary cards in discard: [29. 23. 11.  8.  3.  3.  4.  3. 11.  0. 14.  3.  3.  1.  8.  0.  1. 14.
  4. 15.  1. 16.  0. 14.  0.] 
adversary owned cards: [15  3 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8
  3  8  8  4  0 29  3  1  4] -> size -> 33 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.040404222905635834
desired expected reward: 24.8435001373291



buy possibilites: [-1] 
expected returns: [[24.83602]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 8.] 
cards in discard: [ 6. 29.  0.  6.  6. 16.  0. 11.  8. 16. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0 16 29  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0
  8  3 11  8  0  3 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 15. 27.  8.  3.  7.  4.  0. 10.  8.  4.  9.  5.  9.  8.] 
adversary cards in hand: [15. 14.  8.] 
adversary cards in discard: [29. 23. 11.  8.  3.  3.  4.  3. 11.  0. 14.  3.  3.  1.  8.  0.  1. 14.
  4. 15.  1. 16.  0. 14.  0.] 
adversary owned cards: [15  3 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8
  3  8  8  4  0 29  3  1  4] -> size -> 33 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 10.0
Learning step: 0.5195914506912231
desired expected reward: 24.871248245239258






         -------------------- Turn: 55 -------------------- 
Player: 1 
cards in hand: [15. 14.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 14.  8.] 
cards in discard: [29. 23. 11.  8.  3.  3.  4.  3. 11.  0. 14.  3.  3.  1.  8.  0.  1. 14.
  4. 15.  1. 16.  0. 14.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [15  3 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8
  3  8  8  4  0 29  3  1  4] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 15. 27.  8.  3.  7.  4.  0. 10.  8.  4.  9.  5.  9.  8.] 
adversary cards in hand: [3. 8. 0. 0. 8.] 
adversary cards in discard: [ 6. 29.  0.  6.  6. 16.  0. 11.  8. 16. 10. 14.  3.  3.  0.  8.] 
adversary owned cards: [ 0 16 29  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0
  8  3 11  8  0  3 10] -> size -> 31 
adversary victory points: 2
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 14.  8.] 
cards in discard: [29. 23. 11.  8.  3.  3.  4.  3. 11.  0. 14.  3.  3.  1.  8.  0.  1. 14.
  4. 15.  1. 16.  0. 14.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [15  3 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8
  3  8  8  4  0 29  3  1  4] -> size -> 33 
action values: 1 
buys: 1 
player value: 0 
card supply: [15. 25. 30. 15. 27.  8.  3.  7.  4.  0. 10.  8.  4.  9.  5.  9.  8.] 
adversary cards in hand: [3. 8. 0. 0. 8.] 
adversary cards in discard: [ 6. 29.  0.  6.  6. 16.  0. 11.  8. 16. 10. 14.  3.  3.  0.  8.] 
adversary owned cards: [ 0 16 29  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0
  8  3 11  8  0  3 10] -> size -> 31 
adversary victory points: 2
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 14.  8.] 
cards in discard: [29. 23. 11.  8.  3.  3.  4.  3. 11.  0. 14.  3.  3.  1.  8.  0.  1. 14.
  4. 15.  1. 16.  0. 14.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [15  3 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8
  3  8  8  4  0 29  3  1  4  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 15. 27.  8.  3.  7.  4.  0. 10.  8.  4.  9.  5.  9.  8.] 
adversary cards in hand: [3. 8. 0. 0. 8.] 
adversary cards in discard: [ 6. 29.  0.  6.  6. 16.  0. 11.  8. 16. 10. 14.  3.  3.  0.  8.] 
adversary owned cards: [ 0 16 29  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0
  8  3 11  8  0  3 10] -> size -> 31 
adversary victory points: 2
player victory points: 11 





Player: 0 
cards in hand: [3. 8. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[28.085081]
 [27.54783 ]
 [27.54783 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0. 8.] 
cards in discard: [ 6. 29.  0.  6.  6. 16.  0. 11.  8. 16. 10. 14.  3.  3.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16 29  3  8  0  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0
  8  3 11  8  0  3 10] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 15. 27.  8.  3.  7.  4.  0. 10.  8.  4.  9.  5.  9.  8.] 
adversary cards in hand: [10.  0.  0.  8. 22.] 
adversary cards in discard: [29. 23. 11.  8.  3.  3.  4.  3. 11.  0. 14.  3.  3.  1.  8.  0.  1. 14.
  4. 15.  1. 16.  0. 14.  0.  0. 15. 14.  8.] 
adversary owned cards: [15  3 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8
  3  8  8  4  0 29  3  1  4  0] -> size -> 34 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.60319584608078
desired expected reward: 24.232824325561523



action possibilites: [-1] 
expected returns: [[30.620108]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 6. 29.  0.  6.  6. 16.  0. 11.  8. 16. 10. 14.  3.  3.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 15. 27.  8.  3.  7.  4.  0. 10.  8.  4.  9.  5.  9.  8.] 
adversary cards in hand: [10.  0.  0.  8. 22.] 
adversary cards in discard: [29. 23. 11.  8.  3.  3.  4.  3. 11.  0. 14.  3.  3.  1.  8.  0.  1. 14.
  4. 15.  1. 16.  0. 14.  0.  0. 15. 14.  8.] 
adversary owned cards: [15  3 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8
  3  8  8  4  0 29  3  1  4  0] -> size -> 34 
adversary victory points: 11
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 10
Learning step: -0.050017718225717545
desired expected reward: 27.33427619934082





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[29.801064]
 [29.721989]
 [30.82604 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 6. 29.  0.  6.  6. 16.  0. 11.  8. 16. 10. 14.  3.  3.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 25. 30. 15. 27.  8.  3.  7.  4.  0. 10.  8.  4.  9.  5.  9.  8.] 
adversary cards in hand: [10.  0.  0.  8. 22.] 
adversary cards in discard: [29. 23. 11.  8.  3.  3.  4.  3. 11.  0. 14.  3.  3.  1.  8.  0.  1. 14.
  4. 15.  1. 16.  0. 14.  0.  0. 15. 14.  8.] 
adversary owned cards: [15  3 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8
  3  8  8  4  0 29  3  1  4  0] -> size -> 34 
adversary victory points: 11
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.15089109539985657
desired expected reward: 30.46921730041504



buy possibilites: [-1] 
expected returns: [[31.217852]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 6. 29.  0.  6.  6. 16.  0. 11.  8. 16. 10. 14.  3.  3.  0.  8.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 15. 27.  8.  2.  7.  4.  0. 10.  8.  4.  9.  5.  9.  8.] 
adversary cards in hand: [10.  0.  0.  8. 22.] 
adversary cards in discard: [29. 23. 11.  8.  3.  3.  4.  3. 11.  0. 14.  3.  3.  1.  8.  0.  1. 14.
  4. 15.  1. 16.  0. 14.  0.  0. 15. 14.  8.] 
adversary owned cards: [15  3 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8
  3  8  8  4  0 29  3  1  4  0] -> size -> 34 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -285 

action type: buy - action 6.0
Learning step: -9.113872528076172
desired expected reward: 20.60811424255371






         -------------------- Turn: 56 -------------------- 
Player: 1 
cards in hand: [10.  0.  0.  8. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  8. 22.] 
cards in discard: [29. 23. 11.  8.  3.  3.  4.  3. 11.  0. 14.  3.  3.  1.  8.  0.  1. 14.
  4. 15.  1. 16.  0. 14.  0.  0. 15. 14.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [15  3 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8
  3  8  8  4  0 29  3  1  4  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 15. 27.  8.  2.  7.  4.  0. 10.  8.  4.  9.  5.  9.  8.] 
adversary cards in hand: [3. 0. 3. 6. 8.] 
adversary cards in discard: [ 6. 29.  0.  6.  6. 16.  0. 11.  8. 16. 10. 14.  3.  3.  0.  8.  6.  8.] 
adversary owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6] -> size -> 28 
adversary victory points: 0
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  8. 22.] 
cards in discard: [29. 23. 11.  8.  3.  3.  4.  3. 11.  0. 14.  3.  3.  1.  8.  0.  1. 14.
  4. 15.  1. 16.  0. 14.  0.  0. 15. 14.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [15  3 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8
  3  8  8  4  0 29  3  1  4  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 25. 30. 15. 27.  8.  2.  7.  4.  0. 10.  8.  4.  9.  5.  9.  8.] 
adversary cards in hand: [3. 0. 3. 6. 8.] 
adversary cards in discard: [ 6. 29.  0.  6.  6. 16.  0. 11.  8. 16. 10. 14.  3.  3.  0.  8.  6.  8.] 
adversary owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6] -> size -> 28 
adversary victory points: 0
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  8. 22.] 
cards in discard: [29. 23. 11.  8.  3.  3.  4.  3. 11.  0. 14.  3.  3.  1.  8.  0.  1. 14.
  4. 15.  1. 16.  0. 14.  0.  0. 15. 14.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [15  3 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8
  3  8  8  4  0 29  3  1  4  0  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 25. 30. 15. 27.  8.  2.  7.  4.  0. 10.  8.  4.  9.  5.  9.  8.] 
adversary cards in hand: [3. 0. 3. 6. 8.] 
adversary cards in discard: [ 6. 29.  0.  6.  6. 16.  0. 11.  8. 16. 10. 14.  3.  3.  0.  8.  6.  8.] 
adversary owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6] -> size -> 28 
adversary victory points: 0
player victory points: 11 





Player: 0 
cards in hand: [3. 0. 3. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[29.300543]
 [28.763292]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 6. 8.] 
cards in discard: [ 6. 29.  0.  6.  6. 16.  0. 11.  8. 16. 10. 14.  3.  3.  0.  8.  6.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 15. 27.  8.  2.  7.  4.  0. 10.  8.  4.  9.  5.  9.  8.] 
adversary cards in hand: [ 3.  0.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [15  3 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8
  3  8  8  4  0 29  3  1  4  0  0] -> size -> 35 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7811362743377686
desired expected reward: 30.436716079711914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[28.382828]
 [28.303755]
 [29.407808]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 6. 8.] 
cards in discard: [ 6. 29.  0.  6.  6. 16.  0. 11.  8. 16. 10. 14.  3.  3.  0.  8.  6.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 25. 30. 15. 27.  8.  2.  7.  4.  0. 10.  8.  4.  9.  5.  9.  8.] 
adversary cards in hand: [ 3.  0.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [15  3 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8
  3  8  8  4  0 29  3  1  4  0  0] -> size -> 35 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7261955738067627
desired expected reward: 28.5743465423584



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 57 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 15.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [15  3 22  0 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8
  3  8  8  4  0 29  3  1  4  0  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 15. 27.  8.  2.  7.  4.  0. 10.  8.  4.  9.  5.  9.  8.] 
adversary cards in hand: [ 3.  0.  0. 11. 10.] 
adversary cards in discard: [ 6. 29.  0.  6.  6. 16.  0. 11.  8. 16. 10. 14.  3.  3.  0.  8.  6.  8.
  3.  0.  3.  6.  8.] 
adversary owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6] -> size -> 28 
adversary victory points: 0
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  3 22 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8  3
  8  8  4  0 29  3  1  4  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [13. 25. 30. 15. 27.  8.  2.  7.  4.  0. 10.  8.  4.  9.  5.  9.  8.] 
adversary cards in hand: [ 3.  0.  0. 11. 10.] 
adversary cards in discard: [ 6. 29.  0.  6.  6. 16.  0. 11.  8. 16. 10. 14.  3.  3.  0.  8.  6.  8.
  3.  0.  3.  6.  8.] 
adversary owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6] -> size -> 28 
adversary victory points: 0
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  3 22 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8  3
  8  8  4  0 29  3  1  4  0  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 5 
card supply: [13. 25. 30. 15. 27.  8.  2.  7.  4.  0. 10.  8.  4.  9.  5.  9.  8.] 
adversary cards in hand: [ 3.  0.  0. 11. 10.] 
adversary cards in discard: [ 6. 29.  0.  6.  6. 16.  0. 11.  8. 16. 10. 14.  3.  3.  0.  8.  6.  8.
  3.  0.  3.  6.  8.] 
adversary owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6] -> size -> 28 
adversary victory points: 0
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [11.] 
cards in deck: 30 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  3 22 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8  3
  8  8  4  0 29  3  1  4  0  0 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 25. 30. 15. 27.  8.  2.  7.  3.  0. 10.  8.  4.  9.  5.  9.  8.] 
adversary cards in hand: [ 3.  0.  0. 11. 10.] 
adversary cards in discard: [ 6. 29.  0.  6.  6. 16.  0. 11.  8. 16. 10. 14.  3.  3.  0.  8.  6.  8.
  3.  0.  3.  6.  8.] 
adversary owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6] -> size -> 28 
adversary victory points: 0
player victory points: 11 





Player: 0 
cards in hand: [ 3.  0.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[25.828001]
 [25.526712]
 [25.270897]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11. 10.] 
cards in discard: [ 6. 29.  0.  6.  6. 16.  0. 11.  8. 16. 10. 14.  3.  3.  0.  8.  6.  8.
  3.  0.  3.  6.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 15. 27.  8.  2.  7.  3.  0. 10.  8.  4.  9.  5.  9.  8.] 
adversary cards in hand: [ 1. 14.  4.  8. 10.] 
adversary cards in discard: [11. 15.  3.  0.  0.] 
adversary owned cards: [15  3 22 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8  3
  8  8  4  0 29  3  1  4  0  0 11] -> size -> 35 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.763443648815155
desired expected reward: 28.644363403320312



action possibilites: [-1] 
expected returns: [[26.700994]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10.] 
cards in discard: [ 6. 29.  0.  6.  6. 16.  0. 11.  8. 16. 10. 14.  3.  3.  0.  8.  6.  8.
  3.  0.  3.  6.  8. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 15. 27.  8.  2.  7.  3.  0. 10.  8.  4.  9.  5.  9.  7.] 
adversary cards in hand: [ 1. 14.  4.  8. 10.] 
adversary cards in discard: [11. 15.  3.  0.  0.] 
adversary owned cards: [15  3 22 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8  3
  8  8  4  0 29  3  1  4  0  0 11] -> size -> 35 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 9
Learning step: 0.4439634680747986
desired expected reward: 25.990530014038086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[25.871687]
 [26.107647]
 [25.792612]
 [26.896666]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.] 
cards in discard: [ 6. 29.  0.  6.  6. 16.  0. 11.  8. 16. 10. 14.  3.  3.  0.  8.  6.  8.
  3.  0.  3.  6.  8. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 25. 30. 15. 27.  8.  2.  7.  3.  0. 10.  8.  4.  9.  5.  9.  7.] 
adversary cards in hand: [ 1. 14.  4.  8. 10.] 
adversary cards in discard: [11. 15.  3.  0.  0.] 
adversary owned cards: [15  3 22 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8  3
  8  8  4  0 29  3  1  4  0  0 11] -> size -> 35 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.07474273443222046
desired expected reward: 26.626251220703125



buy possibilites: [-1] 
expected returns: [[25.656507]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.] 
cards in discard: [ 6. 29.  0.  6.  6. 16.  0. 11.  8. 16. 10. 14.  3.  3.  0.  8.  6.  8.
  3.  0.  3.  6.  8. 15.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6 15  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 25. 30. 15. 27.  8.  1.  7.  3.  0. 10.  8.  4.  9.  5.  9.  7.] 
adversary cards in hand: [ 1. 14.  4.  8. 10.] 
adversary cards in discard: [11. 15.  3.  0.  0.] 
adversary owned cards: [15  3 22 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8  3
  8  8  4  0 29  3  1  4  0  0 11] -> size -> 35 
adversary victory points: 11
player victory points: -1 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -285.0 

action type: buy - action 6.0
Learning step: -9.0543851852417
desired expected reward: 16.73822784423828






         -------------------- Turn: 58 -------------------- 
Player: 1 
cards in hand: [ 1. 14.  4.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 14.  4.  8. 10.] 
cards in discard: [11. 15.  3.  0.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [15  3 22 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8  3
  8  8  4  0 29  3  1  4  0  0 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 15. 27.  8.  1.  7.  3.  0. 10.  8.  4.  9.  5.  9.  7.] 
adversary cards in hand: [ 8. 10.  3.  8.  6.] 
adversary cards in discard: [] 
adversary owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6 15  6] -> size -> 30 
adversary victory points: -1
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 14.  4.  8. 10.] 
cards in discard: [11. 15.  3.  0.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [15  3 22 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8  3
  8  8  4  0 29  3  1  4  0  0 11] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 25. 30. 15. 27.  8.  1.  7.  3.  0. 10.  8.  4.  9.  5.  9.  7.] 
adversary cards in hand: [ 8. 10.  3.  8.  6.] 
adversary cards in discard: [] 
adversary owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6 15  6] -> size -> 30 
adversary victory points: -1
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 14.  4.  8. 10.] 
cards in discard: [11. 15.  3.  0.  0.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [15  3 22 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8  3
  8  8  4  0 29  3  1  4  0  0 11  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 25. 30. 15. 27.  8.  1.  7.  3.  0. 10.  8.  4.  9.  5.  9.  7.] 
adversary cards in hand: [ 8. 10.  3.  8.  6.] 
adversary cards in discard: [] 
adversary owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6 15  6] -> size -> 30 
adversary victory points: -1
player victory points: 11 





Player: 0 
cards in hand: [ 8. 10.  3.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.] 
expected returns: [[22.844757]
 [22.307508]
 [22.287653]
 [22.307508]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  3.  8.  6.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6 15  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 25. 30. 15. 27.  8.  1.  7.  3.  0. 10.  8.  4.  9.  5.  9.  7.] 
adversary cards in hand: [ 4.  0.  3. 16.  3.] 
adversary cards in discard: [11. 15.  3.  0.  0.  0.  1. 14.  4.  8. 10.] 
adversary owned cards: [15  3 22 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8  3
  8  8  4  0 29  3  1  4  0  0 11  0] -> size -> 36 
adversary victory points: 11
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6832516193389893
desired expected reward: 24.973255157470703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[21.941362]
 [21.862288]
 [22.96634 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  3.  8.  6.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6 15  6] -> size -> 30 
action values: 1 
buys: 1 
player value: 0 
card supply: [12. 25. 30. 15. 27.  8.  1.  7.  3.  0. 10.  8.  4.  9.  5.  9.  7.] 
adversary cards in hand: [ 4.  0.  3. 16.  3.] 
adversary cards in discard: [11. 15.  3.  0.  0.  0.  1. 14.  4.  8. 10.] 
adversary owned cards: [15  3 22 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8  3
  8  8  4  0 29  3  1  4  0  0 11  0] -> size -> 36 
adversary victory points: 11
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6001574397087097
desired expected reward: 22.244600296020508



buy possibilites: [-1] 
expected returns: [[23.259062]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  3.  8.  6.] 
cards in discard: [6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6 15  6  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 25. 30. 15. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  5.  9.  7.] 
adversary cards in hand: [ 4.  0.  3. 16.  3.] 
adversary cards in discard: [11. 15.  3.  0.  0.  0.  1. 14.  4.  8. 10.] 
adversary owned cards: [15  3 22 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8  3
  8  8  4  0 29  3  1  4  0  0 11  0] -> size -> 36 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -305 

action type: buy - action 6.0
Learning step: -9.561647415161133
desired expected reward: 12.300640106201172






         -------------------- Turn: 59 -------------------- 
Player: 1 
cards in hand: [ 4.  0.  3. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4.  0.  3. 16.  3.] 
cards in discard: [11. 15.  3.  0.  0.  0.  1. 14.  4.  8. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [15  3 22 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8  3
  8  8  4  0 29  3  1  4  0  0 11  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 25. 30. 15. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  5.  9.  7.] 
adversary cards in hand: [14.  0. 29.  0.  6.] 
adversary cards in discard: [ 6.  8. 10.  3.  8.  6.] 
adversary owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6 15  6  6] -> size -> 31 
adversary victory points: -2
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 0. 3.] 
cards in discard: [11. 15.  3.  0.  0.  0.  1. 14.  4.  8. 10.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [16.] 
owned cards: [15 22 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8  3  8
  8  4  0 29  3  1  4  0  0 11  0  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 15. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  5.  9.  7.] 
adversary cards in hand: [14.  0. 29.  0.  6.] 
adversary cards in discard: [ 6.  8. 10.  3.  8.  6.] 
adversary owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6 15  6  6] -> size -> 31 
adversary victory points: -2
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0. 3.] 
cards in discard: [11. 15.  3.  0.  0.  0.  1. 14.  4.  8. 10.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [16.] 
owned cards: [15 22 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8  3  8
  8  4  0 29  3  1  4  0  0 11  0  1] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 24. 30. 15. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  5.  9.  7.] 
adversary cards in hand: [14.  0. 29.  0.  6.] 
adversary cards in discard: [ 6.  8. 10.  3.  8.  6.] 
adversary owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6 15  6  6] -> size -> 31 
adversary victory points: -2
player victory points: 10 





Player: 0 
cards in hand: [14.  0. 29.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29.] 
expected returns: [[25.539759]
 [24.923433]
 [25.304934]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0. 29.  0.  6.] 
cards in discard: [ 6.  8. 10.  3.  8.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6 15  6  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 15. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  5.  9.  7.] 
adversary cards in hand: [11. 14.  1.  0.  0.] 
adversary cards in discard: [11. 15.  3.  0.  0.  0.  1. 14.  4.  8. 10.  1. 16.  4.  0.  3.] 
adversary owned cards: [15 22 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8  3  8
  8  4  0 29  3  1  4  0  0 11  0  1] -> size -> 36 
adversary victory points: 10
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5819875597953796
desired expected reward: 22.677074432373047



action possibilites: [-1.] 
expected returns: [[25.024803]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3.] 
cards in discard: [ 6.  8. 10.  3.  8.  6. 14.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6 15  6  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [12. 24. 30. 15. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  5.  9.  7.] 
adversary cards in hand: [11. 14.  1.  0.  0.] 
adversary cards in discard: [11. 15.  3.  0.  0.  0.  1. 14.  4.  8. 10.  1. 16.  4.  0.  3.] 
adversary owned cards: [15 22 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8  3  8
  8  4  0 29  3  1  4  0  0 11  0  1] -> size -> 36 
adversary victory points: 10
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 4
Learning step: 0.001452541328035295
desired expected reward: 23.71171760559082





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[24.10549 ]
 [24.338076]
 [25.113195]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3.] 
cards in discard: [ 6.  8. 10.  3.  8.  6. 14.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6 15  6  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 24. 30. 15. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  5.  9.  7.] 
adversary cards in hand: [11. 14.  1.  0.  0.] 
adversary cards in discard: [11. 15.  3.  0.  0.  0.  1. 14.  4.  8. 10.  1. 16.  4.  0.  3.] 
adversary owned cards: [15 22 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8  3  8
  8  4  0 29  3  1  4  0  0 11  0  1] -> size -> 36 
adversary victory points: 10
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.042047422379255295
desired expected reward: 24.982755661010742






         -------------------- Turn: 60 -------------------- 
Player: 1 
cards in hand: [11. 14.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 14.  1.  0.  0.] 
cards in discard: [11. 15.  3.  0.  0.  0.  1. 14.  4.  8. 10.  1. 16.  4.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [15 22 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8  3  8
  8  4  0 29  3  1  4  0  0 11  0  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 15. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  5.  9.  7.] 
adversary cards in hand: [3. 0. 6. 0. 8.] 
adversary cards in discard: [ 6.  8. 10.  3.  8.  6. 14.  0. 29.  0.  6.  3.] 
adversary owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6 15  6  6] -> size -> 31 
adversary victory points: -2
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 14.  1.  0.  0.] 
cards in discard: [11. 15.  3.  0.  0.  0.  1. 14.  4.  8. 10.  1. 16.  4.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [15 22 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8  3  8
  8  4  0 29  3  1  4  0  0 11  0  1] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 24. 30. 15. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  5.  9.  7.] 
adversary cards in hand: [3. 0. 6. 0. 8.] 
adversary cards in discard: [ 6.  8. 10.  3.  8.  6. 14.  0. 29.  0.  6.  3.] 
adversary owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6 15  6  6] -> size -> 31 
adversary victory points: -2
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 14.  1.  0.  0.] 
cards in discard: [11. 15.  3.  0.  0.  0.  1. 14.  4.  8. 10.  1. 16.  4.  0.  3. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [15 22 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8  3  8
  8  4  0 29  3  1  4  0  0 11  0  1 10] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 24. 30. 15. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  4.  9.  7.] 
adversary cards in hand: [3. 0. 6. 0. 8.] 
adversary cards in discard: [ 6.  8. 10.  3.  8.  6. 14.  0. 29.  0.  6.  3.] 
adversary owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6 15  6  6] -> size -> 31 
adversary victory points: -2
player victory points: 10 





Player: 0 
cards in hand: [3. 0. 6. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[20.623951]
 [20.098724]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 0. 8.] 
cards in discard: [ 6.  8. 10.  3.  8.  6. 14.  0. 29.  0.  6.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6 15  6  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 15. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  4.  9.  7.] 
adversary cards in hand: [ 0.  0.  8.  8. 22.] 
adversary cards in discard: [11. 15.  3.  0.  0.  0.  1. 14.  4.  8. 10.  1. 16.  4.  0.  3. 10. 11.
 14.  1.  0.  0.] 
adversary owned cards: [15 22 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8  3  8
  8  4  0 29  3  1  4  0  0 11  0  1 10] -> size -> 37 
adversary victory points: 10
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6890503168106079
desired expected reward: 24.424144744873047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[19.70924 ]
 [19.941828]
 [20.716944]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 8.] 
cards in discard: [ 6.  8. 10.  3.  8.  6. 14.  0. 29.  0.  6.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6 15  6  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 24. 30. 15. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  4.  9.  7.] 
adversary cards in hand: [ 0.  0.  8.  8. 22.] 
adversary cards in discard: [11. 15.  3.  0.  0.  0.  1. 14.  4.  8. 10.  1. 16.  4.  0.  3. 10. 11.
 14.  1.  0.  0.] 
adversary owned cards: [15 22 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8  3  8
  8  4  0 29  3  1  4  0  0 11  0  1 10] -> size -> 37 
adversary victory points: 10
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5561824440956116
desired expected reward: 20.067766189575195



buy possibilites: [-1] 
expected returns: [[19.552876]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 8.] 
cards in discard: [ 6.  8. 10.  3.  8.  6. 14.  0. 29.  0.  6.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6 15  6  6  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 24. 30. 15. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  4.  9.  7.] 
adversary cards in hand: [ 0.  0.  8.  8. 22.] 
adversary cards in discard: [11. 15.  3.  0.  0.  0.  1. 14.  4.  8. 10.  1. 16.  4.  0.  3. 10. 11.
 14.  1.  0.  0.] 
adversary owned cards: [15 22 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8  3  8
  8  4  0 29  3  1  4  0  0 11  0  1 10] -> size -> 37 
adversary victory points: 10
player victory points: -2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.535971999168396
desired expected reward: 19.173267364501953






         -------------------- Turn: 61 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  8.  8. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8.  8. 22.] 
cards in discard: [11. 15.  3.  0.  0.  0.  1. 14.  4.  8. 10.  1. 16.  4.  0.  3. 10. 11.
 14.  1.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [15 22 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8  3  8
  8  4  0 29  3  1  4  0  0 11  0  1 10] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 15. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  4.  9.  7.] 
adversary cards in hand: [ 3. 11.  8.  0. 11.] 
adversary cards in discard: [ 6.  8. 10.  3.  8.  6. 14.  0. 29.  0.  6.  3.  0.  3.  0.  6.  0.  8.] 
adversary owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6 15  6  6  0] -> size -> 32 
adversary victory points: -2
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8.  8. 23. 14.  3.] 
cards in discard: [11. 15.  3.  0.  0.  0.  1. 14.  4.  8. 10.  1. 16.  4.  0.  3. 10. 11.
 14.  1.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [22.] 
owned cards: [15 22 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8  3  8
  8  4  0 29  3  1  4  0  0 11  0  1 10] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 15. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  4.  9.  7.] 
adversary cards in hand: [ 3. 11.  8.  0. 11.] 
adversary cards in discard: [ 6.  8. 10.  3.  8.  6. 14.  0. 29.  0.  6.  3.  0.  3.  0.  6.  0.  8.] 
adversary owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6 15  6  6  0] -> size -> 32 
adversary victory points: -2
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8.  8. 23. 14.  3.] 
cards in discard: [11. 15.  3.  0.  0.  0.  1. 14.  4.  8. 10.  1. 16.  4.  0.  3. 10. 11.
 14.  1.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [22.] 
owned cards: [15 22 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8  3  8
  8  4  0 29  3  1  4  0  0 11  0  1 10] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 24. 30. 15. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  4.  9.  7.] 
adversary cards in hand: [ 3. 11.  8.  0. 11.] 
adversary cards in discard: [ 6.  8. 10.  3.  8.  6. 14.  0. 29.  0.  6.  3.  0.  3.  0.  6.  0.  8.] 
adversary owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6 15  6  6  0] -> size -> 32 
adversary victory points: -2
player victory points: 10 





Player: 0 
cards in hand: [ 3. 11.  8.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 11.] 
expected returns: [[21.225466]
 [20.932825]
 [20.70024 ]
 [20.932825]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  8.  0. 11.] 
cards in discard: [ 6.  8. 10.  3.  8.  6. 14.  0. 29.  0.  6.  3.  0.  3.  0.  6.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6 15  6  6  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 15. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  4.  9.  7.] 
adversary cards in hand: [15. 11.  1.  3. 29.] 
adversary cards in discard: [11. 15.  3.  0.  0.  0.  1. 14.  4.  8. 10.  1. 16.  4.  0.  3. 10. 11.
 14.  1.  0.  0. 22.  0.  0.  8.  8. 23. 14.  3.] 
adversary owned cards: [15 22 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8  3  8
  8  4  0 29  3  1  4  0  0 11  0  1 10] -> size -> 37 
adversary victory points: 10
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5160509347915649
desired expected reward: 19.03682518005371





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[20.387976]
 [21.395678]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  8.  0. 11.] 
cards in discard: [ 6.  8. 10.  3.  8.  6. 14.  0. 29.  0.  6.  3.  0.  3.  0.  6.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6 15  6  6  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 24. 30. 15. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  4.  9.  7.] 
adversary cards in hand: [15. 11.  1.  3. 29.] 
adversary cards in discard: [11. 15.  3.  0.  0.  0.  1. 14.  4.  8. 10.  1. 16.  4.  0.  3. 10. 11.
 14.  1.  0.  0. 22.  0.  0.  8.  8. 23. 14.  3.] 
adversary owned cards: [15 22 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8  3  8
  8  4  0 29  3  1  4  0  0 11  0  1 10] -> size -> 37 
adversary victory points: 10
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5663416385650635
desired expected reward: 20.65912437438965



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 62 -------------------- 
Player: 1 
cards in hand: [15. 11.  1.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 29.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.  1.  3. 29.] 
cards in discard: [11. 15.  3.  0.  0.  0.  1. 14.  4.  8. 10.  1. 16.  4.  0.  3. 10. 11.
 14.  1.  0.  0. 22.  0.  0.  8.  8. 23. 14.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [15 22 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8  3  8
  8  4  0 29  3  1  4  0  0 11  0  1 10] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 15. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  4.  9.  7.] 
adversary cards in hand: [10.  0. 15.  6. 16.] 
adversary cards in discard: [ 6.  8. 10.  3.  8.  6. 14.  0. 29.  0.  6.  3.  0.  3.  0.  6.  0.  8.
  3. 11.  8.  0. 11.] 
adversary owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6 15  6  6  0] -> size -> 32 
adversary victory points: -2
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1.  3. 29.] 
cards in discard: [11. 15.  3.  0.  0.  0.  1. 14.  4.  8. 10.  1. 16.  4.  0.  3. 10. 11.
 14.  1.  0.  0. 22.  0.  0.  8.  8. 23. 14.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [15 22 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8  3  8
  8  4  0 29  3  1  4  0  0 11  0  1 10  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 14. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  4.  9.  7.] 
adversary cards in hand: [10.  0. 15.  6. 16.] 
adversary cards in discard: [ 6.  8. 10.  3.  8.  6. 14.  0. 29.  0.  6.  3.  0.  3.  0.  6.  0.  8.
  3. 11.  8.  0. 11.] 
adversary owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6 15  6  6  0] -> size -> 32 
adversary victory points: -2
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1.  3. 29.] 
cards in discard: [11. 15.  3.  0.  0.  0.  1. 14.  4.  8. 10.  1. 16.  4.  0.  3. 10. 11.
 14.  1.  0.  0. 22.  0.  0.  8.  8. 23. 14.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [15 22 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8  3  8
  8  4  0 29  3  1  4  0  0 11  0  1 10  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 24. 30. 14. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  4.  9.  7.] 
adversary cards in hand: [10.  0. 15.  6. 16.] 
adversary cards in discard: [ 6.  8. 10.  3.  8.  6. 14.  0. 29.  0.  6.  3.  0.  3.  0.  6.  0.  8.
  3. 11.  8.  0. 11.] 
adversary owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6 15  6  6  0] -> size -> 32 
adversary victory points: -2
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1.  3. 29.] 
cards in discard: [11. 15.  3.  0.  0.  0.  1. 14.  4.  8. 10.  1. 16.  4.  0.  3. 10. 11.
 14.  1.  0.  0. 22.  0.  0.  8.  8. 23. 14.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [15 22 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8  3  8
  8  4  0 29  3  1  4  0  0 11  0  1 10  3  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 24. 30. 14. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  4.  9.  7.] 
adversary cards in hand: [10.  0. 15.  6. 16.] 
adversary cards in discard: [ 6.  8. 10.  3.  8.  6. 14.  0. 29.  0.  6.  3.  0.  3.  0.  6.  0.  8.
  3. 11.  8.  0. 11.] 
adversary owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6 15  6  6  0] -> size -> 32 
adversary victory points: -2
player victory points: 11 





Player: 0 
cards in hand: [10.  0. 15.  6. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 16.] 
expected returns: [[22.084871]
 [21.539646]
 [21.731762]
 [21.180824]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 15.  6. 16.] 
cards in discard: [ 6.  8. 10.  3.  8.  6. 14.  0. 29.  0.  6.  3.  0.  3.  0.  6.  0.  8.
  3. 11.  8.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6 15  6  6  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 24. 30. 14. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  4.  9.  7.] 
adversary cards in hand: [11. 11.  0.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [15 22 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8  3  8
  8  4  0 29  3  1  4  0  0 11  0  1 10  3  0] -> size -> 39 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5637641549110413
desired expected reward: 20.831912994384766





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[21.024723]
 [22.032427]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 15.  6. 16.] 
cards in discard: [ 6.  8. 10.  3.  8.  6. 14.  0. 29.  0.  6.  3.  0.  3.  0.  6.  0.  8.
  3. 11.  8.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6 15  6  6  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 24. 30. 14. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  4.  9.  7.] 
adversary cards in hand: [11. 11.  0.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [15 22 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8  3  8
  8  4  0 29  3  1  4  0  0 11  0  1 10  3  0] -> size -> 39 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5854380130767822
desired expected reward: 21.499433517456055



buy possibilites: [-1] 
expected returns: [[22.97093]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 15.  6. 16.] 
cards in discard: [ 6.  8. 10.  3.  8.  6. 14.  0. 29.  0.  6.  3.  0.  3.  0.  6.  0.  8.
  3. 11.  8.  0. 11.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6 15  6  6  0  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 24. 30. 14. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  4.  9.  7.] 
adversary cards in hand: [11. 11.  0.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [15 22 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8  3  8
  8  4  0 29  3  1  4  0  0 11  0  1 10  3  0] -> size -> 39 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.5395469069480896
desired expected reward: 20.485177993774414






         -------------------- Turn: 63 -------------------- 
Player: 1 
cards in hand: [11. 11.  0.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0.  8. 14.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [15 22 14 10  0  8  1  1  0 14  0 14 16 15  3  3 23 11 11 14  0  8  3  8
  8  4  0 29  3  1  4  0  0 11  0  1 10  3  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 24. 30. 14. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  4.  9.  7.] 
adversary cards in hand: [ 0.  6.  6.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6 15  6  6  0  0] -> size -> 33 
adversary victory points: -2
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [8.] 
owned cards: [15 22 14 10  8  1  1  0 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0
 29  3  1  4  0  0 11  0  1 10  3  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 24. 30. 14. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  4.  9.  7.] 
adversary cards in hand: [ 0.  6.  6.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6 15  6  6  0  0] -> size -> 33 
adversary victory points: -2
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [8.] 
owned cards: [15 22 14 10  8  1  1  0 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0
 29  3  1  4  0  0 11  0  1 10  3  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 24. 30. 14. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  4.  9.  7.] 
adversary cards in hand: [ 0.  6.  6.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6 15  6  6  0  0] -> size -> 33 
adversary victory points: -2
player victory points: 11 





Player: 0 
cards in hand: [ 0.  6.  6.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[17.458593]
 [16.554546]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  6.  3. 16.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6 15  6  6  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 24. 30. 14. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  4.  9.  7.] 
adversary cards in hand: [0. 0. 0. 3. 4.] 
adversary cards in discard: [ 8. 14.] 
adversary owned cards: [15 22 14 10  8  1  1  0 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0
 29  3  1  4  0  0 11  0  1 10  3  0] -> size -> 36 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6596096158027649
desired expected reward: 22.311321258544922





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[16.479998]
 [17.4877  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  6.  3. 16.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6 15  6  6  0  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 24. 30. 14. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  4.  9.  7.] 
adversary cards in hand: [0. 0. 0. 3. 4.] 
adversary cards in discard: [ 8. 14.] 
adversary owned cards: [15 22 14 10  8  1  1  0 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0
 29  3  1  4  0  0 11  0  1 10  3  0] -> size -> 36 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.494369238615036
desired expected reward: 16.964221954345703



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 64 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 4.] 
cards in discard: [ 8. 14.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [15 22 14 10  8  1  1  0 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0
 29  3  1  4  0  0 11  0  1 10  3  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 24. 30. 14. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  4.  9.  7.] 
adversary cards in hand: [14.  3.  6.  3. 11.] 
adversary cards in discard: [ 0.  6.  6.  3. 16.] 
adversary owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6 15  6  6  0  0] -> size -> 33 
adversary victory points: -2
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 4.] 
cards in discard: [ 8. 14.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [15 22 14 10  8  1  1  0 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0
 29  3  1  4  0  0 11  0  1 10  3  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 24. 30. 14. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  4.  9.  7.] 
adversary cards in hand: [14.  3.  6.  3. 11.] 
adversary cards in discard: [ 0.  6.  6.  3. 16.] 
adversary owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6 15  6  6  0  0] -> size -> 33 
adversary victory points: -2
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 4.] 
cards in discard: [ 8. 14. 10.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [15 22 14 10  8  1  1  0 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0
 29  3  1  4  0  0 11  0  1 10  3  0 10] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 24. 30. 14. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [14.  3.  6.  3. 11.] 
adversary cards in discard: [ 0.  6.  6.  3. 16.] 
adversary owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6 15  6  6  0  0] -> size -> 33 
adversary victory points: -2
player victory points: 11 





Player: 0 
cards in hand: [14.  3.  6.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
expected returns: [[21.325472]
 [20.719776]
 [21.032831]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  6.  3. 11.] 
cards in discard: [ 0.  6.  6.  3. 16.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6 15  6  6  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 24. 30. 14. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [14. 11.  8. 23.  3.] 
adversary cards in discard: [ 8. 14. 10.  0.  0.  0.  3.  4.] 
adversary owned cards: [15 22 14 10  8  1  1  0 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0
 29  3  1  4  0  0 11  0  1 10  3  0 10] -> size -> 37 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.4532289206981659
desired expected reward: 17.034473419189453





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[20.376818]
 [21.384521]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  6.  3. 11.] 
cards in discard: [ 0.  6.  6.  3. 16.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6 15  6  6  0  0] -> size -> 33 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 9. 24. 30. 14. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [14. 11.  8. 23.  3.] 
adversary cards in discard: [ 8. 14. 10.  0.  0.  0.  3.  4.] 
adversary owned cards: [15 22 14 10  8  1  1  0 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0
 29  3  1  4  0  0 11  0  1 10  3  0 10] -> size -> 37 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5694590210914612
desired expected reward: 20.756011962890625



buy possibilites: [-1] 
expected returns: [[18.153622]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  6.  3. 11.] 
cards in discard: [ 0.  6.  6.  3. 16.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6 15  6  6  0  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 24. 30. 14. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [14. 11.  8. 23.  3.] 
adversary cards in discard: [ 8. 14. 10.  0.  0.  0.  3.  4.] 
adversary owned cards: [15 22 14 10  8  1  1  0 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0
 29  3  1  4  0  0 11  0  1 10  3  0 10] -> size -> 37 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action 0.0
Learning step: -0.5656880736351013
desired expected reward: 19.81113052368164






         -------------------- Turn: 65 -------------------- 
Player: 1 
cards in hand: [14. 11.  8. 23.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.  8. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 11.  8. 23.  3.] 
cards in discard: [ 8. 14. 10.  0.  0.  0.  3.  4.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [15 22 14 10  8  1  1  0 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0
 29  3  1  4  0  0 11  0  1 10  3  0 10] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 24. 30. 14. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [29.  6.  3.  6.  8.] 
adversary cards in discard: [ 0.  6.  6.  3. 16.  0. 14.  3.  6.  3. 11.] 
adversary owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6 15  6  6  0  0  0] -> size -> 34 
adversary victory points: -2
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 11.  8. 23.  3.] 
cards in discard: [ 8. 14. 10.  0.  0.  0.  3.  4.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [15 22 14 10  8  1  1  0 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0
 29  3  1  4  0  0 11  0  1 10  3  0 10] -> size -> 37 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 8. 24. 30. 14. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [29.  6.  3.  6.  8.] 
adversary cards in discard: [ 0.  6.  6.  3. 16.  0. 14.  3.  6.  3. 11.] 
adversary owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6 15  6  6  0  0  0] -> size -> 34 
adversary victory points: -2
player victory points: 11 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29.  6.  3.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[21.472631]
 [21.24487 ]
 [20.95172 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6.  3.  6.  8.] 
cards in discard: [ 0.  6.  6.  3. 16.  0. 14.  3.  6.  3. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [16 29  0 11  8  0 10  8  3  6  3  0  3  6 16  6 14  6  0  0  8  3 11  8
  0  3 10  6 15  6  6  0  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 24. 30. 14. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [16. 22.  8.  8.  0.] 
adversary cards in discard: [ 8. 14. 10.  0.  0.  0.  3.  4. 14. 11.  8. 23.  3.] 
adversary owned cards: [15 22 14 10  8  1  1  0 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0
 29  3  1  4  0  0 11  0  1 10  3  0 10] -> size -> 37 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4712422788143158
desired expected reward: 17.6823787689209



action possibilites: [-1] 
expected returns: [[24.268599]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 0.  6.  6.  3. 16.  0. 14.  3.  6.  3. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  0 11  8  0 10  8  3  0  3  6 16  6 14  6  0  0  8  3 11  8  0  3 10
  6 15  6  6  0  0  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 24. 30. 14. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [16. 22.  8.  8.  0.] 
adversary cards in discard: [ 8. 14. 10.  0.  0.  0.  3.  4. 14. 11.  8. 23.  3.] 
adversary owned cards: [15 22 14 10  8  1  1  0 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0
 29  3  1  4  0  0 11  0  1 10  3  0 10] -> size -> 37 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 9
Learning step: 0.0660012811422348
desired expected reward: 21.359968185424805





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[23.455908]
 [24.459421]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 0.  6.  6.  3. 16.  0. 14.  3.  6.  3. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  0 11  8  0 10  8  3  0  3  6 16  6 14  6  0  0  8  3 11  8  0  3 10
  6 15  6  6  0  0  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 24. 30. 14. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [16. 22.  8.  8.  0.] 
adversary cards in discard: [ 8. 14. 10.  0.  0.  0.  3.  4. 14. 11.  8. 23.  3.] 
adversary owned cards: [15 22 14 10  8  1  1  0 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0
 29  3  1  4  0  0 11  0  1 10  3  0 10] -> size -> 37 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.025448741391301155
desired expected reward: 24.24315071105957






         -------------------- Turn: 66 -------------------- 
Player: 1 
cards in hand: [16. 22.  8.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 22.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 22.  8.  8.  0.] 
cards in discard: [ 8. 14. 10.  0.  0.  0.  3.  4. 14. 11.  8. 23.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [15 22 14 10  8  1  1  0 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0
 29  3  1  4  0  0 11  0  1 10  3  0 10] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 24. 30. 14. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [0. 8. 8. 6. 0.] 
adversary cards in discard: [ 0.  6.  6.  3. 16.  0. 14.  3.  6.  3. 11.  8.  6.] 
adversary owned cards: [16  0 11  8  0 10  8  3  0  3  6 16  6 14  6  0  0  8  3 11  8  0  3 10
  6 15  6  6  0  0  0] -> size -> 31 
adversary victory points: -2
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 22.  8.] 
cards in discard: [ 8. 14. 10.  0.  0.  0.  3.  4. 14. 11.  8. 23.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [15 22 14 10  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29
  3  1  4  0  0 11  0  1 10  3  0 10] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 24. 30. 14. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [0. 8. 8. 6. 0.] 
adversary cards in discard: [ 0.  6.  6.  3. 16.  0. 14.  3.  6.  3. 11.  8.  6.] 
adversary owned cards: [16  0 11  8  0 10  8  3  0  3  6 16  6 14  6  0  0  8  3 11  8  0  3 10
  6 15  6  6  0  0  0] -> size -> 31 
adversary victory points: -2
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 22.  8.] 
cards in discard: [ 8. 14. 10.  0.  0.  0.  3.  4. 14. 11.  8. 23.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [15 22 14 10  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29
  3  1  4  0  0 11  0  1 10  3  0 10] -> size -> 36 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 24. 30. 14. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [0. 8. 8. 6. 0.] 
adversary cards in discard: [ 0.  6.  6.  3. 16.  0. 14.  3.  6.  3. 11.  8.  6.] 
adversary owned cards: [16  0 11  8  0 10  8  3  0  3  6 16  6 14  6  0  0  8  3 11  8  0  3 10
  6 15  6  6  0  0  0] -> size -> 31 
adversary victory points: -2
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 22.  8.] 
cards in discard: [ 8. 14. 10.  0.  0.  0.  3.  4. 14. 11.  8. 23.  3.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [15 22 14 10  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29
  3  1  4  0  0 11  0  1 10  3  0 10  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 14. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [0. 8. 8. 6. 0.] 
adversary cards in discard: [ 0.  6.  6.  3. 16.  0. 14.  3.  6.  3. 11.  8.  6.] 
adversary owned cards: [16  0 11  8  0 10  8  3  0  3  6 16  6 14  6  0  0  8  3 11  8  0  3 10
  6 15  6  6  0  0  0] -> size -> 31 
adversary victory points: -2
player victory points: 11 





Player: 0 
cards in hand: [0. 8. 8. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[22.722012]
 [22.201097]
 [22.201097]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 6. 0.] 
cards in discard: [ 0.  6.  6.  3. 16.  0. 14.  3.  6.  3. 11.  8.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [16  0 11  8  0 10  8  3  0  3  6 16  6 14  6  0  0  8  3 11  8  0  3 10
  6 15  6  6  0  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 14. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [ 0.  4. 10.  3.  1.] 
adversary cards in discard: [ 8. 14. 10.  0.  0.  0.  3.  4. 14. 11.  8. 23.  3.  0.  8. 16. 22.  8.] 
adversary owned cards: [15 22 14 10  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29
  3  1  4  0  0 11  0  1 10  3  0 10  0] -> size -> 37 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6481185555458069
desired expected reward: 23.81130027770996



action possibilites: [-1] 
expected returns: [[24.326082]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6.] 
cards in discard: [ 0.  6.  6.  3. 16.  0. 14.  3.  6.  3. 11.  8.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 11  8 10  8  3  0  3  6 16  6 14  6  0  0  8  3 11  8  0  3 10  6 15
  6  6  0  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 14. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [ 0.  4. 10.  3.  1.] 
adversary cards in discard: [ 8. 14. 10.  0.  0.  0.  3.  4. 14. 11.  8. 23.  3.  0.  8. 16. 22.  8.] 
adversary owned cards: [15 22 14 10  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29
  3  1  4  0  0 11  0  1 10  3  0 10  0] -> size -> 37 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 3
Learning step: 0.04477620869874954
desired expected reward: 22.06636619567871





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[23.416426]
 [24.419937]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6.] 
cards in discard: [ 0.  6.  6.  3. 16.  0. 14.  3.  6.  3. 11.  8.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 11  8 10  8  3  0  3  6 16  6 14  6  0  0  8  3 11  8  0  3 10  6 15
  6  6  0  0  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 7. 24. 30. 14. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [ 0.  4. 10.  3.  1.] 
adversary cards in discard: [ 8. 14. 10.  0.  0.  0.  3.  4. 14. 11.  8. 23.  3.  0.  8. 16. 22.  8.] 
adversary owned cards: [15 22 14 10  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29
  3  1  4  0  0 11  0  1 10  3  0 10  0] -> size -> 37 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.02758787013590336
desired expected reward: 24.298494338989258



buy possibilites: [-1] 
expected returns: [[18.42684]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6.] 
cards in discard: [ 0.  6.  6.  3. 16.  0. 14.  3.  6.  3. 11.  8.  6.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 11  8 10  8  3  0  3  6 16  6 14  6  0  0  8  3 11  8  0  3 10  6 15
  6  6  0  0  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 24. 30. 14. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [ 0.  4. 10.  3.  1.] 
adversary cards in discard: [ 8. 14. 10.  0.  0.  0.  3.  4. 14. 11.  8. 23.  3.  0.  8. 16. 22.  8.] 
adversary owned cards: [15 22 14 10  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29
  3  1  4  0  0 11  0  1 10  3  0 10  0] -> size -> 37 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: buy - action 0.0
Learning step: -0.05901094153523445
desired expected reward: 23.35741424560547






         -------------------- Turn: 67 -------------------- 
Player: 1 
cards in hand: [ 0.  4. 10.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  4. 10.  3.  1.] 
cards in discard: [ 8. 14. 10.  0.  0.  0.  3.  4. 14. 11.  8. 23.  3.  0.  8. 16. 22.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [15 22 14 10  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29
  3  1  4  0  0 11  0  1 10  3  0 10  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 24. 30. 14. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [ 0.  0.  8. 16. 10.] 
adversary cards in discard: [ 0.  6.  6.  3. 16.  0. 14.  3.  6.  3. 11.  8.  6.  0.  8.  8.  6.] 
adversary owned cards: [16 11  8 10  8  3  0  3  6 16  6 14  6  0  0  8  3 11  8  0  3 10  6 15
  6  6  0  0  0  0] -> size -> 30 
adversary victory points: -2
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  4. 10.  3.  1.] 
cards in discard: [ 8. 14. 10.  0.  0.  0.  3.  4. 14. 11.  8. 23.  3.  0.  8. 16. 22.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [15 22 14 10  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29
  3  1  4  0  0 11  0  1 10  3  0 10  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 24. 30. 14. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [ 0.  0.  8. 16. 10.] 
adversary cards in discard: [ 0.  6.  6.  3. 16.  0. 14.  3.  6.  3. 11.  8.  6.  0.  8.  8.  6.] 
adversary owned cards: [16 11  8 10  8  3  0  3  6 16  6 14  6  0  0  8  3 11  8  0  3 10  6 15
  6  6  0  0  0  0] -> size -> 30 
adversary victory points: -2
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  4. 10.  3.  1.] 
cards in discard: [ 8. 14. 10.  0.  0.  0.  3.  4. 14. 11.  8. 23.  3.  0.  8. 16. 22.  8.
  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [15 22 14 10  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29
  3  1  4  0  0 11  0  1 10  3  0 10  0  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 23. 30. 14. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [ 0.  0.  8. 16. 10.] 
adversary cards in discard: [ 0.  6.  6.  3. 16.  0. 14.  3.  6.  3. 11.  8.  6.  0.  8.  8.  6.] 
adversary owned cards: [16 11  8 10  8  3  0  3  6 16  6 14  6  0  0  8  3 11  8  0  3 10  6 15
  6  6  0  0  0  0] -> size -> 30 
adversary victory points: -2
player victory points: 11 





Player: 0 
cards in hand: [ 0.  0.  8. 16. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 10.] 
expected returns: [[18.616232]
 [18.095318]
 [17.715649]
 [18.074934]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 16. 10.] 
cards in discard: [ 0.  6.  6.  3. 16.  0. 14.  3.  6.  3. 11.  8.  6.  0.  8.  8.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [16 11  8 10  8  3  0  3  6 16  6 14  6  0  0  8  3 11  8  0  3 10  6 15
  6  6  0  0  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 23. 30. 14. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [10.  3.  0.  1. 14.] 
adversary cards in discard: [ 8. 14. 10.  0.  0.  0.  3.  4. 14. 11.  8. 23.  3.  0.  8. 16. 22.  8.
  1.  0.  4. 10.  3.  1.] 
adversary owned cards: [15 22 14 10  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29
  3  1  4  0  0 11  0  1 10  3  0 10  0  1] -> size -> 38 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5114566087722778
desired expected reward: 17.915382385253906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[17.568954]
 [17.800924]
 [18.572466]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 16. 10.] 
cards in discard: [ 0.  6.  6.  3. 16.  0. 14.  3.  6.  3. 11.  8.  6.  0.  8.  8.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [16 11  8 10  8  3  0  3  6 16  6 14  6  0  0  8  3 11  8  0  3 10  6 15
  6  6  0  0  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 23. 30. 14. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [10.  3.  0.  1. 14.] 
adversary cards in discard: [ 8. 14. 10.  0.  0.  0.  3.  4. 14. 11.  8. 23.  3.  0.  8. 16. 22.  8.
  1.  0.  4. 10.  3.  1.] 
adversary owned cards: [15 22 14 10  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29
  3  1  4  0  0 11  0  1 10  3  0 10  0  1] -> size -> 38 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5184462070465088
desired expected reward: 18.09778594970703



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 68 -------------------- 
Player: 1 
cards in hand: [10.  3.  0.  1. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  1. 14.] 
cards in discard: [ 8. 14. 10.  0.  0.  0.  3.  4. 14. 11.  8. 23.  3.  0.  8. 16. 22.  8.
  1.  0.  4. 10.  3.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [15 22 14 10  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29
  3  1  4  0  0 11  0  1 10  3  0 10  0  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 23. 30. 14. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [15.  6. 11.  0.  0.] 
adversary cards in discard: [ 0.  6.  6.  3. 16.  0. 14.  3.  6.  3. 11.  8.  6.  0.  8.  8.  6.  0.
  0.  8. 16. 10.] 
adversary owned cards: [16 11  8 10  8  3  0  3  6 16  6 14  6  0  0  8  3 11  8  0  3 10  6 15
  6  6  0  0  0  0] -> size -> 30 
adversary victory points: -2
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  1. 14.] 
cards in discard: [ 8. 14. 10.  0.  0.  0.  3.  4. 14. 11.  8. 23.  3.  0.  8. 16. 22.  8.
  1.  0.  4. 10.  3.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [15 22 14 10  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29
  3  1  4  0  0 11  0  1 10  3  0 10  0  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 23. 30. 14. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [15.  6. 11.  0.  0.] 
adversary cards in discard: [ 0.  6.  6.  3. 16.  0. 14.  3.  6.  3. 11.  8.  6.  0.  8.  8.  6.  0.
  0.  8. 16. 10.] 
adversary owned cards: [16 11  8 10  8  3  0  3  6 16  6 14  6  0  0  8  3 11  8  0  3 10  6 15
  6  6  0  0  0  0] -> size -> 30 
adversary victory points: -2
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  1. 14.] 
cards in discard: [ 8. 14. 10.  0.  0.  0.  3.  4. 14. 11.  8. 23.  3.  0.  8. 16. 22.  8.
  1.  0.  4. 10.  3.  1.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [15 22 14 10  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29
  3  1  4  0  0 11  0  1 10  3  0 10  0  1  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 23. 30. 13. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [15.  6. 11.  0.  0.] 
adversary cards in discard: [ 0.  6.  6.  3. 16.  0. 14.  3.  6.  3. 11.  8.  6.  0.  8.  8.  6.  0.
  0.  8. 16. 10.] 
adversary owned cards: [16 11  8 10  8  3  0  3  6 16  6 14  6  0  0  8  3 11  8  0  3 10  6 15
  6  6  0  0  0  0] -> size -> 30 
adversary victory points: -2
player victory points: 12 





Player: 0 
cards in hand: [15.  6. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
expected returns: [[21.800257]
 [21.449184]
 [21.51131 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6. 11.  0.  0.] 
cards in discard: [ 0.  6.  6.  3. 16.  0. 14.  3.  6.  3. 11.  8.  6.  0.  8.  8.  6.  0.
  0.  8. 16. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [16 11  8 10  8  3  0  3  6 16  6 14  6  0  0  8  3 11  8  0  3 10  6 15
  6  6  0  0  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 23. 30. 13. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [14.  1. 15. 15.  0.] 
adversary cards in discard: [ 8. 14. 10.  0.  0.  0.  3.  4. 14. 11.  8. 23.  3.  0.  8. 16. 22.  8.
  1.  0.  4. 10.  3.  1.  3. 10.  3.  0.  1. 14.] 
adversary owned cards: [15 22 14 10  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29
  3  1  4  0  0 11  0  1 10  3  0 10  0  1  3] -> size -> 39 
adversary victory points: 12
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.4800633192062378
desired expected reward: 18.092403411865234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[20.866707]
 [21.098677]
 [21.870218]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  6. 11.  0.  0.] 
cards in discard: [ 0.  6.  6.  3. 16.  0. 14.  3.  6.  3. 11.  8.  6.  0.  8.  8.  6.  0.
  0.  8. 16. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [16 11  8 10  8  3  0  3  6 16  6 14  6  0  0  8  3 11  8  0  3 10  6 15
  6  6  0  0  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 23. 30. 13. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [14.  1. 15. 15.  0.] 
adversary cards in discard: [ 8. 14. 10.  0.  0.  0.  3.  4. 14. 11.  8. 23.  3.  0.  8. 16. 22.  8.
  1.  0.  4. 10.  3.  1.  3. 10.  3.  0.  1. 14.] 
adversary owned cards: [15 22 14 10  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29
  3  1  4  0  0 11  0  1 10  3  0 10  0  1  3] -> size -> 39 
adversary victory points: 12
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5793405175209045
desired expected reward: 21.220916748046875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 69 -------------------- 
Player: 1 
cards in hand: [14.  1. 15. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  1. 15. 15.  0.] 
cards in discard: [ 8. 14. 10.  0.  0.  0.  3.  4. 14. 11.  8. 23.  3.  0.  8. 16. 22.  8.
  1.  0.  4. 10.  3.  1.  3. 10.  3.  0.  1. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [15 22 14 10  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29
  3  1  4  0  0 11  0  1 10  3  0 10  0  1  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 23. 30. 13. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [ 3.  6.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [16 11  8 10  8  3  0  3  6 16  6 14  6  0  0  8  3 11  8  0  3 10  6 15
  6  6  0  0  0  0] -> size -> 30 
adversary victory points: -2
player victory points: 12 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  1. 15. 15.  0.] 
cards in discard: [ 8. 14. 10.  0.  0.  0.  3.  4. 14. 11.  8. 23.  3.  0.  8. 16. 22.  8.
  1.  0.  4. 10.  3.  1.  3. 10.  3.  0.  1. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [15 22 14 10  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29
  3  1  4  0  0 11  0  1 10  3  0 10  0  1  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 23. 30. 13. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [ 3.  6.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [16 11  8 10  8  3  0  3  6 16  6 14  6  0  0  8  3 11  8  0  3 10  6 15
  6  6  0  0  0  0] -> size -> 30 
adversary victory points: -2
player victory points: 12 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  1. 15. 15.  0.] 
cards in discard: [ 8. 14. 10.  0.  0.  0.  3.  4. 14. 11.  8. 23.  3.  0.  8. 16. 22.  8.
  1.  0.  4. 10.  3.  1.  3. 10.  3.  0.  1. 14.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [15 22 14 10  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29
  3  1  4  0  0 11  0  1 10  3  0 10  0  1  3  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 23. 30. 12. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [ 3.  6.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [16 11  8 10  8  3  0  3  6 16  6 14  6  0  0  8  3 11  8  0  3 10  6 15
  6  6  0  0  0  0] -> size -> 30 
adversary victory points: -2
player victory points: 13 





Player: 0 
cards in hand: [ 3.  6.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[20.643541]
 [20.102245]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  0. 10.  3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [16 11  8 10  8  3  0  3  6 16  6 14  6  0  0  8  3 11  8  0  3 10  6 15
  6  6  0  0  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 23. 30. 12. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [ 3.  3.  1.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [15 22 14 10  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29
  3  1  4  0  0 11  0  1 10  3  0 10  0  1  3  3] -> size -> 40 
adversary victory points: 13
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5916227698326111
desired expected reward: 21.278594970703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[19.681116]
 [20.68463 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  0. 10.  3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [16 11  8 10  8  3  0  3  6 16  6 14  6  0  0  8  3 11  8  0  3 10  6 15
  6  6  0  0  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 23. 30. 12. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [ 3.  3.  1.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [15 22 14 10  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29
  3  1  4  0  0 11  0  1 10  3  0 10  0  1  3  3] -> size -> 40 
adversary victory points: 13
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5563324093818665
desired expected reward: 20.08721160888672



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 70 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  1.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  1.  0. 29.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [15 22 14 10  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29
  3  1  4  0  0 11  0  1 10  3  0 10  0  1  3  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 23. 30. 12. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [0. 6. 6. 0. 6.] 
adversary cards in discard: [ 3.  6.  0. 10.  3.] 
adversary owned cards: [16 11  8 10  8  3  0  3  6 16  6 14  6  0  0  8  3 11  8  0  3 10  6 15
  6  6  0  0  0  0] -> size -> 30 
adversary victory points: -2
player victory points: 13 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 1.] 
cards in discard: [3. 3.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29.] 
owned cards: [15 22 14 10  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29
  3  1  4  0  0 11  0  1 10  3  0 10  0  1  3  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 6. 23. 30. 12. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [0. 6. 6. 0. 6.] 
adversary cards in discard: [ 3.  6.  0. 10.  3.] 
adversary owned cards: [16 11  8 10  8  3  0  3  6 16  6 14  6  0  0  8  3 11  8  0  3 10  6 15
  6  6  0  0  0  0] -> size -> 30 
adversary victory points: -2
player victory points: 13 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1.] 
cards in discard: [3. 3.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29.] 
owned cards: [15 22 14 10  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29
  3  1  4  0  0 11  0  1 10  3  0 10  0  1  3  3] -> size -> 40 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 6. 23. 30. 12. 27.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [0. 6. 6. 0. 6.] 
adversary cards in discard: [ 3.  6.  0. 10.  3.] 
adversary owned cards: [16 11  8 10  8  3  0  3  6 16  6 14  6  0  0  8  3 11  8  0  3 10  6 15
  6  6  0  0  0  0] -> size -> 30 
adversary victory points: -2
player victory points: 13 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1.] 
cards in discard: [3. 3. 4.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29.] 
owned cards: [15 22 14 10  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29
  3  1  4  0  0 11  0  1 10  3  0 10  0  1  3  3  4] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 23. 30. 12. 26.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [0. 6. 6. 0. 6.] 
adversary cards in discard: [ 3.  6.  0. 10.  3.] 
adversary owned cards: [16 11  8 10  8  3  0  3  6 16  6 14  6  0  0  8  3 11  8  0  3 10  6 15
  6  6  0  0  0  0] -> size -> 30 
adversary victory points: -2
player victory points: 16 





Player: 0 
cards in hand: [0. 6. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[20.317493]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 0. 6.] 
cards in discard: [ 3.  6.  0. 10.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [16 11  8 10  8  3  0  3  6 16  6 14  6  0  0  8  3 11  8  0  3 10  6 15
  6  6  0  0  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 23. 30. 12. 26.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [ 4. 14.  0.  3.  0.] 
adversary cards in discard: [ 3.  3.  4. 29.  1.  0.  1.] 
adversary owned cards: [15 22 14 10  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29
  3  1  4  0  0 11  0  1 10  3  0 10  0  1  3  3  4] -> size -> 41 
adversary victory points: 16
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5572051405906677
desired expected reward: 20.127424240112305





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[18.93276 ]
 [19.162289]
 [19.923641]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0. 6.] 
cards in discard: [ 3.  6.  0. 10.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [16 11  8 10  8  3  0  3  6 16  6 14  6  0  0  8  3 11  8  0  3 10  6 15
  6  6  0  0  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 23. 30. 12. 26.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [ 4. 14.  0.  3.  0.] 
adversary cards in discard: [ 3.  3.  4. 29.  1.  0.  1.] 
adversary owned cards: [15 22 14 10  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29
  3  1  4  0  0 11  0  1 10  3  0 10  0  1  3  3  4] -> size -> 41 
adversary victory points: 16
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5406139492988586
desired expected reward: 19.28958511352539



buy possibilites: [-1] 
expected returns: [[21.26786]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0. 6.] 
cards in discard: [ 3.  6.  0. 10.  3.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [16 11  8 10  8  3  0  3  6 16  6 14  6  0  0  8  3 11  8  0  3 10  6 15
  6  6  0  0  0  0  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 5. 23. 30. 12. 26.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [ 4. 14.  0.  3.  0.] 
adversary cards in discard: [ 3.  3.  4. 29.  1.  0.  1.] 
adversary owned cards: [15 22 14 10  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29
  3  1  4  0  0 11  0  1 10  3  0 10  0  1  3  3  4] -> size -> 41 
adversary victory points: 16
player victory points: -2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.4946702718734741
desired expected reward: 18.43808937072754






         -------------------- Turn: 71 -------------------- 
Player: 1 
cards in hand: [ 4. 14.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4. 14.  0.  3.  0.] 
cards in discard: [ 3.  3.  4. 29.  1.  0.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [15 22 14 10  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29
  3  1  4  0  0 11  0  1 10  3  0 10  0  1  3  3  4] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 23. 30. 12. 26.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [15.  8.  3.  6.  0.] 
adversary cards in discard: [ 3.  6.  0. 10.  3.  0.  0.  6.  6.  0.  6.] 
adversary owned cards: [16 11  8 10  8  3  0  3  6 16  6 14  6  0  0  8  3 11  8  0  3 10  6 15
  6  6  0  0  0  0  0] -> size -> 31 
adversary victory points: -2
player victory points: 16 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4. 14.  0.  3.  0.] 
cards in discard: [ 3.  3.  4. 29.  1.  0.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [15 22 14 10  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29
  3  1  4  0  0 11  0  1 10  3  0 10  0  1  3  3  4] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 23. 30. 12. 26.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [15.  8.  3.  6.  0.] 
adversary cards in discard: [ 3.  6.  0. 10.  3.  0.  0.  6.  6.  0.  6.] 
adversary owned cards: [16 11  8 10  8  3  0  3  6 16  6 14  6  0  0  8  3 11  8  0  3 10  6 15
  6  6  0  0  0  0  0] -> size -> 31 
adversary victory points: -2
player victory points: 16 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4. 14.  0.  3.  0.] 
cards in discard: [ 3.  3.  4. 29.  1.  0.  1.  3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [15 22 14 10  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29
  3  1  4  0  0 11  0  1 10  3  0 10  0  1  3  3  4  3] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 23. 30. 11. 26.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [15.  8.  3.  6.  0.] 
adversary cards in discard: [ 3.  6.  0. 10.  3.  0.  0.  6.  6.  0.  6.] 
adversary owned cards: [16 11  8 10  8  3  0  3  6 16  6 14  6  0  0  8  3 11  8  0  3 10  6 15
  6  6  0  0  0  0  0] -> size -> 31 
adversary victory points: -2
player victory points: 17 





Player: 0 
cards in hand: [15.  8.  3.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[18.40148 ]
 [18.056095]
 [17.889797]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  3.  6.  0.] 
cards in discard: [ 3.  6.  0. 10.  3.  0.  0.  6.  6.  0.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [16 11  8 10  8  3  0  3  6 16  6 14  6  0  0  8  3 11  8  0  3 10  6 15
  6  6  0  0  0  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 23. 30. 11. 26.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [14. 16.  0.  8.  1.] 
adversary cards in discard: [ 3.  3.  4. 29.  1.  0.  1.  3.  4. 14.  0.  3.  0.] 
adversary owned cards: [15 22 14 10  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29
  3  1  4  0  0 11  0  1 10  3  0 10  0  1  3  3  4  3] -> size -> 42 
adversary victory points: 17
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5972200632095337
desired expected reward: 20.67064094543457



action possibilites: [-1] 
expected returns: [[20.897501]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.] 
cards in discard: [ 3.  6.  0. 10.  3.  0.  0.  6.  6.  0.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 11  8 10  8  0  3 16  6 14  6  0  0  8  3 11  8  0  3 10  6 15  6  6
  0  0  0  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 23. 30. 11. 26.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [14. 16.  0.  8.  1.] 
adversary cards in discard: [ 3.  3.  4. 29.  1.  0.  1.  3.  4. 14.  0.  3.  0.] 
adversary owned cards: [15 22 14 10  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29
  3  1  4  0  0 11  0  1 10  3  0 10  0  1  3  3  4  3] -> size -> 42 
adversary victory points: 17
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 9
Learning step: 0.1282501071691513
desired expected reward: 18.16737174987793





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[20.122433]
 [21.113314]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.] 
cards in discard: [ 3.  6.  0. 10.  3.  0.  0.  6.  6.  0.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 11  8 10  8  0  3 16  6 14  6  0  0  8  3 11  8  0  3 10  6 15  6  6
  0  0  0  0  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 23. 30. 11. 26.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [14. 16.  0.  8.  1.] 
adversary cards in discard: [ 3.  3.  4. 29.  1.  0.  1.  3.  4. 14.  0.  3.  0.] 
adversary owned cards: [15 22 14 10  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29
  3  1  4  0  0 11  0  1 10  3  0 10  0  1  3  3  4  3] -> size -> 42 
adversary victory points: 17
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.04060306400060654
desired expected reward: 20.9381046295166



buy possibilites: [-1] 
expected returns: [[25.104832]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.] 
cards in discard: [ 3.  6.  0. 10.  3.  0.  0.  6.  6.  0.  6.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 11  8 10  8  0  3 16  6 14  6  0  0  8  3 11  8  0  3 10  6 15  6  6
  0  0  0  0  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 23. 30. 11. 26.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [14. 16.  0.  8.  1.] 
adversary cards in discard: [ 3.  3.  4. 29.  1.  0.  1.  3.  4. 14.  0.  3.  0.] 
adversary owned cards: [15 22 14 10  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29
  3  1  4  0  0 11  0  1 10  3  0 10  0  1  3  3  4  3] -> size -> 42 
adversary victory points: 17
player victory points: -2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: 0.1099277064204216
desired expected reward: 20.23236083984375






         -------------------- Turn: 72 -------------------- 
Player: 1 
cards in hand: [14. 16.  0.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 16.  0.  8.  1.] 
cards in discard: [ 3.  3.  4. 29.  1.  0.  1.  3.  4. 14.  0.  3.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [15 22 14 10  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29
  3  1  4  0  0 11  0  1 10  3  0 10  0  1  3  3  4  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 23. 30. 11. 26.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [ 6.  0. 10.  8.  0.] 
adversary cards in discard: [ 3.  6.  0. 10.  3.  0.  0.  6.  6.  0.  6.  0.  8. 15.  0.] 
adversary owned cards: [16 11  8 10  8  0  3 16  6 14  6  0  0  8  3 11  8  0  3 10  6 15  6  6
  0  0  0  0  0  0] -> size -> 30 
adversary victory points: -2
player victory points: 17 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  8.  1.] 
cards in discard: [ 3.  3.  4. 29.  1.  0.  1.  3.  4. 14.  0.  3.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [14.] 
owned cards: [15 22 14 10  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29
  3  1  4  0  0 11  0  1 10  3  0 10  0  1  3  3  4  3] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 23. 30. 11. 26.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [6. 8. 0.] 
adversary cards in discard: [ 3.  6.  0. 10.  3.  0.  0.  6.  6.  0.  6.  0.  8. 15.  0. 10.  0.] 
adversary owned cards: [16 11  8 10  8  0  3 16  6 14  6  0  0  8  3 11  8  0  3 10  6 15  6  6
  0  0  0  0  0  0] -> size -> 30 
adversary victory points: -2
player victory points: 17 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  8.  1.] 
cards in discard: [ 3.  3.  4. 29.  1.  0.  1.  3.  4. 14.  0.  3.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [14.] 
owned cards: [15 22 14 10  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29
  3  1  4  0  0 11  0  1 10  3  0 10  0  1  3  3  4  3] -> size -> 42 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 4. 23. 30. 11. 26.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  7.] 
adversary cards in hand: [6. 8. 0.] 
adversary cards in discard: [ 3.  6.  0. 10.  3.  0.  0.  6.  6.  0.  6.  0.  8. 15.  0. 10.  0.] 
adversary owned cards: [16 11  8 10  8  0  3 16  6 14  6  0  0  8  3 11  8  0  3 10  6 15  6  6
  0  0  0  0  0  0] -> size -> 30 
adversary victory points: -2
player victory points: 17 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  8.  1.] 
cards in discard: [ 3.  3.  4. 29.  1.  0.  1.  3.  4. 14.  0.  3.  0. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [14.] 
owned cards: [15 22 14 10  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29
  3  1  4  0  0 11  0  1 10  3  0 10  0  1  3  3  4  3 15] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 23. 30. 11. 26.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  6.] 
adversary cards in hand: [6. 8. 0.] 
adversary cards in discard: [ 3.  6.  0. 10.  3.  0.  0.  6.  6.  0.  6.  0.  8. 15.  0. 10.  0.] 
adversary owned cards: [16 11  8 10  8  0  3 16  6 14  6  0  0  8  3 11  8  0  3 10  6 15  6  6
  0  0  0  0  0  0] -> size -> 30 
adversary victory points: -2
player victory points: 17 





Player: 0 
cards in hand: [6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[22.938677]
 [22.42699 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0.] 
cards in discard: [ 3.  6.  0. 10.  3.  0.  0.  6.  6.  0.  6.  0.  8. 15.  0. 10.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [16 11  8 10  8  0  3 16  6 14  6  0  0  8  3 11  8  0  3 10  6 15  6  6
  0  0  0  0  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 23. 30. 11. 26.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  6.] 
adversary cards in hand: [ 3. 15. 22. 10.  8.] 
adversary cards in discard: [ 3.  3.  4. 29.  1.  0.  1.  3.  4. 14.  0.  3.  0. 15. 14. 16.  0.  8.
  1.] 
adversary owned cards: [15 22 14 10  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29
  3  1  4  0  0 11  0  1 10  3  0 10  0  1  3  3  4  3 15] -> size -> 43 
adversary victory points: 17
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 5
Learning step: -0.5719214081764221
desired expected reward: 21.449026107788086



action possibilites: [-1] 
expected returns: [[23.476877]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 3.  6.  0. 10.  3.  0.  0.  6.  6.  0.  6.  0.  8. 15.  0. 10.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 11  8 10  8  3 16 14  6  0  0  8  3 11  8  0  3 10  6 15  6  6  0  0
  0  0  0  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 23. 30. 11. 26.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  6.] 
adversary cards in hand: [ 3. 15. 22. 10.  8.] 
adversary cards in discard: [ 3.  3.  4. 29.  1.  0.  1.  3.  4. 14.  0.  3.  0. 15. 14. 16.  0.  8.
  1.] 
adversary owned cards: [15 22 14 10  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29
  3  1  4  0  0 11  0  1 10  3  0 10  0  1  3  3  4  3 15] -> size -> 43 
adversary victory points: 17
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 2
Learning step: 0.03600877523422241
desired expected reward: 22.052623748779297





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[22.503485]
 [23.494364]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3.  6.  0. 10.  3.  0.  0.  6.  6.  0.  6.  0.  8. 15.  0. 10.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 11  8 10  8  3 16 14  6  0  0  8  3 11  8  0  3 10  6 15  6  6  0  0
  0  0  0  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 4. 23. 30. 11. 26.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  6.] 
adversary cards in hand: [ 3. 15. 22. 10.  8.] 
adversary cards in discard: [ 3.  3.  4. 29.  1.  0.  1.  3.  4. 14.  0.  3.  0. 15. 14. 16.  0.  8.
  1.] 
adversary owned cards: [15 22 14 10  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29
  3  1  4  0  0 11  0  1 10  3  0 10  0  1  3  3  4  3 15] -> size -> 43 
adversary victory points: 17
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.011777171865105629
desired expected reward: 23.465099334716797



buy possibilites: [-1] 
expected returns: [[19.22803]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3.  6.  0. 10.  3.  0.  0.  6.  6.  0.  6.  0.  8. 15.  0. 10.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 11  8 10  8  3 16 14  6  0  0  8  3 11  8  0  3 10  6 15  6  6  0  0
  0  0  0  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 23. 30. 11. 26.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  6.] 
adversary cards in hand: [ 3. 15. 22. 10.  8.] 
adversary cards in discard: [ 3.  3.  4. 29.  1.  0.  1.  3.  4. 14.  0.  3.  0. 15. 14. 16.  0.  8.
  1.] 
adversary owned cards: [15 22 14 10  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29
  3  1  4  0  0 11  0  1 10  3  0 10  0  1  3  3  4  3 15] -> size -> 43 
adversary victory points: 17
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: buy - action 0.0
Learning step: -0.02321022003889084
desired expected reward: 22.480274200439453






         -------------------- Turn: 73 -------------------- 
Player: 1 
cards in hand: [ 3. 15. 22. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 22. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 22. 10.  8.] 
cards in discard: [ 3.  3.  4. 29.  1.  0.  1.  3.  4. 14.  0.  3.  0. 15. 14. 16.  0.  8.
  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [15 22 14 10  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29
  3  1  4  0  0 11  0  1 10  3  0 10  0  1  3  3  4  3 15] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 23. 30. 11. 26.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  6.] 
adversary cards in hand: [16. 16.  3. 11. 14.] 
adversary cards in discard: [ 3.  6.  0. 10.  3.  0.  0.  6.  6.  0.  6.  0.  8. 15.  0. 10.  0.  0.
  8.] 
adversary owned cards: [16 11  8 10  8  3 16 14  6  0  0  8  3 11  8  0  3 10  6 15  6  6  0  0
  0  0  0  0  0] -> size -> 29 
adversary victory points: -1
player victory points: 17 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.] 
cards in discard: [ 3.  3.  4. 29.  1.  0.  1.  3.  4. 14.  0.  3.  0. 15. 14. 16.  0.  8.
  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [15 14  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29  3  1
  4  0  0 11  0  1 10  3  0 10  0  1  3  3  4  3 15] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 23. 30. 11. 26.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  6.] 
adversary cards in hand: [16. 16.  3. 11. 14.] 
adversary cards in discard: [ 3.  6.  0. 10.  3.  0.  0.  6.  6.  0.  6.  0.  8. 15.  0. 10.  0.  0.
  8.] 
adversary owned cards: [16 11  8 10  8  3 16 14  6  0  0  8  3 11  8  0  3 10  6 15  6  6  0  0
  0  0  0  0  0] -> size -> 29 
adversary victory points: -1
player victory points: 17 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.] 
cards in discard: [ 3.  3.  4. 29.  1.  0.  1.  3.  4. 14.  0.  3.  0. 15. 14. 16.  0.  8.
  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [15 14  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29  3  1
  4  0  0 11  0  1 10  3  0 10  0  1  3  3  4  3 15] -> size -> 41 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 3. 23. 30. 11. 26.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  6.] 
adversary cards in hand: [16. 16.  3. 11. 14.] 
adversary cards in discard: [ 3.  6.  0. 10.  3.  0.  0.  6.  6.  0.  6.  0.  8. 15.  0. 10.  0.  0.
  8.] 
adversary owned cards: [16 11  8 10  8  3 16 14  6  0  0  8  3 11  8  0  3 10  6 15  6  6  0  0
  0  0  0  0  0] -> size -> 29 
adversary victory points: -1
player victory points: 17 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.] 
cards in discard: [ 3.  3.  4. 29.  1.  0.  1.  3.  4. 14.  0.  3.  0. 15. 14. 16.  0.  8.
  1.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [15 14  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29  3  1
  4  0  0 11  0  1 10  3  0 10  0  1  3  3  4  3 15  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 23. 30. 11. 26.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  6.] 
adversary cards in hand: [16. 16.  3. 11. 14.] 
adversary cards in discard: [ 3.  6.  0. 10.  3.  0.  0.  6.  6.  0.  6.  0.  8. 15.  0. 10.  0.  0.
  8.] 
adversary owned cards: [16 11  8 10  8  3 16 14  6  0  0  8  3 11  8  0  3 10  6 15  6  6  0  0
  0  0  0  0  0] -> size -> 29 
adversary victory points: -1
player victory points: 17 





Player: 0 
cards in hand: [16. 16.  3. 11. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16. 11. 14.] 
expected returns: [[19.833462]
 [18.943884]
 [18.943884]
 [19.551302]
 [19.237621]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 16.  3. 11. 14.] 
cards in discard: [ 3.  6.  0. 10.  3.  0.  0.  6.  6.  0.  6.  0.  8. 15.  0. 10.  0.  0.
  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [16 11  8 10  8  3 16 14  6  0  0  8  3 11  8  0  3 10  6 15  6  6  0  0
  0  0  0  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 23. 30. 11. 26.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  6.] 
adversary cards in hand: [ 1.  0. 14. 23.  3.] 
adversary cards in discard: [ 3.  3.  4. 29.  1.  0.  1.  3.  4. 14.  0.  3.  0. 15. 14. 16.  0.  8.
  1.  0.  8.  3. 15.] 
adversary owned cards: [15 14  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29  3  1
  4  0  0 11  0  1 10  3  0 10  0  1  3  3  4  3 15  0] -> size -> 42 
adversary victory points: 17
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5230535268783569
desired expected reward: 18.704975128173828



action possibilites: [-1] 
expected returns: [[18.53819]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 16.  3. 14.] 
cards in discard: [ 3.  6.  0. 10.  3.  0.  0.  6.  6.  0.  6.  0.  8. 15.  0. 10.  0.  0.
  8.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [16 11  8 10  8  3 16 14  6  0  0  8  3 11  8  0  3 10  6 15  6  6  0  0
  0  0  0  0  0  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 22. 30. 11. 26.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  6.] 
adversary cards in hand: [ 1.  0. 14. 23.  3.] 
adversary cards in discard: [ 3.  3.  4. 29.  1.  0.  1.  3.  4. 14.  0.  3.  0. 15. 14. 16.  0.  8.
  1.  0.  8.  3. 15.] 
adversary owned cards: [15 14  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29  3  1
  4  0  0 11  0  1 10  3  0 10  0  1  3  3  4  3 15  0] -> size -> 42 
adversary victory points: 17
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 1
Learning step: 0.3444764316082001
desired expected reward: 19.437511444091797





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[17.602142]
 [18.588428]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 16.  3. 14.] 
cards in discard: [ 3.  6.  0. 10.  3.  0.  0.  6.  6.  0.  6.  0.  8. 15.  0. 10.  0.  0.
  8.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [16 11  8 10  8  3 16 14  6  0  0  8  3 11  8  0  3 10  6 15  6  6  0  0
  0  0  0  0  0  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 2. 22. 30. 11. 26.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  6.] 
adversary cards in hand: [ 1.  0. 14. 23.  3.] 
adversary cards in discard: [ 3.  3.  4. 29.  1.  0.  1.  3.  4. 14.  0.  3.  0. 15. 14. 16.  0.  8.
  1.  0.  8.  3. 15.] 
adversary owned cards: [15 14  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29  3  1
  4  0  0 11  0  1 10  3  0 10  0  1  3  3  4  3 15  0] -> size -> 42 
adversary victory points: 17
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.08489038050174713
desired expected reward: 18.62308120727539






         -------------------- Turn: 74 -------------------- 
Player: 1 
cards in hand: [ 1.  0. 14. 23.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 14. 23.  3.] 
cards in discard: [ 3.  3.  4. 29.  1.  0.  1.  3.  4. 14.  0.  3.  0. 15. 14. 16.  0.  8.
  1.  0.  8.  3. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [15 14  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29  3  1
  4  0  0 11  0  1 10  3  0 10  0  1  3  3  4  3 15  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 22. 30. 11. 26.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  6.] 
adversary cards in hand: [ 0. 11.  0.  8.  8.] 
adversary cards in discard: [ 3.  6.  0. 10.  3.  0.  0.  6.  6.  0.  6.  0.  8. 15.  0. 10.  0.  0.
  8.  1. 11. 16. 16.  3. 14.] 
adversary owned cards: [16 11  8 10  8  3 16 14  6  0  0  8  3 11  8  0  3 10  6 15  6  6  0  0
  0  0  0  0  0  1] -> size -> 30 
adversary victory points: -1
player victory points: 17 


action possibilites: [-1. 14. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 14.  3. 15.] 
cards in discard: [ 3.  3.  4. 29.  1.  0.  1.  3.  4. 14.  0.  3.  0. 15. 14. 16.  0.  8.
  1.  0.  8.  3. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [23.] 
owned cards: [15 14  8  1  1 14  0 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29  3  1
  4  0  0 11  0  1 10  3  0 10  0  1  3  3  4  3 15  0] -> size -> 42 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 2. 22. 30. 11. 26.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  6.] 
adversary cards in hand: [ 0. 11.  0.  8.  8.] 
adversary cards in discard: [ 3.  6.  0. 10.  3.  0.  0.  6.  6.  0.  6.  0.  8. 15.  0. 10.  0.  0.
  8.  1. 11. 16. 16.  3. 14.] 
adversary owned cards: [16 11  8 10  8  3 16 14  6  0  0  8  3 11  8  0  3 10  6 15  6  6  0  0
  0  0  0  0  0  1] -> size -> 30 
adversary victory points: -1
player victory points: 17 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 14.  3.] 
cards in discard: [ 3.  3.  4. 29.  1.  0.  1.  3.  4. 14.  0.  3.  0. 15. 14. 16.  0.  8.
  1.  0.  8.  3. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [23. 15.] 
owned cards: [15 14  8  1  1 14 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29  3  1  4
  0  0 11  0  1 10  3  0 10  0  1  3  3  4  3 15  0] -> size -> 41 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 2. 22. 30. 11. 26.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  6.] 
adversary cards in hand: [ 0. 11.  0.  8.  8.] 
adversary cards in discard: [ 3.  6.  0. 10.  3.  0.  0.  6.  6.  0.  6.  0.  8. 15.  0. 10.  0.  0.
  8.  1. 11. 16. 16.  3. 14.] 
adversary owned cards: [16 11  8 10  8  3 16 14  6  0  0  8  3 11  8  0  3 10  6 15  6  6  0  0
  0  0  0  0  0  1] -> size -> 30 
adversary victory points: -1
player victory points: 17 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 14.  3.] 
cards in discard: [ 3.  3.  4. 29.  1.  0.  1.  3.  4. 14.  0.  3.  0. 15. 14. 16.  0.  8.
  1.  0.  8.  3. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [23. 15.] 
owned cards: [15 14  8  1  1 14 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29  3  1  4
  0  0 11  0  1 10  3  0 10  0  1  3  3  4  3 15  0] -> size -> 41 
action values: 0 
buys: 2 
player value: 6 
card supply: [ 2. 22. 30. 11. 26.  8.  0.  7.  3.  0. 10.  8.  4.  9.  3.  9.  6.] 
adversary cards in hand: [ 0. 11.  0.  8.  8.] 
adversary cards in discard: [ 3.  6.  0. 10.  3.  0.  0.  6.  6.  0.  6.  0.  8. 15.  0. 10.  0.  0.
  8.  1. 11. 16. 16.  3. 14.] 
adversary owned cards: [16 11  8 10  8  3 16 14  6  0  0  8  3 11  8  0  3 10  6 15  6  6  0  0
  0  0  0  0  0  1] -> size -> 30 
adversary victory points: -1
player victory points: 17 


buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 14.  3.] 
cards in discard: [ 3.  3.  4. 29.  1.  0.  1.  3.  4. 14.  0.  3.  0. 15. 14. 16.  0.  8.
  1.  0.  8.  3. 15. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [23. 15.] 
owned cards: [15 14  8  1  1 14 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29  3  1  4
  0  0 11  0  1 10  3  0 10  0  1  3  3  4  3 15  0 10] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 22. 30. 11. 26.  8.  0.  7.  3.  0. 10.  8.  4.  9.  2.  9.  6.] 
adversary cards in hand: [ 0. 11.  0.  8.  8.] 
adversary cards in discard: [ 3.  6.  0. 10.  3.  0.  0.  6.  6.  0.  6.  0.  8. 15.  0. 10.  0.  0.
  8.  1. 11. 16. 16.  3. 14.] 
adversary owned cards: [16 11  8 10  8  3 16 14  6  0  0  8  3 11  8  0  3 10  6 15  6  6  0  0
  0  0  0  0  0  1] -> size -> 30 
adversary victory points: -1
player victory points: 17 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 14.  3.] 
cards in discard: [ 3.  3.  4. 29.  1.  0.  1.  3.  4. 14.  0.  3.  0. 15. 14. 16.  0.  8.
  1.  0.  8.  3. 15. 10.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [23. 15.] 
owned cards: [15 14  8  1  1 14 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29  3  1  4
  0  0 11  0  1 10  3  0 10  0  1  3  3  4  3 15  0 10  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 1. 22. 30. 11. 26.  8.  0.  7.  3.  0. 10.  8.  4.  9.  2.  9.  6.] 
adversary cards in hand: [ 0. 11.  0.  8.  8.] 
adversary cards in discard: [ 3.  6.  0. 10.  3.  0.  0.  6.  6.  0.  6.  0.  8. 15.  0. 10.  0.  0.
  8.  1. 11. 16. 16.  3. 14.] 
adversary owned cards: [16 11  8 10  8  3 16 14  6  0  0  8  3 11  8  0  3 10  6 15  6  6  0  0
  0  0  0  0  0  1] -> size -> 30 
adversary victory points: -1
player victory points: 17 





Player: 0 
cards in hand: [ 0. 11.  0.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8.] 
expected returns: [[20.626421]
 [20.347387]
 [20.118366]
 [20.118366]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  8.  8.] 
cards in discard: [ 3.  6.  0. 10.  3.  0.  0.  6.  6.  0.  6.  0.  8. 15.  0. 10.  0.  0.
  8.  1. 11. 16. 16.  3. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [16 11  8 10  8  3 16 14  6  0  0  8  3 11  8  0  3 10  6 15  6  6  0  0
  0  0  0  0  0  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 22. 30. 11. 26.  8.  0.  7.  3.  0. 10.  8.  4.  9.  2.  9.  6.] 
adversary cards in hand: [ 4. 11. 14.  3. 10.] 
adversary cards in discard: [ 3.  3.  4. 29.  1.  0.  1.  3.  4. 14.  0.  3.  0. 15. 14. 16.  0.  8.
  1.  0.  8.  3. 15. 10.  0. 23. 15.  1. 14.  3.] 
adversary owned cards: [15 14  8  1  1 14 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29  3  1  4
  0  0 11  0  1 10  3  0 10  0  1  3  3  4  3 15  0 10  0] -> size -> 43 
adversary victory points: 17
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.4937952160835266
desired expected reward: 18.094633102416992





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[19.586771]
 [19.815792]
 [20.573057]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  8.  8.] 
cards in discard: [ 3.  6.  0. 10.  3.  0.  0.  6.  6.  0.  6.  0.  8. 15.  0. 10.  0.  0.
  8.  1. 11. 16. 16.  3. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [16 11  8 10  8  3 16 14  6  0  0  8  3 11  8  0  3 10  6 15  6  6  0  0
  0  0  0  0  0  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 22. 30. 11. 26.  8.  0.  7.  3.  0. 10.  8.  4.  9.  2.  9.  6.] 
adversary cards in hand: [ 4. 11. 14.  3. 10.] 
adversary cards in discard: [ 3.  3.  4. 29.  1.  0.  1.  3.  4. 14.  0.  3.  0. 15. 14. 16.  0.  8.
  1.  0.  8.  3. 15. 10.  0. 23. 15.  1. 14.  3.] 
adversary owned cards: [15 14  8  1  1 14 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29  3  1  4
  0  0 11  0  1 10  3  0 10  0  1  3  3  4  3 15  0 10  0] -> size -> 43 
adversary victory points: 17
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5576574802398682
desired expected reward: 20.06876564025879



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 75 -------------------- 
Player: 1 
cards in hand: [ 4. 11. 14.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4. 11. 14.  3. 10.] 
cards in discard: [ 3.  3.  4. 29.  1.  0.  1.  3.  4. 14.  0.  3.  0. 15. 14. 16.  0.  8.
  1.  0.  8.  3. 15. 10.  0. 23. 15.  1. 14.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [15 14  8  1  1 14 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29  3  1  4
  0  0 11  0  1 10  3  0 10  0  1  3  3  4  3 15  0 10  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 22. 30. 11. 26.  8.  0.  7.  3.  0. 10.  8.  4.  9.  2.  9.  6.] 
adversary cards in hand: [ 8.  8.  6.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [16 11  8 10  8  3 16 14  6  0  0  8  3 11  8  0  3 10  6 15  6  6  0  0
  0  0  0  0  0  1] -> size -> 30 
adversary victory points: -1
player victory points: 17 


action possibilites: [-1. 11. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4. 11. 14.  3.  8.] 
cards in discard: [ 3.  3.  4. 29.  1.  0.  1.  3.  4. 14.  0.  3.  0. 15. 14. 16.  0.  8.
  1.  0.  8.  3. 15. 10.  0. 23. 15.  1. 14.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [15 14  8  1  1 14 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29  3  1  4
  0  0 11  0  1 10  3  0 10  0  1  3  3  4  3 15  0 10  0] -> size -> 43 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 1. 22. 30. 11. 26.  8.  0.  7.  3.  0. 10.  8.  4.  9.  2.  9.  6.] 
adversary cards in hand: [ 8.  8.  6.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [16 11  8 10  8  3 16 14  6  0  0  8  3 11  8  0  3 10  6 15  6  6  0  0
  0  0  0  0  0  1] -> size -> 30 
adversary victory points: -1
player victory points: 17 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4. 11. 14.  3.  8.] 
cards in discard: [ 3.  3.  4. 29.  1.  0.  1.  3.  4. 14.  0.  3.  0. 15. 14. 16.  0.  8.
  1.  0.  8.  3. 15. 10.  0. 23. 15.  1. 14.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [15 14  8  1  1 14 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29  3  1  4
  0  0 11  0  1 10  3  0 10  0  1  3  3  4  3 15  0 10  0] -> size -> 43 
action values: 2 
buys: 1 
player value: 0 
card supply: [ 1. 22. 30. 11. 26.  8.  0.  7.  3.  0. 10.  8.  4.  9.  2.  9.  6.] 
adversary cards in hand: [ 8.  8.  6.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [16 11  8 10  8  3 16 14  6  0  0  8  3 11  8  0  3 10  6 15  6  6  0  0
  0  0  0  0  0  1] -> size -> 30 
adversary victory points: -1
player victory points: 17 


Player 1 won the game! 



Player 0 bought cards:
Copper: 14 
Silver: 0 
Gold: 0 
Estate: 6 
Duchy: 0 
Province: 0 
Curse: 9 

Remodel: 1 
Workshop: 2 
Chapel: 4 
Witch: 0 
Poacher: 0 
Militia: 0 
Market: 0 
Village: 4 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 8.  8.  6.  1. 10.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [16 11  8 10  8  3 16 14  6  0  0  8  3 11  8  0  3 10  6 15  6  6  0  0
  0  0  0  0  0  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 22. 30. 11. 26.  8.  0.  7.  3.  0. 10.  8.  4.  9.  2.  9.  6.] 
adversary cards in hand: [ 4. 11. 14.  3.  8.] 
adversary cards in discard: [ 3.  3.  4. 29.  1.  0.  1.  3.  4. 14.  0.  3.  0. 15. 14. 16.  0.  8.
  1.  0.  8.  3. 15. 10.  0. 23. 15.  1. 14.  3.  0.] 
adversary owned cards: [15 14  8  1  1 14 14 16 15  3  3 23 14  0  8  3  8  8  4  0 29  3  1  4
  0  0 11  0  1 10  3  0 10  0  1  3  3  4  3 15  0 10  0  0] -> size -> 44 
adversary victory points: 17
player victory points: -1 

Reward from previous game state: 
[  -5 -500    0    0    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -505 

action type: buy - action -1.0
Learning step: -15.767191886901855
desired expected reward: 4.805865287780762



