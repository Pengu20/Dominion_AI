 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[335.389]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    3  -30    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -812 

action type: buy - action 6.0
Learning step: -43.087974548339844
desired expected reward: 6.671485900878906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[311.51605]
 [311.5419 ]
 [311.55597]
 [311.51605]
 [312.70657]
 [315.12857]
 [313.3776 ]
 [320.29565]
 [315.12793]
 [313.32068]
 [317.02844]
 [330.98688]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.674264907836914
desired expected reward: 327.3763732910156



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[362.55753]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [0. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [10.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -8.43942928314209
desired expected reward: 322.5474548339844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[339.75436]
 [339.78018]
 [339.79428]
 [339.75436]
 [343.30255]
 [341.6159 ]
 [341.55896]
 [358.1691 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [0. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [10.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -10.449616432189941
desired expected reward: 354.4355163574219



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [10.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [10.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [10.  0.  3.  0.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[339.20593]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -10.338669776916504
desired expected reward: 347.83038330078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[316.31384]
 [316.3397 ]
 [316.35382]
 [316.31384]
 [317.50443]
 [319.8621 ]
 [318.17545]
 [324.81735]
 [319.86163]
 [318.1185 ]
 [321.6115 ]
 [335.30444]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.764355659484863
desired expected reward: 331.11492919921875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10] -> size -> 12 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[370.25262]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  0.  3.  0.] 
adversary cards in discard: [14. 10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -8.521476745605469
desired expected reward: 326.7829284667969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[347.04144]
 [347.0661 ]
 [347.07953]
 [347.04144]
 [350.45074]
 [348.81946]
 [348.7648 ]
 [365.61383]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  0.  3.  0.] 
adversary cards in discard: [14. 10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -10.581409454345703
desired expected reward: 360.25164794921875



buy possibilites: [-1] 
expected returns: [[331.08234]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 0.  0.  0.  0.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  0.  3.  0.] 
adversary cards in discard: [14. 10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 16 

action type: buy - action 11.0
Learning step: -9.273183822631836
desired expected reward: 341.1775207519531






Player: 1 
cards in hand: [10.  3.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  3.  0.] 
cards in discard: [14. 10.  0.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  3.  0.] 
cards in discard: [14. 10.  0.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  3.  0.] 
cards in discard: [14. 10.  0.  0.  0.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[305.11267]
 [290.8241 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -10.290323257446289
desired expected reward: 320.7920227050781



action possibilites: [-1] 
expected returns: [[342.1828]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: 17 

action type: gain_card_n - action 9
Learning step: -8.029936790466309
desired expected reward: 323.5510559082031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[319.79022]
 [319.81604]
 [319.83017]
 [319.79022]
 [323.3384 ]
 [321.6518 ]
 [321.59485]
 [338.68552]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action -1
Learning step: -9.257421493530273
desired expected reward: 332.9253845214844



buy possibilites: [-1] 
expected returns: [[346.37585]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: 26 

action type: buy - action 10.0
Learning step: -6.986286163330078
desired expected reward: 314.6085510253906






Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [10. 10. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [10. 10. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10] -> size -> 13 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [10. 10. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10] -> size -> 13 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[333.24872]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [10. 10. 11.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0.  3.  0. 10.] 
adversary cards in discard: [0. 0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -10.429314613342285
desired expected reward: 335.946533203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[315.8868 ]
 [315.91144]
 [315.92484]
 [315.8868 ]
 [319.2757 ]
 [317.6648 ]
 [317.61017]
 [333.1704 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [10. 10. 11.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0.  3.  0. 10.] 
adversary cards in discard: [0. 0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -9.900869369506836
desired expected reward: 322.96484375



buy possibilites: [-1] 
expected returns: [[339.824]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [10. 10. 11.  0.  3.  0.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0.  3.  0. 10.] 
adversary cards in discard: [0. 0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: 6 

action type: buy - action 1.0
Learning step: -7.970397472381592
desired expected reward: 307.9410705566406






Player: 1 
cards in hand: [10.  0.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0. 10.] 
cards in discard: [0. 0. 3. 0. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [10. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1] -> size -> 14 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0. 10.] 
cards in discard: [0. 0. 3. 0. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [10. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1] -> size -> 14 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0. 10.] 
cards in discard: [0. 0. 3. 0. 3. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [10. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1] -> size -> 14 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [10. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[350.35605]
 [331.11084]
 [331.11084]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [10.  3.  0. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1
Learning step: -10.340502738952637
desired expected reward: 329.4834899902344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[324.37112]
 [324.4026 ]
 [324.42545]
 [324.3727 ]
 [328.2294 ]
 [326.39236]
 [326.3387 ]
 [345.24957]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [10.  3.  0. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -11.048251152038574
desired expected reward: 339.54791259765625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10.  3.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0. 14.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [11.  3.  3.  0.  3.] 
adversary cards in discard: [10. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1] -> size -> 14 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0. 14.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [11.  3.  3.  0.  3.] 
adversary cards in discard: [10. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1] -> size -> 14 
adversary victory points: 3
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [11.  3.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[336.6911 ]
 [322.63828]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  3.  0.  3.] 
cards in discard: [10. 10.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [10.  3.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1.0
Learning step: -10.87038516998291
desired expected reward: 334.3791809082031



action possibilites: [-1] 
expected returns: [[336.3696]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3.] 
cards in discard: [10. 10.  0.  0.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  8. 10. 10. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [10.  3.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: 7 

action type: gain_card_n - action 5
Learning step: -8.106120109558105
desired expected reward: 312.3825988769531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[318.25824]
 [318.25967]
 [335.75656]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3.] 
cards in discard: [10. 10.  0.  0.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  8. 10. 10. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [10.  3.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -2 

action type: take_action - action -1
Learning step: -9.489919662475586
desired expected reward: 326.8796691894531






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [10.  3.  0. 14.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  8. 10. 10. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [3. 1. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11] -> size -> 15 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [10.  3.  0. 14.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  8. 10. 10. 10.  9. 10.  6. 10. 10.] 
adversary cards in hand: [3. 1. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11] -> size -> 15 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [10.  3.  0. 14.  0. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  8. 10. 10. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [3. 1. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11] -> size -> 15 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [3. 1. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[347.95047]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  8. 10. 10. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [10.  3.  0.  0.  3.] 
adversary cards in discard: [10.  3.  0. 14.  0. 14.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1.0
Learning step: -10.04320240020752
desired expected reward: 325.7133483886719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[325.10004]
 [325.1301 ]
 [325.15198]
 [325.18695]
 [325.1015 ]
 [326.34482]
 [328.79437]
 [327.03543]
 [331.9832 ]
 [333.87054]
 [328.79138]
 [329.91437]
 [326.98376]
 [328.10074]
 [330.63583]
 [344.48645]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  8. 10. 10. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [10.  3.  0.  0.  3.] 
adversary cards in discard: [10.  3.  0. 14.  0. 14.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -10.949721336364746
desired expected reward: 337.7003479003906



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10.  3.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.  3.] 
cards in discard: [10.  3.  0. 14.  0. 14.  3.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  8. 10. 10. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [11. 10.  0.  0.  0.] 
adversary cards in discard: [3. 1. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11] -> size -> 15 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.  3.] 
cards in discard: [10.  3.  0. 14.  0. 14.  3.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  8. 10. 10. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [11. 10.  0.  0.  0.] 
adversary cards in discard: [3. 1. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11] -> size -> 15 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.  3.] 
cards in discard: [10.  3.  0. 14.  0. 14.  3.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  8. 10. 10. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [11. 10.  0.  0.  0.] 
adversary cards in discard: [3. 1. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11] -> size -> 15 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [11. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[384.52835]
 [369.45706]
 [367.6465 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.  0.  0.] 
cards in discard: [3. 1. 0. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  8. 10. 10. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1.0
Learning step: -9.791330337524414
desired expected reward: 334.6950988769531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[363.60886]
 [363.63895]
 [363.66083]
 [363.61038]
 [367.30316]
 [365.54428]
 [365.49265]
 [382.37445]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  0.  0.  0.] 
cards in discard: [3. 1. 0. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  8. 10. 10. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -11.881412506103516
desired expected reward: 372.4743347167969



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  8. 10. 10. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [11. 10.  3.  3.  0.] 
adversary cards in discard: [ 3.  1.  0.  0.  0. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11] -> size -> 15 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  8. 10. 10. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [11. 10.  3.  3.  0.] 
adversary cards in discard: [ 3.  1.  0.  0.  0. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11] -> size -> 15 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [16.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  8. 10. 10. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [11. 10.  3.  3.  0.] 
adversary cards in discard: [ 3.  1.  0.  0.  0. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11] -> size -> 15 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [11. 10.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[353.39377]
 [338.01535]
 [336.16776]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  3.  3.  0.] 
cards in discard: [ 3.  1.  0.  0.  0. 11. 10.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  8. 10. 10. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [14.  0.  0.  3.  3.] 
adversary cards in discard: [16.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1.0
Learning step: -12.394659042358398
desired expected reward: 369.9798278808594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[333.18704]
 [333.18863]
 [352.33713]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  3.  3.  0.] 
cards in discard: [ 3.  1.  0.  0.  0. 11. 10.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  8. 10. 10. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [14.  0.  0.  3.  3.] 
adversary cards in discard: [16.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -10.957869529724121
desired expected reward: 341.99420166015625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [14.  0.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  3.  3.] 
cards in discard: [16.  0.  0.  0.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  8. 10. 10. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [10. 11.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11] -> size -> 15 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  3.  3.] 
cards in discard: [16.  0.  0.  0.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  8. 10. 10. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [10. 11.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11] -> size -> 15 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  3.  3.] 
cards in discard: [16.  0.  0.  0.  0.  3.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  8.  9. 10. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [10. 11.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11] -> size -> 15 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [10. 11.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[334.92386]
 [319.18234]
 [320.871  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  8.  9. 10. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  0. 10.] 
adversary cards in discard: [16.  0.  0.  0.  0.  3.  8. 14.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1.0
Learning step: -11.295893669128418
desired expected reward: 341.0412292480469



action possibilites: [-1] 
expected returns: [[292.589]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.] 
cards in discard: [15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  8.  9. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.  0. 10.] 
adversary cards in discard: [16.  0.  0.  0.  0.  3.  8. 14.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 14 

action type: gain_card_n - action 10
Learning step: -8.6559419631958
desired expected reward: 310.1279296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[278.11563]
 [278.1612 ]
 [278.11694]
 [279.81094]
 [294.54813]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.] 
cards in discard: [15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  8.  9. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.  0. 10.] 
adversary cards in discard: [16.  0.  0.  0.  0.  3.  8. 14.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -2 

action type: take_action - action -1
Learning step: -8.240307807922363
desired expected reward: 284.34869384765625



buy possibilites: [-1] 
expected returns: [[246.09256]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.] 
cards in discard: [15.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  8.  8. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.  0. 10.] 
adversary cards in discard: [16.  0.  0.  0.  0.  3.  8. 14.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: 6 

action type: buy - action 8.0
Learning step: -6.827932834625244
desired expected reward: 246.47238159179688






Player: 1 
cards in hand: [ 0. 10.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0. 10.] 
cards in discard: [16.  0.  0.  0.  0.  3.  8. 14.  0.  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  8.  8. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [10.  1.  3.  0.  0.] 
adversary cards in discard: [15.  8. 11. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8] -> size -> 17 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0. 10.] 
cards in discard: [16.  0.  0.  0.  0.  3.  8. 14.  0.  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  8.  8. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [10.  1.  3.  0.  0.] 
adversary cards in discard: [15.  8. 11. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8] -> size -> 17 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0. 10.] 
cards in discard: [16.  0.  0.  0.  0.  3.  8. 14.  0.  0.  3.  3.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  8.  7. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [10.  1.  3.  0.  0.] 
adversary cards in discard: [15.  8. 11. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8] -> size -> 17 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [10.  1.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[238.51164]
 [225.13905]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  3.  0.  0.] 
cards in discard: [15.  8. 11. 10.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  8.  7. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  8.  0. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8] -> size -> 21 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1
Learning step: -8.121393203735352
desired expected reward: 237.97116088867188



action possibilites: [-1.] 
expected returns: [[247.76942]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 0. 0.] 
cards in discard: [15.  8. 11. 10.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  8.  7. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  8.  0. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8] -> size -> 21 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -1 

action type: take_action - action 10.0
Learning step: -5.707526683807373
desired expected reward: 218.9392547607422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[234.167  ]
 [234.18504]
 [234.1868 ]
 [234.21526]
 [234.167  ]
 [235.0276 ]
 [236.74712]
 [235.52005]
 [238.95152]
 [240.22314]
 [236.74237]
 [237.52623]
 [235.47073]
 [236.24988]
 [238.0187 ]
 [247.47563]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 0.] 
cards in discard: [15.  8. 11. 10.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  8.  7. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  8.  0. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8] -> size -> 21 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -7.035496711730957
desired expected reward: 240.7339324951172



buy possibilites: [-1] 
expected returns: [[234.57094]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 0.] 
cards in discard: [15.  8. 11. 10.  3.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  8.  7. 10. 10.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  8.  0. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8] -> size -> 21 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    3.  -20.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: 2.5 

action type: buy - action 10.0
Learning step: -6.370691299438477
desired expected reward: 229.1000518798828






Player: 1 
cards in hand: [ 3.  8.  0. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0. 14.  3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  8.  7. 10. 10.  8. 10.  5. 10.  9.] 
adversary cards in hand: [10. 11.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10] -> size -> 18 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  8.  7. 10. 10.  8. 10.  5. 10.  9.] 
adversary cards in hand: [11.  3.  0.] 
adversary cards in discard: [10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10] -> size -> 18 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 28. 30.  8. 10.  9.  8.  7. 10. 10.  8. 10.  5. 10.  9.] 
adversary cards in hand: [11.  3.  0.] 
adversary cards in discard: [10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10] -> size -> 18 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 3.] 
cards in discard: [1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10.  9.  8.  7. 10. 10.  8. 10.  5. 10.  9.] 
adversary cards in hand: [11.  3.  0.] 
adversary cards in discard: [10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10] -> size -> 18 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[251.13866]
 [238.59352]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.] 
cards in discard: [10.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10.  9.  8.  7. 10. 10.  8. 10.  5. 10.  9.] 
adversary cards in hand: [10.  3.  3. 10.  3.] 
adversary cards in discard: [ 1. 14.  3.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1] -> size -> 22 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: discard_down_to_3_cards - action 5
Learning step: -7.760730266571045
desired expected reward: 237.0736541748047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[237.88008]
 [237.88008]
 [253.6407 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.] 
cards in discard: [10.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 28. 30. 28. 30.  8. 10.  9.  8.  7. 10. 10.  8. 10.  5. 10.  9.] 
adversary cards in hand: [10.  3.  3. 10.  3.] 
adversary cards in discard: [ 1. 14.  3.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1] -> size -> 22 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -8.062774658203125
desired expected reward: 243.06187438964844



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10.  3.  3. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3. 10.  3.] 
cards in discard: [ 1. 14.  3.  8.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10.  9.  8.  7. 10. 10.  8. 10.  5. 10.  9.] 
adversary cards in hand: [10. 15. 10.  0. 11.] 
adversary cards in discard: [10.  0. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10] -> size -> 18 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.  3.  0.] 
cards in discard: [ 1. 14.  3.  8.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10.  9.  8.  7. 10. 10.  8. 10.  5. 10.  9.] 
adversary cards in hand: [10. 15. 10.  0. 11.] 
adversary cards in discard: [10.  0. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10] -> size -> 18 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.  3.  0.] 
cards in discard: [ 1. 14.  3.  8.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 28. 30. 28. 30.  8. 10.  9.  8.  7. 10. 10.  8. 10.  5. 10.  9.] 
adversary cards in hand: [10. 15. 10.  0. 11.] 
adversary cards in discard: [10.  0. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10] -> size -> 18 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.  3.  0.] 
cards in discard: [ 1. 14.  3.  8.  0.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 28. 30.  8. 10.  9.  8.  7. 10. 10.  8. 10.  5. 10.  9.] 
adversary cards in hand: [10. 15. 10.  0. 11.] 
adversary cards in discard: [10.  0. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10] -> size -> 18 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [10. 15. 10.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 10. 11.] 
expected returns: [[264.45087]
 [251.07832]
 [253.9323 ]
 [251.07832]
 [252.508  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15. 10.  0. 11.] 
cards in discard: [10.  0. 11.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8. 10.  9.  8.  7. 10. 10.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 16.  0.  8.] 
adversary cards in discard: [ 1. 14.  3.  8.  0.  3.  0. 10.  3.  3. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0] -> size -> 23 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1.0
Learning step: -7.948423862457275
desired expected reward: 245.69227600097656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[251.39922]
 [251.39922]
 [266.232  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15. 10.  0. 11.] 
cards in discard: [10.  0. 11.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 28. 30.  8. 10.  9.  8.  7. 10. 10.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 16.  0.  8.] 
adversary cards in discard: [ 1. 14.  3.  8.  0.  3.  0. 10.  3.  3. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0] -> size -> 23 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -8.416290283203125
desired expected reward: 255.57833862304688



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0. 16.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  0.  8.] 
cards in discard: [ 1. 14.  3.  8.  0.  3.  0. 10.  3.  3. 10.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8. 10.  9.  8.  7. 10. 10.  8. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 1. 3. 8.] 
adversary cards in discard: [10.  0. 11.  3.  0. 10. 15. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10] -> size -> 18 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.  0.  8.] 
cards in discard: [ 1. 14.  3.  8.  0.  3.  0. 10.  3.  3. 10.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 28. 30.  8. 10.  9.  8.  7. 10. 10.  8. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 1. 3. 8.] 
adversary cards in discard: [10.  0. 11.  3.  0. 10. 15. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10] -> size -> 18 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.  0.  8.] 
cards in discard: [ 1. 14.  3.  8.  0.  3.  0. 10.  3.  3. 10.  3.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 27. 30.  8. 10.  9.  8.  7. 10. 10.  8. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 1. 3. 8.] 
adversary cards in discard: [10.  0. 11.  3.  0. 10. 15. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10] -> size -> 18 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [0. 0. 1. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[150.99715]
 [139.9129 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3. 8.] 
cards in discard: [10.  0. 11.  3.  0. 10. 15. 10.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8. 10.  9.  8.  7. 10. 10.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 14.  0.  0.  0.] 
adversary cards in discard: [ 1. 14.  3.  8.  0.  3.  0. 10.  3.  3. 10.  3.  0.  3.  0.  0. 16.  0.
  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0  3] -> size -> 24 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1.0
Learning step: -11.582855224609375
desired expected reward: 254.649169921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[139.30518]
 [139.32213]
 [139.32344]
 [139.30518]
 [140.10721]
 [141.71002]
 [140.56667]
 [144.95125]
 [141.706  ]
 [140.5201 ]
 [142.89594]
 [151.6509 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 8.] 
cards in discard: [10.  0. 11.  3.  0. 10. 15. 10.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 28. 30. 27. 30.  8. 10.  9.  8.  7. 10. 10.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 14.  0.  0.  0.] 
adversary cards in discard: [ 1. 14.  3.  8.  0.  3.  0. 10.  3.  3. 10.  3.  0.  3.  0.  0. 16.  0.
  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0  3] -> size -> 24 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -5.824642181396484
desired expected reward: 144.77940368652344



buy possibilites: [-1] 
expected returns: [[175.53654]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 8.] 
cards in discard: [10.  0. 11.  3.  0. 10. 15. 10.  0. 11.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 26. 30.  8. 10.  9.  8.  7. 10. 10.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 14.  0.  0.  0.] 
adversary cards in discard: [ 1. 14.  3.  8.  0.  3.  0. 10.  3.  3. 10.  3.  0.  3.  0.  0. 16.  0.
  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0  3] -> size -> 24 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4. -20.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -19.0 

action type: buy - action 3.0
Learning step: -3.966600179672241
desired expected reward: 135.35684204101562






Player: 1 
cards in hand: [ 0. 14.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  0.  0.] 
cards in discard: [ 1. 14.  3.  8.  0.  3.  0. 10.  3.  3. 10.  3.  0.  3.  0.  0. 16.  0.
  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8. 10.  9.  8.  7. 10. 10.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 3. 10.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3] -> size -> 19 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  0.  0.] 
cards in discard: [ 1. 14.  3.  8.  0.  3.  0. 10.  3.  3. 10.  3.  0.  3.  0.  0. 16.  0.
  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 28. 30. 26. 30.  8. 10.  9.  8.  7. 10. 10.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 3. 10.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3] -> size -> 19 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  0.  0.] 
cards in discard: [ 1. 14.  3.  8.  0.  3.  0. 10.  3.  3. 10.  3.  0.  3.  0.  0. 16.  0.
  8. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0  3
 14] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8. 10.  9.  8.  7. 10. 10.  7. 10.  5. 10.  9.] 
adversary cards in hand: [ 3. 10.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3] -> size -> 19 
adversary victory points: 4
player victory points: 6 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 3. 10.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[263.22662]
 [248.96213]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8. 10.  9.  8.  7. 10. 10.  7. 10.  5. 10.  9.] 
adversary cards in hand: [10.  0. 10. 14. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0  3
 14] -> size -> 25 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: buy - action -1
Learning step: -3.9999866485595703
desired expected reward: 171.53656005859375



action possibilites: [-1.  8.] 
expected returns: [[246.23253]
 [231.4561 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3] -> size -> 19 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8. 10.  9.  8.  7. 10. 10.  7. 10.  5. 10.  9.] 
adversary cards in hand: [10.  0. 10. 14. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0  3
 14] -> size -> 25 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -1 

action type: take_action - action 10.0
Learning step: -6.988122463226318
desired expected reward: 240.98338317871094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[229.11586]
 [229.13904]
 [229.11586]
 [230.6936 ]
 [245.4186 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 26. 30.  8. 10.  9.  8.  7. 10. 10.  7. 10.  5. 10.  9.] 
adversary cards in hand: [10.  0. 10. 14. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0  3
 14] -> size -> 25 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -6.9770827293396
desired expected reward: 239.2554473876953



buy possibilites: [-1] 
expected returns: [[212.37352]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 8.] 
cards in discard: [8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8. 10.  9.  8.  6. 10. 10.  7. 10.  5. 10.  9.] 
adversary cards in hand: [10.  0. 10. 14. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0  3
 14] -> size -> 25 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: 7 

action type: buy - action 8.0
Learning step: -6.39458703994751
desired expected reward: 224.0652313232422






Player: 1 
cards in hand: [10.  0. 10. 14. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 14. 16.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10. 14. 16.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0  3
 14] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8. 10.  9.  8.  6. 10. 10.  7. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 10. 10.  0.] 
adversary cards in discard: [ 8. 10.  3.  3.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8] -> size -> 20 
adversary victory points: 4
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10. 16.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0  3
 14] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 26. 30.  8. 10.  9.  8.  6. 10. 10.  7. 10.  5. 10.  9.] 
adversary cards in hand: [10. 10.  0.] 
adversary cards in discard: [ 8. 10.  3.  3.  0.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8] -> size -> 20 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10. 16.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0  3
 14] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 26. 30.  8. 10.  9.  8.  6. 10. 10.  7. 10.  5. 10.  9.] 
adversary cards in hand: [10. 10.  0.] 
adversary cards in discard: [ 8. 10.  3.  3.  0.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8] -> size -> 20 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10. 16.] 
cards in discard: [10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0  3
 14 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8. 10.  9.  8.  6. 10. 10.  7. 10.  4. 10.  9.] 
adversary cards in hand: [10. 10.  0.] 
adversary cards in discard: [ 8. 10.  3.  3.  0.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8] -> size -> 20 
adversary victory points: 4
player victory points: 6 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[197.37126]
 [183.68153]
 [183.68153]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.] 
cards in discard: [ 8. 10.  3.  3.  0.  0.  8.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8. 10.  9.  8.  6. 10. 10.  7. 10.  4. 10.  9.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [10. 14. 10.  0. 10. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0  3
 14 10] -> size -> 26 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: discard_down_to_3_cards - action 3
Learning step: -6.142765045166016
desired expected reward: 182.29331970214844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[184.62227]
 [184.62227]
 [199.97716]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.] 
cards in discard: [ 8. 10.  3.  3.  0.  0.  8.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 26. 30.  8. 10.  9.  8.  6. 10. 10.  7. 10.  4. 10.  9.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [10. 14. 10.  0. 10. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0  3
 14 10] -> size -> 26 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: take_action - action -1.0
Learning step: -6.501220703125
desired expected reward: 190.30218505859375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0. 0.] 
cards in discard: [10. 14. 10.  0. 10. 16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0  3
 14 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8. 10.  9.  8.  6. 10. 10.  7. 10.  4. 10.  9.] 
adversary cards in hand: [11.  3.  3. 11.  1.] 
adversary cards in discard: [ 8. 10.  3.  3.  0.  0.  8.  0.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8] -> size -> 20 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 0. 0.] 
cards in discard: [10. 14. 10.  0. 10. 16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0  3
 14 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 26. 30.  8. 10.  9.  8.  6. 10. 10.  7. 10.  4. 10.  9.] 
adversary cards in hand: [11.  3.  3. 11.  1.] 
adversary cards in discard: [ 8. 10.  3.  3.  0.  0.  8.  0.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8] -> size -> 20 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 0. 0.] 
cards in discard: [10. 14. 10.  0. 10. 16.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0  3
 14 10  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 26. 30.  8. 10.  9.  8.  5. 10. 10.  7. 10.  4. 10.  9.] 
adversary cards in hand: [11.  3.  3. 11.  1.] 
adversary cards in discard: [ 8. 10.  3.  3.  0.  0.  8.  0.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8] -> size -> 20 
adversary victory points: 4
player victory points: 6 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [11.  3.  3. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[221.4579 ]
 [204.88628]
 [204.88628]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  3. 11.  1.] 
cards in discard: [ 8. 10.  3.  3.  0.  0.  8.  0.  0. 10. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8. 10.  9.  8.  5. 10. 10.  7. 10.  4. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [10. 14. 10.  0. 10. 16.  8.  0.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0  3
 14 10  8] -> size -> 27 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: buy - action -1.0
Learning step: -6.1853508949279785
desired expected reward: 193.79180908203125



action possibilites: [-1] 
expected returns: [[149.6392]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11.  1.] 
cards in discard: [ 8. 10.  3.  3.  0.  0.  8.  0.  0. 10. 10.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8. 10.  9.  8.  5. 10. 10.  7. 10.  3. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [10. 14. 10.  0. 10. 16.  8.  0.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0  3
 14 10  8] -> size -> 27 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: 8 

action type: gain_card_n - action 9
Learning step: -6.481163024902344
desired expected reward: 198.479736328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[137.89377]
 [137.91231]
 [137.89377]
 [139.1855 ]
 [150.5161 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 11.  1.] 
cards in discard: [ 8. 10.  3.  3.  0.  0.  8.  0.  0. 10. 10.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 26. 30.  8. 10.  9.  8.  5. 10. 10.  7. 10.  3. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [10. 14. 10.  0. 10. 16.  8.  0.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0  3
 14 10  8] -> size -> 27 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -1 

action type: take_action - action -1
Learning step: -4.251557350158691
desired expected reward: 145.3876495361328






Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [10. 14. 10.  0. 10. 16.  8.  0.  8.  3.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0  3
 14 10  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8. 10.  9.  8.  5. 10. 10.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 1.  8. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [10. 14. 10.  0. 10. 16.  8.  0.  8.  3.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0  3
 14 10  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 26. 30.  8. 10.  9.  8.  5. 10. 10.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 1.  8. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
adversary victory points: 4
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 1.  8. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
expected returns: [[212.1149 ]
 [198.45815]
 [201.22176]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8. 15.  0.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8. 10.  9.  8.  5. 10. 10.  7. 10.  3. 10.  9.] 
adversary cards in hand: [8. 0. 0. 3. 3.] 
adversary cards in discard: [10. 14. 10.  0. 10. 16.  8.  0.  8.  3.  0.  0.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0  3
 14 10  8] -> size -> 27 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: buy - action -1.0
Learning step: -3.9228551387786865
desired expected reward: 146.59326171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[194.06114]
 [194.08139]
 [194.0828 ]
 [194.06114]
 [195.01433]
 [196.91898]
 [195.56133]
 [200.86548]
 [196.91232]
 [195.50636]
 [198.32494]
 [209.26521]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8. 15.  0.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 28. 30. 26. 30.  8. 10.  9.  8.  5. 10. 10.  7. 10.  3. 10.  9.] 
adversary cards in hand: [8. 0. 0. 3. 3.] 
adversary cards in discard: [10. 14. 10.  0. 10. 16.  8.  0.  8.  3.  0.  0.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0  3
 14 10  8] -> size -> 27 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: take_action - action -1.0
Learning step: -7.0114898681640625
desired expected reward: 203.7506103515625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3. 3.] 
cards in discard: [10. 14. 10.  0. 10. 16.  8.  0.  8.  3.  0.  0.  0.  3.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0  3
 14 10  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8. 10.  9.  8.  5. 10. 10.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 10.  3. 11.  0.] 
adversary cards in discard: [ 1.  8. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3. 3.] 
cards in discard: [10. 14. 10.  0. 10. 16.  8.  0.  8.  3.  0.  0.  0.  3.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0  3
 14 10  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 26. 30.  8. 10.  9.  8.  5. 10. 10.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 10.  3. 11.  0.] 
adversary cards in discard: [ 1.  8. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3. 3.] 
cards in discard: [10. 14. 10.  0. 10. 16.  8.  0.  8.  3.  0.  0.  0.  3.  0.  0.  3.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0  3
 14 10  8  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8. 10.  9.  8.  4. 10. 10.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 10.  3. 11.  0.] 
adversary cards in discard: [ 1.  8. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
adversary victory points: 4
player victory points: 6 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[201.09747]
 [189.85457]
 [191.03864]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 11.  0.] 
cards in discard: [ 1.  8. 15.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8. 10.  9.  8.  4. 10. 10.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 1.  3. 14. 14.  0.] 
adversary cards in discard: [10. 14. 10.  0. 10. 16.  8.  0.  8.  3.  0.  0.  0.  3.  0.  0.  3.  8.
  8.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0  3
 14 10  8  8] -> size -> 28 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: buy - action -1.0
Learning step: -7.079948425292969
desired expected reward: 202.18527221679688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[189.66817]
 [189.68628]
 [189.66817]
 [190.92513]
 [202.16936]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3. 11.  0.] 
cards in discard: [ 1.  8. 15.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 26. 30.  8. 10.  9.  8.  4. 10. 10.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 1.  3. 14. 14.  0.] 
adversary cards in discard: [10. 14. 10.  0. 10. 16.  8.  0.  8.  3.  0.  0.  0.  3.  0.  0.  3.  8.
  8.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0  3
 14 10  8  8] -> size -> 28 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: take_action - action -1.0
Learning step: -6.628776550292969
desired expected reward: 193.81817626953125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 1.  3. 14. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 14. 14.  0.] 
cards in discard: [10. 14. 10.  0. 10. 16.  8.  0.  8.  3.  0.  0.  0.  3.  0.  0.  3.  8.
  8.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0  3
 14 10  8  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8. 10.  9.  8.  4. 10. 10.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  3.  3.  0. 10.] 
adversary cards in discard: [ 1.  8. 15.  0.  0.  0. 10.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
adversary victory points: 4
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 14.  0.] 
cards in discard: [10. 14. 10.  0. 10. 16.  8.  0.  8.  3.  0.  0.  0.  3.  0.  0.  3.  8.
  8.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0  3
 14 10  8  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 26. 30.  8. 10.  9.  8.  4. 10. 10.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  3. 10.] 
adversary cards in discard: [ 1.  8. 15.  0.  0.  0. 10.  3. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 14.  0.] 
cards in discard: [10. 14. 10.  0. 10. 16.  8.  0.  8.  3.  0.  0.  0.  3.  0.  0.  3.  8.
  8.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0  3
 14 10  8  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 28. 30. 26. 30.  8. 10.  9.  8.  4. 10. 10.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  3. 10.] 
adversary cards in discard: [ 1.  8. 15.  0.  0.  0. 10.  3. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 14.  0.] 
cards in discard: [10. 14. 10.  0. 10. 16.  8.  0.  8.  3.  0.  0.  0.  3.  0.  0.  3.  8.
  8.  0.  0.  3.  3. 22.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0  3
 14 10  8  8 22] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8. 10.  9.  8.  4. 10. 10.  7. 10.  3.  9.  9.] 
adversary cards in hand: [ 3.  3. 10.] 
adversary cards in discard: [ 1.  8. 15.  0.  0.  0. 10.  3. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
adversary victory points: 4
player victory points: 6 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 3.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[160.40169]
 [146.93028]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.] 
cards in discard: [ 1.  8. 15.  0.  0.  0. 10.  3. 11.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8. 10.  9.  8.  4. 10. 10.  7. 10.  3.  9.  9.] 
adversary cards in hand: [ 0.  3.  0. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0  3
 14 10  8  8 22] -> size -> 29 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: discard_down_to_3_cards - action 3
Learning step: -4.7145586013793945
desired expected reward: 139.30270385742188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[146.41176]
 [146.41176]
 [161.3577 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.] 
cards in discard: [ 1.  8. 15.  0.  0.  0. 10.  3. 11.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
action values: 1 
buys: 1 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8. 10.  9.  8.  4. 10. 10.  7. 10.  3.  9.  9.] 
adversary cards in hand: [ 0.  3.  0. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0  3
 14 10  8  8 22] -> size -> 29 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: take_action - action -1.0
Learning step: -5.547129154205322
desired expected reward: 154.85455322265625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10. 10.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0  3
 14 10  8  8 22] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8. 10.  9.  8.  4. 10. 10.  7. 10.  3.  9.  9.] 
adversary cards in hand: [11. 10.  8.  0.  0.] 
adversary cards in discard: [ 1.  8. 15.  0.  0.  0. 10.  3. 11.  0.  3.  0.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
adversary victory points: 4
player victory points: 6 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0  3
 14 10  8  8 22] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8. 10.  9.  8.  4. 10. 10.  7. 10.  3.  9.  9.] 
adversary cards in hand: [11. 10.  8.  0.  0.] 
adversary cards in discard: [ 1.  8. 15.  0.  0.  0. 10.  3. 11.  0.  3.  0.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
adversary victory points: 4
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0  3
 14 10  8  8 22] -> size -> 29 
action values: 3 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8. 10.  9.  8.  4. 10. 10.  7. 10.  3.  9.  9.] 
adversary cards in hand: [11. 10.  8.  0.  0.] 
adversary cards in discard: [ 1.  8. 15.  0.  0.  0. 10.  3. 11.  0.  3.  0.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0  3
 14 10  8  8 22] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 26. 30.  8. 10.  9.  8.  4. 10. 10.  7. 10.  3.  9.  9.] 
adversary cards in hand: [11. 10.  8.  0.  0.] 
adversary cards in discard: [ 1.  8. 15.  0.  0.  0. 10.  3. 11.  0.  3.  0.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0  3
 14 10  8  8 22  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 26. 30.  8. 10.  9.  8.  4. 10. 10.  7. 10.  3.  9.  9.] 
adversary cards in hand: [11. 10.  8.  0.  0.] 
adversary cards in discard: [ 1.  8. 15.  0.  0.  0. 10.  3. 11.  0.  3.  0.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
adversary victory points: 4
player victory points: 6 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [11. 10.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8.] 
expected returns: [[198.197  ]
 [184.26868]
 [182.73907]
 [182.799  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  8.  0.  0.] 
cards in discard: [ 1.  8. 15.  0.  0.  0. 10.  3. 11.  0.  3.  0.  3.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 26. 30.  8. 10.  9.  8.  4. 10. 10.  7. 10.  3.  9.  9.] 
adversary cards in hand: [ 8.  3.  3. 14.  1.] 
adversary cards in discard: [ 1. 10. 10.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0  3
 14 10  8  8 22  1] -> size -> 30 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: buy - action -1.0
Learning step: -4.779350757598877
desired expected reward: 156.57835388183594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[167.8365 ]
 [167.8497 ]
 [167.8365 ]
 [169.24036]
 [181.84026]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  8.  0.  0.] 
cards in discard: [ 1.  8. 15.  0.  0.  0. 10.  3. 11.  0.  3.  0.  3.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 26. 30.  8. 10.  9.  8.  4. 10. 10.  7. 10.  3.  9.  9.] 
adversary cards in hand: [ 8.  3.  3. 14.  1.] 
adversary cards in discard: [ 1. 10. 10.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0  3
 14 10  8  8 22  1] -> size -> 30 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: take_action - action -1.0
Learning step: -6.149272918701172
desired expected reward: 175.30606079101562



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8.  3.  3. 14.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  3. 14.  1.] 
cards in discard: [ 1. 10. 10.  0.  3.  0.  0.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10 14  3  0  3 14  0 16  8  8  1  0  3
 14 10  8  8 22  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 26. 30.  8. 10.  9.  8.  4. 10. 10.  7. 10.  3.  9.  9.] 
adversary cards in hand: [ 8. 11.  3. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
adversary victory points: 4
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 1.] 
cards in discard: [ 1. 10. 10.  0.  3.  0.  0.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  3  0  3 14  0 16  8  8  1  0  3 14
 10  8  8 22  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 26. 30.  8. 10.  9.  8.  4. 10. 10.  7. 10.  3.  9.  9.] 
adversary cards in hand: [ 8. 11.  3. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1.] 
cards in discard: [ 1. 10. 10.  0.  3.  0.  0.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  3  0  3 14  0 16  8  8  1  0  3 14
 10  8  8 22  1] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 26. 30.  8. 10.  9.  8.  4. 10. 10.  7. 10.  3.  9.  9.] 
adversary cards in hand: [ 8. 11.  3. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
adversary victory points: 4
player victory points: 6 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 8. 11.  3. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10. 10.] 
expected returns: [[188.33185]
 [174.34381]
 [175.69096]
 [174.28058]
 [174.28058]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  3. 10. 10.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 26. 30.  8. 10.  9.  8.  4. 10. 10.  7. 10.  3.  9.  9.] 
adversary cards in hand: [ 0. 10.  8.  8. 22.] 
adversary cards in discard: [ 1. 10. 10.  0.  3.  0.  0.  3.  8.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  3  0  3 14  0 16  8  8  1  0  3 14
 10  8  8 22  1] -> size -> 29 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: buy - action -1.0
Learning step: -6.057597637176514
desired expected reward: 175.7826385498047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[171.96358]
 [171.96358]
 [187.12886]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  3. 10. 10.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
action values: 1 
buys: 1 
player value: 0 
card supply: [27. 27. 30. 26. 30.  8. 10.  9.  8.  4. 10. 10.  7. 10.  3.  9.  9.] 
adversary cards in hand: [ 0. 10.  8.  8. 22.] 
adversary cards in discard: [ 1. 10. 10.  0.  3.  0.  0.  3.  8.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  3  0  3 14  0 16  8  8  1  0  3 14
 10  8  8 22  1] -> size -> 29 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: take_action - action -1.0
Learning step: -6.2898712158203125
desired expected reward: 180.5321044921875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 10.  8.  8. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8. 22.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8.  8. 22.] 
cards in discard: [ 1. 10. 10.  0.  3.  0.  0.  3.  8.  3.  3.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  3  0  3 14  0 16  8  8  1  0  3 14
 10  8  8 22  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 26. 30.  8. 10.  9.  8.  4. 10. 10.  7. 10.  3.  9.  9.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [ 8. 11.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
adversary victory points: 4
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 22.] 
cards in discard: [ 1. 10. 10.  0.  3.  0.  0.  3.  8.  3.  3.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10
  8  8 22  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 26. 30.  8. 10.  9.  8.  4. 10. 10.  7. 10.  3.  9.  9.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [ 8. 11.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 22.] 
cards in discard: [ 1. 10. 10.  0.  3.  0.  0.  3.  8.  3.  3.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10
  8  8 22  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 27. 30. 26. 30.  8. 10.  9.  8.  4. 10. 10.  7. 10.  3.  9.  9.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [ 8. 11.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 22.] 
cards in discard: [ 1. 10. 10.  0.  3.  0.  0.  3.  8.  3.  3.  1.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10
  8  8 22  1  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 26. 30.  8. 10.  9.  8.  4. 10. 10.  7. 10.  3.  9.  9.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [ 8. 11.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
adversary victory points: 4
player victory points: 6 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [0. 0. 1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[189.05669]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [ 8. 11.  3. 10. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 30.  8. 10.  9.  8.  4. 10. 10.  7. 10.  3.  9.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 1. 10. 10.  0.  3.  0.  0.  3.  8.  3.  3.  1.  0.  8.  0.  8. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10
  8  8 22  1  0] -> size -> 29 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: buy - action -1.0
Learning step: -6.171158313751221
desired expected reward: 180.95770263671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[179.367  ]
 [179.3819 ]
 [179.37889]
 [179.40337]
 [179.367  ]
 [180.15938]
 [181.75888]
 [180.625  ]
 [183.83493]
 [185.02298]
 [181.75827]
 [182.48135]
 [180.5702 ]
 [181.29266]
 [182.94696]
 [191.86916]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [ 8. 11.  3. 10. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 27. 30. 26. 30.  8. 10.  9.  8.  4. 10. 10.  7. 10.  3.  9.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 1. 10. 10.  0.  3.  0.  0.  3.  8.  3.  3.  1.  0.  8.  0.  8. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10
  8  8 22  1  0] -> size -> 29 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: take_action - action -1.0
Learning step: -6.253134727478027
desired expected reward: 181.98175048828125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 1. 10. 10.  0.  3.  0.  0.  3.  8.  3.  3.  1.  0.  8.  0.  8. 22.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10
  8  8 22  1  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 30.  8. 10.  9.  8.  4. 10. 10.  7. 10.  3.  9.  9.] 
adversary cards in hand: [ 0.  3.  0. 10.  0.] 
adversary cards in discard: [ 8. 11.  3. 10. 10.  0.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 1. 10. 10.  0.  3.  0.  0.  3.  8.  3.  3.  1.  0.  8.  0.  8. 22.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10
  8  8 22  1  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 27. 30. 26. 30.  8. 10.  9.  8.  4. 10. 10.  7. 10.  3.  9.  9.] 
adversary cards in hand: [ 0.  3.  0. 10.  0.] 
adversary cards in discard: [ 8. 11.  3. 10. 10.  0.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 1. 10. 10.  0.  3.  0.  0.  3.  8.  3.  3.  1.  0.  8.  0.  8. 22.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10
  8  8 22  1  0  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 27. 30. 25. 30.  8. 10.  9.  8.  4. 10. 10.  7. 10.  3.  9.  9.] 
adversary cards in hand: [ 0.  3.  0. 10.  0.] 
adversary cards in discard: [ 8. 11.  3. 10. 10.  0.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
adversary victory points: 4
player victory points: 7 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[198.02405]
 [186.83495]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10.  0.] 
cards in discard: [ 8. 11.  3. 10. 10.  0.  0.  1.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 30.  8. 10.  9.  8.  4. 10. 10.  7. 10.  3.  9.  9.] 
adversary cards in hand: [14.  0. 14.  8.  0.] 
adversary cards in discard: [ 1. 10. 10.  0.  3.  0.  0.  3.  8.  3.  3.  1.  0.  8.  0.  8. 22.  3.
  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10
  8  8 22  1  0  3] -> size -> 30 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -31 

action type: buy - action -1.0
Learning step: -6.748327732086182
desired expected reward: 185.12083435058594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[188.34094]
 [188.35583]
 [188.3528 ]
 [188.34094]
 [190.7328 ]
 [189.59892]
 [189.54414]
 [200.73323]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.  0.] 
cards in discard: [ 8. 11.  3. 10. 10.  0.  0.  1.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 25. 30.  8. 10.  9.  8.  4. 10. 10.  7. 10.  3.  9.  9.] 
adversary cards in hand: [14.  0. 14.  8.  0.] 
adversary cards in discard: [ 1. 10. 10.  0.  3.  0.  0.  3.  8.  3.  3.  1.  0.  8.  0.  8. 22.  3.
  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10
  8  8 22  1  0  3] -> size -> 30 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -31 

action type: take_action - action -1.0
Learning step: -7.045205593109131
desired expected reward: 190.97885131835938



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [14.  0. 14.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0. 14.  8.  0.] 
cards in discard: [ 1. 10. 10.  0.  3.  0.  0.  3.  8.  3.  3.  1.  0.  8.  0.  8. 22.  3.
  3.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10
  8  8 22  1  0  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 30.  8. 10.  9.  8.  4. 10. 10.  7. 10.  3.  9.  9.] 
adversary cards in hand: [ 0. 10.  8.  3. 15.] 
adversary cards in discard: [ 8. 11.  3. 10. 10.  0.  0.  1.  3.  0.  0.  3.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
adversary victory points: 4
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  8.  0.] 
cards in discard: [ 1. 10. 10.  0.  3.  0.  0.  3.  8.  3.  3.  1.  0.  8.  0.  8. 22.  3.
  3.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10
  8  8 22  1  0  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 27. 30. 25. 30.  8. 10.  9.  8.  4. 10. 10.  7. 10.  3.  9.  9.] 
adversary cards in hand: [ 0. 10.  8.] 
adversary cards in discard: [ 8. 11.  3. 10. 10.  0.  0.  1.  3.  0.  0.  3.  0. 10.  0.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
adversary victory points: 4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  8.  0.] 
cards in discard: [ 1. 10. 10.  0.  3.  0.  0.  3.  8.  3.  3.  1.  0.  8.  0.  8. 22.  3.
  3.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10
  8  8 22  1  0  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 27. 30. 25. 30.  8. 10.  9.  8.  4. 10. 10.  7. 10.  3.  9.  9.] 
adversary cards in hand: [ 0. 10.  8.] 
adversary cards in discard: [ 8. 11.  3. 10. 10.  0.  0.  1.  3.  0.  0.  3.  0. 10.  0.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
adversary victory points: 4
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  8.  0.] 
cards in discard: [ 1. 10. 10.  0.  3.  0.  0.  3.  8.  3.  3.  1.  0.  8.  0.  8. 22.  3.
  3.  0.  0.  0.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10
  8  8 22  1  0  3 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 25. 30.  8. 10.  9.  7.  4. 10. 10.  7. 10.  3.  9.  9.] 
adversary cards in hand: [ 0. 10.  8.] 
adversary cards in discard: [ 8. 11.  3. 10. 10.  0.  0.  1.  3.  0.  0.  3.  0. 10.  0.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
adversary victory points: 4
player victory points: 7 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[136.22899]
 [124.88259]
 [124.93832]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8.] 
cards in discard: [ 8. 11.  3. 10. 10.  0.  0.  1.  3.  0.  0.  3.  0. 10.  0.  3. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 30.  8. 10.  9.  7.  4. 10. 10.  7. 10.  3.  9.  9.] 
adversary cards in hand: [ 3.  0.  0.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10
  8  8 22  1  0  3 11] -> size -> 31 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -31 

action type: discard_down_to_3_cards - action 9
Learning step: -5.577430248260498
desired expected reward: 134.64462280273438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[123.945465]
 [123.945465]
 [136.51222 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  8.] 
cards in discard: [ 8. 11.  3. 10. 10.  0.  0.  1.  3.  0.  0.  3.  0. 10.  0.  3. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 27. 30. 25. 30.  8. 10.  9.  7.  4. 10. 10.  7. 10.  3.  9.  9.] 
adversary cards in hand: [ 3.  0.  0.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10
  8  8 22  1  0  3 11] -> size -> 31 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -31 

action type: take_action - action -1.0
Learning step: -5.380390167236328
desired expected reward: 130.84860229492188



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  0.  0.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  3. 16.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10
  8  8 22  1  0  3 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 25. 30.  8. 10.  9.  7.  4. 10. 10.  7. 10.  3.  9.  9.] 
adversary cards in hand: [ 0. 10.  1.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
adversary victory points: 4
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10  8
  8 22  1  0  3 11  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 25. 30.  8. 10.  9.  7.  4. 10. 10.  7. 10.  3.  9.  9.] 
adversary cards in hand: [ 0. 10.  1.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
adversary victory points: 4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10  8
  8 22  1  0  3 11  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 25. 30.  8. 10.  9.  7.  4. 10. 10.  7. 10.  3.  9.  9.] 
adversary cards in hand: [ 0. 10.  1.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
adversary victory points: 4
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [0. 0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10  8
  8 22  1  0  3 11  0  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 25. 30.  8. 10.  9.  7.  4. 10. 10.  7. 10.  3.  9.  9.] 
adversary cards in hand: [ 0. 10.  1.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
adversary victory points: 4
player victory points: 7 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  1.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[160.49107]
 [146.79256]
 [148.13887]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  1.  3. 11.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 25. 30.  8. 10.  9.  7.  4. 10. 10.  7. 10.  3.  9.  9.] 
adversary cards in hand: [ 0. 14.  0.  3.  0.] 
adversary cards in discard: [ 0.  0. 16.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10  8
  8 22  1  0  3 11  0  0] -> size -> 32 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -31 

action type: buy - action -1.0
Learning step: -4.872025966644287
desired expected reward: 131.64019775390625



action possibilites: [-1] 
expected returns: [[195.86473]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  1.  3.] 
cards in discard: [10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 25. 30.  8. 10.  9.  7.  4. 10. 10.  7. 10.  2.  9.  9.] 
adversary cards in hand: [ 0. 14.  0.  3.  0.] 
adversary cards in discard: [ 0.  0. 16.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10  8
  8 22  1  0  3 11  0  0] -> size -> 32 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -2 

action type: gain_card_n - action 9
Learning step: -3.850008487701416
desired expected reward: 159.28929138183594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[182.82912]
 [182.8474 ]
 [182.84378]
 [182.82912]
 [185.7774 ]
 [184.37982]
 [184.31253]
 [198.10242]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  1.  3.] 
cards in discard: [10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 27. 30. 25. 30.  8. 10.  9.  7.  4. 10. 10.  7. 10.  2.  9.  9.] 
adversary cards in hand: [ 0. 14.  0.  3.  0.] 
adversary cards in discard: [ 0.  0. 16.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10  8
  8 22  1  0  3 11  0  0] -> size -> 32 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1
Learning step: -6.022121429443359
desired expected reward: 189.8426055908203






Player: 1 
cards in hand: [ 0. 14.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  3.  0.] 
cards in discard: [ 0.  0. 16.  3.  0.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10  8
  8 22  1  0  3 11  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 25. 30.  8. 10.  9.  7.  4. 10. 10.  7. 10.  2.  9.  9.] 
adversary cards in hand: [10. 10.  3. 11. 10.] 
adversary cards in discard: [10. 11.  0. 10.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10 10] -> size -> 22 
adversary victory points: 4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  3.  0.] 
cards in discard: [ 0.  0. 16.  3.  0.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10  8
  8 22  1  0  3 11  0  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 27. 30. 25. 30.  8. 10.  9.  7.  4. 10. 10.  7. 10.  2.  9.  9.] 
adversary cards in hand: [10. 10.  3. 11. 10.] 
adversary cards in discard: [10. 11.  0. 10.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10 10] -> size -> 22 
adversary victory points: 4
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  3.  0.] 
cards in discard: [ 0.  0. 16.  3.  0.  3.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10  8
  8 22  1  0  3 11  0  0  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 25. 30.  8. 10.  9.  7.  3. 10. 10.  7. 10.  2.  9.  9.] 
adversary cards in hand: [10. 10.  3. 11. 10.] 
adversary cards in discard: [10. 11.  0. 10.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10 10] -> size -> 22 
adversary victory points: 4
player victory points: 7 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [10. 10.  3. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11. 10.] 
expected returns: [[157.30113]
 [144.83476]
 [144.83476]
 [146.1142 ]
 [144.83476]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3. 11. 10.] 
cards in discard: [10. 11.  0. 10.  1.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 25. 30.  8. 10.  9.  7.  3. 10. 10.  7. 10.  2.  9.  9.] 
adversary cards in hand: [22.  0.  8.  0.  3.] 
adversary cards in discard: [ 0.  0. 16.  3.  0.  3.  8.  0. 14.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10  8
  8 22  1  0  3 11  0  0  8] -> size -> 33 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -31 

action type: buy - action -1.0
Learning step: -8.020774841308594
desired expected reward: 190.0816650390625



action possibilites: [-1] 
expected returns: [[107.01146]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3. 10.] 
cards in discard: [10. 11.  0. 10.  1.  3.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10 10  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 24. 30.  8. 10.  9.  7.  3. 10. 10.  7. 10.  2.  9.  9.] 
adversary cards in hand: [22.  0.  8.  0.  3.] 
adversary cards in discard: [ 0.  0. 16.  3.  0.  3.  8.  0. 14.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10  8
  8 22  1  0  3 11  0  0  8] -> size -> 33 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0  20   0   0   0   0   0   0   0   4   0] 
sum of rewards: 4 

action type: gain_card_n - action 2
Learning step: -4.342060089111328
desired expected reward: 134.654296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 96.11342]
 [ 96.11342]
 [107.30716]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  3. 10.] 
cards in discard: [10. 11.  0. 10.  1.  3.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10 10  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 27. 30. 24. 30.  8. 10.  9.  7.  3. 10. 10.  7. 10.  2.  9.  9.] 
adversary cards in hand: [22.  0.  8.  0.  3.] 
adversary cards in discard: [ 0.  0. 16.  3.  0.  3.  8.  0. 14.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10  8
  8 22  1  0  3 11  0  0  8] -> size -> 33 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 0 

action type: take_action - action -1
Learning step: -3.0167434215545654
desired expected reward: 103.99471282958984



buy possibilites: [-1] 
expected returns: [[142.61208]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  3. 10.] 
cards in discard: [10. 11.  0. 10.  1.  3.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10 10  3  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 24. 30.  8. 10.  9.  7.  3. 10. 10.  7. 10.  2.  9.  9.] 
adversary cards in hand: [22.  0.  8.  0.  3.] 
adversary cards in discard: [ 0.  0. 16.  3.  0.  3.  8.  0. 14.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10  8
  8 22  1  0  3 11  0  0  8] -> size -> 33 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -30 

action type: buy - action 0.0
Learning step: -3.0968995094299316
desired expected reward: 93.01651763916016






Player: 1 
cards in hand: [22.  0.  8.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  0.  8.  0.  3.] 
cards in discard: [ 0.  0. 16.  3.  0.  3.  8.  0. 14.  0.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10  8
  8 22  1  0  3 11  0  0  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 24. 30.  8. 10.  9.  7.  3. 10. 10.  7. 10.  2.  9.  9.] 
adversary cards in hand: [ 0.  8.  0.  8. 15.] 
adversary cards in discard: [10. 11.  0. 10.  1.  3.  3.  0. 11. 10. 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10 10  3  0] -> size -> 24 
adversary victory points: 5
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.] 
cards in discard: [ 0.  0. 16.  3.  0.  3.  8.  0. 14.  0.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10  8  8 22  1
  0  3 11  0  0  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 24. 30.  8. 10.  9.  7.  3. 10. 10.  7. 10.  2.  9.  9.] 
adversary cards in hand: [ 0.  8.  0.  8. 15.] 
adversary cards in discard: [10. 11.  0. 10.  1.  3.  3.  0. 11. 10. 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10 10  3  0] -> size -> 24 
adversary victory points: 5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.] 
cards in discard: [ 0.  0. 16.  3.  0.  3.  8.  0. 14.  0.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10  8  8 22  1
  0  3 11  0  0  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 27. 30. 24. 30.  8. 10.  9.  7.  3. 10. 10.  7. 10.  2.  9.  9.] 
adversary cards in hand: [ 0.  8.  0.  8. 15.] 
adversary cards in discard: [10. 11.  0. 10.  1.  3.  3.  0. 11. 10. 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10 10  3  0] -> size -> 24 
adversary victory points: 5
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.] 
cards in discard: [ 0.  0. 16.  3.  0.  3.  8.  0. 14.  0.  3.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10  8  8 22  1
  0  3 11  0  0  8  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 24. 30.  8. 10.  9.  7.  3. 10. 10.  7. 10.  2.  9.  9.] 
adversary cards in hand: [ 0.  8.  0.  8. 15.] 
adversary cards in discard: [10. 11.  0. 10.  1.  3.  3.  0. 11. 10. 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10 10  3  0] -> size -> 24 
adversary victory points: 5
player victory points: 6 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 0.  8.  0.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 15.] 
expected returns: [[140.52496]
 [126.06861]
 [126.06861]
 [129.00052]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0.  8. 15.] 
cards in discard: [10. 11.  0. 10.  1.  3.  3.  0. 11. 10. 10.  3. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10 10  3  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 24. 30.  8. 10.  9.  7.  3. 10. 10.  7. 10.  2.  9.  9.] 
adversary cards in hand: [ 1. 10.  1.  3. 11.] 
adversary cards in discard: [ 0.  0. 16.  3.  0.  3.  8.  0. 14.  0.  3.  0.  0.  8. 22.] 
adversary owned cards: [ 0  0  0  0  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10  8  8 22  1
  0  3 11  0  0  8  0] -> size -> 31 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -10 

action type: buy - action -1
Learning step: -4.5779547691345215
desired expected reward: 138.03411865234375



action possibilites: [-1] 
expected returns: [[142.57593]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8.] 
cards in discard: [10. 11.  0. 10.  1.  3.  3.  0. 11. 10. 10.  3. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10 10  3  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 27. 30. 24. 30.  8. 10.  9.  7.  3. 10. 10.  7. 10.  2.  9.  9.] 
adversary cards in hand: [ 1. 10.  1.  3. 11.] 
adversary cards in discard: [ 0.  0. 16.  3.  0.  3.  8.  0. 14.  0.  3.  0.  0.  8. 22.] 
adversary owned cards: [ 0  0  0  0  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10  8  8 22  1
  0  3 11  0  0  8  0] -> size -> 31 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 10 

action type: take_action - action 15.0
Learning step: -2.7420685291290283
desired expected reward: 126.25846862792969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[130.48088]
 [130.4944 ]
 [130.49065]
 [130.48088]
 [131.21999]
 [132.7164 ]
 [131.65814]
 [135.86638]
 [132.71803]
 [131.60503]
 [133.82939]
 [142.70581]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8.] 
cards in discard: [10. 11.  0. 10.  1.  3.  3.  0. 11. 10. 10.  3. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10 10  3  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 27. 30. 24. 30.  8. 10.  9.  7.  3. 10. 10.  7. 10.  2.  9.  9.] 
adversary cards in hand: [ 1. 10.  1.  3. 11.] 
adversary cards in discard: [ 0.  0. 16.  3.  0.  3.  8.  0. 14.  0.  3.  0.  0.  8. 22.] 
adversary owned cards: [ 0  0  0  0  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10  8  8 22  1
  0  3 11  0  0  8  0] -> size -> 31 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 10 

action type: take_action - action -1
Learning step: -3.5242812633514404
desired expected reward: 139.05165100097656






Player: 1 
cards in hand: [ 1. 10.  1.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  1.  3. 11.] 
cards in discard: [ 0.  0. 16.  3.  0.  3.  8.  0. 14.  0.  3.  0.  0.  8. 22.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10  8  8 22  1
  0  3 11  0  0  8  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 24. 30.  8. 10.  9.  7.  3. 10. 10.  7. 10.  2.  9.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [10. 11.  0. 10.  1.  3.  3.  0. 11. 10. 10.  3. 10. 15.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10 10  3  0] -> size -> 23 
adversary victory points: 5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  1.  3. 11.] 
cards in discard: [ 0.  0. 16.  3.  0.  3.  8.  0. 14.  0.  3.  0.  0.  8. 22.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10  8  8 22  1
  0  3 11  0  0  8  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 27. 30. 24. 30.  8. 10.  9.  7.  3. 10. 10.  7. 10.  2.  9.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [10. 11.  0. 10.  1.  3.  3.  0. 11. 10. 10.  3. 10. 15.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10 10  3  0] -> size -> 23 
adversary victory points: 5
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  1.  3. 11.] 
cards in discard: [ 0.  0. 16.  3.  0.  3.  8.  0. 14.  0.  3.  0.  0.  8. 22. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10  8  8 22  1
  0  3 11  0  0  8  0 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 24. 30.  8. 10.  9.  6.  3. 10. 10.  7. 10.  2.  9.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [10. 11.  0. 10.  1.  3.  3.  0. 11. 10. 10.  3. 10. 15.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10 10  3  0] -> size -> 23 
adversary victory points: 5
player victory points: 6 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[96.99771]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [10. 11.  0. 10.  1.  3.  3.  0. 11. 10. 10.  3. 10. 15.  8.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10 10  3  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 24. 30.  8. 10.  9.  6.  3. 10. 10.  7. 10.  2.  9.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 0.  0. 16.  3.  0.  3.  8.  0. 14.  0.  3.  0.  0.  8. 22. 11.  1. 10.
  1.  3. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10  8  8 22  1
  0  3 11  0  0  8  0 11] -> size -> 32 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -10 

action type: buy - action -1.0
Learning step: -5.4528422355651855
desired expected reward: 137.2529754638672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[87.52338 ]
 [87.53491 ]
 [87.531715]
 [87.52338 ]
 [89.456635]
 [88.54137 ]
 [88.495346]
 [97.79889 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [10. 11.  0. 10.  1.  3.  3.  0. 11. 10. 10.  3. 10. 15.  8.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10 10  3  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 27. 30. 24. 30.  8. 10.  9.  6.  3. 10. 10.  7. 10.  2.  9.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 0.  0. 16.  3.  0.  3.  8.  0. 14.  0.  3.  0.  0.  8. 22. 11.  1. 10.
  1.  3. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10  8  8 22  1
  0  3 11  0  0  8  0 11] -> size -> 32 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -10 

action type: take_action - action -1.0
Learning step: -3.241175889968872
desired expected reward: 93.75653839111328



buy possibilites: [-1] 
expected returns: [[101.13046]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [10. 11.  0. 10.  1.  3.  3.  0. 11. 10. 10.  3. 10. 15.  8.  0.  8.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10 10  3  0  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 24. 30.  8. 10.  9.  6.  2. 10. 10.  7. 10.  2.  9.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 0.  0. 16.  3.  0.  3.  8.  0. 14.  0.  3.  0.  0.  8. 22. 11.  1. 10.
  1.  3. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10  8  8 22  1
  0  3 11  0  0  8  0 11] -> size -> 32 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5.   0.   5. -10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -8.0 

action type: buy - action 8.0
Learning step: -2.55163311958313
desired expected reward: 85.98973083496094






Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 0.  0. 16.  3.  0.  3.  8.  0. 14.  0.  3.  0.  0.  8. 22. 11.  1. 10.
  1.  3. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10  8  8 22  1
  0  3 11  0  0  8  0 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 24. 30.  8. 10.  9.  6.  2. 10. 10.  7. 10.  2.  9.  9.] 
adversary cards in hand: [11. 10. 10.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10 10  3  0  8] -> size -> 24 
adversary victory points: 5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 0.  0. 16.  3.  0.  3.  8.  0. 14.  0.  3.  0.  0.  8. 22. 11.  1. 10.
  1.  3. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10  8  8 22  1
  0  3 11  0  0  8  0 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 27. 30. 24. 30.  8. 10.  9.  6.  2. 10. 10.  7. 10.  2.  9.  9.] 
adversary cards in hand: [11. 10. 10.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10 10  3  0  8] -> size -> 24 
adversary victory points: 5
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 0.  0. 16.  3.  0.  3.  8.  0. 14.  0.  3.  0.  0.  8. 22. 11.  1. 10.
  1.  3. 11.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10  8  8 22  1
  0  3 11  0  0  8  0 11  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 23. 30.  8. 10.  9.  6.  2. 10. 10.  7. 10.  2.  9.  9.] 
adversary cards in hand: [11. 10. 10.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10 10  3  0  8] -> size -> 24 
adversary victory points: 5
player victory points: 7 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [11. 10. 10.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10.  8.] 
expected returns: [[121.431755]
 [110.425385]
 [109.128525]
 [109.128525]
 [109.19027 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 10.  8.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10 10  1 11 15  8 10  3  8 10 10  3  0  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 23. 30.  8. 10.  9.  6.  2. 10. 10.  7. 10.  2.  9.  9.] 
adversary cards in hand: [ 8.  8. 14.  0. 10.] 
adversary cards in discard: [ 0.  0. 16.  3.  0.  3.  8.  0. 14.  0.  3.  0.  0.  8. 22. 11.  1. 10.
  1.  3. 11.  3.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10  8  8 22  1
  0  3 11  0  0  8  0 11  3] -> size -> 33 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -20 

action type: buy - action -1
Learning step: -3.4471328258514404
desired expected reward: 97.6833267211914



action possibilites: [-1] 
expected returns: [[132.29462]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 23. 30.  8. 10.  9.  6.  2. 10. 10.  7. 10.  2.  9.  9.] 
adversary cards in hand: [ 8.  8. 14.  0. 10.] 
adversary cards in discard: [ 0.  0. 16.  3.  0.  3.  8.  0. 14.  0.  3.  0.  0.  8. 22. 11.  1. 10.
  1.  3. 11.  3.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10  8  8 22  1
  0  3 11  0  0  8  0 11  3] -> size -> 33 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 0 

action type: trash_cards_n_from_hand - action 8
Learning step: -2.3614749908447266
desired expected reward: 104.40060424804688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[120.516266]
 [120.516266]
 [133.84479 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 27. 30. 23. 30.  8. 10.  9.  6.  2. 10. 10.  7. 10.  2.  9.  9.] 
adversary cards in hand: [ 8.  8. 14.  0. 10.] 
adversary cards in discard: [ 0.  0. 16.  3.  0.  3.  8.  0. 14.  0.  3.  0.  0.  8. 22. 11.  1. 10.
  1.  3. 11.  3.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10  8  8 22  1
  0  3 11  0  0  8  0 11  3] -> size -> 33 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 0 

action type: take_action - action -1
Learning step: -3.699172258377075
desired expected reward: 128.59544372558594






Player: 1 
cards in hand: [ 8.  8. 14.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 14. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 14.  0. 10.] 
cards in discard: [ 0.  0. 16.  3.  0.  3.  8.  0. 14.  0.  3.  0.  0.  8. 22. 11.  1. 10.
  1.  3. 11.  3.  0.  3.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  3  0  3 14  0 16  8  8  1  0  3 14 10  8  8 22  1
  0  3 11  0  0  8  0 11  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 23. 30.  8. 10.  9.  6.  2. 10. 10.  7. 10.  2.  9.  9.] 
adversary cards in hand: [10. 10.  0.  8.  3.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8] -> size -> 21 
adversary victory points: 5
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [ 0.  0. 16.  3.  0.  3.  8.  0. 14.  0.  3.  0.  0.  8. 22. 11.  1. 10.
  1.  3. 11.  3.  0.  3.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  0  3  0 16  8  8  1  0  3 14 10  8  8 22  1  0  3
 11  0  0  8  0 11  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 23. 30.  8. 10.  9.  6.  2. 10. 10.  7. 10.  2.  9.  9.] 
adversary cards in hand: [10. 10.  0.  8.  3.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8] -> size -> 21 
adversary victory points: 5
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [ 0.  0. 16.  3.  0.  3.  8.  0. 14.  0.  3.  0.  0.  8. 22. 11.  1. 10.
  1.  3. 11.  3.  0.  3.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  0  3  0 16  8  8  1  0  3 14 10  8  8 22  1  0  3
 11  0  0  8  0 11  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 27. 30. 23. 30.  8. 10.  9.  6.  2. 10. 10.  7. 10.  2.  9.  9.] 
adversary cards in hand: [10. 10.  0.  8.  3.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8] -> size -> 21 
adversary victory points: 5
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [ 0.  0. 16.  3.  0.  3.  8.  0. 14.  0.  3.  0.  0.  8. 22. 11.  1. 10.
  1.  3. 11.  3.  0.  3.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  0  3  0 16  8  8  1  0  3 14 10  8  8 22  1  0  3
 11  0  0  8  0 11  3  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 27. 30. 23. 30.  8. 10.  9.  6.  2. 10. 10.  7. 10.  2.  9.  9.] 
adversary cards in hand: [10. 10.  0.  8.  3.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8] -> size -> 21 
adversary victory points: 5
player victory points: 7 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [10. 10.  0.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.  8.] 
expected returns: [[146.95164]
 [134.1837 ]
 [134.1837 ]
 [134.24722]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  8.  3.] 
cards in discard: [8. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 23. 30.  8. 10.  9.  6.  2. 10. 10.  7. 10.  2.  9.  9.] 
adversary cards in hand: [0. 3. 0. 1. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  3  0 16  8  8  1  0  3 14 10  8  8 22  1  0  3
 11  0  0  8  0 11  3  0] -> size -> 32 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -20 

action type: buy - action -1.0
Learning step: -4.508025169372559
desired expected reward: 129.33677673339844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[133.64531]
 [133.64531]
 [147.75148]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  8.  3.] 
cards in discard: [8. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 27. 30. 23. 30.  8. 10.  9.  6.  2. 10. 10.  7. 10.  2.  9.  9.] 
adversary cards in hand: [0. 3. 0. 1. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  3  0 16  8  8  1  0  3 14 10  8  8 22  1  0  3
 11  0  0  8  0 11  3  0] -> size -> 32 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -20 

action type: take_action - action -1.0
Learning step: -5.082723140716553
desired expected reward: 141.02896118164062



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 3. 0. 1. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 1. 8.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  3  0 16  8  8  1  0  3 14 10  8  8 22  1  0  3
 11  0  0  8  0 11  3  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 23. 30.  8. 10.  9.  6.  2. 10. 10.  7. 10.  2.  9.  9.] 
adversary cards in hand: [10.  3.  0.  3. 15.] 
adversary cards in discard: [ 8.  0. 10. 10.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8] -> size -> 21 
adversary victory points: 5
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  0  3  0 16  8  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8
  0 11  3  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 23. 30.  8. 10.  9.  6.  2. 10. 10.  7. 10.  2.  9.  9.] 
adversary cards in hand: [10.  3.  0.  3. 15.] 
adversary cards in discard: [ 8.  0. 10. 10.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8] -> size -> 21 
adversary victory points: 5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  0  3  0 16  8  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8
  0 11  3  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 27. 30. 23. 30.  8. 10.  9.  6.  2. 10. 10.  7. 10.  2.  9.  9.] 
adversary cards in hand: [10.  3.  0.  3. 15.] 
adversary cards in discard: [ 8.  0. 10. 10.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8] -> size -> 21 
adversary victory points: 5
player victory points: 6 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [10.  3.  0.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
expected returns: [[202.22133]
 [186.4639 ]
 [189.75377]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  3. 15.] 
cards in discard: [ 8.  0. 10. 10.  0.  8.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 23. 30.  8. 10.  9.  6.  2. 10. 10.  7. 10.  2.  9.  9.] 
adversary cards in hand: [ 8. 11.  8.  3. 22.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 0  0  3  3  0  3  0 16  8  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8
  0 11  3  0] -> size -> 28 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -10 

action type: buy - action -1.0
Learning step: -3.467585802078247
desired expected reward: 144.2838897705078



action possibilites: [-1. 15.] 
expected returns: [[162.88725]
 [154.17555]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 15.  0.] 
cards in discard: [ 8.  0. 10. 10.  0.  8.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 23. 30.  8. 10.  9.  6.  2. 10. 10.  7. 10.  2.  9.  9.] 
adversary cards in hand: [ 8. 11.  8.  3. 22.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 0  0  3  3  0  3  0 16  8  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8
  0 11  3  0] -> size -> 28 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: 11 

action type: take_action - action 10.0
Learning step: -4.939153671264648
desired expected reward: 177.20248413085938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[149.98036]
 [149.98926]
 [149.98036]
 [151.12344]
 [162.0264 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 15.  0.] 
cards in discard: [ 8.  0. 10. 10.  0.  8.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 27. 30. 23. 30.  8. 10.  9.  6.  2. 10. 10.  7. 10.  2.  9.  9.] 
adversary cards in hand: [ 8. 11.  8.  3. 22.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 0  0  3  3  0  3  0 16  8  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8
  0 11  3  0] -> size -> 28 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 10 

action type: take_action - action -1.0
Learning step: -4.100342273712158
desired expected reward: 158.78692626953125






Player: 1 
cards in hand: [ 8. 11.  8.  3. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.  8. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  8.  3. 22.] 
cards in discard: [8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  3  0 16  8  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8
  0 11  3  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 23. 30.  8. 10.  9.  6.  2. 10. 10.  7. 10.  2.  9.  9.] 
adversary cards in hand: [ 0.  3. 11.  0.  8.] 
adversary cards in discard: [ 8.  0. 10. 10.  0.  8.  3. 10.  3.  0.  3. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8] -> size -> 21 
adversary victory points: 5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  8.  3. 22.] 
cards in discard: [8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  3  0 16  8  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8
  0 11  3  0] -> size -> 28 
action values: 1 
buys: 1 
player value: 0 
card supply: [21. 27. 30. 23. 30.  8. 10.  9.  6.  2. 10. 10.  7. 10.  2.  9.  9.] 
adversary cards in hand: [ 0.  3. 11.  0.  8.] 
adversary cards in discard: [ 8.  0. 10. 10.  0.  8.  3. 10.  3.  0.  3. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8] -> size -> 21 
adversary victory points: 5
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 11.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[132.5651 ]
 [121.38795]
 [120.17719]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  0.  8.] 
cards in discard: [ 8.  0. 10. 10.  0.  8.  3. 10.  3.  0.  3. 15.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 23. 30.  8. 10.  9.  6.  2. 10. 10.  7. 10.  2.  9.  9.] 
adversary cards in hand: [ 0.  3.  0. 14.  0.] 
adversary cards in discard: [ 8.  8. 11.  8.  3. 22.] 
adversary owned cards: [ 0  0  3  3  0  3  0 16  8  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8
  0 11  3  0] -> size -> 28 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -10 

action type: buy - action -1.0
Learning step: -5.703425407409668
desired expected reward: 156.32296752929688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[118.81076 ]
 [118.82107 ]
 [118.81076 ]
 [120.160835]
 [132.42256 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  0.  8.] 
cards in discard: [ 8.  0. 10. 10.  0.  8.  3. 10.  3.  0.  3. 15.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 27. 30. 23. 30.  8. 10.  9.  6.  2. 10. 10.  7. 10.  2.  9.  9.] 
adversary cards in hand: [ 0.  3.  0. 14.  0.] 
adversary cards in discard: [ 8.  8. 11.  8.  3. 22.] 
adversary owned cards: [ 0  0  3  3  0  3  0 16  8  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8
  0 11  3  0] -> size -> 28 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -10 

action type: take_action - action -1.0
Learning step: -4.263396739959717
desired expected reward: 128.3017120361328



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 14.  0.] 
cards in discard: [ 8.  8. 11.  8.  3. 22.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  3  0 16  8  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8
  0 11  3  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 23. 30.  8. 10.  9.  6.  2. 10. 10.  7. 10.  2.  9.  9.] 
adversary cards in hand: [10.  0.  0.  3.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8] -> size -> 21 
adversary victory points: 5
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [ 8.  8. 11.  8.  3. 22.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3  0  3  0 16  8  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8
  0 11  3  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 27. 30. 23. 30.  8. 10.  9.  6.  2. 10. 10.  7. 10.  2.  9.  9.] 
adversary cards in hand: [10.  0.  1.] 
adversary cards in discard: [0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8] -> size -> 21 
adversary victory points: 5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [ 8.  8. 11.  8.  3. 22.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3  0  3  0 16  8  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8
  0 11  3  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 27. 30. 23. 30.  8. 10.  9.  6.  2. 10. 10.  7. 10.  2.  9.  9.] 
adversary cards in hand: [10.  0.  1.] 
adversary cards in discard: [0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8] -> size -> 21 
adversary victory points: 5
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [ 8.  8. 11.  8.  3. 22. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3  0  3  0 16  8  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8
  0 11  3  0 29] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 27. 30. 23. 30.  8. 10.  9.  6.  2. 10.  9.  7. 10.  2.  9.  9.] 
adversary cards in hand: [10.  0.  1.] 
adversary cards in discard: [0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8] -> size -> 21 
adversary victory points: 5
player victory points: 6 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [10.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[188.92969]
 [176.25432]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  1.] 
cards in discard: [0. 3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 23. 30.  8. 10.  9.  6.  2. 10.  9.  7. 10.  2.  9.  9.] 
adversary cards in hand: [10.  0.  3.  0.  3.] 
adversary cards in discard: [ 8.  8. 11.  8.  3. 22. 29. 14.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  3  3  0  3  0 16  8  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8
  0 11  3  0 29] -> size -> 29 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -10 

action type: discard_down_to_3_cards - action 3
Learning step: -0.5521480441093445
desired expected reward: 83.37586975097656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[171.50757]
 [171.5236 ]
 [171.51869]
 [171.50757]
 [174.20905]
 [172.93118]
 [172.86577]
 [185.54114]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  1.] 
cards in discard: [0. 3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 27. 30. 23. 30.  8. 10.  9.  6.  2. 10.  9.  7. 10.  2.  9.  9.] 
adversary cards in hand: [10.  0.  3.  0.  3.] 
adversary cards in discard: [ 8.  8. 11.  8.  3. 22. 29. 14.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  3  3  0  3  0 16  8  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8
  0 11  3  0 29] -> size -> 29 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -10 

action type: take_action - action -1.0
Learning step: -5.812011241912842
desired expected reward: 181.41856384277344



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10.  0.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.  3.] 
cards in discard: [ 8.  8. 11.  8.  3. 22. 29. 14.  0.  3.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  3  0 16  8  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8
  0 11  3  0 29] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 23. 30.  8. 10.  9.  6.  2. 10.  9.  7. 10.  2.  9.  9.] 
adversary cards in hand: [ 3.  0. 11.  3.  3.] 
adversary cards in discard: [ 0.  3. 10.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8] -> size -> 21 
adversary victory points: 5
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [ 8.  8. 11.  8.  3. 22. 29. 14.  0.  3.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  0  3  0 16  8  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8
  0 11  3  0 29] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 23. 30.  8. 10.  9.  6.  2. 10.  9.  7. 10.  2.  9.  9.] 
adversary cards in hand: [ 3.  0. 11.  3.  3.] 
adversary cards in discard: [ 0.  3. 10.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8] -> size -> 21 
adversary victory points: 5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [ 8.  8. 11.  8.  3. 22. 29. 14.  0.  3.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  0  3  0 16  8  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8
  0 11  3  0 29] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 27. 30. 23. 30.  8. 10.  9.  6.  2. 10.  9.  7. 10.  2.  9.  9.] 
adversary cards in hand: [ 3.  0. 11.  3.  3.] 
adversary cards in discard: [ 0.  3. 10.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8] -> size -> 21 
adversary victory points: 5
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [ 8.  8. 11.  8.  3. 22. 29. 14.  0.  3.  0.  0.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  0  3  0 16  8  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8
  0 11  3  0 29  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 23. 30.  8. 10.  9.  6.  1. 10.  9.  7. 10.  2.  9.  9.] 
adversary cards in hand: [ 3.  0. 11.  3.  3.] 
adversary cards in discard: [ 0.  3. 10.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8] -> size -> 21 
adversary victory points: 5
player victory points: 6 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 11.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[172.40628]
 [162.5861 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  3.  3.] 
cards in discard: [ 0.  3. 10.  0.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 23. 30.  8. 10.  9.  6.  1. 10.  9.  7. 10.  2.  9.  9.] 
adversary cards in hand: [16.  1.  8.  8.  0.] 
adversary cards in discard: [ 8.  8. 11.  8.  3. 22. 29. 14.  0.  3.  0.  0.  8. 10.  0.  3.  0.  3.
  3.] 
adversary owned cards: [ 0  0  3  3  0  3  0 16  8  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8
  0 11  3  0 29  8] -> size -> 30 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -10 

action type: buy - action -1.0
Learning step: -5.977687835693359
desired expected reward: 179.56344604492188



action possibilites: [-1] 
expected returns: [[217.40126]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3.] 
cards in discard: [ 0.  3. 10.  0.  1. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 23. 30.  8. 10.  9.  6.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [16.  1.  8.  8.  0.] 
adversary cards in discard: [ 8.  8. 11.  8.  3. 22. 29. 14.  0.  3.  0.  0.  8. 10.  0.  3.  0.  3.
  3.] 
adversary owned cards: [ 0  0  3  3  0  3  0 16  8  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8
  0 11  3  0 29  8] -> size -> 30 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: 19 

action type: gain_card_n - action 9
Learning step: -2.233657121658325
desired expected reward: 159.27005004882812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[200.51695]
 [200.51695]
 [217.84123]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3.] 
cards in discard: [ 0.  3. 10.  0.  1. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 27. 30. 23. 30.  8. 10.  9.  6.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [16.  1.  8.  8.  0.] 
adversary cards in discard: [ 8.  8. 11.  8.  3. 22. 29. 14.  0.  3.  0.  0.  8. 10.  0.  3.  0.  3.
  3.] 
adversary owned cards: [ 0  0  3  3  0  3  0 16  8  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8
  0 11  3  0 29  8] -> size -> 30 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 10 

action type: take_action - action -1
Learning step: -5.593348979949951
desired expected reward: 211.8079071044922






Player: 1 
cards in hand: [16.  1.  8.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  1.  8.  8.  0.] 
cards in discard: [ 8.  8. 11.  8.  3. 22. 29. 14.  0.  3.  0.  0.  8. 10.  0.  3.  0.  3.
  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  3  0 16  8  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8
  0 11  3  0 29  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 23. 30.  8. 10.  9.  6.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 8.  0. 10.  0.  0.] 
adversary cards in discard: [ 0.  3. 10.  0.  1. 10. 11.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8 10] -> size -> 22 
adversary victory points: 5
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  1.  0.] 
cards in discard: [ 8.  8. 11.  8.  3. 22. 29. 14.  0.  3.  0.  0.  8. 10.  0.  3.  0.  3.
  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  0  3  0 16  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8  0
 11  3  0 29  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 23. 30.  8. 10.  9.  6.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 8.  0. 10.  0.  0.] 
adversary cards in discard: [ 0.  3. 10.  0.  1. 10. 11.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8 10] -> size -> 22 
adversary victory points: 5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  1.  0.] 
cards in discard: [ 8.  8. 11.  8.  3. 22. 29. 14.  0.  3.  0.  0.  8. 10.  0.  3.  0.  3.
  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  0  3  0 16  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8  0
 11  3  0 29  8] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 27. 30. 23. 30.  8. 10.  9.  6.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 8.  0. 10.  0.  0.] 
adversary cards in discard: [ 0.  3. 10.  0.  1. 10. 11.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8 10] -> size -> 22 
adversary victory points: 5
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  1.  0.] 
cards in discard: [ 8.  8. 11.  8.  3. 22. 29. 14.  0.  3.  0.  0.  8. 10.  0.  3.  0.  3.
  3. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  0  3  0 16  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8  0
 11  3  0 29  8 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 23. 30.  8. 10.  9.  5.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 8.  0. 10.  0.  0.] 
adversary cards in discard: [ 0.  3. 10.  0.  1. 10. 11.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8 10] -> size -> 22 
adversary victory points: 5
player victory points: 6 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[127.306435]
 [117.283   ]
 [117.23597 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  0.  0.] 
cards in discard: [ 0.  3. 10.  0.  1. 10. 11.  3.  0.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 23. 30.  8. 10.  9.  5.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 8.  8. 11.  8.  3. 22. 29. 14.  0.  3.  0.  0.  8. 10.  0.  3.  0.  3.
  3. 11.  8. 16.  1.  0.] 
adversary owned cards: [ 0  0  3  3  0  3  0 16  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8  0
 11  3  0 29  8 11] -> size -> 30 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -10 

action type: buy - action -1.0
Learning step: -8.599993705749512
desired expected reward: 209.24124145507812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[117.57613 ]
 [117.58897 ]
 [117.584724]
 [117.57613 ]
 [119.703835]
 [118.691635]
 [118.63957 ]
 [128.88737 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10.  0.  0.] 
cards in discard: [ 0.  3. 10.  0.  1. 10. 11.  3.  0.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 27. 30. 23. 30.  8. 10.  9.  5.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 8.  8. 11.  8.  3. 22. 29. 14.  0.  3.  0.  0.  8. 10.  0.  3.  0.  3.
  3. 11.  8. 16.  1.  0.] 
adversary owned cards: [ 0  0  3  3  0  3  0 16  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8  0
 11  3  0 29  8 11] -> size -> 30 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -10 

action type: take_action - action -1.0
Learning step: -4.066387176513672
desired expected reward: 123.24005126953125



buy possibilites: [-1] 
expected returns: [[143.81758]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10.  0.  0.] 
cards in discard: [ 0.  3. 10.  0.  1. 10. 11.  3.  0.  3.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8 10  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 27. 30. 22. 30.  8. 10.  9.  5.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 8.  8. 11.  8.  3. 22. 29. 14.  0.  3.  0.  0.  8. 10.  0.  3.  0.  3.
  3. 11.  8. 16.  1.  0.] 
adversary owned cards: [ 0  0  3  3  0  3  0 16  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8  0
 11  3  0 29  8 11] -> size -> 30 
adversary victory points: 6
player victory points: 6 

Reward from previous game state: 
[-5.  0.  6.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 3.0 

action type: buy - action 3.0
Learning step: -2.4933414459228516
desired expected reward: 115.09140014648438






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 8.  8. 11.  8.  3. 22. 29. 14.  0.  3.  0.  0.  8. 10.  0.  3.  0.  3.
  3. 11.  8. 16.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  3  0 16  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8  0
 11  3  0 29  8 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 22. 30.  8. 10.  9.  5.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [15. 10.  8.  3.  8.] 
adversary cards in discard: [ 0.  3. 10.  0.  1. 10. 11.  3.  0.  3.  3.  3.  8.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8 10  3] -> size -> 23 
adversary victory points: 6
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 8.  8. 11.  8.  3. 22. 29. 14.  0.  3.  0.  0.  8. 10.  0.  3.  0.  3.
  3. 11.  8. 16.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  3  0 16  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8  0
 11  3  0 29  8 11] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 27. 30. 22. 30.  8. 10.  9.  5.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [15. 10.  8.  3.  8.] 
adversary cards in discard: [ 0.  3. 10.  0.  1. 10. 11.  3.  0.  3.  3.  3.  8.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8 10  3] -> size -> 23 
adversary victory points: 6
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 8.  8. 11.  8.  3. 22. 29. 14.  0.  3.  0.  0.  8. 10.  0.  3.  0.  3.
  3. 11.  8. 16.  1.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  3  0 16  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8  0
 11  3  0 29  8 11 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 27. 30. 22. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [15. 10.  8.  3.  8.] 
adversary cards in discard: [ 0.  3. 10.  0.  1. 10. 11.  3.  0.  3.  3.  3.  8.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8 10  3] -> size -> 23 
adversary victory points: 6
player victory points: 6 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [15. 10.  8.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.  8.  8.] 
expected returns: [[80.726685]
 [73.24903 ]
 [71.26977 ]
 [71.31764 ]
 [71.31764 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  8.  3.  8.] 
cards in discard: [ 0.  3. 10.  0.  1. 10. 11.  3.  0.  3.  3.  3.  8.  0. 10.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8 10  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 22. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 8.  0.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0  3  0 16  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8  0
 11  3  0 29  8 11 11] -> size -> 31 
adversary victory points: 6
player victory points: 6 

Reward from previous game state: 
[-5  0  6  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 1 

action type: buy - action -1
Learning step: -5.401741027832031
desired expected reward: 138.41583251953125



action possibilites: [-1. 15.  8.  8.] 
expected returns: [[145.60715]
 [136.3857 ]
 [133.98676]
 [133.98676]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  3.  8.  0.] 
cards in discard: [ 0.  3. 10.  0.  1. 10. 11.  3.  0.  3.  3.  3.  8.  0. 10.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8 10  3] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 22. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 8.  0.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0  3  0 16  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8  0
 11  3  0 29  8 11 11] -> size -> 31 
adversary victory points: 6
player victory points: 6 

Reward from previous game state: 
[-5  0  6  0  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 22 

action type: take_action - action 10.0
Learning step: 0.753727376461029
desired expected reward: 72.02349853515625



action possibilites: [-1.  8.  8.] 
expected returns: [[112.96152]
 [102.36415]
 [102.36415]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 8.] 
cards in discard: [ 0.  3. 10.  0.  1. 10. 11.  3.  0.  3.  3.  3.  8.  0. 10.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8 10  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 3 
card supply: [21. 27. 30. 22. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 8.  0.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0  3  0 16  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8  0
 11  3  0 29  8 11 11] -> size -> 31 
adversary victory points: 6
player victory points: 6 

Reward from previous game state: 
[-5  0  6  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 41 

action type: take_action - action 15.0
Learning step: -2.303938388824463
desired expected reward: 134.0817413330078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[101.962494]
 [101.97474 ]
 [101.97    ]
 [101.962494]
 [104.0341  ]
 [103.05658 ]
 [103.00416 ]
 [113.62653 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 8.] 
cards in discard: [ 0.  3. 10.  0.  1. 10. 11.  3.  0.  3.  3.  3.  8.  0. 10.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8 10  3] -> size -> 22 
action values: 1 
buys: 1 
player value: 3 
card supply: [21. 27. 30. 22. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 8.  0.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0  3  0 16  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8  0
 11  3  0 29  8 11 11] -> size -> 31 
adversary victory points: 6
player victory points: 6 

Reward from previous game state: 
[-5  0  6  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 41 

action type: take_action - action -1.0
Learning step: -1.1459797620773315
desired expected reward: 111.8155288696289






Player: 1 
cards in hand: [ 8.  0.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  3  0 16  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8  0
 11  3  0 29  8 11 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 22. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [10.  1. 11.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8 10  3] -> size -> 22 
adversary victory points: 6
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  3  0 16  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8  0
 11  3  0 29  8 11 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 27. 30. 22. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [10.  1. 11.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8 10  3] -> size -> 22 
adversary victory points: 6
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3.  0. 11.] 
cards in discard: [0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  3  0 16  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8  0
 11  3  0 29  8 11 11  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 27. 30. 22. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [10.  1. 11.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8 10  3] -> size -> 22 
adversary victory points: 6
player victory points: 6 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [10.  1. 11.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.  8.] 
expected returns: [[109.94076]
 [ 99.97337]
 [100.98481]
 [100.02425]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1. 11.  8.  3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8 10  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 22. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 0. 10.  0.  3.  8.] 
adversary cards in discard: [ 0.  8.  0.  3.  0. 11.] 
adversary owned cards: [ 0  0  3  3  0  3  0 16  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8  0
 11  3  0 29  8 11 11  0] -> size -> 32 
adversary victory points: 6
player victory points: 6 

Reward from previous game state: 
[-5  0  6  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 1 

action type: buy - action -1.0
Learning step: -3.2506721019744873
desired expected reward: 110.3758544921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 99.13789]
 [ 99.14518]
 [ 99.13789]
 [100.20391]
 [110.11541]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1. 11.  8.  3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8 10  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 27. 30. 22. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 0. 10.  0.  3.  8.] 
adversary cards in discard: [ 0.  8.  0.  3.  0. 11.] 
adversary owned cards: [ 0  0  3  3  0  3  0 16  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8  0
 11  3  0 29  8 11 11  0] -> size -> 32 
adversary victory points: 6
player victory points: 6 

Reward from previous game state: 
[-5  0  6  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 1 

action type: take_action - action -1.0
Learning step: -3.02730393409729
desired expected reward: 106.22046661376953



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 10.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3.  8.] 
cards in discard: [ 0.  8.  0.  3.  0. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  3  0 16  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8  0
 11  3  0 29  8 11 11  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 22. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [10.  1. 11.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8 10  3] -> size -> 22 
adversary victory points: 6
player victory points: 6 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 0.] 
cards in discard: [ 0.  8.  0.  3.  0. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  0  3  0 16  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8  0
 11  3  0 29  8 11 11  0] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 22. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [10.  1. 11.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8 10  3] -> size -> 22 
adversary victory points: 6
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0.  8.  0.  3.  0. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3  0  3  0 16  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8  0 11  3  0
 29  8 11 11  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 22. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [10.  1. 11.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8 10  3] -> size -> 22 
adversary victory points: 6
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  8.  0.  3.  0. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3  0  3  0 16  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8  0 11  3  0
 29  8 11 11  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 27. 30. 22. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [10.  1. 11.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8 10  3] -> size -> 22 
adversary victory points: 6
player victory points: 5 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[167.01862]
 [156.97675]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  3.] 
cards in discard: [10.  1. 11.  8.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8 10  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 22. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 3. 11.  8.  0.  8.] 
adversary cards in discard: [ 0.  8.  0.  3.  0. 11. 10.  8.  0.] 
adversary owned cards: [ 3  0  3  0 16  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8  0 11  3  0
 29  8 11 11  0] -> size -> 29 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  6 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 11 

action type: buy - action -1.0
Learning step: -1.278262734413147
desired expected reward: 108.83714294433594



action possibilites: [-1. 10.] 
expected returns: [[117.20091]
 [107.65483]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 10.] 
cards in discard: [10.  1. 11.  8.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8 10  3] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 22. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 3. 11.  8.  0.  8.] 
adversary cards in discard: [ 0.  8.  0.  3.  0. 11. 10.  8.  0.] 
adversary owned cards: [ 3  0  3  0 16  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8  0 11  3  0
 29  8 11 11  0] -> size -> 29 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  6 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 31 

action type: take_action - action 10.0
Learning step: -3.6551480293273926
desired expected reward: 152.15740966796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[106.39911 ]
 [106.41102 ]
 [106.4064  ]
 [106.39911 ]
 [108.42061 ]
 [107.46696 ]
 [107.416115]
 [116.92111 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 10.] 
cards in discard: [10.  1. 11.  8.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8 10  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 27. 30. 22. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 3. 11.  8.  0.  8.] 
adversary cards in discard: [ 0.  8.  0.  3.  0. 11. 10.  8.  0.] 
adversary owned cards: [ 3  0  3  0 16  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8  0 11  3  0
 29  8 11 11  0] -> size -> 29 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  6 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 31 

action type: take_action - action -1.0
Learning step: -1.7731682062149048
desired expected reward: 115.42774200439453



buy possibilites: [-1] 
expected returns: [[159.73648]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 10.] 
cards in discard: [10.  1. 11.  8.  3.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8 10  3  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 27. 30. 21. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 3. 11.  8.  0.  8.] 
adversary cards in discard: [ 0.  8.  0.  3.  0. 11. 10.  8.  0.] 
adversary owned cards: [ 3  0  3  0 16  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8  0 11  3  0
 29  8 11 11  0] -> size -> 29 
adversary victory points: 5
player victory points: 7 

Reward from previous game state: 
[-5.  0.  7. 20.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 44.0 

action type: buy - action 3.0
Learning step: 0.4737503230571747
desired expected reward: 106.88015747070312






Player: 1 
cards in hand: [ 3. 11.  8.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  8.  0.  8.] 
cards in discard: [ 0.  8.  0.  3.  0. 11. 10.  8.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  3  0 16  8  0  3 14 10  8  8 22  1  0  3 11  0  0  8  0 11  3  0
 29  8 11 11  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 21. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [10.  1. 11.  8.  3.  3. 10.  0.  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8 10  3  3] -> size -> 23 
adversary victory points: 7
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0.  8.  0.  3.  0. 11. 10.  8.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  0 16  0  3 14 10  8  8 22  1  0  3  0  0  8  0 11  3  0 29  8 11
 11  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 21. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [10.  1. 11.  8.  3.  3. 10.  0.  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8 10  3  3] -> size -> 23 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  8.  0.  3.  0. 11. 10.  8.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  0 16  0  3 14 10  8  8 22  1  0  3  0  0  8  0 11  3  0 29  8 11
 11  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 27. 30. 21. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [10.  1. 11.  8.  3.  3. 10.  0.  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8 10  3  3] -> size -> 23 
adversary victory points: 7
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  8.  0.  3.  0. 11. 10.  8.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  0 16  0  3 14 10  8  8 22  1  0  3  0  0  8  0 11  3  0 29  8 11
 11  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 27. 30. 21. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [10.  1. 11.  8.  3.  3. 10.  0.  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8 10  3  3] -> size -> 23 
adversary victory points: 7
player victory points: 4 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[121.15668]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [10.  1. 11.  8.  3.  3. 10.  0.  0.  0.  3. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8 10  3  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 21. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 1.  3. 14.  0. 16.] 
adversary cards in discard: [ 0.  8.  0.  3.  0. 11. 10.  8.  0.  0.  8.  0.] 
adversary owned cards: [ 0  3  0 16  0  3 14 10  8  8 22  1  0  3  0  0  8  0 11  3  0 29  8 11
 11  0  0] -> size -> 27 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  7 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 32 

action type: buy - action -1
Learning step: -3.6607987880706787
desired expected reward: 156.07568359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[109.75225 ]
 [109.759766]
 [109.75225 ]
 [110.84955 ]
 [120.99644 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [10.  1. 11.  8.  3.  3. 10.  0.  0.  0.  3. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8 10  3  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 27. 30. 21. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 1.  3. 14.  0. 16.] 
adversary cards in discard: [ 0.  8.  0.  3.  0. 11. 10.  8.  0.  0.  8.  0.] 
adversary owned cards: [ 0  3  0 16  0  3 14 10  8  8 22  1  0  3  0  0  8  0 11  3  0 29  8 11
 11  0  0] -> size -> 27 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  7 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 32 

action type: take_action - action -1.0
Learning step: -1.830161690711975
desired expected reward: 119.3265151977539



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 1.  3. 14.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 14.  0. 16.] 
cards in discard: [ 0.  8.  0.  3.  0. 11. 10.  8.  0.  0.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 16  0  3 14 10  8  8 22  1  0  3  0  0  8  0 11  3  0 29  8 11
 11  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 21. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [10.  0.  3. 15.  8.] 
adversary cards in discard: [10.  1. 11.  8.  3.  3. 10.  0.  0.  0.  3. 10.  0.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8 10  3  3] -> size -> 23 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 14.  0. 16.] 
cards in discard: [ 0.  8.  0.  3.  0. 11. 10.  8.  0.  0.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 16  0  3 14 10  8  8 22  1  0  3  0  0  8  0 11  3  0 29  8 11
 11  0  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 27. 30. 21. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [10.  0.  3. 15.  8.] 
adversary cards in discard: [10.  1. 11.  8.  3.  3. 10.  0.  0.  0.  3. 10.  0.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8 10  3  3] -> size -> 23 
adversary victory points: 7
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 14.  0. 16.] 
cards in discard: [ 0.  8.  0.  3.  0. 11. 10.  8.  0.  0.  8.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 16  0  3 14 10  8  8 22  1  0  3  0  0  8  0 11  3  0 29  8 11
 11  0  0  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 27. 30. 20. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [10.  0.  3. 15.  8.] 
adversary cards in discard: [10.  1. 11.  8.  3.  3. 10.  0.  0.  0.  3. 10.  0.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8 10  3  3] -> size -> 23 
adversary victory points: 7
player victory points: 5 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [10.  0.  3. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.  8.] 
expected returns: [[100.69444 ]
 [ 91.77292 ]
 [ 93.66412 ]
 [ 91.820915]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3. 15.  8.] 
cards in discard: [10.  1. 11.  8.  3.  3. 10.  0.  0.  0.  3. 10.  0.  3.  0.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11 15  8 10  3  8 10 10  3  0  8 10  3  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 20. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [11.  0.  0.  8. 11.] 
adversary cards in discard: [ 0.  8.  0.  3.  0. 11. 10.  8.  0.  0.  8.  0.  3.  1.  3. 14.  0. 16.] 
adversary owned cards: [ 0  3  0 16  0  3 14 10  8  8 22  1  0  3  0  0  8  0 11  3  0 29  8 11
 11  0  0  3] -> size -> 28 
adversary victory points: 5
player victory points: 7 

Reward from previous game state: 
[-5  0  7 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 22 

action type: buy - action -1.0
Learning step: -2.751213788986206
desired expected reward: 118.2452163696289



action possibilites: [-1] 
expected returns: [[111.398964]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.] 
cards in discard: [10.  1. 11.  8.  3.  3. 10.  0.  0.  0.  3. 10.  0.  3.  0.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  1 11 15  8  3  8 10 10  3  0  8 10  3  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 20. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [11.  0.  0.  8. 11.] 
adversary cards in discard: [ 0.  8.  0.  3.  0. 11. 10.  8.  0.  0.  8.  0.  3.  1.  3. 14.  0. 16.] 
adversary owned cards: [ 0  3  0 16  0  3 14 10  8  8 22  1  0  3  0  0  8  0 11  3  0 29  8 11
 11  0  0  3] -> size -> 28 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  6 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 31 

action type: trash_cards_n_from_hand - action 13
Learning step: -0.606977105140686
desired expected reward: 92.66209411621094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[100.13666 ]
 [100.13666 ]
 [113.236305]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [10.  1. 11.  8.  3.  3. 10.  0.  0.  0.  3. 10.  0.  3.  0.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  1 11 15  8  3  8 10 10  3  0  8 10  3  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 27. 30. 20. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [11.  0.  0.  8. 11.] 
adversary cards in discard: [ 0.  8.  0.  3.  0. 11. 10.  8.  0.  0.  8.  0.  3.  1.  3. 14.  0. 16.] 
adversary owned cards: [ 0  3  0 16  0  3 14 10  8  8 22  1  0  3  0  0  8  0 11  3  0 29  8 11
 11  0  0  3] -> size -> 28 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  6 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 31 

action type: take_action - action -1
Learning step: -1.566433310508728
desired expected reward: 109.83252716064453






Player: 1 
cards in hand: [11.  0.  0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  8. 11.] 
cards in discard: [ 0.  8.  0.  3.  0. 11. 10.  8.  0.  0.  8.  0.  3.  1.  3. 14.  0. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 16  0  3 14 10  8  8 22  1  0  3  0  0  8  0 11  3  0 29  8 11
 11  0  0  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 20. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 1. 11.  0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1 11 15  8  3  8 10 10  3  0  8 10  3  3] -> size -> 20 
adversary victory points: 6
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [ 0.  8.  0.  3.  0. 11. 10.  8.  0.  0.  8.  0.  3.  1.  3. 14.  0. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 16  0  3 14 10  8  8 22  1  0  3  0  0  8  0  3  0 29  8 11 11  0  0
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 20. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 1. 11.  0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1 11 15  8  3  8 10 10  3  0  8 10  3  3] -> size -> 20 
adversary victory points: 6
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [ 0.  8.  0.  3.  0. 11. 10.  8.  0.  0.  8.  0.  3.  1.  3. 14.  0. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 16  0  3 14 10  8  8 22  1  0  3  0  0  8  0  3  0 29  8 11 11  0  0
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 27. 30. 20. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 1. 11.  0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1 11 15  8  3  8 10 10  3  0  8 10  3  3] -> size -> 20 
adversary victory points: 6
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [ 0.  8.  0.  3.  0. 11. 10.  8.  0.  0.  8.  0.  3.  1.  3. 14.  0. 16.
  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 16  0  3 14 10  8  8 22  1  0  3  0  0  8  0  3  0 29  8 11 11  0  0
  3  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 20. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 1. 11.  0. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1 11 15  8  3  8 10 10  3  0  8 10  3  3] -> size -> 20 
adversary victory points: 6
player victory points: 5 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [ 1. 11.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8.] 
expected returns: [[93.96875]
 [84.45375]
 [83.3819 ]
 [83.43626]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  0. 10.  8.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1 11 15  8  3  8 10 10  3  0  8 10  3  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 20. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 3. 22.  3.  0. 29.] 
adversary cards in discard: [ 0.  8.  0.  3.  0. 11. 10.  8.  0.  0.  8.  0.  3.  1.  3. 14.  0. 16.
  0.  8. 11.] 
adversary owned cards: [ 3 16  0  3 14 10  8  8 22  1  0  3  0  0  8  0  3  0 29  8 11 11  0  0
  3  0] -> size -> 26 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  6 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 11 

action type: buy - action -1.0
Learning step: -3.0957882404327393
desired expected reward: 110.14051055908203



action possibilites: [-1] 
expected returns: [[131.49556]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 15  8  3  8 10  3  0  8 10  3  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 20. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 3. 22.  3.  0. 29.] 
adversary cards in discard: [ 0.  8.  0.  3.  0. 11. 10.  8.  0.  0.  8.  0.  3.  1.  3. 14.  0. 16.
  0.  8. 11.] 
adversary owned cards: [ 3 16  0  3 14 10  8  8 22  1  0  3  0  0  8  0  3  0 29  8 11 11  0  0
  3  0] -> size -> 26 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  6 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 31 

action type: trash_cards_n_from_hand - action 12
Learning step: 0.3270381987094879
desired expected reward: 83.95928192138672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[123.16418]
 [123.16418]
 [133.53458]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 15  8  3  8 10  3  0  8 10  3  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 27. 30. 20. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 3. 22.  3.  0. 29.] 
adversary cards in discard: [ 0.  8.  0.  3.  0. 11. 10.  8.  0.  0.  8.  0.  3.  1.  3. 14.  0. 16.
  0.  8. 11.] 
adversary owned cards: [ 3 16  0  3 14 10  8  8 22  1  0  3  0  0  8  0  3  0 29  8 11 11  0  0
  3  0] -> size -> 26 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  6 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 31 

action type: take_action - action -1
Learning step: -2.0949044227600098
desired expected reward: 129.40065002441406






Player: 1 
cards in hand: [ 3. 22.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 22.  3.  0. 29.] 
cards in discard: [ 0.  8.  0.  3.  0. 11. 10.  8.  0.  0.  8.  0.  3.  1.  3. 14.  0. 16.
  0.  8. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  0  3 14 10  8  8 22  1  0  3  0  0  8  0  3  0 29  8 11 11  0  0
  3  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 20. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 0.  3.  8.  0. 10.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  3  3 15  8  3  8 10  3  0  8 10  3  3] -> size -> 17 
adversary victory points: 6
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 22.  3.  0. 29.] 
cards in discard: [ 0.  8.  0.  3.  0. 11. 10.  8.  0.  0.  8.  0.  3.  1.  3. 14.  0. 16.
  0.  8. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  0  3 14 10  8  8 22  1  0  3  0  0  8  0  3  0 29  8 11 11  0  0
  3  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 27. 30. 20. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 0.  3.  8.  0. 10.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  3  3 15  8  3  8 10  3  0  8 10  3  3] -> size -> 17 
adversary victory points: 6
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 22.  3.  0. 29.] 
cards in discard: [ 0.  8.  0.  3.  0. 11. 10.  8.  0.  0.  8.  0.  3.  1.  3. 14.  0. 16.
  0.  8. 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  0  3 14 10  8  8 22  1  0  3  0  0  8  0  3  0 29  8 11 11  0  0
  3  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 27. 30. 20. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 0.  3.  8.  0. 10.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  3  3 15  8  3  8 10  3  0  8 10  3  3] -> size -> 17 
adversary victory points: 6
player victory points: 5 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[128.4397  ]
 [116.70987 ]
 [116.646614]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8.  0. 10.] 
cards in discard: [8. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15  8  3  8 10  3  0  8 10  3  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 20. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [29.  0.  8.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 16  0  3 14 10  8  8 22  1  0  3  0  0  8  0  3  0 29  8 11 11  0  0
  3  0  0] -> size -> 27 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  6 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 11 

action type: buy - action -1.0
Learning step: -3.3377702236175537
desired expected reward: 130.19680786132812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[116.79291 ]
 [116.801865]
 [116.79291 ]
 [118.09424 ]
 [129.76605 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  8.  0. 10.] 
cards in discard: [8. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15  8  3  8 10  3  0  8 10  3  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 27. 30. 20. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [29.  0.  8.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 16  0  3 14 10  8  8 22  1  0  3  0  0  8  0  3  0 29  8 11 11  0  0
  3  0  0] -> size -> 27 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  6 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 11 

action type: take_action - action -1.0
Learning step: -3.0256168842315674
desired expected reward: 124.69664764404297



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [29.  0.  8.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  8.  8. 16.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  0  3 14 10  8  8 22  1  0  3  0  0  8  0  3  0 29  8 11 11  0  0
  3  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 20. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [ 8.  0.  0.  3.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 15  8  3  8 10  3  0  8 10  3  3] -> size -> 17 
adversary victory points: 6
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 14 10  8  8 22  1  0  3  0  0  8  0  3  0  8 11 11  0  0  3  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 20. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [ 8.  0.  0.  3.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 15  8  3  8 10  3  0  8 10  3  3] -> size -> 17 
adversary victory points: 6
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 14 10  8  8 22  1  0  3  0  0  8  0  3  0  8 11 11  0  0  3  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 27. 30. 20. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [ 8.  0.  0.  3.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 15  8  3  8 10  3  0  8 10  3  3] -> size -> 17 
adversary victory points: 6
player victory points: 5 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[177.02423]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [ 8.  0.  0.  3.  8.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15  8  3  8 10  3  0  8 10  3  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 20. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [14.  3.  0.  0.  0.] 
adversary cards in discard: [8. 8.] 
adversary owned cards: [ 3  3 14 10  8  8 22  1  0  3  0  0  8  0  3  0  8 11 11  0  0  3  0  0] -> size -> 24 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  6 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 11 

action type: buy - action -1.0
Learning step: -1.9917716979980469
desired expected reward: 127.77427673339844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[164.26648]
 [164.27592]
 [164.26648]
 [165.63025]
 [177.68494]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [ 8.  0.  0.  3.  8.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15  8  3  8 10  3  0  8 10  3  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 27. 30. 20. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [14.  3.  0.  0.  0.] 
adversary cards in discard: [8. 8.] 
adversary owned cards: [ 3  3 14 10  8  8 22  1  0  3  0  0  8  0  3  0  8 11 11  0  0  3  0  0] -> size -> 24 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  6 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 11 

action type: take_action - action -1.0
Learning step: -4.335108757019043
desired expected reward: 171.06626892089844



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [14.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0.  0.  0.] 
cards in discard: [8. 8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14 10  8  8 22  1  0  3  0  0  8  0  3  0  8 11 11  0  0  3  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 20. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 3.  3. 15. 10.  8.] 
adversary cards in discard: [ 8.  0.  0.  3.  8.  0. 10.  0.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 15  8  3  8 10  3  0  8 10  3  3] -> size -> 17 
adversary victory points: 6
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  0.  0.  0.] 
cards in discard: [8. 8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14 10  8  8 22  1  0  3  0  0  8  0  3  0  8 11 11  0  0  3  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 27. 30. 20. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 3.  3. 15. 10.  8.] 
adversary cards in discard: [ 8.  0.  0.  3.  8.  0. 10.  0.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 15  8  3  8 10  3  0  8 10  3  3] -> size -> 17 
adversary victory points: 6
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  0.  0.  0.] 
cards in discard: [8. 8. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14 10  8  8 22  1  0  3  0  0  8  0  3  0  8 11 11  0  0  3  0  0
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 27. 30. 20. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 3.  3. 15. 10.  8.] 
adversary cards in discard: [ 8.  0.  0.  3.  8.  0. 10.  0.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 15  8  3  8 10  3  0  8 10  3  3] -> size -> 17 
adversary victory points: 6
player victory points: 5 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [ 3.  3. 15. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.  8.] 
expected returns: [[177.59624]
 [167.47296]
 [164.89912]
 [164.96472]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 15. 10.  8.] 
cards in discard: [ 8.  0.  0.  3.  8.  0. 10.  0.  3.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15  8  3  8 10  3  0  8 10  3  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 20. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 3.  3.  3. 11.  0.] 
adversary cards in discard: [ 8.  8.  0. 14.  3.  0.  0.  0.] 
adversary owned cards: [ 3  3 14 10  8  8 22  1  0  3  0  0  8  0  3  0  8 11 11  0  0  3  0  0
  0] -> size -> 25 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  6 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 11 

action type: buy - action -1.0
Learning step: -4.452229976654053
desired expected reward: 173.23269653320312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[163.70164]
 [163.70164]
 [177.74542]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 15. 10.  8.] 
cards in discard: [ 8.  0.  0.  3.  8.  0. 10.  0.  3.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15  8  3  8 10  3  0  8 10  3  3] -> size -> 17 
action values: 1 
buys: 1 
player value: 0 
card supply: [16. 27. 30. 20. 30.  8. 10.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 3.  3.  3. 11.  0.] 
adversary cards in discard: [ 8.  8.  0. 14.  3.  0.  0.  0.] 
adversary owned cards: [ 3  3 14 10  8  8 22  1  0  3  0  0  8  0  3  0  8 11 11  0  0  3  0  0
  0] -> size -> 25 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  6 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 11 

action type: take_action - action -1.0
Learning step: -4.3902201652526855
desired expected reward: 172.37765502929688



buy possibilites: [-1] 
expected returns: [[178.18362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 15. 10.  8.] 
cards in discard: [ 8.  0.  0.  3.  8.  0. 10.  0.  3.  3.  3.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15  8  3  8 10  3  0  8 10  3  3  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 20. 30.  8.  9.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 3.  3.  3. 11.  0.] 
adversary cards in discard: [ 8.  8.  0. 14.  3.  0.  0.  0.] 
adversary owned cards: [ 3  3 14 10  8  8 22  1  0  3  0  0  8  0  3  0  8 11 11  0  0  3  0  0
  0] -> size -> 25 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[  -5    0    5    0    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -300 

action type: buy - action 6.0
Learning step: -19.17595100402832
desired expected reward: 144.52569580078125






Player: 1 
cards in hand: [ 3.  3.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3. 11.  0.] 
cards in discard: [ 8.  8.  0. 14.  3.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14 10  8  8 22  1  0  3  0  0  8  0  3  0  8 11 11  0  0  3  0  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 20. 30.  8.  9.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [10.  6. 15.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 15  8  3  8 10  3  0  8 10  3  3  6] -> size -> 18 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3. 11.  0.] 
cards in discard: [ 8.  8.  0. 14.  3.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14 10  8  8 22  1  0  3  0  0  8  0  3  0  8 11 11  0  0  3  0  0
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 27. 30. 20. 30.  8.  9.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [10.  6. 15.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 15  8  3  8 10  3  0  8 10  3  3  6] -> size -> 18 
adversary victory points: 5
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [10.  6. 15.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
expected returns: [[148.68987]
 [136.41992]
 [139.01976]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6. 15.  0.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15  8  3  8 10  3  0  8 10  3  3  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 20. 30.  8.  9.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 8.  8. 11.  0.  0.] 
adversary cards in discard: [ 8.  8.  0. 14.  3.  0.  0.  0.  3.  3.  3. 11.  0.] 
adversary owned cards: [ 3  3 14 10  8  8 22  1  0  3  0  0  8  0  3  0  8 11 11  0  0  3  0  0
  0] -> size -> 25 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 0 

action type: buy - action -1
Learning step: -5.672314643859863
desired expected reward: 172.5113067626953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[136.31279]
 [136.31279]
 [149.8966 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6. 15.  0.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15  8  3  8 10  3  0  8 10  3  3  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 27. 30. 20. 30.  8.  9.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 8.  8. 11.  0.  0.] 
adversary cards in discard: [ 8.  8.  0. 14.  3.  0.  0.  0.  3.  3.  3. 11.  0.] 
adversary owned cards: [ 3  3 14 10  8  8 22  1  0  3  0  0  8  0  3  0  8 11 11  0  0  3  0  0
  0] -> size -> 25 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 0 

action type: take_action - action -1.0
Learning step: -4.093641757965088
desired expected reward: 143.27691650390625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8.  8. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 11.  0.  0.] 
cards in discard: [ 8.  8.  0. 14.  3.  0.  0.  0.  3.  3.  3. 11.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14 10  8  8 22  1  0  3  0  0  8  0  3  0  8 11 11  0  0  3  0  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 20. 30.  8.  9.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [10.  3.  0.  8.  3.] 
adversary cards in discard: [10.  6. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 15  8  3  8 10  3  0  8 10  3  3  6] -> size -> 18 
adversary victory points: 5
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 8.  8.  0. 14.  3.  0.  0.  0.  3.  3.  3. 11.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 14 10  8 22  1  0  3  0  0  8  0  3  0  8 11  0  0  3  0  0  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 20. 30.  8.  9.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [10.  3.  0.  8.  3.] 
adversary cards in discard: [10.  6. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 15  8  3  8 10  3  0  8 10  3  3  6] -> size -> 18 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 8.  8.  0. 14.  3.  0.  0.  0.  3.  3.  3. 11.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 14 10  8 22  1  0  3  0  0  8  0  3  0  8 11  0  0  3  0  0  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 27. 30. 20. 30.  8.  9.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [10.  3.  0.  8.  3.] 
adversary cards in discard: [10.  6. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 15  8  3  8 10  3  0  8 10  3  3  6] -> size -> 18 
adversary victory points: 5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 8.  8.  0. 14.  3.  0.  0.  0.  3.  3.  3. 11.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 14 10  8 22  1  0  3  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 19. 30.  8.  9.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [10.  3.  0.  8.  3.] 
adversary cards in discard: [10.  6. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 15  8  3  8 10  3  0  8 10  3  3  6] -> size -> 18 
adversary victory points: 5
player victory points: 6 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [10.  3.  0.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[105.67731]
 [ 95.99139]
 [ 96.04403]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  8.  3.] 
cards in discard: [10.  6. 15.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15  8  3  8 10  3  0  8 10  3  3  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 19. 30.  8.  9.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 0. 10.  3.  1.  0.] 
adversary cards in discard: [ 8.  8.  0. 14.  3.  0.  0.  0.  3.  3.  3. 11.  0.  3.  8.  0.  0.] 
adversary owned cards: [ 3  3 14 10  8 22  1  0  3  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3] -> size -> 24 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -10 

action type: buy - action -1.0
Learning step: -5.693317413330078
desired expected reward: 144.20330810546875



action possibilites: [-1.  8.] 
expected returns: [[110.94872]
 [100.69235]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 3. 3.] 
cards in discard: [10.  6. 15.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3 15  8  3  8 10  3  0  8 10  3  3  6] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 19. 30.  8.  9.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 0. 10.  3.  1.  0.] 
adversary cards in discard: [ 8.  8.  0. 14.  3.  0.  0.  0.  3.  3.  3. 11.  0.  3.  8.  0.  0.] 
adversary owned cards: [ 3  3 14 10  8 22  1  0  3  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3] -> size -> 24 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 10 

action type: take_action - action 10.0
Learning step: -1.8441160917282104
desired expected reward: 93.85762786865234



action possibilites: [-1.] 
expected returns: [[110.541855]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [10.  6. 15.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 19. 30.  8.  9.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 0. 10.  3.  1.  0.] 
adversary cards in discard: [ 8.  8.  0. 14.  3.  0.  0.  0.  3.  3.  3. 11.  0.  3.  8.  0.  0.] 
adversary owned cards: [ 3  3 14 10  8 22  1  0  3  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3] -> size -> 24 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: trash_cards_n_from_hand - action 6
Learning step: -2.013674736022949
desired expected reward: 96.00365447998047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 99.36573]
 [ 99.36573]
 [111.66263]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [10.  6. 15.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6] -> size -> 15 
action values: 1 
buys: 1 
player value: 0 
card supply: [16. 27. 30. 19. 30.  8.  9.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 0. 10.  3.  1.  0.] 
adversary cards in discard: [ 8.  8.  0. 14.  3.  0.  0.  0.  3.  3.  3. 11.  0.  3.  8.  0.  0.] 
adversary owned cards: [ 3  3 14 10  8 22  1  0  3  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3] -> size -> 24 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -2.7032065391540527
desired expected reward: 107.8386459350586






Player: 1 
cards in hand: [ 0. 10.  3.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  1.  0.] 
cards in discard: [ 8.  8.  0. 14.  3.  0.  0.  0.  3.  3.  3. 11.  0.  3.  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14 10  8 22  1  0  3  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 19. 30.  8.  9.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [3. 3. 0. 8. 0.] 
adversary cards in discard: [10.  6. 15.  0.  3. 10.  8.  3.] 
adversary owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6] -> size -> 15 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  1.  0.] 
cards in discard: [ 8.  8.  0. 14.  3.  0.  0.  0.  3.  3.  3. 11.  0.  3.  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14 10  8 22  1  0  3  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 27. 30. 19. 30.  8.  9.  9.  4.  1. 10.  9.  7. 10.  1.  9.  9.] 
adversary cards in hand: [3. 3. 0. 8. 0.] 
adversary cards in discard: [10.  6. 15.  0.  3. 10.  8.  3.] 
adversary owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6] -> size -> 15 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  1.  0.] 
cards in discard: [ 8.  8.  0. 14.  3.  0.  0.  0.  3.  3.  3. 11.  0.  3.  8.  0.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14 10  8 22  1  0  3  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 19. 30.  8.  9.  9.  4.  1. 10.  8.  7. 10.  1.  9.  9.] 
adversary cards in hand: [3. 3. 0. 8. 0.] 
adversary cards in discard: [10.  6. 15.  0.  3. 10.  8.  3.] 
adversary owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6] -> size -> 15 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[100.518005]
 [ 92.17591 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 8. 0.] 
cards in discard: [10.  6. 15.  0.  3. 10.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 19. 30.  8.  9.  9.  4.  1. 10.  8.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 8.  8.  0.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 14 10  8 22  1  0  3  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3
 29] -> size -> 25 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1.0
Learning step: -4.8385210037231445
desired expected reward: 103.69910430908203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 92.35737]
 [ 92.36351]
 [ 92.35737]
 [ 93.29215]
 [101.65614]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 8. 0.] 
cards in discard: [10.  6. 15.  0.  3. 10.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 27. 30. 19. 30.  8.  9.  9.  4.  1. 10.  8.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 8.  8.  0.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 14 10  8 22  1  0  3  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3
 29] -> size -> 25 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -4.3540873527526855
desired expected reward: 94.9070053100586



buy possibilites: [-1] 
expected returns: [[130.73395]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 8. 0.] 
cards in discard: [10.  6. 15.  0.  3. 10.  8.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 18. 30.  8.  9.  9.  4.  1. 10.  8.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 8.  8.  0.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 14 10  8 22  1  0  3  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3
 29] -> size -> 25 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -13 

action type: buy - action 3.0
Learning step: -2.3266613483428955
desired expected reward: 90.0368423461914






Player: 1 
cards in hand: [ 8.  8.  0.  0. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  0.  0. 22.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14 10  8 22  1  0  3  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 18. 30.  8.  9.  9.  4.  1. 10.  8.  7. 10.  1.  9.  9.] 
adversary cards in hand: [0. 8. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6  3] -> size -> 16 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8.  0.  0. 22.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14 10  8 22  1  0  3  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 27. 30. 18. 30.  8.  9.  9.  4.  1. 10.  8.  7. 10.  1.  9.  9.] 
adversary cards in hand: [0. 8. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6  3] -> size -> 16 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8.  0.  0. 22.] 
cards in discard: [3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14 10  8 22  1  0  3  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3
 29  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 17. 30.  8.  9.  9.  4.  1. 10.  8.  7. 10.  1.  9.  9.] 
adversary cards in hand: [0. 8. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6  3] -> size -> 16 
adversary victory points: 4
player victory points: 7 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [0. 8. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[93.364914]
 [83.90506 ]
 [83.90506 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 8. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 17. 30.  8.  9.  9.  4.  1. 10.  8.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 0.  3. 14.  0.  0.] 
adversary cards in discard: [ 3.  8.  8.  0.  0. 22.] 
adversary owned cards: [ 3  3 14 10  8 22  1  0  3  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3
 29  3] -> size -> 26 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -31 

action type: buy - action -1
Learning step: -6.073709011077881
desired expected reward: 124.66024017333984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[82.0264  ]
 [82.033394]
 [82.0264  ]
 [83.09143 ]
 [92.65143 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 8. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 27. 30. 17. 30.  8.  9.  9.  4.  1. 10.  8.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 0.  3. 14.  0.  0.] 
adversary cards in discard: [ 3.  8.  8.  0.  0. 22.] 
adversary owned cards: [ 3  3 14 10  8 22  1  0  3  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3
 29  3] -> size -> 26 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -31 

action type: take_action - action -1.0
Learning step: -4.1794562339782715
desired expected reward: 88.31341552734375



buy possibilites: [-1] 
expected returns: [[85.974464]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 8. 0.] 
cards in discard: [3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6  3  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 16. 30.  8.  9.  9.  4.  1. 10.  8.  7. 10.  1.  9.  9.] 
adversary cards in hand: [ 0.  3. 14.  0.  0.] 
adversary cards in discard: [ 3.  8.  8.  0.  0. 22.] 
adversary owned cards: [ 3  3 14 10  8 22  1  0  3  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3
 29  3] -> size -> 26 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -12 

action type: buy - action 3.0
Learning step: -2.7672441005706787
desired expected reward: 79.26614379882812






Player: 1 
cards in hand: [ 0.  3. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 14.  0.  0.] 
cards in discard: [ 3.  8.  8.  0.  0. 22.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14 10  8 22  1  0  3  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3
 29  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 16. 30.  8.  9.  9.  4.  1. 10.  8.  7. 10.  1.  9.  9.] 
adversary cards in hand: [10.  3. 15. 10.  6.] 
adversary cards in discard: [3. 0. 8. 3. 8. 0.] 
adversary owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6  3  3] -> size -> 17 
adversary victory points: 5
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [ 3.  8.  8.  0.  0. 22.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 14 10  8 22  1  0  3  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3
 29  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 27. 30. 16. 30.  8.  9.  9.  4.  1. 10.  8.  7. 10.  1.  9.  9.] 
adversary cards in hand: [10. 10.  6.] 
adversary cards in discard: [ 3.  0.  8.  3.  8.  0.  3. 15.] 
adversary owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6  3  3] -> size -> 17 
adversary victory points: 5
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [ 3.  8.  8.  0.  0. 22.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 14 10  8 22  1  0  3  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3
 29  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 5 
card supply: [16. 27. 30. 16. 30.  8.  9.  9.  4.  1. 10.  8.  7. 10.  1.  9.  9.] 
adversary cards in hand: [10. 10.  6.] 
adversary cards in discard: [ 3.  0.  8.  3.  8.  0.  3. 15.] 
adversary owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6  3  3] -> size -> 17 
adversary victory points: 5
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [ 3.  8.  8.  0.  0. 22. 25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  3 14 10  8 22  1  0  3  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3
 29  3 25] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 16. 30.  8.  9.  9.  4.  1.  9.  8.  7. 10.  1.  9.  9.] 
adversary cards in hand: [10. 10.  6.] 
adversary cards in discard: [ 3.  0.  8.  3.  8.  0.  3. 15.] 
adversary owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6  3  3] -> size -> 17 
adversary victory points: 5
player victory points: 7 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [10. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[85.597466]
 [76.197586]
 [76.197586]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  6.] 
cards in discard: [ 3.  0.  8.  3.  8.  0.  3. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6  3  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 16. 30.  8.  9.  9.  4.  1.  9.  8.  7. 10.  1.  9.  9.] 
adversary cards in hand: [29.  3. 11.  3.  0.] 
adversary cards in discard: [ 3.  8.  8.  0.  0. 22. 25. 14.  0.  3.  0.  0.] 
adversary owned cards: [ 3  3 14 10  8 22  1  0  3  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3
 29  3 25] -> size -> 27 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -20 

action type: discard_down_to_3_cards - action 8
Learning step: -0.9128261804580688
desired expected reward: 33.84292984008789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[74.8625 ]
 [74.8625 ]
 [84.95389]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  6.] 
cards in discard: [ 3.  0.  8.  3.  8.  0.  3. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6  3  3] -> size -> 17 
action values: 1 
buys: 1 
player value: 0 
card supply: [16. 27. 30. 16. 30.  8.  9.  9.  4.  1.  9.  8.  7. 10.  1.  9.  9.] 
adversary cards in hand: [29.  3. 11.  3.  0.] 
adversary cards in discard: [ 3.  8.  8.  0.  0. 22. 25. 14.  0.  3.  0.  0.] 
adversary owned cards: [ 3  3 14 10  8 22  1  0  3  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3
 29  3 25] -> size -> 27 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -20 

action type: take_action - action -1.0
Learning step: -3.3634376525878906
desired expected reward: 80.68165588378906



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [29.  3. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 11.  3.  0.] 
cards in discard: [ 3.  8.  8.  0.  0. 22. 25. 14.  0.  3.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14 10  8 22  1  0  3  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3
 29  3 25] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 16. 30.  8.  9.  9.  4.  1.  9.  8.  7. 10.  1.  9.  9.] 
adversary cards in hand: [3. 0. 8. 3. 3.] 
adversary cards in discard: [ 3.  0.  8.  3.  8.  0.  3. 15. 10. 10.  6.] 
adversary owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6  3  3] -> size -> 17 
adversary victory points: 5
player victory points: 7 


action possibilites: [-1. 11. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3.  0. 10.] 
cards in discard: [ 3.  8.  8.  0.  0. 22. 25. 14.  0.  3.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3 14 10  8 22  1  0  3  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3
 29  3 25] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 27. 30. 16. 30.  8.  9.  9.  4.  1.  9.  8.  7. 10.  1.  9.  9.] 
adversary cards in hand: [3. 0. 8. 3. 3.] 
adversary cards in discard: [ 3.  0.  8.  3.  8.  0.  3. 15. 10. 10.  6.] 
adversary owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6  3  3] -> size -> 17 
adversary victory points: 5
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  3.  0. 10.] 
cards in discard: [ 3.  8.  8.  0.  0. 22. 25. 14.  0.  3.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3 14 10  8 22  1  0  3  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3
 29  3 25] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 27. 30. 16. 30.  8.  9.  9.  4.  1.  9.  8.  7. 10.  1.  9.  9.] 
adversary cards in hand: [3. 0. 8. 3. 3.] 
adversary cards in discard: [ 3.  0.  8.  3.  8.  0.  3. 15. 10. 10.  6.] 
adversary owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6  3  3] -> size -> 17 
adversary victory points: 5
player victory points: 7 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [3. 0. 8. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[78.84967]
 [68.82046]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 3. 3.] 
cards in discard: [ 3.  0.  8.  3.  8.  0.  3. 15. 10. 10.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6  3  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 16. 30.  8.  9.  9.  4.  1.  9.  8.  7. 10.  1.  9.  9.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [ 3.  8.  8.  0.  0. 22. 25. 14.  0.  3.  0.  0. 29.  3. 11.  3.  0. 10.] 
adversary owned cards: [ 3  3 14 10  8 22  1  0  3  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3
 29  3 25] -> size -> 27 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -20 

action type: buy - action -1.0
Learning step: -3.546407461166382
desired expected reward: 81.407470703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[67.48312]
 [67.48312]
 [78.64702]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 3. 3.] 
cards in discard: [ 3.  0.  8.  3.  8.  0.  3. 15. 10. 10.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6  3  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 27. 30. 16. 30.  8.  9.  9.  4.  1.  9.  8.  7. 10.  1.  9.  9.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [ 3.  8.  8.  0.  0. 22. 25. 14.  0.  3.  0.  0. 29.  3. 11.  3.  0. 10.] 
adversary owned cards: [ 3  3 14 10  8 22  1  0  3  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3
 29  3 25] -> size -> 27 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -20 

action type: take_action - action -1.0
Learning step: -3.2117767333984375
desired expected reward: 74.80758666992188



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [ 3.  8.  8.  0.  0. 22. 25. 14.  0.  3.  0.  0. 29.  3. 11.  3.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14 10  8 22  1  0  3  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3
 29  3 25] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 16. 30.  8.  9.  9.  4.  1.  9.  8.  7. 10.  1.  9.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6  3  3] -> size -> 17 
adversary victory points: 5
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [ 3.  8.  8.  0.  0. 22. 25. 14.  0.  3.  0.  0. 29.  3. 11.  3.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14 10  8 22  1  0  3  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3
 29  3 25] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [16. 27. 30. 16. 30.  8.  9.  9.  4.  1.  9.  8.  7. 10.  1.  9.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6  3  3] -> size -> 17 
adversary victory points: 5
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [ 3.  8.  8.  0.  0. 22. 25. 14.  0.  3.  0.  0. 29.  3. 11.  3.  0. 10.
 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14 10  8 22  1  0  3  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3
 29  3 25 14] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 27. 30. 16. 30.  8.  9.  9.  4.  1.  9.  8.  6. 10.  1.  9.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6  3  3] -> size -> 17 
adversary victory points: 5
player victory points: 7 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[89.15879]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6  3  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 16. 30.  8.  9.  9.  4.  1.  9.  8.  6. 10.  1.  9.  9.] 
adversary cards in hand: [3. 3. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 14 10  8 22  1  0  3  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3
 29  3 25 14] -> size -> 28 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -20 

action type: buy - action -1.0
Learning step: -2.909776449203491
desired expected reward: 75.73724365234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[81.6772  ]
 [81.69059 ]
 [81.68543 ]
 [81.6772  ]
 [84.07398 ]
 [82.945656]
 [82.87971 ]
 [94.15039 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6  3  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 27. 30. 16. 30.  8.  9.  9.  4.  1.  9.  8.  6. 10.  1.  9.  9.] 
adversary cards in hand: [3. 3. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 14 10  8 22  1  0  3  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3
 29  3 25 14] -> size -> 28 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -20 

action type: take_action - action -1.0
Learning step: -3.487478733062744
desired expected reward: 86.40471649169922



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 3. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0. 8.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 14 10  8 22  1  0  3  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3
 29  3 25 14] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 16. 30.  8.  9.  9.  4.  1.  9.  8.  6. 10.  1.  9.  9.] 
adversary cards in hand: [ 3. 10.  3.  8.  8.] 
adversary cards in discard: [3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6  3  3] -> size -> 17 
adversary victory points: 5
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [14 10  8 22  1  0  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3 29  3 25
 14] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 16. 30.  8.  9.  9.  4.  1.  9.  8.  6. 10.  1.  9.  9.] 
adversary cards in hand: [ 3. 10.  3.  8.  8.] 
adversary cards in discard: [3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6  3  3] -> size -> 17 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [14 10  8 22  1  0  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3 29  3 25
 14] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 27. 30. 16. 30.  8.  9.  9.  4.  1.  9.  8.  6. 10.  1.  9.  9.] 
adversary cards in hand: [ 3. 10.  3.  8.  8.] 
adversary cards in discard: [3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6  3  3] -> size -> 17 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [14 10  8 22  1  0  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3 29  3 25
 14  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 27. 30. 16. 30.  8.  9.  9.  4.  1.  9.  8.  6. 10.  1.  9.  9.] 
adversary cards in hand: [ 3. 10.  3.  8.  8.] 
adversary cards in discard: [3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6  3  3] -> size -> 17 
adversary victory points: 5
player victory points: 4 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [ 3. 10.  3.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8.] 
expected returns: [[135.7337 ]
 [123.80373]
 [123.87055]
 [123.87055]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  8.  8.] 
cards in discard: [3. 3. 0. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6  3  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 16. 30.  8.  9.  9.  4.  1.  9.  8.  6. 10.  1.  9.  9.] 
adversary cards in hand: [ 0.  3. 14.  3. 25.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [14 10  8 22  1  0  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3 29  3 25
 14  0] -> size -> 26 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 10 

action type: buy - action -1.0
Learning step: -1.2854470014572144
desired expected reward: 92.86494445800781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[121.61536]
 [121.61536]
 [134.79472]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  8.  8.] 
cards in discard: [3. 3. 0. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6  3  3] -> size -> 17 
action values: 1 
buys: 1 
player value: 0 
card supply: [15. 27. 30. 16. 30.  8.  9.  9.  4.  1.  9.  8.  6. 10.  1.  9.  9.] 
adversary cards in hand: [ 0.  3. 14.  3. 25.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [14 10  8 22  1  0  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3 29  3 25
 14  0] -> size -> 26 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 10 

action type: take_action - action -1.0
Learning step: -3.271465301513672
desired expected reward: 130.91793823242188



buy possibilites: [-1] 
expected returns: [[140.7552]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  8.  8.] 
cards in discard: [3. 3. 0. 0. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6  3  3  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 16. 30.  8.  9.  9.  4.  1.  9.  8.  6. 10.  1.  9.  9.] 
adversary cards in hand: [ 0.  3. 14.  3. 25.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [14 10  8 22  1  0  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3 29  3 25
 14  0] -> size -> 26 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[ -5   0   5  10   0   0   0 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -20 

action type: buy - action 0.0
Learning step: -3.7873189449310303
desired expected reward: 117.82804107666016






Player: 1 
cards in hand: [ 0.  3. 14.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 14.  3. 25.] 
cards in discard: [0. 8. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [14 10  8 22  1  0  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3 29  3 25
 14  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 16. 30.  8.  9.  9.  4.  1.  9.  8.  6. 10.  1.  9.  9.] 
adversary cards in hand: [3. 0. 3. 6. 8.] 
adversary cards in discard: [ 3.  3.  0.  0.  0.  0.  3. 10.  3.  8.  8.] 
adversary owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6  3  3  0] -> size -> 18 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 14.  3. 25.] 
cards in discard: [0. 8. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [14 10  8 22  1  0  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3 29  3 25
 14  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 27. 30. 16. 30.  8.  9.  9.  4.  1.  9.  8.  6. 10.  1.  9.  9.] 
adversary cards in hand: [3. 0. 3. 6. 8.] 
adversary cards in discard: [ 3.  3.  0.  0.  0.  0.  3. 10.  3.  8.  8.] 
adversary owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6  3  3  0] -> size -> 18 
adversary victory points: 5
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[109.44839]
 [ 98.36793]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 6. 8.] 
cards in discard: [ 3.  3.  0.  0.  0.  0.  3. 10.  3.  8.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6  3  3  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 16. 30.  8.  9.  9.  4.  1.  9.  8.  6. 10.  1.  9.  9.] 
adversary cards in hand: [ 0.  0.  0.  8. 11.] 
adversary cards in discard: [ 0.  8.  0.  0.  3. 14.  3. 25.] 
adversary owned cards: [14 10  8 22  1  0  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3 29  3 25
 14  0] -> size -> 26 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 10 

action type: buy - action -1
Learning step: -4.154141426086426
desired expected reward: 136.60105895996094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 96.34847]
 [ 96.34847]
 [108.68244]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 6. 8.] 
cards in discard: [ 3.  3.  0.  0.  0.  0.  3. 10.  3.  8.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6  3  3  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 27. 30. 16. 30.  8.  9.  9.  4.  1.  9.  8.  6. 10.  1.  9.  9.] 
adversary cards in hand: [ 0.  0.  0.  8. 11.] 
adversary cards in discard: [ 0.  8.  0.  0.  3. 14.  3. 25.] 
adversary owned cards: [14 10  8 22  1  0  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3 29  3 25
 14  0] -> size -> 26 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 10 

action type: take_action - action -1.0
Learning step: -2.5733094215393066
desired expected reward: 106.02417755126953



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0.  0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  8. 11.] 
cards in discard: [ 0.  8.  0.  0.  3. 14.  3. 25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [14 10  8 22  1  0  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3 29  3 25
 14  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 16. 30.  8.  9.  9.  4.  1.  9.  8.  6. 10.  1.  9.  9.] 
adversary cards in hand: [ 0.  3.  0. 10. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6  3  3  0] -> size -> 18 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  8. 11.] 
cards in discard: [ 0.  8.  0.  0.  3. 14.  3. 25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [14 10  8 22  1  0  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3 29  3 25
 14  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 27. 30. 16. 30.  8.  9.  9.  4.  1.  9.  8.  6. 10.  1.  9.  9.] 
adversary cards in hand: [ 0.  3.  0. 10. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6  3  3  0] -> size -> 18 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  8. 11.] 
cards in discard: [ 0.  8.  0.  0.  3. 14.  3. 25.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [14 10  8 22  1  0  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3 29  3 25
 14  0  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 27. 30. 16. 30.  8.  9.  9.  4.  0.  9.  8.  6. 10.  1.  9.  9.] 
adversary cards in hand: [ 0.  3.  0. 10. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6  3  3  0] -> size -> 18 
adversary victory points: 5
player victory points: 4 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
expected returns: [[104.31037 ]
 [ 94.21108 ]
 [ 96.351234]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10. 15.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6  3  3  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 16. 30.  8.  9.  9.  4.  0.  9.  8.  6. 10.  1.  9.  9.] 
adversary cards in hand: [22.  3.  3. 10. 14.] 
adversary cards in discard: [ 0.  8.  0.  0.  3. 14.  3. 25.  8.  0.  0.  0.  8. 11.] 
adversary owned cards: [14 10  8 22  1  0  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3 29  3 25
 14  0  8] -> size -> 27 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 10 

action type: buy - action -1.0
Learning step: -2.662771701812744
desired expected reward: 106.01966857910156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[ 95.34942 ]
 [ 95.355255]
 [ 95.34942 ]
 [106.422264]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10. 15.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6  3  3  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 27. 30. 16. 30.  8.  9.  9.  4.  0.  9.  8.  6. 10.  1.  9.  9.] 
adversary cards in hand: [22.  3.  3. 10. 14.] 
adversary cards in discard: [ 0.  8.  0.  0.  3. 14.  3. 25.  8.  0.  0.  0.  8. 11.] 
adversary owned cards: [14 10  8 22  1  0  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3 29  3 25
 14  0  8] -> size -> 27 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 10 

action type: take_action - action -1.0
Learning step: -2.386232376098633
desired expected reward: 101.43524932861328



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [22.  3.  3. 10. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 10. 14.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  3.  3. 10. 14.] 
cards in discard: [ 0.  8.  0.  0.  3. 14.  3. 25.  8.  0.  0.  0.  8. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [14 10  8 22  1  0  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3 29  3 25
 14  0  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 16. 30.  8.  9.  9.  4.  0.  9.  8.  6. 10.  1.  9.  9.] 
adversary cards in hand: [3. 8. 8. 0. 0.] 
adversary cards in discard: [ 0.  3.  0. 10. 15.] 
adversary owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6  3  3  0] -> size -> 18 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1. 22. 14.  8.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  3.  3. 14.  8.] 
cards in discard: [ 0.  8.  0.  0.  3. 14.  3. 25.  8.  0.  0.  0.  8. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [14 10  8 22  1  0  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3 29  3 25
 14  0  8] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 16. 30.  8.  9.  9.  4.  0.  9.  8.  6. 10.  1.  9.  9.] 
adversary cards in hand: [3. 8. 8. 0. 0.] 
adversary cards in discard: [ 0.  3.  0. 10. 15.] 
adversary owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6  3  3  0] -> size -> 18 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 14.  8.  0.  1.  0.] 
cards in discard: [ 0.  8.  0.  0.  3. 14.  3. 25.  8.  0.  0.  0.  8. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 22.] 
owned cards: [14 10  8 22  1  0  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3 29  3 25
 14  0  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 16. 30.  8.  9.  9.  4.  0.  9.  8.  6. 10.  1.  9.  9.] 
adversary cards in hand: [3. 8. 8. 0. 0.] 
adversary cards in discard: [ 0.  3.  0. 10. 15.] 
adversary owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6  3  3  0] -> size -> 18 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 14.  8.  0.  1.  0.] 
cards in discard: [ 0.  8.  0.  0.  3. 14.  3. 25.  8.  0.  0.  0.  8. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 22.] 
owned cards: [14 10  8 22  1  0  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3 29  3 25
 14  0  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 27. 30. 16. 30.  8.  9.  9.  4.  0.  9.  8.  6. 10.  1.  9.  9.] 
adversary cards in hand: [3. 8. 8. 0. 0.] 
adversary cards in discard: [ 0.  3.  0. 10. 15.] 
adversary owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6  3  3  0] -> size -> 18 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 14.  8.  0.  1.  0.] 
cards in discard: [ 0.  8.  0.  0.  3. 14.  3. 25.  8.  0.  0.  0.  8. 11. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 22.] 
owned cards: [14 10  8 22  1  0  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3 29  3 25
 14  0  8 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 16. 30.  8.  9.  9.  4.  0.  9.  7.  6. 10.  1.  9.  9.] 
adversary cards in hand: [3. 8. 8. 0. 0.] 
adversary cards in discard: [ 0.  3.  0. 10. 15.] 
adversary owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6  3  3  0] -> size -> 18 
adversary victory points: 5
player victory points: 4 





         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [3. 8. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[99.31253]
 [89.14315]
 [89.14315]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 8. 0. 0.] 
cards in discard: [ 0.  3.  0. 10. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  8  3  8 10  3  0  8 10  3  3  6  3  3  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 16. 30.  8.  9.  9.  4.  0.  9.  7.  6. 10.  1.  9.  9.] 
adversary cards in hand: [ 1. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [14 10  8 22  1  0  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3 29  3 25
 14  0  8 29] -> size -> 28 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 10 

action type: buy - action -1.0
Learning step: -2.6851441860198975
desired expected reward: 103.73712158203125



action possibilites: [-1] 
expected returns: [[48.07322]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0.  3.  0. 10. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 15  8 10  3  0  8 10  3  3  6  3  3  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 16. 30.  8.  9.  9.  4.  0.  9.  7.  6. 10.  1.  9.  9.] 
adversary cards in hand: [ 1. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [14 10  8 22  1  0  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3 29  3 25
 14  0  8 29] -> size -> 28 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: trash_cards_n_from_hand - action 9
Learning step: -2.3687520027160645
desired expected reward: 85.63923645019531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[39.92414 ]
 [39.92414 ]
 [49.125496]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  3.  0. 10. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 15  8 10  3  0  8 10  3  3  6  3  3  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 27. 30. 16. 30.  8.  9.  9.  4.  0.  9.  7.  6. 10.  1.  9.  9.] 
adversary cards in hand: [ 1. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [14 10  8 22  1  0  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3 29  3 25
 14  0  8 29] -> size -> 28 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1
Learning step: -0.4145759642124176
desired expected reward: 47.65864181518555



buy possibilites: [-1] 
expected returns: [[92.702]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  3.  0. 10. 15.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 15  8 10  3  0  8 10  3  3  6  3  3  0  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 27. 30. 16. 30.  8.  9.  9.  4.  0.  9.  7.  6. 10.  1.  9.  9.] 
adversary cards in hand: [ 1. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [14 10  8 22  1  0  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3 29  3 25
 14  0  8 29] -> size -> 28 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4.   0.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -11.0 

action type: buy - action 0.0
Learning step: -0.46041202545166016
desired expected reward: 39.46372985839844






Player: 1 
cards in hand: [ 1. 29.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [14 10  8 22  1  0  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3 29  3 25
 14  0  8 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 16. 30.  8.  9.  9.  4.  0.  9.  7.  6. 10.  1.  9.  9.] 
adversary cards in hand: [ 0.  8.  6.  3. 10.] 
adversary cards in discard: [ 0.  3.  0. 10. 15.  0.  8.  0.] 
adversary owned cards: [ 0  0 15  8 10  3  0  8 10  3  3  6  3  3  0  0] -> size -> 16 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [14 10  8 22  1  0  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3 29  3 25
 14  0  8 29] -> size -> 28 
action values: 0 
buys: 1 
player value: 5 
card supply: [13. 27. 30. 16. 30.  8.  9.  9.  4.  0.  9.  7.  6. 10.  1.  9.  9.] 
adversary cards in hand: [ 0.  8.  6.  3. 10.] 
adversary cards in discard: [ 0.  3.  0. 10. 15.  0.  8.  0.] 
adversary owned cards: [ 0  0 15  8 10  3  0  8 10  3  3  6  3  3  0  0] -> size -> 16 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.  0.  0.  0.] 
cards in discard: [14.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [14 10  8 22  1  0  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3 29  3 25
 14  0  8 29 14] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 27. 30. 16. 30.  8.  9.  9.  4.  0.  9.  7.  5. 10.  1.  9.  9.] 
adversary cards in hand: [ 0.  8.  6.  3. 10.] 
adversary cards in discard: [ 0.  3.  0. 10. 15.  0.  8.  0.] 
adversary owned cards: [ 0  0 15  8 10  3  0  8 10  3  3  6  3  3  0  0] -> size -> 16 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [ 0.  8.  6.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[77.549736]
 [68.06861 ]
 [68.00786 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  6.  3. 10.] 
cards in discard: [ 0.  3.  0. 10. 15.  0.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  8 10  3  0  8 10  3  3  6  3  3  0  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 16. 30.  8.  9.  9.  4.  0.  9.  7.  5. 10.  1.  9.  9.] 
adversary cards in hand: [10. 14.  8. 22.  3.] 
adversary cards in discard: [14.  1. 29.  0.  0.  0.] 
adversary owned cards: [14 10  8 22  1  0  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3 29  3 25
 14  0  8 29 14] -> size -> 29 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -3.0199718475341797
desired expected reward: 89.6820297241211



action possibilites: [-1] 
expected returns: [[68.67911]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [ 0.  3.  0. 10. 15.  0.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 16. 30.  8.  9.  9.  4.  0.  9.  7.  5. 10.  1.  9.  9.] 
adversary cards in hand: [10. 14.  8. 22.  3.] 
adversary cards in discard: [14.  1. 29.  0.  0.  0.] 
adversary owned cards: [14 10  8 22  1  0  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3 29  3 25
 14  0  8 29 14] -> size -> 29 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: trash_cards_n_from_hand - action 13
Learning step: -0.9343790411949158
desired expected reward: 67.65879821777344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[60.723507]
 [60.723507]
 [69.5385  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [ 0.  3.  0. 10. 15.  0.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 27. 30. 16. 30.  8.  9.  9.  4.  0.  9.  7.  5. 10.  1.  9.  9.] 
adversary cards in hand: [10. 14.  8. 22.  3.] 
adversary cards in discard: [14.  1. 29.  0.  0.  0.] 
adversary owned cards: [14 10  8 22  1  0  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3 29  3 25
 14  0  8 29 14] -> size -> 29 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1
Learning step: -0.9827964901924133
desired expected reward: 67.6963119506836






Player: 1 
cards in hand: [10. 14.  8. 22.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.  8. 22.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 14.  8. 22.  3.] 
cards in discard: [14.  1. 29.  0.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [14 10  8 22  1  0  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3 29  3 25
 14  0  8 29 14] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 16. 30.  8.  9.  9.  4.  0.  9.  7.  5. 10.  1.  9.  9.] 
adversary cards in hand: [15. 10.  3.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0] -> size -> 13 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1. 14.  8. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8. 22.  3.  0.] 
cards in discard: [14.  1. 29.  0.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [14 10  8 22  1  0  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3 29  3 25
 14  0  8 29 14] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 16. 30.  8.  9.  9.  4.  0.  9.  7.  5. 10.  1.  9.  9.] 
adversary cards in hand: [15. 10.  3.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0] -> size -> 13 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8. 22.  3.  0.] 
cards in discard: [14.  1. 29.  0.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [14 10  8 22  1  0  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3 29  3 25
 14  0  8 29 14] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 27. 30. 16. 30.  8.  9.  9.  4.  0.  9.  7.  5. 10.  1.  9.  9.] 
adversary cards in hand: [15. 10.  3.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0] -> size -> 13 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [15. 10.  3.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
expected returns: [[90.773865]
 [83.83285 ]
 [82.05767 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  3.  3.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 16. 30.  8.  9.  9.  4.  0.  9.  7.  5. 10.  1.  9.  9.] 
adversary cards in hand: [ 0. 14.  0. 29.  3.] 
adversary cards in discard: [14.  1. 29.  0.  0.  0. 10. 14.  8. 22.  3.  0.] 
adversary owned cards: [14 10  8 22  1  0  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3 29  3 25
 14  0  8 29 14] -> size -> 29 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -1.559705376625061
desired expected reward: 67.97879028320312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[80.9575  ]
 [80.9575  ]
 [90.573006]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10.  3.  3.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0] -> size -> 13 
action values: 1 
buys: 1 
player value: 0 
card supply: [13. 27. 30. 16. 30.  8.  9.  9.  4.  0.  9.  7.  5. 10.  1.  9.  9.] 
adversary cards in hand: [ 0. 14.  0. 29.  3.] 
adversary cards in discard: [14.  1. 29.  0.  0.  0. 10. 14.  8. 22.  3.  0.] 
adversary owned cards: [14 10  8 22  1  0  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3 29  3 25
 14  0  8 29 14] -> size -> 29 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -2.5759313106536865
desired expected reward: 87.31614685058594



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 14.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0. 29.  3.] 
cards in discard: [14.  1. 29.  0.  0.  0. 10. 14.  8. 22.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [14 10  8 22  1  0  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3 29  3 25
 14  0  8 29 14] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 16. 30.  8.  9.  9.  4.  0.  9.  7.  5. 10.  1.  9.  9.] 
adversary cards in hand: [3. 8. 0. 8. 0.] 
adversary cards in discard: [15. 10.  3.  3.  3.] 
adversary owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0] -> size -> 13 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  3.] 
cards in discard: [14.  1. 29.  0.  0.  0. 10. 14.  8. 22.  3.  0. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [14 10  8 22  1  0  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3 29  3 25
 14  0  8 29 14] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [13. 27. 30. 16. 30.  8.  9.  9.  4.  0.  9.  7.  5. 10.  1.  9.  9.] 
adversary cards in hand: [3. 8. 0. 8. 0.] 
adversary cards in discard: [15. 10.  3.  3.  3.] 
adversary owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0] -> size -> 13 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [14.  1. 29.  0.  0.  0. 10. 14.  8. 22.  3.  0. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [14 10  8 22  1  0  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3 29  3 25
 14  0  8 29 14] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [13. 27. 30. 16. 30.  8.  9.  9.  4.  0.  9.  7.  5. 10.  1.  9.  9.] 
adversary cards in hand: [3. 8. 0.] 
adversary cards in discard: [15. 10.  3.  3.  3.  0.  8.] 
adversary owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0] -> size -> 13 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [14.  1. 29.  0.  0.  0. 10. 14.  8. 22.  3.  0. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [14 10  8 22  1  0  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3 29  3 25
 14  0  8 29 14] -> size -> 29 
action values: 0 
buys: 1 
player value: 5 
card supply: [13. 27. 30. 16. 30.  8.  9.  9.  4.  0.  9.  7.  5. 10.  1.  9.  9.] 
adversary cards in hand: [3. 8. 0.] 
adversary cards in discard: [15. 10.  3.  3.  3.  0.  8.] 
adversary owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0] -> size -> 13 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [14.  1. 29.  0.  0.  0. 10. 14.  8. 22.  3.  0. 25. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [14 10  8 22  1  0  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3 29  3 25
 14  0  8 29 14 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 27. 30. 16. 30.  8.  9.  9.  3.  0.  9.  7.  5. 10.  1.  9.  9.] 
adversary cards in hand: [3. 8. 0.] 
adversary cards in discard: [15. 10.  3.  3.  3.  0.  8.] 
adversary owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0] -> size -> 13 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[76.66668]
 [68.43224]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0.] 
cards in discard: [15. 10.  3.  3.  3.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 16. 30.  8.  9.  9.  3.  0.  9.  7.  5. 10.  1.  9.  9.] 
adversary cards in hand: [ 8.  0. 11.  3.  8.] 
adversary cards in discard: [14.  1. 29.  0.  0.  0. 10. 14.  8. 22.  3.  0. 25. 11. 29. 14.  0.  0.
  3.] 
adversary owned cards: [14 10  8 22  1  0  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3 29  3 25
 14  0  8 29 14 11] -> size -> 30 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: discard_down_to_3_cards - action 5
Learning step: -0.9007356762886047
desired expected reward: 49.16243362426758





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[68.45252]
 [68.45252]
 [77.67034]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0.] 
cards in discard: [15. 10.  3.  3.  3.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 27. 30. 16. 30.  8.  9.  9.  3.  0.  9.  7.  5. 10.  1.  9.  9.] 
adversary cards in hand: [ 8.  0. 11.  3.  8.] 
adversary cards in discard: [14.  1. 29.  0.  0.  0. 10. 14.  8. 22.  3.  0. 25. 11. 29. 14.  0.  0.
  3.] 
adversary owned cards: [14 10  8 22  1  0  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3 29  3 25
 14  0  8 29 14 11] -> size -> 30 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -2.138840436935425
desired expected reward: 73.26248168945312



buy possibilites: [-1] 
expected returns: [[44.160843]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0.] 
cards in discard: [15. 10.  3.  3.  3.  0.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 27. 30. 16. 30.  8.  9.  9.  3.  0.  9.  7.  5. 10.  1.  9.  9.] 
adversary cards in hand: [ 8.  0. 11.  3.  8.] 
adversary cards in discard: [14.  1. 29.  0.  0.  0. 10. 14.  8. 22.  3.  0. 25. 11. 29. 14.  0.  0.
  3.] 
adversary owned cards: [14 10  8 22  1  0  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3 29  3 25
 14  0  8 29 14 11] -> size -> 30 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -31.0 

action type: buy - action 0.0
Learning step: -3.9790070056915283
desired expected reward: 64.47351837158203






Player: 1 
cards in hand: [ 8.  0. 11.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.  3.  8.] 
cards in discard: [14.  1. 29.  0.  0.  0. 10. 14.  8. 22.  3.  0. 25. 11. 29. 14.  0.  0.
  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [14 10  8 22  1  0  0  0  8  0  3  0  8 11  0  0  3  0  0  0  3 29  3 25
 14  0  8 29 14 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 16. 30.  8.  9.  9.  3.  0.  9.  7.  5. 10.  1.  9.  9.] 
adversary cards in hand: [ 8.  8.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0  0] -> size -> 14 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [14.  1. 29.  0.  0.  0. 10. 14.  8. 22.  3.  0. 25. 11. 29. 14.  0.  0.
  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 16. 30.  8.  9.  9.  3.  0.  9.  7.  5. 10.  1.  9.  9.] 
adversary cards in hand: [ 8.  8.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0  0] -> size -> 14 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [14.  1. 29.  0.  0.  0. 10. 14.  8. 22.  3.  0. 25. 11. 29. 14.  0.  0.
  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 27. 30. 16. 30.  8.  9.  9.  3.  0.  9.  7.  5. 10.  1.  9.  9.] 
adversary cards in hand: [ 8.  8.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0  0] -> size -> 14 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 62 -------------------- 
Player: 0 
cards in hand: [ 8.  8.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.] 
expected returns: [[100.504135]
 [ 92.99795 ]
 [ 92.99795 ]
 [ 92.948814]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 16. 30.  8.  9.  9.  3.  0.  9.  7.  5. 10.  1.  9.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [14.  1. 29.  0.  0.  0. 10. 14.  8. 22.  3.  0. 25. 11. 29. 14.  0.  0.
  3.  8.  3.] 
adversary owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11] -> size -> 27 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -0.06346835941076279
desired expected reward: 44.097373962402344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[ 92.60153]
 [ 92.60584]
 [ 92.60153]
 [100.96003]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 27. 30. 16. 30.  8.  9.  9.  3.  0.  9.  7.  5. 10.  1.  9.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [14.  1. 29.  0.  0.  0. 10. 14.  8. 22.  3.  0. 25. 11. 29. 14.  0.  0.
  3.  8.  3.] 
adversary owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11] -> size -> 27 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -2.8582656383514404
desired expected reward: 97.38543701171875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [14.  1. 29.  0.  0.  0. 10. 14.  8. 22.  3.  0. 25. 11. 29. 14.  0.  0.
  3.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 16. 30.  8.  9.  9.  3.  0.  9.  7.  5. 10.  1.  9.  9.] 
adversary cards in hand: [ 3. 15.  3.  3.  3.] 
adversary cards in discard: [ 8.  8.  0.  0. 10.] 
adversary owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0  0] -> size -> 14 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [14.  1. 29.  0.  0.  0. 10. 14.  8. 22.  3.  0. 25. 11. 29. 14.  0.  0.
  3.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 27. 30. 16. 30.  8.  9.  9.  3.  0.  9.  7.  5. 10.  1.  9.  9.] 
adversary cards in hand: [ 3. 15.  3.  3.  3.] 
adversary cards in discard: [ 8.  8.  0.  0. 10.] 
adversary owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0  0] -> size -> 14 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [14.  1. 29.  0.  0.  0. 10. 14.  8. 22.  3.  0. 25. 11. 29. 14.  0.  0.
  3.  8.  3. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 16. 30.  8.  9.  9.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [ 3. 15.  3.  3.  3.] 
adversary cards in discard: [ 8.  8.  0.  0. 10.] 
adversary owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0  0] -> size -> 14 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 63 -------------------- 
Player: 0 
cards in hand: [ 3. 15.  3.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[52.754658]
 [46.96173 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  3.  3.  3.] 
cards in discard: [ 8.  8.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 16. 30.  8.  9.  9.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [22.  0.  8.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14] -> size -> 28 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -3.9446983337402344
desired expected reward: 97.01533508300781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[45.58957]
 [45.58957]
 [53.71972]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  3.  3.  3.] 
cards in discard: [ 8.  8.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0  0] -> size -> 14 
action values: 1 
buys: 1 
player value: 0 
card supply: [12. 27. 30. 16. 30.  8.  9.  9.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [22.  0.  8.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14] -> size -> 28 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -1.5322333574295044
desired expected reward: 51.115760803222656



buy possibilites: [-1] 
expected returns: [[36.40141]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  3.  3.  3.] 
cards in discard: [ 8.  8.  0.  0. 10.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0  0  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 16. 30.  8.  9.  9.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [22.  0.  8.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14] -> size -> 28 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[ -5   0   4   0   0   0   0 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -31 

action type: buy - action 0.0
Learning step: -3.010446786880493
desired expected reward: 42.57912063598633






Player: 1 
cards in hand: [22.  0.  8.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.  8.  8.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  0.  8.  0.  8.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 16. 30.  8.  9.  9.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0  0  0] -> size -> 15 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0.  8. 14.  1.  3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [22.] 
owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 16. 30.  8.  9.  9.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0  0  0] -> size -> 15 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0.  8. 14.  1.  3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [22.] 
owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 27. 30. 16. 30.  8.  9.  9.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0  0  0] -> size -> 15 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0.  8. 14.  1.  3.] 
cards in discard: [16.] 
cards in deck: 20 
card top of deck: [] 
played cards: [22.] 
owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14 16] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 16. 30.  8.  9.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0  0  0] -> size -> 15 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 64 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[105.91281 ]
 [ 96.938515]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0  0  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 16. 30.  8.  9.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [ 0.  0. 10.  3. 14.] 
adversary cards in discard: [16. 22.  0.  8.  0.  8. 14.  1.  3.] 
adversary owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14 16] -> size -> 29 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: 0.4534160792827606
desired expected reward: 36.85482406616211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[ 94.43646 ]
 [ 94.445854]
 [ 94.4415  ]
 [ 94.43646 ]
 [ 95.034035]
 [ 96.29148 ]
 [ 98.861984]
 [ 96.29391 ]
 [ 95.36454 ]
 [ 97.220856]
 [104.35606 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0  0  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 27. 30. 16. 30.  8.  9.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [ 0.  0. 10.  3. 14.] 
adversary cards in discard: [16. 22.  0.  8.  0.  8. 14.  1.  3.] 
adversary owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14 16] -> size -> 29 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -3.056755781173706
desired expected reward: 102.33573913574219



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0. 10.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3. 14.] 
cards in discard: [16. 22.  0.  8.  0.  8. 14.  1.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14 16] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 16. 30.  8.  9.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [ 8.  3.  0. 15.  8.] 
adversary cards in discard: [ 0.  0.  0.  0. 10.] 
adversary owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0  0  0] -> size -> 15 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3. 14.] 
cards in discard: [16. 22.  0.  8.  0.  8. 14.  1.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14 16] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 27. 30. 16. 30.  8.  9.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [ 8.  3.  0. 15.  8.] 
adversary cards in discard: [ 0.  0.  0.  0. 10.] 
adversary owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0  0  0] -> size -> 15 
adversary victory points: 4
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 65 -------------------- 
Player: 0 
cards in hand: [ 8.  3.  0. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.  8.] 
expected returns: [[51.71691 ]
 [43.64984 ]
 [45.249447]
 [43.64984 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0. 15.  8.] 
cards in discard: [ 0.  0.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0  0  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 16. 30.  8.  9.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [ 0. 14.  0. 29.  0.] 
adversary cards in discard: [16. 22.  0.  8.  0.  8. 14.  1.  3.  0.  0. 10.  3. 14.] 
adversary owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14 16] -> size -> 29 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -4.196919918060303
desired expected reward: 100.15914916992188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[41.952118]
 [41.952118]
 [50.742886]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  0. 15.  8.] 
cards in discard: [ 0.  0.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0  0  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 27. 30. 16. 30.  8.  9.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [ 0. 14.  0. 29.  0.] 
adversary cards in discard: [16. 22.  0.  8.  0.  8. 14.  1.  3.  0.  0. 10.  3. 14.] 
adversary owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14 16] -> size -> 29 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -1.4849458932876587
desired expected reward: 48.78260803222656



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 14.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0. 29.  0.] 
cards in discard: [16. 22.  0.  8.  0.  8. 14.  1.  3.  0.  0. 10.  3. 14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14 16] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 16. 30.  8.  9.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [ 3.  3. 10.  3.  0.] 
adversary cards in discard: [ 0.  0.  0.  0. 10.  8.  3.  0. 15.  8.] 
adversary owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0  0  0] -> size -> 15 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.] 
cards in discard: [16. 22.  0.  8.  0.  8. 14.  1.  3.  0.  0. 10.  3. 14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14 16] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 27. 30. 16. 30.  8.  9.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [3. 3. 3.] 
adversary cards in discard: [ 0.  0.  0.  0. 10.  8.  3.  0. 15.  8. 10.  0.] 
adversary owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0  0  0] -> size -> 15 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  0.] 
cards in discard: [16. 22.  0.  8.  0.  8. 14.  1.  3.  0.  0. 10.  3. 14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14 16] -> size -> 29 
action values: 0 
buys: 1 
player value: 5 
card supply: [11. 27. 30. 16. 30.  8.  9.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [3. 3. 3.] 
adversary cards in discard: [ 0.  0.  0.  0. 10.  8.  3.  0. 15.  8. 10.  0.] 
adversary owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0  0  0] -> size -> 15 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  0.] 
cards in discard: [16. 22.  0.  8.  0.  8. 14.  1.  3.  0.  0. 10.  3. 14.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14 16  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [11. 27. 30. 15. 30.  8.  9.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [3. 3. 3.] 
adversary cards in discard: [ 0.  0.  0.  0. 10.  8.  3.  0. 15.  8. 10.  0.] 
adversary owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0  0  0] -> size -> 15 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 66 -------------------- 
Player: 0 
cards in hand: [3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[89.34208]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3.] 
cards in discard: [ 0.  0.  0.  0. 10.  8.  3.  0. 15.  8. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0  0  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 15. 30.  8.  9.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [16. 22.  0.  8.  0.  8. 14.  1.  3.  0.  0. 10.  3. 14.  3. 14.  0.  0.
 29.  0.] 
adversary owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14 16  3] -> size -> 30 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: discard_down_to_3_cards - action 3
Learning step: -4.25058650970459
desired expected reward: 109.6219482421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[80.66288]
 [80.66288]
 [89.23522]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3.] 
cards in discard: [ 0.  0.  0.  0. 10.  8.  3.  0. 15.  8. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0  0  0] -> size -> 15 
action values: 1 
buys: 1 
player value: 0 
card supply: [11. 27. 30. 15. 30.  8.  9.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [16. 22.  0.  8.  0.  8. 14.  1.  3.  0.  0. 10.  3. 14.  3. 14.  0.  0.
 29.  0.] 
adversary owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14 16  3] -> size -> 30 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1.0
Learning step: -3.0328967571258545
desired expected reward: 85.54667663574219



buy possibilites: [-1] 
expected returns: [[72.25512]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3.] 
cards in discard: [ 0.  0.  0.  0. 10.  8.  3.  0. 15.  8. 10.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0  0  0  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 15. 30.  8.  9.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [16. 22.  0.  8.  0.  8. 14.  1.  3.  0.  0. 10.  3. 14.  3. 14.  0.  0.
 29.  0.] 
adversary owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14 16  3] -> size -> 30 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -41 

action type: buy - action 0.0
Learning step: -4.41854190826416
desired expected reward: 76.24433898925781






Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [16. 22.  0.  8.  0.  8. 14.  1.  3.  0.  0. 10.  3. 14.  3. 14.  0.  0.
 29.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14 16  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 27. 30. 15. 30.  8.  9.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0  0  0  0] -> size -> 16 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [16. 22.  0.  8.  0.  8. 14.  1.  3.  0.  0. 10.  3. 14.  3. 14.  0.  0.
 29.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14 16  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 27. 30. 15. 30.  8.  9.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0  0  0  0] -> size -> 16 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [16. 22.  0.  8.  0.  8. 14.  1.  3.  0.  0. 10.  3. 14.  3. 14.  0.  0.
 29.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14 16  3  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 15. 30.  8.  9.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0  0  0  0] -> size -> 16 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 67 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[59.318203]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0  0  0  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 15. 30.  8.  9.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [25. 11. 29.  8. 14.] 
adversary cards in discard: [16. 22.  0.  8.  0.  8. 14.  1.  3.  0.  0. 10.  3. 14.  3. 14.  0.  0.
 29.  0.  1.  3.  0.  0.  0.  3.] 
adversary owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14 16  3  1] -> size -> 31 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1
Learning step: -2.8313589096069336
desired expected reward: 69.42375946044922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[48.6921  ]
 [48.701996]
 [48.696922]
 [48.6921  ]
 [50.62885 ]
 [49.661804]
 [59.01218 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0  0  0  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 26. 30. 15. 30.  8.  9.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [25. 11. 29.  8. 14.] 
adversary cards in discard: [16. 22.  0.  8.  0.  8. 14.  1.  3.  0.  0. 10.  3. 14.  3. 14.  0.  0.
 29.  0.  1.  3.  0.  0.  0.  3.] 
adversary owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14 16  3  1] -> size -> 31 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1.0
Learning step: -2.2718982696533203
desired expected reward: 56.90130615234375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [25. 11. 29.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 29.  8. 14.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11. 29.  8. 14.] 
cards in discard: [16. 22.  0.  8.  0.  8. 14.  1.  3.  0.  0. 10.  3. 14.  3. 14.  0.  0.
 29.  0.  1.  3.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14 16  3  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 15. 30.  8.  9.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 3. 3. 0.] 
adversary owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0  0  0  0] -> size -> 16 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1. 25. 11. 14.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11. 14.  0.] 
cards in discard: [8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14 16  3  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [10. 26. 30. 15. 30.  8.  9.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 3. 3. 0.] 
adversary owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0  0  0  0] -> size -> 16 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 14.  0.  8. 16.] 
cards in discard: [8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14 16  3  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 26. 30. 15. 30.  8.  8.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 3. 3. 0. 6.] 
adversary owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0  0  0  0  6] -> size -> 17 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 14.  0.  8. 16.] 
cards in discard: [8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14 16  3  1] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 26. 30. 15. 30.  8.  8.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 3. 3. 0. 6.] 
adversary owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0  0  0  0  6] -> size -> 17 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 14.  0.  8. 16.] 
cards in discard: [8. 3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14 16  3  1  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 14. 30.  8.  8.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 3. 3. 0. 6.] 
adversary owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0  0  0  0  6] -> size -> 17 
adversary victory points: 4
player victory points: 6 





         -------------------- Turn: 68 -------------------- 
Player: 0 
cards in hand: [8. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[58.775833]
 [48.002403]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [0. 0. 3. 3. 0. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8 10  0  8 10  3  3  3  3  0  0  0  0  0  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 14. 30.  8.  8.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [22. 14. 29.  3.  0.] 
adversary cards in discard: [ 8.  3. 29. 25. 11. 14.  0.  8. 16.] 
adversary owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14 16  3  1  3] -> size -> 32 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[  -5    0    3  -30    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -332 

action type: buy - action -1.0
Learning step: -18.297168731689453
desired expected reward: 40.71500778198242



action possibilites: [-1] 
expected returns: [[47.085747]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [0. 0. 3. 3. 0. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  8 10  8 10  3  3  3  3  0  0  0  0  0  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 14. 30.  8.  8.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [22. 14. 29.  3.  0.] 
adversary cards in discard: [ 8.  3. 29. 25. 11. 14.  0.  8. 16.] 
adversary owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14 16  3  1  3] -> size -> 32 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: trash_cards_n_from_hand - action 1
Learning step: -1.7911159992218018
desired expected reward: 43.21978759765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[41.929935]
 [41.93374 ]
 [41.929935]
 [49.900936]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [0. 0. 3. 3. 0. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  8 10  8 10  3  3  3  3  0  0  0  0  0  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 26. 30. 14. 30.  8.  8.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [22. 14. 29.  3.  0.] 
adversary cards in discard: [ 8.  3. 29. 25. 11. 14.  0.  8. 16.] 
adversary owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14 16  3  1  3] -> size -> 32 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1
Learning step: -1.8960603475570679
desired expected reward: 45.1896858215332






Player: 1 
cards in hand: [22. 14. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 14. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22. 14. 29.  3.  0.] 
cards in discard: [ 8.  3. 29. 25. 11. 14.  0.  8. 16.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14 16  3  1  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 14. 30.  8.  8.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [10. 15. 10.  8.  3.] 
adversary cards in discard: [0. 0. 3. 3. 0. 6. 8. 0. 0.] 
adversary owned cards: [15  8 10  8 10  3  3  3  3  0  0  0  0  0  6] -> size -> 15 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  3.  0.  0.] 
cards in discard: [ 8.  3. 29. 25. 11. 14.  0.  8. 16. 14.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14 16  3  1  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [10. 26. 30. 14. 30.  8.  8.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [10. 15. 10.  8.  3.] 
adversary cards in discard: [0. 0. 3. 3. 0. 6. 8. 0. 0.] 
adversary owned cards: [15  8 10  8 10  3  3  3  3  0  0  0  0  0  6] -> size -> 15 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  3.  0.  0.] 
cards in discard: [ 8.  3. 29. 25. 11. 14.  0.  8. 16. 14.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14 16  3  1  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 26. 30. 14. 30.  8.  8.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [10. 15. 10.  8.  3.] 
adversary cards in discard: [0. 0. 3. 3. 0. 6. 8. 0. 0.] 
adversary owned cards: [15  8 10  8 10  3  3  3  3  0  0  0  0  0  6] -> size -> 15 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  3.  0.  0.] 
cards in discard: [ 8.  3. 29. 25. 11. 14.  0.  8. 16. 14.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14 16  3  1  3  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 9. 26. 30. 14. 30.  8.  8.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [10. 15. 10.  8.  3.] 
adversary cards in discard: [0. 0. 3. 3. 0. 6. 8. 0. 0.] 
adversary owned cards: [15  8 10  8 10  3  3  3  3  0  0  0  0  0  6] -> size -> 15 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 69 -------------------- 
Player: 0 
cards in hand: [10. 15. 10.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 10.  8.] 
expected returns: [[118.62539 ]
 [104.219635]
 [107.2723  ]
 [104.219635]
 [104.318115]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15. 10.  8.  3.] 
cards in discard: [0. 0. 3. 3. 0. 6. 8. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [15  8 10  8 10  3  3  3  3  0  0  0  0  0  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 14. 30.  8.  8.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [14.  0.  3.  0. 14.] 
adversary cards in discard: [ 8.  3. 29. 25. 11. 14.  0.  8. 16. 14.  0. 29. 22.  3.  0.  0.] 
adversary owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14 16  3  1  3  0] -> size -> 33 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: buy - action -1.0
Learning step: -1.5600515604019165
desired expected reward: 48.340885162353516



action possibilites: [-1] 
expected returns: [[109.988945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  8.  3.] 
cards in discard: [0. 0. 3. 3. 0. 6. 8. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  8 10  8 10  3  3  3  3  0  0  0  0  0  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 14. 30.  8.  8.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [14.  0.  3.  0. 14.] 
adversary cards in discard: [ 8.  3. 29. 25. 11. 14.  0.  8. 16. 14.  0. 29. 22.  3.  0.  0.] 
adversary owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14 16  3  1  3  0] -> size -> 33 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action 15.0
Learning step: -3.4523372650146484
desired expected reward: 103.08943176269531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 94.10534 ]
 [ 94.10534 ]
 [110.212494]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  8.  3.] 
cards in discard: [0. 0. 3. 3. 0. 6. 8. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  8 10  8 10  3  3  3  3  0  0  0  0  0  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 26. 30. 14. 30.  8.  8.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [14.  0.  3.  0. 14.] 
adversary cards in discard: [ 8.  3. 29. 25. 11. 14.  0.  8. 16. 14.  0. 29. 22.  3.  0.  0.] 
adversary owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14 16  3  1  3  0] -> size -> 33 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1
Learning step: -3.7356185913085938
desired expected reward: 106.25332641601562



buy possibilites: [-1] 
expected returns: [[76.70964]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  8.  3.] 
cards in discard: [0. 0. 3. 3. 0. 6. 8. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  8 10  8 10  3  3  3  3  0  0  0  0  0  6  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 14. 30.  8.  8.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [14.  0.  3.  0. 14.] 
adversary cards in discard: [ 8.  3. 29. 25. 11. 14.  0.  8. 16. 14.  0. 29. 22.  3.  0.  0.] 
adversary owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14 16  3  1  3  0] -> size -> 33 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: buy - action 0.0
Learning step: -5.0792999267578125
desired expected reward: 89.02603912353516






Player: 1 
cards in hand: [14.  0.  3.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  3.  0. 14.] 
cards in discard: [ 8.  3. 29. 25. 11. 14.  0.  8. 16. 14.  0. 29. 22.  3.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14 16  3  1  3  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 14. 30.  8.  8.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [ 0.  3.  0. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [15  8 10  8 10  3  3  3  3  0  0  0  0  0  6  0] -> size -> 16 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 14.] 
cards in discard: [ 8.  3. 29. 25. 11. 14.  0.  8. 16. 14.  0. 29. 22.  3.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14 16  3  1  3  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 8. 26. 30. 14. 30.  8.  8.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [15.  3.] 
adversary owned cards: [15  8 10  8 10  3  3  3  3  0  0  0  0  0  6  0] -> size -> 16 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 14.] 
cards in discard: [ 8.  3. 29. 25. 11. 14.  0.  8. 16. 14.  0. 29. 22.  3.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14 16  3  1  3  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 8. 26. 30. 14. 30.  8.  8.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [15.  3.] 
adversary owned cards: [15  8 10  8 10  3  3  3  3  0  0  0  0  0  6  0] -> size -> 16 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 70 -------------------- 
Player: 0 
cards in hand: [0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[70.394005]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [15.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [15  8 10  8 10  3  3  3  3  0  0  0  0  0  6  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 14. 30.  8.  8.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [0. 3. 8. 3. 3.] 
adversary cards in discard: [ 8.  3. 29. 25. 11. 14.  0.  8. 16. 14.  0. 29. 22.  3.  0.  0. 14.  0.
  3.  0. 14.] 
adversary owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14 16  3  1  3  0] -> size -> 33 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: discard_down_to_3_cards - action 5
Learning step: -0.5645563006401062
desired expected reward: 9.776267051696777





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[58.06318 ]
 [58.068195]
 [58.06318 ]
 [68.66068 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [15.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [15  8 10  8 10  3  3  3  3  0  0  0  0  0  6  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 26. 30. 14. 30.  8.  8.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [0. 3. 8. 3. 3.] 
adversary cards in discard: [ 8.  3. 29. 25. 11. 14.  0.  8. 16. 14.  0. 29. 22.  3.  0.  0. 14.  0.
  3.  0. 14.] 
adversary owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14 16  3  1  3  0] -> size -> 33 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -3.5909130573272705
desired expected reward: 65.40841674804688



buy possibilites: [-1] 
expected returns: [[85.962105]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [15.  3.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [15  8 10  8 10  3  3  3  3  0  0  0  0  0  6  0  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 13. 30.  8.  8.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [0. 3. 8. 3. 3.] 
adversary cards in discard: [ 8.  3. 29. 25. 11. 14.  0.  8. 16. 14.  0. 29. 22.  3.  0.  0. 14.  0.
  3.  0. 14.] 
adversary owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14 16  3  1  3  0] -> size -> 33 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -13 

action type: buy - action 3.0
Learning step: -1.6192625761032104
desired expected reward: 56.44893264770508






Player: 1 
cards in hand: [0. 3. 8. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 3. 3.] 
cards in discard: [ 8.  3. 29. 25. 11. 14.  0.  8. 16. 14.  0. 29. 22.  3.  0.  0. 14.  0.
  3.  0. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [14 10 22  1  0  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8
 29 14 11 14 16  3  1  3  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 13. 30.  8.  8.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [10.  0.  3.  8.  0.] 
adversary cards in discard: [15.  3.  3.  0.  0.  3.] 
adversary owned cards: [15  8 10  8 10  3  3  3  3  0  0  0  0  0  6  0  3] -> size -> 17 
adversary victory points: 4
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3.] 
cards in discard: [ 8.  3. 29. 25. 11. 14.  0.  8. 16. 14.  0. 29. 22.  3.  0.  0. 14.  0.
  3.  0. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [14 10 22  1  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29
 14 11 14 16  3  1  3  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 13. 30.  8.  8.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [10.  0.  3.  8.  0.] 
adversary cards in discard: [15.  3.  3.  0.  0.  3.] 
adversary owned cards: [15  8 10  8 10  3  3  3  3  0  0  0  0  0  6  0  3] -> size -> 17 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3.] 
cards in discard: [ 8.  3. 29. 25. 11. 14.  0.  8. 16. 14.  0. 29. 22.  3.  0.  0. 14.  0.
  3.  0. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [14 10 22  1  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29
 14 11 14 16  3  1  3  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 26. 30. 13. 30.  8.  8.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [10.  0.  3.  8.  0.] 
adversary cards in discard: [15.  3.  3.  0.  0.  3.] 
adversary owned cards: [15  8 10  8 10  3  3  3  3  0  0  0  0  0  6  0  3] -> size -> 17 
adversary victory points: 4
player victory points: 6 





         -------------------- Turn: 71 -------------------- 
Player: 0 
cards in hand: [10.  0.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[32.637444]
 [25.901722]
 [25.946762]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  8.  0.] 
cards in discard: [15.  3.  3.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [15  8 10  8 10  3  3  3  3  0  0  0  0  0  6  0  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 13. 30.  8.  8.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [ 0.  1.  0. 10.  0.] 
adversary cards in discard: [ 8.  3. 29. 25. 11. 14.  0.  8. 16. 14.  0. 29. 22.  3.  0.  0. 14.  0.
  3.  0. 14.  8.  3.  3.  3.] 
adversary owned cards: [14 10 22  1  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29
 14 11 14 16  3  1  3  0] -> size -> 32 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: buy - action -1
Learning step: -4.676721096038818
desired expected reward: 81.28538513183594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[26.07162 ]
 [26.075026]
 [26.07162 ]
 [33.70183 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  8.  0.] 
cards in discard: [15.  3.  3.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [15  8 10  8 10  3  3  3  3  0  0  0  0  0  6  0  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 26. 30. 13. 30.  8.  8.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [ 0.  1.  0. 10.  0.] 
adversary cards in discard: [ 8.  3. 29. 25. 11. 14.  0.  8. 16. 14.  0. 29. 22.  3.  0.  0. 14.  0.
  3.  0. 14.  8.  3.  3.  3.] 
adversary owned cards: [14 10 22  1  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29
 14 11 14 16  3  1  3  0] -> size -> 32 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: take_action - action -1.0
Learning step: -1.9529424905776978
desired expected reward: 30.036027908325195



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  1.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0. 10.  0.] 
cards in discard: [ 8.  3. 29. 25. 11. 14.  0.  8. 16. 14.  0. 29. 22.  3.  0.  0. 14.  0.
  3.  0. 14.  8.  3.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [14 10 22  1  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29
 14 11 14 16  3  1  3  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 13. 30.  8.  8.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [ 6.  0. 10.  3.  0.] 
adversary cards in discard: [15.  3.  3.  0.  0.  3. 10.  0.  3.  8.  0.] 
adversary owned cards: [15  8 10  8 10  3  3  3  3  0  0  0  0  0  6  0  3] -> size -> 17 
adversary victory points: 4
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0. 1.] 
cards in discard: [ 8.  3. 29. 25. 11. 14.  0.  8. 16. 14.  0. 29. 22.  3.  0.  0. 14.  0.
  3.  0. 14.  8.  3.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [14 10 22  1  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29
 14 11 14 16  3  1  3  0] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 13. 30.  8.  8.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [ 6.  0. 10.  3.  0.] 
adversary cards in discard: [15.  3.  3.  0.  0.  3. 10.  0.  3.  8.  0.] 
adversary owned cards: [15  8 10  8 10  3  3  3  3  0  0  0  0  0  6  0  3] -> size -> 17 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 1.] 
cards in discard: [ 8.  3. 29. 25. 11. 14.  0.  8. 16. 14.  0. 29. 22.  3.  0.  0. 14.  0.
  3.  0. 14.  8.  3.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [14 10 22  1  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29
 14 11 14 16  3  1  3  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 8. 26. 30. 13. 30.  8.  8.  8.  3.  0.  9.  7.  4. 10.  1.  9.  9.] 
adversary cards in hand: [ 6.  0. 10.  3.  0.] 
adversary cards in discard: [15.  3.  3.  0.  0.  3. 10.  0.  3.  8.  0.] 
adversary owned cards: [15  8 10  8 10  3  3  3  3  0  0  0  0  0  6  0  3] -> size -> 17 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 1.] 
cards in discard: [ 8.  3. 29. 25. 11. 14.  0.  8. 16. 14.  0. 29. 22.  3.  0.  0. 14.  0.
  3.  0. 14.  8.  3.  3.  3. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [14 10 22  1  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29
 14 11 14 16  3  1  3  0 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 8. 26. 30. 13. 30.  8.  8.  8.  3.  0.  9.  7.  4. 10.  1.  9.  8.] 
adversary cards in hand: [ 6.  0. 10.  3.  0.] 
adversary cards in discard: [15.  3.  3.  0.  0.  3. 10.  0.  3.  8.  0.] 
adversary owned cards: [15  8 10  8 10  3  3  3  3  0  0  0  0  0  6  0  3] -> size -> 17 
adversary victory points: 4
player victory points: 6 





         -------------------- Turn: 72 -------------------- 
Player: 0 
cards in hand: [ 6.  0. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[63.46416 ]
 [52.729946]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10.  3.  0.] 
cards in discard: [15.  3.  3.  0.  0.  3. 10.  0.  3.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [15  8 10  8 10  3  3  3  3  0  0  0  0  0  6  0  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 13. 30.  8.  8.  8.  3.  0.  9.  7.  4. 10.  1.  9.  8.] 
adversary cards in hand: [ 0. 29. 25. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [14 10 22  1  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29
 14 11 14 16  3  1  3  0 15] -> size -> 33 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: buy - action -1.0
Learning step: -1.3398823738098145
desired expected reward: 31.85753631591797



action possibilites: [-1.  8.] 
expected returns: [[88.45118]
 [78.91856]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0. 8.] 
cards in discard: [15.  3.  3.  0.  0.  3. 10.  0.  3.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [15  8 10  8 10  3  3  3  3  0  0  0  0  0  6  0  3] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 13. 30.  8.  8.  8.  3.  0.  9.  7.  4. 10.  1.  9.  8.] 
adversary cards in hand: [ 0. 29. 25. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [14 10 22  1  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29
 14 11 14 16  3  1  3  0 15] -> size -> 33 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -1 

action type: take_action - action 10.0
Learning step: -0.7478130459785461
desired expected reward: 51.98212432861328



action possibilites: [-1.] 
expected returns: [[53.976955]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [15.  3.  3.  0.  0.  3. 10.  0.  3.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 13. 30.  8.  8.  8.  3.  0.  9.  7.  4. 10.  1.  9.  8.] 
adversary cards in hand: [ 0. 29. 25. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [14 10 22  1  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29
 14 11 14 16  3  1  3  0 15] -> size -> 33 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 19 

action type: trash_cards_n_from_hand - action 12
Learning step: -1.7462528944015503
desired expected reward: 76.46842956542969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[47.073605]
 [47.073605]
 [55.185284]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [15.  3.  3.  0.  0.  3. 10.  0.  3.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3] -> size -> 13 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 8. 26. 30. 13. 30.  8.  8.  8.  3.  0.  9.  7.  4. 10.  1.  9.  8.] 
adversary cards in hand: [ 0. 29. 25. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [14 10 22  1  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29
 14 11 14 16  3  1  3  0 15] -> size -> 33 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 19 

action type: take_action - action -1.0
Learning step: -0.5655733346939087
desired expected reward: 53.411380767822266



buy possibilites: [-1] 
expected returns: [[92.40723]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [15.  3.  3.  0.  0.  3. 10.  0.  3.  8.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 13. 30.  8.  7.  8.  3.  0.  9.  7.  4. 10.  1.  9.  8.] 
adversary cards in hand: [ 0. 29. 25. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [14 10 22  1  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29
 14 11 14 16  3  1  3  0 15] -> size -> 33 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[  -5    0    3  -30    0    0   40    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -292 

action type: buy - action 6.0
Learning step: -14.874518394470215
desired expected reward: 32.1990852355957






Player: 1 
cards in hand: [ 0. 29. 25. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 10.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 25. 10.  0.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [14 10 22  1  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29
 14 11 14 16  3  1  3  0 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 13. 30.  8.  7.  8.  3.  0.  9.  7.  4. 10.  1.  9.  8.] 
adversary cards in hand: [ 0.  3. 10. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6] -> size -> 14 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [14 10 22  1  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29
 14 11 14 16  3  1  3  0 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 13. 30.  8.  6.  8.  3.  0.  9.  7.  4. 10.  1.  9.  8.] 
adversary cards in hand: [ 0.  3. 10. 10.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6] -> size -> 15 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 10.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [14 10 22  1  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29
 14 11 14 16  3  1  3  0 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 26. 30. 13. 30.  8.  6.  8.  3.  0.  9.  7.  4. 10.  1.  9.  8.] 
adversary cards in hand: [ 0.  3. 10. 10.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6] -> size -> 15 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 10.  0.  0.  8.] 
cards in discard: [3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [14 10 22  1  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29
 14 11 14 16  3  1  3  0 15  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 26. 30. 12. 30.  8.  6.  8.  3.  0.  9.  7.  4. 10.  1.  9.  8.] 
adversary cards in hand: [ 0.  3. 10. 10.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6] -> size -> 15 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 73 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[95.03776]
 [86.75861]
 [86.75861]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10. 10.  0.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 12. 30.  8.  6.  8.  3.  0.  9.  7.  4. 10.  1.  9.  8.] 
adversary cards in hand: [ 0.  0. 14.  0. 14.] 
adversary cards in discard: [ 3. 25.  0. 29. 10.  0.  0.  8.] 
adversary owned cards: [14 10 22  1  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29
 14 11 14 16  3  1  3  0 15  3] -> size -> 34 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    2  -50    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -353 

action type: buy - action -1
Learning step: -20.217267990112305
desired expected reward: 72.18995666503906



action possibilites: [-1. 10.  8.] 
expected returns: [[37.647953]
 [29.514421]
 [29.568441]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  0.  8.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 12. 30.  8.  6.  8.  3.  0.  9.  7.  4. 10.  1.  9.  8.] 
adversary cards in hand: [ 0.  0. 14.  0. 14.] 
adversary cards in discard: [ 3. 25.  0. 29. 10.  0.  0.  8.] 
adversary owned cards: [14 10 22  1  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29
 14 11 14 16  3  1  3  0 15  3] -> size -> 34 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action 10.0
Learning step: -5.14269495010376
desired expected reward: 80.48563385009766



action possibilites: [-1.  8.] 
expected returns: [[79.07922]
 [71.33643]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8. 3.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6] -> size -> 15 
action values: 3 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 12. 30.  8.  6.  8.  3.  0.  9.  7.  4. 10.  1.  9.  8.] 
adversary cards in hand: [ 0.  0. 14.  0. 14.] 
adversary cards in discard: [ 3. 25.  0. 29. 10.  0.  0.  8.] 
adversary owned cards: [14 10 22  1  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29
 14 11 14 16  3  1  3  0 15  3] -> size -> 34 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action 10.0
Learning step: -0.38824254274368286
desired expected reward: 29.126176834106445





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[72.988655]
 [72.99318 ]
 [72.988655]
 [81.691086]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 8. 3.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 26. 30. 12. 30.  8.  6.  8.  3.  0.  9.  7.  4. 10.  1.  9.  8.] 
adversary cards in hand: [ 0.  0. 14.  0. 14.] 
adversary cards in discard: [ 3. 25.  0. 29. 10.  0.  0.  8.] 
adversary owned cards: [14 10 22  1  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29
 14 11 14 16  3  1  3  0 15  3] -> size -> 34 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -2.8363780975341797
desired expected reward: 76.24285888671875






Player: 1 
cards in hand: [ 0.  0. 14.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  0. 14.] 
cards in discard: [ 3. 25.  0. 29. 10.  0.  0.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [14 10 22  1  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29
 14 11 14 16  3  1  3  0 15  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 12. 30.  8.  6.  8.  3.  0.  9.  7.  4. 10.  1.  9.  8.] 
adversary cards in hand: [ 0.  3. 15.  0.  8.] 
adversary cards in discard: [ 6. 10. 10.  0.  3.  0.  8.  3.] 
adversary owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6] -> size -> 15 
adversary victory points: 2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 14.] 
cards in discard: [ 3. 25.  0. 29. 10.  0.  0.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [14.] 
owned cards: [14 10 22  1  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29
 14 11 14 16  3  1  3  0 15  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 8. 26. 30. 12. 30.  8.  6.  8.  3.  0.  9.  7.  4. 10.  1.  9.  8.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [ 6. 10. 10.  0.  3.  0.  8.  3.  3. 15.] 
adversary owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6] -> size -> 15 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 14.] 
cards in discard: [ 3. 25.  0. 29. 10.  0.  0.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [14.] 
owned cards: [14 10 22  1  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29
 14 11 14 16  3  1  3  0 15  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 8. 26. 30. 12. 30.  8.  6.  8.  3.  0.  9.  7.  4. 10.  1.  9.  8.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [ 6. 10. 10.  0.  3.  0.  8.  3.  3. 15.] 
adversary owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6] -> size -> 15 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 14.] 
cards in discard: [ 3. 25.  0. 29. 10.  0.  0.  8. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [14.] 
owned cards: [14 10 22  1  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29
 14 11 14 16  3  1  3  0 15  3 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 26. 30. 12. 30.  8.  6.  8.  3.  0.  9.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [ 6. 10. 10.  0.  3.  0.  8.  3.  3. 15.] 
adversary owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6] -> size -> 15 
adversary victory points: 2
player victory points: 7 





         -------------------- Turn: 74 -------------------- 
Player: 0 
cards in hand: [0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[20.587692]
 [14.418471]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [ 6. 10. 10.  0.  3.  0.  8.  3.  3. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 12. 30.  8.  6.  8.  3.  0.  9.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 3. 16.  8.  3.  1.] 
adversary cards in discard: [ 3. 25.  0. 29. 10.  0.  0.  8. 15. 14.  0.  0.  0. 14.] 
adversary owned cards: [14 10 22  1  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29
 14 11 14 16  3  1  3  0 15  3 15] -> size -> 35 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: discard_down_to_3_cards - action 8
Learning step: -4.029294013977051
desired expected reward: 31.979557037353516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[14.49534 ]
 [14.498842]
 [14.49534 ]
 [21.397404]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [ 6. 10. 10.  0.  3.  0.  8.  3.  3. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 26. 30. 12. 30.  8.  6.  8.  3.  0.  9.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 3. 16.  8.  3.  1.] 
adversary cards in discard: [ 3. 25.  0. 29. 10.  0.  0.  8. 15. 14.  0.  0.  0. 14.] 
adversary owned cards: [14 10 22  1  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29
 14 11 14 16  3  1  3  0 15  3 15] -> size -> 35 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: take_action - action -1.0
Learning step: -3.234182834625244
desired expected reward: 16.960548400878906



buy possibilites: [-1] 
expected returns: [[33.364613]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [ 6. 10. 10.  0.  3.  0.  8.  3.  3. 15.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 11. 30.  8.  6.  8.  3.  0.  9.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 3. 16.  8.  3.  1.] 
adversary cards in discard: [ 3. 25.  0. 29. 10.  0.  0.  8. 15. 14.  0.  0.  0. 14.] 
adversary owned cards: [14 10 22  1  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29
 14 11 14 16  3  1  3  0 15  3 15] -> size -> 35 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -34 

action type: buy - action 3.0
Learning step: -1.6742382049560547
desired expected reward: 12.824600219726562






Player: 1 
cards in hand: [ 3. 16.  8.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  8.  3.  1.] 
cards in discard: [ 3. 25.  0. 29. 10.  0.  0.  8. 15. 14.  0.  0.  0. 14.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [14 10 22  1  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29
 14 11 14 16  3  1  3  0 15  3 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 11. 30.  8.  6.  8.  3.  0.  9.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 8. 10.  3.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3] -> size -> 16 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  8.  3.  1.] 
cards in discard: [ 3. 25.  0. 29. 10.  0.  0.  8. 15. 14.  0.  0.  0. 14.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [14 10 22  1  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29
 14 11 14 16  3  1  3  0 15  3 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 26. 30. 11. 30.  8.  6.  8.  3.  0.  9.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 8. 10.  3.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3] -> size -> 16 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  8.  3.  1.] 
cards in discard: [ 3. 25.  0. 29. 10.  0.  0.  8. 15. 14.  0.  0.  0. 14.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [14 10 22  1  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29
 14 11 14 16  3  1  3  0 15  3 15  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 10. 30.  8.  6.  8.  3.  0.  9.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 8. 10.  3.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3] -> size -> 16 
adversary victory points: 3
player victory points: 8 





         -------------------- Turn: 75 -------------------- 
Player: 0 
cards in hand: [ 8. 10.  3.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[70.32272 ]
 [62.37106 ]
 [62.316647]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  3.  3.  6.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 10. 30.  8.  6.  8.  3.  0.  9.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 3. 11.  1. 29.  8.] 
adversary cards in discard: [ 3. 25.  0. 29. 10.  0.  0.  8. 15. 14.  0.  0.  0. 14.  3.  3. 16.  8.
  3.  1.] 
adversary owned cards: [14 10 22  1  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29
 14 11 14 16  3  1  3  0 15  3 15  3] -> size -> 36 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -52 

action type: buy - action -1
Learning step: -2.751453161239624
desired expected reward: 30.6131591796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[61.55633]
 [61.55633]
 [70.39802]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  3.  3.  6.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3] -> size -> 16 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 8. 26. 30. 10. 30.  8.  6.  8.  3.  0.  9.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 3. 11.  1. 29.  8.] 
adversary cards in discard: [ 3. 25.  0. 29. 10.  0.  0.  8. 15. 14.  0.  0.  0. 14.  3.  3. 16.  8.
  3.  1.] 
adversary owned cards: [14 10 22  1  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29
 14 11 14 16  3  1  3  0 15  3 15  3] -> size -> 36 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -52 

action type: take_action - action -1.0
Learning step: -4.578009605407715
desired expected reward: 65.38829803466797



buy possibilites: [-1] 
expected returns: [[26.602839]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  3.  3.  6.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 10. 30.  8.  5.  8.  3.  0.  9.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 3. 11.  1. 29.  8.] 
adversary cards in discard: [ 3. 25.  0. 29. 10.  0.  0.  8. 15. 14.  0.  0.  0. 14.  3.  3. 16.  8.
  3.  1.] 
adversary owned cards: [14 10 22  1  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29
 14 11 14 16  3  1  3  0 15  3 15  3] -> size -> 36 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[  -5    0    2  -60    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -363 

action type: buy - action 6.0
Learning step: -20.335182189941406
desired expected reward: 35.33975601196289






Player: 1 
cards in hand: [ 3. 11.  1. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  1. 29.  8.] 
cards in discard: [ 3. 25.  0. 29. 10.  0.  0.  8. 15. 14.  0.  0.  0. 14.  3.  3. 16.  8.
  3.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [14 10 22  1  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29
 14 11 14 16  3  1  3  0 15  3 15  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 10. 30.  8.  5.  8.  3.  0.  9.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [ 6.  8. 10.  3.  3.  6.] 
adversary owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6] -> size -> 17 
adversary victory points: 2
player victory points: 8 


action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  8.  3.] 
cards in discard: [ 3. 25.  0. 29. 10.  0.  0.  8. 15. 14.  0.  0.  0. 14.  3.  3. 16.  8.
  3.  1.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [14 10 22  1  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29
 14 11 14 16  3  1  3  0 15  3 15  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 8. 26. 30. 10. 30.  8.  5.  8.  3.  0.  9.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [ 6.  8. 10.  3.  3.  6.] 
adversary owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6] -> size -> 17 
adversary victory points: 2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  8.  3.] 
cards in discard: [ 3. 25.  0. 29. 10.  0.  0.  8. 15. 14.  0.  0.  0. 14.  3.  3. 16.  8.
  3.  1.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [14 10 22  1  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29
 14 11 14 16  3  1  3  0 15  3 15  3] -> size -> 36 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 8. 26. 30. 10. 30.  8.  5.  8.  3.  0.  9.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [ 6.  8. 10.  3.  3.  6.] 
adversary owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6] -> size -> 17 
adversary victory points: 2
player victory points: 8 





         -------------------- Turn: 76 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[8.98042  ]
 [5.0439644]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 8.] 
cards in discard: [ 6.  8. 10.  3.  3.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 10. 30.  8.  5.  8.  3.  0.  9.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [14. 22. 15.  0.  0.] 
adversary cards in discard: [ 3. 25.  0. 29. 10.  0.  0.  8. 15. 14.  0.  0.  0. 14.  3.  3. 16.  8.
  3.  1.  1. 29.  3. 11.  8.  3.] 
adversary owned cards: [14 10 22  1  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29
 14 11 14 16  3  1  3  0 15  3 15  3] -> size -> 36 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: buy - action -1
Learning step: -4.299335956573486
desired expected reward: 22.303503036499023





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[5.3150325]
 [5.319254 ]
 [5.317189 ]
 [5.3150325]
 [6.088278 ]
 [5.6958413]
 [9.940876 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 8.] 
cards in discard: [ 6.  8. 10.  3.  3.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 26. 30. 10. 30.  8.  5.  8.  3.  0.  9.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [14. 22. 15.  0.  0.] 
adversary cards in discard: [ 3. 25.  0. 29. 10.  0.  0.  8. 15. 14.  0.  0.  0. 14.  3.  3. 16.  8.
  3.  1.  1. 29.  3. 11.  8.  3.] 
adversary owned cards: [14 10 22  1  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29
 14 11 14 16  3  1  3  0 15  3 15  3] -> size -> 36 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: take_action - action -1.0
Learning step: -3.4163761138916016
desired expected reward: 5.564044952392578



buy possibilites: [-1] 
expected returns: [[24.584738]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 8.] 
cards in discard: [ 6.  8. 10.  3.  3.  6. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 10. 30.  8.  5.  8.  2.  0.  9.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [14. 22. 15.  0.  0.] 
adversary cards in discard: [ 3. 25.  0. 29. 10.  0.  0.  8. 15. 14.  0.  0.  0. 14.  3.  3. 16.  8.
  3.  1.  1. 29.  3. 11.  8.  3.] 
adversary owned cards: [14 10 22  1  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29
 14 11 14 16  3  1  3  0 15  3 15  3] -> size -> 36 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -45 

action type: buy - action 11.0
Learning step: -2.0012574195861816
desired expected reward: 4.087021350860596






Player: 1 
cards in hand: [14. 22. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 22. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 22. 15.  0.  0.] 
cards in discard: [ 3. 25.  0. 29. 10.  0.  0.  8. 15. 14.  0.  0.  0. 14.  3.  3. 16.  8.
  3.  1.  1. 29.  3. 11.  8.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [14 10 22  1  0  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29
 14 11 14 16  3  1  3  0 15  3 15  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 10. 30.  8.  5.  8.  2.  0.  9.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 3.  6.  0.  3. 10.] 
adversary cards in discard: [ 6.  8. 10.  3.  3.  6. 11.  0.  0.  3.  0.  8.] 
adversary owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6 11] -> size -> 18 
adversary victory points: 2
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 22.  0.] 
cards in discard: [ 3. 25.  0. 29. 10.  0.  0.  8. 15. 14.  0.  0.  0. 14.  3.  3. 16.  8.
  3.  1.  1. 29.  3. 11.  8.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [14 10 22  1  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29 14
 11 14 16  3  1  3  0 15  3 15  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 8. 26. 30. 10. 30.  8.  5.  8.  2.  0.  9.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 3.  6.  0.  3. 10.] 
adversary cards in discard: [ 6.  8. 10.  3.  3.  6. 11.  0.  0.  3.  0.  8.] 
adversary owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6 11] -> size -> 18 
adversary victory points: 2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 22.  0.] 
cards in discard: [ 3. 25.  0. 29. 10.  0.  0.  8. 15. 14.  0.  0.  0. 14.  3.  3. 16.  8.
  3.  1.  1. 29.  3. 11.  8.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [14 10 22  1  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29 14
 11 14 16  3  1  3  0 15  3 15  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 8. 26. 30. 10. 30.  8.  5.  8.  2.  0.  9.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 3.  6.  0.  3. 10.] 
adversary cards in discard: [ 6.  8. 10.  3.  3.  6. 11.  0.  0.  3.  0.  8.] 
adversary owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6 11] -> size -> 18 
adversary victory points: 2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 22.  0.] 
cards in discard: [ 3. 25.  0. 29. 10.  0.  0.  8. 15. 14.  0.  0.  0. 14.  3.  3. 16.  8.
  3.  1.  1. 29.  3. 11.  8.  3.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [14 10 22  1  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29 14
 11 14 16  3  1  3  0 15  3 15  3  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 25. 30. 10. 30.  8.  5.  8.  2.  0.  9.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 3.  6.  0.  3. 10.] 
adversary cards in discard: [ 6.  8. 10.  3.  3.  6. 11.  0.  0.  3.  0.  8.] 
adversary owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6 11] -> size -> 18 
adversary victory points: 2
player victory points: 8 





         -------------------- Turn: 77 -------------------- 
Player: 0 
cards in hand: [ 3.  6.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[58.409878]
 [51.935146]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  0.  3. 10.] 
cards in discard: [ 6.  8. 10.  3.  3.  6. 11.  0.  0.  3.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 10. 30.  8.  5.  8.  2.  0.  9.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 0.  0. 14.  3.  3.] 
adversary cards in discard: [ 3. 25.  0. 29. 10.  0.  0.  8. 15. 14.  0.  0.  0. 14.  3.  3. 16.  8.
  3.  1.  1. 29.  3. 11.  8.  3.  1. 15. 14. 22.  0.] 
adversary owned cards: [14 10 22  1  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29 14
 11 14 16  3  1  3  0 15  3 15  3  1] -> size -> 36 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: buy - action -1
Learning step: -3.0999724864959717
desired expected reward: 21.484766006469727





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[52.175785]
 [52.175785]
 [59.36485 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  0.  3. 10.] 
cards in discard: [ 6.  8. 10.  3.  3.  6. 11.  0.  0.  3.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 25. 30. 10. 30.  8.  5.  8.  2.  0.  9.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 0.  0. 14.  3.  3.] 
adversary cards in discard: [ 3. 25.  0. 29. 10.  0.  0.  8. 15. 14.  0.  0.  0. 14.  3.  3. 16.  8.
  3.  1.  1. 29.  3. 11.  8.  3.  1. 15. 14. 22.  0.] 
adversary owned cards: [14 10 22  1  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29 14
 11 14 16  3  1  3  0 15  3 15  3  1] -> size -> 36 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: take_action - action -1.0
Learning step: -4.7865376472473145
desired expected reward: 53.62334442138672



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0. 14.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  3.  3.] 
cards in discard: [ 3. 25.  0. 29. 10.  0.  0.  8. 15. 14.  0.  0.  0. 14.  3.  3. 16.  8.
  3.  1.  1. 29.  3. 11.  8.  3.  1. 15. 14. 22.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [14 10 22  1  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29 14
 11 14 16  3  1  3  0 15  3 15  3  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 10. 30.  8.  5.  8.  2.  0.  9.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 3. 10.  8.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6 11] -> size -> 18 
adversary victory points: 2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  3.  3.] 
cards in discard: [ 3. 25.  0. 29. 10.  0.  0.  8. 15. 14.  0.  0.  0. 14.  3.  3. 16.  8.
  3.  1.  1. 29.  3. 11.  8.  3.  1. 15. 14. 22.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [14 10 22  1  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29 14
 11 14 16  3  1  3  0 15  3 15  3  1] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 25. 30. 10. 30.  8.  5.  8.  2.  0.  9.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 3. 10.  8.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6 11] -> size -> 18 
adversary victory points: 2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  3.  3.] 
cards in discard: [ 3. 25.  0. 29. 10.  0.  0.  8. 15. 14.  0.  0.  0. 14.  3.  3. 16.  8.
  3.  1.  1. 29.  3. 11.  8.  3.  1. 15. 14. 22.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [14 10 22  1  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29 14
 11 14 16  3  1  3  0 15  3 15  3  1  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 7. 25. 30. 10. 30.  8.  5.  8.  2.  0.  9.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 3. 10.  8.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6 11] -> size -> 18 
adversary victory points: 2
player victory points: 8 





         -------------------- Turn: 78 -------------------- 
Player: 0 
cards in hand: [ 3. 10.  8.  6. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 15.] 
expected returns: [[35.616993]
 [26.235746]
 [26.296968]
 [28.135736]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  8.  6. 15.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30. 10. 30.  8.  5.  8.  2.  0.  9.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 0.  3.  0. 14. 10.] 
adversary cards in discard: [] 
adversary owned cards: [14 10 22  1  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29 14
 11 14 16  3  1  3  0 15  3 15  3  1  0] -> size -> 37 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: buy - action -1.0
Learning step: -5.3927693367004395
desired expected reward: 53.972084045410156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[26.06251 ]
 [26.06251 ]
 [36.465504]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  8.  6. 15.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6 11] -> size -> 18 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 7. 25. 30. 10. 30.  8.  5.  8.  2.  0.  9.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 0.  3.  0. 14. 10.] 
adversary cards in discard: [] 
adversary owned cards: [14 10 22  1  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29 14
 11 14 16  3  1  3  0 15  3 15  3  1  0] -> size -> 37 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: take_action - action -1.0
Learning step: -4.173125743865967
desired expected reward: 31.20107650756836



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3.  0. 14. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 14. 10.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [14 10 22  1  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29 14
 11 14 16  3  1  3  0 15  3 15  3  1  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30. 10. 30.  8.  5.  8.  2.  0.  9.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 3.  3.  0.  3. 11.] 
adversary cards in discard: [ 3. 10.  8.  6. 15.] 
adversary owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6 11] -> size -> 18 
adversary victory points: 2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 14. 10.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [14 10 22  1  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29 14
 11 14 16  3  1  3  0 15  3 15  3  1  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 25. 30. 10. 30.  8.  5.  8.  2.  0.  9.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 3.  3.  0.  3. 11.] 
adversary cards in discard: [ 3. 10.  8.  6. 15.] 
adversary owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6 11] -> size -> 18 
adversary victory points: 2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 14. 10.] 
cards in discard: [3.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [14 10 22  1  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29 14
 11 14 16  3  1  3  0 15  3 15  3  1  0  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30.  9. 30.  8.  5.  8.  2.  0.  9.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 3.  3.  0.  3. 11.] 
adversary cards in discard: [ 3. 10.  8.  6. 15.] 
adversary owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6 11] -> size -> 18 
adversary victory points: 2
player victory points: 9 





         -------------------- Turn: 79 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[40.421543]
 [34.505596]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  3. 11.] 
cards in discard: [ 3. 10.  8.  6. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30.  9. 30.  8.  5.  8.  2.  0.  9.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 0.  0.  3. 25.  3.] 
adversary cards in discard: [ 3.  0.  3.  0. 14. 10.] 
adversary owned cards: [14 10 22  1  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29 14
 11 14 16  3  1  3  0 15  3 15  3  1  0  3] -> size -> 38 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: buy - action -1.0
Learning step: -4.595731258392334
desired expected reward: 31.869768142700195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[33.975327]
 [33.975327]
 [41.300537]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  3. 11.] 
cards in discard: [ 3. 10.  8.  6. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 25. 30.  9. 30.  8.  5.  8.  2.  0.  9.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 0.  0.  3. 25.  3.] 
adversary cards in discard: [ 3.  0.  3.  0. 14. 10.] 
adversary owned cards: [14 10 22  1  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29 14
 11 14 16  3  1  3  0 15  3 15  3  1  0  3] -> size -> 38 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: take_action - action -1.0
Learning step: -4.794548034667969
desired expected reward: 35.62699890136719



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0.  3. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 25.  3.] 
cards in discard: [ 3.  0.  3.  0. 14. 10.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [14 10 22  1  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29 14
 11 14 16  3  1  3  0 15  3 15  3  1  0  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30.  9. 30.  8.  5.  8.  2.  0.  9.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 6. 10.  0.  0.  6.] 
adversary cards in discard: [ 3. 10.  8.  6. 15.  3.  3.  0.  3. 11.] 
adversary owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6 11] -> size -> 18 
adversary victory points: 2
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  3. 15. 14.] 
cards in discard: [ 3.  0.  3.  0. 14. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [14 10 22  1  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29 14
 11 14 16  3  1  3  0 15  3 15  3  1  0  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30.  9. 30.  8.  4.  8.  2.  0.  9.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 6. 10.  0.  0.  6.] 
adversary cards in discard: [ 3. 10.  8.  6. 15.  3.  3.  0.  3. 11.  6.] 
adversary owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6 11  6] -> size -> 19 
adversary victory points: 2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  3. 15. 14.] 
cards in discard: [ 3.  0.  3.  0. 14. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [14 10 22  1  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29 14
 11 14 16  3  1  3  0 15  3 15  3  1  0  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 25. 30.  9. 30.  8.  4.  8.  2.  0.  9.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 6. 10.  0.  0.  6.] 
adversary cards in discard: [ 3. 10.  8.  6. 15.  3.  3.  0.  3. 11.  6.] 
adversary owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6 11  6] -> size -> 19 
adversary victory points: 2
player victory points: 9 





         -------------------- Turn: 80 -------------------- 
Player: 0 
cards in hand: [ 6. 10.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[39.733364]
 [31.895273]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.  0.  6.] 
cards in discard: [ 3. 10.  8.  6. 15.  3.  3.  0.  3. 11.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6 11  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30.  9. 30.  8.  4.  8.  2.  0.  9.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [22.  0.  3.  3. 29.] 
adversary cards in discard: [ 3.  0.  3.  0. 14. 10. 25.  0.  0.  3.  3. 15. 14.] 
adversary owned cards: [14 10 22  1  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29 14
 11 14 16  3  1  3  0 15  3 15  3  1  0  3] -> size -> 38 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[  -5    0    1  -80    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -384 

action type: buy - action -1.0
Learning step: -20.413345336914062
desired expected reward: 20.887195587158203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[32.860775]
 [32.86452 ]
 [32.860775]
 [40.918606]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0.  0.  6.] 
cards in discard: [ 3. 10.  8.  6. 15.  3.  3.  0.  3. 11.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6 11  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 25. 30.  9. 30.  8.  4.  8.  2.  0.  9.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [22.  0.  3.  3. 29.] 
adversary cards in discard: [ 3.  0.  3.  0. 14. 10. 25.  0.  0.  3.  3. 15. 14.] 
adversary owned cards: [14 10 22  1  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29 14
 11 14 16  3  1  3  0 15  3 15  3  1  0  3] -> size -> 38 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: take_action - action -1.0
Learning step: -5.331246852874756
desired expected reward: 34.40211486816406



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [22.  0.  3.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 29.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  0.  3.  3. 29.] 
cards in discard: [ 3.  0.  3.  0. 14. 10. 25.  0.  0.  3.  3. 15. 14.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [14 10 22  1  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29 14
 11 14 16  3  1  3  0 15  3 15  3  1  0  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30.  9. 30.  8.  4.  8.  2.  0.  9.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 6. 10.  3.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6 11  6] -> size -> 19 
adversary victory points: 1
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 29.  8.  1.  1.] 
cards in discard: [ 3.  0.  3.  0. 14. 10. 25.  0.  0.  3.  3. 15. 14.] 
cards in deck: 16 
card top of deck: [] 
played cards: [22.  8.] 
owned cards: [14 10 22  1  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29 14
 11 14 16  3  1  3  0 15  3 15  3  1  0  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30.  9. 30.  8.  4.  8.  2.  0.  9.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 6. 10.  3.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6 11  6] -> size -> 19 
adversary victory points: 1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 29.  8.  1.  1.] 
cards in discard: [ 3.  0.  3.  0. 14. 10. 25.  0.  0.  3.  3. 15. 14.] 
cards in deck: 16 
card top of deck: [] 
played cards: [22.  8.] 
owned cards: [14 10 22  1  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29 14
 11 14 16  3  1  3  0 15  3 15  3  1  0  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 7. 25. 30.  9. 30.  8.  4.  8.  2.  0.  9.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 6. 10.  3.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6 11  6] -> size -> 19 
adversary victory points: 1
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 29.  8.  1.  1.] 
cards in discard: [ 3.  0.  3.  0. 14. 10. 25.  0.  0.  3.  3. 15. 14. 25.] 
cards in deck: 16 
card top of deck: [] 
played cards: [22.  8.] 
owned cards: [14 10 22  1  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29 14
 11 14 16  3  1  3  0 15  3 15  3  1  0  3 25] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30.  9. 30.  8.  4.  8.  2.  0.  8.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 6. 10.  3.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6 11  6] -> size -> 19 
adversary victory points: 1
player victory points: 9 





         -------------------- Turn: 81 -------------------- 
Player: 0 
cards in hand: [ 6. 10.  3.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[35.65919 ]
 [28.81516 ]
 [28.860132]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  3.  0.  8.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6 11  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30.  9. 30.  8.  4.  8.  2.  0.  8.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 3.  0. 29. 14.  0.] 
adversary cards in discard: [ 3.  0.  3.  0. 14. 10. 25.  0.  0.  3.  3. 15. 14. 25. 22.  8.  0.  3.
  3. 29.  8.  1.  1.] 
adversary owned cards: [14 10 22  1  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29 14
 11 14 16  3  1  3  0 15  3 15  3  1  0  3 25] -> size -> 39 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: buy - action -1.0
Learning step: -5.503091335296631
desired expected reward: 35.41551208496094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[28.058893]
 [28.058893]
 [35.604656]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  3.  0.  8.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6 11  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 25. 30.  9. 30.  8.  4.  8.  2.  0.  8.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 3.  0. 29. 14.  0.] 
adversary cards in discard: [ 3.  0.  3.  0. 14. 10. 25.  0.  0.  3.  3. 15. 14. 25. 22.  8.  0.  3.
  3. 29.  8.  1.  1.] 
adversary owned cards: [14 10 22  1  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29 14
 11 14 16  3  1  3  0 15  3 15  3  1  0  3 25] -> size -> 39 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: take_action - action -1.0
Learning step: -5.2125139236450195
desired expected reward: 29.973445892333984



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  0. 29. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29. 14.  0.] 
cards in discard: [ 3.  0.  3.  0. 14. 10. 25.  0.  0.  3.  3. 15. 14. 25. 22.  8.  0.  3.
  3. 29.  8.  1.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [14 10 22  1  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29 14
 11 14 16  3  1  3  0 15  3 15  3  1  0  3 25] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30.  9. 30.  8.  4.  8.  2.  0.  8.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 3. 10. 11.  3.  0.] 
adversary cards in discard: [ 6. 10.  3.  0.  8.] 
adversary owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6 11  6] -> size -> 19 
adversary victory points: 1
player victory points: 9 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 1.] 
cards in discard: [ 3.  0.  3.  0. 14. 10. 25.  0.  0.  3.  3. 15. 14. 25. 22.  8.  0.  3.
  3. 29.  8.  1.  1. 14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [14 10 22  1  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29 14
 11 14 16  3  1  3  0 15  3 15  3  1  0  3 25] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 7. 25. 30.  9. 30.  8.  4.  8.  2.  0.  8.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 3. 10. 11.  3.  0.] 
adversary cards in discard: [ 6. 10.  3.  0.  8.] 
adversary owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6 11  6] -> size -> 19 
adversary victory points: 1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1.] 
cards in discard: [ 3.  0.  3.  0. 14. 10. 25.  0.  0.  3.  3. 15. 14. 25. 22.  8.  0.  3.
  3. 29.  8.  1.  1. 14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [14 10 22  1  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29 14
 11 14 16  3  1  3  0 15  3 15  3  1  0  3 25] -> size -> 39 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 7. 25. 30.  9. 30.  8.  4.  8.  2.  0.  8.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 3. 10. 11.  3.  0.] 
adversary cards in discard: [ 6. 10.  3.  0.  8.] 
adversary owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6 11  6] -> size -> 19 
adversary victory points: 1
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1.] 
cards in discard: [ 3.  0.  3.  0. 14. 10. 25.  0.  0.  3.  3. 15. 14. 25. 22.  8.  0.  3.
  3. 29.  8.  1.  1. 14. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [14 10 22  1  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29 14
 11 14 16  3  1  3  0 15  3 15  3  1  0  3 25 25] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30.  9. 30.  8.  4.  8.  2.  0.  7.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 3. 10. 11.  3.  0.] 
adversary cards in discard: [ 6. 10.  3.  0.  8.] 
adversary owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6 11  6] -> size -> 19 
adversary victory points: 1
player victory points: 9 





         -------------------- Turn: 82 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[13.68882 ]
 [ 9.0737  ]
 [ 9.510127]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11.  3.  0.] 
cards in discard: [ 6. 10.  3.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6 11  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30.  9. 30.  8.  4.  8.  2.  0.  7.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 0. 14.  3. 16. 15.] 
adversary cards in discard: [ 3.  0.  3.  0. 14. 10. 25.  0.  0.  3.  3. 15. 14. 25. 22.  8.  0.  3.
  3. 29.  8.  1.  1. 14. 25. 29.  3.  0.  0.  1.] 
adversary owned cards: [14 10 22  1  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29 14
 11 14 16  3  1  3  0 15  3 15  3  1  0  3 25 25] -> size -> 40 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: buy - action -1.0
Learning step: -5.703887462615967
desired expected reward: 29.900768280029297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 8.816265]
 [ 8.816265]
 [13.954205]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 11.  3.  0.] 
cards in discard: [ 6. 10.  3.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6 11  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 25. 30.  9. 30.  8.  4.  8.  2.  0.  7.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 0. 14.  3. 16. 15.] 
adversary cards in discard: [ 3.  0.  3.  0. 14. 10. 25.  0.  0.  3.  3. 15. 14. 25. 22.  8.  0.  3.
  3. 29.  8.  1.  1. 14. 25. 29.  3.  0.  0.  1.] 
adversary owned cards: [14 10 22  1  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29 14
 11 14 16  3  1  3  0 15  3 15  3  1  0  3 25 25] -> size -> 40 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: take_action - action -1.0
Learning step: -4.607458591461182
desired expected reward: 9.081361770629883



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 14.  3. 16. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16. 15.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3. 16. 15.] 
cards in discard: [ 3.  0.  3.  0. 14. 10. 25.  0.  0.  3.  3. 15. 14. 25. 22.  8.  0.  3.
  3. 29.  8.  1.  1. 14. 25. 29.  3.  0.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [14 10 22  1  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29 14
 11 14 16  3  1  3  0 15  3 15  3  1  0  3 25 25] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30.  9. 30.  8.  4.  8.  2.  0.  7.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [15.  6.  0.  3.  6.] 
adversary cards in discard: [ 6. 10.  3.  0.  8.  3. 10. 11.  3.  0.] 
adversary owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6 11  6] -> size -> 19 
adversary victory points: 1
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 16. 15.] 
cards in discard: [ 3.  0.  3.  0. 14. 10. 25.  0.  0.  3.  3. 15. 14. 25. 22.  8.  0.  3.
  3. 29.  8.  1.  1. 14. 25. 29.  3.  0.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [14 10 22  1  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29 14
 11 14 16  3  1  3  0 15  3 15  3  1  0  3 25 25] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 7. 25. 30.  9. 30.  8.  4.  8.  2.  0.  7.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [15.  0.  6.] 
adversary cards in discard: [ 6. 10.  3.  0.  8.  3. 10. 11.  3.  0.  6.  3.] 
adversary owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6 11  6] -> size -> 19 
adversary victory points: 1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 16. 15.] 
cards in discard: [ 3.  0.  3.  0. 14. 10. 25.  0.  0.  3.  3. 15. 14. 25. 22.  8.  0.  3.
  3. 29.  8.  1.  1. 14. 25. 29.  3.  0.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [14 10 22  1  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29 14
 11 14 16  3  1  3  0 15  3 15  3  1  0  3 25 25] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 25. 30.  9. 30.  8.  4.  8.  2.  0.  7.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [15.  0.  6.] 
adversary cards in discard: [ 6. 10.  3.  0.  8.  3. 10. 11.  3.  0.  6.  3.] 
adversary owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6 11  6] -> size -> 19 
adversary victory points: 1
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 16. 15.] 
cards in discard: [ 3.  0.  3.  0. 14. 10. 25.  0.  0.  3.  3. 15. 14. 25. 22.  8.  0.  3.
  3. 29.  8.  1.  1. 14. 25. 29.  3.  0.  0.  1.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [14 10 22  1  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29 14
 11 14 16  3  1  3  0 15  3 15  3  1  0  3 25 25  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30.  9. 30.  8.  4.  8.  2.  0.  7.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [15.  0.  6.] 
adversary cards in discard: [ 6. 10.  3.  0.  8.  3. 10. 11.  3.  0.  6.  3.] 
adversary owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6 11  6] -> size -> 19 
adversary victory points: 1
player victory points: 9 





         -------------------- Turn: 83 -------------------- 
Player: 0 
cards in hand: [15.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[17.799603]
 [12.240881]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  6.] 
cards in discard: [ 6. 10.  3.  0.  8.  3. 10. 11.  3.  0.  6.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6 11  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30.  9. 30.  8.  4.  8.  2.  0.  7.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 0.  3. 11.  0.  8.] 
adversary cards in discard: [ 3.  0.  3.  0. 14. 10. 25.  0.  0.  3.  3. 15. 14. 25. 22.  8.  0.  3.
  3. 29.  8.  1.  1. 14. 25. 29.  3.  0.  0.  1.  1. 14.  0.  3. 16. 15.] 
adversary owned cards: [14 10 22  1  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29 14
 11 14 16  3  1  3  0 15  3 15  3  1  0  3 25 25  1] -> size -> 41 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: discard_down_to_3_cards - action 8
Learning step: -5.06735897064209
desired expected reward: 19.689395904541016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 9.822622]
 [ 9.822622]
 [17.418877]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  6.] 
cards in discard: [ 6. 10.  3.  0.  8.  3. 10. 11.  3.  0.  6.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6 11  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 24. 30.  9. 30.  8.  4.  8.  2.  0.  7.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 0.  3. 11.  0.  8.] 
adversary cards in discard: [ 3.  0.  3.  0. 14. 10. 25.  0.  0.  3.  3. 15. 14. 25. 22.  8.  0.  3.
  3. 29.  8.  1.  1. 14. 25. 29.  3.  0.  0.  1.  1. 14.  0.  3. 16. 15.] 
adversary owned cards: [14 10 22  1  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29 14
 11 14 16  3  1  3  0 15  3 15  3  1  0  3 25 25  1] -> size -> 41 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: take_action - action -1.0
Learning step: -4.752738952636719
desired expected reward: 13.04686164855957



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3. 11.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  0.  8.] 
cards in discard: [ 3.  0.  3.  0. 14. 10. 25.  0.  0.  3.  3. 15. 14. 25. 22.  8.  0.  3.
  3. 29.  8.  1.  1. 14. 25. 29.  3.  0.  0.  1.  1. 14.  0.  3. 16. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [14 10 22  1  8  0  3  0  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29 14
 11 14 16  3  1  3  0 15  3 15  3  1  0  3 25 25  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30.  9. 30.  8.  4.  8.  2.  0.  7.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [10.  6.  3.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6 11  6] -> size -> 19 
adversary victory points: 1
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 3.  0.  3.  0. 14. 10. 25.  0.  0.  3.  3. 15. 14. 25. 22.  8.  0.  3.
  3. 29.  8.  1.  1. 14. 25. 29.  3.  0.  0.  1.  1. 14.  0.  3. 16. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [14 10 22  1  8  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3
  1  3  0 15  3 15  3  1  0  3 25 25  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30.  9. 30.  8.  4.  8.  2.  0.  7.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [10.  6.  3.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6 11  6] -> size -> 19 
adversary victory points: 1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3.  0.  3.  0. 14. 10. 25.  0.  0.  3.  3. 15. 14. 25. 22.  8.  0.  3.
  3. 29.  8.  1.  1. 14. 25. 29.  3.  0.  0.  1.  1. 14.  0.  3. 16. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [14 10 22  1  8  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3
  1  3  0 15  3 15  3  1  0  3 25 25  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 7. 24. 30.  9. 30.  8.  4.  8.  2.  0.  7.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [10.  6.  3.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6 11  6] -> size -> 19 
adversary victory points: 1
player victory points: 8 





         -------------------- Turn: 84 -------------------- 
Player: 0 
cards in hand: [10.  6.  3.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[74.26522]
 [67.44539]
 [67.49835]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  3.  0.  8.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [15  8 10  8 10  3  3  3  0  0  0  0  3  6  6  3  6 11  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30.  9. 30.  8.  4.  8.  2.  0.  7.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 8. 14.  3.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [14 10 22  1  8  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3
  1  3  0 15  3 15  3  1  0  3 25 25  1] -> size -> 37 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -74 

action type: buy - action -1.0
Learning step: -2.967319965362549
desired expected reward: 14.451555252075195



action possibilites: [-1] 
expected returns: [[130.70836]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  8  8 10  3  3  0  0  0  0  3  6  6  3  6 11  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30.  9. 30.  8.  4.  8.  2.  0.  7.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 8. 14.  3.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [14 10 22  1  8  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3
  1  3  0 15  3 15  3  1  0  3 25 25  1] -> size -> 37 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: trash_cards_n_from_hand - action 9
Learning step: -3.6622979640960693
desired expected reward: 63.40242385864258





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[115.75507]
 [115.75507]
 [130.48828]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  8  8 10  3  3  0  0  0  0  3  6  6  3  6 11  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 24. 30.  9. 30.  8.  4.  8.  2.  0.  7.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 8. 14.  3.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [14 10 22  1  8  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3
  1  3  0 15  3 15  3  1  0  3 25 25  1] -> size -> 37 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1
Learning step: -6.955493450164795
desired expected reward: 123.75286865234375



buy possibilites: [-1] 
expected returns: [[72.94221]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  8  8 10  3  3  0  0  0  0  3  6  6  3  6 11  6  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 24. 30.  9. 30.  8.  3.  8.  2.  0.  7.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 8. 14.  3.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [14 10 22  1  8  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3
  1  3  0 15  3 15  3  1  0  3 25 25  1] -> size -> 37 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -90.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -376.0 

action type: buy - action 6.0
Learning step: -22.94655418395996
desired expected reward: 92.80850982666016






Player: 1 
cards in hand: [ 8. 14.  3.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  3.  0.  1.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [14 10 22  1  8  8  0  0  3  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3
  1  3  0 15  3 15  3  1  0  3 25 25  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30.  9. 30.  8.  3.  8.  2.  0.  7.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [0. 3. 6. 3. 6.] 
adversary cards in discard: [6. 8. 6. 0.] 
adversary owned cards: [15  8  8 10  3  3  0  0  0  0  3  6  6  3  6 11  6  6] -> size -> 18 
adversary victory points: -1
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 22  8  8  0  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0
 15  3 15  3  1  0  3 25 25  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30.  9. 30.  8.  3.  8.  2.  0.  7.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [0. 3. 6. 3. 6.] 
adversary cards in discard: [6. 8. 6. 0.] 
adversary owned cards: [15  8  8 10  3  3  0  0  0  0  3  6  6  3  6 11  6  6] -> size -> 18 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 22  8  8  0  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0
 15  3 15  3  1  0  3 25 25  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 24. 30.  9. 30.  8.  3.  8.  2.  0.  7.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [0. 3. 6. 3. 6.] 
adversary cards in discard: [6. 8. 6. 0.] 
adversary owned cards: [15  8  8 10  3  3  0  0  0  0  3  6  6  3  6 11  6  6] -> size -> 18 
adversary victory points: -1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 22  8  8  0  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0
 15  3 15  3  1  0  3 25 25  1  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 24. 30.  9. 30.  8.  3.  8.  2.  0.  7.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [0. 3. 6. 3. 6.] 
adversary cards in discard: [6. 8. 6. 0.] 
adversary owned cards: [15  8  8 10  3  3  0  0  0  0  3  6  6  3  6 11  6  6] -> size -> 18 
adversary victory points: -1
player victory points: 7 





         -------------------- Turn: 85 -------------------- 
Player: 0 
cards in hand: [0. 3. 6. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[72.74632]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 3. 6.] 
cards in discard: [6. 8. 6. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  8 10  3  3  0  0  0  0  3  6  6  3  6 11  6  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 24. 30.  9. 30.  8.  3.  8.  2.  0.  7.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 0. 29.  3.  3. 15.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [10 22  8  8  0  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0
 15  3 15  3  1  0  3 25 25  1  0] -> size -> 35 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1
Learning step: -6.323151588439941
desired expected reward: 66.61905670166016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[64.53497]
 [64.53497]
 [71.9527 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 3. 6.] 
cards in discard: [6. 8. 6. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  8 10  3  3  0  0  0  0  3  6  6  3  6 11  6  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 24. 30.  9. 30.  8.  3.  8.  2.  0.  7.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 0. 29.  3.  3. 15.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [10 22  8  8  0  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0
 15  3 15  3  1  0  3 25 25  1  0] -> size -> 35 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: take_action - action -1.0
Learning step: -6.343260765075684
desired expected reward: 65.83268737792969



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 29.  3.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  3. 15.] 
cards in discard: [0. 8. 0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [10 22  8  8  0  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0
 15  3 15  3  1  0  3 25 25  1  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 24. 30.  9. 30.  8.  3.  8.  2.  0.  7.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [10.  3.  8.  3. 15.] 
adversary cards in discard: [6. 8. 6. 0. 0. 3. 6. 3. 6.] 
adversary owned cards: [15  8  8 10  3  3  0  0  0  0  3  6  6  3  6 11  6  6] -> size -> 18 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3.  3. 15.] 
cards in discard: [0. 8. 0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [10 22  8  8  0  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0
 15  3 15  3  1  0  3 25 25  1  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 24. 30.  9. 30.  8.  3.  8.  2.  0.  7.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [10.  3.  8.  3. 15.] 
adversary cards in discard: [6. 8. 6. 0. 0. 3. 6. 3. 6.] 
adversary owned cards: [15  8  8 10  3  3  0  0  0  0  3  6  6  3  6 11  6  6] -> size -> 18 
adversary victory points: -1
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 86 -------------------- 
Player: 0 
cards in hand: [10.  3.  8.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 15.] 
expected returns: [[2.721838 ]
 [1.2384833]
 [1.2497892]
 [1.5535076]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  8.  3. 15.] 
cards in discard: [6. 8. 6. 0. 0. 3. 6. 3. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  8 10  3  3  0  0  0  0  3  6  6  3  6 11  6  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 24. 30.  9. 30.  8.  3.  8.  2.  0.  7.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 3. 25. 25.  0.  3.] 
adversary cards in discard: [ 0.  8.  0.  0. 29.  3.  3. 15.] 
adversary owned cards: [10 22  8  8  0  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0
 15  3 15  3  1  0  3 25 25  1  0] -> size -> 35 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1.0
Learning step: -7.8475260734558105
desired expected reward: 64.10517120361328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[1.1260945]
 [1.1260945]
 [2.7655015]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  8.  3. 15.] 
cards in discard: [6. 8. 6. 0. 0. 3. 6. 3. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  8 10  3  3  0  0  0  0  3  6  6  3  6 11  6  6] -> size -> 18 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 6. 24. 30.  9. 30.  8.  3.  8.  2.  0.  7.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 3. 25. 25.  0.  3.] 
adversary cards in discard: [ 0.  8.  0.  0. 29.  3.  3. 15.] 
adversary owned cards: [10 22  8  8  0  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0
 15  3 15  3  1  0  3 25 25  1  0] -> size -> 35 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: take_action - action -1.0
Learning step: -4.385670185089111
desired expected reward: -1.6638317108154297



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3. 25. 25.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 25.  0.  3.] 
cards in discard: [ 0.  8.  0.  0. 29.  3.  3. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [10 22  8  8  0  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0
 15  3 15  3  1  0  3 25 25  1  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 24. 30.  9. 30.  8.  3.  8.  2.  0.  7.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 6.  6. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [15  8  8 10  3  3  0  0  0  0  3  6  6  3  6 11  6  6] -> size -> 18 
adversary victory points: -1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  0.  3.  0. 16.] 
cards in discard: [ 0.  8.  0.  0. 29.  3.  3. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [10 22  8  8  0  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0
 15  3 15  3  1  0  3 25 25  1  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 24. 30.  9. 30.  8.  2.  8.  2.  0.  7.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 6.  6. 11.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [15  8  8 10  3  3  0  0  0  0  3  6  6  3  6 11  6  6  6] -> size -> 19 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25.  0.  3.  0. 16.] 
cards in discard: [ 0.  8.  0.  0. 29.  3.  3. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [10 22  8  8  0  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0
 15  3 15  3  1  0  3 25 25  1  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 24. 30.  9. 30.  8.  2.  8.  2.  0.  7.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 6.  6. 11.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [15  8  8 10  3  3  0  0  0  0  3  6  6  3  6 11  6  6  6] -> size -> 19 
adversary victory points: -1
player victory points: 7 





         -------------------- Turn: 87 -------------------- 
Player: 0 
cards in hand: [ 6.  6. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[42.30229 ]
 [36.201355]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 11.  0.  0.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  8 10  3  3  0  0  0  0  3  6  6  3  6 11  6  6  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 24. 30.  9. 30.  8.  2.  8.  2.  0.  7.  7.  4. 10.  1.  9.  7.] 
adversary cards in hand: [ 0.  3.  8.  0. 22.] 
adversary cards in discard: [ 0.  8.  0.  0. 29.  3.  3. 15. 25.  3. 25.  0.  3.  0. 16.] 
adversary owned cards: [10 22  8  8  0  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0
 15  3 15  3  1  0  3 25 25  1  0] -> size -> 35 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2  -90    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -397 

action type: buy - action -1.0
Learning step: -19.08509635925293
desired expected reward: -16.31959342956543



action possibilites: [-1] 
expected returns: [[83.31327]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 0.] 
cards in discard: [ 6. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [15  8  8 10  3  3  0  0  0  0  3  6  6  3  6 11  6  6  6 15] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 24. 30.  9. 30.  8.  2.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [ 0.  3.  8.  0. 22.] 
adversary cards in discard: [ 0.  8.  0.  0. 29.  3.  3. 15. 25.  3. 25.  0.  3.  0. 16.] 
adversary owned cards: [10 22  8  8  0  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0
 15  3 15  3  1  0  3 25 25  1  0] -> size -> 35 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -61 

action type: gain_card_n - action 9
Learning step: -2.952519416809082
desired expected reward: 32.58884048461914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[75.73033 ]
 [75.73291 ]
 [75.73033 ]
 [83.245926]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 0.] 
cards in discard: [ 6. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [15  8  8 10  3  3  0  0  0  0  3  6  6  3  6 11  6  6  6 15] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 24. 30.  9. 30.  8.  2.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [ 0.  3.  8.  0. 22.] 
adversary cards in discard: [ 0.  8.  0.  0. 29.  3.  3. 15. 25.  3. 25.  0.  3.  0. 16.] 
adversary owned cards: [10 22  8  8  0  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0
 15  3 15  3  1  0  3 25 25  1  0] -> size -> 35 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1
Learning step: -6.203489780426025
desired expected reward: 77.10977935791016



buy possibilites: [-1] 
expected returns: [[64.48671]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 0.] 
cards in discard: [ 6. 15.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [15  8  8 10  3  3  0  0  0  0  3  6  6  3  6 11  6  6  6 15  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 24. 30.  9. 30.  8.  1.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [ 0.  3.  8.  0. 22.] 
adversary cards in discard: [ 0.  8.  0.  0. 29.  3.  3. 15. 25.  3. 25.  0.  3.  0. 16.] 
adversary owned cards: [10 22  8  8  0  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0
 15  3 15  3  1  0  3 25 25  1  0] -> size -> 35 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3. -100.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -388.0 

action type: buy - action 6.0
Learning step: -21.128686904907227
desired expected reward: 42.46406555175781






Player: 1 
cards in hand: [ 0.  3.  8.  0. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8.  0. 22.] 
cards in discard: [ 0.  8.  0.  0. 29.  3.  3. 15. 25.  3. 25.  0.  3.  0. 16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [10 22  8  8  0  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0
 15  3 15  3  1  0  3 25 25  1  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 24. 30.  9. 30.  8.  1.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [3. 6. 3. 8. 6.] 
adversary cards in discard: [ 6. 15.  6. 11.  6.  6.  0.  0.] 
adversary owned cards: [15  8  8 10  3  3  0  0  0  0  3  6  6  3  6 11  6  6  6 15  6] -> size -> 21 
adversary victory points: -3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  8.  0. 22.] 
cards in discard: [ 0.  8.  0.  0. 29.  3.  3. 15. 25.  3. 25.  0.  3.  0. 16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [10 22  8  8  0  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0
 15  3 15  3  1  0  3 25 25  1  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 24. 30.  9. 30.  8.  1.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [3. 6. 3. 8. 6.] 
adversary cards in discard: [ 6. 15.  6. 11.  6.  6.  0.  0.] 
adversary owned cards: [15  8  8 10  3  3  0  0  0  0  3  6  6  3  6 11  6  6  6 15  6] -> size -> 21 
adversary victory points: -3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  8.  0. 22.] 
cards in discard: [ 0.  8.  0.  0. 29.  3.  3. 15. 25.  3. 25.  0.  3.  0. 16.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [10 22  8  8  0  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0
 15  3 15  3  1  0  3 25 25  1  0  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 24. 30.  8. 30.  8.  1.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [3. 6. 3. 8. 6.] 
adversary cards in discard: [ 6. 15.  6. 11.  6.  6.  0.  0.] 
adversary owned cards: [15  8  8 10  3  3  0  0  0  0  3  6  6  3  6 11  6  6  6 15  6] -> size -> 21 
adversary victory points: -3
player victory points: 8 





         -------------------- Turn: 88 -------------------- 
Player: 0 
cards in hand: [3. 6. 3. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[18.196178]
 [12.826374]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 8. 6.] 
cards in discard: [ 6. 15.  6. 11.  6.  6.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  8 10  3  3  0  0  0  0  3  6  6  3  6 11  6  6  6 15  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 24. 30.  8. 30.  8.  1.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [25.  0. 14. 10.  3.] 
adversary cards in discard: [ 0.  8.  0.  0. 29.  3.  3. 15. 25.  3. 25.  0.  3.  0. 16.  3.  0.  3.
  8.  0. 22.] 
adversary owned cards: [10 22  8  8  0  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0
 15  3 15  3  1  0  3 25 25  1  0  3] -> size -> 36 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -118 

action type: buy - action -1
Learning step: -8.743913650512695
desired expected reward: 55.7427978515625



action possibilites: [-1] 
expected returns: [[29.00267]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6.] 
cards in discard: [ 6. 15.  6. 11.  6.  6.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  8  8 10  0  0  0  0  3  6  6  3  6 11  6  6  6 15  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 24. 30.  8. 30.  8.  1.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [25.  0. 14. 10.  3.] 
adversary cards in discard: [ 0.  8.  0.  0. 29.  3.  3. 15. 25.  3. 25.  0.  3.  0. 16.  3.  0.  3.
  8.  0. 22.] 
adversary owned cards: [10 22  8  8  0  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0
 15  3 15  3  1  0  3 25 25  1  0  3] -> size -> 36 
adversary victory points: 8
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -130    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -120 

action type: trash_cards_n_from_hand - action 4
Learning step: -5.911630153656006
desired expected reward: 5.3721795082092285





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[21.069897]
 [21.069897]
 [29.380428]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6.] 
cards in discard: [ 6. 15.  6. 11.  6.  6.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  8  8 10  0  0  0  0  3  6  6  3  6 11  6  6  6 15  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 6. 24. 30.  8. 30.  8.  1.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [25.  0. 14. 10.  3.] 
adversary cards in discard: [ 0.  8.  0.  0. 29.  3.  3. 15. 25.  3. 25.  0.  3.  0. 16.  3.  0.  3.
  8.  0. 22.] 
adversary owned cards: [10 22  8  8  0  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0
 15  3 15  3  1  0  3 25 25  1  0  3] -> size -> 36 
adversary victory points: 8
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -130    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -120 

action type: take_action - action -1
Learning step: -6.848899841308594
desired expected reward: 22.153770446777344






Player: 1 
cards in hand: [25.  0. 14. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 14. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 14. 10.  3.] 
cards in discard: [ 0.  8.  0.  0. 29.  3.  3. 15. 25.  3. 25.  0.  3.  0. 16.  3.  0.  3.
  8.  0. 22.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [10 22  8  8  0  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0
 15  3 15  3  1  0  3 25 25  1  0  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 24. 30.  8. 30.  8.  1.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [ 6.  0.  3. 15.  0.] 
adversary cards in discard: [ 6. 15.  6. 11.  6.  6.  0.  0.  8.  6.  6.] 
adversary owned cards: [15  8  8 10  0  0  0  0  3  6  6  3  6 11  6  6  6 15  6] -> size -> 19 
adversary victory points: -5
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0. 14. 10.  3.] 
cards in discard: [ 0.  8.  0.  0. 29.  3.  3. 15. 25.  3. 25.  0.  3.  0. 16.  3.  0.  3.
  8.  0. 22.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [10 22  8  8  0  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0
 15  3 15  3  1  0  3 25 25  1  0  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 24. 30.  8. 30.  8.  1.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [ 6.  0.  3. 15.  0.] 
adversary cards in discard: [ 6. 15.  6. 11.  6.  6.  0.  0.  8.  6.  6.] 
adversary owned cards: [15  8  8 10  0  0  0  0  3  6  6  3  6 11  6  6  6 15  6] -> size -> 19 
adversary victory points: -5
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0. 14. 10.  3.] 
cards in discard: [ 0.  8.  0.  0. 29.  3.  3. 15. 25.  3. 25.  0.  3.  0. 16.  3.  0.  3.
  8.  0. 22.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [10 22  8  8  0  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0
 15  3 15  3  1  0  3 25 25  1  0  3  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 24. 30.  8. 30.  8.  1.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [ 6.  0.  3. 15.  0.] 
adversary cards in discard: [ 6. 15.  6. 11.  6.  6.  0.  0.  8.  6.  6.] 
adversary owned cards: [15  8  8 10  0  0  0  0  3  6  6  3  6 11  6  6  6 15  6] -> size -> 19 
adversary victory points: -5
player victory points: 8 





         -------------------- Turn: 89 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  3. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[14.52878 ]
 [11.439598]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3. 15.  0.] 
cards in discard: [ 6. 15.  6. 11.  6.  6.  0.  0.  8.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  8 10  0  0  0  0  3  6  6  3  6 11  6  6  6 15  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 24. 30.  8. 30.  8.  1.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [15. 29.  1.  1. 14.] 
adversary cards in discard: [ 0.  8.  0.  0. 29.  3.  3. 15. 25.  3. 25.  0.  3.  0. 16.  3.  0.  3.
  8.  0. 22.  0. 25.  0. 14. 10.  3.] 
adversary owned cards: [10 22  8  8  0  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0
 15  3 15  3  1  0  3 25 25  1  0  3  0] -> size -> 37 
adversary victory points: 8
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -140 

action type: buy - action -1.0
Learning step: -8.15880298614502
desired expected reward: 21.221622467041016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[11.141394]
 [11.142233]
 [11.141394]
 [15.550841]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  3. 15.  0.] 
cards in discard: [ 6. 15.  6. 11.  6.  6.  0.  0.  8.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  8 10  0  0  0  0  3  6  6  3  6 11  6  6  6 15  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 24. 30.  8. 30.  8.  1.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [15. 29.  1.  1. 14.] 
adversary cards in discard: [ 0.  8.  0.  0. 29.  3.  3. 15. 25.  3. 25.  0.  3.  0. 16.  3.  0.  3.
  8.  0. 22.  0. 25.  0. 14. 10.  3.] 
adversary owned cards: [10 22  8  8  0  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0
 15  3 15  3  1  0  3 25 25  1  0  3  0] -> size -> 37 
adversary victory points: 8
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -140 

action type: take_action - action -1.0
Learning step: -7.4122538566589355
desired expected reward: 7.116527080535889



buy possibilites: [-1] 
expected returns: [[30.210072]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  3. 15.  0.] 
cards in discard: [ 6. 15.  6. 11.  6.  6.  0.  0.  8.  6.  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  8 10  0  0  0  0  3  6  6  3  6 11  6  6  6 15  6  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 24. 30.  7. 30.  8.  1.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [15. 29.  1.  1. 14.] 
adversary cards in discard: [ 0.  8.  0.  0. 29.  3.  3. 15. 25.  3. 25.  0.  3.  0. 16.  3.  0.  3.
  8.  0. 22.  0. 25.  0. 14. 10.  3.] 
adversary owned cards: [10 22  8  8  0  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0
 15  3 15  3  1  0  3 25 25  1  0  3  0] -> size -> 37 
adversary victory points: 8
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -120    0    0    0    0    0    0    0    0    0    0
    8    0] 
sum of rewards: -121 

action type: buy - action 3.0
Learning step: -5.927385330200195
desired expected reward: 5.214847564697266






Player: 1 
cards in hand: [15. 29.  1.  1. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29.  1.  1. 14.] 
cards in discard: [ 0.  8.  0.  0. 29.  3.  3. 15. 25.  3. 25.  0.  3.  0. 16.  3.  0.  3.
  8.  0. 22.  0. 25.  0. 14. 10.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10 22  8  8  0  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0
 15  3 15  3  1  0  3 25 25  1  0  3  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 24. 30.  7. 30.  8.  1.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [ 3.  8.  3. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [15  8  8 10  0  0  0  0  3  6  6  3  6 11  6  6  6 15  6  3] -> size -> 20 
adversary victory points: -4
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 29.  1.  1. 14.] 
cards in discard: [ 0.  8.  0.  0. 29.  3.  3. 15. 25.  3. 25.  0.  3.  0. 16.  3.  0.  3.
  8.  0. 22.  0. 25.  0. 14. 10.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10 22  8  8  0  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0
 15  3 15  3  1  0  3 25 25  1  0  3  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 5. 24. 30.  7. 30.  8.  1.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [ 3.  8.  3. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [15  8  8 10  0  0  0  0  3  6  6  3  6 11  6  6  6 15  6  3] -> size -> 20 
adversary victory points: -4
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 29.  1.  1. 14.] 
cards in discard: [ 0.  8.  0.  0. 29.  3.  3. 15. 25.  3. 25.  0.  3.  0. 16.  3.  0.  3.
  8.  0. 22.  0. 25.  0. 14. 10.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10 22  8  8  0  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0
 15  3 15  3  1  0  3 25 25  1  0  3  0  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 4. 24. 30.  7. 30.  8.  1.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [ 3.  8.  3. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [15  8  8 10  0  0  0  0  3  6  6  3  6 11  6  6  6 15  6  3] -> size -> 20 
adversary victory points: -4
player victory points: 8 





         -------------------- Turn: 90 -------------------- 
Player: 0 
cards in hand: [ 3.  8.  3. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.] 
expected returns: [[15.94319 ]
 [11.438803]
 [11.403662]
 [11.438803]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  3. 10.  8.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  8 10  0  0  0  0  3  6  6  3  6 11  6  6  6 15  6  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30.  7. 30.  8.  1.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [ 0. 14.  1.  8.  3.] 
adversary cards in discard: [ 0.  8.  0.  0. 29.  3.  3. 15. 25.  3. 25.  0.  3.  0. 16.  3.  0.  3.
  8.  0. 22.  0. 25.  0. 14. 10.  3.  0. 15. 29.  1.  1. 14.] 
adversary owned cards: [10 22  8  8  0  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0
 15  3 15  3  1  0  3 25 25  1  0  3  0  0] -> size -> 38 
adversary victory points: 8
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -129 

action type: buy - action -1
Learning step: -7.645832061767578
desired expected reward: 22.564239501953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[10.998182]
 [10.998182]
 [16.001436]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  3. 10.  8.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  8 10  0  0  0  0  3  6  6  3  6 11  6  6  6 15  6  3] -> size -> 20 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 4. 24. 30.  7. 30.  8.  1.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [ 0. 14.  1.  8.  3.] 
adversary cards in discard: [ 0.  8.  0.  0. 29.  3.  3. 15. 25.  3. 25.  0.  3.  0. 16.  3.  0.  3.
  8.  0. 22.  0. 25.  0. 14. 10.  3.  0. 15. 29.  1.  1. 14.] 
adversary owned cards: [10 22  8  8  0  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0
 15  3 15  3  1  0  3 25 25  1  0  3  0  0] -> size -> 38 
adversary victory points: 8
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -129 

action type: take_action - action -1.0
Learning step: -6.905783176422119
desired expected reward: 8.690174102783203



buy possibilites: [-1] 
expected returns: [[14.486583]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  3. 10.  8.] 
cards in discard: [0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  8 10  0  0  0  0  3  6  6  3  6 11  6  6  6 15  6  3  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 24. 30.  7. 30.  8.  1.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [ 0. 14.  1.  8.  3.] 
adversary cards in discard: [ 0.  8.  0.  0. 29.  3.  3. 15. 25.  3. 25.  0.  3.  0. 16.  3.  0.  3.
  8.  0. 22.  0. 25.  0. 14. 10.  3.  0. 15. 29.  1.  1. 14.] 
adversary owned cards: [10 22  8  8  0  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0
 15  3 15  3  1  0  3 25 25  1  0  3  0  0] -> size -> 38 
adversary victory points: 8
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -120    0    0    0  -30    0    0    0    0    0    0
    0    0] 
sum of rewards: -159 

action type: buy - action 0.0
Learning step: -8.17396068572998
desired expected reward: 2.824220657348633






Player: 1 
cards in hand: [ 0. 14.  1.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  1.  8.  3.] 
cards in discard: [ 0.  8.  0.  0. 29.  3.  3. 15. 25.  3. 25.  0.  3.  0. 16.  3.  0.  3.
  8.  0. 22.  0. 25.  0. 14. 10.  3.  0. 15. 29.  1.  1. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10 22  8  8  0  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0
 15  3 15  3  1  0  3 25 25  1  0  3  0  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 24. 30.  7. 30.  8.  1.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [15.  0.  6.  6. 15.] 
adversary cards in discard: [ 0.  3.  8.  3. 10.  8.] 
adversary owned cards: [15  8  8 10  0  0  0  0  3  6  6  3  6 11  6  6  6 15  6  3  0] -> size -> 21 
adversary victory points: -4
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  1.  8.  3.] 
cards in discard: [ 0.  8.  0.  0. 29.  3.  3. 15. 25.  3. 25.  0.  3.  0. 16.  3.  0.  3.
  8.  0. 22.  0. 25.  0. 14. 10.  3.  0. 15. 29.  1.  1. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10 22  8  8  0  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0
 15  3 15  3  1  0  3 25 25  1  0  3  0  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 24. 30.  7. 30.  8.  1.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [15.  0.  6.  6. 15.] 
adversary cards in discard: [ 0.  3.  8.  3. 10.  8.] 
adversary owned cards: [15  8  8 10  0  0  0  0  3  6  6  3  6 11  6  6  6 15  6  3  0] -> size -> 21 
adversary victory points: -4
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  1.  8.  3.] 
cards in discard: [ 0.  8.  0.  0. 29.  3.  3. 15. 25.  3. 25.  0.  3.  0. 16.  3.  0.  3.
  8.  0. 22.  0. 25.  0. 14. 10.  3.  0. 15. 29.  1.  1. 14.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10 22  8  8  0  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0
 15  3 15  3  1  0  3 25 25  1  0  3  0  0  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 23. 30.  7. 30.  8.  1.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [15.  0.  6.  6. 15.] 
adversary cards in discard: [ 0.  3.  8.  3. 10.  8.] 
adversary owned cards: [15  8  8 10  0  0  0  0  3  6  6  3  6 11  6  6  6 15  6  3  0] -> size -> 21 
adversary victory points: -4
player victory points: 8 





         -------------------- Turn: 91 -------------------- 
Player: 0 
cards in hand: [15.  0.  6.  6. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
expected returns: [[0.8005365 ]
 [0.15889108]
 [0.15889108]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  6.  6. 15.] 
cards in discard: [ 0.  3.  8.  3. 10.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  8 10  0  0  0  0  3  6  6  3  6 11  6  6  6 15  6  3  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 23. 30.  7. 30.  8.  1.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [10.  0. 14. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10 22  8  8  0  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0
 15  3 15  3  1  0  3 25 25  1  0  3  0  0  1] -> size -> 39 
adversary victory points: 8
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -129 

action type: buy - action -1
Learning step: -7.1609368324279785
desired expected reward: 7.325645923614502





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-0.02716982]
 [-0.02716982]
 [ 0.8005365 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  6.  6. 15.] 
cards in discard: [ 0.  3.  8.  3. 10.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  8 10  0  0  0  0  3  6  6  3  6 11  6  6  6 15  6  3  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 23. 30.  7. 30.  8.  1.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [10.  0. 14. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10 22  8  8  0  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0
 15  3 15  3  1  0  3 25 25  1  0  3  0  0  1] -> size -> 39 
adversary victory points: 8
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -129 

action type: take_action - action -1.0
Learning step: -6.477973461151123
desired expected reward: -5.677436828613281



buy possibilites: [-1] 
expected returns: [[0.8005365]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  6.  6. 15.] 
cards in discard: [ 0.  3.  8.  3. 10.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  8 10  0  0  0  0  3  6  6  3  6 11  6  6  6 15  6  3  0  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 23. 30.  7. 30.  8.  1.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [10.  0. 14. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [10 22  8  8  0  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0
 15  3 15  3  1  0  3 25 25  1  0  3  0  0  1] -> size -> 39 
adversary victory points: 8
player victory points: -4 

Reward from previous game state: 
[  -5.    0.   -4. -120.    0.    0.    0.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -159.0 

action type: buy - action 0.0
Learning step: -7.930629253387451
desired expected reward: -7.957798957824707






Player: 1 
cards in hand: [10.  0. 14. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 14. 25.  0.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [10 22  8  8  0  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0
 15  3 15  3  1  0  3 25 25  1  0  3  0  0  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 23. 30.  7. 30.  8.  1.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [ 6.  6.  0.  0. 11.] 
adversary cards in discard: [ 0.  3.  8.  3. 10.  8.  0. 15.  0.  6.  6. 15.] 
adversary owned cards: [15  8  8 10  0  0  0  0  3  6  6  3  6 11  6  6  6 15  6  3  0  0] -> size -> 22 
adversary victory points: -4
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 14. 25.  0.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [10 22  8  8  0  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0
 15  3 15  3  1  0  3 25 25  1  0  3  0  0  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 23. 30.  7. 30.  8.  1.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [ 6.  6.  0.  0. 11.] 
adversary cards in discard: [ 0.  3.  8.  3. 10.  8.  0. 15.  0.  6.  6. 15.] 
adversary owned cards: [15  8  8 10  0  0  0  0  3  6  6  3  6 11  6  6  6 15  6  3  0  0] -> size -> 22 
adversary victory points: -4
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 14. 25.  0.] 
cards in discard: [3.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [10 22  8  8  0  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0
 15  3 15  3  1  0  3 25 25  1  0  3  0  0  1  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 23. 30.  6. 30.  8.  1.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [ 6.  6.  0.  0. 11.] 
adversary cards in discard: [ 0.  3.  8.  3. 10.  8.  0. 15.  0.  6.  6. 15.] 
adversary owned cards: [15  8  8 10  0  0  0  0  3  6  6  3  6 11  6  6  6 15  6  3  0  0] -> size -> 22 
adversary victory points: -4
player victory points: 9 





         -------------------- Turn: 92 -------------------- 
Player: 0 
cards in hand: [ 6.  6.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[37.696045]
 [32.81522 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0.  0. 11.] 
cards in discard: [ 0.  3.  8.  3. 10.  8.  0. 15.  0.  6.  6. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  8 10  0  0  0  0  3  6  6  3  6 11  6  6  6 15  6  3  0  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 23. 30.  6. 30.  8.  1.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [ 3.  0.  8. 29.  0.] 
adversary cards in discard: [ 3. 10.  0. 14. 25.  0.] 
adversary owned cards: [10 22  8  8  0  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0
 15  3 15  3  1  0  3 25 25  1  0  3  0  0  1  3] -> size -> 40 
adversary victory points: 9
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -139 

action type: buy - action -1
Learning step: -6.16821813583374
desired expected reward: -5.367681503295898





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[31.326931]
 [31.328094]
 [31.326931]
 [37.325603]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0.  0. 11.] 
cards in discard: [ 0.  3.  8.  3. 10.  8.  0. 15.  0.  6.  6. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  8 10  0  0  0  0  3  6  6  3  6 11  6  6  6 15  6  3  0  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 23. 30.  6. 30.  8.  1.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [ 3.  0.  8. 29.  0.] 
adversary cards in discard: [ 3. 10.  0. 14. 25.  0.] 
adversary owned cards: [10 22  8  8  0  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0
 15  3 15  3  1  0  3 25 25  1  0  3  0  0  1  3] -> size -> 40 
adversary victory points: 9
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -139 

action type: take_action - action -1.0
Learning step: -8.043553352355957
desired expected reward: 29.652484893798828



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  0.  8. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8. 29.  0.] 
cards in discard: [ 3. 10.  0. 14. 25.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [10 22  8  8  0  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0
 15  3 15  3  1  0  3 25 25  1  0  3  0  0  1  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 23. 30.  6. 30.  8.  1.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [0. 6. 6. 6. 3.] 
adversary cards in discard: [ 0.  3.  8.  3. 10.  8.  0. 15.  0.  6.  6. 15.  6.  6.  0.  0. 11.] 
adversary owned cards: [15  8  8 10  0  0  0  0  3  6  6  3  6 11  6  6  6 15  6  3  0  0] -> size -> 22 
adversary victory points: -4
player victory points: 9 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 0.] 
cards in discard: [ 3. 10.  0. 14. 25.  0. 29.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29.] 
owned cards: [10 22  8  8  0  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0
 15  3 15  3  1  0  3 25 25  1  0  3  0  0  1  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 2. 23. 30.  6. 30.  8.  1.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [0. 6. 6. 6. 3.] 
adversary cards in discard: [ 0.  3.  8.  3. 10.  8.  0. 15.  0.  6.  6. 15.  6.  6.  0.  0. 11.] 
adversary owned cards: [15  8  8 10  0  0  0  0  3  6  6  3  6 11  6  6  6 15  6  3  0  0] -> size -> 22 
adversary victory points: -4
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [ 3. 10.  0. 14. 25.  0. 29.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [10 22  8  8  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0 15
  3 15  3  1  0  3 25 25  1  0  3  0  0  1  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 23. 30.  6. 30.  8.  1.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [0. 6. 6. 6. 3.] 
adversary cards in discard: [ 0.  3.  8.  3. 10.  8.  0. 15.  0.  6.  6. 15.  6.  6.  0.  0. 11.] 
adversary owned cards: [15  8  8 10  0  0  0  0  3  6  6  3  6 11  6  6  6 15  6  3  0  0] -> size -> 22 
adversary victory points: -4
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 3. 10.  0. 14. 25.  0. 29.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [10 22  8  8  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0 15
  3 15  3  1  0  3 25 25  1  0  3  0  0  1  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 23. 30.  6. 30.  8.  1.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [0. 6. 6. 6. 3.] 
adversary cards in discard: [ 0.  3.  8.  3. 10.  8.  0. 15.  0.  6.  6. 15.  6.  6.  0.  0. 11.] 
adversary owned cards: [15  8  8 10  0  0  0  0  3  6  6  3  6 11  6  6  6 15  6  3  0  0] -> size -> 22 
adversary victory points: -4
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 3. 10.  0. 14. 25.  0. 29.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [10 22  8  8  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0 15
  3 15  3  1  0  3 25 25  1  0  3  0  0  1  3  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 1. 23. 30.  6. 30.  8.  1.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [0. 6. 6. 6. 3.] 
adversary cards in discard: [ 0.  3.  8.  3. 10.  8.  0. 15.  0.  6.  6. 15.  6.  6.  0.  0. 11.] 
adversary owned cards: [15  8  8 10  0  0  0  0  3  6  6  3  6 11  6  6  6 15  6  3  0  0] -> size -> 22 
adversary victory points: -4
player victory points: 9 





         -------------------- Turn: 93 -------------------- 
Player: 0 
cards in hand: [0. 6. 6. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[13.173559]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 6. 3.] 
cards in discard: [ 0.  3.  8.  3. 10.  8.  0. 15.  0.  6.  6. 15.  6.  6.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  8 10  0  0  0  0  3  6  6  3  6 11  6  6  6 15  6  3  0  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 23. 30.  6. 30.  8.  1.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [ 0.  1. 14.  3. 25.] 
adversary cards in discard: [ 3. 10.  0. 14. 25.  0. 29.  0. 29.  8.  3.  0.] 
adversary owned cards: [10 22  8  8  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0 15
  3 15  3  1  0  3 25 25  1  0  3  0  0  1  3  0] -> size -> 40 
adversary victory points: 9
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -139 

action type: buy - action -1.0
Learning step: -8.156317710876465
desired expected reward: 21.898120880126953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 6.651016]
 [ 6.651016]
 [12.750713]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 6. 3.] 
cards in discard: [ 0.  3.  8.  3. 10.  8.  0. 15.  0.  6.  6. 15.  6.  6.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  8 10  0  0  0  0  3  6  6  3  6 11  6  6  6 15  6  3  0  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 23. 30.  6. 30.  8.  1.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [ 0.  1. 14.  3. 25.] 
adversary cards in discard: [ 3. 10.  0. 14. 25.  0. 29.  0. 29.  8.  3.  0.] 
adversary owned cards: [10 22  8  8  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0 15
  3 15  3  1  0  3 25 25  1  0  3  0  0  1  3  0] -> size -> 40 
adversary victory points: 9
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -139 

action type: take_action - action -1.0
Learning step: -7.365696907043457
desired expected reward: 5.807862281799316



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  1. 14.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 14.  3. 25.] 
cards in discard: [ 3. 10.  0. 14. 25.  0. 29.  0. 29.  8.  3.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [10 22  8  8  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0 15
  3 15  3  1  0  3 25 25  1  0  3  0  0  1  3  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 23. 30.  6. 30.  8.  1.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [15.  6.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [15  8  8 10  0  0  0  0  3  6  6  3  6 11  6  6  6 15  6  3  0  0] -> size -> 22 
adversary victory points: -4
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 14.  3. 15.  0.] 
cards in discard: [ 3. 10.  0. 14. 25.  0. 29.  0. 29.  8.  3.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [10 22  8  8  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0 15
  3 15  3  1  0  3 25 25  1  0  3  0  0  1  3  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 23. 30.  6. 30.  8.  0.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [15.  6.  0.  3.  8.] 
adversary cards in discard: [6.] 
adversary owned cards: [15  8  8 10  0  0  0  0  3  6  6  3  6 11  6  6  6 15  6  3  0  0  6] -> size -> 23 
adversary victory points: -4
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 14.  3. 15.  0.] 
cards in discard: [ 3. 10.  0. 14. 25.  0. 29.  0. 29.  8.  3.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [10 22  8  8  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0 15
  3 15  3  1  0  3 25 25  1  0  3  0  0  1  3  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 1. 23. 30.  6. 30.  8.  0.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [15.  6.  0.  3.  8.] 
adversary cards in discard: [6.] 
adversary owned cards: [15  8  8 10  0  0  0  0  3  6  6  3  6 11  6  6  6 15  6  3  0  0  6] -> size -> 23 
adversary victory points: -4
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 14.  3. 15.  0.] 
cards in discard: [ 3. 10.  0. 14. 25.  0. 29.  0. 29.  8.  3.  0.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [10 22  8  8  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0 15
  3 15  3  1  0  3 25 25  1  0  3  0  0  1  3  0  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 1. 23. 30.  5. 30.  8.  0.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [15.  6.  0.  3.  8.] 
adversary cards in discard: [6.] 
adversary owned cards: [15  8  8 10  0  0  0  0  3  6  6  3  6 11  6  6  6 15  6  3  0  0  6] -> size -> 23 
adversary victory points: -4
player victory points: 10 





         -------------------- Turn: 94 -------------------- 
Player: 0 
cards in hand: [15.  6.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[22.413666]
 [17.81293 ]
 [16.703823]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6.  0.  3.  8.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  8 10  0  0  0  0  3  6  6  3  6 11  6  6  6 15  6  3  0  0  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 23. 30.  5. 30.  8.  0.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [ 3.  8. 25.  1.  8.] 
adversary cards in discard: [ 3. 10.  0. 14. 25.  0. 29.  0. 29.  8.  3.  0.  3. 25.  0.  1. 14.  3.
 15.  0.] 
adversary owned cards: [10 22  8  8  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0 15
  3 15  3  1  0  3 25 25  1  0  3  0  0  1  3  0  3] -> size -> 41 
adversary victory points: 10
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -150    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -460 

action type: buy - action -1.0
Learning step: -23.170339584350586
desired expected reward: -10.419628143310547





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[16.402706]
 [22.753437]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  6.  0.  3.  8.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  8 10  0  0  0  0  3  6  6  3  6 11  6  6  6 15  6  3  0  0  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 23. 30.  5. 30.  8.  0.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [ 3.  8. 25.  1.  8.] 
adversary cards in discard: [ 3. 10.  0. 14. 25.  0. 29.  0. 29.  8.  3.  0.  3. 25.  0.  1. 14.  3.
 15.  0.] 
adversary owned cards: [10 22  8  8  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0 15
  3 15  3  1  0  3 25 25  1  0  3  0  0  1  3  0  3] -> size -> 41 
adversary victory points: 10
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -160 

action type: take_action - action -1.0
Learning step: -8.643019676208496
desired expected reward: 13.770644187927246



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  8. 25.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 25.  1.  8.] 
cards in discard: [ 3. 10.  0. 14. 25.  0. 29.  0. 29.  8.  3.  0.  3. 25.  0.  1. 14.  3.
 15.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [10 22  8  8  0  0  0  0  3 29  3 25 14  0  8 29 14 14 16  3  1  3  0 15
  3 15  3  1  0  3 25 25  1  0  3  0  0  1  3  0  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 23. 30.  5. 30.  8.  0.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [6. 0. 6. 6. 8.] 
adversary cards in discard: [ 6. 15.  6.  0.  3.  8.] 
adversary owned cards: [15  8  8 10  0  0  0  0  3  6  6  3  6 11  6  6  6 15  6  3  0  0  6] -> size -> 23 
adversary victory points: -5
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  8.] 
cards in discard: [ 3. 10.  0. 14. 25.  0. 29.  0. 29.  8.  3.  0.  3. 25.  0.  1. 14.  3.
 15.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 22  8  8  0  0  0  0 29  3 25 14  0  8 29 14 14 16  3  1  3  0 15  3
 15  3  1  0  3 25 25  1  0  3  0  0  1  3  0  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 23. 30.  5. 30.  8.  0.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [6. 0. 6. 6. 8.] 
adversary cards in discard: [ 6. 15.  6.  0.  3.  8.] 
adversary owned cards: [15  8  8 10  0  0  0  0  3  6  6  3  6 11  6  6  6 15  6  3  0  0  6] -> size -> 23 
adversary victory points: -5
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1.  8.] 
cards in discard: [ 3. 10.  0. 14. 25.  0. 29.  0. 29.  8.  3.  0.  3. 25.  0.  1. 14.  3.
 15.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 22  8  8  0  0  0  0 29  3 25 14  0  8 29 14 14 16  3  1  3  0 15  3
 15  3  1  0  3 25 25  1  0  3  0  0  1  3  0  3] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 23. 30.  5. 30.  8.  0.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [6. 0. 6. 6. 8.] 
adversary cards in discard: [ 6. 15.  6.  0.  3.  8.] 
adversary owned cards: [15  8  8 10  0  0  0  0  3  6  6  3  6 11  6  6  6 15  6  3  0  0  6] -> size -> 23 
adversary victory points: -5
player victory points: 9 


Player 1 won the game! 



Player 0 bought cards:
Copper: 9 
Silver: 1 
Gold: 0 
Estate: 8 
Duchy: 0 
Province: 0 
Curse: 5 

Remodel: 0 
Workshop: 2 
Chapel: 3 
Witch: 0 
Poacher: 0 
Militia: 0 
Market: 0 
Village: 2 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [6. 0. 6. 6. 8.] 
cards in discard: [ 6. 15.  6.  0.  3.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  8 10  0  0  0  0  3  6  6  3  6 11  6  6  6 15  6  3  0  0  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30.  5. 30.  8.  0.  8.  2.  0.  7.  7.  4. 10.  1.  9.  6.] 
adversary cards in hand: [25.  1.  8.] 
adversary cards in discard: [ 3. 10.  0. 14. 25.  0. 29.  0. 29.  8.  3.  0.  3. 25.  0.  1. 14.  3.
 15.  0.  0.] 
adversary owned cards: [10 22  8  8  0  0  0  0 29  3 25 14  0  8 29 14 14 16  3  1  3  0 15  3
 15  3  1  0  3 25 25  1  0  3  0  0  1  3  0  3  0] -> size -> 41 
adversary victory points: 9
player victory points: -5 

Reward from previous game state: 
[  -5 -500   -5 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -650 

action type: buy - action -1.0
Learning step: -33.637672424316406
desired expected reward: -10.884235382080078



