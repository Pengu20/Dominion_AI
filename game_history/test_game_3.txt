 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[340.2134]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [8. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500   -6  -90    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -601 

action type: buy - action -1.0
Learning step: -59.8946647644043
desired expected reward: -61.948028564453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[325.91708]
 [338.88364]
 [342.43573]
 [322.5768 ]
 [325.175  ]
 [343.53238]
 [327.73276]
 [333.36517]
 [326.18542]
 [330.5668 ]
 [336.39993]
 [338.44302]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [8. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 340.9569091796875



buy possibilites: [-1] 
expected returns: [[306.99188]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [8. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   3.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 2.5 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 343.5323486328125






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [8. 0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [11.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [8. 0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [11.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [8. 0. 0. 3. 0. 0. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [11.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[334.54657]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [11.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: 0
desired expected reward: 306.99188232421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[323.3366 ]
 [336.6241 ]
 [340.2035 ]
 [319.861  ]
 [341.1844 ]
 [325.00595]
 [327.87018]
 [335.69012]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [11.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 335.5633239746094



buy possibilites: [-1] 
expected returns: [[283.48175]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [11.  0.  0.  3.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 16 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 341.18438720703125






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [8. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 3 3 3 8 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 3 3 3 8 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  3.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[262.3086 ]
 [267.39795]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [8. 3. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 8 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: 0
desired expected reward: 283.48175048828125



action possibilites: [-1] 
expected returns: [[267.50894]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [8. 3. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 8 8] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5    0    2  -10    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -293 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 266.9012145996094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[255.4914 ]
 [271.1962 ]
 [252.30815]
 [257.2557 ]
 [267.53714]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [8. 3. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 8 8] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action -1
Learning step: 0
desired expected reward: 267.5089416503906



buy possibilites: [-1] 
expected returns: [[272.80667]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [6. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [8. 3. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 8 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 26 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 271.1961975097656






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [8. 3. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 3 8 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 6.  3. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [8. 3. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 3 8 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 6.  3. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [8. 3. 3. 3. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 3 8 8 8] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  8.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 6.  3. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3] -> size -> 14 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[255.98926]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 6.  3. 11.  0.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  8.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 8 8 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: 0
desired expected reward: 272.8066711425781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[250.99422]
 [263.9407 ]
 [267.39047]
 [247.63246]
 [250.13663]
 [268.35303]
 [252.61665]
 [258.0942 ]
 [251.11081]
 [255.40652]
 [261.1756 ]
 [263.02066]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 6.  3. 11.  0.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  8.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 8 8 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 257.43359375



buy possibilites: [-1] 
expected returns: [[252.62723]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 6.  3. 11.  0.  3.  3.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  7.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 8 8 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   3.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 2.5 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 268.35302734375






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [3. 3. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 3 8 8 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  7.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 6. 11.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 3 8 8 8] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  7.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 6. 11.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 0. 0.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 3 8 8 8 0] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  7.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 6. 11.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 6. 11.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[232.64894]
 [237.4226 ]
 [237.4226 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  7.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 3. 3. 8. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 8 8 8 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: 0
desired expected reward: 252.62722778320312



action possibilites: [-1] 
expected returns: [[237.54092]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 11.  0.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  7.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 3. 3. 8. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 8 8 8 0] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5    0    2  -10    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -293 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 237.1522979736328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[222.58539]
 [238.29022]
 [219.40218]
 [224.3497 ]
 [234.63116]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 11.  0.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  7.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 3. 3. 8. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 8 8 8 0] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action -1
Learning step: 0
desired expected reward: 237.54092407226562



buy possibilites: [-1] 
expected returns: [[236.62308]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 11.  0.] 
cards in discard: [6. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  8. 10.  7.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 3. 3. 8. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 8 8 8 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 26 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 238.29022216796875






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0. 3. 3. 8. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 3 8 8 8 0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  8. 10.  7.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [ 6.  3. 11.  6.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3] -> size -> 17 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0. 3. 3. 8. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 3 8 8 8 0] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 28. 30.  8.  8. 10.  7.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [ 6.  3. 11.  6.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3] -> size -> 17 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0. 3. 3. 8. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 3 8 8 8 0 3] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 27. 30.  8.  8. 10.  7.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [ 6.  3. 11.  6.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3] -> size -> 17 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [3. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[233.56873]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [ 6.  3. 11.  6.  0. 11.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8.  8. 10.  7.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 8. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 8 8 8 0 3] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: 0
desired expected reward: 236.62307739257812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[224.46817]
 [241.29834]
 [221.04625]
 [226.08076]
 [236.72778]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [ 6.  3. 11.  6.  0. 11.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 27. 30.  8.  8. 10.  7.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 8. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 8 8 8 0 3] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 236.57757568359375



buy possibilites: [-1] 
expected returns: [[258.83914]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [ 6.  3. 11.  6.  0. 11.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  8. 10.  7.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 8. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 3 3 3 8 8 8 0 3] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 7 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 241.29833984375






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [0. 3. 8. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 8. 8.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 3 8 8 8 0 3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  8. 10.  7.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 11.  0.] 
adversary cards in discard: [ 6.  3. 11.  6.  0. 11.  0.  3.  3.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3] -> size -> 18 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 3 3 3 8 0 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  8. 10.  7.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 11.  0.] 
adversary cards in discard: [ 6.  3. 11.  6.  0. 11.  0.  3.  3.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3] -> size -> 18 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 3 3 3 8 0 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  8. 10.  7.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 11.  0.] 
adversary cards in discard: [ 6.  3. 11.  6.  0. 11.  0.  3.  3.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3] -> size -> 18 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[249.82532]
 [255.26715]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 11.  0.] 
cards in discard: [ 6.  3. 11.  6.  0. 11.  0.  3.  3.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  8. 10.  7.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 0 3] -> size -> 11 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: 0
desired expected reward: 258.8391418457031



action possibilites: [-1] 
expected returns: [[234.86142]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 6.  3. 11.  6.  0. 11.  0.  3.  3.  0.  3.  3.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  7. 10.  7.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 0 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5    0    3  -10    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -292 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 255.6099853515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[220.47856]
 [234.13013]
 [237.76999]
 [216.921  ]
 [238.84909]
 [222.2448 ]
 [225.19756]
 [233.30034]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 6.  3. 11.  6.  0. 11.  0.  3.  3.  0.  3.  3.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 26. 30.  8.  7. 10.  7.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 0 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action -1
Learning step: 0
desired expected reward: 234.86141967773438



buy possibilites: [-1] 
expected returns: [[207.74475]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 6.  3. 11.  6.  0. 11.  0.  3.  3.  0.  3.  3.  0.  6. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  7. 10.  6.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [0 0 0 0 0 3 3 3 8 0 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: 26 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 238.8490753173828






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [8. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 8 0 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  7. 10.  6.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11] -> size -> 20 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [8. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 3 8 0 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 26. 30.  8.  7. 10.  6.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11] -> size -> 20 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 8.  3. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  3 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  7. 10.  5.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11] -> size -> 20 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [11.  0. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[195.97537]
 [200.97601]
 [200.97601]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  7. 10.  5.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  3 11] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: 0
desired expected reward: 207.7447509765625



action possibilites: [-1] 
expected returns: [[157.55978]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  6. 10.  5.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  3 11] -> size -> 12 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5    0    2  -20    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -303 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 200.9324951171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[147.9953 ]
 [163.98964]
 [144.8341 ]
 [149.61827]
 [159.66429]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 26. 30.  8.  6. 10.  5.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  3 11] -> size -> 12 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: take_action - action -1
Learning step: 0
desired expected reward: 157.55978393554688



buy possibilites: [-1] 
expected returns: [[195.33615]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.] 
cards in discard: [6. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 25. 30.  8.  6. 10.  5.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  3 11] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: 16 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 163.98965454101562






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [8. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  3 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 25. 30.  8.  6. 10.  5.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 3. 6. 3. 0.] 
adversary cards in discard: [ 6.  3. 11.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3] -> size -> 22 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  3 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 25. 30.  8.  6. 10.  5.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 3. 6. 3. 0.] 
adversary cards in discard: [ 6.  3. 11.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3] -> size -> 22 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  3 11  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 30. 30. 25. 30.  8.  6. 10.  5.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 3. 6. 3. 0.] 
adversary cards in discard: [ 6.  3. 11.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3] -> size -> 22 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [6. 3. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[167.82286]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 6. 3. 0.] 
cards in discard: [ 6.  3. 11.  0. 11.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 25. 30.  8.  6. 10.  5.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  3.  0.] 
adversary cards in discard: [0. 8. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  3 11  0] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: 0
desired expected reward: 195.33615112304688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[157.55386]
 [154.36227]
 [168.95676]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 3. 0.] 
cards in discard: [ 6.  3. 11.  0. 11.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 25. 30.  8.  6. 10.  5.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  3.  0.] 
adversary cards in discard: [0. 8. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  3 11  0] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 168.53770446777344



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  3.  0.] 
cards in discard: [0. 8. 3. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  3 11  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 25. 30.  8.  6. 10.  5.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11. 11.  3.  3.] 
adversary cards in discard: [ 6.  3. 11.  0. 11.  0.  3.  6.  3.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3] -> size -> 22 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  3.  0.] 
cards in discard: [0. 8. 3. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  3 11  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 25. 30.  8.  6. 10.  5.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11. 11.  3.  3.] 
adversary cards in discard: [ 6.  3. 11.  0. 11.  0.  3.  6.  3.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3] -> size -> 22 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 11. 11.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[185.25835]
 [190.8071 ]
 [190.8071 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  3.  3.] 
cards in discard: [ 6.  3. 11.  0. 11.  0.  3.  6.  3.  6.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 25. 30.  8.  6. 10.  5.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  3 11  0] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 168.9567413330078



action possibilites: [-1] 
expected returns: [[215.73953]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  3.] 
cards in discard: [ 6.  3. 11.  0. 11.  0.  3.  6.  3.  6.  3.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 25. 30.  8.  5. 10.  5.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  3 11  0] -> size -> 13 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5    0    2  -20    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -303 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 190.2476806640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[205.10806]
 [201.46677]
 [217.84679]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  3.] 
cards in discard: [ 6.  3. 11.  0. 11.  0.  3.  6.  3.  6.  3.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 25. 30.  8.  5. 10.  5.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  3 11  0] -> size -> 13 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: take_action - action -1
Learning step: 0
desired expected reward: 215.73953247070312






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  3 11  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 25. 30.  8.  5. 10.  5.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 6. 0.] 
adversary cards in discard: [ 6.  3. 11.  0. 11.  0.  3.  6.  3.  6.  3.  0.  6. 11.  0. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6] -> size -> 23 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  3 11  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 25. 30.  8.  5. 10.  5.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 6. 0.] 
adversary cards in discard: [ 6.  3. 11.  0. 11.  0.  3.  6.  3.  6.  3.  0.  6. 11.  0. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6] -> size -> 23 
adversary victory points: 2
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [3. 0. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[179.26991]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 6. 0.] 
cards in discard: [ 6.  3. 11.  0. 11.  0.  3.  6.  3.  6.  3.  0.  6. 11.  0. 11.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 25. 30.  8.  5. 10.  5.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 8.] 
adversary cards in discard: [ 0.  3. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  3 11  0] -> size -> 13 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 217.84678649902344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[168.68765]
 [179.98575]
 [183.0123 ]
 [165.80933]
 [184.19743]
 [170.38338]
 [172.87764]
 [179.88799]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 0.] 
cards in discard: [ 6.  3. 11.  0. 11.  0.  3.  6.  3.  6.  3.  0.  6. 11.  0. 11.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 25. 30.  8.  5. 10.  5.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 8.] 
adversary cards in discard: [ 0.  3. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  3 11  0] -> size -> 13 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 179.28106689453125



buy possibilites: [-1] 
expected returns: [[156.25648]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 0.] 
cards in discard: [ 6.  3. 11.  0. 11.  0.  3.  6.  3.  6.  3.  0.  6. 11.  0. 11.  3.  3.
 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 25. 30.  8.  5. 10.  4.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 8.] 
adversary cards in discard: [ 0.  3. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  0  3 11  0] -> size -> 13 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -5 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 184.19741821289062






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 8.] 
cards in discard: [ 0.  3. 11.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  0  3 11  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 25. 30.  8.  5. 10.  4.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 6.  0. 11. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11] -> size -> 24 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [ 0.  3. 11.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  8  0  3 11  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 25. 30.  8.  5. 10.  4.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 6.  0. 11. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11] -> size -> 24 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [ 0.  3. 11.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  8  0  3 11  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 30. 30. 25. 30.  8.  5. 10.  4.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 6.  0. 11. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11] -> size -> 24 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [ 6.  0. 11. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[151.75487]
 [156.75552]
 [156.75552]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 11. 11.  6.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 25. 30.  8.  5. 10.  4.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  8  0  3 11  0] -> size -> 11 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: 0
desired expected reward: 156.25648498535156



action possibilites: [-1] 
expected returns: [[154.64293]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 11.  6.] 
cards in discard: [6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 25. 30.  8.  4. 10.  4.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  8  0  3 11  0] -> size -> 11 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[  -5    0    1  -30    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -314 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 156.8285675048828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[141.60275]
 [138.53769]
 [153.10844]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 11.  6.] 
cards in discard: [6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 25. 30.  8.  4. 10.  4.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  8  0  3 11  0] -> size -> 11 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1
Learning step: 0
desired expected reward: 154.64292907714844






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  8  0  3 11  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 25. 30.  8.  4. 10.  4.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [ 6. 11.  6.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6] -> size -> 25 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  8  0  3 11  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 25. 30.  8.  4. 10.  4.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [ 6. 11.  6.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6] -> size -> 25 
adversary victory points: 1
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [3. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[136.16592]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [ 6. 11.  6.  0. 11.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 25. 30.  8.  4. 10.  4.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  3.  8.  3.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  3  3  3  8  0  3 11  0] -> size -> 11 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 153.1084442138672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[123.35122]
 [140.27551]
 [119.98216]
 [124.97176]
 [135.7056 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [ 6. 11.  6.  0. 11.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 25. 30.  8.  4. 10.  4.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  3.  8.  3.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  3  3  3  8  0  3 11  0] -> size -> 11 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 137.42135620117188



buy possibilites: [-1] 
expected returns: [[130.46487]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [ 6. 11.  6.  0. 11.  6.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8.  4. 10.  4.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  3.  8.  3.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  3  3  3  8  0  3 11  0] -> size -> 11 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -15 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 140.27549743652344






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [11.  0.  3.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  8.  3.] 
cards in discard: [0. 3. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  8  0  3 11  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 24. 30.  8.  4. 10.  4.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  6.  6.  3. 11.] 
adversary cards in discard: [ 6. 11.  6.  0. 11.  6.  3.  3.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3] -> size -> 26 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  8.  3.] 
cards in discard: [0. 3. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  8  0  3 11  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 24. 30.  8.  4. 10.  4.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  6.  6.  3. 11.] 
adversary cards in discard: [ 6. 11.  6.  0. 11.  6.  3.  3.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3] -> size -> 26 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  8.  3.] 
cards in discard: [0. 3. 0. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  8  0  3 11  0  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 24. 30.  8.  4. 10.  4.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  6.  6.  3. 11.] 
adversary cards in discard: [ 6. 11.  6.  0. 11.  6.  3.  3.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3] -> size -> 26 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [ 0.  6.  6.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[123.47468]
 [128.84734]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  6.  3. 11.] 
cards in discard: [ 6. 11.  6.  0. 11.  6.  3.  3.  0.  0.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 24. 30.  8.  4. 10.  4.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  8  0  3 11  0  0] -> size -> 12 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: 0
desired expected reward: 130.46487426757812



action possibilites: [-1] 
expected returns: [[169.97888]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 3.] 
cards in discard: [ 6. 11.  6.  0. 11.  6.  3.  3.  0.  0.  3.  3.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 24. 30.  8.  3. 10.  4.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  8  0  3 11  0  0] -> size -> 12 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[  -5    0    1  -30    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -314 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 126.7931900024414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[158.54066]
 [155.10295]
 [171.2987 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 3.] 
cards in discard: [ 6. 11.  6.  0. 11.  6.  3.  3.  0.  0.  3.  3.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 24. 30.  8.  3. 10.  4.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  8  0  3 11  0  0] -> size -> 12 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1
Learning step: 0
desired expected reward: 169.9788818359375






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  8  0  3 11  0  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 24. 30.  8.  3. 10.  4.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3. 11.] 
adversary cards in discard: [ 6. 11.  6.  0. 11.  6.  3.  3.  0.  0.  3.  3.  6. 11.  0.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6] -> size -> 27 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  8  0  3 11  0  0 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 24. 30.  8.  3. 10.  3.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3. 11.] 
adversary cards in discard: [ 6. 11.  6.  0. 11.  6.  3.  3.  0.  0.  3.  3.  6. 11.  0.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6] -> size -> 27 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  8  0  3 11  0  0 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 24. 30.  8.  3. 10.  3.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3. 11.] 
adversary cards in discard: [ 6. 11.  6.  0. 11.  6.  3.  3.  0.  0.  3.  3.  6. 11.  0.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6] -> size -> 27 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [11.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  8  0  3 11  0  0 11  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 23. 30.  8.  3. 10.  3.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3. 11.] 
adversary cards in discard: [ 6. 11.  6.  0. 11.  6.  3.  3.  0.  0.  3.  3.  6. 11.  0.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6] -> size -> 27 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [ 0. 11.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[93.51046]
 [96.99445]
 [96.99445]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3. 11.] 
cards in discard: [ 6. 11.  6.  0. 11.  6.  3.  3.  0.  0.  3.  3.  6. 11.  0.  6.  6.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 23. 30.  8.  3. 10.  3.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [11.  3. 11.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  8  0  3 11  0  0 11  3] -> size -> 14 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 171.29872131347656



action possibilites: [-1] 
expected returns: [[105.405334]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 11.] 
cards in discard: [ 6. 11.  6.  0. 11.  6.  3.  3.  0.  0.  3.  3.  6. 11.  0.  6.  6.  3.
  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 23. 30.  8.  2. 10.  3.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [11.  3. 11.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  8  0  3 11  0  0 11  3] -> size -> 14 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5    0    0  -50    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -335 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 95.69815826416016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 95.44975]
 [108.89381]
 [ 92.77385]
 [ 97.08262]
 [106.06724]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 11.] 
cards in discard: [ 6. 11.  6.  0. 11.  6.  3.  3.  0.  0.  3.  3.  6. 11.  0.  6.  6.  3.
  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 23. 30.  8.  2. 10.  3.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [11.  3. 11.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  8  0  3 11  0  0 11  3] -> size -> 14 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 105.40533447265625



buy possibilites: [-1] 
expected returns: [[113.74489]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 11.] 
cards in discard: [ 6. 11.  6.  0. 11.  6.  3.  3.  0.  0.  3.  3.  6. 11.  0.  6.  6.  3.
  6.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 22. 30.  8.  2. 10.  3.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [11.  3. 11.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  8  0  3 11  0  0 11  3] -> size -> 14 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: -16 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 108.893798828125






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [11.  3. 11.  3.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  8  0  3 11  0  0 11  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 22. 30.  8.  2. 10.  3.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3] -> size -> 29 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [11.  3. 11.  3.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  8  0  3 11  0  0 11  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 22. 30.  8.  2. 10.  3.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3] -> size -> 29 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [11.  3. 11.  3.  0.  0.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  8  0  3 11  0  0 11  3  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 22. 30.  8.  2. 10.  3.  6. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3] -> size -> 29 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [0. 3. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[123.83341]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 3. 0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 22. 30.  8.  2. 10.  3.  6. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  8  0  3 11  0  0 11  3  8] -> size -> 15 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1
Learning step: 0
desired expected reward: 113.74488830566406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[114.071144]
 [129.83307 ]
 [110.89261 ]
 [115.74616 ]
 [125.88155 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 3. 0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 22. 30.  8.  2. 10.  3.  6. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  8  0  3 11  0  0 11  3  8] -> size -> 15 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 125.34745025634766



buy possibilites: [-1] 
expected returns: [[146.49919]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 3. 0.] 
cards in discard: [3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 21. 30.  8.  2. 10.  3.  6. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  8  0  3 11  0  0 11  3  8] -> size -> 15 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -25 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 129.8330535888672






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 8. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  8  0  3 11  0  0 11  3  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 21. 30.  8.  2. 10.  3.  6. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3. 11.  3.  0.] 
adversary cards in discard: [3. 0. 3. 6. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3] -> size -> 30 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 21. 30.  8.  2. 10.  3.  6. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3. 11.  3.  0.] 
adversary cards in discard: [3. 0. 3. 6. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3] -> size -> 30 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 21. 30.  8.  2. 10.  3.  6. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3. 11.  3.  0.] 
adversary cards in discard: [3. 0. 3. 6. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3] -> size -> 30 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 20. 30.  8.  2. 10.  3.  6. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3. 11.  3.  0.] 
adversary cards in discard: [3. 0. 3. 6. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3] -> size -> 30 
adversary victory points: 2
player victory points: 6 





Player: 0 
cards in hand: [ 3.  3. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[172.61734]
 [178.11371]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11.  3.  0.] 
cards in discard: [3. 0. 3. 6. 3. 0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 20. 30.  8.  2. 10.  3.  6. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  3.  3.  3.  3.] 
adversary cards in discard: [3. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3] -> size -> 15 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: buy - action -1
Learning step: 0
desired expected reward: 146.4991912841797



action possibilites: [-1] 
expected returns: [[146.53036]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0.] 
cards in discard: [3. 0. 3. 6. 3. 0. 6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 20. 30.  8.  1. 10.  3.  6. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  3.  3.  3.  3.] 
adversary cards in discard: [3. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3] -> size -> 15 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    1  -50    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -334 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 174.88449096679688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[136.33325]
 [133.06398]
 [148.25113]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0.] 
cards in discard: [3. 0. 3. 6. 3. 0. 6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 20. 30.  8.  1. 10.  3.  6. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  3.  3.  3.  3.] 
adversary cards in discard: [3. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3] -> size -> 15 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1
Learning step: 0
desired expected reward: 146.53036499023438






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [11.  3.  3.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  3.  3.  3.] 
cards in discard: [3. 8. 0. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 20. 30.  8.  1. 10.  3.  6. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  3. 11.] 
adversary cards in discard: [ 3.  0.  3.  6.  3.  0.  6. 11.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6] -> size -> 31 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  3.  3.  3.] 
cards in discard: [3. 8. 0. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3] -> size -> 15 
action values: 1 
buys: 1 
player value: 0 
card supply: [27. 30. 30. 20. 30.  8.  1. 10.  3.  6. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  3. 11.] 
adversary cards in discard: [ 3.  0.  3.  6.  3.  0.  6. 11.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6] -> size -> 31 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  3.  3.  3.] 
cards in discard: [3. 8. 0. 0. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 20. 30.  8.  1. 10.  3.  6. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  3. 11.] 
adversary cards in discard: [ 3.  0.  3.  6.  3.  0.  6. 11.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6] -> size -> 31 
adversary victory points: 1
player victory points: 6 





Player: 0 
cards in hand: [ 3.  0.  3.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[158.58128]
 [163.85066]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  3. 11.] 
cards in discard: [ 3.  0.  3.  6.  3.  0.  6. 11.  3.  3.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 20. 30.  8.  1. 10.  3.  6. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 11.  0.] 
adversary cards in discard: [ 3.  8.  0.  0.  0.  0. 11.  3.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0] -> size -> 16 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 148.25112915039062



action possibilites: [-1] 
expected returns: [[130.57932]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3.] 
cards in discard: [ 3.  0.  3.  6.  3.  0.  6. 11.  3.  3.  3.  0.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 20. 30.  8.  0. 10.  3.  6. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 11.  0.] 
adversary cards in discard: [ 3.  8.  0.  0.  0.  0. 11.  3.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0] -> size -> 16 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[  -5    0    0  -60    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -345 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 162.6768035888672





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[120.26899]
 [131.42361]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3.] 
cards in discard: [ 3.  0.  3.  6.  3.  0.  6. 11.  3.  3.  3.  0.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 20. 30.  8.  0. 10.  3.  6. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 11.  0.] 
adversary cards in discard: [ 3.  8.  0.  0.  0.  0. 11.  3.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0] -> size -> 16 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 130.57931518554688






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 11.  0.] 
cards in discard: [ 3.  8.  0.  0.  0.  0. 11.  3.  3.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 20. 30.  8.  0. 10.  3.  6. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 6. 6. 6. 6.] 
adversary cards in discard: [ 3.  0.  3.  6.  3.  0.  6. 11.  3.  3.  3.  0.  6. 11.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6] -> size -> 32 
adversary victory points: 0
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 3.  8.  0.  0.  0.  0. 11.  3.  3.  3.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 20. 30.  8.  0. 10.  2.  6. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 6. 6. 6. 6.] 
adversary cards in discard: [ 3.  0.  3.  6.  3.  0.  6. 11.  3.  3.  3.  0.  6. 11.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6] -> size -> 32 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 3.  8.  0.  0.  0.  0. 11.  3.  3.  3.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 20. 30.  8.  0. 10.  2.  6. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 6. 6. 6. 6.] 
adversary cards in discard: [ 3.  0.  3.  6.  3.  0.  6. 11.  3.  3.  3.  0.  6. 11.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6] -> size -> 32 
adversary victory points: 0
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 3.  8.  0.  0.  0.  0. 11.  3.  3.  3.  3. 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 30. 30. 20. 30.  8.  0. 10.  2.  6. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 6. 6. 6. 6.] 
adversary cards in discard: [ 3.  0.  3.  6.  3.  0.  6. 11.  3.  3.  3.  0.  6. 11.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6] -> size -> 32 
adversary victory points: 0
player victory points: 6 





Player: 0 
cards in hand: [3. 6. 6. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[113.93749]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 6. 6.] 
cards in discard: [ 3.  0.  3.  6.  3.  0.  6. 11.  3.  3.  3.  0.  6. 11.  3.  0.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 20. 30.  8.  0. 10.  2.  6. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0] -> size -> 18 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 131.4236297607422





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[102.950714]
 [114.45    ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 6. 6.] 
cards in discard: [ 3.  0.  3.  6.  3.  0.  6. 11.  3.  3.  3.  0.  6. 11.  3.  0.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6] -> size -> 32 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 30. 30. 20. 30.  8.  0. 10.  2.  6. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0] -> size -> 18 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 113.93749237060547



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 20. 30.  8.  0. 10.  2.  6. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  6.  0. 11.] 
adversary cards in discard: [ 3.  0.  3.  6.  3.  0.  6. 11.  3.  3.  3.  0.  6. 11.  3.  0.  3.  3.
  3.  6.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6] -> size -> 32 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 30. 30. 20. 30.  8.  0. 10.  2.  6. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  6.  0. 11.] 
adversary cards in discard: [ 3.  0.  3.  6.  3.  0.  6. 11.  3.  3.  3.  0.  6. 11.  3.  0.  3.  3.
  3.  6.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6] -> size -> 32 
adversary victory points: 0
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 20. 30.  8.  0. 10.  2.  6. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  6.  0. 11.] 
adversary cards in discard: [ 3.  0.  3.  6.  3.  0.  6. 11.  3.  3.  3.  0.  6. 11.  3.  0.  3.  3.
  3.  6.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6] -> size -> 32 
adversary victory points: 0
player victory points: 6 





Player: 0 
cards in hand: [11.  0.  6.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[121.22586]
 [125.61944]
 [125.61944]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6.  0. 11.] 
cards in discard: [ 3.  0.  3.  6.  3.  0.  6. 11.  3.  3.  3.  0.  6. 11.  3.  0.  3.  3.
  3.  6.  6.  6.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 20. 30.  8.  0. 10.  2.  6. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0.  8.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0 29] -> size -> 19 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 114.44999694824219



action possibilites: [-1] 
expected returns: [[118.19535]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 11.] 
cards in discard: [ 3.  0.  3.  6.  3.  0.  6. 11.  3.  3.  3.  0.  6. 11.  3.  0.  3.  3.
  3.  6.  6.  6.  6. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 20. 30.  8.  0.  9.  2.  6. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0.  8.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0 29] -> size -> 19 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -29 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 124.38883972167969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[107.57231]
 [122.05004]
 [109.18696]
 [118.65501]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 11.] 
cards in discard: [ 3.  0.  3.  6.  3.  0.  6. 11.  3.  3.  3.  0.  6. 11.  3.  0.  3.  3.
  3.  6.  6.  6.  6. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 30. 30. 20. 30.  8.  0.  9.  2.  6. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0.  8.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0 29] -> size -> 19 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 118.19535064697266



buy possibilites: [-1] 
expected returns: [[124.06991]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 11.] 
cards in discard: [ 3.  0.  3.  6.  3.  0.  6. 11.  3.  3.  3.  0.  6. 11.  3.  0.  3.  3.
  3.  6.  6.  6.  6. 16.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 19. 30.  8.  0.  9.  2.  6. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0.  8.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0 29] -> size -> 19 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: -26 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 122.05004119873047






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 11.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0.  8.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 19. 30.  8.  0.  9.  2.  6. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  6.  6. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3] -> size -> 34 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 8.] 
cards in discard: [29.  0.  0.  3.  0.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0 29  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 19. 30.  8.  0.  9.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  6.  6. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3] -> size -> 34 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8.] 
cards in discard: [29.  0.  0.  3.  0.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0 29  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 30. 30. 19. 30.  8.  0.  9.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  6.  6. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3] -> size -> 34 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8.] 
cards in discard: [29.  0.  0.  3.  0.  0.  8.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0 29  8  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 18. 30.  8.  0.  9.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  6.  6. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3] -> size -> 34 
adversary victory points: 1
player victory points: 7 





Player: 0 
cards in hand: [ 3.  6.  6. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[120.20865]
 [124.95385]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  6. 11.  0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 18. 30.  8.  0.  9.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  3.  3.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.  8.  3. 11.  3.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0 29  8  3] -> size -> 21 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: buy - action -1
Learning step: 0
desired expected reward: 124.06990814208984



action possibilites: [-1] 
expected returns: [[104.747154]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 0.] 
cards in discard: [16.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 18. 30.  8.  0.  8.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  3.  3.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.  8.  3. 11.  3.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0 29  8  3] -> size -> 21 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -28 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 123.02235412597656





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 93.54112]
 [105.10958]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 0.] 
cards in discard: [16.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 30. 30. 18. 30.  8.  0.  8.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  3.  3.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.  8.  3. 11.  3.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0 29  8  3] -> size -> 21 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1
Learning step: 0
desired expected reward: 104.74715423583984






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  3.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  3.  3.] 
cards in discard: [29.  0.  0.  3.  0.  0.  8.  3. 11.  3.  0.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0 29  8  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 18. 30.  8.  0.  8.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 6. 3.] 
adversary cards in discard: [16. 11.  3.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16] -> size -> 35 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  3.  3.] 
cards in discard: [29.  0.  0.  3.  0.  0.  8.  3. 11.  3.  0.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0 29  8  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 30. 30. 18. 30.  8.  0.  8.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 6. 3.] 
adversary cards in discard: [16. 11.  3.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16] -> size -> 35 
adversary victory points: 1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  3.  3.] 
cards in discard: [29.  0.  0.  3.  0.  0.  8.  3. 11.  3.  0.  0.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0 29  8  3  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 30. 30. 18. 30.  8.  0.  8.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 6. 3.] 
adversary cards in discard: [16. 11.  3.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16] -> size -> 35 
adversary victory points: 1
player victory points: 7 





Player: 0 
cards in hand: [0. 0. 3. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[73.320366]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 6. 3.] 
cards in discard: [16. 11.  3.  6.  6.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 18. 30.  8.  0.  8.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0 29  8  3  0] -> size -> 22 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 105.10958099365234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[63.522713]
 [76.82012 ]
 [64.8788  ]
 [73.596855]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 3.] 
cards in discard: [16. 11.  3.  6.  6.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 30. 30. 18. 30.  8.  0.  8.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0 29  8  3  0] -> size -> 22 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 73.32036590576172



buy possibilites: [-1] 
expected returns: [[82.232796]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 3.] 
cards in discard: [16. 11.  3.  6.  6.  0.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 17. 30.  8.  0.  8.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0 29  8  3  0] -> size -> 22 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0  -1   0   0   8   0] 
sum of rewards: -46 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 76.82012176513672






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 11.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0 29  8  3  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 17. 30.  8.  0.  8.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  3.  6.  0. 16.] 
adversary cards in discard: [16. 11.  3.  6.  6.  0.  3.  0.  0.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3] -> size -> 36 
adversary victory points: 2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0 29  8  3  0  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 17. 30.  8.  0.  8.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  3.  6.  0. 16.] 
adversary cards in discard: [16. 11.  3.  6.  6.  0.  3.  0.  0.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3] -> size -> 36 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0 29  8  3  0  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 29. 30. 17. 30.  8.  0.  8.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  3.  6.  0. 16.] 
adversary cards in discard: [16. 11.  3.  6.  6.  0.  3.  0.  0.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3] -> size -> 36 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [1. 1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0 29  8  3  0  1  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 17. 30.  8.  0.  8.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  3.  6.  0. 16.] 
adversary cards in discard: [16. 11.  3.  6.  6.  0.  3.  0.  0.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3] -> size -> 36 
adversary victory points: 2
player victory points: 7 





Player: 0 
cards in hand: [11.  3.  6.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
expected returns: [[74.24563 ]
 [78.72118 ]
 [62.418724]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  6.  0. 16.] 
cards in discard: [16. 11.  3.  6.  6.  0.  3.  0.  0.  3.  6.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 17. 30.  8.  0.  8.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0.  0.] 
adversary cards in discard: [ 1.  1. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0 29  8  3  0  1  1] -> size -> 24 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: buy - action -1
Learning step: 0
desired expected reward: 82.23279571533203



action possibilites: [-1] 
expected returns: [[102.713585]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  0. 16.] 
cards in discard: [16. 11.  3.  6.  6.  0.  3.  0.  0.  3.  6.  3. 16.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 17. 30.  8.  0.  7.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0.  0.] 
adversary cards in discard: [ 1.  1. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0 29  8  3  0  1  1] -> size -> 24 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0  20   0   0   0   0  -2   0   0  16   0] 
sum of rewards: -19 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 77.60090637207031





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 91.56207]
 [103.50177]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  0. 16.] 
cards in discard: [16. 11.  3.  6.  6.  0.  3.  0.  0.  3.  6.  3. 16.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 28. 30. 17. 30.  8.  0.  7.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  0.  0.] 
adversary cards in discard: [ 1.  1. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0 29  8  3  0  1  1] -> size -> 24 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1
Learning step: 0
desired expected reward: 102.71358489990234






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  0.  0.] 
cards in discard: [ 1.  1. 11.  0.  0.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0 29  8  3  0  1  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 17. 30.  8.  0.  7.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 6. 6. 0. 6.] 
adversary cards in discard: [16. 11.  3.  6.  6.  0.  3.  0.  0.  3.  6.  3. 16. 11.  3.  6.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16] -> size -> 37 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  0.  0.] 
cards in discard: [ 1.  1. 11.  0.  0.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0 29  8  3  0  1  1] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 28. 30. 17. 30.  8.  0.  7.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 6. 6. 0. 6.] 
adversary cards in discard: [16. 11.  3.  6.  6.  0.  3.  0.  0.  3.  6.  3. 16. 11.  3.  6.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16] -> size -> 37 
adversary victory points: 2
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [3. 6. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[72.32473]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 0. 6.] 
cards in discard: [16. 11.  3.  6.  6.  0.  3.  0.  0.  3.  6.  3. 16. 11.  3.  6.  0. 16.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 17. 30.  8.  0.  7.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3.  3.  0. 11.] 
adversary cards in discard: [ 1.  1. 11.  0.  0.  0.  3.  3.  0. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0 29  8  3  0  1  1] -> size -> 24 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 103.50176239013672





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[64.27049 ]
 [73.731895]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 0. 6.] 
cards in discard: [16. 11.  3.  6.  6.  0.  3.  0.  0.  3.  6.  3. 16. 11.  3.  6.  0. 16.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 28. 30. 17. 30.  8.  0.  7.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3.  3.  0. 11.] 
adversary cards in discard: [ 1.  1. 11.  0.  0.  0.  3.  3.  0. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0 29  8  3  0  1  1] -> size -> 24 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 72.3247299194336



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3.  0. 11.] 
cards in discard: [ 1.  1. 11.  0.  0.  0.  3.  3.  0. 29.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0 29  8  3  0  1  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 17. 30.  8.  0.  7.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 6.  6.  3.  3. 11.] 
adversary cards in discard: [16. 11.  3.  6.  6.  0.  3.  0.  0.  3.  6.  3. 16. 11.  3.  6.  0. 16.
  3.  6.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16] -> size -> 37 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3.  0. 11.] 
cards in discard: [ 1.  1. 11.  0.  0.  0.  3.  3.  0. 29.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0 29  8  3  0  1  1] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 28. 30. 17. 30.  8.  0.  7.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 6.  6.  3.  3. 11.] 
adversary cards in discard: [16. 11.  3.  6.  6.  0.  3.  0.  0.  3.  6.  3. 16. 11.  3.  6.  0. 16.
  3.  6.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16] -> size -> 37 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3.  0. 11.] 
cards in discard: [ 1.  1. 11.  0.  0.  0.  3.  3.  0. 29.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0 29  8  3  0  1  1
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 17. 30.  8.  0.  7.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 6.  6.  3.  3. 11.] 
adversary cards in discard: [16. 11.  3.  6.  6.  0.  3.  0.  0.  3.  6.  3. 16. 11.  3.  6.  0. 16.
  3.  6.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16] -> size -> 37 
adversary victory points: 2
player victory points: 7 





Player: 0 
cards in hand: [ 6.  6.  3.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[72.30125]
 [76.08408]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  3.  3. 11.] 
cards in discard: [16. 11.  3.  6.  6.  0.  3.  0.  0.  3.  6.  3. 16. 11.  3.  6.  0. 16.
  3.  6.  6.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 17. 30.  8.  0.  7.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  8. 11.  0.  3.] 
adversary cards in discard: [ 1.  1. 11.  0.  0.  0.  3.  3.  0. 29.  0.  0.  0.  3.  3.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0 29  8  3  0  1  1
  0] -> size -> 25 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 73.73189544677734



action possibilites: [-1] 
expected returns: [[105.61671]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 3. 3.] 
cards in discard: [16. 11.  3.  6.  6.  0.  3.  0.  0.  3.  6.  3. 16. 11.  3.  6.  0. 16.
  3.  6.  6.  0.  6. 16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 17. 30.  8.  0.  6.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  8. 11.  0.  3.] 
adversary cards in discard: [ 1.  1. 11.  0.  0.  0.  3.  3.  0. 29.  0.  0.  0.  3.  3.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0 29  8  3  0  1  1
  0] -> size -> 25 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0  20   0   0   0   0  -3   0   0  16   0] 
sum of rewards: -20 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 74.78913116455078





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 94.79387]
 [106.31444]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3. 3.] 
cards in discard: [16. 11.  3.  6.  6.  0.  3.  0.  0.  3.  6.  3. 16. 11.  3.  6.  0. 16.
  3.  6.  6.  0.  6. 16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16] -> size -> 38 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 28. 30. 17. 30.  8.  0.  6.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  8. 11.  0.  3.] 
adversary cards in discard: [ 1.  1. 11.  0.  0.  0.  3.  3.  0. 29.  0.  0.  0.  3.  3.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0 29  8  3  0  1  1
  0] -> size -> 25 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1
Learning step: 0
desired expected reward: 105.61670684814453






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 3.  8. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 11.  0.  3.] 
cards in discard: [ 1.  1. 11.  0.  0.  0.  3.  3.  0. 29.  0.  0.  0.  3.  3.  3.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0 29  8  3  0  1  1
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 17. 30.  8.  0.  6.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  6.  3.  3.  3.] 
adversary cards in discard: [16. 11.  3.  6.  6.  0.  3.  0.  0.  3.  6.  3. 16. 11.  3.  6.  0. 16.
  3.  6.  6.  0.  6. 16. 11.  6.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16] -> size -> 38 
adversary victory points: 2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 3.] 
cards in discard: [ 1.  1. 11.  0.  0.  0.  3.  3.  0. 29.  0.  0.  0.  3.  3.  3.  0. 11.
  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0 29  8  3  0  1  1
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 17. 30.  8.  0.  6.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  6.  3.  3.  3.] 
adversary cards in discard: [16. 11.  3.  6.  6.  0.  3.  0.  0.  3.  6.  3. 16. 11.  3.  6.  0. 16.
  3.  6.  6.  0.  6. 16. 11.  6.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16] -> size -> 38 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 3.] 
cards in discard: [ 1.  1. 11.  0.  0.  0.  3.  3.  0. 29.  0.  0.  0.  3.  3.  3.  0. 11.
  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0 29  8  3  0  1  1
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 28. 30. 17. 30.  8.  0.  6.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  6.  3.  3.  3.] 
adversary cards in discard: [16. 11.  3.  6.  6.  0.  3.  0.  0.  3.  6.  3. 16. 11.  3.  6.  0. 16.
  3.  6.  6.  0.  6. 16. 11.  6.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16] -> size -> 38 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 3.] 
cards in discard: [ 1.  1. 11.  0.  0.  0.  3.  3.  0. 29.  0.  0.  0.  3.  3.  3.  0. 11.
  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0 29  8  3  0  1  1
  0  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 28. 30. 17. 30.  8.  0.  6.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  6.  3.  3.  3.] 
adversary cards in discard: [16. 11.  3.  6.  6.  0.  3.  0.  0.  3.  6.  3. 16. 11.  3.  6.  0. 16.
  3.  6.  6.  0.  6. 16. 11.  6.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16] -> size -> 38 
adversary victory points: 2
player victory points: 7 





Player: 0 
cards in hand: [11.  6.  3.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[93.21601]
 [97.25495]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  3.  3.  3.] 
cards in discard: [16. 11.  3.  6.  6.  0.  3.  0.  0.  3.  6.  3. 16. 11.  3.  6.  0. 16.
  3.  6.  6.  0.  6. 16. 11.  6.  6.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 17. 30.  8.  0.  6.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0 29  8  3  0  1  1
  0  0  0] -> size -> 27 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 106.31444549560547



action possibilites: [-1] 
expected returns: [[100.26447]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 3.] 
cards in discard: [16. 11.  3.  6.  6.  0.  3.  0.  0.  3.  6.  3. 16. 11.  3.  6.  0. 16.
  3.  6.  6.  0.  6. 16. 11.  6.  6.  3.  3. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 17. 30.  8.  0.  5.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0 29  8  3  0  1  1
  0  0  0] -> size -> 27 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0  20   0   0   0   0  -4   0   0  16   0] 
sum of rewards: -21 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 96.0533447265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 89.68345]
 [100.26448]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 3.] 
cards in discard: [16. 11.  3.  6.  6.  0.  3.  0.  0.  3.  6.  3. 16. 11.  3.  6.  0. 16.
  3.  6.  6.  0.  6. 16. 11.  6.  6.  3.  3. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16] -> size -> 39 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 28. 30. 17. 30.  8.  0.  5.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0 29  8  3  0  1  1
  0  0  0] -> size -> 27 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1
Learning step: 0
desired expected reward: 100.26447296142578






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [29.  0.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0 29  8  3  0  1  1
  0  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 17. 30.  8.  0.  5.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  3. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16] -> size -> 39 
adversary victory points: 2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0  8  3  0  1  1  0  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 17. 30.  8.  0.  5.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  3. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16] -> size -> 39 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0  8  3  0  1  1  0  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 28. 30. 17. 30.  8.  0.  5.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  3. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16] -> size -> 39 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0  8  3  0  1  1  0  0  0
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 17. 30.  8.  0.  5.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  3. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16] -> size -> 39 
adversary victory points: 2
player victory points: 7 





Player: 0 
cards in hand: [11.  3. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[121.50065]
 [125.7683 ]
 [125.7683 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 17. 30.  8.  0.  5.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0  8  3  0  1  1  0  0  0
  0] -> size -> 25 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 100.26447296142578



action possibilites: [-1] 
expected returns: [[92.50279]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.] 
cards in discard: [16.] 
cards in deck: 34 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 17. 30.  8.  0.  4.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0  8  3  0  1  1  0  0  0
  0] -> size -> 25 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0  20   0   0   0   0  -5   0   0  16   0] 
sum of rewards: -22 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 124.62944030761719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[82.3402  ]
 [95.58794 ]
 [83.980316]
 [92.9649  ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  0.] 
cards in discard: [16.] 
cards in deck: 34 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 28. 30. 17. 30.  8.  0.  4.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0  8  3  0  1  1  0  0  0
  0] -> size -> 25 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1
Learning step: 0
desired expected reward: 92.50279235839844



buy possibilites: [-1] 
expected returns: [[106.33642]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  0.] 
cards in discard: [16.  3.] 
cards in deck: 34 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 16. 30.  8.  0.  4.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0  8  3  0  1  1  0  0  0
  0] -> size -> 25 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0  20   0   0   0   0  -6   0   0   8   0] 
sum of rewards: -20 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 95.58792877197266






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 8. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0  8  3  0  1  1  0  0  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 16. 30.  8.  0.  4.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 16.  3.] 
adversary cards in discard: [16.  3. 11.  3. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3] -> size -> 41 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 8. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0  8  3  0  1  1  0  0  0
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 28. 30. 16. 30.  8.  0.  4.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 16.  3.] 
adversary cards in discard: [16.  3. 11.  3. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3] -> size -> 41 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 8. 0. 3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0  8  3  0  1  1  0  0  0
  0  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 28. 30. 15. 30.  8.  0.  4.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 16.  3.] 
adversary cards in discard: [16.  3. 11.  3. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3] -> size -> 41 
adversary victory points: 3
player victory points: 8 





Player: 0 
cards in hand: [ 0.  3.  3. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[55.824444]
 [45.97631 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 16.  3.] 
cards in discard: [16.  3. 11.  3. 11.  0.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 15. 30.  8.  0.  4.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 1. 0.] 
adversary cards in discard: [0. 8. 0. 3. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0  8  3  0  1  1  0  0  0
  0  3] -> size -> 26 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -52 

action type: buy - action -1
Learning step: 0
desired expected reward: 106.33641815185547





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[46.243984]
 [55.743332]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 16.  3.] 
cards in discard: [16.  3. 11.  3. 11.  0.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 30. 15. 30.  8.  0.  4.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 1. 0.] 
adversary cards in discard: [0. 8. 0. 3. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0  8  3  0  1  1  0  0  0
  0  3] -> size -> 26 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -52 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 55.82444763183594



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 1. 0.] 
cards in discard: [0. 8. 0. 3. 3. 0. 0. 0. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0  8  3  0  1  1  0  0  0
  0  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 15. 30.  8.  0.  4.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 6. 0. 3.] 
adversary cards in discard: [16.  3. 11.  3. 11.  0.  0.  0.  3.  3. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3] -> size -> 41 
adversary victory points: 3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 1. 0.] 
cards in discard: [0. 8. 0. 3. 3. 0. 0. 0. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0  8  3  0  1  1  0  0  0
  0  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 28. 30. 15. 30.  8.  0.  4.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 6. 0. 3.] 
adversary cards in discard: [16.  3. 11.  3. 11.  0.  0.  0.  3.  3. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3] -> size -> 41 
adversary victory points: 3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 1. 0.] 
cards in discard: [0. 8. 0. 3. 3. 0. 0. 0. 0. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0  8  3  0  1  1  0  0  0
  0  3  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 28. 30. 14. 30.  8.  0.  4.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 6. 0. 3.] 
adversary cards in discard: [16.  3. 11.  3. 11.  0.  0.  0.  3.  3. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3] -> size -> 41 
adversary victory points: 3
player victory points: 9 





Player: 0 
cards in hand: [0. 3. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[105.95237]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 0. 3.] 
cards in discard: [16.  3. 11.  3. 11.  0.  0.  0.  3.  3. 16.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 14. 30.  8.  0.  4.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 11.  3.] 
adversary cards in discard: [0. 8. 0. 3. 3. 0. 0. 0. 0. 3. 0. 3. 3. 1. 0.] 
adversary owned cards: [ 0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0  8  3  0  1  1  0  0  0
  0  3  3] -> size -> 27 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -62 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 55.74333190917969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 93.77616]
 [109.25535]
 [ 95.50409]
 [105.6286 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 3.] 
cards in discard: [16.  3. 11.  3. 11.  0.  0.  0.  3.  3. 16.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 28. 30. 14. 30.  8.  0.  4.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 11.  3.] 
adversary cards in discard: [0. 8. 0. 3. 3. 0. 0. 0. 0. 3. 0. 3. 3. 1. 0.] 
adversary owned cards: [ 0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0  8  3  0  1  1  0  0  0
  0  3  3] -> size -> 27 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -62 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 105.9523696899414



buy possibilites: [-1] 
expected returns: [[109.24294]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 3.] 
cards in discard: [16.  3. 11.  3. 11.  0.  0.  0.  3.  3. 16.  3.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3  3] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 13. 30.  8.  0.  4.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 11.  3.] 
adversary cards in discard: [0. 8. 0. 3. 3. 0. 0. 0. 0. 3. 0. 3. 3. 1. 0.] 
adversary owned cards: [ 0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0  8  3  0  1  1  0  0  0
  0  3  3] -> size -> 27 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -50   0   0   0   0   0   0   0  -7   0   0   8   0] 
sum of rewards: -50 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 109.2553482055664






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  3. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 11.  3.] 
cards in discard: [0. 8. 0. 3. 3. 0. 0. 0. 0. 3. 0. 3. 3. 1. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0  8  3  0  1  1  0  0  0
  0  3  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 13. 30.  8.  0.  4.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3. 16. 11.  6.] 
adversary cards in discard: [16.  3. 11.  3. 11.  0.  0.  0.  3.  3. 16.  3.  3.  0.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3  3] -> size -> 42 
adversary victory points: 4
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 11.  3.] 
cards in discard: [0. 8. 0. 3. 3. 0. 0. 0. 0. 3. 0. 3. 3. 1. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0  8  3  0  1  1  0  0  0
  0  3  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 30. 13. 30.  8.  0.  4.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3. 16. 11.  6.] 
adversary cards in discard: [16.  3. 11.  3. 11.  0.  0.  0.  3.  3. 16.  3.  3.  0.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3  3] -> size -> 42 
adversary victory points: 4
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 11.  3.] 
cards in discard: [0. 8. 0. 3. 3. 0. 0. 0. 0. 3. 0. 3. 3. 1. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0  8  3  0  1  1  0  0  0
  0  3  3  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 13. 30.  8.  0.  4.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3. 16. 11.  6.] 
adversary cards in discard: [16.  3. 11.  3. 11.  0.  0.  0.  3.  3. 16.  3.  3.  0.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3  3] -> size -> 42 
adversary victory points: 4
player victory points: 9 





Player: 0 
cards in hand: [ 3.  3. 16. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
expected returns: [[82.68455]
 [71.18285]
 [86.97181]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 16. 11.  6.] 
cards in discard: [16.  3. 11.  3. 11.  0.  0.  0.  3.  3. 16.  3.  3.  0.  3.  6.  0.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 13. 30.  8.  0.  4.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  8. 11.  0.] 
adversary cards in discard: [ 0.  8.  0.  3.  3.  0.  0.  0.  0.  3.  0.  3.  3.  1.  0.  0.  3.  0.
  3. 11.  3.] 
adversary owned cards: [ 0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0  8  3  0  1  1  0  0  0
  0  3  3  0] -> size -> 28 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -51 

action type: buy - action -1
Learning step: 0
desired expected reward: 109.2429428100586



action possibilites: [-1] 
expected returns: [[151.41283]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 16.  6.] 
cards in discard: [16.  3. 11.  3. 11.  0.  0.  0.  3.  3. 16.  3.  3.  0.  3.  6.  0.  3.
 16.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3  3 16] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 13. 30.  8.  0.  3.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  8. 11.  0.] 
adversary cards in discard: [ 0.  8.  0.  3.  3.  0.  0.  0.  0.  3.  0.  3.  3.  1.  0.  0.  3.  0.
  3. 11.  3.] 
adversary owned cards: [ 0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0  8  3  0  1  1  0  0  0
  0  3  3  0] -> size -> 28 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -50   0   0  20   0   0   0   0  -8   0   0  16   0] 
sum of rewards: -23 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 85.75183868408203





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[139.84737]
 [151.68883]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 16.  6.] 
cards in discard: [16.  3. 11.  3. 11.  0.  0.  0.  3.  3. 16.  3.  3.  0.  3.  6.  0.  3.
 16.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3  3 16] -> size -> 43 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 28. 30. 13. 30.  8.  0.  3.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  8. 11.  0.] 
adversary cards in discard: [ 0.  8.  0.  3.  3.  0.  0.  0.  0.  3.  0.  3.  3.  1.  0.  0.  3.  0.
  3. 11.  3.] 
adversary owned cards: [ 0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0  8  3  0  1  1  0  0  0
  0  3  3  0] -> size -> 28 
adversary victory points: 9
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -31 

action type: take_action - action -1
Learning step: 0
desired expected reward: 151.41282653808594






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  8. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8. 11.  0.] 
cards in discard: [ 0.  8.  0.  3.  3.  0.  0.  0.  0.  3.  0.  3.  3.  1.  0.  0.  3.  0.
  3. 11.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  0  3 11  0  0 11  3  8  3  0 11  0  8  3  0  1  1  0  0  0
  0  3  3  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 13. 30.  8.  0.  3.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 16.  3. 11.] 
adversary cards in discard: [16.  3. 11.  3. 11.  0.  0.  0.  3.  3. 16.  3.  3.  0.  3.  6.  0.  3.
 16. 11.  3.  3. 16.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3  3 16] -> size -> 43 
adversary victory points: 4
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 0.  8.  0.  3.  3.  0.  0.  0.  0.  3.  0.  3.  3.  1.  0.  0.  3.  0.
  3. 11.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3  0  3  0  0  3  8  3  0 11  0  8  3  0  1  1  0  0  0  0  3
  3  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 13. 30.  8.  0.  3.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 16.  3. 11.] 
adversary cards in discard: [16.  3. 11.  3. 11.  0.  0.  0.  3.  3. 16.  3.  3.  0.  3.  6.  0.  3.
 16. 11.  3.  3. 16.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3  3 16] -> size -> 43 
adversary victory points: 4
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 0.  8.  0.  3.  3.  0.  0.  0.  0.  3.  0.  3.  3.  1.  0.  0.  3.  0.
  3. 11.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3  0  3  0  0  3  8  3  0 11  0  8  3  0  1  1  0  0  0  0  3
  3  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 28. 30. 13. 30.  8.  0.  3.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 16.  3. 11.] 
adversary cards in discard: [16.  3. 11.  3. 11.  0.  0.  0.  3.  3. 16.  3.  3.  0.  3.  6.  0.  3.
 16. 11.  3.  3. 16.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3  3 16] -> size -> 43 
adversary victory points: 4
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 0.  8.  0.  3.  3.  0.  0.  0.  0.  3.  0.  3.  3.  1.  0.  0.  3.  0.
  3. 11.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3  0  3  0  0  3  8  3  0 11  0  8  3  0  1  1  0  0  0  0  3
  3  0  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 12. 30.  8.  0.  3.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 16.  3. 11.] 
adversary cards in discard: [16.  3. 11.  3. 11.  0.  0.  0.  3.  3. 16.  3.  3.  0.  3.  6.  0.  3.
 16. 11.  3.  3. 16.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3  3 16] -> size -> 43 
adversary victory points: 4
player victory points: 10 





Player: 0 
cards in hand: [ 3.  0. 16.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
expected returns: [[83.60539]
 [72.72213]
 [87.0543 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 16.  3. 11.] 
cards in discard: [16.  3. 11.  3. 11.  0.  0.  0.  3.  3. 16.  3.  3.  0.  3.  6.  0.  3.
 16. 11.  3.  3. 16.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3  3 16] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 12. 30.  8.  0.  3.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 8. 3. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  0  3  0  0  3  8  3  0 11  0  8  3  0  1  1  0  0  0  0  3
  3  0  3] -> size -> 27 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -61 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 151.68882751464844



action possibilites: [-1] 
expected returns: [[129.89151]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 16.  3.] 
cards in discard: [16.  3. 11.  3. 11.  0.  0.  0.  3.  3. 16.  3.  3.  0.  3.  6.  0.  3.
 16. 11.  3.  3. 16.  6. 16.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3  3 16 16] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 12. 30.  8.  0.  2.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 8. 3. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  0  3  0  0  3  8  3  0 11  0  8  3  0  1  1  0  0  0  0  3
  3  0  3] -> size -> 27 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -60   0   0  20   0   0   0   0  -9   0   0  16   0] 
sum of rewards: -34 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 85.71758270263672





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[118.93647]
 [129.89151]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 16.  3.] 
cards in discard: [16.  3. 11.  3. 11.  0.  0.  0.  3.  3. 16.  3.  3.  0.  3.  6.  0.  3.
 16. 11.  3.  3. 16.  6. 16.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3  3 16 16] -> size -> 44 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 28. 30. 12. 30.  8.  0.  2.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 8. 3. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  0  3  0  0  3  8  3  0 11  0  8  3  0  1  1  0  0  0  0  3
  3  0  3] -> size -> 27 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -41 

action type: take_action - action -1
Learning step: 0
desired expected reward: 129.89151000976562






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [3. 8. 3. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3. 3. 1.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  0  3  0  0  3  8  3  0 11  0  8  3  0  1  1  0  0  0  0  3
  3  0  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 12. 30.  8.  0.  2.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16.  3.  6.  6.  6.] 
adversary cards in discard: [16.  3. 11.  3. 11.  0.  0.  0.  3.  3. 16.  3.  3.  0.  3.  6.  0.  3.
 16. 11.  3.  3. 16.  6. 16. 11.  3.  0. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3  3 16 16] -> size -> 44 
adversary victory points: 4
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3. 3. 1.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  0  3  0  0  3  8  3  0 11  0  8  3  0  1  1  0  0  0  0  3
  3  0  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 28. 30. 12. 30.  8.  0.  2.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16.  3.  6.  6.  6.] 
adversary cards in discard: [16.  3. 11.  3. 11.  0.  0.  0.  3.  3. 16.  3.  3.  0.  3.  6.  0.  3.
 16. 11.  3.  3. 16.  6. 16. 11.  3.  0. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3  3 16 16] -> size -> 44 
adversary victory points: 4
player victory points: 10 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [16.  3.  6.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[54.80535]
 [44.89029]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  6.  6.  6.] 
cards in discard: [16.  3. 11.  3. 11.  0.  0.  0.  3.  3. 16.  3.  3.  0.  3.  6.  0.  3.
 16. 11.  3.  3. 16.  6. 16. 11.  3.  0. 16.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3  3 16 16] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 12. 30.  8.  0.  2.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 1.  3.  3.  0. 11.] 
adversary cards in discard: [3. 8. 3. 3. 1.] 
adversary owned cards: [ 0  3  3  3  0  3  0  0  3  8  3  0 11  0  8  3  0  1  1  0  0  0  0  3
  3  0  3] -> size -> 27 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -61 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 129.89151000976562





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[45.25718]
 [54.80535]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  6.  6.  6.] 
cards in discard: [16.  3. 11.  3. 11.  0.  0.  0.  3.  3. 16.  3.  3.  0.  3.  6.  0.  3.
 16. 11.  3.  3. 16.  6. 16. 11.  3.  0. 16.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3  3 16 16] -> size -> 44 
action values: 1 
buys: 1 
player value: 0 
card supply: [19. 28. 30. 12. 30.  8.  0.  2.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 1.  3.  3.  0. 11.] 
adversary cards in discard: [3. 8. 3. 3. 1.] 
adversary owned cards: [ 0  3  3  3  0  3  0  0  3  8  3  0 11  0  8  3  0  1  1  0  0  0  0  3
  3  0  3] -> size -> 27 
adversary victory points: 10
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -61 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 54.80535125732422



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 1.  3.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  3.  0. 11.] 
cards in discard: [3. 8. 3. 3. 1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  0  3  0  0  3  8  3  0 11  0  8  3  0  1  1  0  0  0  0  3
  3  0  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 12. 30.  8.  0.  2.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 6.  0.  6. 11.  3.] 
adversary cards in discard: [16.  3. 11.  3. 11.  0.  0.  0.  3.  3. 16.  3.  3.  0.  3.  6.  0.  3.
 16. 11.  3.  3. 16.  6. 16. 11.  3.  0. 16.  3. 16.  3.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3  3 16 16] -> size -> 44 
adversary victory points: 4
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  3.  0. 11.] 
cards in discard: [3. 8. 3. 3. 1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  0  3  0  0  3  8  3  0 11  0  8  3  0  1  1  0  0  0  0  3
  3  0  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 28. 30. 12. 30.  8.  0.  2.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 6.  0.  6. 11.  3.] 
adversary cards in discard: [16.  3. 11.  3. 11.  0.  0.  0.  3.  3. 16.  3.  3.  0.  3.  6.  0.  3.
 16. 11.  3.  3. 16.  6. 16. 11.  3.  0. 16.  3. 16.  3.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3  3 16 16] -> size -> 44 
adversary victory points: 4
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  3.  0. 11.] 
cards in discard: [3. 8. 3. 3. 1. 3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  0  3  0  0  3  8  3  0 11  0  8  3  0  1  1  0  0  0  0  3
  3  0  3  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 11. 30.  8.  0.  2.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 6.  0.  6. 11.  3.] 
adversary cards in discard: [16.  3. 11.  3. 11.  0.  0.  0.  3.  3. 16.  3.  3.  0.  3.  6.  0.  3.
 16. 11.  3.  3. 16.  6. 16. 11.  3.  0. 16.  3. 16.  3.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3  3 16 16] -> size -> 44 
adversary victory points: 4
player victory points: 11 





Player: 0 
cards in hand: [ 6.  0.  6. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[65.62282]
 [70.08739]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  6. 11.  3.] 
cards in discard: [16.  3. 11.  3. 11.  0.  0.  0.  3.  3. 16.  3.  3.  0.  3.  6.  0.  3.
 16. 11.  3.  3. 16.  6. 16. 11.  3.  0. 16.  3. 16.  3.  6.  6.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3  3 16 16] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 11. 30.  8.  0.  2.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 3.  8.  3.  3.  1.  3.  1.  3.  3.  0. 11.] 
adversary owned cards: [ 0  3  3  3  0  3  0  0  3  8  3  0 11  0  8  3  0  1  1  0  0  0  0  3
  3  0  3  3] -> size -> 28 
adversary victory points: 11
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -71 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 54.80535125732422



action possibilites: [-1] 
expected returns: [[116.21035]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 3.] 
cards in discard: [16.  3. 11.  3. 11.  0.  0.  0.  3.  3. 16.  3.  3.  0.  3.  6.  0.  3.
 16. 11.  3.  3. 16.  6. 16. 11.  3.  0. 16.  3. 16.  3.  6.  6.  6. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3  3 16 16 16] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 11. 30.  8.  0.  1.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 3.  8.  3.  3.  1.  3.  1.  3.  3.  0. 11.] 
adversary owned cards: [ 0  3  3  3  0  3  0  0  3  8  3  0 11  0  8  3  0  1  1  0  0  0  0  3
  3  0  3  3] -> size -> 28 
adversary victory points: 11
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -70   0   0  20   0   0   0   0 -10   0   0  16   0] 
sum of rewards: -45 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 68.82987213134766





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[104.08275]
 [116.21034]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 3.] 
cards in discard: [16.  3. 11.  3. 11.  0.  0.  0.  3.  3. 16.  3.  3.  0.  3.  6.  0.  3.
 16. 11.  3.  3. 16.  6. 16. 11.  3.  0. 16.  3. 16.  3.  6.  6.  6. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3  3 16 16 16] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 28. 30. 11. 30.  8.  0.  1.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 3.  8.  3.  3.  1.  3.  1.  3.  3.  0. 11.] 
adversary owned cards: [ 0  3  3  3  0  3  0  0  3  8  3  0 11  0  8  3  0  1  1  0  0  0  0  3
  3  0  3  3] -> size -> 28 
adversary victory points: 11
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -51 

action type: take_action - action -1
Learning step: 0
desired expected reward: 116.2103500366211






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 3.  8.  3.  3.  1.  3.  1.  3.  3.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  0  3  0  0  3  8  3  0 11  0  8  3  0  1  1  0  0  0  0  3
  3  0  3  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 11. 30.  8.  0.  1.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 16.  6.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3  3 16 16 16] -> size -> 45 
adversary victory points: 4
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 3.  8.  3.  3.  1.  3.  1.  3.  3.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  0  3  0  0  3  8  3  0 11  0  8  3  0  1  1  0  0  0  0  3
  3  0  3  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 28. 30. 11. 30.  8.  0.  1.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 16.  6.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3  3 16 16 16] -> size -> 45 
adversary victory points: 4
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 3.  8.  3.  3.  1.  3.  1.  3.  3.  0. 11.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  0  3  0  0  3  8  3  0 11  0  8  3  0  1  1  0  0  0  0  3
  3  0  3  3  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 10. 30.  8.  0.  1.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 16.  6.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3  3 16 16 16] -> size -> 45 
adversary victory points: 4
player victory points: 12 





Player: 0 
cards in hand: [ 3. 16.  6.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[108.62658]
 [ 97.05404]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  6.  6.  6.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3  3 16 16 16] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 10. 30.  8.  0.  1.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 3.  8.  3.  3.  1.  3.  1.  3.  3.  0. 11.  3.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  3  3  3  0  3  0  0  3  8  3  0 11  0  8  3  0  1  1  0  0  0  0  3
  3  0  3  3  3] -> size -> 29 
adversary victory points: 12
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -81 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 116.2103500366211





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 97.40699]
 [108.50167]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  6.  6.  6.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3  3 16 16 16] -> size -> 45 
action values: 1 
buys: 1 
player value: 0 
card supply: [19. 28. 30. 10. 30.  8.  0.  1.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 3.  8.  3.  3.  1.  3.  1.  3.  3.  0. 11.  3.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  3  3  3  0  3  0  0  3  8  3  0 11  0  8  3  0  1  1  0  0  0  0  3
  3  0  3  3  3] -> size -> 29 
adversary victory points: 12
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -81 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 108.62657165527344



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 3.  8.  3.  3.  1.  3.  1.  3.  3.  0. 11.  3.  0.  0.  3.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  0  3  0  0  3  8  3  0 11  0  8  3  0  1  1  0  0  0  0  3
  3  0  3  3  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 10. 30.  8.  0.  1.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  3. 11. 16.] 
adversary cards in discard: [ 3. 16.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3  3 16 16 16] -> size -> 45 
adversary victory points: 4
player victory points: 12 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 3.  8.  3.  3.  1.  3.  1.  3.  3.  0. 11.  3.  0.  0.  3.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  0  3  0  0  3  8  3  0 11  0  8  3  0  1  1  0  0  0  0  3
  3  0  3  3  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 28. 30. 10. 30.  8.  0.  1.  2.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  3. 11. 16.] 
adversary cards in discard: [ 3. 16.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3  3 16 16 16] -> size -> 45 
adversary victory points: 4
player victory points: 12 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 3.  8.  3.  3.  1.  3.  1.  3.  3.  0. 11.  3.  0.  0.  3.  0.  3. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  0  3  0  0  3  8  3  0 11  0  8  3  0  1  1  0  0  0  0  3
  3  0  3  3  3 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 10. 30.  8.  0.  1.  1.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  3. 11. 16.] 
adversary cards in discard: [ 3. 16.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3  3 16 16 16] -> size -> 45 
adversary victory points: 4
player victory points: 12 





Player: 0 
cards in hand: [ 0. 11.  3. 11. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 16.] 
expected returns: [[104.754364]
 [109.63055 ]
 [109.63055 ]
 [ 92.52445 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3. 11. 16.] 
cards in discard: [ 3. 16.  6.  6.  6.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3  3 16 16 16] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 10. 30.  8.  0.  1.  1.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 3.  8.  3.  3.  1.  3.  1.  3.  3.  0. 11.  3.  0.  0.  3.  0.  3. 11.
  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  3  3  3  0  3  0  0  3  8  3  0 11  0  8  3  0  1  1  0  0  0  0  3
  3  0  3  3  3 11] -> size -> 30 
adversary victory points: 12
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -81 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 108.50167083740234



action possibilites: [-1] 
expected returns: [[100.775955]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11. 16.] 
cards in discard: [ 3. 16.  6.  6.  6. 16.] 
cards in deck: 35 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3  3 16 16 16 16] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 10. 30.  8.  0.  0.  1.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 3.  8.  3.  3.  1.  3.  1.  3.  3.  0. 11.  3.  0.  0.  3.  0.  3. 11.
  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  3  3  3  0  3  0  0  3  8  3  0 11  0  8  3  0  1  1  0  0  0  0  3
  3  0  3  3  3 11] -> size -> 30 
adversary victory points: 12
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -80   0   0  20   0   0   0   0 -11   0   0  16   0] 
sum of rewards: -56 

action type: gain_card_n - action 3
Learning step: 0
desired expected reward: 108.52486419677734





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 91.654594]
 [101.44576 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11. 16.] 
cards in discard: [ 3. 16.  6.  6.  6. 16.] 
cards in deck: 35 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3  3 16 16 16 16] -> size -> 46 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 28. 30. 10. 30.  8.  0.  0.  1.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 3.  8.  3.  3.  1.  3.  1.  3.  3.  0. 11.  3.  0.  0.  3.  0.  3. 11.
  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  3  3  3  0  3  0  0  3  8  3  0 11  0  8  3  0  1  1  0  0  0  0  3
  3  0  3  3  3 11] -> size -> 30 
adversary victory points: 12
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -61 

action type: take_action - action -1
Learning step: 0
desired expected reward: 100.77595520019531






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 3.  8.  3.  3.  1.  3.  1.  3.  3.  0. 11.  3.  0.  0.  3.  0.  3. 11.
  3.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  0  3  0  0  3  8  3  0 11  0  8  3  0  1  1  0  0  0  0  3
  3  0  3  3  3 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 10. 30.  8.  0.  0.  1.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 6. 11. 16.  3.  0.] 
adversary cards in discard: [ 3. 16.  6.  6.  6. 16. 11.  0.  3. 11. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3  3 16 16 16 16] -> size -> 46 
adversary victory points: 4
player victory points: 12 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 3.  8.  3.  3.  1.  3.  1.  3.  3.  0. 11.  3.  0.  0.  3.  0.  3. 11.
  3.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  0  3  0  0  3  8  3  0 11  0  8  3  0  1  1  0  0  0  0  3
  3  0  3  3  3 11] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 28. 30. 10. 30.  8.  0.  0.  1.  5. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 6. 11. 16.  3.  0.] 
adversary cards in discard: [ 3. 16.  6.  6.  6. 16. 11.  0.  3. 11. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3  3 16 16 16 16] -> size -> 46 
adversary victory points: 4
player victory points: 12 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 3.  8.  3.  3.  1.  3.  1.  3.  3.  0. 11.  3.  0.  0.  3.  0.  3. 11.
  3.  0.  0.  0.  3. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  0  3  0  0  3  8  3  0 11  0  8  3  0  1  1  0  0  0  0  3
  3  0  3  3  3 11 14] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 10. 30.  8.  0.  0.  1.  5. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 6. 11. 16.  3.  0.] 
adversary cards in discard: [ 3. 16.  6.  6.  6. 16. 11.  0.  3. 11. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3  3 16 16 16 16] -> size -> 46 
adversary victory points: 4
player victory points: 12 





Player: 0 
cards in hand: [ 6. 11. 16.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
expected returns: [[105.48319 ]
 [110.137184]
 [ 94.2569  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11. 16.  3.  0.] 
cards in discard: [ 3. 16.  6.  6.  6. 16. 11.  0.  3. 11. 16.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3  3 16 16 16 16] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 10. 30.  8.  0.  0.  1.  5. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  0  3  0  0  3  8  3  0 11  0  8  3  0  1  1  0  0  0  0  3
  3  0  3  3  3 11 14] -> size -> 31 
adversary victory points: 12
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -81 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 101.44577026367188



Player 1 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 11 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 5 
Chapel: 0 
Witch: 0 
Poacher: 0 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 6. 16.  3.  0.] 
cards in discard: [ 3. 16.  6.  6.  6. 16. 11.  0.  3. 11. 16. 11.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 11  6  3 11  6  3  3  6 11  6  3  6 11
  6  3  6  6  3  3  6  6 16  3 16  3 16 16 16 16  3  3 16 16 16 16 11] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 10. 30.  8.  0.  0.  0.  5. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  0  3  0  0  3  8  3  0 11  0  8  3  0  1  1  0  0  0  0  3
  3  0  3  3  3 11 14] -> size -> 31 
adversary victory points: 12
player victory points: 4 

Reward from previous game state: 
[  -5 -500    4  -80    0    0   20    0    0    0    0  -12    0    0
    9    0] 
sum of rewards: -564 

action type: gain_card_n - action 3
Learning step: -67.32112121582031
desired expected reward: 41.890052795410156



