 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[82.149925]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -150        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000155 

action type: buy - action 0.0
Learning step: -120004.234375
desired expected reward: -120053.2734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[69.850876]
 [77.80753 ]
 [48.477806]
 [81.46123 ]
 [82.88534 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 84.8942642211914



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[89.40329]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [3. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 82.88533020019531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 77.8709  ]
 [ 95.30024 ]
 [ 86.14901 ]
 [ 64.381996]
 [ 56.414387]
 [ 90.393875]
 [ 98.70111 ]
 [ 89.94929 ]
 [124.26165 ]
 [107.20243 ]
 [ 67.39383 ]
 [ 84.68919 ]
 [ 81.025894]
 [ 67.816475]
 [ 84.2446  ]
 [ 91.48302 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [3. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 91.89244842529297



buy possibilites: [-1] 
expected returns: [[88.94126]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0.  3.  0.  3.  3. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [3. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0 250   0] 
sum of rewards: 215 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 124.26163482666016






Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [3. 0. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [3. 0. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [3. 0. 0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[84.788826]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 88.9412612915039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 69.53198 ]
 [ 88.19164 ]
 [ 78.419586]
 [ 46.702282]
 [ 82.99742 ]
 [ 91.73265 ]
 [ 82.52523 ]
 [100.08149 ]
 [ 58.469517]
 [ 72.881546]
 [ 76.36802 ]
 [ 84.1875  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 86.03233337402344



buy possibilites: [-1] 
expected returns: [[85.241035]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 93 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 100.08147430419922






Player: 1 
cards in hand: [3. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  3. 25.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  3. 25.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  3. 25.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[ 89.44661]
 [122.21386]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  3. 25.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 85.24103546142578



action possibilites: [-1] 
expected returns: [[81.065994]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 3. 0. 3. 6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0 6] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 124.00678253173828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[68.91626 ]
 [83.99937 ]
 [76.094376]
 [49.779778]
 [79.79229 ]
 [86.88602 ]
 [79.39548 ]
 [93.831314]
 [59.535564]
 [71.648155]
 [74.4366  ]
 [80.649536]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 29. 30.  8.  9. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 3. 0. 3. 6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0 6] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 81.06599426269531



buy possibilites: [-1] 
expected returns: [[62.96607]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9. 10. 10. 10.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 3. 0. 3. 6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0 6] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 113 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 93.83130645751953






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 3. 0. 3. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0 6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9. 10. 10. 10.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [29. 25.  0.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 0. 3. 0. 3. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 0 6] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 30. 30. 29. 30.  8.  9. 10. 10. 10.  9.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [29. 25.  0.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0.  3.  0.  3.  0.  3.  6. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8.  9. 10. 10. 10.  9.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [29. 25.  0.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [29.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[116.49659]
 [130.20905]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  0.  0.] 
cards in discard: [29. 25.  0.  0.  3.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9. 10. 10. 10.  9.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 62.966068267822266



action possibilites: [-1. 25.] 
expected returns: [[ 89.19954]
 [116.03943]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8.  9. 10. 10. 10.  9.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 131.34011840820312



action possibilites: [-1] 
expected returns: [[86.23464]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8.  8. 10. 10. 10.  9.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 116.03943634033203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 80.81528 ]
 [ 95.00423 ]
 [ 73.6064  ]
 [ 87.65171 ]
 [ 69.77075 ]
 [ 63.00886 ]
 [ 91.13203 ]
 [ 97.61775 ]
 [ 90.7813  ]
 [115.784546]
 [103.87048 ]
 [ 72.17259 ]
 [ 86.44464 ]
 [ 83.428795]
 [ 72.49762 ]
 [ 86.09391 ]
 [ 92.09016 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29] -> size -> 13 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 30. 30. 29. 30.  8.  8. 10. 10. 10.  9.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 86.2346420288086



buy possibilites: [-1] 
expected returns: [[97.47727]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8.  8. 10. 10. 10.  8.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 97.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 115.78450775146484






Player: 1 
cards in hand: [3. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  8. 10. 10. 10.  8.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3. 29.  0.  3.] 
adversary cards in discard: [25. 29. 25.  3.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25] -> size -> 14 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8.  8. 10. 10. 10.  8.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3. 29.  0.  3.] 
adversary cards in discard: [25. 29. 25.  3.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25] -> size -> 14 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [6. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  8. 10. 10. 10.  8.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3. 29.  0.  3.] 
adversary cards in discard: [25. 29. 25.  3.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25] -> size -> 14 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 97.3209 ]
 [111.27102]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  0.  3.] 
cards in discard: [25. 29. 25.  3.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  8. 10. 10. 10.  8.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [6. 3. 3. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 97.4772720336914



action possibilites: [-1. 25.] 
expected returns: [[ 82.51066]
 [108.6395 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  3. 25.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8.  8. 10. 10. 10.  8.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [6. 3. 3. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 109.79047393798828



action possibilites: [-1] 
expected returns: [[77.76516]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8.  7. 10. 10. 10.  8.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [6. 3. 3. 3. 0. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 108.6395034790039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 73.526054]
 [ 86.85804 ]
 [ 79.94868 ]
 [ 64.928375]
 [ 59.598225]
 [ 83.221275]
 [ 89.31263 ]
 [ 82.890015]
 [106.00744 ]
 [ 95.08816 ]
 [ 66.87783 ]
 [ 78.81485 ]
 [ 75.98065 ]
 [ 67.13619 ]
 [ 78.483574]
 [ 84.11086 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 30. 30. 28. 30.  8.  7. 10. 10. 10.  8.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [6. 3. 3. 3. 0. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 77.7651596069336



buy possibilites: [-1] 
expected returns: [[114.58821]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0. 0.] 
cards in discard: [25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  7. 10. 10. 10.  7.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [6. 3. 3. 3. 0. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 285 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 106.0074234008789






Player: 1 
cards in hand: [0. 0. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [6. 3. 3. 3. 0. 0. 3. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  7. 10. 10. 10.  7.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3. 29.  0.  0.] 
adversary cards in discard: [25. 29. 25.  0.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25] -> size -> 15 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [6. 3. 3. 3. 0. 0. 3. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 28. 30.  8.  7. 10. 10. 10.  7.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3. 29.  0.  0.] 
adversary cards in discard: [25. 29. 25.  0.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25] -> size -> 15 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 96.738304]
 [110.87778 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  0.  0.] 
cards in discard: [25. 29. 25.  0.  3.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  7. 10. 10. 10.  7.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [15.  3.  0.  0.  0.] 
adversary cards in discard: [6. 3. 3. 3. 0. 0. 3. 6. 0. 0. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 114.58821105957031



action possibilites: [-1. 25.] 
expected returns: [[118.641  ]
 [149.30228]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 25.] 
cards in discard: [25. 29. 25.  0.  3.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8.  7. 10. 10. 10.  7.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [15.  3.  0.  0.  0.] 
adversary cards in discard: [6. 3. 3. 3. 0. 0. 3. 6. 0. 0. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 108.58956146240234



action possibilites: [-1] 
expected returns: [[92.01415]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8.  6. 10. 10. 10.  7.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [15.  3.  0.  0.  0.] 
adversary cards in discard: [6. 3. 3. 3. 0. 0. 3. 6. 0. 0. 0. 0. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6] -> size -> 19 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 149.30227661132812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 88.09389 ]
 [ 99.33015 ]
 [ 93.510475]
 [ 78.97195 ]
 [ 73.152275]
 [ 96.26153 ]
 [101.40464 ]
 [ 95.98805 ]
 [116.16982 ]
 [106.314224]
 [ 81.04644 ]
 [ 92.55619 ]
 [ 90.168365]
 [ 81.31992 ]
 [ 92.282715]
 [ 97.048386]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 30. 30. 28. 30.  8.  6. 10. 10. 10.  7.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [15.  3.  0.  0.  0.] 
adversary cards in discard: [6. 3. 3. 3. 0. 0. 3. 6. 0. 0. 0. 0. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6] -> size -> 19 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 92.01415252685547



buy possibilites: [-1] 
expected returns: [[129.29385]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3. 0.] 
cards in discard: [25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  6. 10. 10. 10.  6.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [15.  3.  0.  0.  0.] 
adversary cards in discard: [6. 3. 3. 3. 0. 0. 3. 6. 0. 0. 0. 0. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6] -> size -> 19 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 315 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 116.16979217529297






Player: 1 
cards in hand: [15.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0.  0.  0.] 
cards in discard: [6. 3. 3. 3. 0. 0. 3. 6. 0. 0. 0. 0. 6. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  6. 10. 10. 10.  6.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [29. 25.  0.  0.  3.] 
adversary cards in discard: [25. 29. 25.  0.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25] -> size -> 16 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  0.  0.  0.] 
cards in discard: [6. 3. 3. 3. 0. 0. 3. 6. 0. 0. 0. 0. 6. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 28. 30.  8.  6. 10. 10. 10.  6.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [29. 25.  0.  0.  3.] 
adversary cards in discard: [25. 29. 25.  0.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25] -> size -> 16 
adversary victory points: 3
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [29. 25.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[116.50938]
 [128.15915]
 [139.71597]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  0.  0.  3.] 
cards in discard: [25. 29. 25.  0.  3.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  6. 10. 10. 10.  6.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 6. 0. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6] -> size -> 19 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 129.29385375976562



action possibilites: [-1] 
expected returns: [[134.89062]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  3. 25.  0.] 
cards in discard: [25. 29. 25.  0.  3.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  5. 10. 10. 10.  6.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 6. 0. 6. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6] -> size -> 20 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 136.3123016357422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[129.93114 ]
 [143.34113 ]
 [136.38585 ]
 [113.556915]
 [145.96951 ]
 [139.33763 ]
 [132.40486 ]
 [140.61365 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  3. 25.  0.] 
cards in discard: [25. 29. 25.  0.  3.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 28. 30.  8.  5. 10. 10. 10.  6.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 6. 0. 6. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6] -> size -> 20 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 134.890625



buy possibilites: [-1] 
expected returns: [[140.14503]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  3. 25.  0.] 
cards in discard: [25. 29. 25.  0.  3.  0.  0.  3.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  5. 10.  9. 10.  6.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 6. 0. 6. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6] -> size -> 20 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 129 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 145.96951293945312






Player: 1 
cards in hand: [3. 6. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 6. 3.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  5. 10.  9. 10.  6.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [29.  0. 11. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11] -> size -> 17 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 6. 3.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8.  5. 10.  9. 10.  6.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [29.  0. 11. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11] -> size -> 17 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [29.  0. 11. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 25.] 
expected returns: [[42.49891 ]
 [52.96531 ]
 [47.431797]
 [63.33952 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 11. 25.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  5. 10.  9. 10.  6.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [6. 3. 6. 0. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6] -> size -> 20 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 140.14503479003906



action possibilites: [-1] 
expected returns: [[76.551704]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 11.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  4. 10.  9. 10.  6.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [6. 3. 6. 0. 6. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6] -> size -> 21 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 61.91347122192383





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[71.03488 ]
 [82.14279 ]
 [76.393875]
 [56.27229 ]
 [84.19935 ]
 [78.84036 ]
 [73.09147 ]
 [79.927505]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 11.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 28. 30.  8.  4. 10.  9. 10.  6.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [6. 3. 6. 0. 6. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6] -> size -> 21 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 76.55170440673828



buy possibilites: [-1] 
expected returns: [[102.24636]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 11.  0.  3.  0.] 
cards in discard: [11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  4. 10.  8. 10.  6.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [6. 3. 6. 0. 6. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6] -> size -> 21 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 159 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 84.19933319091797






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [6. 3. 6. 0. 6. 3. 6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  4. 10.  8. 10.  6.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [25. 29.  0. 25.  3.] 
adversary cards in discard: [11. 25. 29.  0. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11] -> size -> 18 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [6. 3. 6. 0. 6. 3. 6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 30. 30. 28. 30.  8.  4. 10.  8. 10.  6.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [25. 29.  0. 25.  3.] 
adversary cards in discard: [11. 25. 29.  0. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11] -> size -> 18 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [6. 3. 6. 0. 6. 3. 6. 4.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 29.  8.  4. 10.  8. 10.  6.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [25. 29.  0. 25.  3.] 
adversary cards in discard: [11. 25. 29.  0. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11] -> size -> 18 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [25. 29.  0. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25.] 
expected returns: [[76.81379]
 [96.17192]
 [86.36611]
 [96.17192]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29.  0. 25.  3.] 
cards in discard: [11. 25. 29.  0. 11.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 29.  8.  4. 10.  8. 10.  6.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 15.  3.  6.  6.] 
adversary cards in discard: [6. 3. 6. 0. 6. 3. 6. 4. 0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 102.2463607788086



action possibilites: [-1] 
expected returns: [[96.473495]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 25.  3.  0.  3.] 
cards in discard: [11. 25. 29.  0. 11.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 29.  8.  3. 10.  8. 10.  6.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 15.  3.  6.  6.] 
adversary cards in discard: [6. 3. 6. 0. 6. 3. 6. 4. 0. 0. 0. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 91.32440948486328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[87.97576 ]
 [94.63137 ]
 [71.104195]
 [97.704666]
 [99.03186 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 25.  3.  0.  3.] 
cards in discard: [11. 25. 29.  0. 11.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 28. 29.  8.  3. 10.  8. 10.  6.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 15.  3.  6.  6.] 
adversary cards in discard: [6. 3. 6. 0. 6. 3. 6. 4. 0. 0. 0. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 96.47349548339844






Player: 1 
cards in hand: [ 3. 15.  3.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  3.  6.  6.] 
cards in discard: [6. 3. 6. 0. 6. 3. 6. 4. 0. 0. 0. 0. 0. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 29.  8.  3. 10.  8. 10.  6.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [29.  0. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11] -> size -> 18 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  3.  6.  6.] 
cards in discard: [6. 3. 6. 0. 6. 3. 6. 4. 0. 0. 0. 0. 0. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6] -> size -> 23 
action values: 1 
buys: 1 
player value: 0 
card supply: [28. 30. 30. 28. 29.  8.  3. 10.  8. 10.  6.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [29.  0. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11] -> size -> 18 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  3.  6.  6.] 
cards in discard: [6. 3. 6. 0. 6. 3. 6. 4. 0. 0. 0. 0. 0. 6. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 29.  8.  3. 10.  8. 10.  6.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [29.  0. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11] -> size -> 18 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [29.  0. 25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[32.18542 ]
 [40.11027 ]
 [49.341278]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 25.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 29.  8.  3. 10.  8. 10.  6.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0] -> size -> 24 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 99.03186798095703



action possibilites: [-1] 
expected returns: [[64.79017]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0. 25.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 29.  8.  2. 10.  8. 10.  6.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6] -> size -> 25 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 47.77949905395508





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[60.12617 ]
 [70.26436 ]
 [65.01544 ]
 [46.647915]
 [67.49144 ]
 [72.139046]
 [67.24979 ]
 [76.64832 ]
 [53.77154 ]
 [62.000866]
 [63.909733]
 [68.223755]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  0. 25.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 28. 29.  8.  2. 10.  8. 10.  6.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6] -> size -> 25 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 64.79016876220703



buy possibilites: [-1] 
expected returns: [[105.446754]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  0. 25.  0.] 
cards in discard: [29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 29.  8.  2. 10.  8. 10.  6.  7. 10. 10. 10. 10.  9.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6] -> size -> 25 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 203 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 76.6483154296875






Player: 1 
cards in hand: [6. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 29.  8.  2. 10.  8. 10.  6.  7. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29.  0. 25.  3.] 
adversary cards in discard: [29. 25. 29.  0.  0.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29] -> size -> 19 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 28. 29.  8.  2. 10.  8. 10.  6.  7. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29.  0. 25.  3.] 
adversary cards in discard: [29. 25. 29.  0.  0.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29] -> size -> 19 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [ 6. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 29.  8.  2. 10.  7. 10.  6.  7. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29.  0. 25.  3.] 
adversary cards in discard: [29. 25. 29.  0.  0.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29] -> size -> 19 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[57.3112  ]
 [65.596275]
 [73.92445 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 25.  3.] 
cards in discard: [29. 25. 29.  0.  0.  0. 25.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 29.  8.  2. 10.  7. 10.  6.  7. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  6. 15.  6.] 
adversary cards in discard: [ 6. 11.  6.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11] -> size -> 26 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 105.4467544555664



action possibilites: [-1] 
expected returns: [[78.891975]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  3.  3. 25.] 
cards in discard: [29. 25. 29.  0.  0.  0. 25.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 29.  8.  1. 10.  7. 10.  6.  7. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  6. 15.  6.] 
adversary cards in discard: [ 6. 11.  6.  0.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6] -> size -> 27 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 71.14188385009766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[68.39782 ]
 [73.30574 ]
 [56.531303]
 [75.60287 ]
 [76.55266 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  3.  3. 25.] 
cards in discard: [29. 25. 29.  0.  0.  0. 25.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 28. 29.  8.  1. 10.  7. 10.  6.  7. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  6. 15.  6.] 
adversary cards in discard: [ 6. 11.  6.  0.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6] -> size -> 27 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 78.89197540283203






Player: 1 
cards in hand: [ 0.  3.  6. 15.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  6. 15.  6.] 
cards in discard: [ 6. 11.  6.  0.  3.  0.  0.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 29.  8.  1. 10.  7. 10.  6.  7. 10. 10. 10. 10.  9.] 
adversary cards in hand: [25. 11. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29] -> size -> 19 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  6. 15.  6.] 
cards in discard: [ 6. 11.  6.  0.  3.  0.  0.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 28. 29.  8.  1. 10.  7. 10.  6.  7. 10. 10. 10. 10.  9.] 
adversary cards in hand: [25. 11. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29] -> size -> 19 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  6. 15.  6.] 
cards in discard: [ 6. 11.  6.  0.  3.  0.  0.  6.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 28. 29.  8.  1. 10.  7. 10.  6.  7. 10. 10. 10. 10.  9.] 
adversary cards in hand: [25. 11. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29] -> size -> 19 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [25. 11. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 11.] 
expected returns: [[28.235018]
 [41.548473]
 [31.415827]
 [31.415827]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 29.  8.  1. 10.  7. 10.  6.  7. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 6. 0. 3.] 
adversary cards in discard: [ 6. 11.  6.  0.  3.  0.  0.  6.  0.  0.  3.  6. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0] -> size -> 28 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 76.55265808105469



action possibilites: [-1] 
expected returns: [[68.77834]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  3.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 29.  8.  0. 10.  7. 10.  6.  7. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 6. 0. 3.] 
adversary cards in discard: [ 6. 11.  6.  0.  3.  0.  0.  6.  0.  0.  3.  6. 15.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 39.216026306152344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[59.232487]
 [63.713207]
 [65.762505]
 [66.64561 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  3.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 28. 29.  8.  0. 10.  7. 10.  6.  7. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 6. 0. 3.] 
adversary cards in discard: [ 6. 11.  6.  0.  3.  0.  0.  6.  0.  0.  3.  6. 15.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 68.7783432006836






Player: 1 
cards in hand: [0. 3. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 0. 3.] 
cards in discard: [ 6. 11.  6.  0.  3.  0.  0.  6.  0.  0.  3.  6. 15.  6.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 29.  8.  0. 10.  7. 10.  6.  7. 10. 10. 10. 10.  9.] 
adversary cards in hand: [29.  0.  3. 29.  3.] 
adversary cards in discard: [25. 11. 11.  3.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29] -> size -> 19 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 3.] 
cards in discard: [ 6. 11.  6.  0.  3.  0.  0.  6.  0.  0.  3.  6. 15.  6.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 28. 29.  8.  0. 10.  7. 10.  6.  7. 10. 10. 10. 10.  9.] 
adversary cards in hand: [29.  0.  3. 29.  3.] 
adversary cards in discard: [25. 11. 11.  3.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29] -> size -> 19 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 3.] 
cards in discard: [ 6. 11.  6.  0.  3.  0.  0.  6.  0.  0.  3.  6. 15.  6.  6.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 29.  8.  0. 10.  7. 10.  6.  7. 10. 10. 10. 10.  9.] 
adversary cards in hand: [29.  0.  3. 29.  3.] 
adversary cards in discard: [25. 11. 11.  3.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29] -> size -> 19 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [29.  0.  3. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[36.554337]
 [44.702427]
 [44.702427]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3. 29.  3.] 
cards in discard: [25. 11. 11.  3.  0.  0. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 29.  8.  0. 10.  7. 10.  6.  7. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 4. 3. 6.] 
adversary cards in discard: [ 6. 11.  6.  0.  3.  0.  0.  6.  0.  0.  3.  6. 15.  6.  6.  3.  0.  3.
  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3] -> size -> 30 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 66.64559173583984



action possibilites: [-1. 25.] 
expected returns: [[68.33433]
 [85.05263]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 25.] 
cards in discard: [25. 11. 11.  3.  0.  0. 25. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 27. 29.  8.  0. 10.  7. 10.  6.  7. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 4. 3. 6.] 
adversary cards in discard: [ 6. 11.  6.  0.  3.  0.  0.  6.  0.  0.  3.  6. 15.  6.  6.  3.  0.  3.
  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3] -> size -> 30 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 37.34610366821289



action possibilites: [-1] 
expected returns: [[61.10007]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [25. 11. 11.  3.  0.  0. 25. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 27. 29.  8.  0. 10.  7. 10.  6.  7. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 4. 3. 6.] 
adversary cards in discard: [ 6. 11.  6.  0.  3.  0.  0.  6.  0.  0.  3.  6. 15.  6.  6.  3.  0.  3.
  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3] -> size -> 30 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 85.0526351928711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[55.113857]
 [65.66999 ]
 [60.116886]
 [62.75395 ]
 [67.642265]
 [62.483204]
 [72.28994 ]
 [48.877285]
 [56.93944 ]
 [58.94071 ]
 [63.44978 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [25. 11. 11.  3.  0.  0. 25. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 30. 30. 27. 29.  8.  0. 10.  7. 10.  6.  7. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 4. 3. 6.] 
adversary cards in discard: [ 6. 11.  6.  0.  3.  0.  0.  6.  0.  0.  3.  6. 15.  6.  6.  3.  0.  3.
  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3] -> size -> 30 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: 61.10007095336914



buy possibilites: [-1] 
expected returns: [[88.54354]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [25. 11. 11.  3.  0.  0. 25. 29. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 29.  8.  0. 10.  7. 10.  6.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 4. 3. 6.] 
adversary cards in discard: [ 6. 11.  6.  0.  3.  0.  0.  6.  0.  0.  3.  6. 15.  6.  6.  3.  0.  3.
  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3] -> size -> 30 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 283 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 72.2899398803711






Player: 1 
cards in hand: [0. 0. 4. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 4. 3. 6.] 
cards in discard: [ 6. 11.  6.  0.  3.  0.  0.  6.  0.  0.  3.  6. 15.  6.  6.  3.  0.  3.
  6.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 29.  8.  0. 10.  7. 10.  6.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 29. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29] -> size -> 20 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 4. 3. 6.] 
cards in discard: [ 6. 11.  6.  0.  3.  0.  0.  6.  0.  0.  3.  6. 15.  6.  6.  3.  0.  3.
  6.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 27. 29.  8.  0. 10.  7. 10.  6.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 29. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29] -> size -> 20 
adversary victory points: 3
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 3. 29. 25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[43.13265 ]
 [49.451   ]
 [56.289444]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 25.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 29.  8.  0. 10.  7. 10.  6.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 6. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3] -> size -> 30 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 88.54354095458984



action possibilites: [-1] 
expected returns: [[75.318634]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 29.  8.  0. 10.  7. 10.  6.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 6. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3] -> size -> 30 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 54.27180862426758





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[70.86547 ]
 [81.6559  ]
 [76.03815 ]
 [83.670166]
 [78.42976 ]
 [72.82764 ]
 [79.50643 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  0.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 27. 29.  8.  0. 10.  7. 10.  6.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 6. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3] -> size -> 30 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 75.31863403320312



buy possibilites: [-1] 
expected returns: [[83.69837]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  0.  0. 29.  0.] 
cards in discard: [11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 29.  8.  0. 10.  6. 10.  6.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 6. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3] -> size -> 30 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 189 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 83.67015838623047






Player: 1 
cards in hand: [3. 6. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 29.  8.  0. 10.  6. 10.  6.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 25. 25.  0. 29.] 
adversary cards in discard: [11. 25.  3. 29.  0.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11] -> size -> 21 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 27. 29.  8.  0. 10.  6. 10.  6.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 25. 25.  0. 29.] 
adversary cards in discard: [11. 25.  3. 29.  0.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11] -> size -> 21 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 6. 0.] 
cards in discard: [8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 29.  8.  0. 10.  6.  9.  6.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 25. 25.  0. 29.] 
adversary cards in discard: [11. 25.  3. 29.  0.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11] -> size -> 21 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 0. 25. 25.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 29.] 
expected returns: [[39.545895]
 [54.736324]
 [54.736324]
 [46.981037]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 25.  0. 29.] 
cards in discard: [11. 25.  3. 29.  0.  0. 29.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 29.  8.  0. 10.  6.  9.  6.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 6. 0. 6. 3.] 
adversary cards in discard: [8. 3. 6. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3  8] -> size -> 31 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 83.69837188720703



action possibilites: [-1] 
expected returns: [[44.68188]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0. 29.  3. 11.] 
cards in discard: [11. 25.  3. 29.  0.  0. 29.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 29.  8.  0. 10.  6.  9.  6.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 6. 0. 6. 3.] 
adversary cards in discard: [8. 3. 6. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3  8] -> size -> 31 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 54.7363166809082





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[37.840763]
 [42.522625]
 [44.86849 ]
 [45.84115 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  0. 29.  3. 11.] 
cards in discard: [11. 25.  3. 29.  0.  0. 29.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 27. 29.  8.  0. 10.  6.  9.  6.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 6. 0. 6. 3.] 
adversary cards in discard: [8. 3. 6. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3  8] -> size -> 31 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 44.681880950927734






Player: 1 
cards in hand: [0. 6. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 6. 3.] 
cards in discard: [8. 3. 6. 0. 6. 0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 29.  8.  0. 10.  6.  9.  6.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  3. 25.] 
adversary cards in discard: [11. 25.  3. 29.  0.  0. 29.  0. 25.  0. 25.  0. 29.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11] -> size -> 21 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6. 3.] 
cards in discard: [8. 3. 6. 0. 6. 0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 27. 29.  8.  0. 10.  6.  9.  6.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  3. 25.] 
adversary cards in discard: [11. 25.  3. 29.  0.  0. 29.  0. 25.  0. 25.  0. 29.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11] -> size -> 21 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6. 3.] 
cards in discard: [8. 3. 6. 0. 6. 0. 8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3  8  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 29.  8.  0. 10.  6.  8.  6.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  3. 25.] 
adversary cards in discard: [11. 25.  3. 29.  0.  0. 29.  0. 25.  0. 25.  0. 29.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11] -> size -> 21 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[ 83.931755]
 [ 92.76074 ]
 [101.43075 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  3. 25.] 
cards in discard: [11. 25.  3. 29.  0.  0. 29.  0. 25.  0. 25.  0. 29.  3. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 29.  8.  0. 10.  6.  8.  6.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  3.  6.  6. 15.] 
adversary cards in discard: [8. 3. 6. 0. 6. 0. 8. 0. 6. 0. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3  8  8] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 45.84115982055664



action possibilites: [-1] 
expected returns: [[47.089428]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  3. 29. 11.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 29.  8.  0. 10.  6.  8.  6.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  3.  6.  6. 15.] 
adversary cards in discard: [8. 3. 6. 0. 6. 0. 8. 0. 6. 0. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3  8  8] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 101.43074798583984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[41.795105]
 [46.064453]
 [48.017307]
 [48.858967]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  3. 29. 11.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 27. 29.  8.  0. 10.  6.  8.  6.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  3.  6.  6. 15.] 
adversary cards in discard: [8. 3. 6. 0. 6. 0. 8. 0. 6. 0. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3  8  8] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 47.08942794799805






Player: 1 
cards in hand: [ 3.  3.  6.  6. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  6.  6. 15.] 
cards in discard: [8. 3. 6. 0. 6. 0. 8. 0. 6. 0. 6. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3  8  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 29.  8.  0. 10.  6.  8.  6.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [25. 11.  0. 29.  0.] 
adversary cards in discard: [25.  0. 29.  0.  3. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11] -> size -> 21 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 6.] 
cards in discard: [8. 3. 6. 0. 6. 0. 8. 0. 6. 0. 6. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3  8  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 29.  8.  0. 10.  6.  8.  6.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [25. 11.  0. 29.  0.] 
adversary cards in discard: [25.  0. 29.  0.  3. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11] -> size -> 21 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 6.] 
cards in discard: [8. 3. 6. 0. 6. 0. 8. 0. 6. 0. 6. 3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3  8  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 30. 30. 27. 29.  8.  0. 10.  6.  8.  6.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [25. 11.  0. 29.  0.] 
adversary cards in discard: [25.  0. 29.  0.  3. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11] -> size -> 21 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [25. 11.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 29.] 
expected returns: [[46.265633]
 [61.68749 ]
 [49.93923 ]
 [53.978542]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11.  0. 29.  0.] 
cards in discard: [25.  0. 29.  0.  3. 29. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 29.  8.  0. 10.  6.  8.  6.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [6. 6. 4. 0. 3.] 
adversary cards in discard: [ 8.  3.  6.  0.  6.  0.  8.  0.  6.  0.  6.  3. 15.  3.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3  8  8] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 48.85895919799805



action possibilites: [-1] 
expected returns: [[63.93556]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 29.  0. 25.  0.] 
cards in discard: [25.  0. 29.  0.  3. 29. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 29.  8.  0. 10.  6.  8.  6.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [6. 6. 4. 0. 3.] 
adversary cards in discard: [ 8.  3.  6.  0.  6.  0.  8.  0.  6.  0.  6.  3. 15.  3.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3  8  8] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 61.6874885559082





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[57.330334]
 [68.155   ]
 [62.544865]
 [70.15263 ]
 [64.93418 ]
 [59.326466]
 [65.94187 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 29.  0. 25.  0.] 
cards in discard: [25.  0. 29.  0.  3. 29. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 27. 29.  8.  0. 10.  6.  8.  6.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [6. 6. 4. 0. 3.] 
adversary cards in discard: [ 8.  3.  6.  0.  6.  0.  8.  0.  6.  0.  6.  3. 15.  3.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3  8  8] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 63.9355583190918



buy possibilites: [-1] 
expected returns: [[54.736298]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 29.  0. 25.  0.] 
cards in discard: [25.  0. 29.  0.  3. 29. 11. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 29.  8.  0. 10.  5.  8.  6.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [6. 6. 4. 0. 3.] 
adversary cards in discard: [ 8.  3.  6.  0.  6.  0.  8.  0.  6.  0.  6.  3. 15.  3.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3  8  8] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 189 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 70.15264892578125






Player: 1 
cards in hand: [6. 6. 4. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 4. 0. 3.] 
cards in discard: [ 8.  3.  6.  0.  6.  0.  8.  0.  6.  0.  6.  3. 15.  3.  3.  6.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3  8  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 29.  8.  0. 10.  5.  8.  6.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 29. 25.] 
adversary cards in discard: [25.  0. 29.  0.  3. 29. 11. 11. 25. 11.  0. 29.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11] -> size -> 22 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 4. 0. 3.] 
cards in discard: [ 8.  3.  6.  0.  6.  0.  8.  0.  6.  0.  6.  3. 15.  3.  3.  6.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3  8  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 27. 29.  8.  0. 10.  5.  8.  6.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 29. 25.] 
adversary cards in discard: [25.  0. 29.  0.  3. 29. 11. 11. 25. 11.  0. 29.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11] -> size -> 22 
adversary victory points: 3
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[ 84.8687  ]
 [ 93.731346]
 [102.6201  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 29. 25.] 
cards in discard: [25.  0. 29.  0.  3. 29. 11. 11. 25. 11.  0. 29.  0. 25.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 29.  8.  0. 10.  5.  8.  6.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 3.] 
adversary cards in discard: [ 8.  3.  6.  0.  6.  0.  8.  0.  6.  0.  6.  3. 15.  3.  3.  6.  6.  6.
  6.  4.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3  8  8] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 54.736297607421875



action possibilites: [-1] 
expected returns: [[94.04942]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 29.  3. 11.] 
cards in discard: [25.  0. 29.  0.  3. 29. 11. 11. 25. 11.  0. 29.  0. 25.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 29.  8.  0. 10.  5.  8.  6.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 3.] 
adversary cards in discard: [ 8.  3.  6.  0.  6.  0.  8.  0.  6.  0.  6.  3. 15.  3.  3.  6.  6.  6.
  6.  4.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3  8  8] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 102.62010192871094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[87.610405]
 [92.24158 ]
 [94.47132 ]
 [95.41305 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 29.  3. 11.] 
cards in discard: [25.  0. 29.  0.  3. 29. 11. 11. 25. 11.  0. 29.  0. 25.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 27. 29.  8.  0. 10.  5.  8.  6.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 3.] 
adversary cards in discard: [ 8.  3.  6.  0.  6.  0.  8.  0.  6.  0.  6.  3. 15.  3.  3.  6.  6.  6.
  6.  4.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3  8  8] -> size -> 32 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 94.04942321777344






Player: 1 
cards in hand: [0. 6. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 3.] 
cards in discard: [ 8.  3.  6.  0.  6.  0.  8.  0.  6.  0.  6.  3. 15.  3.  3.  6.  6.  6.
  6.  4.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3  8  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 29.  8.  0. 10.  5.  8.  6.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [25.  0. 25. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11] -> size -> 22 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 3.] 
cards in discard: [ 8.  3.  6.  0.  6.  0.  8.  0.  6.  0.  6.  3. 15.  3.  3.  6.  6.  6.
  6.  4.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3  8  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 27. 29.  8.  0. 10.  5.  8.  6.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [25.  0. 25. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11] -> size -> 22 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 3.] 
cards in discard: [ 8.  3.  6.  0.  6.  0.  8.  0.  6.  0.  6.  3. 15.  3.  3.  6.  6.  6.
  6.  4.  0.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3  8  8  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 26. 29.  8.  0. 10.  5.  8.  6.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [25.  0. 25. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11] -> size -> 22 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [25.  0. 25. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 11.] 
expected returns: [[33.081997]
 [47.819122]
 [47.819122]
 [36.583176]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 25. 11.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 26. 29.  8.  0. 10.  5.  8.  6.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 6.  0.  0.  0. 11.] 
adversary cards in discard: [ 8.  3.  6.  0.  6.  0.  8.  0.  6.  0.  6.  3. 15.  3.  3.  6.  6.  6.
  6.  4.  0.  3.  3.  0.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3  8  8  3] -> size -> 33 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 95.41304779052734



action possibilites: [-1] 
expected returns: [[43.696644]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 11.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 26. 29.  8.  0. 10.  5.  8.  6.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 6.  0.  0.  0. 11.] 
adversary cards in discard: [ 8.  3.  6.  0.  6.  0.  8.  0.  6.  0.  6.  3. 15.  3.  3.  6.  6.  6.
  6.  4.  0.  3.  3.  0.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3  8  8  3] -> size -> 33 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 46.9656867980957





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[39.124176]
 [47.979134]
 [43.393517]
 [49.61571 ]
 [45.34638 ]
 [40.760754]
 [46.188034]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25. 11.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 26. 29.  8.  0. 10.  5.  8.  6.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 6.  0.  0.  0. 11.] 
adversary cards in discard: [ 8.  3.  6.  0.  6.  0.  8.  0.  6.  0.  6.  3. 15.  3.  3.  6.  6.  6.
  6.  4.  0.  3.  3.  0.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3  8  8  3] -> size -> 33 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 43.6966438293457



buy possibilites: [-1] 
expected returns: [[80.90466]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25. 11.  0.  3.  0.] 
cards in discard: [11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 26. 29.  8.  0. 10.  4.  8.  6.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 6.  0.  0.  0. 11.] 
adversary cards in discard: [ 8.  3.  6.  0.  6.  0.  8.  0.  6.  0.  6.  3. 15.  3.  3.  6.  6.  6.
  6.  4.  0.  3.  3.  0.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3  8  8  3] -> size -> 33 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 159 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 49.615718841552734






Player: 1 
cards in hand: [ 6.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0.  0. 11.] 
cards in discard: [ 8.  3.  6.  0.  6.  0.  8.  0.  6.  0.  6.  3. 15.  3.  3.  6.  6.  6.
  6.  4.  0.  3.  3.  0.  6.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3  8  8  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 26. 29.  8.  0. 10.  4.  8.  6.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29. 11. 29.  0.] 
adversary cards in discard: [11. 25.  0. 25. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11] -> size -> 23 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [ 8.  3.  6.  0.  6.  0.  8.  0.  6.  0.  6.  3. 15.  3.  3.  6.  6.  6.
  6.  4.  0.  3.  3.  0.  6.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3  8  8  3  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 25. 29.  8.  0. 10.  4.  8.  6.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29. 11. 29.  0.] 
adversary cards in discard: [11. 25.  0. 25. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11] -> size -> 23 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [ 8.  3.  6.  0.  6.  0.  8.  0.  6.  0.  6.  3. 15.  3.  3.  6.  6.  6.
  6.  4.  0.  3.  3.  0.  6.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3  8  8  3  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 25. 29.  8.  0. 10.  4.  8.  6.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29. 11. 29.  0.] 
adversary cards in discard: [11. 25.  0. 25. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11] -> size -> 23 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 11. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 29.] 
expected returns: [[60.61459]
 [70.48548]
 [65.2831 ]
 [70.48548]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 11. 29.  0.] 
cards in discard: [11. 25.  0. 25. 11.  0.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 25. 29.  8.  0. 10.  4.  8.  6.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  8. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3  8  8  3  3] -> size -> 34 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 80.9046630859375



action possibilites: [-1. 11.] 
expected returns: [[70.91306]
 [75.36775]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3.] 
cards in discard: [11. 25.  0. 25. 11.  0.  3.  0. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 25. 29.  8.  0. 10.  4.  8.  6.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  8. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3  8  8  3  3] -> size -> 34 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 63.06796646118164



action possibilites: [-1] 
expected returns: [[61.327953]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [11. 25.  0. 25. 11.  0.  3.  0. 29. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 25. 29.  8.  0. 10.  4.  8.  6.  6. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  0.  8. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3  8  8  3  3] -> size -> 34 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0 64  0] 
sum of rewards: 159 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 81.28733825683594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[52.988102]
 [65.59365 ]
 [58.983913]
 [67.942924]
 [61.798023]
 [55.19294 ]
 [62.96268 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [11. 25.  0. 25. 11.  0.  3.  0. 29. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 25. 29.  8.  0. 10.  4.  8.  6.  6. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  0.  8. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3  8  8  3  3] -> size -> 34 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 61.32795333862305



buy possibilites: [-1] 
expected returns: [[85.5261]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [11. 25.  0. 25. 11.  0.  3.  0. 29. 15. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 25. 29.  8.  0. 10.  3.  8.  6.  6. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  0.  8. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3  8  8  3  3] -> size -> 34 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 149 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 67.94293975830078






Player: 1 
cards in hand: [ 0.  0.  8. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 11.  3.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3  8  8  3  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 25. 29.  8.  0. 10.  3.  8.  6.  6. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 25.  3. 29. 11.] 
adversary cards in discard: [11. 25.  0. 25. 11.  0.  3.  0. 29. 15. 11. 29. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11] -> size -> 25 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 11.  3.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3  8  8  3  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 25. 29.  8.  0. 10.  3.  8.  6.  6. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 25.  3. 29. 11.] 
adversary cards in discard: [11. 25.  0. 25. 11.  0.  3.  0. 29. 15. 11. 29. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11] -> size -> 25 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 11.  3.] 
cards in discard: [3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3  8  8  3  3  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 24. 29.  8.  0. 10.  3.  8.  6.  6. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 25.  3. 29. 11.] 
adversary cards in discard: [11. 25.  0. 25. 11.  0.  3.  0. 29. 15. 11. 29. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11] -> size -> 25 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  3. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 11.] 
expected returns: [[107.666435]
 [128.13324 ]
 [117.588234]
 [112.3215  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3. 29. 11.] 
cards in discard: [11. 25.  0. 25. 11.  0.  3.  0. 29. 15. 11. 29. 11.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 24. 29.  8.  0. 10.  3.  8.  6.  6. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [ 3.  0.  0.  8. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3  8  8  3  3  3] -> size -> 35 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 85.5261001586914



action possibilites: [-1] 
expected returns: [[108.8937]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29. 11. 25. 29.] 
cards in discard: [11. 25.  0. 25. 11.  0.  3.  0. 29. 15. 11. 29. 11.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 24. 29.  8.  0. 10.  3.  8.  6.  6. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [ 3.  0.  0.  8. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3  8  8  3  3  3] -> size -> 35 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 128.13323974609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 97.54673]
 [109.1545 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 29. 11. 25. 29.] 
cards in discard: [11. 25.  0. 25. 11.  0.  3.  0. 29. 15. 11. 29. 11.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 24. 29.  8.  0. 10.  3.  8.  6.  6. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [ 3.  0.  0.  8. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3  8  8  3  3  3] -> size -> 35 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 108.8936996459961






Player: 1 
cards in hand: [0. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [ 3.  0.  0.  8. 11.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0
  6 11  6  0  6  3  8  8  3  3  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 24. 29.  8.  0. 10.  3.  8.  6.  6. 10. 10. 10. 10.  8.] 
adversary cards in hand: [25.  0. 11. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11] -> size -> 25 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 3.  0.  0.  8. 11.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0  6 11
  6  0  6  3  8  8  3  3  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 24. 29.  8.  0. 10.  3.  8.  6.  6. 10. 10. 10. 10.  8.] 
adversary cards in hand: [25.  0. 11. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11] -> size -> 25 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 3.  0.  0.  8. 11.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0  6 11
  6  0  6  3  8  8  3  3  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 24. 29.  8.  0. 10.  3.  8.  6.  6. 10. 10. 10. 10.  8.] 
adversary cards in hand: [25.  0. 11. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11] -> size -> 25 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 3.  0.  0.  8. 11.  3.  8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0  6 11
  6  0  6  3  8  8  3  3  3  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 24. 29.  8.  0. 10.  3.  7.  6.  6. 10. 10. 10. 10.  8.] 
adversary cards in hand: [25.  0. 11. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11] -> size -> 25 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [25.  0. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 11.] 
expected returns: [[45.35647 ]
 [58.550617]
 [48.49645 ]
 [48.49645 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 11. 11.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 24. 29.  8.  0. 10.  3.  7.  6.  6. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 6. 3. 6.] 
adversary cards in discard: [ 3.  0.  0.  8. 11.  3.  8.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0  6 11
  6  0  6  3  8  8  3  3  3  8] -> size -> 34 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 109.15451049804688



action possibilites: [-1] 
expected returns: [[81.04839]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 24. 29.  8.  0. 10.  3.  7.  6.  6. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 6. 3. 6.] 
adversary cards in discard: [ 3.  0.  0.  8. 11.  3.  8.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0  6 11
  6  0  6  3  8  8  3  3  3  8] -> size -> 34 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 58.55061721801758





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[75.184235]
 [84.429756]
 [79.64277 ]
 [86.139984]
 [81.681435]
 [76.89445 ]
 [82.56779 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 11.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 24. 29.  8.  0. 10.  3.  7.  6.  6. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 6. 3. 6.] 
adversary cards in discard: [ 3.  0.  0.  8. 11.  3.  8.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0  6 11
  6  0  6  3  8  8  3  3  3  8] -> size -> 34 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 81.04839324951172



buy possibilites: [-1] 
expected returns: [[109.34258]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 11.  0. 29.  0.] 
cards in discard: [11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 24. 29.  8.  0. 10.  2.  7.  6.  6. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 6. 3. 6.] 
adversary cards in discard: [ 3.  0.  0.  8. 11.  3.  8.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0  6 11
  6  0  6  3  8  8  3  3  3  8] -> size -> 34 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 99 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 86.13996124267578






Player: 1 
cards in hand: [0. 0. 6. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 3. 6.] 
cards in discard: [ 3.  0.  0.  8. 11.  3.  8.  8.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0  6 11
  6  0  6  3  8  8  3  3  3  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 24. 29.  8.  0. 10.  2.  7.  6.  6. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  0. 29.  3. 15.] 
adversary cards in discard: [11. 25.  0. 11. 11.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11] -> size -> 26 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 6.] 
cards in discard: [ 3.  0.  0.  8. 11.  3.  8.  8.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0  6 11
  6  0  6  3  8  8  3  3  3  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 24. 29.  8.  0. 10.  2.  7.  6.  6. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  0. 29.  3. 15.] 
adversary cards in discard: [11. 25.  0. 11. 11.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11] -> size -> 26 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 6.] 
cards in discard: [ 3.  0.  0.  8. 11.  3.  8.  8.  0.  0.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0  6 11
  6  0  6  3  8  8  3  3  3  8  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 23. 29.  8.  0. 10.  2.  7.  6.  6. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  0. 29.  3. 15.] 
adversary cards in discard: [11. 25.  0. 11. 11.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11] -> size -> 26 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 29.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
expected returns: [[66.51999 ]
 [76.586685]
 [61.591045]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  3. 15.] 
cards in discard: [11. 25.  0. 11. 11.  0. 29.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 23. 29.  8.  0. 10.  2.  7.  6.  6. 10. 10. 10. 10.  8.] 
adversary cards in hand: [6. 3. 0. 3. 3.] 
adversary cards in discard: [ 3.  0.  0.  8. 11.  3.  8.  8.  0.  0.  3.  0.  0.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0  6 11
  6  0  6  3  8  8  3  3  3  8  3] -> size -> 35 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 109.34258270263672



action possibilites: [-1. 15. 11.] 
expected returns: [[76.79571]
 [72.10815]
 [81.15266]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15. 11.] 
cards in discard: [11. 25.  0. 11. 11.  0. 29.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 23. 29.  8.  0. 10.  2.  7.  6.  6. 10. 10. 10. 10.  8.] 
adversary cards in hand: [6. 3. 0. 3. 3.] 
adversary cards in discard: [ 3.  0.  0.  8. 11.  3.  8.  8.  0.  0.  3.  0.  0.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0  6 11
  6  0  6  3  8  8  3  3  3  8  3] -> size -> 35 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 68.9581069946289



action possibilites: [-1] 
expected returns: [[89.610085]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15.] 
cards in discard: [11. 25.  0. 11. 11.  0. 29.  0.  3. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 23. 29.  8.  0. 10.  2.  7.  6.  6. 10. 10. 10. 10.  7.] 
adversary cards in hand: [6. 3. 0. 3. 3.] 
adversary cards in discard: [ 3.  0.  0.  8. 11.  3.  8.  8.  0.  0.  3.  0.  0.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0  6 11
  6  0  6  3  8  8  3  3  3  8  3] -> size -> 35 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 64  0] 
sum of rewards: 99 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 86.99078369140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[78.92926 ]
 [85.275215]
 [88.18076 ]
 [89.40388 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 15.] 
cards in discard: [11. 25.  0. 11. 11.  0. 29.  0.  3. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 23. 29.  8.  0. 10.  2.  7.  6.  6. 10. 10. 10. 10.  7.] 
adversary cards in hand: [6. 3. 0. 3. 3.] 
adversary cards in discard: [ 3.  0.  0.  8. 11.  3.  8.  8.  0.  0.  3.  0.  0.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0  6 11
  6  0  6  3  8  8  3  3  3  8  3] -> size -> 35 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 89.6100845336914






Player: 1 
cards in hand: [6. 3. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 3. 3.] 
cards in discard: [ 3.  0.  0.  8. 11.  3.  8.  8.  0.  0.  3.  0.  0.  6.  3.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0  6 11
  6  0  6  3  8  8  3  3  3  8  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 23. 29.  8.  0. 10.  2.  7.  6.  6. 10. 10. 10. 10.  7.] 
adversary cards in hand: [25.  0. 29.  0. 11.] 
adversary cards in discard: [11. 25.  0. 11. 11.  0. 29.  0.  3. 15. 29. 11.  0.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15] -> size -> 27 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 3. 3.] 
cards in discard: [ 3.  0.  0.  8. 11.  3.  8.  8.  0.  0.  3.  0.  0.  6.  3.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0  6 11
  6  0  6  3  8  8  3  3  3  8  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 23. 29.  8.  0. 10.  2.  7.  6.  6. 10. 10. 10. 10.  7.] 
adversary cards in hand: [25.  0. 29.  0. 11.] 
adversary cards in discard: [11. 25.  0. 11. 11.  0. 29.  0.  3. 15. 29. 11.  0.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15] -> size -> 27 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 3. 3.] 
cards in discard: [ 3.  0.  0.  8. 11.  3.  8.  8.  0.  0.  3.  0.  0.  6.  3.  6.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0  6 11
  6  0  6  3  8  8  3  3  3  8  3  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 23. 29.  8.  0. 10.  2.  7.  6.  6. 10. 10. 10. 10.  7.] 
adversary cards in hand: [25.  0. 29.  0. 11.] 
adversary cards in discard: [11. 25.  0. 11. 11.  0. 29.  0.  3. 15. 29. 11.  0.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15] -> size -> 27 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [25.  0. 29.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 11.] 
expected returns: [[113.377754]
 [137.38402 ]
 [125.44805 ]
 [119.07882 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 29.  0. 11.] 
cards in discard: [11. 25.  0. 11. 11.  0. 29.  0.  3. 15. 29. 11.  0.  3. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 23. 29.  8.  0. 10.  2.  7.  6.  6. 10. 10. 10. 10.  7.] 
adversary cards in hand: [6. 3. 0. 6. 6.] 
adversary cards in discard: [ 3.  0.  0.  8. 11.  3.  8.  8.  0.  0.  3.  0.  0.  6.  3.  6.  0.  6.
  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0  6 11
  6  0  6  3  8  8  3  3  3  8  3  0] -> size -> 36 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 89.40386199951172



action possibilites: [-1] 
expected returns: [[81.08377]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 11. 29. 25.] 
cards in discard: [11. 25.  0. 11. 11.  0. 29.  0.  3. 15. 29. 11.  0.  3. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 23. 29.  8.  0. 10.  2.  7.  6.  6. 10. 10. 10. 10.  7.] 
adversary cards in hand: [6. 3. 0. 6. 6.] 
adversary cards in discard: [ 3.  0.  0.  8. 11.  3.  8.  8.  0.  0.  3.  0.  0.  6.  3.  6.  0.  6.
  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0  6 11
  6  0  6  3  8  8  3  3  3  8  3  0] -> size -> 36 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 137.38401794433594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[73.51014 ]
 [77.854095]
 [79.850044]
 [80.698715]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0. 11. 29. 25.] 
cards in discard: [11. 25.  0. 11. 11.  0. 29.  0.  3. 15. 29. 11.  0.  3. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 30. 30. 23. 29.  8.  0. 10.  2.  7.  6.  6. 10. 10. 10. 10.  7.] 
adversary cards in hand: [6. 3. 0. 6. 6.] 
adversary cards in discard: [ 3.  0.  0.  8. 11.  3.  8.  8.  0.  0.  3.  0.  0.  6.  3.  6.  0.  6.
  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0  6 11
  6  0  6  3  8  8  3  3  3  8  3  0] -> size -> 36 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 81.08377075195312






Player: 1 
cards in hand: [6. 3. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 6. 6.] 
cards in discard: [ 3.  0.  0.  8. 11.  3.  8.  8.  0.  0.  3.  0.  0.  6.  3.  6.  0.  6.
  3.  0.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0  6 11
  6  0  6  3  8  8  3  3  3  8  3  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 23. 29.  8.  0. 10.  2.  7.  6.  6. 10. 10. 10. 10.  7.] 
adversary cards in hand: [25. 11.  0.  3. 11.] 
adversary cards in discard: [11. 25.  0. 11. 11.  0. 29.  0.  3. 15. 29. 11.  0.  3. 15. 25.  0. 29.
  0. 11. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15] -> size -> 27 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 6. 6.] 
cards in discard: [ 3.  0.  0.  8. 11.  3.  8.  8.  0.  0.  3.  0.  0.  6.  3.  6.  0.  6.
  3.  0.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0  6 11
  6  0  6  3  8  8  3  3  3  8  3  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 30. 30. 23. 29.  8.  0. 10.  2.  7.  6.  6. 10. 10. 10. 10.  7.] 
adversary cards in hand: [25. 11.  0.  3. 11.] 
adversary cards in discard: [11. 25.  0. 11. 11.  0. 29.  0.  3. 15. 29. 11.  0.  3. 15. 25.  0. 29.
  0. 11. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15] -> size -> 27 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [25. 11.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 11.] 
expected returns: [[123.871086]
 [143.14413 ]
 [128.33553 ]
 [128.33553 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11.  0.  3. 11.] 
cards in discard: [11. 25.  0. 11. 11.  0. 29.  0.  3. 15. 29. 11.  0.  3. 15. 25.  0. 29.
  0. 11. 29. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 23. 29.  8.  0. 10.  2.  7.  6.  6. 10. 10. 10. 10.  7.] 
adversary cards in hand: [6. 4. 3. 6. 0.] 
adversary cards in discard: [ 3.  0.  0.  8. 11.  3.  8.  8.  0.  0.  3.  0.  0.  6.  3.  6.  0.  6.
  3.  0.  3.  3.  6.  3.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0  6 11
  6  0  6  3  8  8  3  3  3  8  3  0] -> size -> 36 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 80.6987075805664



action possibilites: [-1] 
expected returns: [[84.91015]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3. 11. 29. 29.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 23. 29.  8.  0. 10.  2.  7.  6.  6. 10. 10. 10. 10.  7.] 
adversary cards in hand: [6. 4. 3. 6. 0.] 
adversary cards in discard: [ 3.  0.  0.  8. 11.  3.  8.  8.  0.  0.  3.  0.  0.  6.  3.  6.  0.  6.
  3.  0.  3.  3.  6.  3.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0  6 11
  6  0  6  3  8  8  3  3  3  8  3  0] -> size -> 36 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 143.14413452148438





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[78.84576]
 [86.03316]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3. 11. 29. 29.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 30. 30. 23. 29.  8.  0. 10.  2.  7.  6.  6. 10. 10. 10. 10.  7.] 
adversary cards in hand: [6. 4. 3. 6. 0.] 
adversary cards in discard: [ 3.  0.  0.  8. 11.  3.  8.  8.  0.  0.  3.  0.  0.  6.  3.  6.  0.  6.
  3.  0.  3.  3.  6.  3.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0  6 11
  6  0  6  3  8  8  3  3  3  8  3  0] -> size -> 36 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 84.91014862060547






Player: 1 
cards in hand: [6. 4. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 4. 3. 6. 0.] 
cards in discard: [ 3.  0.  0.  8. 11.  3.  8.  8.  0.  0.  3.  0.  0.  6.  3.  6.  0.  6.
  3.  0.  3.  3.  6.  3.  0.  6.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0  6 11
  6  0  6  3  8  8  3  3  3  8  3  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 23. 29.  8.  0. 10.  2.  7.  6.  6. 10. 10. 10. 10.  7.] 
adversary cards in hand: [15.  0.  0.  3.  3.] 
adversary cards in discard: [25. 11.  0.  3. 11. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15] -> size -> 27 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 4. 3. 6. 0.] 
cards in discard: [ 3.  0.  0.  8. 11.  3.  8.  8.  0.  0.  3.  0.  0.  6.  3.  6.  0.  6.
  3.  0.  3.  3.  6.  3.  0.  6.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0  6 11
  6  0  6  3  8  8  3  3  3  8  3  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 30. 30. 23. 29.  8.  0. 10.  2.  7.  6.  6. 10. 10. 10. 10.  7.] 
adversary cards in hand: [15.  0.  0.  3.  3.] 
adversary cards in discard: [25. 11.  0.  3. 11. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15] -> size -> 27 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 4. 3. 6. 0.] 
cards in discard: [ 3.  0.  0.  8. 11.  3.  8.  8.  0.  0.  3.  0.  0.  6.  3.  6.  0.  6.
  3.  0.  3.  3.  6.  3.  0.  6.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0  6 11
  6  0  6  3  8  8  3  3  3  8  3  0  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 30. 30. 23. 29.  8.  0. 10.  2.  7.  6.  6. 10. 10. 10. 10.  7.] 
adversary cards in hand: [15.  0.  0.  3.  3.] 
adversary cards in discard: [25. 11.  0.  3. 11. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15] -> size -> 27 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [15.  0.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[82.56118]
 [77.83341]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  3.  3.] 
cards in discard: [25. 11.  0.  3. 11. 29. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 23. 29.  8.  0. 10.  2.  7.  6.  6. 10. 10. 10. 10.  7.] 
adversary cards in hand: [ 0.  3.  6.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0  6 11
  6  0  6  3  8  8  3  3  3  8  3  0  0] -> size -> 37 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 86.03315734863281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[74.72253]
 [80.05625]
 [82.51586]
 [83.51725]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.  3.  3.] 
cards in discard: [25. 11.  0.  3. 11. 29. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 30. 30. 23. 29.  8.  0. 10.  2.  7.  6.  6. 10. 10. 10. 10.  7.] 
adversary cards in hand: [ 0.  3.  6.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0  6 11
  6  0  6  3  8  8  3  3  3  8  3  0  0] -> size -> 37 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 82.5611801147461



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3.  6.  6. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  6.  6. 15.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0  6 11
  6  0  6  3  8  8  3  3  3  8  3  0  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 23. 29.  8.  0. 10.  2.  7.  6.  6. 10. 10. 10. 10.  7.] 
adversary cards in hand: [11. 29.  0. 29.  0.] 
adversary cards in discard: [25. 11.  0.  3. 11. 29. 29. 15.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15] -> size -> 27 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  6.  6. 15.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0  6 11
  6  0  6  3  8  8  3  3  3  8  3  0  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 30. 30. 23. 29.  8.  0. 10.  2.  7.  6.  6. 10. 10. 10. 10.  7.] 
adversary cards in hand: [11. 29.  0. 29.  0.] 
adversary cards in discard: [25. 11.  0.  3. 11. 29. 29. 15.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15] -> size -> 27 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [11. 29.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 29.] 
expected returns: [[71.2907  ]
 [74.821594]
 [78.70783 ]
 [78.70783 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  0. 29.  0.] 
cards in discard: [25. 11.  0.  3. 11. 29. 29. 15.  0.  0.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 23. 29.  8.  0. 10.  2.  7.  6.  6. 10. 10. 10. 10.  7.] 
adversary cards in hand: [6. 3. 3. 6. 8.] 
adversary cards in discard: [ 0.  3.  6.  6. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0  6 11
  6  0  6  3  8  8  3  3  3  8  3  0  0] -> size -> 37 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 83.5172348022461



action possibilites: [-1. 11. 11.] 
expected returns: [[68.99953 ]
 [72.876015]
 [72.876015]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 11.] 
cards in discard: [25. 11.  0.  3. 11. 29. 29. 15.  0.  0.  3.  3. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 30. 30. 23. 29.  8.  0. 10.  2.  7.  6.  6. 10. 10. 10. 10.  7.] 
adversary cards in hand: [6. 3. 3. 6. 8.] 
adversary cards in discard: [ 0.  3.  6.  6. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0  6 11
  6  0  6  3  8  8  3  3  3  8  3  0  0] -> size -> 37 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 73.18128967285156



action possibilites: [-1] 
expected returns: [[127.54952]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.] 
cards in discard: [25. 11.  0.  3. 11. 29. 29. 15.  0.  0.  3.  3. 29. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 30. 30. 23. 29.  8.  0. 10.  2.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [6. 3. 3. 6. 8.] 
adversary cards in discard: [ 0.  3.  6.  6. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0  6 11
  6  0  6  3  8  8  3  3  3  8  3  0  0] -> size -> 37 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 64  0] 
sum of rewards: 99 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 77.95982360839844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[117.91451]
 [130.95084]
 [124.19216]
 [133.34955]
 [127.07186]
 [120.3132 ]
 [128.24046]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.] 
cards in discard: [25. 11.  0.  3. 11. 29. 29. 15.  0.  0.  3.  3. 29. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 30. 30. 23. 29.  8.  0. 10.  2.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [6. 3. 3. 6. 8.] 
adversary cards in discard: [ 0.  3.  6.  6. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0  6 11
  6  0  6  3  8  8  3  3  3  8  3  0  0] -> size -> 37 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 127.54952239990234



buy possibilites: [-1] 
expected returns: [[141.6319]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.] 
cards in discard: [25. 11.  0.  3. 11. 29. 29. 15.  0.  0.  3.  3. 29. 15. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 23. 29.  8.  0. 10.  1.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [6. 3. 3. 6. 8.] 
adversary cards in discard: [ 0.  3.  6.  6. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0  6 11
  6  0  6  3  8  8  3  3  3  8  3  0  0] -> size -> 37 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 89 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 133.34954833984375






Player: 1 
cards in hand: [6. 3. 3. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 6. 8.] 
cards in discard: [ 0.  3.  6.  6. 15.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0  0  6 15  6  3  6  6  6  6  4  6  0  6 11
  6  0  6  3  8  8  3  3  3  8  3  0  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 23. 29.  8.  0. 10.  1.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [ 0.  0. 25. 15. 25.] 
adversary cards in discard: [25. 11.  0.  3. 11. 29. 29. 15.  0.  0.  3.  3. 29. 15. 11. 29. 11.  0.
  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11] -> size -> 29 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 0.  3.  6.  6. 15.] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  0  0 15  3  6  6  6  6  4  6  0  6 11  6  0  6  3
  8  8  3  3  3  8  3  0  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 23. 29.  8.  0. 10.  1.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [ 0.  0. 25. 15. 25.] 
adversary cards in discard: [25. 11.  0.  3. 11. 29. 29. 15.  0.  0.  3.  3. 29. 15. 11. 29. 11.  0.
  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11] -> size -> 29 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0.  3.  6.  6. 15.] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  0  0 15  3  6  6  6  6  4  6  0  6 11  6  0  6  3
  8  8  3  3  3  8  3  0  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 30. 30. 23. 29.  8.  0. 10.  1.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [ 0.  0. 25. 15. 25.] 
adversary cards in discard: [25. 11.  0.  3. 11. 29. 29. 15.  0.  0.  3.  3. 29. 15. 11. 29. 11.  0.
  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11] -> size -> 29 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0.  3.  6.  6. 15.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  0  0 15  3  6  6  6  6  4  6  0  6 11  6  0  6  3
  8  8  3  3  3  8  3  0  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 23. 29.  8.  0. 10.  1.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [ 0.  0. 25. 15. 25.] 
adversary cards in discard: [25. 11.  0.  3. 11. 29. 29. 15.  0.  0.  3.  3. 29. 15. 11. 29. 11.  0.
  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11] -> size -> 29 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 25. 15. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15. 25.] 
expected returns: [[ 87.46917 ]
 [107.85689 ]
 [ 82.204094]
 [107.85689 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25. 15. 25.] 
cards in discard: [25. 11.  0.  3. 11. 29. 29. 15.  0.  0.  3.  3. 29. 15. 11. 29. 11.  0.
  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 23. 29.  8.  0. 10.  1.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  3.  6.  6. 15.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  0 15  3  6  6  6  6  4  6  0  6 11  6  0  6  3
  8  8  3  3  3  8  3  0  0  0] -> size -> 34 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 141.63189697265625



action possibilites: [-1] 
expected returns: [[82.892105]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15. 25. 11. 11.] 
cards in discard: [25. 11.  0.  3. 11. 29. 29. 15.  0.  0.  3.  3. 29. 15. 11. 29. 11.  0.
  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 23. 29.  8.  0. 10.  1.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  3.  6.  6. 15.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  0 15  3  6  6  6  6  4  6  0  6 11  6  0  6  3
  8  8  3  3  3  8  3  0  0  0] -> size -> 34 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 107.85687255859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[75.15223 ]
 [80.0722  ]
 [82.394485]
 [83.37057 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15. 25. 11. 11.] 
cards in discard: [25. 11.  0.  3. 11. 29. 29. 15.  0.  0.  3.  3. 29. 15. 11. 29. 11.  0.
  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 30. 30. 23. 29.  8.  0. 10.  1.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  3.  6.  6. 15.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  0 15  3  6  6  6  6  4  6  0  6 11  6  0  6  3
  8  8  3  3  3  8  3  0  0  0] -> size -> 34 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 82.89210510253906






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 0.  3.  6.  6. 15.  0.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  0 15  3  6  6  6  6  4  6  0  6 11  6  0  6  3
  8  8  3  3  3  8  3  0  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 23. 29.  8.  0. 10.  1.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [29.  0.  0. 11. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11] -> size -> 29 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 0.  3.  6.  6. 15.  0.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  0 15  3  6  6  6  6  4  6  0  6 11  6  0  6  3
  8  8  3  3  3  8  3  0  0  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 30. 30. 23. 29.  8.  0. 10.  1.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [29.  0.  0. 11. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11] -> size -> 29 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 0.  3.  6.  6. 15.  0.  8.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  0 15  3  6  6  6  6  4  6  0  6 11  6  0  6  3
  8  8  3  3  3  8  3  0  0  0  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 30. 30. 22. 29.  8.  0. 10.  1.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [29.  0.  0. 11. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11] -> size -> 29 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [29.  0.  0. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 25.] 
expected returns: [[66.378624]
 [73.464714]
 [69.72837 ]
 [80.72395 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 11. 25.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 22. 29.  8.  0. 10.  1.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [3. 3. 0. 8. 0.] 
adversary cards in discard: [ 0.  3.  6.  6. 15.  0.  8.  3.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  0 15  3  6  6  6  6  4  6  0  6 11  6  0  6  3
  8  8  3  3  3  8  3  0  0  0  3] -> size -> 35 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 83.37056732177734



action possibilites: [-1] 
expected returns: [[95.01084]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 11.  0. 29.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 22. 29.  8.  0. 10.  1.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [3. 3. 0. 8. 0.] 
adversary cards in discard: [ 0.  3.  6.  6. 15.  0.  8.  3.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  0 15  3  6  6  6  6  4  6  0  6 11  6  0  6  3
  8  8  3  3  3  8  3  0  0  0  3] -> size -> 35 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 80.72393798828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[ 89.39558 ]
 [100.20714 ]
 [ 94.45791 ]
 [102.316124]
 [ 96.8649  ]
 [ 91.33908 ]
 [ 97.93705 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0. 11.  0. 29.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 30. 30. 22. 29.  8.  0. 10.  1.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [3. 3. 0. 8. 0.] 
adversary cards in discard: [ 0.  3.  6.  6. 15.  0.  8.  3.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  0 15  3  6  6  6  6  4  6  0  6 11  6  0  6  3
  8  8  3  3  3  8  3  0  0  0  3] -> size -> 35 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 95.0108413696289



buy possibilites: [-1] 
expected returns: [[113.91343]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0. 11.  0. 29.] 
cards in discard: [11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 22. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [3. 3. 0. 8. 0.] 
adversary cards in discard: [ 0.  3.  6.  6. 15.  0.  8.  3.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  0 15  3  6  6  6  6  4  6  0  6 11  6  0  6  3
  8  8  3  3  3  8  3  0  0  0  3] -> size -> 35 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 102.31612396240234






Player: 1 
cards in hand: [3. 3. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 8. 0.] 
cards in discard: [ 0.  3.  6.  6. 15.  0.  8.  3.  3.  0.  0.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  0 15  3  6  6  6  6  4  6  0  6 11  6  0  6  3
  8  8  3  3  3  8  3  0  0  0  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 22. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [11. 11. 15. 29. 11.] 
adversary cards in discard: [11. 25. 29.  0.  0. 11.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11] -> size -> 30 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 8. 0.] 
cards in discard: [ 0.  3.  6.  6. 15.  0.  8.  3.  3.  0.  0.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  0 15  3  6  6  6  6  4  6  0  6 11  6  0  6  3
  8  8  3  3  3  8  3  0  0  0  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 30. 30. 22. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [11. 11. 15. 29. 11.] 
adversary cards in discard: [11. 25. 29.  0.  0. 11.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11] -> size -> 30 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 8. 0.] 
cards in discard: [ 0.  3.  6.  6. 15.  0.  8.  3.  3.  0.  0.  0.  0.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  0 15  3  6  6  6  6  4  6  0  6 11  6  0  6  3
  8  8  3  3  3  8  3  0  0  0  3  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [11. 11. 15. 29. 11.] 
adversary cards in discard: [11. 25. 29.  0.  0. 11.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11] -> size -> 30 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [11. 11. 15. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 15. 29. 11.] 
expected returns: [[77.312996]
 [81.16906 ]
 [81.16906 ]
 [73.179344]
 [85.43894 ]
 [81.16906 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 15. 29. 11.] 
cards in discard: [11. 25. 29.  0.  0. 11.  0. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [3. 3. 6. 3. 0.] 
adversary cards in discard: [ 0.  3.  6.  6. 15.  0.  8.  3.  3.  0.  0.  0.  0.  3.  3.  3.  0.  8.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  0 15  3  6  6  6  6  4  6  0  6 11  6  0  6  3
  8  8  3  3  3  8  3  0  0  0  3  3] -> size -> 36 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 113.9134292602539



action possibilites: [-1. 11. 11. 15.] 
expected returns: [[80.86002]
 [85.48121]
 [85.48121]
 [75.85641]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 15.] 
cards in discard: [11. 25. 29.  0.  0. 11.  0. 29. 11. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 30. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [3. 3. 6. 3. 0.] 
adversary cards in discard: [ 0.  3.  6.  6. 15.  0.  8.  3.  3.  0.  0.  0.  0.  3.  3.  3.  0.  8.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  0 15  3  6  6  6  6  4  6  0  6 11  6  0  6  3
  8  8  3  3  3  8  3  0  0  0  3  3] -> size -> 36 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 79.35852813720703



action possibilites: [-1] 
expected returns: [[76.247444]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15.] 
cards in discard: [11. 25. 29.  0.  0. 11.  0. 29. 11. 15.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [3. 3. 6. 3. 0.] 
adversary cards in discard: [ 0.  3.  6.  6. 15.  0.  8.  3.  3.  0.  0.  0.  0.  3.  3.  3.  0.  8.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  0 15  3  6  6  6  6  4  6  0  6 11  6  0  6  3
  8  8  3  3  3  8  3  0  0  0  3  3] -> size -> 36 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 2 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 83.28851318359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[66.50066]
 [75.78262]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 15.] 
cards in discard: [11. 25. 29.  0.  0. 11.  0. 29. 11. 15.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 29. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [3. 3. 6. 3. 0.] 
adversary cards in discard: [ 0.  3.  6.  6. 15.  0.  8.  3.  3.  0.  0.  0.  0.  3.  3.  3.  0.  8.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  0 15  3  6  6  6  6  4  6  0  6 11  6  0  6  3
  8  8  3  3  3  8  3  0  0  0  3  3] -> size -> 36 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 76.24744415283203






Player: 1 
cards in hand: [3. 3. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 3. 0.] 
cards in discard: [ 0.  3.  6.  6. 15.  0.  8.  3.  3.  0.  0.  0.  0.  3.  3.  3.  0.  8.
  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  0 15  3  6  6  6  6  4  6  0  6 11  6  0  6  3
  8  8  3  3  3  8  3  0  0  0  3  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [ 3. 25.  0. 29. 25.] 
adversary cards in discard: [11. 25. 29.  0.  0. 11.  0. 29. 11. 15.  1. 29. 11. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1] -> size -> 31 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 3. 0.] 
cards in discard: [ 0.  3.  6.  6. 15.  0.  8.  3.  3.  0.  0.  0.  0.  3.  3.  3.  0.  8.
  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  0 15  3  6  6  6  6  4  6  0  6 11  6  0  6  3
  8  8  3  3  3  8  3  0  0  0  3  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 29. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [ 3. 25.  0. 29. 25.] 
adversary cards in discard: [11. 25. 29.  0.  0. 11.  0. 29. 11. 15.  1. 29. 11. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1] -> size -> 31 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 3. 0.] 
cards in discard: [ 0.  3.  6.  6. 15.  0.  8.  3.  3.  0.  0.  0.  0.  3.  3.  3.  0.  8.
  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  0 15  3  6  6  6  6  4  6  0  6 11  6  0  6  3
  8  8  3  3  3  8  3  0  0  0  3  3  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 29. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [ 3. 25.  0. 29. 25.] 
adversary cards in discard: [11. 25. 29.  0.  0. 11.  0. 29. 11. 15.  1. 29. 11. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1] -> size -> 31 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 3. 25.  0. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25.] 
expected returns: [[108.14872 ]
 [130.01965 ]
 [119.025276]
 [130.01965 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  0. 29. 25.] 
cards in discard: [11. 25. 29.  0.  0. 11.  0. 29. 11. 15.  1. 29. 11. 11. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [11.  0.  8.  0.  6.] 
adversary cards in discard: [ 0.  3.  6.  6. 15.  0.  8.  3.  3.  0.  0.  0.  0.  3.  3.  3.  0.  8.
  0.  0.  3.  3.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  0 15  3  6  6  6  6  4  6  0  6 11  6  0  6  3
  8  8  3  3  3  8  3  0  0  0  3  3  0] -> size -> 37 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 75.7826156616211



action possibilites: [-1] 
expected returns: [[119.91472]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29. 25. 11. 11.] 
cards in discard: [11. 25. 29.  0.  0. 11.  0. 29. 11. 15.  1. 29. 11. 11. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [11.  0.  8.  0.  6.] 
adversary cards in discard: [ 0.  3.  6.  6. 15.  0.  8.  3.  3.  0.  0.  0.  0.  3.  3.  3.  0.  8.
  0.  0.  3.  3.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  0 15  3  6  6  6  6  4  6  0  6 11  6  0  6  3
  8  8  3  3  3  8  3  0  0  0  3  3  0] -> size -> 37 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 130.0196533203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[110.96226]
 [119.81083]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29. 25. 11. 11.] 
cards in discard: [11. 25. 29.  0.  0. 11.  0. 29. 11. 15.  1. 29. 11. 11. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 29. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [11.  0.  8.  0.  6.] 
adversary cards in discard: [ 0.  3.  6.  6. 15.  0.  8.  3.  3.  0.  0.  0.  0.  3.  3.  3.  0.  8.
  0.  0.  3.  3.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0  0 15  3  6  6  6  6  4  6  0  6 11  6  0  6  3
  8  8  3  3  3  8  3  0  0  0  3  3  0] -> size -> 37 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 119.91471862792969






Player: 1 
cards in hand: [11.  0.  8.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8.  0.  6.] 
cards in discard: [ 0.  3.  6.  6. 15.  0.  8.  3.  3.  0.  0.  0.  0.  3.  3.  3.  0.  8.
  0.  0.  3.  3.  6.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0  0 15  3  6  6  6  6  4  6  0  6 11  6  0  6  3
  8  8  3  3  3  8  3  0  0  0  3  3  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [ 3. 15. 11.  0.  0.] 
adversary cards in discard: [11. 25. 29.  0.  0. 11.  0. 29. 11. 15.  1. 29. 11. 11. 15. 25.  3.  0.
 29. 25. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1] -> size -> 31 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6.] 
cards in discard: [ 0.  3.  6.  6. 15.  0.  8.  3.  3.  0.  0.  0.  0.  3.  3.  3.  0.  8.
  0.  0.  3.  3.  6.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8
  3  3  3  8  3  0  0  0  3  3  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [ 3. 15. 11.  0.  0.] 
adversary cards in discard: [11. 25. 29.  0.  0. 11.  0. 29. 11. 15.  1. 29. 11. 11. 15. 25.  3.  0.
 29. 25. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1] -> size -> 31 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [ 0.  3.  6.  6. 15.  0.  8.  3.  3.  0.  0.  0.  0.  3.  3.  3.  0.  8.
  0.  0.  3.  3.  6.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8
  3  3  3  8  3  0  0  0  3  3  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 29. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [ 3. 15. 11.  0.  0.] 
adversary cards in discard: [11. 25. 29.  0.  0. 11.  0. 29. 11. 15.  1. 29. 11. 11. 15. 25.  3.  0.
 29. 25. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1] -> size -> 31 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [ 0.  3.  6.  6. 15.  0.  8.  3.  3.  0.  0.  0.  0.  3.  3.  3.  0.  8.
  0.  0.  3.  3.  6.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8
  3  3  3  8  3  0  0  0  3  3  0  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [ 3. 15. 11.  0.  0.] 
adversary cards in discard: [11. 25. 29.  0.  0. 11.  0. 29. 11. 15.  1. 29. 11. 11. 15. 25.  3.  0.
 29. 25. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1] -> size -> 31 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 3. 15. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
expected returns: [[80.95643]
 [77.30695]
 [84.44121]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 11.  0.  0.] 
cards in discard: [11. 25. 29.  0.  0. 11.  0. 29. 11. 15.  1. 29. 11. 11. 15. 25.  3.  0.
 29. 25. 11. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [6. 0. 4. 3. 6.] 
adversary cards in discard: [ 0.  3.  6.  6. 15.  0.  8.  3.  3.  0.  0.  0.  0.  3.  3.  3.  0.  8.
  0.  0.  3.  3.  6.  3.  0.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8
  3  3  3  8  3  0  0  0  3  3  0  0] -> size -> 36 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 119.81084442138672



action possibilites: [-1] 
expected returns: [[102.58291]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0.  0.] 
cards in discard: [11. 25. 29.  0.  0. 11.  0. 29. 11. 15.  1. 29. 11. 11. 15. 25.  3.  0.
 29. 25. 11. 11.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [6. 0. 4. 3. 6.] 
adversary cards in discard: [ 0.  3.  6.  6. 15.  0.  8.  3.  3.  0.  0.  0.  0.  3.  3.  3.  0.  8.
  0.  0.  3.  3.  6.  3.  0.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8
  3  3  3  8  3  0  0  0  3  3  0  0] -> size -> 36 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -18 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 82.72936248779297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 93.698204]
 [ 98.72706 ]
 [101.03209 ]
 [101.993774]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  0.  0.] 
cards in discard: [11. 25. 29.  0.  0. 11.  0. 29. 11. 15.  1. 29. 11. 11. 15. 25.  3.  0.
 29. 25. 11. 11.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 28. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [6. 0. 4. 3. 6.] 
adversary cards in discard: [ 0.  3.  6.  6. 15.  0.  8.  3.  3.  0.  0.  0.  0.  3.  3.  3.  0.  8.
  0.  0.  3.  3.  6.  3.  0.  0.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8
  3  3  3  8  3  0  0  0  3  3  0  0] -> size -> 36 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 102.5829086303711






Player: 1 
cards in hand: [6. 0. 4. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 4. 3. 6.] 
cards in discard: [ 0.  3.  6.  6. 15.  0.  8.  3.  3.  0.  0.  0.  0.  3.  3.  3.  0.  8.
  0.  0.  3.  3.  6.  3.  0.  0.  8.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8
  3  3  3  8  3  0  0  0  3  3  0  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [11. 11. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1] -> size -> 32 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 4. 3. 6.] 
cards in discard: [ 0.  3.  6.  6. 15.  0.  8.  3.  3.  0.  0.  0.  0.  3.  3.  3.  0.  8.
  0.  0.  3.  3.  6.  3.  0.  0.  8.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8
  3  3  3  8  3  0  0  0  3  3  0  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 28. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [11. 11. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1] -> size -> 32 
adversary victory points: 3
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [11. 11. 25.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 25.] 
expected returns: [[62.0733  ]
 [65.3483  ]
 [65.3483  ]
 [75.831856]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 25.  3.  0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [0. 0. 3. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8
  3  3  3  8  3  0  0  0  3  3  0  0] -> size -> 36 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 101.99378204345703



action possibilites: [-1] 
expected returns: [[98.15943]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  3.  0.  0. 15.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [0. 0. 3. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8
  3  3  3  8  3  0  0  0  3  3  0  0] -> size -> 36 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 75.83185577392578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[88.411934]
 [94.48092 ]
 [97.2651  ]
 [98.50142 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  3.  0.  0. 15.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 28. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [0. 0. 3. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8
  3  3  3  8  3  0  0  0  3  3  0  0] -> size -> 36 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 98.15943145751953






Player: 1 
cards in hand: [0. 0. 3. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 6. 6.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8
  3  3  3  8  3  0  0  0  3  3  0  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [ 0. 11. 29. 25. 29.] 
adversary cards in discard: [25. 11. 11.  3.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1] -> size -> 32 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 6.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8
  3  3  3  8  3  0  0  0  3  3  0  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 28. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [ 0. 11. 29. 25. 29.] 
adversary cards in discard: [25. 11. 11.  3.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1] -> size -> 32 
adversary victory points: 3
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 29. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 25. 29.] 
expected returns: [[ 99.07085 ]
 [103.29749 ]
 [107.98456 ]
 [116.991425]
 [107.98456 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 29. 25. 29.] 
cards in discard: [25. 11. 11.  3.  0.  0. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [3. 3. 6. 8. 0.] 
adversary cards in discard: [0. 0. 3. 6. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8
  3  3  3  8  3  0  0  0  3  3  0  0] -> size -> 36 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 98.50141906738281



action possibilites: [-1] 
expected returns: [[81.61766]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 29. 29. 25. 15.] 
cards in discard: [25. 11. 11.  3.  0.  0. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [3. 3. 6. 8. 0.] 
adversary cards in discard: [0. 0. 3. 6. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8
  3  3  3  8  3  0  0  0  3  3  0  0] -> size -> 36 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 116.99140167236328





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[73.587685]
 [82.22288 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 29. 29. 25. 15.] 
cards in discard: [25. 11. 11.  3.  0.  0. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 28. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [3. 3. 6. 8. 0.] 
adversary cards in discard: [0. 0. 3. 6. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8
  3  3  3  8  3  0  0  0  3  3  0  0] -> size -> 36 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 81.61766052246094






Player: 1 
cards in hand: [3. 3. 6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 8. 0.] 
cards in discard: [0. 0. 3. 6. 6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8
  3  3  3  8  3  0  0  0  3  3  0  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [11. 11.  3.  0.  3.] 
adversary cards in discard: [25. 11. 11.  3.  0.  0. 15. 25.  0. 11. 29. 29. 25. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1] -> size -> 32 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0.] 
cards in discard: [0. 0. 3. 6. 6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [11. 11.  3.  0.  3.] 
adversary cards in discard: [25. 11. 11.  3.  0.  0. 15. 25.  0. 11. 29. 29. 25. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1] -> size -> 32 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0.] 
cards in discard: [0. 0. 3. 6. 6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 28. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [11. 11.  3.  0.  3.] 
adversary cards in discard: [25. 11. 11.  3.  0.  0. 15. 25.  0. 11. 29. 29. 25. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1] -> size -> 32 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0.] 
cards in discard: [0. 0. 3. 6. 6. 0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [11. 11.  3.  0.  3.] 
adversary cards in discard: [25. 11. 11.  3.  0.  0. 15. 25.  0. 11. 29. 29. 25. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1] -> size -> 32 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [11. 11.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[64.791176]
 [68.84971 ]
 [68.84971 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  3.  0.  3.] 
cards in discard: [25. 11. 11.  3.  0.  0. 15. 25.  0. 11. 29. 29. 25. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [ 0.  3.  6. 15.  8.] 
adversary cards in discard: [0. 0. 3. 6. 6. 0. 8. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0] -> size -> 36 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 82.22286987304688



action possibilites: [-1] 
expected returns: [[92.57815]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  3.] 
cards in discard: [25. 11. 11.  3.  0.  0. 15. 25.  0. 11. 29. 29. 25. 15.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [ 0.  3.  6. 15.  8.] 
adversary cards in discard: [0. 0. 3. 6. 6. 0. 8. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0] -> size -> 36 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 66.90950775146484





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[82.01825]
 [92.34348]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  3.] 
cards in discard: [25. 11. 11.  3.  0.  0. 15. 25.  0. 11. 29. 29. 25. 15.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 27. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [ 0.  3.  6. 15.  8.] 
adversary cards in discard: [0. 0. 3. 6. 6. 0. 8. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0] -> size -> 36 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 92.5781478881836






Player: 1 
cards in hand: [ 0.  3.  6. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  6. 15.  8.] 
cards in discard: [0. 0. 3. 6. 6. 0. 8. 3. 6. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [ 1.  0. 11. 11. 11.] 
adversary cards in discard: [25. 11. 11.  3.  0.  0. 15. 25.  0. 11. 29. 29. 25. 15.  1. 11. 11.  3.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1] -> size -> 33 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  6. 15.  8.] 
cards in discard: [0. 0. 3. 6. 6. 0. 8. 3. 6. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 27. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [ 1.  0. 11. 11. 11.] 
adversary cards in discard: [25. 11. 11.  3.  0.  0. 15. 25.  0. 11. 29. 29. 25. 15.  1. 11. 11.  3.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1] -> size -> 33 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 1.  0. 11. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11.] 
expected returns: [[73.95115]
 [77.88429]
 [77.88429]
 [77.88429]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 11. 11. 11.] 
cards in discard: [25. 11. 11.  3.  0.  0. 15. 25.  0. 11. 29. 29. 25. 15.  1. 11. 11.  3.
  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [0. 3. 6. 0. 3.] 
adversary cards in discard: [ 0.  0.  3.  6.  6.  0.  8.  3.  6.  0.  0.  3.  6. 15.  8.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0] -> size -> 36 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 92.34349822998047



action possibilites: [-1] 
expected returns: [[92.83962]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 11. 11.] 
cards in discard: [25. 11. 11.  3.  0.  0. 15. 25.  0. 11. 29. 29. 25. 15.  1. 11. 11.  3.
  0.  3.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [0. 3. 6. 0. 3.] 
adversary cards in discard: [ 0.  0.  3.  6.  6.  0.  8.  3.  6.  0.  0.  3.  6. 15.  8.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0] -> size -> 36 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 76.02178192138672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[82.16731]
 [94.03217]
 [87.88264]
 [90.50328]
 [84.35372]
 [91.57792]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 11. 11.] 
cards in discard: [25. 11. 11.  3.  0.  0. 15. 25.  0. 11. 29. 29. 25. 15.  1. 11. 11.  3.
  0.  3.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 26. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [0. 3. 6. 0. 3.] 
adversary cards in discard: [ 0.  0.  3.  6.  6.  0.  8.  3.  6.  0.  0.  3.  6. 15.  8.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0] -> size -> 36 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 92.8396224975586



buy possibilites: [-1] 
expected returns: [[79.50153]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 11. 11.] 
cards in discard: [25. 11. 11.  3.  0.  0. 15. 25.  0. 11. 29. 29. 25. 15.  1. 11. 11.  3.
  0.  3.  1.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [0. 3. 6. 0. 3.] 
adversary cards in discard: [ 0.  0.  3.  6.  6.  0.  8.  3.  6.  0.  0.  3.  6. 15.  8.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0] -> size -> 36 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 94.03217315673828






Player: 1 
cards in hand: [0. 3. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 0. 3.] 
cards in discard: [ 0.  0.  3.  6.  6.  0.  8.  3.  6.  0.  0.  3.  6. 15.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [25.  0. 15. 11. 29.] 
adversary cards in discard: [25. 11. 11.  3.  0.  0. 15. 25.  0. 11. 29. 29. 25. 15.  1. 11. 11.  3.
  0.  3.  1.  1. 11.  1.  0. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1] -> size -> 35 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 3.] 
cards in discard: [ 0.  0.  3.  6.  6.  0.  8.  3.  6.  0.  0.  3.  6. 15.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 25. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [25.  0. 15. 11. 29.] 
adversary cards in discard: [25. 11. 11.  3.  0.  0. 15. 25.  0. 11. 29. 29. 25. 15.  1. 11. 11.  3.
  0.  3.  1.  1. 11.  1.  0. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1] -> size -> 35 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 3.] 
cards in discard: [ 0.  0.  3.  6.  6.  0.  8.  3.  6.  0.  0.  3.  6. 15.  8.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 25. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [25.  0. 15. 11. 29.] 
adversary cards in discard: [25. 11. 11.  3.  0.  0. 15. 25.  0. 11. 29. 29. 25. 15.  1. 11. 11.  3.
  0.  3.  1.  1. 11.  1.  0. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1] -> size -> 35 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [25.  0. 15. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15. 11. 29.] 
expected returns: [[-11.847087  ]
 [  0.20311546]
 [-14.741783  ]
 [ -9.194059  ]
 [ -6.229372  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 15. 11. 29.] 
cards in discard: [25. 11. 11.  3.  0.  0. 15. 25.  0. 11. 29. 29. 25. 15.  1. 11. 11.  3.
  0.  3.  1.  1. 11.  1.  0. 11. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [4. 3. 0. 0. 6.] 
adversary cards in discard: [ 0.  0.  3.  6.  6.  0.  8.  3.  6.  0.  0.  3.  6. 15.  8.  0.  0.  3.
  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0] -> size -> 37 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 79.50153350830078



action possibilites: [-1] 
expected returns: [[15.915867]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 11. 29. 29.  1.] 
cards in discard: [25. 11. 11.  3.  0.  0. 15. 25.  0. 11. 29. 29. 25. 15.  1. 11. 11.  3.
  0.  3.  1.  1. 11.  1.  0. 11. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [4. 3. 0. 0. 6.] 
adversary cards in discard: [ 0.  0.  3.  6.  6.  0.  8.  3.  6.  0.  0.  3.  6. 15.  8.  0.  0.  3.
  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0] -> size -> 37 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 0.2031092643737793





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[ 8.75758 ]
 [15.707584]
 [12.105637]
 [13.643858]
 [10.041767]
 [14.27813 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 11. 29. 29.  1.] 
cards in discard: [25. 11. 11.  3.  0.  0. 15. 25.  0. 11. 29. 29. 25. 15.  1. 11. 11.  3.
  0.  3.  1.  1. 11.  1.  0. 11. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 25. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [4. 3. 0. 0. 6.] 
adversary cards in discard: [ 0.  0.  3.  6.  6.  0.  8.  3.  6.  0.  0.  3.  6. 15.  8.  0.  0.  3.
  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0] -> size -> 37 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 15.91586685180664



buy possibilites: [-1] 
expected returns: [[24.312082]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 11. 29. 29.  1.] 
cards in discard: [25. 11. 11.  3.  0.  0. 15. 25.  0. 11. 29. 29. 25. 15.  1. 11. 11.  3.
  0.  3.  1.  1. 11.  1.  0. 11. 11.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [4. 3. 0. 0. 6.] 
adversary cards in discard: [ 0.  0.  3.  6.  6.  0.  8.  3.  6.  0.  0.  3.  6. 15.  8.  0.  0.  3.
  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0] -> size -> 37 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0 -10   0   0  54   0] 
sum of rewards: 29 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 15.707571029663086






Player: 1 
cards in hand: [4. 3. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 3. 0. 0. 6.] 
cards in discard: [ 0.  0.  3.  6.  6.  0.  8.  3.  6.  0.  0.  3.  6. 15.  8.  0.  0.  3.
  6.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [11.  1. 29. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1] -> size -> 36 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 3. 0. 0. 6.] 
cards in discard: [ 0.  0.  3.  6.  6.  0.  8.  3.  6.  0.  0.  3.  6. 15.  8.  0.  0.  3.
  6.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 24. 30. 21. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [11.  1. 29. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1] -> size -> 36 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 3. 0. 0. 6.] 
cards in discard: [ 0.  0.  3.  6.  6.  0.  8.  3.  6.  0.  0.  3.  6. 15.  8.  0.  0.  3.
  6.  0.  3.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 20. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [11.  1. 29. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1] -> size -> 36 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [11.  1. 29. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 11.] 
expected returns: [[61.773235]
 [64.697174]
 [67.94654 ]
 [64.697174]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1. 29. 11.  0.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 20. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [8. 0. 6. 3. 6.] 
adversary cards in discard: [ 0.  0.  3.  6.  6.  0.  8.  3.  6.  0.  0.  3.  6. 15.  8.  0.  0.  3.
  6.  0.  3.  3.  4.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3] -> size -> 38 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 24.312082290649414



action possibilites: [-1. 11. 11.] 
expected returns: [[69.64527]
 [72.87098]
 [72.87098]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11. 11.] 
cards in discard: [11.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 24. 30. 20. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [8. 0. 6. 3. 6.] 
adversary cards in discard: [ 0.  0.  3.  6.  6.  0.  8.  3.  6.  0.  0.  3.  6. 15.  8.  0.  0.  3.
  6.  0.  3.  3.  4.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3] -> size -> 38 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 63.316776275634766



action possibilites: [-1] 
expected returns: [[60.23865]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.] 
cards in discard: [11.  0.  1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 23. 30. 20. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [8. 0. 6. 3. 6.] 
adversary cards in discard: [ 0.  0.  3.  6.  6.  0.  8.  3.  6.  0.  0.  3.  6. 15.  8.  0.  0.  3.
  6.  0.  3.  3.  4.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3] -> size -> 38 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0 -20   0   0  27   0] 
sum of rewards: -18 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 71.35411071777344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[53.512085]
 [62.933147]
 [57.854267]
 [60.016567]
 [55.172825]
 [60.965763]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.] 
cards in discard: [11.  0.  1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 23. 30. 20. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [8. 0. 6. 3. 6.] 
adversary cards in discard: [ 0.  0.  3.  6.  6.  0.  8.  3.  6.  0.  0.  3.  6. 15.  8.  0.  0.  3.
  6.  0.  3.  3.  4.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3] -> size -> 38 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 60.238651275634766



buy possibilites: [-1] 
expected returns: [[66.404]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.] 
cards in discard: [11.  0.  1.  1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 20. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [8. 0. 6. 3. 6.] 
adversary cards in discard: [ 0.  0.  3.  6.  6.  0.  8.  3.  6.  0.  0.  3.  6. 15.  8.  0.  0.  3.
  6.  0.  3.  3.  4.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3] -> size -> 38 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0 -30   0   0  54   0] 
sum of rewards: -1 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 62.93314743041992






Player: 1 
cards in hand: [8. 0. 6. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 3. 6.] 
cards in discard: [ 0.  0.  3.  6.  6.  0.  8.  3.  6.  0.  0.  3.  6. 15.  8.  0.  0.  3.
  6.  0.  3.  3.  4.  3.  0.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 20. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [ 1.  3. 29. 11.  3.] 
adversary cards in discard: [11.  0.  1.  1. 29. 11.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1] -> size -> 38 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6. 3. 6.] 
cards in discard: [ 0.  0.  3.  6.  6.  0.  8.  3.  6.  0.  0.  3.  6. 15.  8.  0.  0.  3.
  6.  0.  3.  3.  4.  3.  0.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 22. 30. 20. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [ 1.  3. 29. 11.  3.] 
adversary cards in discard: [11.  0.  1.  1. 29. 11.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1] -> size -> 38 
adversary victory points: 3
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 1.  3. 29. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[ 89.20202 ]
 [100.34411 ]
 [ 94.342735]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 29. 11.  3.] 
cards in discard: [11.  0.  1.  1. 29. 11.  1. 11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 20. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 0.  0.  3.  6.  6.  0.  8.  3.  6.  0.  0.  3.  6. 15.  8.  0.  0.  3.
  6.  0.  3.  3.  4.  3.  0.  0.  6.  8.  0.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3] -> size -> 38 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 66.40399932861328



action possibilites: [-1.] 
expected returns: [[88.827995]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 1.] 
cards in discard: [11.  0.  1.  1. 29. 11.  1. 11.  1. 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 22. 30. 20. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 0.  0.  3.  6.  6.  0.  8.  3.  6.  0.  0.  3.  6. 15.  8.  0.  0.  3.
  6.  0.  3.  3.  4.  3.  0.  0.  6.  8.  0.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3] -> size -> 38 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 91.89397430419922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[80.46152]
 [91.72461]
 [85.84198]
 [88.31154]
 [82.51956]
 [89.36722]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1.] 
cards in discard: [11.  0.  1.  1. 29. 11.  1. 11.  1. 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 22. 30. 20. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 0.  0.  3.  6.  6.  0.  8.  3.  6.  0.  0.  3.  6. 15.  8.  0.  0.  3.
  6.  0.  3.  3.  4.  3.  0.  0.  6.  8.  0.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3] -> size -> 38 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 88.82799530029297



buy possibilites: [-1] 
expected returns: [[72.09241]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1.] 
cards in discard: [11.  0.  1.  1. 29. 11.  1. 11.  1. 11.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 21. 30. 20. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 0.  0.  3.  6.  6.  0.  8.  3.  6.  0.  0.  3.  6. 15.  8.  0.  0.  3.
  6.  0.  3.  3.  4.  3.  0.  0.  6.  8.  0.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3] -> size -> 38 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0 -40   0   0  54   0] 
sum of rewards: -31 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 91.72460174560547






Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 0.  0.  3.  6.  6.  0.  8.  3.  6.  0.  0.  3.  6. 15.  8.  0.  0.  3.
  6.  0.  3.  3.  4.  3.  0.  0.  6.  8.  0.  6.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 21. 30. 20. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [11. 11. 11.  3. 11.] 
adversary cards in discard: [11.  0.  1.  1. 29. 11.  1. 11.  1. 11.  1. 29.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1] -> size -> 39 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 0.  0.  3.  6.  6.  0.  8.  3.  6.  0.  0.  3.  6. 15.  8.  0.  0.  3.
  6.  0.  3.  3.  4.  3.  0.  0.  6.  8.  0.  6.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 21. 30. 20. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [11. 11. 11.  3. 11.] 
adversary cards in discard: [11.  0.  1.  1. 29. 11.  1. 11.  1. 11.  1. 29.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1] -> size -> 39 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 0.  0.  3.  6.  6.  0.  8.  3.  6.  0.  0.  3.  6. 15.  8.  0.  0.  3.
  6.  0.  3.  3.  4.  3.  0.  0.  6.  8.  0.  6.  3.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 3 
card supply: [18. 21. 30. 20. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [11. 11. 11.  3. 11.] 
adversary cards in discard: [11.  0.  1.  1. 29. 11.  1. 11.  1. 11.  1. 29.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1] -> size -> 39 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [11. 11. 11.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11. 11.] 
expected returns: [[75.904205]
 [79.54684 ]
 [79.54684 ]
 [79.54684 ]
 [79.54684 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 11.  3. 11.] 
cards in discard: [11.  0.  1.  1. 29. 11.  1. 11.  1. 11.  1. 29.  3.  3.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 21. 30. 20. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0] -> size -> 39 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 72.0924072265625



action possibilites: [-1] 
expected returns: [[112.82244]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  3. 11.] 
cards in discard: [11.  0.  1.  1. 29. 11.  1. 11.  1. 11.  1. 29.  3.  3.  1.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 20. 30. 20. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0] -> size -> 39 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0 -50   0   0  27   0] 
sum of rewards: -68 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 77.82933807373047





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[102.294655]
 [112.48129 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  3. 11.] 
cards in discard: [11.  0.  1.  1. 29. 11.  1. 11.  1. 11.  1. 29.  3.  3.  1.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 20. 30. 20. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0] -> size -> 39 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 112.82244110107422






Player: 1 
cards in hand: [3. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 20. 30. 20. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [ 1.  0. 15.  0.  1.] 
adversary cards in discard: [11.  0.  1.  1. 29. 11.  1. 11.  1. 11.  1. 29.  3.  3.  1.  1. 11. 11.
 11.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1] -> size -> 40 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 20. 30. 20. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [ 1.  0. 15.  0.  1.] 
adversary cards in discard: [11.  0.  1.  1. 29. 11.  1. 11.  1. 11.  1. 29.  3.  3.  1.  1. 11. 11.
 11.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1] -> size -> 40 
adversary victory points: 3
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [ 1.  0. 15.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[74.076324]
 [69.45367 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 15.  0.  1.] 
cards in discard: [11.  0.  1.  1. 29. 11.  1. 11.  1. 11.  1. 29.  3.  3.  1.  1. 11. 11.
 11.  3. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 20. 30. 20. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [ 0.  6.  0. 15.  6.] 
adversary cards in discard: [3. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0] -> size -> 39 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 112.48126983642578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[63.106358]
 [74.15464 ]
 [57.37553 ]
 [68.42382 ]
 [54.12815 ]
 [71.15573 ]
 [70.86753 ]
 [90.31081 ]
 [80.98701 ]
 [56.158516]
 [67.49501 ]
 [65.13672 ]
 [56.446716]
 [67.2068  ]
 [71.82947 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 15.  0.  1.] 
cards in discard: [11.  0.  1.  1. 29. 11.  1. 11.  1. 11.  1. 29.  3.  3.  1.  1. 11. 11.
 11.  3. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 6 
card supply: [18. 20. 30. 20. 29.  8.  0. 10.  0.  7.  6.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [ 0.  6.  0. 15.  6.] 
adversary cards in discard: [3. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0] -> size -> 39 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 74.07632446289062



buy possibilites: [-1] 
expected returns: [[110.25817]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 15.  0.  1.] 
cards in discard: [11.  0.  1.  1. 29. 11.  1. 11.  1. 11.  1. 29.  3.  3.  1.  1. 11. 11.
 11.  3. 11. 25.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 20. 30. 20. 29.  8.  0. 10.  0.  7.  5.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [ 0.  6.  0. 15.  6.] 
adversary cards in discard: [3. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0] -> size -> 39 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  -60.    0.    0.    0.    0.    0.    0.    0.  -60.
   0.    0.   62.5   0. ] 
sum of rewards: -62.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 90.3108139038086






Player: 1 
cards in hand: [ 0.  6.  0. 15.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 15.  6.] 
cards in discard: [3. 0. 3. 3. 0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 20. 30. 20. 29.  8.  0. 10.  0.  7.  5.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [25.  0. 11. 25. 15.] 
adversary cards in discard: [11.  0.  1.  1. 29. 11.  1. 11.  1. 11.  1. 29.  3.  3.  1.  1. 11. 11.
 11.  3. 11. 25.  1.  0. 15.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25] -> size -> 41 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 15.  6.] 
cards in discard: [3. 0. 3. 3. 0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 20. 30. 20. 29.  8.  0. 10.  0.  7.  5.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [25.  0. 11. 25. 15.] 
adversary cards in discard: [11.  0.  1.  1. 29. 11.  1. 11.  1. 11.  1. 29.  3.  3.  1.  1. 11. 11.
 11.  3. 11. 25.  1.  0. 15.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25] -> size -> 41 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 15.  6.] 
cards in discard: [3. 0. 3. 3. 0. 3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 20. 30. 19. 29.  8.  0. 10.  0.  7.  5.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [25.  0. 11. 25. 15.] 
adversary cards in discard: [11.  0.  1.  1. 29. 11.  1. 11.  1. 11.  1. 29.  3.  3.  1.  1. 11. 11.
 11.  3. 11. 25.  1.  0. 15.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25] -> size -> 41 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [25.  0. 11. 25. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 25. 15.] 
expected returns: [[-6.374972 ]
 [ 8.227655 ]
 [-3.0636344]
 [ 8.227655 ]
 [-9.901127 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 11. 25. 15.] 
cards in discard: [11.  0.  1.  1. 29. 11.  1. 11.  1. 11.  1. 29.  3.  3.  1.  1. 11. 11.
 11.  3. 11. 25.  1.  0. 15.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 20. 30. 19. 29.  8.  0. 10.  0.  7.  5.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [0. 6. 0. 3. 0.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  6.  0. 15.  6.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3] -> size -> 40 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 110.25817108154297



action possibilites: [-1] 
expected returns: [[-11.395075]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 25. 15.  0. 29.] 
cards in discard: [11.  0.  1.  1. 29. 11.  1. 11.  1. 11.  1. 29.  3.  3.  1.  1. 11. 11.
 11.  3. 11. 25.  1.  0. 15.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 20. 30. 19. 29.  8.  0. 10.  0.  7.  5.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [0. 6. 0. 3. 0.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  6.  0. 15.  6.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3] -> size -> 40 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 8.227655410766602





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-16.486998]
 [-13.486334]
 [-12.030763]
 [-11.395079]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 25. 15.  0. 29.] 
cards in discard: [11.  0.  1.  1. 29. 11.  1. 11.  1. 11.  1. 29.  3.  3.  1.  1. 11. 11.
 11.  3. 11. 25.  1.  0. 15.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 20. 30. 19. 29.  8.  0. 10.  0.  7.  5.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [0. 6. 0. 3. 0.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  6.  0. 15.  6.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3] -> size -> 40 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: -11.395074844360352






Player: 1 
cards in hand: [0. 6. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 3. 0.] 
cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  6.  0. 15.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 20. 30. 19. 29.  8.  0. 10.  0.  7.  5.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [25.  0. 29. 15.  1.] 
adversary cards in discard: [11.  0.  1.  1. 29. 11.  1. 11.  1. 11.  1. 29.  3.  3.  1.  1. 11. 11.
 11.  3. 11. 25.  1.  0. 15.  0.  1. 25.  0. 11. 25. 15.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25] -> size -> 41 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3. 0.] 
cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  6.  0. 15.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 20. 30. 19. 29.  8.  0. 10.  0.  7.  5.  6. 10. 10. 10. 10.  6.] 
adversary cards in hand: [25.  0. 29. 15.  1.] 
adversary cards in discard: [11.  0.  1.  1. 29. 11.  1. 11.  1. 11.  1. 29.  3.  3.  1.  1. 11. 11.
 11.  3. 11. 25.  1.  0. 15.  0.  1. 25.  0. 11. 25. 15.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25] -> size -> 41 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3. 0.] 
cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  6.  0. 15.  6. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 20. 30. 19. 29.  8.  0. 10.  0.  7.  5.  6. 10. 10.  9. 10.  6.] 
adversary cards in hand: [25.  0. 29. 15.  1.] 
adversary cards in discard: [11.  0.  1.  1. 29. 11.  1. 11.  1. 11.  1. 29.  3.  3.  1.  1. 11. 11.
 11.  3. 11. 25.  1.  0. 15.  0.  1. 25.  0. 11. 25. 15.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25] -> size -> 41 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [25.  0. 29. 15.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 15.] 
expected returns: [[23.909986]
 [36.38611 ]
 [30.034098]
 [20.869116]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 29. 15.  1.] 
cards in discard: [11.  0.  1.  1. 29. 11.  1. 11.  1. 11.  1. 29.  3.  3.  1.  1. 11. 11.
 11.  3. 11. 25.  1.  0. 15.  0.  1. 25.  0. 11. 25. 15.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 20. 30. 19. 29.  8.  0. 10.  0.  7.  5.  6. 10. 10.  9. 10.  6.] 
adversary cards in hand: [6. 0. 6. 3. 8.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  6.  0. 15.  6. 10.  0.  6.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10] -> size -> 41 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -11.395074844360352



action possibilites: [-1] 
expected returns: [[26.065304]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 15.  1. 25.  0.] 
cards in discard: [11.  0.  1.  1. 29. 11.  1. 11.  1. 11.  1. 29.  3.  3.  1.  1. 11. 11.
 11.  3. 11. 25.  1.  0. 15.  0.  1. 25.  0. 11. 25. 15.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 20. 30. 19. 29.  8.  0. 10.  0.  7.  5.  6. 10. 10.  9. 10.  6.] 
adversary cards in hand: [6. 0. 6. 3. 8.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  6.  0. 15.  6. 10.  0.  6.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10] -> size -> 41 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 36.38612365722656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[22.350597]
 [27.312803]
 [24.718689]
 [26.016062]
 [25.83509 ]
 [30.994944]
 [19.187668]
 [23.240986]
 [24.149872]
 [26.06529 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 15.  1. 25.  0.] 
cards in discard: [11.  0.  1.  1. 29. 11.  1. 11.  1. 11.  1. 29.  3.  3.  1.  1. 11. 11.
 11.  3. 11. 25.  1.  0. 15.  0.  1. 25.  0. 11. 25. 15.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25] -> size -> 41 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 20. 30. 19. 29.  8.  0. 10.  0.  7.  5.  6. 10. 10.  9. 10.  6.] 
adversary cards in hand: [6. 0. 6. 3. 8.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  6.  0. 15.  6. 10.  0.  6.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10] -> size -> 41 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 26.065303802490234



buy possibilites: [-1] 
expected returns: [[28.551329]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 15.  1. 25.  0.] 
cards in discard: [11.  0.  1.  1. 29. 11.  1. 11.  1. 11.  1. 29.  3.  3.  1.  1. 11. 11.
 11.  3. 11. 25.  1.  0. 15.  0.  1. 25.  0. 11. 25. 15.  0. 29. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 20. 30. 19. 29.  8.  0. 10.  0.  7.  5.  5. 10. 10.  9. 10.  6.] 
adversary cards in hand: [6. 0. 6. 3. 8.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  6.  0. 15.  6. 10.  0.  6.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10] -> size -> 41 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0 -70   0   0 128   0] 
sum of rewards: -17 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 30.994951248168945






Player: 1 
cards in hand: [6. 0. 6. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 3. 8.] 
cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  6.  0. 15.  6. 10.  0.  6.  0.  3.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 20. 30. 19. 29.  8.  0. 10.  0.  7.  5.  5. 10. 10.  9. 10.  6.] 
adversary cards in hand: [ 1. 11. 11. 11. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29] -> size -> 42 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 3. 8.] 
cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  6.  0. 15.  6. 10.  0.  6.  0.  3.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 20. 30. 19. 29.  8.  0. 10.  0.  7.  5.  5. 10. 10.  9. 10.  6.] 
adversary cards in hand: [ 1. 11. 11. 11. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29] -> size -> 42 
adversary victory points: 3
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [ 1. 11. 11. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11. 25.] 
expected returns: [[66.95323]
 [70.69141]
 [70.69141]
 [70.69141]
 [82.67518]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11. 11. 11. 25.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 20. 30. 19. 29.  8.  0. 10.  0.  7.  5.  5. 10. 10.  9. 10.  6.] 
adversary cards in hand: [3. 0. 4. 6. 3.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  6.  0. 15.  6. 10.  0.  6.  0.  3.  0.  6.
  0.  6.  3.  8.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10] -> size -> 41 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 28.551328659057617



action possibilites: [-1] 
expected returns: [[95.41561]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11. 11. 11.  0. 11.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 20. 30. 19. 29.  8.  0. 10.  0.  7.  5.  5. 10. 10.  9. 10.  6.] 
adversary cards in hand: [3. 0. 4. 6. 3.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  6.  0. 15.  6. 10.  0.  6.  0.  3.  0.  6.
  0.  6.  3.  8.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10] -> size -> 41 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 82.67517852783203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[88.97944]
 [99.10875]
 [93.86692]
 [96.10006]
 [90.85825]
 [97.09149]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11. 11. 11.  0. 11.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 20. 30. 19. 29.  8.  0. 10.  0.  7.  5.  5. 10. 10.  9. 10.  6.] 
adversary cards in hand: [3. 0. 4. 6. 3.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  6.  0. 15.  6. 10.  0.  6.  0.  3.  0.  6.
  0.  6.  3.  8.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10] -> size -> 41 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 95.41561126708984



buy possibilites: [-1] 
expected returns: [[110.88611]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11. 11. 11.  0. 11.] 
cards in discard: [1.] 
cards in deck: 35 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 19. 30. 19. 29.  8.  0. 10.  0.  7.  5.  5. 10. 10.  9. 10.  6.] 
adversary cards in hand: [3. 0. 4. 6. 3.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  6.  0. 15.  6. 10.  0.  6.  0.  3.  0.  6.
  0.  6.  3.  8.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10] -> size -> 41 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0 -80   0   0  54   0] 
sum of rewards: -101 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 99.10875701904297






Player: 1 
cards in hand: [3. 0. 4. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 4. 6. 3.] 
cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  6.  0. 15.  6. 10.  0.  6.  0.  3.  0.  6.
  0.  6.  3.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 19. 30. 19. 29.  8.  0. 10.  0.  7.  5.  5. 10. 10.  9. 10.  6.] 
adversary cards in hand: [ 0.  1. 29. 29. 11.] 
adversary cards in discard: [ 1. 25.  1. 11. 11. 11.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1] -> size -> 43 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 4. 6. 3.] 
cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  6.  0. 15.  6. 10.  0.  6.  0.  3.  0.  6.
  0.  6.  3.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 19. 30. 19. 29.  8.  0. 10.  0.  7.  5.  5. 10. 10.  9. 10.  6.] 
adversary cards in hand: [ 0.  1. 29. 29. 11.] 
adversary cards in discard: [ 1. 25.  1. 11. 11. 11.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1] -> size -> 43 
adversary victory points: 3
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [ 0.  1. 29. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 11.] 
expected returns: [[83.404724]
 [93.4575  ]
 [93.4575  ]
 [88.099976]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 29. 29. 11.] 
cards in discard: [ 1. 25.  1. 11. 11. 11.  0. 11.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 19. 30. 19. 29.  8.  0. 10.  0.  7.  5.  5. 10. 10.  9. 10.  6.] 
adversary cards in hand: [3. 3. 0. 8. 0.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  6.  0. 15.  6. 10.  0.  6.  0.  3.  0.  6.
  0.  6.  3.  8.  3.  0.  4.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10] -> size -> 41 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 110.8861083984375



action possibilites: [-1. 11. 11.] 
expected returns: [[80.96461]
 [85.4589 ]
 [85.4589 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11. 11.] 
cards in discard: [ 1. 25.  1. 11. 11. 11.  0. 11.  0. 29.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 19. 30. 19. 29.  8.  0. 10.  0.  7.  5.  5. 10. 10.  9. 10.  6.] 
adversary cards in hand: [3. 3. 0. 8. 0.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  6.  0. 15.  6. 10.  0.  6.  0.  3.  0.  6.
  0.  6.  3.  8.  3.  0.  4.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10] -> size -> 41 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 85.83985137939453



action possibilites: [-1] 
expected returns: [[94.80004]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.] 
cards in discard: [ 1. 25.  1. 11. 11. 11.  0. 11.  0. 29.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 18. 30. 19. 29.  8.  0. 10.  0.  7.  5.  5. 10. 10.  9. 10.  6.] 
adversary cards in hand: [3. 3. 0. 8. 0.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  6.  0. 15.  6. 10.  0.  6.  0.  3.  0.  6.
  0.  6.  3.  8.  3.  0.  4.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10] -> size -> 41 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0 -90   0   0  27   0] 
sum of rewards: -118 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 83.31472778320312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[85.98751 ]
 [96.041756]
 [90.81196 ]
 [93.02357 ]
 [87.8352  ]
 [93.94976 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.] 
cards in discard: [ 1. 25.  1. 11. 11. 11.  0. 11.  0. 29.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1] -> size -> 44 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 18. 30. 19. 29.  8.  0. 10.  0.  7.  5.  5. 10. 10.  9. 10.  6.] 
adversary cards in hand: [3. 3. 0. 8. 0.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  6.  0. 15.  6. 10.  0.  6.  0.  3.  0.  6.
  0.  6.  3.  8.  3.  0.  4.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10] -> size -> 41 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 94.80004119873047



buy possibilites: [-1] 
expected returns: [[66.55806]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.] 
cards in discard: [ 1. 25.  1. 11. 11. 11.  0. 11.  0. 29.  1.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 17. 30. 19. 29.  8.  0. 10.  0.  7.  5.  5. 10. 10.  9. 10.  6.] 
adversary cards in hand: [3. 3. 0. 8. 0.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  6.  0. 15.  6. 10.  0.  6.  0.  3.  0.  6.
  0.  6.  3.  8.  3.  0.  4.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10] -> size -> 41 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[  -5    0    0  -90    0    0   40    0    0    0    0 -100    0    0
   54    0] 
sum of rewards: -101 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 96.04174041748047






Player: 1 
cards in hand: [3. 3. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 8. 0.] 
cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  6.  0. 15.  6. 10.  0.  6.  0.  3.  0.  6.
  0.  6.  3.  8.  3.  0.  4.  6.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 17. 30. 19. 29.  8.  0. 10.  0.  7.  5.  5. 10. 10.  9. 10.  6.] 
adversary cards in hand: [ 0. 29. 25.  0.  1.] 
adversary cards in discard: [ 1. 25.  1. 11. 11. 11.  0. 11.  0. 29.  1.  1. 29. 11.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1] -> size -> 45 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 8. 0.] 
cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  6.  0. 15.  6. 10.  0.  6.  0.  3.  0.  6.
  0.  6.  3.  8.  3.  0.  4.  6.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 17. 30. 19. 29.  8.  0. 10.  0.  7.  5.  5. 10. 10.  9. 10.  6.] 
adversary cards in hand: [ 0. 29. 25.  0.  1.] 
adversary cards in discard: [ 1. 25.  1. 11. 11. 11.  0. 11.  0. 29.  1.  1. 29. 11.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1] -> size -> 45 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 8. 0.] 
cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  6.  0. 15.  6. 10.  0.  6.  0.  3.  0.  6.
  0.  6.  3.  8.  3.  0.  4.  6.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 17. 30. 18. 29.  8.  0. 10.  0.  7.  5.  5. 10. 10.  9. 10.  6.] 
adversary cards in hand: [ 0. 29. 25.  0.  1.] 
adversary cards in discard: [ 1. 25.  1. 11. 11. 11.  0. 11.  0. 29.  1.  1. 29. 11.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1] -> size -> 45 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 25.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[ 91.25208 ]
 [101.917244]
 [113.51452 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 25.  0.  1.] 
cards in discard: [ 1. 25.  1. 11. 11. 11.  0. 11.  0. 29.  1.  1. 29. 11.  1. 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 17. 30. 18. 29.  8.  0. 10.  0.  7.  5.  5. 10. 10.  9. 10.  6.] 
adversary cards in hand: [3. 0. 0. 8. 0.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  6.  0. 15.  6. 10.  0.  6.  0.  3.  0.  6.
  0.  6.  3.  8.  3.  0.  4.  6.  3.  3.  3.  3.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3] -> size -> 42 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 66.55805969238281



action possibilites: [-1] 
expected returns: [[95.886116]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  1. 15. 25.] 
cards in discard: [ 1. 25.  1. 11. 11. 11.  0. 11.  0. 29.  1.  1. 29. 11.  1. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 17. 30. 18. 29.  8.  0. 10.  0.  7.  5.  5. 10. 10.  9. 10.  6.] 
adversary cards in hand: [3. 0. 0. 8. 0.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  6.  0. 15.  6. 10.  0.  6.  0.  3.  0.  6.
  0.  6.  3.  8.  3.  0.  4.  6.  3.  3.  3.  3.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3] -> size -> 42 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 113.5145263671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 83.002464]
 [ 93.60359 ]
 [ 88.10224 ]
 [ 90.73384 ]
 [ 90.44987 ]
 [100.16548 ]
 [ 76.331665]
 [ 84.94851 ]
 [ 86.93278 ]
 [ 91.34668 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  1. 15. 25.] 
cards in discard: [ 1. 25.  1. 11. 11. 11.  0. 11.  0. 29.  1.  1. 29. 11.  1. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1] -> size -> 45 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 17. 30. 18. 29.  8.  0. 10.  0.  7.  5.  5. 10. 10.  9. 10.  6.] 
adversary cards in hand: [3. 0. 0. 8. 0.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  6.  0. 15.  6. 10.  0.  6.  0.  3.  0.  6.
  0.  6.  3.  8.  3.  0.  4.  6.  3.  3.  3.  3.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3] -> size -> 42 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 95.88611602783203



buy possibilites: [-1] 
expected returns: [[55.474167]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  1. 15. 25.] 
cards in discard: [ 1. 25.  1. 11. 11. 11.  0. 11.  0. 29.  1.  1. 29. 11.  1. 11. 29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 17. 30. 18. 29.  8.  0. 10.  0.  7.  5.  4. 10. 10.  9. 10.  6.] 
adversary cards in hand: [3. 0. 0. 8. 0.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  6.  0. 15.  6. 10.  0.  6.  0.  3.  0.  6.
  0.  6.  3.  8.  3.  0.  4.  6.  3.  3.  3.  3.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3] -> size -> 42 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0 -110    0    0
  128    0] 
sum of rewards: -87 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 100.16548919677734






Player: 1 
cards in hand: [3. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 8. 0.] 
cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  6.  0. 15.  6. 10.  0.  6.  0.  3.  0.  6.
  0.  6.  3.  8.  3.  0.  4.  6.  3.  3.  3.  3.  0.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 17. 30. 18. 29.  8.  0. 10.  0.  7.  5.  4. 10. 10.  9. 10.  6.] 
adversary cards in hand: [29.  1.  3. 15.  0.] 
adversary cards in discard: [ 1. 25.  1. 11. 11. 11.  0. 11.  0. 29.  1.  1. 29. 11.  1. 11. 29. 25.
  0. 29.  0.  1. 15. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29] -> size -> 46 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8. 0.] 
cards in discard: [ 3.  0.  3.  3.  0.  3.  0.  6.  0. 15.  6. 10.  0.  6.  0.  3.  0.  6.
  0.  6.  3.  8.  3.  0.  4.  6.  3.  3.  3.  3.  0.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 17. 30. 18. 29.  8.  0. 10.  0.  7.  5.  4. 10. 10.  9. 10.  6.] 
adversary cards in hand: [29.  1.  3. 15.  0.] 
adversary cards in discard: [ 1. 25.  1. 11. 11. 11.  0. 11.  0. 29.  1.  1. 29. 11.  1. 11. 29. 25.
  0. 29.  0.  1. 15. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29] -> size -> 46 
adversary victory points: 3
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [29.  1.  3. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
expected returns: [[46.105686]
 [52.105106]
 [43.078312]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  3. 15.  0.] 
cards in discard: [ 1. 25.  1. 11. 11. 11.  0. 11.  0. 29.  1.  1. 29. 11.  1. 11. 29. 25.
  0. 29.  0.  1. 15. 25.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 17. 30. 18. 29.  8.  0. 10.  0.  7.  5.  4. 10. 10.  9. 10.  6.] 
adversary cards in hand: [0. 0. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3] -> size -> 42 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 55.47416687011719



action possibilites: [-1. 15.] 
expected returns: [[33.005978]
 [30.457476]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  1.] 
cards in discard: [ 1. 25.  1. 11. 11. 11.  0. 11.  0. 29.  1.  1. 29. 11.  1. 11. 29. 25.
  0. 29.  0.  1. 15. 25.  1.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29] -> size -> 46 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 17. 30. 18. 29.  8.  0. 10.  0.  7.  5.  4. 10. 10.  9. 10.  6.] 
adversary cards in hand: [0. 0. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3] -> size -> 42 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 52.70798873901367





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[28.199194]
 [34.25945 ]
 [31.118494]
 [32.61472 ]
 [32.4586  ]
 [38.013947]
 [24.397228]
 [29.317652]
 [30.457476]
 [33.005974]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  1.] 
cards in discard: [ 1. 25.  1. 11. 11. 11.  0. 11.  0. 29.  1.  1. 29. 11.  1. 11. 29. 25.
  0. 29.  0.  1. 15. 25.  1.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29] -> size -> 46 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 17. 30. 18. 29.  8.  0. 10.  0.  7.  5.  4. 10. 10.  9. 10.  6.] 
adversary cards in hand: [0. 0. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3] -> size -> 42 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 33.0059814453125



buy possibilites: [-1] 
expected returns: [[36.535385]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  1.] 
cards in discard: [ 1. 25.  1. 11. 11. 11.  0. 11.  0. 29.  1.  1. 29. 11.  1. 11. 29. 25.
  0. 29.  0.  1. 15. 25.  1.  3. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 17. 30. 18. 29.  8.  0. 10.  0.  7.  5.  3. 10. 10.  9. 10.  6.] 
adversary cards in hand: [0. 0. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3] -> size -> 42 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0 -120    0    0
  128    0] 
sum of rewards: -97 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 38.01395797729492






Player: 1 
cards in hand: [0. 0. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 6.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 17. 30. 18. 29.  8.  0. 10.  0.  7.  5.  3. 10. 10.  9. 10.  6.] 
adversary cards in hand: [ 3.  1. 25.  0.  1.] 
adversary cards in discard: [ 1. 25.  1. 11. 11. 11.  0. 11.  0. 29.  1.  1. 29. 11.  1. 11. 29. 25.
  0. 29.  0.  1. 15. 25.  1.  3. 29. 29. 15.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29] -> size -> 47 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 6.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 17. 30. 18. 29.  8.  0. 10.  0.  7.  5.  3. 10. 10.  9. 10.  6.] 
adversary cards in hand: [ 3.  1. 25.  0.  1.] 
adversary cards in discard: [ 1. 25.  1. 11. 11. 11.  0. 11.  0. 29.  1.  1. 29. 11.  1. 11. 29. 25.
  0. 29.  0.  1. 15. 25.  1.  3. 29. 29. 15.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29] -> size -> 47 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 6.] 
cards in discard: [0.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 17. 30. 18. 29.  8.  0. 10.  0.  7.  5.  3. 10. 10.  9. 10.  6.] 
adversary cards in hand: [ 3.  1. 25.  0.  1.] 
adversary cards in discard: [ 1. 25.  1. 11. 11. 11.  0. 11.  0. 29.  1.  1. 29. 11.  1. 11. 29. 25.
  0. 29.  0.  1. 15. 25.  1.  3. 29. 29. 15.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29] -> size -> 47 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [ 3.  1. 25.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[83.66723]
 [99.52706]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 25.  0.  1.] 
cards in discard: [ 1. 25.  1. 11. 11. 11.  0. 11.  0. 29.  1.  1. 29. 11.  1. 11. 29. 25.
  0. 29.  0.  1. 15. 25.  1.  3. 29. 29. 15.  0.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 17. 30. 18. 29.  8.  0. 10.  0.  7.  5.  3. 10. 10.  9. 10.  6.] 
adversary cards in hand: [6. 8. 3. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 6. 6.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0] -> size -> 43 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 36.53538513183594



action possibilites: [-1] 
expected returns: [[67.542755]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  0.  1.  1. 15.] 
cards in discard: [ 1. 25.  1. 11. 11. 11.  0. 11.  0. 29.  1.  1. 29. 11.  1. 11. 29. 25.
  0. 29.  0.  1. 15. 25.  1.  3. 29. 29. 15.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 17. 30. 18. 29.  8.  0. 10.  0.  7.  5.  3. 10. 10.  9. 10.  6.] 
adversary cards in hand: [6. 8. 3. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 6. 6.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0] -> size -> 43 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 99.5270767211914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[61.56303 ]
 [69.19759 ]
 [58.212864]
 [65.06372 ]
 [56.312157]
 [66.9836  ]
 [66.78218 ]
 [81.6603  ]
 [74.22629 ]
 [57.511494]
 [64.433426]
 [62.876583]
 [57.67047 ]
 [64.25015 ]
 [67.54276 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  0.  1.  1. 15.] 
cards in discard: [ 1. 25.  1. 11. 11. 11.  0. 11.  0. 29.  1.  1. 29. 11.  1. 11. 29. 25.
  0. 29.  0.  1. 15. 25.  1.  3. 29. 29. 15.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29] -> size -> 47 
action values: 0 
buys: 1 
player value: 7 
card supply: [17. 17. 30. 18. 29.  8.  0. 10.  0.  7.  5.  3. 10. 10.  9. 10.  6.] 
adversary cards in hand: [6. 8. 3. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 6. 6.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0] -> size -> 43 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 67.54275512695312



buy possibilites: [-1] 
expected returns: [[66.6444]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  0.  1.  1. 15.] 
cards in discard: [ 1. 25.  1. 11. 11. 11.  0. 11.  0. 29.  1.  1. 29. 11.  1. 11. 29. 25.
  0. 29.  0.  1. 15. 25.  1.  3. 29. 29. 15.  0.  1. 25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25] -> size -> 48 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 17. 30. 18. 29.  8.  0. 10.  0.  7.  4.  3. 10. 10.  9. 10.  6.] 
adversary cards in hand: [6. 8. 3. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 6. 6.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0] -> size -> 43 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.  -120.     0.     0.    20.     0.     0.     0.
    0.  -130.     0.     0.    62.5    0. ] 
sum of rewards: -172.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 81.66031646728516






Player: 1 
cards in hand: [6. 8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 3. 0. 0.] 
cards in discard: [0. 0. 0. 0. 6. 6.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 17. 30. 18. 29.  8.  0. 10.  0.  7.  4.  3. 10. 10.  9. 10.  6.] 
adversary cards in hand: [11.  0. 29. 25.  3.] 
adversary cards in discard: [ 1. 25.  1. 11. 11. 11.  0. 11.  0. 29.  1.  1. 29. 11.  1. 11. 29. 25.
  0. 29.  0.  1. 15. 25.  1.  3. 29. 29. 15.  0.  1. 25. 25.  3.  1.  0.
  1.  1. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25] -> size -> 48 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 3. 0. 0.] 
cards in discard: [0. 0. 0. 0. 6. 6.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 17. 30. 18. 29.  8.  0. 10.  0.  7.  4.  3. 10. 10.  9. 10.  6.] 
adversary cards in hand: [11.  0. 29. 25.  3.] 
adversary cards in discard: [ 1. 25.  1. 11. 11. 11.  0. 11.  0. 29.  1.  1. 29. 11.  1. 11. 29. 25.
  0. 29.  0.  1. 15. 25.  1.  3. 29. 29. 15.  0.  1. 25. 25.  3.  1.  0.
  1.  1. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25] -> size -> 48 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 3. 0. 0.] 
cards in discard: [0. 0. 0. 0. 6. 6. 0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 17. 30. 18. 29.  8.  0. 10.  0.  7.  4.  3. 10. 10.  9. 10.  6.] 
adversary cards in hand: [11.  0. 29. 25.  3.] 
adversary cards in discard: [ 1. 25.  1. 11. 11. 11.  0. 11.  0. 29.  1.  1. 29. 11.  1. 11. 29. 25.
  0. 29.  0.  1. 15. 25.  1.  3. 29. 29. 15.  0.  1. 25. 25.  3.  1.  0.
  1.  1. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25] -> size -> 48 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [11.  0. 29. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 25.] 
expected returns: [[44.216465]
 [46.412914]
 [48.715294]
 [52.95322 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 29. 25.  3.] 
cards in discard: [ 1. 25.  1. 11. 11. 11.  0. 11.  0. 29.  1.  1. 29. 11.  1. 11. 29. 25.
  0. 29.  0.  1. 15. 25.  1.  3. 29. 29. 15.  0.  1. 25. 25.  3.  1.  0.
  1.  1. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 17. 30. 18. 29.  8.  0. 10.  0.  7.  4.  3. 10. 10.  9. 10.  6.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [0. 0. 0. 0. 6. 6. 0. 6. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0] -> size -> 44 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 66.64440155029297



action possibilites: [-1] 
expected returns: [[17.459045]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 29.  3.  1. 11.] 
cards in discard: [ 1. 25.  1. 11. 11. 11.  0. 11.  0. 29.  1.  1. 29. 11.  1. 11. 29. 25.
  0. 29.  0.  1. 15. 25.  1.  3. 29. 29. 15.  0.  1. 25. 25.  3.  1.  0.
  1.  1. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 17. 30. 18. 29.  8.  0. 10.  0.  7.  4.  3. 10. 10.  9. 10.  6.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [0. 0. 0. 0. 6. 6. 0. 6. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0] -> size -> 44 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 52.95320510864258





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[13.059677]
 [18.642132]
 [15.746012]
 [16.982468]
 [14.086344]
 [17.459036]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 29.  3.  1. 11.] 
cards in discard: [ 1. 25.  1. 11. 11. 11.  0. 11.  0. 29.  1.  1. 29. 11.  1. 11. 29. 25.
  0. 29.  0.  1. 15. 25.  1.  3. 29. 29. 15.  0.  1. 25. 25.  3.  1.  0.
  1.  1. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25] -> size -> 48 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 17. 30. 18. 29.  8.  0. 10.  0.  7.  4.  3. 10. 10.  9. 10.  6.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [0. 0. 0. 0. 6. 6. 0. 6. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0] -> size -> 44 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 17.45904541015625



buy possibilites: [-1] 
expected returns: [[5.253905]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 29.  3.  1. 11.] 
cards in discard: [ 1. 25.  1. 11. 11. 11.  0. 11.  0. 29.  1.  1. 29. 11.  1. 11. 29. 25.
  0. 29.  0.  1. 15. 25.  1.  3. 29. 29. 15.  0.  1. 25. 25.  3.  1.  0.
  1.  1. 15.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 16. 30. 18. 29.  8.  0. 10.  0.  7.  4.  3. 10. 10.  9. 10.  6.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [0. 0. 0. 0. 6. 6. 0. 6. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0] -> size -> 44 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0 -140    0    0
   54    0] 
sum of rewards: -191 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 18.642141342163086






Player: 1 
cards in hand: [3. 0. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 8.] 
cards in discard: [0. 0. 0. 0. 6. 6. 0. 6. 8. 3. 0. 0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3
  3  3  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 16. 30. 18. 29.  8.  0. 10.  0.  7.  4.  3. 10. 10.  9. 10.  6.] 
adversary cards in hand: [ 1.  1. 11.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1] -> size -> 49 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [0. 0. 0. 0. 6. 6. 0. 6. 8. 3. 0. 0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3
  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 16. 30. 18. 29.  8.  0. 10.  0.  7.  4.  3. 10. 10.  9. 10.  6.] 
adversary cards in hand: [ 1.  1. 11.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1] -> size -> 49 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [0. 0. 0. 0. 6. 6. 0. 6. 8. 3. 0. 0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3
  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 16. 30. 18. 29.  8.  0. 10.  0.  7.  4.  3. 10. 10.  9. 10.  6.] 
adversary cards in hand: [ 1.  1. 11.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1] -> size -> 49 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [0. 0. 0. 0. 6. 6. 0. 6. 8. 3. 0. 0. 0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3
  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 16. 30. 18. 29.  8.  0. 10.  0.  7.  4.  3. 10. 10.  9. 10.  6.] 
adversary cards in hand: [ 1.  1. 11.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1] -> size -> 49 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [ 1.  1. 11.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[57.442707]
 [61.527317]
 [61.527317]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1. 11.  1. 11.] 
cards in discard: [] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 16. 30. 18. 29.  8.  0. 10.  0.  7.  4.  3. 10. 10.  9. 10.  6.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 6. 6. 0. 6. 8. 3. 0. 0. 0. 8. 3. 3.] 
adversary owned cards: [ 0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3
  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0] -> size -> 43 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 5.253904819488525



action possibilites: [-1] 
expected returns: [[61.776745]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1.  1. 11.] 
cards in discard: [1.] 
cards in deck: 44 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 15. 30. 18. 29.  8.  0. 10.  0.  7.  4.  3. 10. 10.  9. 10.  6.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 6. 6. 0. 6. 8. 3. 0. 0. 0. 8. 3. 3.] 
adversary owned cards: [ 0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3
  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0] -> size -> 43 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0 -150    0    0
   27    0] 
sum of rewards: -228 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 59.56403732299805





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[52.152424]
 [61.84238 ]
 [47.51244 ]
 [56.820312]
 [44.903145]
 [59.190044]
 [58.95516 ]
 [75.81892 ]
 [67.884384]
 [46.541416]
 [56.000614]
 [53.942013]
 [46.762535]
 [55.765728]
 [59.876095]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1.  1. 11.] 
cards in discard: [1.] 
cards in deck: 44 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1] -> size -> 50 
action values: 0 
buys: 1 
player value: 6 
card supply: [15. 15. 30. 18. 29.  8.  0. 10.  0.  7.  4.  3. 10. 10.  9. 10.  6.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 6. 6. 0. 6. 8. 3. 0. 0. 0. 8. 3. 3.] 
adversary owned cards: [ 0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3
  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0] -> size -> 43 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 61.7767448425293



buy possibilites: [-1] 
expected returns: [[96.69789]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1.  1. 11.] 
cards in discard: [ 1. 25.] 
cards in deck: 44 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25] -> size -> 51 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 15. 30. 18. 29.  8.  0. 10.  0.  7.  3.  3. 10. 10.  9. 10.  6.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 6. 6. 0. 6. 8. 3. 0. 0. 0. 8. 3. 3.] 
adversary owned cards: [ 0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3
  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0] -> size -> 43 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.  -120.     0.     0.    20.     0.     0.     0.
    0.  -160.     0.     0.    62.5    0. ] 
sum of rewards: -202.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 75.81893157958984






Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 6. 6. 0. 6. 8. 3. 0. 0. 0. 8. 3. 3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3
  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 15. 30. 18. 29.  8.  0. 10.  0.  7.  3.  3. 10. 10.  9. 10.  6.] 
adversary cards in hand: [29.  1. 29. 25. 25.] 
adversary cards in discard: [ 1. 25. 11.  1.  1.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25] -> size -> 51 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 6. 6. 0. 6. 8. 3. 0. 0. 0. 8. 3. 3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3
  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0] -> size -> 43 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 15. 30. 18. 29.  8.  0. 10.  0.  7.  3.  3. 10. 10.  9. 10.  6.] 
adversary cards in hand: [29.  1. 29. 25. 25.] 
adversary cards in discard: [ 1. 25. 11.  1.  1.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25] -> size -> 51 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 6. 6. 0. 6. 8. 3. 0. 0. 0. 8. 3. 3. 8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3
  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 15. 30. 18. 29.  8.  0. 10.  0.  6.  3.  3. 10. 10.  9. 10.  6.] 
adversary cards in hand: [29.  1. 29. 25. 25.] 
adversary cards in discard: [ 1. 25. 11.  1.  1.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25] -> size -> 51 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [29.  1. 29. 25. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 25. 25.] 
expected returns: [[79.443344]
 [87.2323  ]
 [87.2323  ]
 [95.59467 ]
 [95.59467 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1. 29. 25. 25.] 
cards in discard: [ 1. 25. 11.  1.  1.  1. 11.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 15. 30. 18. 29.  8.  0. 10.  0.  6.  3.  3. 10. 10.  9. 10.  6.] 
adversary cards in hand: [6. 3. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 6. 6. 0. 6. 8. 3. 0. 0. 0. 8. 3. 3. 8. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3
  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8] -> size -> 44 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 96.69789123535156



action possibilites: [-1] 
expected returns: [[63.561108]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1. 29. 25.  1. 25.] 
cards in discard: [ 1. 25. 11.  1.  1.  1. 11.] 
cards in deck: 37 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 15. 30. 18. 29.  8.  0. 10.  0.  6.  3.  3. 10. 10.  9. 10.  6.] 
adversary cards in hand: [6. 3. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 6. 6. 0. 6. 8. 3. 0. 0. 0. 8. 3. 3. 8. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3
  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8] -> size -> 44 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 95.59467315673828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[54.32186 ]
 [63.917522]
 [58.944088]
 [61.307415]
 [61.065037]
 [69.85318 ]
 [48.32759 ]
 [56.091595]
 [57.894188]
 [61.93465 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1. 29. 25.  1. 25.] 
cards in discard: [ 1. 25. 11.  1.  1.  1. 11.] 
cards in deck: 37 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25] -> size -> 51 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 15. 30. 18. 29.  8.  0. 10.  0.  6.  3.  3. 10. 10.  9. 10.  6.] 
adversary cards in hand: [6. 3. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 6. 6. 0. 6. 8. 3. 0. 0. 0. 8. 3. 3. 8. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3
  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8] -> size -> 44 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 63.56110763549805



buy possibilites: [-1] 
expected returns: [[48.808704]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1. 29. 25.  1. 25.] 
cards in discard: [ 1. 25. 11.  1.  1.  1. 11. 29.] 
cards in deck: 37 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 15. 30. 18. 29.  8.  0. 10.  0.  6.  3.  2. 10. 10.  9. 10.  6.] 
adversary cards in hand: [6. 3. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 0. 6. 6. 0. 6. 8. 3. 0. 0. 0. 8. 3. 3. 8. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3
  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8] -> size -> 44 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0 -170    0    0
  128    0] 
sum of rewards: -147 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 69.85318756103516






Player: 1 
cards in hand: [6. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 0. 3.] 
cards in discard: [0. 0. 0. 0. 6. 6. 0. 6. 8. 3. 0. 0. 0. 8. 3. 3. 8. 3. 3. 0. 0. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3
  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 15. 30. 18. 29.  8.  0. 10.  0.  6.  3.  2. 10. 10.  9. 10.  6.] 
adversary cards in hand: [ 1.  0. 11.  1.  1.] 
adversary cards in discard: [ 1. 25. 11.  1.  1.  1. 11. 29. 25. 29.  1. 29. 25.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29] -> size -> 52 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0. 3.] 
cards in discard: [0. 0. 0. 0. 6. 6. 0. 6. 8. 3. 0. 0. 0. 8. 3. 3. 8. 3. 3. 0. 0. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3
  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 15. 30. 18. 29.  8.  0. 10.  0.  6.  3.  2. 10. 10.  9. 10.  6.] 
adversary cards in hand: [ 1.  0. 11.  1.  1.] 
adversary cards in discard: [ 1. 25. 11.  1.  1.  1. 11. 29. 25. 29.  1. 29. 25.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29] -> size -> 52 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0. 3.] 
cards in discard: [0. 0. 0. 0. 6. 6. 0. 6. 8. 3. 0. 0. 0. 8. 3. 3. 8. 3. 3. 0. 0. 0. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3
  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 15. 30. 18. 29.  8.  0. 10.  0.  6.  3.  2. 10. 10.  9. 10.  6.] 
adversary cards in hand: [ 1.  0. 11.  1.  1.] 
adversary cards in discard: [ 1. 25. 11.  1.  1.  1. 11. 29. 25. 29.  1. 29. 25.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29] -> size -> 52 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [ 1.  0. 11.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[60.36739]
 [63.80354]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 11.  1.  1.] 
cards in discard: [ 1. 25. 11.  1.  1.  1. 11. 29. 25. 29.  1. 29. 25.  1. 25.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 15. 30. 18. 29.  8.  0. 10.  0.  6.  3.  2. 10. 10.  9. 10.  6.] 
adversary cards in hand: [6. 3. 4. 3. 3.] 
adversary cards in discard: [0. 0. 0. 0. 6. 6. 0. 6. 8. 3. 0. 0. 0. 8. 3. 3. 8. 3. 3. 0. 0. 0. 0. 6.
 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3
  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0] -> size -> 45 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 48.8087043762207



action possibilites: [-1] 
expected returns: [[68.02474]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 1. 1.] 
cards in discard: [ 1. 25. 11.  1.  1.  1. 11. 29. 25. 29.  1. 29. 25.  1. 25.  1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 14. 30. 18. 29.  8.  0. 10.  0.  6.  3.  2. 10. 10.  9. 10.  6.] 
adversary cards in hand: [6. 3. 4. 3. 3.] 
adversary cards in discard: [0. 0. 0. 0. 6. 6. 0. 6. 8. 3. 0. 0. 0. 8. 3. 3. 8. 3. 3. 0. 0. 0. 0. 6.
 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3
  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0] -> size -> 45 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0 -180    0    0
   27    0] 
sum of rewards: -258 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 62.1640739440918





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[61.06428 ]
 [69.82636 ]
 [56.523933]
 [65.28602 ]
 [53.950695]
 [67.44282 ]
 [67.22136 ]
 [83.10485 ]
 [75.375595]
 [55.56742 ]
 [64.55097 ]
 [62.68101 ]
 [55.788883]
 [64.3295  ]
 [68.02475 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 1.] 
cards in discard: [ 1. 25. 11.  1.  1.  1. 11. 29. 25. 29.  1. 29. 25.  1. 25.  1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1] -> size -> 53 
action values: 0 
buys: 1 
player value: 7 
card supply: [14. 14. 30. 18. 29.  8.  0. 10.  0.  6.  3.  2. 10. 10.  9. 10.  6.] 
adversary cards in hand: [6. 3. 4. 3. 3.] 
adversary cards in discard: [0. 0. 0. 0. 6. 6. 0. 6. 8. 3. 0. 0. 0. 8. 3. 3. 8. 3. 3. 0. 0. 0. 0. 6.
 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3
  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0] -> size -> 45 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 68.02474212646484



buy possibilites: [-1] 
expected returns: [[66.26367]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 1.] 
cards in discard: [ 1. 25. 11.  1.  1.  1. 11. 29. 25. 29.  1. 29. 25.  1. 25.  1. 25.] 
cards in deck: 32 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25] -> size -> 54 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 14. 30. 18. 29.  8.  0. 10.  0.  6.  2.  2. 10. 10.  9. 10.  6.] 
adversary cards in hand: [6. 3. 4. 3. 3.] 
adversary cards in discard: [0. 0. 0. 0. 6. 6. 0. 6. 8. 3. 0. 0. 0. 8. 3. 3. 8. 3. 3. 0. 0. 0. 0. 6.
 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3
  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0] -> size -> 45 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.  -120.     0.     0.    20.     0.     0.     0.
    0.  -190.     0.     0.    62.5    0. ] 
sum of rewards: -232.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 83.1048355102539






Player: 1 
cards in hand: [6. 3. 4. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 4. 3. 3.] 
cards in discard: [0. 0. 0. 0. 6. 6. 0. 6. 8. 3. 0. 0. 0. 8. 3. 3. 8. 3. 3. 0. 0. 0. 0. 6.
 3. 0. 0. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3
  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 14. 30. 18. 29.  8.  0. 10.  0.  6.  2.  2. 10. 10.  9. 10.  6.] 
adversary cards in hand: [15. 11.  0.  0.  1.] 
adversary cards in discard: [ 1. 25. 11.  1.  1.  1. 11. 29. 25. 29.  1. 29. 25.  1. 25.  1. 25. 11.
  1.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25] -> size -> 54 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 4. 3. 3.] 
cards in discard: [0. 0. 0. 0. 6. 6. 0. 6. 8. 3. 0. 0. 0. 8. 3. 3. 8. 3. 3. 0. 0. 0. 0. 6.
 3. 0. 0. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3
  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0] -> size -> 45 
action values: 1 
buys: 1 
player value: 0 
card supply: [14. 14. 30. 18. 29.  8.  0. 10.  0.  6.  2.  2. 10. 10.  9. 10.  6.] 
adversary cards in hand: [15. 11.  0.  0.  1.] 
adversary cards in discard: [ 1. 25. 11.  1.  1.  1. 11. 29. 25. 29.  1. 29. 25.  1. 25.  1. 25. 11.
  1.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25] -> size -> 54 
adversary victory points: 3
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [15. 11.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
expected returns: [[52.885056]
 [49.28839 ]
 [56.194233]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.  0.  0.  1.] 
cards in discard: [ 1. 25. 11.  1.  1.  1. 11. 29. 25. 29.  1. 29. 25.  1. 25.  1. 25. 11.
  1.  0.  1.  1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 14. 30. 18. 29.  8.  0. 10.  0.  6.  2.  2. 10. 10.  9. 10.  6.] 
adversary cards in hand: [ 0. 10.  6.  0.  0.] 
adversary cards in discard: [0. 0. 0. 0. 6. 6. 0. 6. 8. 3. 0. 0. 0. 8. 3. 3. 8. 3. 3. 0. 0. 0. 0. 6.
 3. 0. 0. 3. 6. 3. 4. 3. 3.] 
adversary owned cards: [ 0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3
  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0] -> size -> 45 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 66.263671875



action possibilites: [-1] 
expected returns: [[41.49837]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  1.] 
cards in discard: [ 1. 25. 11.  1.  1.  1. 11. 29. 25. 29.  1. 29. 25.  1. 25.  1. 25. 11.
  1.  0.  1.  1.  1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1] -> size -> 55 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 13. 30. 18. 29.  8.  0. 10.  0.  6.  2.  2. 10. 10.  9. 10.  6.] 
adversary cards in hand: [ 0. 10.  6.  0.  0.] 
adversary cards in discard: [0. 0. 0. 0. 6. 6. 0. 6. 8. 3. 0. 0. 0. 8. 3. 3. 8. 3. 3. 0. 0. 0. 0. 6.
 3. 0. 0. 3. 6. 3. 4. 3. 3.] 
adversary owned cards: [ 0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3
  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0] -> size -> 45 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0 -200    0    0
   27    0] 
sum of rewards: -278 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 54.62250900268555





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[35.382267]
 [43.09197 ]
 [39.071712]
 [40.98179 ]
 [40.785713]
 [47.89428 ]
 [30.76436 ]
 [36.765453]
 [38.22546 ]
 [41.498367]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.  1.] 
cards in discard: [ 1. 25. 11.  1.  1.  1. 11. 29. 25. 29.  1. 29. 25.  1. 25.  1. 25. 11.
  1.  0.  1.  1.  1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1] -> size -> 55 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 13. 30. 18. 29.  8.  0. 10.  0.  6.  2.  2. 10. 10.  9. 10.  6.] 
adversary cards in hand: [ 0. 10.  6.  0.  0.] 
adversary cards in discard: [0. 0. 0. 0. 6. 6. 0. 6. 8. 3. 0. 0. 0. 8. 3. 3. 8. 3. 3. 0. 0. 0. 0. 6.
 3. 0. 0. 3. 6. 3. 4. 3. 3.] 
adversary owned cards: [ 0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3
  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0] -> size -> 45 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 41.49837112426758



buy possibilites: [-1] 
expected returns: [[22.83828]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.  1.] 
cards in discard: [ 1. 25. 11.  1.  1.  1. 11. 29. 25. 29.  1. 29. 25.  1. 25.  1. 25. 11.
  1.  0.  1.  1.  1. 29.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29] -> size -> 56 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 13. 30. 18. 29.  8.  0. 10.  0.  6.  2.  1. 10. 10.  9. 10.  6.] 
adversary cards in hand: [ 0. 10.  6.  0.  0.] 
adversary cards in discard: [0. 0. 0. 0. 6. 6. 0. 6. 8. 3. 0. 0. 0. 8. 3. 3. 8. 3. 3. 0. 0. 0. 0. 6.
 3. 0. 0. 3. 6. 3. 4. 3. 3.] 
adversary owned cards: [ 0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3
  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0] -> size -> 45 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0 -210    0    0
  128    0] 
sum of rewards: -187 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 47.894283294677734






Player: 1 
cards in hand: [ 0. 10.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  6.  0.  0.] 
cards in discard: [0. 0. 0. 0. 6. 6. 0. 6. 8. 3. 0. 0. 0. 8. 3. 3. 8. 3. 3. 0. 0. 0. 0. 6.
 3. 0. 0. 3. 6. 3. 4. 3. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3
  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 13. 30. 18. 29.  8.  0. 10.  0.  6.  2.  1. 10. 10.  9. 10.  6.] 
adversary cards in hand: [29.  1. 15. 29.  3.] 
adversary cards in discard: [ 1. 25. 11.  1.  1.  1. 11. 29. 25. 29.  1. 29. 25.  1. 25.  1. 25. 11.
  1.  0.  1.  1.  1. 29. 11. 15.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29] -> size -> 56 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  6.  0.  0.] 
cards in discard: [0. 0. 0. 0. 6. 6. 0. 6. 8. 3. 0. 0. 0. 8. 3. 3. 8. 3. 3. 0. 0. 0. 0. 6.
 3. 0. 0. 3. 6. 3. 4. 3. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3
  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0] -> size -> 45 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 13. 30. 18. 29.  8.  0. 10.  0.  6.  2.  1. 10. 10.  9. 10.  6.] 
adversary cards in hand: [29.  1. 15. 29.  3.] 
adversary cards in discard: [ 1. 25. 11.  1.  1.  1. 11. 29. 25. 29.  1. 29. 25.  1. 25.  1. 25. 11.
  1.  0.  1.  1.  1. 29. 11. 15.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29] -> size -> 56 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  6.  0.  0.] 
cards in discard: [0. 0. 0. 0. 6. 6. 0. 6. 8. 3. 0. 0. 0. 8. 3. 3. 8. 3. 3. 0. 0. 0. 0. 6.
 3. 0. 0. 3. 6. 3. 4. 3. 3. 1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3
  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0  1] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 12. 30. 18. 29.  8.  0. 10.  0.  6.  2.  1. 10. 10.  9. 10.  6.] 
adversary cards in hand: [29.  1. 15. 29.  3.] 
adversary cards in discard: [ 1. 25. 11.  1.  1.  1. 11. 29. 25. 29.  1. 29. 25.  1. 25.  1. 25. 11.
  1.  0.  1.  1.  1. 29. 11. 15.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29] -> size -> 56 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [29.  1. 15. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 29.] 
expected returns: [[15.974325]
 [22.390387]
 [12.850504]
 [22.390387]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1. 15. 29.  3.] 
cards in discard: [ 1. 25. 11.  1.  1.  1. 11. 29. 25. 29.  1. 29. 25.  1. 25.  1. 25. 11.
  1.  0.  1.  1.  1. 29. 11. 15.  0.  0.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 12. 30. 18. 29.  8.  0. 10.  0.  6.  2.  1. 10. 10.  9. 10.  6.] 
adversary cards in hand: [3. 6. 3. 6. 0.] 
adversary cards in discard: [ 0.  0.  0.  0.  6.  6.  0.  6.  8.  3.  0.  0.  0.  8.  3.  3.  8.  3.
  3.  0.  0.  0.  0.  6.  3.  0.  0.  3.  6.  3.  4.  3.  3.  1.  0. 10.
  6.  0.  0.] 
adversary owned cards: [ 0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3
  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0  1] -> size -> 46 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 22.838279724121094



action possibilites: [-1. 15. 29.] 
expected returns: [[19.235357]
 [16.817715]
 [24.653734]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29.  3.] 
cards in discard: [ 1. 25. 11.  1.  1.  1. 11. 29. 25. 29.  1. 29. 25.  1. 25.  1. 25. 11.
  1.  0.  1.  1.  1. 29. 11. 15.  0.  0.  1.  1. 25.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29] -> size -> 56 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 12. 30. 18. 29.  8.  0. 10.  0.  6.  2.  1. 10. 10.  9. 10.  6.] 
adversary cards in hand: [3. 6. 3. 6. 0.] 
adversary cards in discard: [ 0.  0.  0.  0.  6.  6.  0.  6.  8.  3.  0.  0.  0.  8.  3.  3.  8.  3.
  3.  0.  0.  0.  0.  6.  3.  0.  0.  3.  6.  3.  4.  3.  3.  1.  0. 10.
  6.  0.  0.] 
adversary owned cards: [ 0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3
  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0  1] -> size -> 46 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 23.057479858398438



action possibilites: [-1.] 
expected returns: [[6.7983603]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 1. 25. 11.  1.  1.  1. 11. 29. 25. 29.  1. 29. 25.  1. 25.  1. 25. 11.
  1.  0.  1.  1.  1. 29. 11. 15.  0.  0.  1.  1. 25. 15. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29] -> size -> 56 
action values: 1 
buys: 0 
player value: 2 
card supply: [14. 12. 30. 18. 29.  8.  0. 10.  0.  6.  2.  1. 10. 10.  9. 10.  6.] 
adversary cards in hand: [3. 6. 3. 6. 0.] 
adversary cards in discard: [ 0.  0.  0.  0.  6.  6.  0.  6.  8.  3.  0.  0.  0.  8.  3.  3.  8.  3.
  3.  0.  0.  0.  0.  6.  3.  0.  0.  3.  6.  3.  4.  3.  3.  1.  0. 10.
  6.  0.  0.] 
adversary owned cards: [ 0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3
  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0  1] -> size -> 46 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 20.4588680267334





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[2.4831557]
 [5.0931735]
 [6.2907043]
 [6.7983584]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 1. 25. 11.  1.  1.  1. 11. 29. 25. 29.  1. 29. 25.  1. 25.  1. 25. 11.
  1.  0.  1.  1.  1. 29. 11. 15.  0.  0.  1.  1. 25. 15. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29] -> size -> 56 
action values: 1 
buys: 1 
player value: 2 
card supply: [14. 12. 30. 18. 29.  8.  0. 10.  0.  6.  2.  1. 10. 10.  9. 10.  6.] 
adversary cards in hand: [3. 6. 3. 6. 0.] 
adversary cards in discard: [ 0.  0.  0.  0.  6.  6.  0.  6.  8.  3.  0.  0.  0.  8.  3.  3.  8.  3.
  3.  0.  0.  0.  0.  6.  3.  0.  0.  3.  6.  3.  4.  3.  3.  1.  0. 10.
  6.  0.  0.] 
adversary owned cards: [ 0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3
  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0  1] -> size -> 46 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 6.798360347747803






Player: 1 
cards in hand: [3. 6. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 6. 0.] 
cards in discard: [ 0.  0.  0.  0.  6.  6.  0.  6.  8.  3.  0.  0.  0.  8.  3.  3.  8.  3.
  3.  0.  0.  0.  0.  6.  3.  0.  0.  3.  6.  3.  4.  3.  3.  1.  0. 10.
  6.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3
  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0  1] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 12. 30. 18. 29.  8.  0. 10.  0.  6.  2.  1. 10. 10.  9. 10.  6.] 
adversary cards in hand: [ 0.  1.  1. 25.  0.] 
adversary cards in discard: [ 1. 25. 11.  1.  1.  1. 11. 29. 25. 29.  1. 29. 25.  1. 25.  1. 25. 11.
  1.  0.  1.  1.  1. 29. 11. 15.  0.  0.  1.  1. 25. 15. 29. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29] -> size -> 56 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 6. 0.] 
cards in discard: [ 0.  0.  0.  0.  6.  6.  0.  6.  8.  3.  0.  0.  0.  8.  3.  3.  8.  3.
  3.  0.  0.  0.  0.  6.  3.  0.  0.  3.  6.  3.  4.  3.  3.  1.  0. 10.
  6.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3
  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0  1] -> size -> 46 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 12. 30. 18. 29.  8.  0. 10.  0.  6.  2.  1. 10. 10.  9. 10.  6.] 
adversary cards in hand: [ 0.  1.  1. 25.  0.] 
adversary cards in discard: [ 1. 25. 11.  1.  1.  1. 11. 29. 25. 29.  1. 29. 25.  1. 25.  1. 25. 11.
  1.  0.  1.  1.  1. 29. 11. 15.  0.  0.  1.  1. 25. 15. 29. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29] -> size -> 56 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 6. 0.] 
cards in discard: [ 0.  0.  0.  0.  6.  6.  0.  6.  8.  3.  0.  0.  0.  8.  3.  3.  8.  3.
  3.  0.  0.  0.  0.  6.  3.  0.  0.  3.  6.  3.  4.  3.  3.  1.  0. 10.
  6.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3
  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0  1  0] -> size -> 47 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 12. 30. 18. 29.  8.  0. 10.  0.  6.  2.  1. 10. 10.  9. 10.  6.] 
adversary cards in hand: [ 0.  1.  1. 25.  0.] 
adversary cards in discard: [ 1. 25. 11.  1.  1.  1. 11. 29. 25. 29.  1. 29. 25.  1. 25.  1. 25. 11.
  1.  0.  1.  1.  1. 29. 11. 15.  0.  0.  1.  1. 25. 15. 29. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29] -> size -> 56 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [ 0.  1.  1. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[44.522366]
 [54.114872]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  1. 25.  0.] 
cards in discard: [ 1. 25. 11.  1.  1.  1. 11. 29. 25. 29.  1. 29. 25.  1. 25.  1. 25. 11.
  1.  0.  1.  1.  1. 29. 11. 15.  0.  0.  1.  1. 25. 15. 29. 29. 29.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 12. 30. 18. 29.  8.  0. 10.  0.  6.  2.  1. 10. 10.  9. 10.  6.] 
adversary cards in hand: [ 3.  0.  3.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3
  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0  1  0] -> size -> 47 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 6.798360347747803



action possibilites: [-1] 
expected returns: [[52.1488]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  1.  0.  3. 11.] 
cards in discard: [ 1. 25. 11.  1.  1.  1. 11. 29. 25. 29.  1. 29. 25.  1. 25.  1. 25. 11.
  1.  0.  1.  1.  1. 29. 11. 15.  0.  0.  1.  1. 25. 15. 29. 29. 29.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29] -> size -> 56 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 12. 30. 18. 29.  8.  0. 10.  0.  6.  2.  1. 10. 10.  9. 10.  6.] 
adversary cards in hand: [ 3.  0.  3.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3
  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0  1  0] -> size -> 47 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 54.11485290527344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[47.191746]
 [53.653896]
 [44.23321 ]
 [50.287167]
 [42.743443]
 [51.934895]
 [51.728928]
 [63.247044]
 [57.668575]
 [43.613007]
 [49.764668]
 [48.36219 ]
 [43.79713 ]
 [49.55872 ]
 [52.148808]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  1.  0.  3. 11.] 
cards in discard: [ 1. 25. 11.  1.  1.  1. 11. 29. 25. 29.  1. 29. 25.  1. 25.  1. 25. 11.
  1.  0.  1.  1.  1. 29. 11. 15.  0.  0.  1.  1. 25. 15. 29. 29. 29.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29] -> size -> 56 
action values: 0 
buys: 1 
player value: 6 
card supply: [13. 12. 30. 18. 29.  8.  0. 10.  0.  6.  2.  1. 10. 10.  9. 10.  6.] 
adversary cards in hand: [ 3.  0.  3.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3
  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0  1  0] -> size -> 47 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 52.148799896240234



buy possibilites: [-1] 
expected returns: [[31.748186]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  1.  0.  3. 11.] 
cards in discard: [ 1. 25. 11.  1.  1.  1. 11. 29. 25. 29.  1. 29. 25.  1. 25.  1. 25. 11.
  1.  0.  1.  1.  1. 29. 11. 15.  0.  0.  1.  1. 25. 15. 29. 29. 29.  3.
 25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29 25] -> size -> 57 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 12. 30. 18. 29.  8.  0. 10.  0.  6.  1.  1. 10. 10.  9. 10.  6.] 
adversary cards in hand: [ 3.  0.  3.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3
  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0  1  0] -> size -> 47 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.  -120.     0.     0.    20.     0.     0.     0.
    0.  -220.     0.     0.    62.5    0. ] 
sum of rewards: -262.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 63.24703598022461






Player: 1 
cards in hand: [ 3.  0.  3.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  8. 15.] 
cards in discard: [] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3
  8  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0  1  0] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 12. 30. 18. 29.  8.  0. 10.  0.  6.  1.  1. 10. 10.  9. 10.  6.] 
adversary cards in hand: [25.  1.  0. 29. 11.] 
adversary cards in discard: [ 1. 25. 11.  1.  1.  1. 11. 29. 25. 29.  1. 29. 25.  1. 25.  1. 25. 11.
  1.  0.  1.  1.  1. 29. 11. 15.  0.  0.  1.  1. 25. 15. 29. 29. 29.  3.
 25. 25.  0.  1.  1.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29 25] -> size -> 57 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8.] 
cards in discard: [] 
cards in deck: 42 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3  8
  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0  1  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 3 
card supply: [13. 12. 30. 18. 29.  8.  0. 10.  0.  6.  1.  1. 10. 10.  9. 10.  6.] 
adversary cards in hand: [25.  1.  0. 29. 11.] 
adversary cards in discard: [ 1. 25. 11.  1.  1.  1. 11. 29. 25. 29.  1. 29. 25.  1. 25.  1. 25. 11.
  1.  0.  1.  1.  1. 29. 11. 15.  0.  0.  1.  1. 25. 15. 29. 29. 29.  3.
 25. 25.  0.  1.  1.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29 25] -> size -> 57 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8.] 
cards in discard: [] 
cards in deck: 42 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3  8
  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0  1  0] -> size -> 46 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 12. 30. 18. 29.  8.  0. 10.  0.  6.  1.  1. 10. 10.  9. 10.  6.] 
adversary cards in hand: [25.  1.  0. 29. 11.] 
adversary cards in discard: [ 1. 25. 11.  1.  1.  1. 11. 29. 25. 29.  1. 29. 25.  1. 25.  1. 25. 11.
  1.  0.  1.  1.  1. 29. 11. 15.  0.  0.  1.  1. 25. 15. 29. 29. 29.  3.
 25. 25.  0.  1.  1.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29 25] -> size -> 57 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8.] 
cards in discard: [1.] 
cards in deck: 42 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3  8
  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0  1  0  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 11. 30. 18. 29.  8.  0. 10.  0.  6.  1.  1. 10. 10.  9. 10.  6.] 
adversary cards in hand: [25.  1.  0. 29. 11.] 
adversary cards in discard: [ 1. 25. 11.  1.  1.  1. 11. 29. 25. 29.  1. 29. 25.  1. 25.  1. 25. 11.
  1.  0.  1.  1.  1. 29. 11. 15.  0.  0.  1.  1. 25. 15. 29. 29. 29.  3.
 25. 25.  0.  1.  1.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29 25] -> size -> 57 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [25.  1.  0. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 11.] 
expected returns: [[38.53239 ]
 [48.189953]
 [42.676205]
 [40.37296 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  0. 29. 11.] 
cards in discard: [ 1. 25. 11.  1.  1.  1. 11. 29. 25. 29.  1. 29. 25.  1. 25.  1. 25. 11.
  1.  0.  1.  1.  1. 29. 11. 15.  0.  0.  1.  1. 25. 15. 29. 29. 29.  3.
 25. 25.  0.  1.  1.  0.  3. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29 25] -> size -> 57 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 11. 30. 18. 29.  8.  0. 10.  0.  6.  1.  1. 10. 10.  9. 10.  6.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [ 1. 15.  3.  3.  8.] 
adversary owned cards: [ 0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3  8
  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0  1  0  1] -> size -> 47 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 31.748186111450195



action possibilites: [-1] 
expected returns: [[7.9720216]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 29. 11.  3. 15.] 
cards in discard: [ 1. 25. 11.  1.  1.  1. 11. 29. 25. 29.  1. 29. 25.  1. 25.  1. 25. 11.
  1.  0.  1.  1.  1. 29. 11. 15.  0.  0.  1.  1. 25. 15. 29. 29. 29.  3.
 25. 25.  0.  1.  1.  0.  3. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29 25] -> size -> 57 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 11. 30. 18. 29.  8.  0. 10.  0.  6.  1.  1. 10. 10.  9. 10.  6.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [ 1. 15.  3.  3.  8.] 
adversary owned cards: [ 0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3  8
  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0  1  0  1] -> size -> 47 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 48.189945220947266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[4.3398166]
 [8.962074 ]
 [6.559129 ]
 [7.586124 ]
 [5.1831756]
 [7.972014 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 29. 11.  3. 15.] 
cards in discard: [ 1. 25. 11.  1.  1.  1. 11. 29. 25. 29.  1. 29. 25.  1. 25.  1. 25. 11.
  1.  0.  1.  1.  1. 29. 11. 15.  0.  0.  1.  1. 25. 15. 29. 29. 29.  3.
 25. 25.  0.  1.  1.  0.  3. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29 25] -> size -> 57 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 11. 30. 18. 29.  8.  0. 10.  0.  6.  1.  1. 10. 10.  9. 10.  6.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [ 1. 15.  3.  3.  8.] 
adversary owned cards: [ 0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3  8
  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0  1  0  1] -> size -> 47 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 7.972021579742432



buy possibilites: [-1] 
expected returns: [[16.825888]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 29. 11.  3. 15.] 
cards in discard: [ 1. 25. 11.  1.  1.  1. 11. 29. 25. 29.  1. 29. 25.  1. 25.  1. 25. 11.
  1.  0.  1.  1.  1. 29. 11. 15.  0.  0.  1.  1. 25. 15. 29. 29. 29.  3.
 25. 25.  0.  1.  1.  0.  3. 11.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29 25  1] -> size -> 58 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 10. 30. 18. 29.  8.  0. 10.  0.  6.  1.  1. 10. 10.  9. 10.  6.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [ 1. 15.  3.  3.  8.] 
adversary owned cards: [ 0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3  8
  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0  1  0  1] -> size -> 47 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0 -230    0    0
   54    0] 
sum of rewards: -281 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 8.962080001831055






Player: 1 
cards in hand: [0. 0. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [ 1. 15.  3.  3.  8.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3  8
  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0  1  0  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 10. 30. 18. 29.  8.  0. 10.  0.  6.  1.  1. 10. 10.  9. 10.  6.] 
adversary cards in hand: [11.  1. 29.  0. 11.] 
adversary cards in discard: [ 1. 25. 11.  1.  1.  1. 11. 29. 25. 29.  1. 29. 25.  1. 25.  1. 25. 11.
  1.  0.  1.  1.  1. 29. 11. 15.  0.  0.  1.  1. 25. 15. 29. 29. 29.  3.
 25. 25.  0.  1.  1.  0.  3. 11.  1. 25.  1.  0. 29. 11.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29 25  1] -> size -> 58 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [ 1. 15.  3.  3.  8.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3  8
  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0  1  0  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 10. 30. 18. 29.  8.  0. 10.  0.  6.  1.  1. 10. 10.  9. 10.  6.] 
adversary cards in hand: [11.  1. 29.  0. 11.] 
adversary cards in discard: [ 1. 25. 11.  1.  1.  1. 11. 29. 25. 29.  1. 29. 25.  1. 25.  1. 25. 11.
  1.  0.  1.  1.  1. 29. 11. 15.  0.  0.  1.  1. 25. 15. 29. 29. 29.  3.
 25. 25.  0.  1.  1.  0.  3. 11.  1. 25.  1.  0. 29. 11.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29 25  1] -> size -> 58 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [ 1. 15.  3.  3.  8. 10.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3  8
  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0  1  0  1 10] -> size -> 48 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 10. 30. 18. 29.  8.  0. 10.  0.  6.  1.  1. 10. 10.  8. 10.  6.] 
adversary cards in hand: [11.  1. 29.  0. 11.] 
adversary cards in discard: [ 1. 25. 11.  1.  1.  1. 11. 29. 25. 29.  1. 29. 25.  1. 25.  1. 25. 11.
  1.  0.  1.  1.  1. 29. 11. 15.  0.  0.  1.  1. 25. 15. 29. 29. 29.  3.
 25. 25.  0.  1.  1.  0.  3. 11.  1. 25.  1.  0. 29. 11.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29 25  1] -> size -> 58 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [11.  1. 29.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 11.] 
expected returns: [[27.828707]
 [30.023096]
 [32.474346]
 [30.023096]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1. 29.  0. 11.] 
cards in discard: [ 1. 25. 11.  1.  1.  1. 11. 29. 25. 29.  1. 29. 25.  1. 25.  1. 25. 11.
  1.  0.  1.  1.  1. 29. 11. 15.  0.  0.  1.  1. 25. 15. 29. 29. 29.  3.
 25. 25.  0.  1.  1.  0.  3. 11.  1. 25.  1.  0. 29. 11.  3. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29 25  1] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 10. 30. 18. 29.  8.  0. 10.  0.  6.  1.  1. 10. 10.  8. 10.  6.] 
adversary cards in hand: [ 6. 10.  6.  0.  3.] 
adversary cards in discard: [ 1. 15.  3.  3.  8. 10.  0.  0.  0.  6.  0.] 
adversary owned cards: [ 0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3  8
  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0  1  0  1 10] -> size -> 48 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 16.82588768005371



action possibilites: [-1. 11. 11.] 
expected returns: [[15.183119]
 [17.854723]
 [17.854723]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11. 11.] 
cards in discard: [ 1. 25. 11.  1.  1.  1. 11. 29. 25. 29.  1. 29. 25.  1. 25.  1. 25. 11.
  1.  0.  1.  1.  1. 29. 11. 15.  0.  0.  1.  1. 25. 15. 29. 29. 29.  3.
 25. 25.  0.  1.  1.  0.  3. 11.  1. 25.  1.  0. 29. 11.  3. 15. 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29 25  1] -> size -> 58 
action values: 1 
buys: 0 
player value: 1 
card supply: [13. 10. 30. 18. 29.  8.  0. 10.  0.  6.  1.  1. 10. 10.  8. 10.  6.] 
adversary cards in hand: [ 6. 10.  6.  0.  3.] 
adversary cards in discard: [ 1. 15.  3.  3.  8. 10.  0.  0.  0.  6.  0.] 
adversary owned cards: [ 0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3  8
  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0  1  0  1 10] -> size -> 48 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 28.980348587036133



action possibilites: [-1] 
expected returns: [[20.14394]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.] 
cards in discard: [ 1. 25. 11.  1.  1.  1. 11. 29. 25. 29.  1. 29. 25.  1. 25.  1. 25. 11.
  1.  0.  1.  1.  1. 29. 11. 15.  0.  0.  1.  1. 25. 15. 29. 29. 29.  3.
 25. 25.  0.  1.  1.  0.  3. 11.  1. 25.  1.  0. 29. 11.  3. 15. 11.  0.
  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29 25  1  1] -> size -> 59 
action values: 0 
buys: 0 
player value: 1 
card supply: [13.  9. 30. 18. 29.  8.  0. 10.  0.  6.  1.  1. 10. 10.  8. 10.  6.] 
adversary cards in hand: [ 6. 10.  6.  0.  3.] 
adversary cards in discard: [ 1. 15.  3.  3.  8. 10.  0.  0.  0.  6.  0.] 
adversary owned cards: [ 0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3  8
  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0  1  0  1 10] -> size -> 48 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0 -240    0    0
   27    0] 
sum of rewards: -298 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 16.58171272277832





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[14.733435]
 [21.570065]
 [18.02545 ]
 [19.537989]
 [15.993376]
 [20.14394 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.] 
cards in discard: [ 1. 25. 11.  1.  1.  1. 11. 29. 25. 29.  1. 29. 25.  1. 25.  1. 25. 11.
  1.  0.  1.  1.  1. 29. 11. 15.  0.  0.  1.  1. 25. 15. 29. 29. 29.  3.
 25. 25.  0.  1.  1.  0.  3. 11.  1. 25.  1.  0. 29. 11.  3. 15. 11.  0.
  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29 25  1  1] -> size -> 59 
action values: 0 
buys: 1 
player value: 3 
card supply: [13.  9. 30. 18. 29.  8.  0. 10.  0.  6.  1.  1. 10. 10.  8. 10.  6.] 
adversary cards in hand: [ 6. 10.  6.  0.  3.] 
adversary cards in discard: [ 1. 15.  3.  3.  8. 10.  0.  0.  0.  6.  0.] 
adversary owned cards: [ 0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3  8
  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0  1  0  1 10] -> size -> 48 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action -1
Learning step: 0
desired expected reward: 20.143939971923828



buy possibilites: [-1] 
expected returns: [[9.013773]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.] 
cards in discard: [ 1. 25. 11.  1.  1.  1. 11. 29. 25. 29.  1. 29. 25.  1. 25.  1. 25. 11.
  1.  0.  1.  1.  1. 29. 11. 15.  0.  0.  1.  1. 25. 15. 29. 29. 29.  3.
 25. 25.  0.  1.  1.  0.  3. 11.  1. 25.  1.  0. 29. 11.  3. 15. 11.  0.
  1.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29 25  1  1  1] -> size -> 60 
action values: 0 
buys: 0 
player value: 0 
card supply: [13.  8. 30. 18. 29.  8.  0. 10.  0.  6.  1.  1. 10. 10.  8. 10.  6.] 
adversary cards in hand: [ 6. 10.  6.  0.  3.] 
adversary cards in discard: [ 1. 15.  3.  3.  8. 10.  0.  0.  0.  6.  0.] 
adversary owned cards: [ 0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3  8
  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0  1  0  1 10] -> size -> 48 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0 -250    0    0
   54    0] 
sum of rewards: -281 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 21.570058822631836






Player: 1 
cards in hand: [ 6. 10.  6.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  6.  0.  3.] 
cards in discard: [ 1. 15.  3.  3.  8. 10.  0.  0.  0.  6.  0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3  8
  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0  1  0  1 10] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [13.  8. 30. 18. 29.  8.  0. 10.  0.  6.  1.  1. 10. 10.  8. 10.  6.] 
adversary cards in hand: [15.  1. 29. 11. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29 25  1  1  1] -> size -> 60 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 3. 3.] 
cards in discard: [ 1. 15.  3.  3.  8. 10.  0.  0.  0.  6.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3  8
  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0  1  0  1 10] -> size -> 48 
action values: 2 
buys: 0 
player value: 0 
card supply: [13.  8. 30. 18. 29.  8.  0. 10.  0.  6.  1.  1. 10. 10.  8. 10.  6.] 
adversary cards in hand: [15.  1. 29. 11. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29 25  1  1  1] -> size -> 60 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 3. 3.] 
cards in discard: [ 1. 15.  3.  3.  8. 10.  0.  0.  0.  6.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3  8
  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0  1  0  1 10] -> size -> 48 
action values: 0 
buys: 1 
player value: 1 
card supply: [13.  8. 30. 18. 29.  8.  0. 10.  0.  6.  1.  1. 10. 10.  8. 10.  6.] 
adversary cards in hand: [15.  1. 29. 11. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29 25  1  1  1] -> size -> 60 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 3. 3.] 
cards in discard: [ 1. 15.  3.  3.  8. 10.  0.  0.  0.  6.  0.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3  8
  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0  1  0  1 10
  0] -> size -> 49 
action values: 0 
buys: 0 
player value: 1 
card supply: [12.  8. 30. 18. 29.  8.  0. 10.  0.  6.  1.  1. 10. 10.  8. 10.  6.] 
adversary cards in hand: [15.  1. 29. 11. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29 25  1  1  1] -> size -> 60 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [15.  1. 29. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29. 11. 25.] 
expected returns: [[47.628048]
 [45.04183 ]
 [52.734386]
 [50.05273 ]
 [57.743347]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1. 29. 11. 25.] 
cards in discard: [] 
cards in deck: 55 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29 25  1  1  1] -> size -> 60 
action values: 1 
buys: 0 
player value: 0 
card supply: [12.  8. 30. 18. 29.  8.  0. 10.  0.  6.  1.  1. 10. 10.  8. 10.  6.] 
adversary cards in hand: [1. 3. 3. 6. 6.] 
adversary cards in discard: [ 1. 15.  3.  3.  8. 10.  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.  3.] 
adversary owned cards: [ 0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3  8
  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0  1  0  1 10
  0] -> size -> 49 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 9.013772964477539



action possibilites: [-1] 
expected returns: [[91.82894]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1. 29. 11. 11.  3.] 
cards in discard: [] 
cards in deck: 53 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29 25  1  1  1] -> size -> 60 
action values: 0 
buys: 0 
player value: 0 
card supply: [12.  8. 30. 18. 29.  8.  0. 10.  0.  6.  1.  1. 10. 10.  8. 10.  6.] 
adversary cards in hand: [1. 3. 3. 6. 6.] 
adversary cards in discard: [ 1. 15.  3.  3.  8. 10.  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.  3.] 
adversary owned cards: [ 0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3  8
  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0  1  0  1 10
  0] -> size -> 49 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 57.74335861206055





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[80.83787]
 [85.95055]
 [88.28575]
 [89.32599]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1. 29. 11. 11.  3.] 
cards in discard: [] 
cards in deck: 53 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29 25  1  1  1] -> size -> 60 
action values: 0 
buys: 1 
player value: 2 
card supply: [12.  8. 30. 18. 29.  8.  0. 10.  0.  6.  1.  1. 10. 10.  8. 10.  6.] 
adversary cards in hand: [1. 3. 3. 6. 6.] 
adversary cards in discard: [ 1. 15.  3.  3.  8. 10.  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.  3.] 
adversary owned cards: [ 0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3  8
  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0  1  0  1 10
  0] -> size -> 49 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 91.82894134521484






Player: 1 
cards in hand: [1. 3. 3. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3. 6. 6.] 
cards in discard: [ 1. 15.  3.  3.  8. 10.  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3  8
  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0  1  0  1 10
  0] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [12.  8. 30. 18. 29.  8.  0. 10.  0.  6.  1.  1. 10. 10.  8. 10.  6.] 
adversary cards in hand: [11.  1. 29. 11.  1.] 
adversary cards in discard: [25. 15.  1. 29. 11. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29 25  1  1  1] -> size -> 60 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 6. 6.] 
cards in discard: [ 1. 15.  3.  3.  8. 10.  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3  8
  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0  1  0  1 10
  0] -> size -> 49 
action values: 0 
buys: 1 
player value: 2 
card supply: [12.  8. 30. 18. 29.  8.  0. 10.  0.  6.  1.  1. 10. 10.  8. 10.  6.] 
adversary cards in hand: [11.  1. 29. 11.  1.] 
adversary cards in discard: [25. 15.  1. 29. 11. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29 25  1  1  1] -> size -> 60 
adversary victory points: 3
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [11.  1. 29. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 11.] 
expected returns: [[81.31585]
 [84.33966]
 [87.67192]
 [84.33966]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1. 29. 11.  1.] 
cards in discard: [25. 15.  1. 29. 11. 11.  3.] 
cards in deck: 48 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29 25  1  1  1] -> size -> 60 
action values: 1 
buys: 0 
player value: 0 
card supply: [12.  8. 30. 18. 29.  8.  0. 10.  0.  6.  1.  1. 10. 10.  8. 10.  6.] 
adversary cards in hand: [3. 8. 0. 6. 3.] 
adversary cards in discard: [ 1. 15.  3.  3.  8. 10.  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.  3.
  1.  3.  3.  6.  6.] 
adversary owned cards: [ 0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3  8
  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0  1  0  1 10
  0] -> size -> 49 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 89.32598114013672



action possibilites: [-1. 11. 11. 11.] 
expected returns: [[59.84431]
 [62.39745]
 [62.39745]
 [62.39745]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 11.] 
cards in discard: [25. 15.  1. 29. 11. 11.  3.  1.  1.] 
cards in deck: 47 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29 25  1  1  1] -> size -> 60 
action values: 1 
buys: 0 
player value: 1 
card supply: [12.  8. 30. 18. 29.  8.  0. 10.  0.  6.  1.  1. 10. 10.  8. 10.  6.] 
adversary cards in hand: [3. 8. 0. 6. 3.] 
adversary cards in discard: [ 1. 15.  3.  3.  8. 10.  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.  3.
  1.  3.  3.  6.  6.] 
adversary owned cards: [ 0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3  8
  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0  1  0  1 10
  0] -> size -> 49 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 82.93079376220703



action possibilites: [-1] 
expected returns: [[54.24067]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.] 
cards in discard: [25. 15.  1. 29. 11. 11.  3.  1.  1.  1.] 
cards in deck: 47 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29 25  1  1  1  1] -> size -> 61 
action values: 0 
buys: 0 
player value: 1 
card supply: [12.  7. 30. 18. 29.  8.  0. 10.  0.  6.  1.  1. 10. 10.  8. 10.  6.] 
adversary cards in hand: [3. 8. 0. 6. 3.] 
adversary cards in discard: [ 1. 15.  3.  3.  8. 10.  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.  3.
  1.  3.  3.  6.  6.] 
adversary owned cards: [ 0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3  8
  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0  1  0  1 10
  0] -> size -> 49 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0 -260    0    0
   27    0] 
sum of rewards: -318 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 61.20925521850586





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[49.481594]
 [54.24065 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.] 
cards in discard: [25. 15.  1. 29. 11. 11.  3.  1.  1.  1.] 
cards in deck: 47 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29 25  1  1  1  1] -> size -> 61 
action values: 0 
buys: 1 
player value: 1 
card supply: [12.  7. 30. 18. 29.  8.  0. 10.  0.  6.  1.  1. 10. 10.  8. 10.  6.] 
adversary cards in hand: [3. 8. 0. 6. 3.] 
adversary cards in discard: [ 1. 15.  3.  3.  8. 10.  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.  3.
  1.  3.  3.  6.  6.] 
adversary owned cards: [ 0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3  8
  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0  1  0  1 10
  0] -> size -> 49 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action -1
Learning step: 0
desired expected reward: 54.24066925048828






Player: 1 
cards in hand: [3. 8. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 6. 3.] 
cards in discard: [ 1. 15.  3.  3.  8. 10.  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.  3.
  1.  3.  3.  6.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3  8
  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0  1  0  1 10
  0] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [12.  7. 30. 18. 29.  8.  0. 10.  0.  6.  1.  1. 10. 10.  8. 10.  6.] 
adversary cards in hand: [ 0. 25.  1.  1.  1.] 
adversary cards in discard: [25. 15.  1. 29. 11. 11.  3.  1.  1.  1. 29. 11. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29 25  1  1  1  1] -> size -> 61 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 6. 3.] 
cards in discard: [ 1. 15.  3.  3.  8. 10.  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.  3.
  1.  3.  3.  6.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3  8
  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0  1  0  1 10
  0] -> size -> 49 
action values: 0 
buys: 1 
player value: 1 
card supply: [12.  7. 30. 18. 29.  8.  0. 10.  0.  6.  1.  1. 10. 10.  8. 10.  6.] 
adversary cards in hand: [ 0. 25.  1.  1.  1.] 
adversary cards in discard: [25. 15.  1. 29. 11. 11.  3.  1.  1.  1. 29. 11. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29 25  1  1  1  1] -> size -> 61 
adversary victory points: 3
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  1.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[27.644938]
 [38.258717]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  1.  1.  1.] 
cards in discard: [25. 15.  1. 29. 11. 11.  3.  1.  1.  1. 29. 11. 11. 11.] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29 25  1  1  1  1] -> size -> 61 
action values: 1 
buys: 0 
player value: 0 
card supply: [12.  7. 30. 18. 29.  8.  0. 10.  0.  6.  1.  1. 10. 10.  8. 10.  6.] 
adversary cards in hand: [8. 0. 3. 0. 3.] 
adversary cards in discard: [ 1. 15.  3.  3.  8. 10.  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.  3.
  1.  3.  3.  6.  6.  3.  8.  0.  6.  3.] 
adversary owned cards: [ 0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3  8
  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0  1  0  1 10
  0] -> size -> 49 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 54.24066925048828



action possibilites: [-1] 
expected returns: [[45.63545]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  1.  1. 25.  0.] 
cards in discard: [25. 15.  1. 29. 11. 11.  3.  1.  1.  1. 29. 11. 11. 11.] 
cards in deck: 40 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29 25  1  1  1  1] -> size -> 61 
action values: 0 
buys: 0 
player value: 0 
card supply: [12.  7. 30. 18. 29.  8.  0. 10.  0.  6.  1.  1. 10. 10.  8. 10.  6.] 
adversary cards in hand: [8. 0. 3. 0. 3.] 
adversary cards in discard: [ 1. 15.  3.  3.  8. 10.  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.  3.
  1.  3.  3.  6.  6.  3.  8.  0.  6.  3.] 
adversary owned cards: [ 0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3  8
  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0  1  0  1 10
  0] -> size -> 49 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 38.25872802734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[39.447033]
 [47.38637 ]
 [35.591892]
 [43.035793]
 [33.408695]
 [40.84904 ]
 [45.044014]
 [44.83091 ]
 [59.69714 ]
 [52.70678 ]
 [34.78154 ]
 [42.41229 ]
 [40.82219 ]
 [34.969406]
 [42.224182]
 [45.635452]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  1.  1. 25.  0.] 
cards in discard: [25. 15.  1. 29. 11. 11.  3.  1.  1.  1. 29. 11. 11. 11.] 
cards in deck: 40 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29 25  1  1  1  1] -> size -> 61 
action values: 0 
buys: 1 
player value: 8 
card supply: [12.  7. 30. 18. 29.  8.  0. 10.  0.  6.  1.  1. 10. 10.  8. 10.  6.] 
adversary cards in hand: [8. 0. 3. 0. 3.] 
adversary cards in discard: [ 1. 15.  3.  3.  8. 10.  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.  3.
  1.  3.  3.  6.  6.  3.  8.  0.  6.  3.] 
adversary owned cards: [ 0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3  8
  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0  1  0  1 10
  0] -> size -> 49 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 45.63544845581055



Player 1 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 9 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 9 
Chapel: 0 
Witch: 10 
Poacher: 9 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 0.  1.  1.  1. 25.  0.] 
cards in discard: [25. 15.  1. 29. 11. 11.  3.  1.  1.  1. 29. 11. 11. 11. 25.] 
cards in deck: 40 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25 29 29 25 25 25 11 11 29 29 11 11 11 15
 11 11 15 15 11 11  1  1  1  1  1  1  1  1  1  1 25 29  1  1  1 29 29 25
  1  1 25 29  1 25  1 29 25  1  1  1  1 25] -> size -> 62 
action values: 0 
buys: 0 
player value: 3 
card supply: [12.  7. 30. 18. 29.  8.  0. 10.  0.  6.  0.  1. 10. 10.  8. 10.  6.] 
adversary cards in hand: [8. 0. 3. 0. 3.] 
adversary cards in discard: [ 1. 15.  3.  3.  8. 10.  0.  0.  0.  6.  0.  0. 10.  6.  6.  0.  3.  3.
  1.  3.  3.  6.  6.  3.  8.  0.  6.  3.] 
adversary owned cards: [ 0  3  0  0 15  3  6  6  6  6  4  6  0  6  6  0  6  3  8  8  3  3  3  8
  3  0  0  0  3  3  0  0  0  0  3  0  3 10  3  0  0  0  8  0  1  0  1 10
  0] -> size -> 49 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -120        0        0       20        0
        0        0        0     -270        0        0      125        0] 
sum of rewards: -3000250 

action type: buy - action 25.0
Learning step: -120012.390625
desired expected reward: -119952.6953125



