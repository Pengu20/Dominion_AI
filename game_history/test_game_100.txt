 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[104.11825]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -240        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000245 

action type: buy - action -1
Learning step: -120002.6171875
desired expected reward: -120182.125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 86.64119 ]
 [117.13984 ]
 [106.02145 ]
 [ 57.526207]
 [104.99297 ]
 [124.154945]
 [104.77467 ]
 [135.20041 ]
 [ 75.23153 ]
 [ 93.65628 ]
 [105.7302  ]
 [102.152016]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 104.06806182861328



buy possibilites: [-1] 
expected returns: [[76.10926]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 135.2003936767578






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[89.987885]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [3. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 76.10926055908203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 75.020226]
 [103.71108 ]
 [ 93.22849 ]
 [ 49.19845 ]
 [110.324844]
 [ 92.05413 ]
 [ 81.57156 ]
 [ 89.58263 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [3. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 89.48975372314453



buy possibilites: [-1] 
expected returns: [[81.67985]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [29.  3.  0.  0.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [3. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0  54   0] 
sum of rewards: 19 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 110.32482147216797






Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [3. 0. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [3. 0. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [3. 0. 0. 0. 3. 0. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [3. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[87.43255]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 1] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 81.67984771728516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[70.62312 ]
 [88.166115]
 [44.19928 ]
 [87.01536 ]
 [84.615074]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 1] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 88.0048828125



buy possibilites: [-1] 
expected returns: [[77.09006]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 1] -> size -> 12 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 16  0] 
sum of rewards: 11 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 88.16610717773438






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11. 29.] 
adversary cards in discard: [3. 3. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3] -> size -> 13 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 1] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11. 29.] 
adversary cards in discard: [3. 3. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3] -> size -> 13 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11. 29.] 
adversary cards in discard: [3. 3. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3] -> size -> 13 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[53.279327]
 [72.606895]
 [82.4605  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11. 29.] 
cards in discard: [3. 3. 3. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 1. 3. 0.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 77.09005737304688



action possibilites: [-1. 11.] 
expected returns: [[ 87.25703]
 [106.46937]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.  0.] 
cards in discard: [3. 3. 3. 3. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 1. 3. 0.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 80.13993835449219



action possibilites: [-1] 
expected returns: [[82.32755]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 3.  3.  3.  3.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 1. 3. 0.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 122.49649810791016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 71.58997 ]
 [ 97.13828 ]
 [ 87.82346 ]
 [ 56.658054]
 [ 47.862362]
 [ 86.966995]
 [103.030685]
 [ 86.78671 ]
 [129.83536 ]
 [112.64856 ]
 [ 62.223846]
 [ 87.76897 ]
 [ 77.47735 ]
 [ 62.393883]
 [ 87.588684]
 [ 84.65684 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 3.  3.  3.  3.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 1. 3. 0.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 82.32755279541016



buy possibilites: [-1] 
expected returns: [[80.86677]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 3.  3.  3.  3.  0.  0. 10. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 1. 3. 0.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 285 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 129.8353729248047






Player: 1 
cards in hand: [0. 3. 1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 3. 0.] 
cards in discard: [14.  0.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25] -> size -> 15 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 3. 0.] 
cards in discard: [14.  0.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 28. 30.  8. 10. 10.  9. 10.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25] -> size -> 15 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 3. 0.] 
cards in discard: [14.  0.  0.  0.  0.  3.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  9. 10.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25] -> size -> 15 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[43.087402]
 [59.466995]
 [36.60572 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  9. 10.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 80.86676788330078



action possibilites: [-1] 
expected returns: [[51.02056]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  9. 10.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 67.5377197265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[41.146755]
 [63.629402]
 [55.355392]
 [20.282743]
 [68.942276]
 [54.433327]
 [46.1593  ]
 [52.588493]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  9. 10.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 51.02056121826172



buy possibilites: [-1] 
expected returns: [[46.186584]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [10. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  8. 10.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 68.9422836303711






Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  8. 10.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  0.  3.] 
adversary cards in discard: [10. 11. 11.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11] -> size -> 17 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  8. 10.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  0.  3.] 
adversary cards in discard: [10. 11. 11.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11] -> size -> 17 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  8. 10.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  0.  3.] 
adversary cards in discard: [10. 11. 11.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11] -> size -> 17 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 3. 29.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[22.507729]
 [47.892418]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  0.  3.] 
cards in discard: [10. 11. 11.  0.  0. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  8. 10.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 1.  0.  3.  1. 14.] 
adversary cards in discard: [10.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10] -> size -> 15 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 46.18658447265625



action possibilites: [-1. 25.] 
expected returns: [[ 62.350952]
 [102.01671 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  3. 25.] 
cards in discard: [10. 11. 11.  0.  0. 10.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  8. 10.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 1.  0.  3.  1. 14.] 
adversary cards in discard: [10.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10] -> size -> 15 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 45.87358093261719



action possibilites: [-1] 
expected returns: [[75.32695]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0. 3.] 
cards in discard: [10. 11. 11.  0.  0. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 28. 30.  8.  9. 10.  8. 10.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 1.  0.  3.  1. 14.] 
adversary cards in discard: [10.  0.  0.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6] -> size -> 16 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 102.01668548583984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 63.894295]
 [ 87.99953 ]
 [ 78.959656]
 [ 42.529495]
 [ 78.14111 ]
 [ 93.87214 ]
 [ 77.96628 ]
 [103.08883 ]
 [ 55.597775]
 [ 69.29752 ]
 [ 78.748215]
 [ 76.02683 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0. 3.] 
cards in discard: [10. 11. 11.  0.  0. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 28. 30.  8.  9. 10.  8. 10.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 1.  0.  3.  1. 14.] 
adversary cards in discard: [10.  0.  0.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6] -> size -> 16 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 75.32695007324219



buy possibilites: [-1] 
expected returns: [[67.20486]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0. 3.] 
cards in discard: [10. 11. 11.  0.  0. 10.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  9. 10.  8. 10.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 1.  0.  3.  1. 14.] 
adversary cards in discard: [10.  0.  0.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6] -> size -> 16 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 163 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 103.08882904052734






Player: 1 
cards in hand: [ 1.  0.  3.  1. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3.  1. 14.] 
cards in discard: [10.  0.  0.  3.  3.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  9. 10.  8. 10.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29] -> size -> 18 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3.  1. 14.] 
cards in discard: [10.  0.  0.  3.  3.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 28. 30.  8.  9. 10.  8. 10.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29] -> size -> 18 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3.  1. 14.] 
cards in discard: [10.  0.  0.  3.  3.  0.  6. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 28. 30.  8.  9.  9.  8. 10.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29] -> size -> 18 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[52.752876]
 [67.92659 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  9.  9.  8. 10.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16] -> size -> 17 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 67.2048568725586



action possibilites: [-1] 
expected returns: [[50.159424]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  9.  9.  8. 10.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16] -> size -> 17 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 74.57317352294922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[40.975906]
 [61.525803]
 [53.957104]
 [21.872513]
 [66.340004]
 [53.11235 ]
 [45.674576]
 [51.486813]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 28. 30.  8.  9.  9.  8. 10.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16] -> size -> 17 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 50.159423828125



buy possibilites: [-1] 
expected returns: [[22.678745]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  9.  9.  7. 10.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16] -> size -> 17 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 99 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 66.33999633789062






Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  9.  9.  7. 10.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0. 29.  3. 29.] 
adversary cards in discard: [10. 11. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11] -> size -> 20 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 28. 30.  8.  9.  9.  7. 10.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0. 29.  3. 29.] 
adversary cards in discard: [10. 11. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11] -> size -> 20 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 28. 30.  8.  9.  9.  7.  9.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0. 29.  3. 29.] 
adversary cards in discard: [10. 11. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11] -> size -> 20 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [10.  0. 29.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 29.] 
expected returns: [[29.092941]
 [23.237999]
 [53.643723]
 [53.643723]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29.  3. 29.] 
cards in discard: [10. 11. 11.  0.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  9.  9.  7.  9.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 1.  3.  0. 10.  0.] 
adversary cards in discard: [8. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16  8] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 22.67874526977539



action possibilites: [-1. 10. 29. 11.] 
expected returns: [[44.865993]
 [38.78347 ]
 [67.9781  ]
 [60.210663]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3. 29. 11.] 
cards in discard: [10. 11. 11.  0.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 28. 30.  8.  9.  9.  7.  9.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 1.  3.  0. 10.  0.] 
adversary cards in discard: [8. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16  8] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 51.52461624145508



action possibilites: [-1. 10. 11.] 
expected returns: [[ 91.45815 ]
 [ 84.8689  ]
 [108.092674]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3. 11.  0.] 
cards in discard: [10. 11. 11.  0.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 28. 30.  8.  9.  9.  7.  9.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 1.  3.  0. 10.  0.] 
adversary cards in discard: [8. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16  8] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 67.97810363769531



action possibilites: [-1] 
expected returns: [[101.22141]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [10. 11. 11.  0.  0.  3.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 28. 30.  8.  9.  9.  7.  9.  9.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 1.  3.  0. 10.  0.] 
adversary cards in discard: [8. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16  8] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 112 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 116.52094268798828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 88.73249 ]
 [113.40419 ]
 [104.35062 ]
 [ 65.01804 ]
 [103.522736]
 [119.17789 ]
 [103.34606 ]
 [128.24167 ]
 [ 79.56463 ]
 [ 94.39978 ]
 [104.129036]
 [101.32354 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [10. 11. 11.  0.  0.  3.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 28. 30.  8.  9.  9.  7.  9.  9.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 1.  3.  0. 10.  0.] 
adversary cards in discard: [8. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16  8] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1
Learning step: 0
desired expected reward: 101.2214126586914



buy possibilites: [-1] 
expected returns: [[52.665184]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [10. 11. 11.  0.  0.  3.  0. 10. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  9.  9.  7.  9.  9.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 1.  3.  0. 10.  0.] 
adversary cards in discard: [8. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16  8] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  30   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 213 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 128.24163818359375






Player: 1 
cards in hand: [ 1.  3.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0. 10.  0.] 
cards in discard: [8. 3. 3. 0. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  9.  9.  7.  9.  9.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  3. 10.] 
adversary cards in discard: [10. 11. 11.  0.  0.  3.  0. 10. 29. 29. 29. 11. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29] -> size -> 22 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 0. 1.] 
cards in discard: [8. 3. 3. 0. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16  8] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  9.  9.  7.  9.  9.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  3. 10.] 
adversary cards in discard: [10. 11. 11.  0.  0.  3.  0. 10. 29. 29. 29. 11. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29] -> size -> 22 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 1.] 
cards in discard: [8. 3. 3. 0. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 28. 30. 28. 30.  8.  9.  9.  7.  9.  9.  7.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  3. 10.] 
adversary cards in discard: [10. 11. 11.  0.  0.  3.  0. 10. 29. 29. 29. 11. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29] -> size -> 22 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 1.] 
cards in discard: [ 8.  3.  3.  0.  0.  0. 23.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16  8 23] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 28. 30.  8.  9.  9.  7.  9.  9.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  3. 10.] 
adversary cards in discard: [10. 11. 11.  0.  0.  3.  0. 10. 29. 29. 29. 11. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29] -> size -> 22 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[39.30169 ]
 [33.800827]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  3. 10.] 
cards in discard: [10. 11. 11.  0.  0.  3.  0. 10. 29. 29. 29. 11. 10.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  9.  9.  7.  9.  9.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [14.  3.  0.  6. 16.] 
adversary cards in discard: [ 8.  3.  3.  0.  0.  0. 23. 10.  1.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16  8 23] -> size -> 19 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 52.665184020996094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[28.811104]
 [40.55488 ]
 [12.674467]
 [39.781445]
 [38.32829 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  3. 10.] 
cards in discard: [10. 11. 11.  0.  0.  3.  0. 10. 29. 29. 29. 11. 10.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 28. 30.  8.  9.  9.  7.  9.  9.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [14.  3.  0.  6. 16.] 
adversary cards in discard: [ 8.  3.  3.  0.  0.  0. 23. 10.  1.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16  8 23] -> size -> 19 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 38.83430099487305



buy possibilites: [-1] 
expected returns: [[44.358765]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  3. 10.] 
cards in discard: [10. 11. 11.  0.  0.  3.  0. 10. 29. 29. 29. 11. 10.  0.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 30.  8.  9.  9.  7.  9.  9.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [14.  3.  0.  6. 16.] 
adversary cards in discard: [ 8.  3.  3.  0.  0.  0. 23. 10.  1.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16  8 23] -> size -> 19 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0 16  0] 
sum of rewards: 71 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 40.55487823486328






Player: 1 
cards in hand: [14.  3.  0.  6. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0.  6. 16.] 
cards in discard: [ 8.  3.  3.  0.  0.  0. 23. 10.  1.  3.  0.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16  8 23] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 30.  8.  9.  9.  7.  9.  9.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [11. 29. 11. 10. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3] -> size -> 23 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  0.  6. 16.] 
cards in discard: [ 8.  3.  3.  0.  0.  0. 23. 10.  1.  3.  0.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16  8 23] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 28. 30. 27. 30.  8.  9.  9.  7.  9.  9.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [11. 29. 11. 10. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3] -> size -> 23 
adversary victory points: 5
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [11. 29. 11. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 11. 10. 25.] 
expected returns: [[ 6.6357656]
 [17.956844 ]
 [23.84919  ]
 [17.956844 ]
 [ 2.1549406]
 [33.80113  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 11. 10. 25.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 30.  8.  9.  9.  7.  9.  9.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 6. 14.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16  8 23] -> size -> 19 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 44.3587646484375



action possibilites: [-1] 
expected returns: [[-9.732759]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 11. 10.  3. 10.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 30.  8.  8.  9.  7.  9.  9.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 6. 14.  0.  3.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16  8 23  6] -> size -> 20 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 32.83815383911133





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-18.963856]
 [-31.349705]
 [-12.01393 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29. 11. 10.  3. 10.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [30. 28. 30. 27. 30.  8.  8.  9.  7.  9.  9.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 6. 14.  0.  3.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16  8 23  6] -> size -> 20 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: -9.732759475708008






Player: 1 
cards in hand: [ 6. 14.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.  0.  3.  0.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16  8 23  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 30.  8.  8.  9.  7.  9.  9.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0. 10. 10.  3.  0.] 
adversary cards in discard: [25. 11. 29. 11. 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3] -> size -> 23 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.  0.  3.  0.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16  8 23  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 27. 30.  8.  8.  9.  7.  9.  9.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0. 10. 10.  3.  0.] 
adversary cards in discard: [25. 11. 29. 11. 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3] -> size -> 23 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.  0.  3.  0.] 
cards in discard: [6. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16  8 23  6  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 27. 30.  8.  8.  9.  7.  9.  9.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0. 10. 10.  3.  0.] 
adversary cards in discard: [25. 11. 29. 11. 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3] -> size -> 23 
adversary victory points: 5
player victory points: 2 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[22.252808]
 [17.274446]
 [17.274446]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.  3.  0.] 
cards in discard: [25. 11. 29. 11. 10.  3. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  8.  9.  7.  9.  9.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 3. 23.  1.  0.  3.] 
adversary cards in discard: [ 6.  0.  6. 14.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16  8 23  6  0] -> size -> 21 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -12.013930320739746





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[11.7922   ]
 [22.288284 ]
 [-3.3915968]
 [21.597794 ]
 [20.364904 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.  3.  0.] 
cards in discard: [25. 11. 29. 11. 10.  3. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 27. 30.  8.  8.  9.  7.  9.  9.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 3. 23.  1.  0.  3.] 
adversary cards in discard: [ 6.  0.  6. 14.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16  8 23  6  0] -> size -> 21 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 21.126262664794922



buy possibilites: [-1] 
expected returns: [[28.468819]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.  3.  0.] 
cards in discard: [25. 11. 29. 11. 10.  3. 10.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 26. 30.  8.  8.  9.  7.  9.  9.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 3. 23.  1.  0.  3.] 
adversary cards in discard: [ 6.  0.  6. 14.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16  8 23  6  0] -> size -> 21 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0  16   0] 
sum of rewards: 131 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 22.288284301757812






Player: 1 
cards in hand: [ 3. 23.  1.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 23.  1.  0.  3.] 
cards in discard: [ 6.  0.  6. 14.  0.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16  8 23  6  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 26. 30.  8.  8.  9.  7.  9.  9.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [25. 11. 29. 11. 10.  3. 10.  3.  0. 10. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3] -> size -> 24 
adversary victory points: 6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 23.  1.  0.  3.] 
cards in discard: [ 6.  0.  6. 14.  0.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16  8 23  6  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 26. 30.  8.  8.  9.  7.  9.  9.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [25. 11. 29. 11. 10.  3. 10.  3.  0. 10. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3] -> size -> 24 
adversary victory points: 6
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 23.  1.  0.  3.] 
cards in discard: [ 6.  0.  6. 14.  0.  3.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16  8 23  6  0  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 25. 30.  8.  8.  9.  7.  9.  9.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [25. 11. 29. 11. 10.  3. 10.  3.  0. 10. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3] -> size -> 24 
adversary victory points: 6
player victory points: 3 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[14.022461]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [25. 11. 29. 11. 10.  3. 10.  3.  0. 10. 10.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 25. 30.  8.  8.  9.  7.  9.  9.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  1. 10.] 
adversary cards in discard: [ 6.  0.  6. 14.  0.  3.  0.  3.  3. 23.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16  8 23  6  0  3] -> size -> 22 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 28.46881866455078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[  1.654758 ]
 [ 22.501759 ]
 [ 14.832329 ]
 [-10.393078 ]
 [-17.425262 ]
 [ 14.122652 ]
 [ 27.522835 ]
 [ 13.970684 ]
 [ 48.79577  ]
 [ 35.50199  ]
 [ -5.910142 ]
 [ 14.804951 ]
 [  6.392857 ]
 [ -5.7713947]
 [ 14.652981 ]
 [ 12.313805 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [25. 11. 29. 11. 10.  3. 10.  3.  0. 10. 10.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 28. 30. 25. 30.  8.  8.  9.  7.  9.  9.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  1. 10.] 
adversary cards in discard: [ 6.  0.  6. 14.  0.  3.  0.  3.  3. 23.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16  8 23  6  0  3] -> size -> 22 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 14.0224609375



buy possibilites: [-1] 
expected returns: [[20.90287]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [25. 11. 29. 11. 10.  3. 10.  3.  0. 10. 10.  3.  0. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 25. 30.  8.  8.  9.  7.  9.  8.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  1. 10.] 
adversary cards in discard: [ 6.  0.  6. 14.  0.  3.  0.  3.  3. 23.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16  8 23  6  0  3] -> size -> 22 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0  90   0   0   0   0   0   0   0   0   0   0 250   0] 
sum of rewards: 335 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 48.79576873779297






Player: 1 
cards in hand: [ 0.  0.  0.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  1. 10.] 
cards in discard: [ 6.  0.  6. 14.  0.  3.  0.  3.  3. 23.  1.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16  8 23  6  0  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 25. 30.  8.  8.  9.  7.  9.  8.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [11. 29.  3.  3.  3.] 
adversary cards in discard: [25. 11. 29. 11. 10.  3. 10.  3.  0. 10. 10.  3.  0. 25.  0.  0.  0.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25] -> size -> 25 
adversary victory points: 6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  1. 10.] 
cards in discard: [ 6.  0.  6. 14.  0.  3.  0.  3.  3. 23.  1.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16  8 23  6  0  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 28. 30. 25. 30.  8.  8.  9.  7.  9.  8.  7.  9.  9.  5. 10. 10.] 
adversary cards in hand: [11. 29.  3.  3.  3.] 
adversary cards in discard: [25. 11. 29. 11. 10.  3. 10.  3.  0. 10. 10.  3.  0. 25.  0.  0.  0.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25] -> size -> 25 
adversary victory points: 6
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  1. 10.] 
cards in discard: [ 6.  0.  6. 14.  0.  3.  0.  3.  3. 23.  1.  0.  3. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16  8 23  6  0  3 14] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 25. 30.  8.  8.  9.  7.  9.  8.  7.  8.  9.  5. 10. 10.] 
adversary cards in hand: [11. 29.  3.  3.  3.] 
adversary cards in discard: [25. 11. 29. 11. 10.  3. 10.  3.  0. 10. 10.  3.  0. 25.  0.  0.  0.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25] -> size -> 25 
adversary victory points: 6
player victory points: 3 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [11. 29.  3.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[-20.726994 ]
 [-10.323351 ]
 [ -4.2783165]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  3.  3.  3.] 
cards in discard: [25. 11. 29. 11. 10.  3. 10.  3.  0. 10. 10.  3.  0. 25.  0.  0.  0.  0.
  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 25. 30.  8.  8.  9.  7.  9.  8.  7.  8.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16  8 23  6  0  3 14] -> size -> 23 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 20.902870178222656



action possibilites: [-1. 11. 29.] 
expected returns: [[-10.514593 ]
 [  0.9129982]
 [  6.8745646]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  3.  3. 29.] 
cards in discard: [25. 11. 29. 11. 10.  3. 10.  3.  0. 10. 10.  3.  0. 25.  0.  0.  0.  0.
  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 25. 30.  8.  8.  9.  7.  9.  8.  7.  8.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16  8 23  6  0  3 14] -> size -> 23 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: -4.278310298919678



action possibilites: [-1. 11. 11.] 
expected returns: [[21.95959 ]
 [35.274483]
 [35.274483]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  3.  3. 11.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 25. 30.  8.  8.  9.  7.  9.  8.  7.  8.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16  8 23  6  0  3 14] -> size -> 23 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 6.874560832977295



action possibilites: [-1] 
expected returns: [[24.299067]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3. 11.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 25. 30.  8.  8.  9.  7.  9.  8.  7.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16  8 23  6  0  3 14] -> size -> 23 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 172 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 42.52500915527344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[14.778265 ]
 [27.30761  ]
 [-3.9438672]
 [26.512264 ]
 [25.002125 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3. 11.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 25. 30.  8.  8.  9.  7.  9.  8.  7.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16  8 23  6  0  3 14] -> size -> 23 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: take_action - action -1
Learning step: 0
desired expected reward: 24.2990665435791



buy possibilites: [-1] 
expected returns: [[10.531633]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3. 11.] 
cards in discard: [10.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 24. 30.  8.  8.  9.  7.  9.  8.  7.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16  8 23  6  0  3 14] -> size -> 23 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0  16   0] 
sum of rewards: 191 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 27.307605743408203






Player: 1 
cards in hand: [ 0.  3.  0.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  8. 16.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16  8 23  6  0  3 14] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 24. 30.  8.  8.  9.  7.  9.  8.  7.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  3. 29.] 
adversary cards in discard: [10.  3. 29. 29. 11.  3.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3] -> size -> 27 
adversary victory points: 7
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [16.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 24. 30.  8.  8.  8.  7.  9.  8.  7.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  3. 29.] 
adversary cards in discard: [10.  3. 29. 29. 11.  3.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3] -> size -> 27 
adversary victory points: 7
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [16.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 24. 30.  8.  8.  8.  7.  9.  8.  7.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  3. 29.] 
adversary cards in discard: [10.  3. 29. 29. 11.  3.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3] -> size -> 27 
adversary victory points: 7
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [16.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 23. 30.  8.  8.  8.  7.  9.  8.  7.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  3. 29.] 
adversary cards in discard: [10.  3. 29. 29. 11.  3.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3] -> size -> 27 
adversary victory points: 7
player victory points: 4 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[ -6.74904 ]
 [-11.028431]
 [  8.943737]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3. 29.] 
cards in discard: [10.  3. 29. 29. 11.  3.  3.  3. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 23. 30.  8.  8.  8.  7.  9.  8.  7.  8.  9.  4. 10. 10.] 
adversary cards in hand: [14.  3.  0.  1.  0.] 
adversary cards in discard: [16.  3. 16.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3] -> size -> 24 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 10.531633377075195



action possibilites: [-1. 10.] 
expected returns: [[-1.2301517]
 [-5.73756  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [10.  3. 29. 29. 11.  3.  3.  3. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 23. 30.  8.  8.  8.  7.  9.  8.  7.  8.  9.  4. 10. 10.] 
adversary cards in hand: [14.  3.  0.  1.  0.] 
adversary cards in discard: [16.  3. 16.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3] -> size -> 24 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 8.943735122680664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ -8.917904  ]
 [  6.28476   ]
 [  0.69173145]
 [-23.29358   ]
 [  0.17691374]
 [  9.881895  ]
 [  0.06650591]
 [ 15.59148   ]
 [-14.4175625 ]
 [ -5.4407215 ]
 [  0.5840001 ]
 [ -0.98025846]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [10.  3. 29. 29. 11.  3.  3.  3. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 23. 30.  8.  8.  8.  7.  9.  8.  7.  8.  9.  4. 10. 10.] 
adversary cards in hand: [14.  3.  0.  1.  0.] 
adversary cards in discard: [16.  3. 16.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3] -> size -> 24 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -1.230154037475586



buy possibilites: [-1] 
expected returns: [[-0.70969343]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [10.  3. 29. 29. 11.  3.  3.  3. 11. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 23. 30.  8.  8.  8.  7.  9.  8.  6.  8.  9.  4. 10. 10.] 
adversary cards in hand: [14.  3.  0.  1.  0.] 
adversary cards in discard: [16.  3. 16.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3] -> size -> 24 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 233 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 15.59146499633789






Player: 1 
cards in hand: [14.  3.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0.  1.  0.] 
cards in discard: [16.  3. 16.  0.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 23. 30.  8.  8.  8.  7.  9.  8.  6.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 3.  0. 10. 10.  3.] 
adversary cards in discard: [10.  3. 29. 29. 11.  3.  3.  3. 11. 29. 29.  0. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29] -> size -> 28 
adversary victory points: 7
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 0.] 
cards in discard: [16.  3. 16.  0.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 23. 30.  8.  8.  8.  7.  9.  8.  6.  8.  9.  4. 10. 10.] 
adversary cards in hand: [10. 10.  3.] 
adversary cards in discard: [10.  3. 29. 29. 11.  3.  3.  3. 11. 29. 29.  0. 10.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29] -> size -> 28 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0.] 
cards in discard: [16.  3. 16.  0.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 6 
card supply: [29. 28. 30. 23. 30.  8.  8.  8.  7.  9.  8.  6.  8.  9.  4. 10. 10.] 
adversary cards in hand: [10. 10.  3.] 
adversary cards in discard: [10.  3. 29. 29. 11.  3.  3.  3. 11. 29. 29.  0. 10.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29] -> size -> 28 
adversary victory points: 7
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0.] 
cards in discard: [16.  3. 16.  0.  3.  0. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 23. 30.  8.  8.  8.  7.  9.  8.  6.  8.  9.  4. 10.  9.] 
adversary cards in hand: [10. 10.  3.] 
adversary cards in discard: [10.  3. 29. 29. 11.  3.  3.  3. 11. 29. 29.  0. 10.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29] -> size -> 28 
adversary victory points: 7
player victory points: 4 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [10. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[-2.1292   ]
 [-7.5402393]
 [-7.5402393]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3.] 
cards in discard: [10.  3. 29. 29. 11.  3.  3.  3. 11. 29. 29.  0. 10.  0.  3.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 23. 30.  8.  8.  8.  7.  9.  8.  6.  8.  9.  4. 10.  9.] 
adversary cards in hand: [10.  0.  0.  3.  6.] 
adversary cards in discard: [16.  3. 16.  0.  3.  0. 15. 14.  3.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15] -> size -> 25 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0  90   0   0   0   0   0   0   0   0   0   0 703   0] 
sum of rewards: 788 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 29.719757080078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-11.99861  ]
 [-28.138676 ]
 [ -2.2585013]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  3.] 
cards in discard: [10.  3. 29. 29. 11.  3.  3.  3. 11. 29. 29.  0. 10.  0.  3.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29] -> size -> 28 
action values: 1 
buys: 1 
player value: 0 
card supply: [29. 28. 30. 23. 30.  8.  8.  8.  7.  9.  8.  6.  8.  9.  4. 10.  9.] 
adversary cards in hand: [10.  0.  0.  3.  6.] 
adversary cards in discard: [16.  3. 16.  0.  3.  0. 15. 14.  3.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15] -> size -> 25 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -2.1292073726654053



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10.  0.  0.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3.  6.] 
cards in discard: [16.  3. 16.  0.  3.  0. 15. 14.  3.  0.  1.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 23. 30.  8.  8.  8.  7.  9.  8.  6.  8.  9.  4. 10.  9.] 
adversary cards in hand: [25. 10. 11. 25.  0.] 
adversary cards in discard: [10.  3. 29. 29. 11.  3.  3.  3. 11. 29. 29.  0. 10.  0.  3.  0.  0.  3.
 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29] -> size -> 28 
adversary victory points: 7
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 6. 3.] 
cards in discard: [16.  3. 16.  0.  3.  0. 15. 14.  3.  0.  1.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 23. 30.  8.  8.  8.  7.  9.  8.  6.  8.  9.  4. 10.  9.] 
adversary cards in hand: [25. 10. 11. 25.  0.] 
adversary cards in discard: [10.  3. 29. 29. 11.  3.  3.  3. 11. 29. 29.  0. 10.  0.  3.  0.  0.  3.
 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29] -> size -> 28 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 3.] 
cards in discard: [16.  3. 16.  0.  3.  0. 15. 14.  3.  0.  1.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 23. 30.  8.  8.  8.  7.  9.  8.  6.  8.  9.  4. 10.  9.] 
adversary cards in hand: [25. 10. 11. 25.  0.] 
adversary cards in discard: [10.  3. 29. 29. 11.  3.  3.  3. 11. 29. 29.  0. 10.  0.  3.  0.  0.  3.
 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29] -> size -> 28 
adversary victory points: 7
player victory points: 4 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [25. 10. 11. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 11. 25.] 
expected returns: [[-14.773245]
 [  5.854465]
 [-18.382456]
 [ -6.520537]
 [  5.854465]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10. 11. 25.  0.] 
cards in discard: [10.  3. 29. 29. 11.  3.  3.  3. 11. 29. 29.  0. 10.  0.  3.  0.  0.  3.
 10. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 23. 30.  8.  8.  8.  7.  9.  8.  6.  8.  9.  4. 10.  9.] 
adversary cards in hand: [ 1.  0. 14.  6. 23.] 
adversary cards in discard: [16.  3. 16.  0.  3.  0. 15. 14.  3.  0.  1.  0. 10.  0.  0.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15] -> size -> 25 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -2.258507251739502



action possibilites: [-1] 
expected returns: [[-25.339766]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 25.  0.  0.  0.] 
cards in discard: [10.  3. 29. 29. 11.  3.  3.  3. 11. 29. 29.  0. 10.  0.  3.  0.  0.  3.
 10. 10.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 23. 30.  8.  7.  8.  7.  9.  8.  6.  8.  9.  4. 10.  9.] 
adversary cards in hand: [ 1.  0. 14.  6. 23.] 
adversary cards in discard: [16.  3. 16.  0.  3.  0. 15. 14.  3.  0.  1.  0. 10.  0.  0.  3.  6.  3.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15  6] -> size -> 26 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 5.854464054107666





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-31.57149 ]
 [-19.195278]
 [-23.886612]
 [-42.389286]
 [-16.163239]
 [-24.405285]
 [-28.811707]
 [-25.199472]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 25.  0.  0.  0.] 
cards in discard: [10.  3. 29. 29. 11.  3.  3.  3. 11. 29. 29.  0. 10.  0.  3.  0.  0.  3.
 10. 10.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 23. 30.  8.  7.  8.  7.  9.  8.  6.  8.  9.  4. 10.  9.] 
adversary cards in hand: [ 1.  0. 14.  6. 23.] 
adversary cards in discard: [16.  3. 16.  0.  3.  0. 15. 14.  3.  0.  1.  0. 10.  0.  0.  3.  6.  3.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15  6] -> size -> 26 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -25.339765548706055



buy possibilites: [-1] 
expected returns: [[-13.455091]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 25.  0.  0.  0.] 
cards in discard: [10.  3. 29. 29. 11.  3.  3.  3. 11. 29. 29.  0. 10.  0.  3.  0.  0.  3.
 10. 10.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 23. 30.  8.  7.  8.  6.  9.  8.  6.  8.  9.  4. 10.  9.] 
adversary cards in hand: [ 1.  0. 14.  6. 23.] 
adversary cards in discard: [16.  3. 16.  0.  3.  0. 15. 14.  3.  0.  1.  0. 10.  0.  0.  3.  6.  3.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15  6] -> size -> 26 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 159 

action type: buy - action 11.0
Learning step: 0
desired expected reward: -16.163240432739258






Player: 1 
cards in hand: [ 1.  0. 14.  6. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 14.  6. 23.] 
cards in discard: [16.  3. 16.  0.  3.  0. 15. 14.  3.  0.  1.  0. 10.  0.  0.  3.  6.  3.
  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 23. 30.  8.  7.  8.  6.  9.  8.  6.  8.  9.  4. 10.  9.] 
adversary cards in hand: [ 0. 25.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11] -> size -> 29 
adversary victory points: 7
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 14.  6. 23.] 
cards in discard: [16.  3. 16.  0.  3.  0. 15. 14.  3.  0.  1.  0. 10.  0.  0.  3.  6.  3.
  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 23. 30.  8.  7.  8.  6.  9.  8.  6.  8.  9.  4. 10.  9.] 
adversary cards in hand: [ 0. 25.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11] -> size -> 29 
adversary victory points: 7
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 14.  6. 23.] 
cards in discard: [16.  3. 16.  0.  3.  0. 15. 14.  3.  0.  1.  0. 10.  0.  0.  3.  6.  3.
  6. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15  6 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 23. 30.  8.  7.  8.  5.  9.  8.  6.  8.  9.  4. 10.  9.] 
adversary cards in hand: [ 0. 25.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11] -> size -> 29 
adversary victory points: 7
player victory points: 3 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[ 6.771054]
 [40.952423]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 23. 30.  8.  7.  8.  5.  9.  8.  6.  8.  9.  4. 10.  9.] 
adversary cards in hand: [ 6.  0. 14.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15  6 11] -> size -> 27 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: -13.45509147644043



action possibilites: [-1] 
expected returns: [[-8.2619505]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 29. 10.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 23. 30.  8.  6.  8.  5.  9.  8.  6.  8.  9.  4. 10.  9.] 
adversary cards in hand: [ 6.  0. 14.  3.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15  6 11  6] -> size -> 28 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 40.41621780395508





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-16.432089 ]
 [ -1.4649367]
 [ -6.970384 ]
 [-30.45882  ]
 [ -7.471555 ]
 [  2.1651626]
 [ -7.5774612]
 [  8.456409 ]
 [-21.803543 ]
 [-13.045643 ]
 [ -7.07806  ]
 [ -8.625359 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 29. 10.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 23. 30.  8.  6.  8.  5.  9.  8.  6.  8.  9.  4. 10.  9.] 
adversary cards in hand: [ 6.  0. 14.  3.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15  6 11  6] -> size -> 28 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: -8.261950492858887



buy possibilites: [-1] 
expected returns: [[3.709618]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 29. 10.] 
cards in discard: [29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 23. 30.  8.  6.  8.  5.  9.  8.  5.  8.  9.  4. 10.  9.] 
adversary cards in hand: [ 6.  0. 14.  3.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15  6 11  6] -> size -> 28 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 263 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 8.456401824951172






Player: 1 
cards in hand: [ 6.  0. 14.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 14.  3.  0.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15  6 11  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 23. 30.  8.  6.  8.  5.  9.  8.  5.  8.  9.  4. 10.  9.] 
adversary cards in hand: [10.  0. 11.  3. 10.] 
adversary cards in discard: [29. 25.  0.  0.  0.  0. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29] -> size -> 30 
adversary victory points: 7
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15  6 11  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 23. 30.  8.  6.  8.  5.  9.  8.  5.  8.  9.  4. 10.  9.] 
adversary cards in hand: [10.  3. 10.] 
adversary cards in discard: [29. 25.  0.  0.  0.  0. 29. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29] -> size -> 30 
adversary victory points: 7
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15  6 11  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 23. 30.  8.  6.  8.  5.  9.  8.  5.  8.  9.  4. 10.  9.] 
adversary cards in hand: [10.  3. 10.] 
adversary cards in discard: [29. 25.  0.  0.  0.  0. 29. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29] -> size -> 30 
adversary victory points: 7
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0.] 
cards in discard: [ 6. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15  6 11  6 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 23. 30.  8.  6.  8.  5.  9.  8.  5.  8.  9.  3. 10.  9.] 
adversary cards in hand: [10.  3. 10.] 
adversary cards in discard: [29. 25.  0.  0.  0.  0. 29. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29] -> size -> 30 
adversary victory points: 7
player victory points: 2 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [10.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[ 3.7197328 ]
 [-0.62418365]
 [-0.62418365]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10.] 
cards in discard: [29. 25.  0.  0.  0.  0. 29. 10.  0. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 23. 30.  8.  6.  8.  5.  9.  8.  5.  8.  9.  3. 10.  9.] 
adversary cards in hand: [0. 1. 6. 0. 1.] 
adversary cards in discard: [ 6. 10. 14.  6.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15  6 11  6 10] -> size -> 29 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0 767   0] 
sum of rewards: 912 

action type: discard_down_to_3_cards - action 9
Learning step: 0
desired expected reward: 49.84950637817383





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -4.1222143]
 [-18.286419 ]
 [  3.644877 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 10.] 
cards in discard: [29. 25.  0.  0.  0.  0. 29. 10.  0. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29] -> size -> 30 
action values: 1 
buys: 1 
player value: 0 
card supply: [29. 28. 30. 23. 30.  8.  6.  8.  5.  9.  8.  5.  8.  9.  3. 10.  9.] 
adversary cards in hand: [0. 1. 6. 0. 1.] 
adversary cards in discard: [ 6. 10. 14.  6.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15  6 11  6 10] -> size -> 29 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 3.7197203636169434



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 1. 6. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 6. 0. 1.] 
cards in discard: [ 6. 10. 14.  6.  0.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15  6 11  6 10] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 23. 30.  8.  6.  8.  5.  9.  8.  5.  8.  9.  3. 10.  9.] 
adversary cards in hand: [11. 29. 10. 29.  3.] 
adversary cards in discard: [29. 25.  0.  0.  0.  0. 29. 10.  0. 11. 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29] -> size -> 30 
adversary victory points: 7
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 0. 1.] 
cards in discard: [ 6. 10. 14.  6.  0.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15  6 11  6 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 6 
card supply: [29. 28. 30. 23. 30.  8.  6.  8.  5.  9.  8.  5.  8.  9.  3. 10.  9.] 
adversary cards in hand: [11. 29. 10. 29.  3.] 
adversary cards in discard: [29. 25.  0.  0.  0.  0. 29. 10.  0. 11. 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29] -> size -> 30 
adversary victory points: 7
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [11. 29. 10. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10. 29.] 
expected returns: [[15.890537]
 [26.691143]
 [32.265903]
 [11.376537]
 [32.265903]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 10. 29.  3.] 
cards in discard: [29. 25.  0.  0.  0.  0. 29. 10.  0. 11. 10.  3. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 23. 30.  8.  6.  8.  5.  9.  8.  5.  8.  9.  3. 10.  9.] 
adversary cards in hand: [ 3. 10. 11. 16. 15.] 
adversary cards in discard: [ 6. 10. 14.  6.  0.  3.  0.  0.  1.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15  6 11  6 10] -> size -> 29 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 3.6448636054992676



action possibilites: [-1. 11. 10. 29.] 
expected returns: [[36.32926 ]
 [50.82489 ]
 [30.438858]
 [58.214783]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 29.  3.  3.] 
cards in discard: [29. 25.  0.  0.  0.  0. 29. 10.  0. 11. 10.  3. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 23. 30.  8.  6.  8.  5.  9.  8.  5.  8.  9.  3. 10.  9.] 
adversary cards in hand: [ 3. 10. 11. 16. 15.] 
adversary cards in discard: [ 6. 10. 14.  6.  0.  3.  0.  0.  1.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15  6 11  6 10] -> size -> 29 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 32.26591491699219



action possibilites: [-1. 11. 10.] 
expected returns: [[66.42417 ]
 [81.98138 ]
 [60.119156]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  3.  3.  0.] 
cards in discard: [29. 25.  0.  0.  0.  0. 29. 10.  0. 11. 10.  3. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 23. 30.  8.  6.  8.  5.  9.  8.  5.  8.  9.  3. 10.  9.] 
adversary cards in hand: [ 3. 10. 11. 16. 15.] 
adversary cards in discard: [ 6. 10. 14.  6.  0.  3.  0.  0.  1.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15  6 11  6 10] -> size -> 29 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 58.214778900146484



action possibilites: [-1] 
expected returns: [[51.467796]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3.  0.] 
cards in discard: [29. 25.  0.  0.  0.  0. 29. 10.  0. 11. 10.  3. 10. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 23. 30.  8.  6.  8.  5.  9.  8.  5.  8.  9.  2. 10.  9.] 
adversary cards in hand: [ 3. 10. 11. 16. 15.] 
adversary cards in discard: [ 6. 10. 14.  6.  0.  3.  0.  0.  1.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15  6 11  6 10] -> size -> 29 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 150   0   0  60   0   0   0   0   0   0   0  27   0] 
sum of rewards: 232 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 90.03606414794922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[40.54503 ]
 [60.836426]
 [53.330383]
 [21.713549]
 [65.762245]
 [52.48951 ]
 [45.204952]
 [51.02761 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3.  0.] 
cards in discard: [29. 25.  0.  0.  0.  0. 29. 10.  0. 11. 10.  3. 10. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 23. 30.  8.  6.  8.  5.  9.  8.  5.  8.  9.  2. 10.  9.] 
adversary cards in hand: [ 3. 10. 11. 16. 15.] 
adversary cards in discard: [ 6. 10. 14.  6.  0.  3.  0.  0.  1.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15  6 11  6 10] -> size -> 29 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 150   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: take_action - action -1
Learning step: 0
desired expected reward: 51.467796325683594



buy possibilites: [-1] 
expected returns: [[58.716034]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3.  0.] 
cards in discard: [29. 25.  0.  0.  0.  0. 29. 10.  0. 11. 10.  3. 10. 10. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 23. 30.  8.  6.  8.  4.  9.  8.  5.  8.  9.  2. 10.  9.] 
adversary cards in hand: [ 3. 10. 11. 16. 15.] 
adversary cards in discard: [ 6. 10. 14.  6.  0.  3.  0.  0.  1.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15  6 11  6 10] -> size -> 29 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 150   0   0  60   0   0   0   0   0   0   0  54   0] 
sum of rewards: 259 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 65.76224517822266






Player: 1 
cards in hand: [ 3. 10. 11. 16. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 16. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11. 16. 15.] 
cards in discard: [ 6. 10. 14.  6.  0.  3.  0.  0.  1.  6.  0.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15  6 11  6 10] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 23. 30.  8.  6.  8.  4.  9.  8.  5.  8.  9.  2. 10.  9.] 
adversary cards in hand: [ 0.  3. 29.  3. 25.] 
adversary cards in discard: [29. 25.  0.  0.  0.  0. 29. 10.  0. 11. 10.  3. 10. 10. 11. 29. 29. 11.
 10.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11] -> size -> 32 
adversary victory points: 7
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11. 16.] 
cards in discard: [ 6. 10. 14.  6.  0.  3.  0.  0.  1.  6.  0.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15  6 11  6 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 23. 30.  8.  6.  8.  4.  9.  8.  5.  8.  9.  2. 10.  9.] 
adversary cards in hand: [ 0.  3. 29.  3. 25.] 
adversary cards in discard: [29. 25.  0.  0.  0.  0. 29. 10.  0. 11. 10.  3. 10. 10. 11. 29. 29. 11.
 10.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11] -> size -> 32 
adversary victory points: 7
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 11. 16.] 
cards in discard: [ 6. 10. 14.  6.  0.  3.  0.  0.  1.  6.  0.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15  6 11  6 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 28. 30. 23. 30.  8.  6.  8.  4.  9.  8.  5.  8.  9.  2. 10.  9.] 
adversary cards in hand: [ 0.  3. 29.  3. 25.] 
adversary cards in discard: [29. 25.  0.  0.  0.  0. 29. 10.  0. 11. 10.  3. 10. 10. 11. 29. 29. 11.
 10.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11] -> size -> 32 
adversary victory points: 7
player victory points: 2 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 29.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[-5.591949]
 [ 7.457564]
 [15.031658]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  3. 25.] 
cards in discard: [29. 25.  0.  0.  0.  0. 29. 10.  0. 11. 10.  3. 10. 10. 11. 29. 29. 11.
 10.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 23. 30.  8.  6.  8.  4.  9.  8.  5.  8.  9.  2. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 14. 23.] 
adversary cards in discard: [ 6. 10. 14.  6.  0.  3.  0.  0.  1.  6.  0.  1. 15.  3. 10. 11. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15  6 11  6 10] -> size -> 29 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 58.716033935546875



action possibilites: [-1] 
expected returns: [[-1.1753383]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  3. 11.  3.] 
cards in discard: [29. 25.  0.  0.  0.  0. 29. 10.  0. 11. 10.  3. 10. 10. 11. 29. 29. 11.
 10.  3.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 23. 30.  8.  5.  8.  4.  9.  8.  5.  8.  9.  2. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 14. 23.] 
adversary cards in discard: [ 6. 10. 14.  6.  0.  3.  0.  0.  1.  6.  0.  1. 15.  3. 10. 11. 16.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15  6 11  6 10  6] -> size -> 30 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 15.031648635864258





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -8.803534  ]
 [-22.324493  ]
 [ -0.79723597]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 29.  3. 11.  3.] 
cards in discard: [29. 25.  0.  0.  0.  0. 29. 10.  0. 11. 10.  3. 10. 10. 11. 29. 29. 11.
 10.  3.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 28. 30. 23. 30.  8.  5.  8.  4.  9.  8.  5.  8.  9.  2. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 14. 23.] 
adversary cards in discard: [ 6. 10. 14.  6.  0.  3.  0.  0.  1.  6.  0.  1. 15.  3. 10. 11. 16.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15  6 11  6 10  6] -> size -> 30 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: -1.1753382682800293






Player: 1 
cards in hand: [ 0.  0.  3. 14. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 23.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 14. 23.] 
cards in discard: [ 6. 10. 14.  6.  0.  3.  0.  0.  1.  6.  0.  1. 15.  3. 10. 11. 16.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15  6 11  6 10  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 23. 30.  8.  5.  8.  4.  9.  8.  5.  8.  9.  2. 10.  9.] 
adversary cards in hand: [10. 10. 11. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11] -> size -> 32 
adversary victory points: 7
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 23.] 
cards in discard: [ 6. 10. 14.  6.  0.  3.  0.  0.  1.  6.  0.  1. 15.  3. 10. 11. 16.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15  6 11  6 10  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 23. 30.  8.  5.  8.  4.  9.  8.  5.  8.  9.  2. 10.  9.] 
adversary cards in hand: [10. 10.  3.] 
adversary cards in discard: [11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11] -> size -> 32 
adversary victory points: 7
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 23.] 
cards in discard: [ 6. 10. 14.  6.  0.  3.  0.  0.  1.  6.  0.  1. 15.  3. 10. 11. 16.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15  6 11  6 10  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 23. 30.  8.  5.  8.  4.  9.  8.  5.  8.  9.  2. 10.  9.] 
adversary cards in hand: [10. 10.  3.] 
adversary cards in discard: [11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11] -> size -> 32 
adversary victory points: 7
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 23.] 
cards in discard: [ 6. 10. 14.  6.  0.  3.  0.  0.  1.  6.  0.  1. 15.  3. 10. 11. 16.  6.
  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15  6 11  6 10  6  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 22. 30.  8.  5.  8.  4.  9.  8.  5.  8.  9.  2. 10.  9.] 
adversary cards in hand: [10. 10.  3.] 
adversary cards in discard: [11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11] -> size -> 32 
adversary victory points: 7
player victory points: 2 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [10. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[-15.417797]
 [-19.781673]
 [-19.781673]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3.] 
cards in discard: [11. 10.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 22. 30.  8.  5.  8.  4.  9.  8.  5.  8.  9.  2. 10.  9.] 
adversary cards in hand: [3. 0. 6. 0. 3.] 
adversary cards in discard: [ 6. 10. 14.  6.  0.  3.  0.  0.  1.  6.  0.  1. 15.  3. 10. 11. 16.  6.
  3. 14.  0.  0.  3. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15  6 11  6 10  6  3] -> size -> 31 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0 794   0] 
sum of rewards: 939 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -27.272811889648438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-23.205437]
 [-37.003204]
 [-15.395081]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  3.] 
cards in discard: [11. 10.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11] -> size -> 32 
action values: 1 
buys: 1 
player value: 0 
card supply: [29. 28. 30. 22. 30.  8.  5.  8.  4.  9.  8.  5.  8.  9.  2. 10.  9.] 
adversary cards in hand: [3. 0. 6. 0. 3.] 
adversary cards in discard: [ 6. 10. 14.  6.  0.  3.  0.  0.  1.  6.  0.  1. 15.  3. 10. 11. 16.  6.
  3. 14.  0.  0.  3. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15  6 11  6 10  6  3] -> size -> 31 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -15.417795181274414



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 0. 3.] 
cards in discard: [ 6. 10. 14.  6.  0.  3.  0.  0.  1.  6.  0.  1. 15.  3. 10. 11. 16.  6.
  3. 14.  0.  0.  3. 23.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15  6 11  6 10  6  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 22. 30.  8.  5.  8.  4.  9.  8.  5.  8.  9.  2. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 29.  0.] 
adversary cards in discard: [11. 10. 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11] -> size -> 32 
adversary victory points: 7
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 3.] 
cards in discard: [ 6. 10. 14.  6.  0.  3.  0.  0.  1.  6.  0.  1. 15.  3. 10. 11. 16.  6.
  3. 14.  0.  0.  3. 23.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15  6 11  6 10  6  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 22. 30.  8.  5.  8.  4.  9.  8.  5.  8.  9.  2. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 29.  0.] 
adversary cards in discard: [11. 10. 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11] -> size -> 32 
adversary victory points: 7
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 3.] 
cards in discard: [ 6. 10. 14.  6.  0.  3.  0.  0.  1.  6.  0.  1. 15.  3. 10. 11. 16.  6.
  3. 14.  0.  0.  3. 23.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15  6 11  6 10  6  3  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 22. 30.  8.  5.  8.  4.  9.  8.  5.  8.  9.  2. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 29.  0.] 
adversary cards in discard: [11. 10. 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11] -> size -> 32 
adversary victory points: 7
player victory points: 2 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-9.976557 ]
 [ 4.8596425]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 29.  0.] 
cards in discard: [11. 10. 10. 10.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 22. 30.  8.  5.  8.  4.  9.  8.  5.  8.  9.  2. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15  6 11  6 10  6  3  0] -> size -> 32 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -15.39508056640625



action possibilites: [-1.] 
expected returns: [[-6.7542467]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [11. 10. 10. 10.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 22. 30.  8.  5.  8.  4.  9.  8.  5.  8.  9.  2. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15  6 11  6 10  6  3  0] -> size -> 32 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 4.8596367835998535





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-14.034325 ]
 [ -0.5481334]
 [ -5.613138 ]
 [-26.540606 ]
 [  2.734778 ]
 [ -6.1471095]
 [-10.97588  ]
 [ -6.9693666]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [11. 10. 10. 10.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 22. 30.  8.  5.  8.  4.  9.  8.  5.  8.  9.  2. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15  6 11  6 10  6  3  0] -> size -> 32 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -6.754246711730957



buy possibilites: [-1] 
expected returns: [[15.921892]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [11. 10. 10. 10.  3. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 22. 30.  8.  5.  8.  3.  9.  8.  5.  8.  9.  2. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15  6 11  6 10  6  3  0] -> size -> 32 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 219 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 2.7347731590270996






Player: 1 
cards in hand: [ 3. 10.  0.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  3. 16.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3
 15  6 11  6 10  6  3  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 22. 30.  8.  5.  8.  3.  9.  8.  5.  8.  9.  2. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 29. 25.] 
adversary cards in discard: [11. 10. 10. 10.  3. 11. 29.  3.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11] -> size -> 33 
adversary victory points: 7
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.] 
cards in discard: [1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 22. 30.  8.  5.  8.  3.  9.  8.  5.  8.  9.  2. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 29. 25.] 
adversary cards in discard: [11. 10. 10. 10.  3. 11. 29.  3.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11] -> size -> 33 
adversary victory points: 7
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.] 
cards in discard: [1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 27. 30. 22. 30.  8.  5.  8.  3.  9.  8.  5.  8.  9.  2. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 29. 25.] 
adversary cards in discard: [11. 10. 10. 10.  3. 11. 29.  3.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11] -> size -> 33 
adversary victory points: 7
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.] 
cards in discard: [1. 0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 22. 30.  8.  5.  8.  3.  9.  8.  5.  8.  9.  2. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 29. 25.] 
adversary cards in discard: [11. 10. 10. 10.  3. 11. 29.  3.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11] -> size -> 33 
adversary victory points: 7
player victory points: 1 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 25.] 
expected returns: [[-11.371418 ]
 [ -1.2460628]
 [  4.27867  ]
 [ 13.458626 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 29. 25.] 
cards in discard: [11. 10. 10. 10.  3. 11. 29.  3.  3.  0.  0.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 22. 30.  8.  5.  8.  3.  9.  8.  5.  8.  9.  2. 10.  9.] 
adversary cards in hand: [23.  6.  3.  0. 14.] 
adversary cards in discard: [ 1.  0. 16. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1  0] -> size -> 33 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 15.921892166137695



action possibilites: [-1] 
expected returns: [[7.673672]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 29.  0. 10.] 
cards in discard: [11. 10. 10. 10.  3. 11. 29.  3.  3.  0.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 22. 30.  8.  4.  8.  3.  9.  8.  5.  8.  9.  2. 10.  9.] 
adversary cards in hand: [23.  6.  3.  0. 14.] 
adversary cards in discard: [ 1.  0. 16. 10.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1  0  6] -> size -> 34 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 13.458621978759766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[  0.38944578]
 [ 14.859531  ]
 [  9.603159  ]
 [-13.6015    ]
 [ 18.238958  ]
 [  9.025242  ]
 [  3.7688766 ]
 [  8.057167  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 29.  0. 10.] 
cards in discard: [11. 10. 10. 10.  3. 11. 29.  3.  3.  0.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 27. 30. 22. 30.  8.  4.  8.  3.  9.  8.  5.  8.  9.  2. 10.  9.] 
adversary cards in hand: [23.  6.  3.  0. 14.] 
adversary cards in discard: [ 1.  0. 16. 10.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1  0  6] -> size -> 34 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 7.673672199249268



buy possibilites: [-1] 
expected returns: [[4.2640023]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 29.  0. 10.] 
cards in discard: [11. 10. 10. 10.  3. 11. 29.  3.  3.  0.  0.  3. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 22. 30.  8.  4.  8.  2.  9.  8.  5.  8.  9.  2. 10.  9.] 
adversary cards in hand: [23.  6.  3.  0. 14.] 
adversary cards in discard: [ 1.  0. 16. 10.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1  0  6] -> size -> 34 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 249 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 18.238956451416016






Player: 1 
cards in hand: [23.  6.  3.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 14.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  6.  3.  0. 14.] 
cards in discard: [ 1.  0. 16. 10.  0.  3.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1  0  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 22. 30.  8.  4.  8.  2.  9.  8.  5.  8.  9.  2. 10.  9.] 
adversary cards in hand: [10. 29. 25.  0. 29.] 
adversary cards in discard: [11. 10. 10. 10.  3. 11. 29.  3.  3.  0.  0.  3. 11. 25.  0.  0. 11. 29.
  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11] -> size -> 34 
adversary victory points: 7
player victory points: 0 


action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  0. 14.  6.] 
cards in discard: [ 1.  0. 16. 10.  0.  3.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1  0  6] -> size -> 34 
action values: 1 
buys: 1 
player value: 1 
card supply: [27. 27. 30. 22. 30.  8.  4.  8.  2.  9.  8.  5.  8.  9.  2. 10.  9.] 
adversary cards in hand: [10. 29. 25.  0. 29.] 
adversary cards in discard: [11. 10. 10. 10.  3. 11. 29.  3.  3.  0.  0.  3. 11. 25.  0.  0. 11. 29.
  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11] -> size -> 34 
adversary victory points: 7
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 6.] 
cards in discard: [ 1.  0. 16. 10.  0.  3.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [23. 14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1  0  6] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 27. 30. 22. 30.  8.  4.  8.  2.  9.  8.  5.  8.  9.  2. 10.  9.] 
adversary cards in hand: [10.  0. 29.] 
adversary cards in discard: [11. 10. 10. 10.  3. 11. 29.  3.  3.  0.  0.  3. 11. 25.  0.  0. 11. 29.
  0. 10. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11] -> size -> 34 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 6.] 
cards in discard: [ 1.  0. 16. 10.  0.  3.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [23. 14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1  0  6] -> size -> 34 
action values: 0 
buys: 2 
player value: 4 
card supply: [27. 27. 30. 22. 30.  8.  4.  8.  2.  9.  8.  5.  8.  9.  2. 10.  9.] 
adversary cards in hand: [10.  0. 29.] 
adversary cards in discard: [11. 10. 10. 10.  3. 11. 29.  3.  3.  0.  0.  3. 11. 25.  0.  0. 11. 29.
  0. 10. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11] -> size -> 34 
adversary victory points: 7
player victory points: 0 


buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 6.] 
cards in discard: [ 1.  0. 16. 10.  0.  3.  6.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [23. 14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1  0  6  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 22. 30.  8.  4.  8.  2.  8.  8.  5.  8.  9.  2. 10.  9.] 
adversary cards in hand: [10.  0. 29.] 
adversary cards in discard: [11. 10. 10. 10.  3. 11. 29.  3.  3.  0.  0.  3. 11. 25.  0.  0. 11. 29.
  0. 10. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11] -> size -> 34 
adversary victory points: 7
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 6.] 
cards in discard: [ 1.  0. 16. 10.  0.  3.  6.  8.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [23. 14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1  0  6  8  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 27. 30. 22. 30.  8.  4.  8.  2.  8.  8.  5.  8.  9.  2. 10.  9.] 
adversary cards in hand: [10.  0. 29.] 
adversary cards in discard: [11. 10. 10. 10.  3. 11. 29.  3.  3.  0.  0.  3. 11. 25.  0.  0. 11. 29.
  0. 10. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11] -> size -> 34 
adversary victory points: 7
player victory points: 0 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [10.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[-25.618021]
 [-29.496204]
 [-11.668554]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29.] 
cards in discard: [11. 10. 10. 10.  3. 11. 29.  3.  3.  0.  0.  3. 11. 25.  0.  0. 11. 29.
  0. 10. 25. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 22. 30.  8.  4.  8.  2.  8.  8.  5.  8.  9.  2. 10.  9.] 
adversary cards in hand: [ 6.  6.  1. 16.  0.] 
adversary cards in discard: [ 1.  0. 16. 10.  0.  3.  6.  8.  0. 23. 14.  6.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1  0  6  8  0] -> size -> 36 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -28.287181854248047



action possibilites: [-1. 10. 10.] 
expected returns: [[-21.099379]
 [-24.882027]
 [-24.882027]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.] 
cards in discard: [11. 10. 10. 10.  3. 11. 29.  3.  3.  0.  0.  3. 11. 25.  0.  0. 11. 29.
  0. 10. 25. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 22. 30.  8.  4.  8.  2.  8.  8.  5.  8.  9.  2. 10.  9.] 
adversary cards in hand: [ 6.  6.  1. 16.  0.] 
adversary cards in discard: [ 1.  0. 16. 10.  0.  3.  6.  8.  0. 23. 14.  6.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1  0  6  8  0] -> size -> 36 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: -11.668545722961426





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-27.234379]
 [-19.282839]
 [-39.062866]
 [-19.785946]
 [-20.520409]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.] 
cards in discard: [11. 10. 10. 10.  3. 11. 29.  3.  3.  0.  0.  3. 11. 25.  0.  0. 11. 29.
  0. 10. 25. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 22. 30.  8.  4.  8.  2.  8.  8.  5.  8.  9.  2. 10.  9.] 
adversary cards in hand: [ 6.  6.  1. 16.  0.] 
adversary cards in discard: [ 1.  0. 16. 10.  0.  3.  6.  8.  0. 23. 14.  6.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1  0  6  8  0] -> size -> 36 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -21.099367141723633



buy possibilites: [-1] 
expected returns: [[-24.427086]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.] 
cards in discard: [11. 10. 10. 10.  3. 11. 29.  3.  3.  0.  0.  3. 11. 25.  0.  0. 11. 29.
  0. 10. 25. 29.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 21. 30.  8.  4.  8.  2.  8.  8.  5.  8.  9.  2. 10.  9.] 
adversary cards in hand: [ 6.  6.  1. 16.  0.] 
adversary cards in discard: [ 1.  0. 16. 10.  0.  3.  6.  8.  0. 23. 14.  6.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1  0  6  8  0] -> size -> 36 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 271 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -19.28282928466797






Player: 1 
cards in hand: [ 6.  6.  1. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  1. 16.  0.] 
cards in discard: [ 1.  0. 16. 10.  0.  3.  6.  8.  0. 23. 14.  6.  3.  0.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1  0  6  8  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 21. 30.  8.  4.  8.  2.  8.  8.  5.  8.  9.  2. 10.  9.] 
adversary cards in hand: [ 0. 11.  3. 29. 11.] 
adversary cards in discard: [11. 10. 10. 10.  3. 11. 29.  3.  3.  0.  0.  3. 11. 25.  0.  0. 11. 29.
  0. 10. 25. 29.  3. 29. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3] -> size -> 35 
adversary victory points: 8
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  1. 16.  0.] 
cards in discard: [ 1.  0. 16. 10.  0.  3.  6.  8.  0. 23. 14.  6.  3.  0.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1  0  6  8  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 21. 30.  8.  4.  8.  2.  8.  8.  5.  8.  9.  2. 10.  9.] 
adversary cards in hand: [ 0. 11.  3. 29. 11.] 
adversary cards in discard: [11. 10. 10. 10.  3. 11. 29.  3.  3.  0.  0.  3. 11. 25.  0.  0. 11. 29.
  0. 10. 25. 29.  3. 29. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3] -> size -> 35 
adversary victory points: 8
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  1. 16.  0.] 
cards in discard: [ 1.  0. 16. 10.  0.  3.  6.  8.  0. 23. 14.  6.  3.  0.  6. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1  0  6  8  0 11] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 21. 30.  8.  4.  8.  1.  8.  8.  5.  8.  9.  2. 10.  9.] 
adversary cards in hand: [ 0. 11.  3. 29. 11.] 
adversary cards in discard: [11. 10. 10. 10.  3. 11. 29.  3.  3.  0.  0.  3. 11. 25.  0.  0. 11. 29.
  0. 10. 25. 29.  3. 29. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3] -> size -> 35 
adversary victory points: 8
player victory points: 0 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  3. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 11.] 
expected returns: [[ 2.0068521]
 [11.44021  ]
 [16.352417 ]
 [11.44021  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3. 29. 11.] 
cards in discard: [11. 10. 10. 10.  3. 11. 29.  3.  3.  0.  0.  3. 11. 25.  0.  0. 11. 29.
  0. 10. 25. 29.  3. 29. 10.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 21. 30.  8.  4.  8.  1.  8.  8.  5.  8.  9.  2. 10.  9.] 
adversary cards in hand: [11.  3. 14.  0.  0.] 
adversary cards in discard: [ 1.  0. 16. 10.  0.  3.  6.  8.  0. 23. 14.  6.  3.  0.  6. 11.  6.  6.
  1. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1  0  6  8  0 11] -> size -> 37 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: -24.427085876464844



action possibilites: [-1. 11. 11.] 
expected returns: [[12.048916]
 [21.514729]
 [21.514729]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3. 11.  3.] 
cards in discard: [11. 10. 10. 10.  3. 11. 29.  3.  3.  0.  0.  3. 11. 25.  0.  0. 11. 29.
  0. 10. 25. 29.  3. 29. 10.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 21. 30.  8.  4.  8.  1.  8.  8.  5.  8.  9.  2. 10.  9.] 
adversary cards in hand: [11.  3. 14.  0.  0.] 
adversary cards in discard: [ 1.  0. 16. 10.  0.  3.  6.  8.  0. 23. 14.  6.  3.  0.  6. 11.  6.  6.
  1. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1  0  6  8  0 11] -> size -> 37 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 16.352413177490234



action possibilites: [-1] 
expected returns: [[-31.630726]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  3.] 
cards in discard: [11. 10. 10. 10.  3. 11. 29.  3.  3.  0.  0.  3. 11. 25.  0.  0. 11. 29.
  0. 10. 25. 29.  3. 29. 10.  0. 10. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 21. 30.  8.  4.  8.  1.  8.  8.  5.  8.  9.  1. 10.  9.] 
adversary cards in hand: [11.  3. 14.  0.  0.] 
adversary cards in discard: [ 1.  0. 16. 10.  0.  3.  6.  8.  0. 23. 14.  6.  3.  0.  6. 11.  6.  6.
  1. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1  0  6  8  0 11] -> size -> 37 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0 -10   0   0  27   0] 
sum of rewards: 292 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 26.42943000793457





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-36.126926]
 [-30.393291]
 [-45.01457 ]
 [-30.737001]
 [-31.156218]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  3.] 
cards in discard: [11. 10. 10. 10.  3. 11. 29.  3.  3.  0.  0.  3. 11. 25.  0.  0. 11. 29.
  0. 10. 25. 29.  3. 29. 10.  0. 10. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 21. 30.  8.  4.  8.  1.  8.  8.  5.  8.  9.  1. 10.  9.] 
adversary cards in hand: [11.  3. 14.  0.  0.] 
adversary cards in discard: [ 1.  0. 16. 10.  0.  3.  6.  8.  0. 23. 14.  6.  3.  0.  6. 11.  6.  6.
  1. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1  0  6  8  0 11] -> size -> 37 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1
Learning step: 0
desired expected reward: -31.630725860595703



buy possibilites: [-1] 
expected returns: [[-34.973366]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  3.] 
cards in discard: [11. 10. 10. 10.  3. 11. 29.  3.  3.  0.  0.  3. 11. 25.  0.  0. 11. 29.
  0. 10. 25. 29.  3. 29. 10.  0. 10. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 20. 30.  8.  4.  8.  1.  8.  8.  5.  8.  9.  1. 10.  9.] 
adversary cards in hand: [11.  3. 14.  0.  0.] 
adversary cards in discard: [ 1.  0. 16. 10.  0.  3.  6.  8.  0. 23. 14.  6.  3.  0.  6. 11.  6.  6.
  1. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1  0  6  8  0 11] -> size -> 37 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0 -20   0   0  16   0] 
sum of rewards: 301 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -30.393295288085938






Player: 1 
cards in hand: [11.  3. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 14.  0.  0.] 
cards in discard: [ 1.  0. 16. 10.  0.  3.  6.  8.  0. 23. 14.  6.  3.  0.  6. 11.  6.  6.
  1. 16.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1  0  6  8  0 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 20. 30.  8.  4.  8.  1.  8.  8.  5.  8.  9.  1. 10.  9.] 
adversary cards in hand: [29.  3. 29.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3] -> size -> 37 
adversary victory points: 9
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 14.  0.  0.] 
cards in discard: [ 1.  0. 16. 10.  0.  3.  6.  8.  0. 23. 14.  6.  3.  0.  6. 11.  6.  6.
  1. 16.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1  0  6  8  0 11] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 20. 30.  8.  4.  8.  1.  8.  8.  5.  8.  9.  1. 10.  9.] 
adversary cards in hand: [29.  3. 29.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3] -> size -> 37 
adversary victory points: 9
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 14.  0.  0.] 
cards in discard: [ 1.  0. 16. 10.  0.  3.  6.  8.  0. 23. 14.  6.  3.  0.  6. 11.  6.  6.
  1. 16.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1  0  6  8  0 11  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 19. 30.  8.  4.  8.  1.  8.  8.  5.  8.  9.  1. 10.  9.] 
adversary cards in hand: [29.  3. 29.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3] -> size -> 37 
adversary victory points: 9
player victory points: 1 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [29.  3. 29.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 11.] 
expected returns: [[-10.926999 ]
 [  4.4214473]
 [  4.4214473]
 [ -1.0948887]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 29.  3. 11.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 19. 30.  8.  4.  8.  1.  8.  8.  5.  8.  9.  1. 10.  9.] 
adversary cards in hand: [1. 0. 0. 0. 6.] 
adversary cards in discard: [ 1.  0. 16. 10.  0.  3.  6.  8.  0. 23. 14.  6.  3.  0.  6. 11.  6.  6.
  1. 16.  0.  3. 11.  3. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1  0  6  8  0 11  3] -> size -> 38 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: -34.973365783691406



action possibilites: [-1. 29. 11.] 
expected returns: [[-10.782314  ]
 [  4.9066987 ]
 [ -0.60026026]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3. 11.  0.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 19. 30.  8.  4.  8.  1.  8.  8.  5.  8.  9.  1. 10.  9.] 
adversary cards in hand: [1. 0. 0. 0. 6.] 
adversary cards in discard: [ 1.  0. 16. 10.  0.  3.  6.  8.  0. 23. 14.  6.  3.  0.  6. 11.  6.  6.
  1. 16.  0.  3. 11.  3. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1  0  6  8  0 11  3] -> size -> 38 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 4.421444416046143



action possibilites: [-1. 11. 25.] 
expected returns: [[-4.466173]
 [ 6.333407]
 [22.16428 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11.  0. 25.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 27. 30. 19. 30.  8.  4.  8.  1.  8.  8.  5.  8.  9.  1. 10.  9.] 
adversary cards in hand: [1. 0. 0. 0. 6.] 
adversary cards in discard: [ 1.  0. 16. 10.  0.  3.  6.  8.  0. 23. 14.  6.  3.  0.  6. 11.  6.  6.
  1. 16.  0.  3. 11.  3. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1  0  6  8  0 11  3] -> size -> 38 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 4.9066996574401855



action possibilites: [-1] 
expected returns: [[-21.914839]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 27. 30. 19. 30.  8.  3.  8.  1.  8.  8.  5.  8.  9.  1. 10.  9.] 
adversary cards in hand: [1. 0. 0. 0. 6.] 
adversary cards in discard: [ 1.  0. 16. 10.  0.  3.  6.  8.  0. 23. 14.  6.  3.  0.  6. 11.  6.  6.
  1. 16.  0.  3. 11.  3. 14.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1  0  6  8  0 11  3  6] -> size -> 39 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 22.16427993774414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-27.422857]
 [-16.242132]
 [-20.447264]
 [-37.981483]
 [-20.807232]
 [-13.437948]
 [-20.884138]
 [ -8.700625]
 [-31.442768]
 [-24.84595 ]
 [-20.505358]
 [-21.497698]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 11.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 27. 30. 19. 30.  8.  3.  8.  1.  8.  8.  5.  8.  9.  1. 10.  9.] 
adversary cards in hand: [1. 0. 0. 0. 6.] 
adversary cards in discard: [ 1.  0. 16. 10.  0.  3.  6.  8.  0. 23. 14.  6.  3.  0.  6. 11.  6.  6.
  1. 16.  0.  3. 11.  3. 14.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1  0  6  8  0 11  3  6] -> size -> 39 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: take_action - action -1
Learning step: 0
desired expected reward: -21.914838790893555



buy possibilites: [-1] 
expected returns: [[-10.550758]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 11.  0.  0. 10.] 
cards in discard: [29.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 19. 30.  8.  3.  8.  1.  8.  8.  4.  8.  9.  1. 10.  9.] 
adversary cards in hand: [1. 0. 0. 0. 6.] 
adversary cards in discard: [ 1.  0. 16. 10.  0.  3.  6.  8.  0. 23. 14.  6.  3.  0.  6. 11.  6.  6.
  1. 16.  0.  3. 11.  3. 14.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1  0  6  8  0 11  3  6] -> size -> 39 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0  60   0   0   0   0 -30   0   0 128   0] 
sum of rewards: 393 

action type: buy - action 29.0
Learning step: 0
desired expected reward: -8.700613021850586






Player: 1 
cards in hand: [1. 0. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 6.] 
cards in discard: [ 1.  0. 16. 10.  0.  3.  6.  8.  0. 23. 14.  6.  3.  0.  6. 11.  6.  6.
  1. 16.  0.  3. 11.  3. 14.  0.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1  0  6  8  0 11  3  6] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 19. 30.  8.  3.  8.  1.  8.  8.  4.  8.  9.  1. 10.  9.] 
adversary cards in hand: [29. 10. 11.  3. 11.] 
adversary cards in discard: [29. 29. 29. 25.  3.  3. 11.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29] -> size -> 38 
adversary victory points: 9
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 6.] 
cards in discard: [ 1.  0. 16. 10.  0.  3.  6.  8.  0. 23. 14.  6.  3.  0.  6. 11.  6.  6.
  1. 16.  0.  3. 11.  3. 14.  0.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1  0  6  8  0 11  3  6] -> size -> 39 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 27. 30. 19. 30.  8.  3.  8.  1.  8.  8.  4.  8.  9.  1. 10.  9.] 
adversary cards in hand: [29. 10. 11.  3. 11.] 
adversary cards in discard: [29. 29. 29. 25.  3.  3. 11.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29] -> size -> 38 
adversary victory points: 9
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 6.] 
cards in discard: [ 1.  0. 16. 10.  0.  3.  6.  8.  0. 23. 14.  6.  3.  0.  6. 11.  6.  6.
  1. 16.  0.  3. 11.  3. 14.  0.  0.  6.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 5 
card supply: [25. 27. 30. 19. 30.  8.  3.  8.  1.  8.  8.  4.  8.  9.  1. 10.  9.] 
adversary cards in hand: [29. 10. 11.  3. 11.] 
adversary cards in discard: [29. 29. 29. 25.  3.  3. 11.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29] -> size -> 38 
adversary victory points: 9
player victory points: 0 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [29. 10. 11.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 11. 11.] 
expected returns: [[19.026821]
 [33.6171  ]
 [14.966446]
 [28.62495 ]
 [28.62495 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 11.  3. 11.] 
cards in discard: [29. 29. 29. 25.  3.  3. 11.  0.  0. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 19. 30.  8.  3.  8.  1.  8.  8.  4.  8.  9.  1. 10.  9.] 
adversary cards in hand: [ 3. 10. 15.  3.  0.] 
adversary cards in discard: [ 1.  0. 16. 10.  0.  3.  6.  8.  0. 23. 14.  6.  3.  0.  6. 11.  6.  6.
  1. 16.  0.  3. 11.  3. 14.  0.  0.  6.  0.  1.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0] -> size -> 40 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.550758361816406



action possibilites: [-1. 10. 11. 11.] 
expected returns: [[24.081528]
 [19.970245]
 [33.970543]
 [33.970543]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  3. 11.  3.] 
cards in discard: [29. 29. 29. 25.  3.  3. 11.  0.  0. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 19. 30.  8.  3.  8.  1.  8.  8.  4.  8.  9.  1. 10.  9.] 
adversary cards in hand: [ 3. 10. 15.  3.  0.] 
adversary cards in discard: [ 1.  0. 16. 10.  0.  3.  6.  8.  0. 23. 14.  6.  3.  0.  6. 11.  6.  6.
  1. 16.  0.  3. 11.  3. 14.  0.  0.  6.  0.  1.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0] -> size -> 40 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 33.61709213256836



action possibilites: [-1] 
expected returns: [[40.989494]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 11.  3.] 
cards in discard: [29. 29. 29. 25.  3.  3. 11.  0.  0. 10. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 19. 30.  8.  3.  8.  1.  8.  8.  4.  8.  9.  0. 10.  9.] 
adversary cards in hand: [ 3. 10. 15.  3.  0.] 
adversary cards in discard: [ 1.  0. 16. 10.  0.  3.  6.  8.  0. 23. 14.  6.  3.  0.  6. 11.  6.  6.
  1. 16.  0.  3. 11.  3. 14.  0.  0.  6.  0.  1.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0] -> size -> 40 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0 -40   0   0  27   0] 
sum of rewards: 292 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 39.29166030883789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[32.599213]
 [17.757816]
 [40.814415]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 11.  3.] 
cards in discard: [29. 29. 29. 25.  3.  3. 11.  0.  0. 10. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 19. 30.  8.  3.  8.  1.  8.  8.  4.  8.  9.  0. 10.  9.] 
adversary cards in hand: [ 3. 10. 15.  3.  0.] 
adversary cards in discard: [ 1.  0. 16. 10.  0.  3.  6.  8.  0. 23. 14.  6.  3.  0.  6. 11.  6.  6.
  1. 16.  0.  3. 11.  3. 14.  0.  0.  6.  0.  1.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0] -> size -> 40 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action -1
Learning step: 0
desired expected reward: 40.98949432373047






Player: 1 
cards in hand: [ 3. 10. 15.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 15.  3.  0.] 
cards in discard: [ 1.  0. 16. 10.  0.  3.  6.  8.  0. 23. 14.  6.  3.  0.  6. 11.  6.  6.
  1. 16.  0.  3. 11.  3. 14.  0.  0.  6.  0.  1.  0.  0.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 19. 30.  8.  3.  8.  1.  8.  8.  4.  8.  9.  0. 10.  9.] 
adversary cards in hand: [25. 10.  3.  0. 10.] 
adversary cards in discard: [29. 29. 29. 25.  3.  3. 11.  0.  0. 10. 10. 29. 11. 10.  3. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10] -> size -> 39 
adversary victory points: 9
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 15.  3.  0.] 
cards in discard: [ 1.  0. 16. 10.  0.  3.  6.  8.  0. 23. 14.  6.  3.  0.  6. 11.  6.  6.
  1. 16.  0.  3. 11.  3. 14.  0.  0.  6.  0.  1.  0.  0.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 19. 30.  8.  3.  8.  1.  8.  8.  4.  8.  9.  0. 10.  9.] 
adversary cards in hand: [25. 10.  3.  0. 10.] 
adversary cards in discard: [29. 29. 29. 25.  3.  3. 11.  0.  0. 10. 10. 29. 11. 10.  3. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10] -> size -> 39 
adversary victory points: 9
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [25. 10.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 10.] 
expected returns: [[-19.653263  ]
 [ -0.24381924]
 [-23.134064  ]
 [-23.134064  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10.  3.  0. 10.] 
cards in discard: [29. 29. 29. 25.  3.  3. 11.  0.  0. 10. 10. 29. 11. 10.  3. 11.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 19. 30.  8.  3.  8.  1.  8.  8.  4.  8.  9.  0. 10.  9.] 
adversary cards in hand: [10.  0.  0. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0] -> size -> 40 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 40.81440734863281



action possibilites: [-1] 
expected returns: [[-23.9541]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0. 10.  0. 10.] 
cards in discard: [29. 29. 29. 25.  3.  3. 11.  0.  0. 10. 10. 29. 11. 10.  3. 11.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 19. 30.  8.  2.  8.  1.  8.  8.  4.  8.  9.  0. 10.  9.] 
adversary cards in hand: [10.  0.  0. 16.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6] -> size -> 41 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -0.2438192367553711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-29.66692 ]
 [-22.993866]
 [-39.768948]
 [-23.406754]
 [-23.966747]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0. 10.  0. 10.] 
cards in discard: [29. 29. 29. 25.  3.  3. 11.  0.  0. 10. 10. 29. 11. 10.  3. 11.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 27. 30. 19. 30.  8.  2.  8.  1.  8.  8.  4.  8.  9.  0. 10.  9.] 
adversary cards in hand: [10.  0.  0. 16.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6] -> size -> 41 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: -23.954099655151367



buy possibilites: [-1] 
expected returns: [[-12.068901]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0. 10.  0. 10.] 
cards in discard: [29. 29. 29. 25.  3.  3. 11.  0.  0. 10. 10. 29. 11. 10.  3. 11.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 18. 30.  8.  2.  8.  1.  8.  8.  4.  8.  9.  0. 10.  9.] 
adversary cards in hand: [10.  0.  0. 16.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6] -> size -> 41 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0 -50   0   0  16   0] 
sum of rewards: 281 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -22.993867874145508






Player: 1 
cards in hand: [10.  0.  0. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 16.  3.] 
cards in discard: [6.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 10  6 16 23  6  0  3 14 16  3 15
  6 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 18. 30.  8.  2.  8.  1.  8.  8.  4.  8.  9.  0. 10.  9.] 
adversary cards in hand: [ 3.  0. 11. 10.  3.] 
adversary cards in discard: [29. 29. 29. 25.  3.  3. 11.  0.  0. 10. 10. 29. 11. 10.  3. 11.  3.  3.
 25. 10.  3.  0. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3] -> size -> 40 
adversary victory points: 10
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [ 6. 23.] 
cards in deck: 35 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 18. 30.  8.  2.  8.  1.  8.  8.  4.  8.  8.  0. 10.  9.] 
adversary cards in hand: [ 3.  0. 11. 10.  3.] 
adversary cards in discard: [29. 29. 29. 25.  3.  3. 11.  0.  0. 10. 10. 29. 11. 10.  3. 11.  3.  3.
 25. 10.  3.  0. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3] -> size -> 40 
adversary victory points: 10
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 6. 23.] 
cards in deck: 35 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 27. 30. 18. 30.  8.  2.  8.  1.  8.  8.  4.  8.  8.  0. 10.  9.] 
adversary cards in hand: [ 3.  0. 11. 10.  3.] 
adversary cards in discard: [29. 29. 29. 25.  3.  3. 11.  0.  0. 10. 10. 29. 11. 10.  3. 11.  3.  3.
 25. 10.  3.  0. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3] -> size -> 40 
adversary victory points: 10
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 6. 23.  3.] 
cards in deck: 35 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 17. 30.  8.  2.  8.  1.  8.  8.  4.  8.  8.  0. 10.  9.] 
adversary cards in hand: [ 3.  0. 11. 10.  3.] 
adversary cards in discard: [29. 29. 29. 25.  3.  3. 11.  0.  0. 10. 10. 29. 11. 10.  3. 11.  3.  3.
 25. 10.  3.  0. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3] -> size -> 40 
adversary victory points: 10
player victory points: 0 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 11. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[-33.900635]
 [-26.695398]
 [-37.139412]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11. 10.  3.] 
cards in discard: [29. 29. 29. 25.  3.  3. 11.  0.  0. 10. 10. 29. 11. 10.  3. 11.  3.  3.
 25. 10.  3.  0. 10.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 17. 30.  8.  2.  8.  1.  8.  8.  4.  8.  8.  0. 10.  9.] 
adversary cards in hand: [0. 6. 0. 1. 3.] 
adversary cards in discard: [ 6. 23.  3. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3] -> size -> 42 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: -12.068901062011719



action possibilites: [-1] 
expected returns: [[-19.651106]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  3.] 
cards in discard: [29. 29. 29. 25.  3.  3. 11.  0.  0. 10. 10. 29. 11. 10.  3. 11.  3.  3.
 25. 10.  3.  0. 10.  0. 10. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 17. 30.  8.  2.  8.  1.  8.  8.  4.  8.  8.  0. 10.  8.] 
adversary cards in hand: [0. 6. 0. 1. 3.] 
adversary cards in discard: [ 6. 23.  3. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3] -> size -> 42 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0 -60   0   0  64   0] 
sum of rewards: 319 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -22.793195724487305





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-26.273046]
 [-38.47403 ]
 [-19.651114]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  3.] 
cards in discard: [29. 29. 29. 25.  3.  3. 11.  0.  0. 10. 10. 29. 11. 10.  3. 11.  3.  3.
 25. 10.  3.  0. 10.  0. 10. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 17. 30.  8.  2.  8.  1.  8.  8.  4.  8.  8.  0. 10.  8.] 
adversary cards in hand: [0. 6. 0. 1. 3.] 
adversary cards in discard: [ 6. 23.  3. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3] -> size -> 42 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: -19.651105880737305






Player: 1 
cards in hand: [0. 6. 0. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 1. 3.] 
cards in discard: [ 6. 23.  3. 16.  0.  0.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 17. 30.  8.  2.  8.  1.  8.  8.  4.  8.  8.  0. 10.  8.] 
adversary cards in hand: [11. 11.  0. 29.  3.] 
adversary cards in discard: [29. 29. 29. 25.  3.  3. 11.  0.  0. 10. 10. 29. 11. 10.  3. 11.  3.  3.
 25. 10.  3.  0. 10.  0. 10. 15. 11.  3.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15] -> size -> 41 
adversary victory points: 10
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 1. 3.] 
cards in discard: [ 6. 23.  3. 16.  0.  0.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3] -> size -> 42 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 27. 30. 17. 30.  8.  2.  8.  1.  8.  8.  4.  8.  8.  0. 10.  8.] 
adversary cards in hand: [11. 11.  0. 29.  3.] 
adversary cards in discard: [29. 29. 29. 25.  3.  3. 11.  0.  0. 10. 10. 29. 11. 10.  3. 11.  3.  3.
 25. 10.  3.  0. 10.  0. 10. 15. 11.  3.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15] -> size -> 41 
adversary victory points: 10
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 1. 3.] 
cards in discard: [ 6. 23.  3. 16.  0.  0.  3.  1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 17. 30.  8.  2.  8.  1.  8.  8.  4.  8.  8.  0. 10.  8.] 
adversary cards in hand: [11. 11.  0. 29.  3.] 
adversary cards in discard: [29. 29. 29. 25.  3.  3. 11.  0.  0. 10. 10. 29. 11. 10.  3. 11.  3.  3.
 25. 10.  3.  0. 10.  0. 10. 15. 11.  3.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15] -> size -> 41 
adversary victory points: 10
player victory points: 0 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [11. 11.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 29.] 
expected returns: [[-24.658953]
 [-17.275885]
 [-17.275885]
 [-13.266533]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0. 29.  3.] 
cards in discard: [29. 29. 29. 25.  3.  3. 11.  0.  0. 10. 10. 29. 11. 10.  3. 11.  3.  3.
 25. 10.  3.  0. 10.  0. 10. 15. 11.  3.  0. 10.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 17. 30.  8.  2.  8.  1.  8.  8.  4.  8.  8.  0. 10.  8.] 
adversary cards in hand: [16.  1.  0.  1.  0.] 
adversary cards in discard: [ 6. 23.  3. 16.  0.  0.  3.  1.  0.  6.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1] -> size -> 43 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -19.651105880737305



action possibilites: [-1. 11. 11. 11.] 
expected returns: [[-23.973648]
 [-16.033764]
 [-16.033764]
 [-16.033764]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  3. 11.] 
cards in discard: [29. 29. 29. 25.  3.  3. 11.  0.  0. 10. 10. 29. 11. 10.  3. 11.  3.  3.
 25. 10.  3.  0. 10.  0. 10. 15. 11.  3.  0. 10.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 17. 30.  8.  2.  8.  1.  8.  8.  4.  8.  8.  0. 10.  8.] 
adversary cards in hand: [16.  1.  0.  1.  0.] 
adversary cards in discard: [ 6. 23.  3. 16.  0.  0.  3.  1.  0.  6.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1] -> size -> 43 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -19.79889678955078



action possibilites: [-1] 
expected returns: [[-27.659912]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 11.] 
cards in discard: [29. 29. 29. 25.  3.  3. 11.  0.  0. 10. 10. 29. 11. 10.  3. 11.  3.  3.
 25. 10.  3.  0. 10.  0. 10. 15. 11.  3.  0. 10.  3.  0. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 17. 30.  8.  2.  8.  1.  8.  8.  4.  8.  8.  0. 10.  7.] 
adversary cards in hand: [16.  1.  0.  1.  0.] 
adversary cards in discard: [ 6. 23.  3. 16.  0.  0.  3.  1.  0.  6.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1] -> size -> 43 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0 -70   0   0  64   0] 
sum of rewards: 329 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -11.889227867126465





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-33.833057]
 [-44.658512]
 [-27.659912]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 11.] 
cards in discard: [29. 29. 29. 25.  3.  3. 11.  0.  0. 10. 10. 29. 11. 10.  3. 11.  3.  3.
 25. 10.  3.  0. 10.  0. 10. 15. 11.  3.  0. 10.  3.  0. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 26. 30. 17. 30.  8.  2.  8.  1.  8.  8.  4.  8.  8.  0. 10.  7.] 
adversary cards in hand: [16.  1.  0.  1.  0.] 
adversary cards in discard: [ 6. 23.  3. 16.  0.  0.  3.  1.  0.  6.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1] -> size -> 43 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: take_action - action -1
Learning step: 0
desired expected reward: -27.659912109375






Player: 1 
cards in hand: [16.  1.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  1.  0.  1.  0.] 
cards in discard: [ 6. 23.  3. 16.  0.  0.  3.  1.  0.  6.  0.  1.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 17. 30.  8.  2.  8.  1.  8.  8.  4.  8.  8.  0. 10.  7.] 
adversary cards in hand: [ 3.  3. 10. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15] -> size -> 42 
adversary victory points: 10
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  1.  0.  1.  0.] 
cards in discard: [ 6. 23.  3. 16.  0.  0.  3.  1.  0.  6.  0.  1.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1] -> size -> 43 
action values: 0 
buys: 1 
player value: 6 
card supply: [25. 26. 30. 17. 30.  8.  2.  8.  1.  8.  8.  4.  8.  8.  0. 10.  7.] 
adversary cards in hand: [ 3.  3. 10. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15] -> size -> 42 
adversary victory points: 10
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  1.  0.  1.  0.] 
cards in discard: [ 6. 23.  3. 16.  0.  0.  3.  1.  0.  6.  0.  1.  3.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 6 
card supply: [24. 26. 30. 17. 30.  8.  2.  8.  1.  8.  8.  4.  8.  8.  0. 10.  7.] 
adversary cards in hand: [ 3.  3. 10. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15] -> size -> 42 
adversary victory points: 10
player victory points: 0 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 3.  3. 10. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[-1.179748 ]
 [-5.6216965]
 [14.556705 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10. 29.  0.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 17. 30.  8.  2.  8.  1.  8.  8.  4.  8.  8.  0. 10.  7.] 
adversary cards in hand: [14.  6.  3.  3. 15.] 
adversary cards in discard: [ 6. 23.  3. 16.  0.  0.  3.  1.  0.  6.  0.  1.  3.  0. 16.  1.  0.  1.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0] -> size -> 44 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -27.659912109375



action possibilites: [-1. 10. 11.] 
expected returns: [[-20.361967]
 [-24.02486 ]
 [-11.298744]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0. 11.] 
cards in discard: [3.] 
cards in deck: 36 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15] -> size -> 42 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 17. 30.  8.  2.  8.  1.  8.  8.  4.  8.  8.  0. 10.  7.] 
adversary cards in hand: [14.  6.  3.  3. 15.] 
adversary cards in discard: [ 6. 23.  3. 16.  0.  0.  3.  1.  0.  6.  0.  1.  3.  0. 16.  1.  0.  1.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0] -> size -> 44 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 5.9380784034729



action possibilites: [-1] 
expected returns: [[-8.974182]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.] 
cards in discard: [ 3. 15.] 
cards in deck: 36 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 17. 30.  8.  2.  8.  1.  8.  8.  4.  8.  8.  0. 10.  6.] 
adversary cards in hand: [14.  6.  3.  3. 15.] 
adversary cards in discard: [ 6. 23.  3. 16.  0.  0.  3.  1.  0.  6.  0.  1.  3.  0. 16.  1.  0.  1.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0] -> size -> 44 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0 -80   0   0  64   0] 
sum of rewards: 319 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -6.477612018585205





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-16.823935 ]
 [ -6.471645 ]
 [-32.06219  ]
 [ -7.1320896]
 [ -8.267765 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.] 
cards in discard: [ 3. 15.] 
cards in deck: 36 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 30. 17. 30.  8.  2.  8.  1.  8.  8.  4.  8.  8.  0. 10.  6.] 
adversary cards in hand: [14.  6.  3.  3. 15.] 
adversary cards in discard: [ 6. 23.  3. 16.  0.  0.  3.  1.  0.  6.  0.  1.  3.  0. 16.  1.  0.  1.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0] -> size -> 44 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: take_action - action -1
Learning step: 0
desired expected reward: -8.97418212890625



buy possibilites: [-1] 
expected returns: [[-2.0649707]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.] 
cards in discard: [ 3. 15.  3.] 
cards in deck: 36 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 16. 30.  8.  2.  8.  1.  8.  8.  4.  8.  8.  0. 10.  6.] 
adversary cards in hand: [14.  6.  3.  3. 15.] 
adversary cards in discard: [ 6. 23.  3. 16.  0.  0.  3.  1.  0.  6.  0.  1.  3.  0. 16.  1.  0.  1.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0] -> size -> 44 
adversary victory points: 0
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0 -90   0   0  16   0] 
sum of rewards: 291 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -6.471650123596191






Player: 1 
cards in hand: [14.  6.  3.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6.  3.  3. 15.] 
cards in discard: [ 6. 23.  3. 16.  0.  0.  3.  1.  0.  6.  0.  1.  3.  0. 16.  1.  0.  1.
  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 16. 30.  8.  2.  8.  1.  8.  8.  4.  8.  8.  0. 10.  6.] 
adversary cards in hand: [11. 10. 10.  3. 15.] 
adversary cards in discard: [ 3. 15.  3. 29. 11.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3] -> size -> 44 
adversary victory points: 11
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.  3.  3. 15.] 
cards in discard: [ 6. 23.  3. 16.  0.  0.  3.  1.  0.  6.  0.  1.  3.  0. 16.  1.  0.  1.
  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0] -> size -> 44 
action values: 1 
buys: 1 
player value: 0 
card supply: [24. 26. 30. 16. 30.  8.  2.  8.  1.  8.  8.  4.  8.  8.  0. 10.  6.] 
adversary cards in hand: [11. 10. 10.  3. 15.] 
adversary cards in discard: [ 3. 15.  3. 29. 11.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3] -> size -> 44 
adversary victory points: 11
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.  3.  3. 15.] 
cards in discard: [ 6. 23.  3. 16.  0.  0.  3.  1.  0.  6.  0.  1.  3.  0. 16.  1.  0.  1.
  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 16. 30.  8.  2.  8.  1.  8.  8.  4.  8.  8.  0. 10.  6.] 
adversary cards in hand: [11. 10. 10.  3. 15.] 
adversary cards in discard: [ 3. 15.  3. 29. 11.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3] -> size -> 44 
adversary victory points: 11
player victory points: 0 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [11. 10. 10.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10. 15.] 
expected returns: [[-1.6594148]
 [ 7.1980767]
 [-5.48936  ]
 [-5.48936  ]
 [-0.4578185]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 10.  3. 15.] 
cards in discard: [ 3. 15.  3. 29. 11.  3. 10.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 16. 30.  8.  2.  8.  1.  8.  8.  4.  8.  8.  0. 10.  6.] 
adversary cards in hand: [ 6. 11.  6.  0.  0.] 
adversary cards in discard: [ 6. 23.  3. 16.  0.  0.  3.  1.  0.  6.  0.  1.  3.  0. 16.  1.  0.  1.
  0.  0. 14.  6.  3.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0  0] -> size -> 45 
adversary victory points: 0
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: -2.0649707317352295



action possibilites: [-1] 
expected returns: [[-19.551413]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3. 15.] 
cards in discard: [ 3. 15.  3. 29. 11.  3. 10.  0. 15.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3 15] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 16. 30.  8.  2.  8.  1.  8.  8.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [ 6. 11.  6.  0.  0.] 
adversary cards in discard: [ 6. 23.  3. 16.  0.  0.  3.  1.  0.  6.  0.  1.  3.  0. 16.  1.  0.  1.
  0.  0. 14.  6.  3.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0  0] -> size -> 45 
adversary victory points: 0
player victory points: 11 

Reward from previous game state: 
[  -5    0    0  330    0    0   20    0    0    0    0 -100    0    0
   64    0] 
sum of rewards: 309 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 11.800857543945312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-26.095736]
 [-37.12152 ]
 [-19.49309 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  3. 15.] 
cards in discard: [ 3. 15.  3. 29. 11.  3. 10.  0. 15.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3 15] -> size -> 45 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 26. 30. 16. 30.  8.  2.  8.  1.  8.  8.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [ 6. 11.  6.  0.  0.] 
adversary cards in discard: [ 6. 23.  3. 16.  0.  0.  3.  1.  0.  6.  0.  1.  3.  0. 16.  1.  0.  1.
  0.  0. 14.  6.  3.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0  0] -> size -> 45 
adversary victory points: 0
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: -19.55141258239746






Player: 1 
cards in hand: [ 6. 11.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  6.  0.  0.] 
cards in discard: [ 6. 23.  3. 16.  0.  0.  3.  1.  0.  6.  0.  1.  3.  0. 16.  1.  0.  1.
  0.  0. 14.  6.  3.  3. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 16. 30.  8.  2.  8.  1.  8.  8.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [ 0.  3. 29. 25. 11.] 
adversary cards in discard: [ 3. 15.  3. 29. 11.  3. 10.  0. 15. 11. 10. 10.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3 15] -> size -> 45 
adversary victory points: 11
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  6.  0.  0.] 
cards in discard: [ 6. 23.  3. 16.  0.  0.  3.  1.  0.  6.  0.  1.  3.  0. 16.  1.  0.  1.
  0.  0. 14.  6.  3.  3. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0  0] -> size -> 45 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 26. 30. 16. 30.  8.  2.  8.  1.  8.  8.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [ 0.  3. 29. 25. 11.] 
adversary cards in discard: [ 3. 15.  3. 29. 11.  3. 10.  0. 15. 11. 10. 10.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3 15] -> size -> 45 
adversary victory points: 11
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 29. 25. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 11.] 
expected returns: [[-18.39743  ]
 [ -5.3799314]
 [  2.0481381]
 [ -9.864628 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29. 25. 11.] 
cards in discard: [ 3. 15.  3. 29. 11.  3. 10.  0. 15. 11. 10. 10.  3. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3 15] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 16. 30.  8.  2.  8.  1.  8.  8.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [ 6.  6.  0.  0. 11.] 
adversary cards in discard: [ 6. 23.  3. 16.  0.  0.  3.  1.  0.  6.  0.  1.  3.  0. 16.  1.  0.  1.
  0.  0. 14.  6.  3.  3. 15.  6. 11.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0  0] -> size -> 45 
adversary victory points: 0
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -19.493093490600586



action possibilites: [-1] 
expected returns: [[-25.500322]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29. 11.  0. 11.] 
cards in discard: [ 3. 15.  3. 29. 11.  3. 10.  0. 15. 11. 10. 10.  3. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3 15] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 16. 30.  8.  1.  8.  1.  8.  8.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [ 6.  6.  0.  0. 11.] 
adversary cards in discard: [ 6. 23.  3. 16.  0.  0.  3.  1.  0.  6.  0.  1.  3.  0. 16.  1.  0.  1.
  0.  0. 14.  6.  3.  3. 15.  6. 11.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0  0  6] -> size -> 46 
adversary victory points: 0
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 2.048125743865967





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-32.485977]
 [-24.8914  ]
 [-43.054626]
 [-25.381756]
 [-26.095589]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 29. 11.  0. 11.] 
cards in discard: [ 3. 15.  3. 29. 11.  3. 10.  0. 15. 11. 10. 10.  3. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3 15] -> size -> 45 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 26. 30. 16. 30.  8.  1.  8.  1.  8.  8.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [ 6.  6.  0.  0. 11.] 
adversary cards in discard: [ 6. 23.  3. 16.  0.  0.  3.  1.  0.  6.  0.  1.  3.  0. 16.  1.  0.  1.
  0.  0. 14.  6.  3.  3. 15.  6. 11.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0  0  6] -> size -> 46 
adversary victory points: 0
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: -25.500322341918945



buy possibilites: [-1] 
expected returns: [[2.5701127]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 29. 11.  0. 11.] 
cards in discard: [ 3. 15.  3. 29. 11.  3. 10.  0. 15. 11. 10. 10.  3. 15.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3 15  3] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 15. 30.  8.  1.  8.  1.  8.  8.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [ 6.  6.  0.  0. 11.] 
adversary cards in discard: [ 6. 23.  3. 16.  0.  0.  3.  1.  0.  6.  0.  1.  3.  0. 16.  1.  0.  1.
  0.  0. 14.  6.  3.  3. 15.  6. 11.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0  0  6] -> size -> 46 
adversary victory points: 0
player victory points: 12 

Reward from previous game state: 
[  -5    0    0  360    0    0   20    0    0    0    0 -110    0    0
   16    0] 
sum of rewards: 281 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -24.89140510559082






Player: 1 
cards in hand: [ 6.  6.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0.  0. 11.] 
cards in discard: [ 6. 23.  3. 16.  0.  0.  3.  1.  0.  6.  0.  1.  3.  0. 16.  1.  0.  1.
  0.  0. 14.  6.  3.  3. 15.  6. 11.  6.  0.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0  0  6] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 15. 30.  8.  1.  8.  1.  8.  8.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [29. 29. 11. 10.  0.] 
adversary cards in discard: [ 3. 15.  3. 29. 11.  3. 10.  0. 15. 11. 10. 10.  3. 15.  3. 25.  0.  3.
 29. 11.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3 15  3] -> size -> 46 
adversary victory points: 12
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0.  0. 11.] 
cards in discard: [ 6. 23.  3. 16.  0.  0.  3.  1.  0.  6.  0.  1.  3.  0. 16.  1.  0.  1.
  0.  0. 14.  6.  3.  3. 15.  6. 11.  6.  0.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0  0  6] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 26. 30. 15. 30.  8.  1.  8.  1.  8.  8.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [29. 29. 11. 10.  0.] 
adversary cards in discard: [ 3. 15.  3. 29. 11.  3. 10.  0. 15. 11. 10. 10.  3. 15.  3. 25.  0.  3.
 29. 11.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3 15  3] -> size -> 46 
adversary victory points: 12
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0.  0. 11.] 
cards in discard: [ 6. 23.  3. 16.  0.  0.  3.  1.  0.  6.  0.  1.  3.  0. 16.  1.  0.  1.
  0.  0. 14.  6.  3.  3. 15.  6. 11.  6.  0.  0.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0  0  6  0] -> size -> 47 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 26. 30. 15. 30.  8.  1.  8.  1.  8.  8.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [29. 29. 11. 10.  0.] 
adversary cards in discard: [ 3. 15.  3. 29. 11.  3. 10.  0. 15. 11. 10. 10.  3. 15.  3. 25.  0.  3.
 29. 11.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3 15  3] -> size -> 46 
adversary victory points: 12
player victory points: -1 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [29. 29. 11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 11. 10.] 
expected returns: [[-37.33389 ]
 [-25.625568]
 [-25.625568]
 [-29.669216]
 [-40.771004]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 11. 10.  0.] 
cards in discard: [ 3. 15.  3. 29. 11.  3. 10.  0. 15. 11. 10. 10.  3. 15.  3. 25.  0.  3.
 29. 11.  0. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3 15  3] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 15. 30.  8.  1.  8.  1.  8.  8.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [ 3.  3. 10.  3. 14.] 
adversary cards in discard: [ 6. 23.  3. 16.  0.  0.  3.  1.  0.  6.  0.  1.  3.  0. 16.  1.  0.  1.
  0.  0. 14.  6.  3.  3. 15.  6. 11.  6.  0.  0.  6.  0.  6.  6.  0.  0.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0  0  6  0] -> size -> 47 
adversary victory points: -1
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1
Learning step: 0
desired expected reward: 2.570112705230713



action possibilites: [-1. 11. 10. 29.] 
expected returns: [[-33.086052]
 [-25.125069]
 [-36.591934]
 [-20.950867]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0. 29.] 
cards in discard: [ 3. 15.  3. 29. 11.  3. 10.  0. 15. 11. 10. 10.  3. 15.  3. 25.  0.  3.
 29. 11.  0. 11. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3 15  3] -> size -> 46 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 26. 30. 15. 30.  8.  1.  8.  1.  8.  8.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [ 3.  3. 10.  3. 14.] 
adversary cards in discard: [ 6. 23.  3. 16.  0.  0.  3.  1.  0.  6.  0.  1.  3.  0. 16.  1.  0.  1.
  0.  0. 14.  6.  3.  3. 15.  6. 11.  6.  0.  0.  6.  0.  6.  6.  0.  0.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0  0  6  0] -> size -> 47 
adversary victory points: -1
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -32.292266845703125



action possibilites: [-1. 11. 10.] 
expected returns: [[-2.892704 ]
 [ 5.3178906]
 [-6.4712195]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.] 
cards in discard: [ 3. 15.  3. 29. 11.  3. 10.  0. 15. 11. 10. 10.  3. 15.  3. 25.  0.  3.
 29. 11.  0. 11. 29. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3 15  3] -> size -> 46 
action values: 1 
buys: 0 
player value: 2 
card supply: [22. 26. 30. 15. 30.  8.  1.  8.  1.  8.  8.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [ 3.  3. 10.  3. 14.] 
adversary cards in discard: [ 6. 23.  3. 16.  0.  0.  3.  1.  0.  6.  0.  1.  3.  0. 16.  1.  0.  1.
  0.  0. 14.  6.  3.  3. 15.  6. 11.  6.  0.  0.  6.  0.  6.  6.  0.  0.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0  0  6  0] -> size -> 47 
adversary victory points: -1
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 390   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 425 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -27.824935913085938



action possibilites: [-1] 
expected returns: [[-40.45119]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.] 
cards in discard: [ 3. 15.  3. 29. 11.  3. 10.  0. 15. 11. 10. 10.  3. 15.  3. 25.  0.  3.
 29. 11.  0. 11. 29. 29. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3 15  3 15] -> size -> 47 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 26. 30. 15. 30.  8.  1.  8.  1.  8.  8.  4.  8.  8.  0. 10.  4.] 
adversary cards in hand: [ 3.  3. 10.  3. 14.] 
adversary cards in discard: [ 6. 23.  3. 16.  0.  0.  3.  1.  0.  6.  0.  1.  3.  0. 16.  1.  0.  1.
  0.  0. 14.  6.  3.  3. 15.  6. 11.  6.  0.  0.  6.  0.  6.  6.  0.  0.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0  0  6  0] -> size -> 47 
adversary victory points: -1
player victory points: 12 

Reward from previous game state: 
[  -5    0    0  390    0    0   60    0    0    0    0 -120    0    0
   64    0] 
sum of rewards: 389 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 9.596281051635742





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[-45.910034]
 [-35.819096]
 [-39.50319 ]
 [-55.30835 ]
 [-33.4218  ]
 [-39.905285]
 [-40.451187]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [ 3. 15.  3. 29. 11.  3. 10.  0. 15. 11. 10. 10.  3. 15.  3. 25.  0.  3.
 29. 11.  0. 11. 29. 29. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3 15  3 15] -> size -> 47 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 26. 30. 15. 30.  8.  1.  8.  1.  8.  8.  4.  8.  8.  0. 10.  4.] 
adversary cards in hand: [ 3.  3. 10.  3. 14.] 
adversary cards in discard: [ 6. 23.  3. 16.  0.  0.  3.  1.  0.  6.  0.  1.  3.  0. 16.  1.  0.  1.
  0.  0. 14.  6.  3.  3. 15.  6. 11.  6.  0.  0.  6.  0.  6.  6.  0.  0.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0  0  6  0] -> size -> 47 
adversary victory points: -1
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 390   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 445 

action type: take_action - action -1
Learning step: 0
desired expected reward: -40.45119094848633



buy possibilites: [-1] 
expected returns: [[-39.311424]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [ 3. 15.  3. 29. 11.  3. 10.  0. 15. 11. 10. 10.  3. 15.  3. 25.  0.  3.
 29. 11.  0. 11. 29. 29. 15. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3 15  3 15 11] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 15. 30.  8.  1.  8.  0.  8.  8.  4.  8.  8.  0. 10.  4.] 
adversary cards in hand: [ 3.  3. 10.  3. 14.] 
adversary cards in discard: [ 6. 23.  3. 16.  0.  0.  3.  1.  0.  6.  0.  1.  3.  0. 16.  1.  0.  1.
  0.  0. 14.  6.  3.  3. 15.  6. 11.  6.  0.  0.  6.  0.  6.  6.  0.  0.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0  0  6  0] -> size -> 47 
adversary victory points: -1
player victory points: 12 

Reward from previous game state: 
[  -5    0    0  390    0    0   60    0    0    0    0 -130    0    0
   54    0] 
sum of rewards: 369 

action type: buy - action 11.0
Learning step: 0
desired expected reward: -33.42179870605469






Player: 1 
cards in hand: [ 3.  3. 10.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.  3. 14.] 
cards in discard: [ 6. 23.  3. 16.  0.  0.  3.  1.  0.  6.  0.  1.  3.  0. 16.  1.  0.  1.
  0.  0. 14.  6.  3.  3. 15.  6. 11.  6.  0.  0.  6.  0.  6.  6.  0.  0.
 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0  0  6  0] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 15. 30.  8.  1.  8.  0.  8.  8.  4.  8.  8.  0. 10.  4.] 
adversary cards in hand: [10.  3.  0.  0.  3.] 
adversary cards in discard: [ 3. 15.  3. 29. 11.  3. 10.  0. 15. 11. 10. 10.  3. 15.  3. 25.  0.  3.
 29. 11.  0. 11. 29. 29. 15. 11. 29. 29. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3 15  3 15 11] -> size -> 48 
adversary victory points: 12
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.  3.] 
cards in discard: [ 6. 23.  3. 16.  0.  0.  3.  1.  0.  6.  0.  1.  3.  0. 16.  1.  0.  1.
  0.  0. 14.  6.  3.  3. 15.  6. 11.  6.  0.  0.  6.  0.  6.  6.  0.  0.
 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0  0  6  0] -> size -> 47 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 26. 30. 15. 30.  8.  1.  8.  0.  8.  8.  4.  8.  8.  0. 10.  4.] 
adversary cards in hand: [10.  0.  3.] 
adversary cards in discard: [ 3. 15.  3. 29. 11.  3. 10.  0. 15. 11. 10. 10.  3. 15.  3. 25.  0.  3.
 29. 11.  0. 11. 29. 29. 15. 11. 29. 29. 11. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3 15  3 15 11] -> size -> 48 
adversary victory points: 12
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.  3.] 
cards in discard: [ 6. 23.  3. 16.  0.  0.  3.  1.  0.  6.  0.  1.  3.  0. 16.  1.  0.  1.
  0.  0. 14.  6.  3.  3. 15.  6. 11.  6.  0.  0.  6.  0.  6.  6.  0.  0.
 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0  0  6  0] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 26. 30. 15. 30.  8.  1.  8.  0.  8.  8.  4.  8.  8.  0. 10.  4.] 
adversary cards in hand: [10.  0.  3.] 
adversary cards in discard: [ 3. 15.  3. 29. 11.  3. 10.  0. 15. 11. 10. 10.  3. 15.  3. 25.  0.  3.
 29. 11.  0. 11. 29. 29. 15. 11. 29. 29. 11. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3 15  3 15 11] -> size -> 48 
adversary victory points: 12
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.  3.] 
cards in discard: [ 6. 23.  3. 16.  0.  0.  3.  1.  0.  6.  0.  1.  3.  0. 16.  1.  0.  1.
  0.  0. 14.  6.  3.  3. 15.  6. 11.  6.  0.  0.  6.  0.  6.  6.  0.  0.
 11.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0  0  6  0  3] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 14. 30.  8.  1.  8.  0.  8.  8.  4.  8.  8.  0. 10.  4.] 
adversary cards in hand: [10.  0.  3.] 
adversary cards in discard: [ 3. 15.  3. 29. 11.  3. 10.  0. 15. 11. 10. 10.  3. 15.  3. 25.  0.  3.
 29. 11.  0. 11. 29. 29. 15. 11. 29. 29. 11. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3 15  3 15 11] -> size -> 48 
adversary victory points: 12
player victory points: 0 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[-17.995775]
 [-21.180525]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.] 
cards in discard: [ 3. 15.  3. 29. 11.  3. 10.  0. 15. 11. 10. 10.  3. 15.  3. 25.  0.  3.
 29. 11.  0. 11. 29. 29. 15. 11. 29. 29. 11. 10.  0.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3 15  3 15 11] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 14. 30.  8.  1.  8.  0.  8.  8.  4.  8.  8.  0. 10.  4.] 
adversary cards in hand: [23.  0.  6.  0.  8.] 
adversary cards in discard: [ 6. 23.  3. 16.  0.  0.  3.  1.  0.  6.  0.  1.  3.  0. 16.  1.  0.  1.
  0.  0. 14.  6.  3.  3. 15.  6. 11.  6.  0.  0.  6.  0.  6.  6.  0.  0.
 11.  3. 14.  3.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0  0  6  0  3] -> size -> 48 
adversary victory points: 0
player victory points: 12 

Reward from previous game state: 
[  -5    0    0  360    0    0    0    0    0    0    0 -130    0    0
 1273    0] 
sum of rewards: 1498 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -71.90324401855469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-23.595757]
 [-33.456047]
 [-17.995775]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.] 
cards in discard: [ 3. 15.  3. 29. 11.  3. 10.  0. 15. 11. 10. 10.  3. 15.  3. 25.  0.  3.
 29. 11.  0. 11. 29. 29. 15. 11. 29. 29. 11. 10.  0.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3 15  3 15 11] -> size -> 48 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 14. 30.  8.  1.  8.  0.  8.  8.  4.  8.  8.  0. 10.  4.] 
adversary cards in hand: [23.  0.  6.  0.  8.] 
adversary cards in discard: [ 6. 23.  3. 16.  0.  0.  3.  1.  0.  6.  0.  1.  3.  0. 16.  1.  0.  1.
  0.  0. 14.  6.  3.  3. 15.  6. 11.  6.  0.  0.  6.  0.  6.  6.  0.  0.
 11.  3. 14.  3.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0  0  6  0  3] -> size -> 48 
adversary victory points: 0
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -17.99576759338379



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [23.  0.  6.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0.  6.  0.  8.] 
cards in discard: [ 6. 23.  3. 16.  0.  0.  3.  1.  0.  6.  0.  1.  3.  0. 16.  1.  0.  1.
  0.  0. 14.  6.  3.  3. 15.  6. 11.  6.  0.  0.  6.  0.  6.  6.  0.  0.
 11.  3. 14.  3.  3. 10.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1  6 16 23  6  0  3 14 16  3 15  6
 11  6 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0  0  6  0  3] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 14. 30.  8.  1.  8.  0.  8.  8.  4.  8.  8.  0. 10.  4.] 
adversary cards in hand: [ 3. 10. 11.  3. 15.] 
adversary cards in discard: [ 3. 15.  3. 29. 11.  3. 10.  0. 15. 11. 10. 10.  3. 15.  3. 25.  0.  3.
 29. 11.  0. 11. 29. 29. 15. 11. 29. 29. 11. 10.  0.  0.  3. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3 15  3 15 11] -> size -> 48 
adversary victory points: 12
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 6. 23.  3. 16.  0.  0.  3.  1.  0.  6.  0.  1.  3.  0. 16.  1.  0.  1.
  0.  0. 14.  6.  3.  3. 15.  6. 11.  6.  0.  0.  6.  0.  6.  6.  0.  0.
 11.  3. 14.  3.  3. 10.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 16  6  0  3 14 16  3 15  6 11  6
 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0  0  6  0  3] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 14. 30.  8.  1.  8.  0.  8.  8.  4.  8.  8.  0. 10.  4.] 
adversary cards in hand: [ 3. 10. 11.  3. 15.] 
adversary cards in discard: [ 3. 15.  3. 29. 11.  3. 10.  0. 15. 11. 10. 10.  3. 15.  3. 25.  0.  3.
 29. 11.  0. 11. 29. 29. 15. 11. 29. 29. 11. 10.  0.  0.  3. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3 15  3 15 11] -> size -> 48 
adversary victory points: 12
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 6. 23.  3. 16.  0.  0.  3.  1.  0.  6.  0.  1.  3.  0. 16.  1.  0.  1.
  0.  0. 14.  6.  3.  3. 15.  6. 11.  6.  0.  0.  6.  0.  6.  6.  0.  0.
 11.  3. 14.  3.  3. 10.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 16  6  0  3 14 16  3 15  6 11  6
 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0  0  6  0  3] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 26. 30. 14. 30.  8.  1.  8.  0.  8.  8.  4.  8.  8.  0. 10.  4.] 
adversary cards in hand: [ 3. 10. 11.  3. 15.] 
adversary cards in discard: [ 3. 15.  3. 29. 11.  3. 10.  0. 15. 11. 10. 10.  3. 15.  3. 25.  0.  3.
 29. 11.  0. 11. 29. 29. 15. 11. 29. 29. 11. 10.  0.  0.  3. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3 15  3 15 11] -> size -> 48 
adversary victory points: 12
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 6. 23.  3. 16.  0.  0.  3.  1.  0.  6.  0.  1.  3.  0. 16.  1.  0.  1.
  0.  0. 14.  6.  3.  3. 15.  6. 11.  6.  0.  0.  6.  0.  6.  6.  0.  0.
 11.  3. 14.  3.  3. 10.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 16  6  0  3 14 16  3 15  6 11  6
 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0  0  6  0  3  8] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 14. 30.  8.  1.  8.  0.  7.  8.  4.  8.  8.  0. 10.  4.] 
adversary cards in hand: [ 3. 10. 11.  3. 15.] 
adversary cards in discard: [ 3. 15.  3. 29. 11.  3. 10.  0. 15. 11. 10. 10.  3. 15.  3. 25.  0.  3.
 29. 11.  0. 11. 29. 29. 15. 11. 29. 29. 11. 10.  0.  0.  3. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3 15  3 15 11] -> size -> 48 
adversary victory points: 12
player victory points: 1 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 11.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 15.] 
expected returns: [[-40.520573]
 [-43.62655 ]
 [-33.5202  ]
 [-39.644493]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11.  3. 15.] 
cards in discard: [ 3. 15.  3. 29. 11.  3. 10.  0. 15. 11. 10. 10.  3. 15.  3. 25.  0.  3.
 29. 11.  0. 11. 29. 29. 15. 11. 29. 29. 11. 10.  0.  0.  3. 10.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3 15  3 15 11] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 14. 30.  8.  1.  8.  0.  7.  8.  4.  8.  8.  0. 10.  4.] 
adversary cards in hand: [14. 16.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 16  6  0  3 14 16  3 15  6 11  6
 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0  0  6  0  3  8] -> size -> 47 
adversary victory points: 1
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -17.99576759338379



action possibilites: [-1] 
expected returns: [[-39.72409]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3. 15.] 
cards in discard: [ 3. 15.  3. 29. 11.  3. 10.  0. 15. 11. 10. 10.  3. 15.  3. 25.  0.  3.
 29. 11.  0. 11. 29. 29. 15. 11. 29. 29. 11. 10.  0.  0.  3. 10.  0.  3.
  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3 15  3 15 11
  1] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 14. 30.  8.  1.  8.  0.  7.  8.  4.  8.  8.  0. 10.  4.] 
adversary cards in hand: [14. 16.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 16  6  0  3 14 16  3 15  6 11  6
 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0  0  6  0  3  8] -> size -> 47 
adversary victory points: 1
player victory points: 12 

Reward from previous game state: 
[  -5    0    0  330    0    0   20    0    0    0    0 -140    0    0
   27    0] 
sum of rewards: 232 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -35.9237060546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-45.79229 ]
 [-56.34671 ]
 [-39.724087]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3. 15.] 
cards in discard: [ 3. 15.  3. 29. 11.  3. 10.  0. 15. 11. 10. 10.  3. 15.  3. 25.  0.  3.
 29. 11.  0. 11. 29. 29. 15. 11. 29. 29. 11. 10.  0.  0.  3. 10.  0.  3.
  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3 15  3 15 11
  1] -> size -> 49 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 25. 30. 14. 30.  8.  1.  8.  0.  7.  8.  4.  8.  8.  0. 10.  4.] 
adversary cards in hand: [14. 16.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 16  6  0  3 14 16  3 15  6 11  6
 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0  0  6  0  3  8] -> size -> 47 
adversary victory points: 1
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: -39.724090576171875






Player: 1 
cards in hand: [14. 16.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 16.  6.  0.  0.] 
cards in discard: [] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 16  6  0  3 14 16  3 15  6 11  6
 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0  0  6  0  3  8] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 14. 30.  8.  1.  8.  0.  7.  8.  4.  8.  8.  0. 10.  4.] 
adversary cards in hand: [ 0. 10. 10. 11.  3.] 
adversary cards in discard: [ 3. 15.  3. 29. 11.  3. 10.  0. 15. 11. 10. 10.  3. 15.  3. 25.  0.  3.
 29. 11.  0. 11. 29. 29. 15. 11. 29. 29. 11. 10.  0.  0.  3. 10.  0.  3.
  1. 11.  3. 10.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3 15  3 15 11
  1] -> size -> 49 
adversary victory points: 12
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6.  0.  0.] 
cards in discard: [] 
cards in deck: 42 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 16  6  0  3 14 16  3 15  6 11  6
 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0  0  6  0  3  8] -> size -> 47 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 25. 30. 14. 30.  8.  1.  8.  0.  7.  8.  4.  8.  8.  0. 10.  4.] 
adversary cards in hand: [10. 11.  3.] 
adversary cards in discard: [ 3. 15.  3. 29. 11.  3. 10.  0. 15. 11. 10. 10.  3. 15.  3. 25.  0.  3.
 29. 11.  0. 11. 29. 29. 15. 11. 29. 29. 11. 10.  0.  0.  3. 10.  0.  3.
  1. 11.  3. 10.  3. 15.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3 15  3 15 11
  1] -> size -> 49 
adversary victory points: 12
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6.  0.  0.] 
cards in discard: [] 
cards in deck: 42 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 16  6  0  3 14 16  3 15  6 11  6
 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0  0  6  0  3  8] -> size -> 47 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 25. 30. 14. 30.  8.  1.  8.  0.  7.  8.  4.  8.  8.  0. 10.  4.] 
adversary cards in hand: [10. 11.  3.] 
adversary cards in discard: [ 3. 15.  3. 29. 11.  3. 10.  0. 15. 11. 10. 10.  3. 15.  3. 25.  0.  3.
 29. 11.  0. 11. 29. 29. 15. 11. 29. 29. 11. 10.  0.  0.  3. 10.  0.  3.
  1. 11.  3. 10.  3. 15.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3 15  3 15 11
  1] -> size -> 49 
adversary victory points: 12
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6.  0.  0.] 
cards in discard: [14.] 
cards in deck: 42 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 16  6  0  3 14 16  3 15  6 11  6
 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0  0  6  0  3  8 14] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 14. 30.  8.  1.  8.  0.  7.  8.  4.  7.  8.  0. 10.  4.] 
adversary cards in hand: [10. 11.  3.] 
adversary cards in discard: [ 3. 15.  3. 29. 11.  3. 10.  0. 15. 11. 10. 10.  3. 15.  3. 25.  0.  3.
 29. 11.  0. 11. 29. 29. 15. 11. 29. 29. 11. 10.  0.  0.  3. 10.  0.  3.
  1. 11.  3. 10.  3. 15.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3 15  3 15 11
  1] -> size -> 49 
adversary victory points: 12
player victory points: 1 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [10. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[-44.309364]
 [-47.565193]
 [-37.00585 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  3.] 
cards in discard: [ 3. 15.  3. 29. 11.  3. 10.  0. 15. 11. 10. 10.  3. 15.  3. 25.  0.  3.
 29. 11.  0. 11. 29. 29. 15. 11. 29. 29. 11. 10.  0.  0.  3. 10.  0.  3.
  1. 11.  3. 10.  3. 15.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3 15  3 15 11
  1] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 14. 30.  8.  1.  8.  0.  7.  8.  4.  7.  8.  0. 10.  4.] 
adversary cards in hand: [ 1. 11. 23.  3. 11.] 
adversary cards in discard: [14. 14. 16.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 16  6  0  3 14 16  3 15  6 11  6
 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0  0  6  0  3  8 14] -> size -> 48 
adversary victory points: 1
player victory points: 12 

Reward from previous game state: 
[  -5    0    0  330    0    0    0    0    0    0    0 -140    0    0
 1265    0] 
sum of rewards: 1450 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -66.21424102783203



action possibilites: [-1] 
expected returns: [[-46.554123]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.] 
cards in discard: [ 3. 15.  3. 29. 11.  3. 10.  0. 15. 11. 10. 10.  3. 15.  3. 25.  0.  3.
 29. 11.  0. 11. 29. 29. 15. 11. 29. 29. 11. 10.  0.  0.  3. 10.  0.  3.
  1. 11.  3. 10.  3. 15.  0. 10.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3 15  3 15 11
  1  1] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 14. 30.  8.  1.  8.  0.  7.  8.  4.  7.  8.  0. 10.  4.] 
adversary cards in hand: [ 1. 11. 23.  3. 11.] 
adversary cards in discard: [14. 14. 16.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 16  6  0  3 14 16  3 15  6 11  6
 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0  0  6  0  3  8 14] -> size -> 48 
adversary victory points: 1
player victory points: 12 

Reward from previous game state: 
[  -5    0    0  330    0    0   20    0    0    0    0 -150    0    0
   27    0] 
sum of rewards: 222 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -39.49303436279297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-51.585045]
 [-60.782314]
 [-46.554123]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.] 
cards in discard: [ 3. 15.  3. 29. 11.  3. 10.  0. 15. 11. 10. 10.  3. 15.  3. 25.  0.  3.
 29. 11.  0. 11. 29. 29. 15. 11. 29. 29. 11. 10.  0.  0.  3. 10.  0.  3.
  1. 11.  3. 10.  3. 15.  0. 10.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3 15  3 15 11
  1  1] -> size -> 50 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 24. 30. 14. 30.  8.  1.  8.  0.  7.  8.  4.  7.  8.  0. 10.  4.] 
adversary cards in hand: [ 1. 11. 23.  3. 11.] 
adversary cards in discard: [14. 14. 16.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 16  6  0  3 14 16  3 15  6 11  6
 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0  0  6  0  3  8 14] -> size -> 48 
adversary victory points: 1
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: -46.55412292480469






Player: 1 
cards in hand: [ 1. 11. 23.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 23. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11. 23.  3. 11.] 
cards in discard: [14. 14. 16.  6.  0.  0.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 16  6  0  3 14 16  3 15  6 11  6
 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0  0  6  0  3  8 14] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 14. 30.  8.  1.  8.  0.  7.  8.  4.  7.  8.  0. 10.  4.] 
adversary cards in hand: [ 3. 10.  1.  3. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3 15  3 15 11
  1  1] -> size -> 50 
adversary victory points: 12
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 23.  3. 11.] 
cards in discard: [14. 14. 16.  6.  0.  0. 15.] 
cards in deck: 37 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 16  6  0  3 14 16  3 15  6 11  6
 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0  0  6  0  3  8 14
 15] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 14. 30.  8.  1.  8.  0.  7.  8.  4.  7.  8.  0. 10.  3.] 
adversary cards in hand: [ 3. 10.  1.  3. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3 15  3 15 11
  1  1] -> size -> 50 
adversary victory points: 12
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 23.  3. 11.] 
cards in discard: [14. 14. 16.  6.  0.  0. 15.] 
cards in deck: 37 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 16  6  0  3 14 16  3 15  6 11  6
 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0  0  6  0  3  8 14
 15] -> size -> 49 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 24. 30. 14. 30.  8.  1.  8.  0.  7.  8.  4.  7.  8.  0. 10.  3.] 
adversary cards in hand: [ 3. 10.  1.  3. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3 15  3 15 11
  1  1] -> size -> 50 
adversary victory points: 12
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 23.  3. 11.] 
cards in discard: [14. 14. 16.  6.  0.  0. 15.  3.] 
cards in deck: 37 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 16  6  0  3 14 16  3 15  6 11  6
 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0  0  6  0  3  8 14
 15  3] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 13. 30.  8.  1.  8.  0.  7.  8.  4.  7.  8.  0. 10.  3.] 
adversary cards in hand: [ 3. 10.  1.  3. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3 15  3 15 11
  1  1] -> size -> 50 
adversary victory points: 12
player victory points: 2 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 3. 10.  1.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[40.74279]
 [36.27165]
 [66.74082]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  1.  3. 25.] 
cards in discard: [] 
cards in deck: 45 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3 15  3 15 11
  1  1] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 13. 30.  8.  1.  8.  0.  7.  8.  4.  7.  8.  0. 10.  3.] 
adversary cards in hand: [ 0.  3.  8.  6. 15.] 
adversary cards in discard: [14. 14. 16.  6.  0.  0. 15.  3. 11.  1. 23.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 16  6  0  3 14 16  3 15  6 11  6
 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0  0  6  0  3  8 14
 15  3] -> size -> 50 
adversary victory points: 2
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -46.55412292480469



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 9 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 8 
Chapel: 0 
Witch: 2 
Poacher: 6 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 3. 10.  1.  3.  3. 11.] 
cards in discard: [] 
cards in deck: 43 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 10 25 10 11 29 10 11 10 29  3  3
 25 10  3 29 11 29 10 11 11 11  3 10  3 29 10  3 15 15 15  3 15  3 15 11
  1  1] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 13. 30.  8.  0.  8.  0.  7.  8.  4.  7.  8.  0. 10.  3.] 
adversary cards in hand: [ 0.  3.  8.  6. 15.] 
adversary cards in discard: [14. 14. 16.  6.  0.  0. 15.  3. 11.  1. 23.  3. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 14  1 16  6  0  3 14 16  3 15  6 11  6
 10  6  3  0  1  0  6  8  0 11  3  6  0  6 23  3  1  0  0  6  0  3  8 14
 15  3  6] -> size -> 51 
adversary victory points: 2
player victory points: 12 

Reward from previous game state: 
[     -5 3000000       0     300       0       0      20       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000315 

action type: take_action - action 25.0
Learning step: 120009.9296875
desired expected reward: 120076.671875



