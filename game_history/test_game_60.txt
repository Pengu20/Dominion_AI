 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[10.600996]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0      -60        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000065 

action type: buy - action -1.0
Learning step: -119998.6796875
desired expected reward: -120096.6484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 10.063946]
 [ 16.02472 ]
 [-54.18052 ]
 [ 12.725224]
 [  9.875311]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 10.394281387329102



buy possibilites: [-1] 
expected returns: [[9.375481]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0 16  0] 
sum of rewards: 41 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 16.02471923828125






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 3. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 3. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 3. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[17.101734]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3. 0. 3. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [8. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 9.375480651855469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 16.84139 ]
 [ 32.386654]
 [ 23.102774]
 [ -9.473828]
 [-47.357082]
 [ 25.30908 ]
 [ 27.90642 ]
 [ 19.421711]
 [ 33.841503]
 [ 39.160233]
 [ 25.54697 ]
 [ 31.570698]
 [ 24.832481]
 [ 13.8022  ]
 [ 31.841412]
 [ 16.525259]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3. 0. 3. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [8. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 15.563142776489258



buy possibilites: [-1] 
expected returns: [[-0.77096725]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 3.  0.  3.  3.  0.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [8. 0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0. 30.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 57.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 39.160240173339844






Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [8. 0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29] -> size -> 12 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [8. 0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29] -> size -> 12 
adversary victory points: 4
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[1.4706953]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.7709672451019287





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ -0.10445738]
 [ 15.128502  ]
 [  6.033765  ]
 [-62.518734  ]
 [ 10.688508  ]
 [  2.2225072 ]
 [  7.83665   ]
 [  0.33452845]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 0.16314363479614258



buy possibilites: [-1] 
expected returns: [[8.718277]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 79 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 15.12850570678711






Player: 1 
cards in hand: [0. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  0.  0.] 
adversary cards in discard: [1. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1] -> size -> 13 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  0.  0.] 
adversary cards in discard: [1. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1] -> size -> 13 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  0.  0.] 
adversary cards in discard: [1. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1] -> size -> 13 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 3. 29.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-5.555854]
 [15.792751]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3.  0.  0.] 
cards in discard: [1. 3. 3. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [1. 0. 0. 0. 8. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 8.718276977539062



action possibilites: [-1.] 
expected returns: [[6.080821]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [1. 3. 3. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [1. 0. 0. 0. 8. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 13.951417922973633





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[  8.246219]
 [ 23.045904]
 [ 14.573778]
 [-56.066643]
 [ 16.80982 ]
 [ 19.208008]
 [ 10.782387]
 [ 29.099236]
 [ 17.064096]
 [ 16.414871]
 [ 22.662252]
 [  8.866503]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [1. 3. 3. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [1. 0. 0. 0. 8. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 6.0808210372924805



buy possibilites: [-1] 
expected returns: [[5.8736925]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 1.  3.  3.  0.  0.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [1. 0. 0. 0. 8. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 173 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 29.099239349365234






Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [1. 0. 0. 0. 8. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29] -> size -> 14 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [1. 0. 0. 0. 8. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 1] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 29. 30.  8. 10. 10. 10.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29] -> size -> 14 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [1. 0. 0. 0. 8. 0. 1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 1 1] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29] -> size -> 14 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [29.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[16.25034]
 [34.72734]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 0. 1. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 1 1] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 5.873692512512207



action possibilites: [-1.] 
expected returns: [[9.853803]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 0. 1. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 1 1] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 31.82861328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[  7.8874598]
 [ 23.90628  ]
 [ 14.481342 ]
 [-21.641344 ]
 [-61.62564  ]
 [ 16.966711 ]
 [ 19.48191  ]
 [ 10.739315 ]
 [ 25.300585 ]
 [ 30.52332  ]
 [ 17.187138 ]
 [ 23.088646 ]
 [ 16.492235 ]
 [  4.415183 ]
 [ 23.343866 ]
 [  8.412736 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 0. 1. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 1 1] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 9.853802680969238



buy possibilites: [-1] 
expected returns: [[-9.08609]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10.  9. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 0. 1. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 1 1] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0. 30.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 77.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 30.523334503173828






Player: 1 
cards in hand: [1. 0. 1. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 1. 3. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 1 1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10.  9. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29.  1.  0.  3.] 
adversary cards in discard: [29. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29] -> size -> 15 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 3. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 1 1] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10.  9. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29.  1.  0.  3.] 
adversary cards in discard: [29. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29] -> size -> 15 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 3. 3.] 
cards in discard: [15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  1  1 15] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10.  9. 10.  7. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 29.  1.  0.  3.] 
adversary cards in discard: [29. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29] -> size -> 15 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 3. 29.  1.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 7.4599476]
 [26.783186 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  1.  0.  3.] 
cards in discard: [29. 29.  3.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10.  9. 10.  7. 10. 10. 10. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [15.  1.  0.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  1  1 15] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -9.086090087890625



action possibilites: [-1.] 
expected returns: [[13.935875]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 3. 0.] 
cards in discard: [29. 29.  3.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10.  9. 10.  7. 10. 10. 10. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [15.  1.  0.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  1  1 15] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 26.438186645507812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 14.098413]
 [ 29.211304]
 [ 20.205297]
 [-12.760185]
 [-50.35531 ]
 [ 22.539774]
 [ 24.863487]
 [ 16.576078]
 [ 30.455418]
 [ 35.499554]
 [ 22.713268]
 [ 28.372604]
 [ 22.062132]
 [ 10.933336]
 [ 28.587357]
 [ 14.534031]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 3. 0.] 
cards in discard: [29. 29.  3.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10.  9. 10.  7. 10. 10. 10. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [15.  1.  0.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  1  1 15] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 13.935874938964844



buy possibilites: [-1] 
expected returns: [[8.37717]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 3. 0.] 
cards in discard: [29. 29.  3.  0.  0.  0.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10.  9. 10.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [15.  1.  0.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  1  1 15] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0. 30.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 77.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 35.49955368041992






Player: 1 
cards in hand: [8. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [15.  1.  0.  1.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  1  1 15] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10.  9. 10.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29] -> size -> 16 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [15.  1.  0.  1.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  1 15] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10.  9. 10.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29] -> size -> 16 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [15.  1.  0.  1.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  1 15] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10.  9. 10.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29] -> size -> 16 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [15.  1.  0.  1.  3.  3.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  1 15  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10.  8. 10.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29] -> size -> 16 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[18.105236]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10.  8. 10.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 1. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  1 15  8] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 8.377169609069824





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 16.003458]
 [ 31.72918 ]
 [ 22.665873]
 [-54.408165]
 [ 27.64142 ]
 [ 18.922688]
 [ 24.723576]
 [ 16.838188]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 27. 30. 29. 30.  8. 10. 10. 10.  8. 10.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 1. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  1 15  8] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 15.446004867553711



buy possibilites: [-1] 
expected returns: [[-2.2830043]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 29. 30.  8. 10. 10. 10.  8. 10.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 1. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  1 15  8] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 79 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 31.72918701171875






Player: 1 
cards in hand: [3. 1. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  1 15  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 29. 30.  8. 10. 10. 10.  8. 10.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [1. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1] -> size -> 17 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  1 15  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 26. 30. 29. 30.  8. 10. 10. 10.  8. 10.  6. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [1. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1] -> size -> 17 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 0. 0.] 
cards in discard: [29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  1 15  8 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 29. 30.  8. 10. 10. 10.  8. 10.  5. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [1. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1] -> size -> 17 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[23.125454]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [1. 0. 0. 3. 3. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 26. 30. 29. 30.  8. 10. 10. 10.  8. 10.  5. 10. 10. 10. 10.  9.] 
adversary cards in hand: [8. 8. 0. 3. 1.] 
adversary cards in discard: [29.  3.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  1 15  8 29] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -2.2830042839050293





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 22.3647  ]
 [ 37.124924]
 [ 28.678497]
 [-45.292652]
 [ 33.293644]
 [ 24.890713]
 [ 30.5397  ]
 [ 23.097237]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [1. 0. 0. 3. 3. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 26. 30. 29. 30.  8. 10. 10. 10.  8. 10.  5. 10. 10. 10. 10.  9.] 
adversary cards in hand: [8. 8. 0. 3. 1.] 
adversary cards in discard: [29.  3.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  1 15  8 29] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 22.401195526123047



buy possibilites: [-1] 
expected returns: [[13.011812]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [1. 0. 0. 3. 3. 0. 1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 29. 30.  8. 10. 10. 10.  8. 10.  5. 10. 10. 10. 10.  9.] 
adversary cards in hand: [8. 8. 0. 3. 1.] 
adversary cards in discard: [29.  3.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  1 15  8 29] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 79 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 37.124916076660156






Player: 1 
cards in hand: [8. 8. 0. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 3. 1.] 
cards in discard: [29.  3.  1.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  1 15  8 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 29. 30.  8. 10. 10. 10.  8. 10.  5. 10. 10. 10. 10.  9.] 
adversary cards in hand: [29. 29. 29.  1.  0.] 
adversary cards in discard: [1. 0. 0. 3. 3. 0. 1. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1] -> size -> 18 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0. 3. 1.] 
cards in discard: [29.  3.  1.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  1 15  8 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 25. 30. 29. 30.  8. 10. 10. 10.  8. 10.  5. 10. 10. 10. 10.  9.] 
adversary cards in hand: [29. 29. 29.  1.  0.] 
adversary cards in discard: [1. 0. 0. 3. 3. 0. 1. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1] -> size -> 18 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0. 3. 1.] 
cards in discard: [29.  3.  1.  3.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  1 15  8 29  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 25. 30. 28. 30.  8. 10. 10. 10.  8. 10.  5. 10. 10. 10. 10.  9.] 
adversary cards in hand: [29. 29. 29.  1.  0.] 
adversary cards in discard: [1. 0. 0. 3. 3. 0. 1. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1] -> size -> 18 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [29. 29. 29.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[-12.714329 ]
 [  7.2094574]
 [  7.2094574]
 [  7.2094574]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29.  1.  0.] 
cards in discard: [1. 0. 0. 3. 3. 0. 1. 0. 0. 3. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 28. 30.  8. 10. 10. 10.  8. 10.  5. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 1. 29. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  1 15  8 29  3] -> size -> 15 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 13.011812210083008



action possibilites: [-1. 29. 29. 29.] 
expected returns: [[38.64934 ]
 [57.711422]
 [57.711422]
 [57.711422]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  1.  0. 29.] 
cards in discard: [1. 0. 0. 3. 3. 0. 1. 0. 0. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 25. 30. 28. 30.  8. 10. 10. 10.  8. 10.  5. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 1. 29. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  1 15  8 29  3] -> size -> 15 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 3.6402413845062256



action possibilites: [-1. 29. 29.] 
expected returns: [[ 7.3222713]
 [28.150959 ]
 [28.150959 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1] -> size -> 18 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 25. 30. 28. 30.  8. 10. 10. 10.  8. 10.  5. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 1. 29. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  1 15  8 29  3] -> size -> 15 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 57.7114372253418



action possibilites: [-1. 29.] 
expected returns: [[ 2.0450432]
 [22.656197 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1] -> size -> 18 
action values: 1 
buys: 0 
player value: 3 
card supply: [30. 25. 30. 28. 30.  8. 10. 10. 10.  8. 10.  5. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 1. 29. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  1 15  8 29  3] -> size -> 15 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 28.15097999572754



action possibilites: [-1.] 
expected returns: [[21.317997]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1] -> size -> 18 
action values: 1 
buys: 0 
player value: 4 
card supply: [30. 25. 30. 28. 30.  8. 10. 10. 10.  8. 10.  5. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 1. 29. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  1 15  8 29  3] -> size -> 15 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 22.656208038330078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 20.891842]
 [ 36.47856 ]
 [-11.897203]
 [ 27.499977]
 [ -8.145594]
 [ 35.32615 ]
 [-46.86927 ]
 [ 29.985275]
 [ 32.31355 ]
 [ 23.481474]
 [ 37.7575  ]
 [ 42.65054 ]
 [ 30.181267]
 [ 35.699467]
 [ 29.535572]
 [ 17.62762 ]
 [ 35.93011 ]
 [ 22.028173]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1] -> size -> 18 
action values: 0 
buys: 1 
player value: 9 
card supply: [30. 25. 30. 28. 30.  8. 10. 10. 10.  8. 10.  5. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 1. 29. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  1 15  8 29  3] -> size -> 15 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 21.317996978759766



buy possibilites: [-1] 
expected returns: [[28.809795]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 5 
card supply: [30. 25. 30. 28. 30.  8. 10. 10. 10.  8. 10.  4. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 1. 29. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  1 15  8 29  3] -> size -> 15 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 80.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 107.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 42.65055465698242






Player: 1 
cards in hand: [ 1. 29. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 15.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  1 15  8 29  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 28. 30.  8. 10. 10. 10.  8. 10.  4. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 1.] 
adversary cards in discard: [29. 29. 29. 29. 29.  1.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29] -> size -> 19 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  1 15  8 29  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 25. 30. 28. 30.  8. 10. 10. 10.  8. 10.  4. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 1.] 
adversary cards in discard: [29. 29. 29. 29. 29.  1.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29] -> size -> 19 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  1 15  8 29  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 25. 30. 28. 30.  8. 10. 10. 10.  8. 10.  4. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 1.] 
adversary cards in discard: [29. 29. 29. 29. 29.  1.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29] -> size -> 19 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  0.  0.  8.] 
cards in discard: [14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  1 15  8 29  3 14] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 25. 30. 28. 30.  8. 10. 10. 10.  8. 10.  4.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 1.] 
adversary cards in discard: [29. 29. 29. 29. 29.  1.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29] -> size -> 19 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-1.1901174]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 1.] 
cards in discard: [29. 29. 29. 29. 29.  1.  0.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 28. 30.  8. 10. 10. 10.  8. 10.  4.  9. 10. 10. 10.  9.] 
adversary cards in hand: [1. 0. 0. 3. 3.] 
adversary cards in discard: [14. 29.  1. 15.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  1 15  8 29  3 14] -> size -> 16 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 28.809795379638672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ -1.1158233]
 [ 13.657768 ]
 [  5.18591  ]
 [-70.32437  ]
 [  7.625003 ]
 [  9.769207 ]
 [  1.4247472]
 [ 19.377304 ]
 [  7.799386 ]
 [  7.202879 ]
 [ 13.131489 ]
 [  0.2674725]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 1.] 
cards in discard: [29. 29. 29. 29. 29.  1.  0.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 25. 30. 28. 30.  8. 10. 10. 10.  8. 10.  4.  9. 10. 10. 10.  9.] 
adversary cards in hand: [1. 0. 0. 3. 3.] 
adversary cards in discard: [14. 29.  1. 15.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  1 15  8 29  3 14] -> size -> 16 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -3.7248849868774414



buy possibilites: [-1] 
expected returns: [[57.59274]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 1.] 
cards in discard: [29. 29. 29. 29. 29.  1.  0.  0.  0.  3. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 28. 30.  8. 10. 10. 10.  8. 10.  3.  9. 10. 10. 10.  9.] 
adversary cards in hand: [1. 0. 0. 3. 3.] 
adversary cards in discard: [14. 29.  1. 15.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  1 15  8 29  3 14] -> size -> 16 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 19.3773193359375






Player: 1 
cards in hand: [1. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 3. 3.] 
cards in discard: [14. 29.  1. 15.  0.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  1 15  8 29  3 14] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 28. 30.  8. 10. 10. 10.  8. 10.  3.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 1. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29] -> size -> 20 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 3. 3.] 
cards in discard: [14. 29.  1. 15.  0.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  1 15  8 29  3 14] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 25. 30. 28. 30.  8. 10. 10. 10.  8. 10.  3.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 1. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29] -> size -> 20 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 3. 3.] 
cards in discard: [14. 29.  1. 15.  0.  0.  8. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  1 15  8 29  3 14 14] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 28. 30.  8. 10. 10. 10.  8. 10.  3.  8. 10. 10. 10.  9.] 
adversary cards in hand: [3. 1. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29] -> size -> 20 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [3. 1. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[35.17812]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 28. 30.  8. 10. 10. 10.  8. 10.  3.  8. 10. 10. 10.  9.] 
adversary cards in hand: [15.  3.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  1 15  8 29  3 14 14] -> size -> 17 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 57.59273910522461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 35.744793]
 [ 51.16946 ]
 [ 42.611763]
 [-33.45353 ]
 [ 45.013638]
 [ 47.463303]
 [ 38.367367]
 [ 57.20879 ]
 [ 45.29817 ]
 [ 44.64253 ]
 [ 50.86341 ]
 [ 37.01945 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 25. 30. 28. 30.  8. 10. 10. 10.  8. 10.  3.  8. 10. 10. 10.  9.] 
adversary cards in hand: [15.  3.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  1 15  8 29  3 14 14] -> size -> 17 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 33.36667251586914



buy possibilites: [-1] 
expected returns: [[-1.75873]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 0. 0.] 
cards in discard: [29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 28. 30.  8. 10. 10. 10.  8. 10.  2.  8. 10. 10. 10.  9.] 
adversary cards in hand: [15.  3.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  8  1  1 15  8 29  3 14 14] -> size -> 17 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 57.20880126953125






Player: 1 
cards in hand: [15.  3.  8.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  8.  3.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  8  1  1 15  8 29  3 14 14] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 28. 30.  8. 10. 10. 10.  8. 10.  2.  8. 10. 10. 10.  9.] 
adversary cards in hand: [29. 29.  0.  0.  1.] 
adversary cards in discard: [29.  3.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29] -> size -> 21 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3  8  1  1 15  8 29  3 14 14] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 25. 30. 28. 30.  8. 10. 10. 10.  8. 10.  2.  8. 10. 10. 10.  9.] 
adversary cards in hand: [29. 29.  0.  0.  1.] 
adversary cards in discard: [29.  3.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29] -> size -> 21 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3  8  1  1 15  8 29  3 14 14] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 25. 30. 28. 30.  8. 10. 10. 10.  8. 10.  2.  8. 10. 10. 10.  9.] 
adversary cards in hand: [29. 29.  0.  0.  1.] 
adversary cards in discard: [29.  3.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29] -> size -> 21 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3.] 
cards in discard: [11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3  8  1  1 15  8 29  3 14 14 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 28. 30.  8. 10. 10.  9.  8. 10.  2.  8. 10. 10. 10.  9.] 
adversary cards in hand: [29. 29.  0.  0.  1.] 
adversary cards in discard: [29.  3.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29] -> size -> 21 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [29. 29.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[-5.2426577]
 [14.905714 ]
 [14.905714 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0.  0.  1.] 
cards in discard: [29.  3.  1.  3.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 28. 30.  8. 10. 10.  9.  8. 10.  2.  8. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 1. 0. 8.] 
adversary cards in discard: [11. 15.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  1  1 15  8 29  3 14 14 11] -> size -> 17 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -1.7587300539016724



action possibilites: [-1. 29.] 
expected returns: [[ 5.916565]
 [25.69189 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  1.  0.] 
cards in discard: [29.  3.  1.  3.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 25. 30. 28. 30.  8. 10. 10.  9.  8. 10.  2.  8. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 1. 0. 8.] 
adversary cards in discard: [11. 15.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  1  1 15  8 29  3 14 14 11] -> size -> 17 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 13.578689575195312



action possibilites: [-1.] 
expected returns: [[33.746235]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 3.] 
cards in discard: [29.  3.  1.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 25. 30. 28. 30.  8. 10. 10.  9.  8. 10.  2.  8. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 1. 0. 8.] 
adversary cards in discard: [11. 15.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  1  1 15  8 29  3 14 14 11] -> size -> 17 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 25.691898345947266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 34.716106]
 [ 49.57954 ]
 [  5.202132]
 [ 40.942226]
 [  9.042494]
 [-33.701355]
 [ 43.17446 ]
 [ 45.402153]
 [ 36.79239 ]
 [ 50.770668]
 [ 55.61414 ]
 [ 43.33972 ]
 [ 48.772556]
 [ 42.715168]
 [ 32.001907]
 [ 48.977676]
 [ 35.45369 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 3.] 
cards in discard: [29.  3.  1.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29] -> size -> 21 
action values: 0 
buys: 1 
player value: 7 
card supply: [30. 25. 30. 28. 30.  8. 10. 10.  9.  8. 10.  2.  8. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 1. 0. 8.] 
adversary cards in discard: [11. 15.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  1  1 15  8 29  3 14 14 11] -> size -> 17 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 33.74623489379883



buy possibilites: [-1] 
expected returns: [[53.284634]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 3.] 
cards in discard: [29.  3.  1.  3.  0.  0. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 25. 30. 28. 30.  8. 10. 10.  9.  8. 10.  1.  8. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 1. 0. 8.] 
adversary cards in discard: [11. 15.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  1  1 15  8 29  3 14 14 11] -> size -> 17 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 40.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 67.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 55.6141471862793






Player: 1 
cards in hand: [0. 0. 1. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 8.] 
cards in discard: [11. 15.  3.  8.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8  1  1 15  8 29  3 14 14 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 28. 30.  8. 10. 10.  9.  8. 10.  1.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29.  1. 29. 29.] 
adversary cards in discard: [29.  3.  1.  3.  0.  0. 29. 29. 29.  0.  0.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29] -> size -> 22 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 8.] 
cards in discard: [11. 15.  3.  8.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8  1  1 15  8 29  3 14 14 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 25. 30. 28. 30.  8. 10. 10.  9.  8. 10.  1.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29.  1. 29. 29.] 
adversary cards in discard: [29.  3.  1.  3.  0.  0. 29. 29. 29.  0.  0.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29] -> size -> 22 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 8.] 
cards in discard: [11. 15.  3.  8.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8  1  1 15  8 29  3 14 14 11  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 25. 30. 27. 30.  8. 10. 10.  9.  8. 10.  1.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29.  1. 29. 29.] 
adversary cards in discard: [29.  3.  1.  3.  0.  0. 29. 29. 29.  0.  0.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29] -> size -> 22 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  1. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[51.102757]
 [67.6253  ]
 [67.6253  ]
 [67.6253  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  1. 29. 29.] 
cards in discard: [29.  3.  1.  3.  0.  0. 29. 29. 29.  0.  0.  1.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 27. 30.  8. 10. 10.  9.  8. 10.  1.  8. 10. 10. 10.  9.] 
adversary cards in hand: [29.  3. 14. 14.  1.] 
adversary cards in discard: [11. 15.  3.  8.  3.  3.  0.  0.  1.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  1  1 15  8 29  3 14 14 11  3] -> size -> 18 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 53.28463363647461



action possibilites: [-1. 29. 29. 29.] 
expected returns: [[34.529545]
 [52.40082 ]
 [52.40082 ]
 [52.40082 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 29. 29. 29.] 
cards in discard: [29.  3.  1.  3.  0.  0. 29. 29. 29.  0.  0.  1.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 25. 30. 27. 30.  8. 10. 10.  9.  8. 10.  1.  8. 10. 10. 10.  9.] 
adversary cards in hand: [29.  3. 14. 14.  1.] 
adversary cards in discard: [11. 15.  3.  8.  3.  3.  0.  0.  1.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  1  1 15  8 29  3 14 14 11  3] -> size -> 18 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 67.10416412353516



action possibilites: [-1. 29. 29.] 
expected returns: [[54.159374]
 [71.97686 ]
 [71.97686 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 29. 29.  3.] 
cards in discard: [29.  3.  1.  3.  0.  0. 29. 29. 29.  0.  0.  1.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 25. 30. 27. 30.  8. 10. 10.  9.  8. 10.  1.  8. 10. 10. 10.  9.] 
adversary cards in hand: [29.  3. 14. 14.  1.] 
adversary cards in discard: [11. 15.  3.  8.  3.  3.  0.  0.  1.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  1  1 15  8 29  3 14 14 11  3] -> size -> 18 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 52.40084457397461



action possibilites: [-1. 29.] 
expected returns: [[26.608618]
 [43.60248 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 29.  3.  0.] 
cards in discard: [29.  3.  1.  3.  0.  0. 29. 29. 29.  0.  0.  1.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 3 
card supply: [30. 25. 30. 27. 30.  8. 10. 10.  9.  8. 10.  1.  8. 10. 10. 10.  9.] 
adversary cards in hand: [29.  3. 14. 14.  1.] 
adversary cards in discard: [11. 15.  3.  8.  3.  3.  0.  0.  1.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  1  1 15  8 29  3 14 14 11  3] -> size -> 18 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 71.97687530517578



action possibilites: [-1.] 
expected returns: [[23.215466]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 4 
card supply: [30. 25. 30. 27. 30.  8. 10. 10.  9.  8. 10.  1.  8. 10. 10. 10.  9.] 
adversary cards in hand: [29.  3. 14. 14.  1.] 
adversary cards in discard: [11. 15.  3.  8.  3.  3.  0.  0.  1.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  1  1 15  8 29  3 14 14 11  3] -> size -> 18 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 43.602516174316406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 24.897045]
 [ 39.972828]
 [-12.981488]
 [ 31.602894]
 [-10.588535]
 [ 38.452255]
 [-54.055183]
 [ 34.170837]
 [ 35.82283 ]
 [ 26.349895]
 [ 40.86529 ]
 [ 45.916035]
 [ 34.393196]
 [ 39.333138]
 [ 33.797993]
 [ 20.760332]
 [ 39.204353]
 [ 26.877642]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 9 
card supply: [30. 25. 30. 27. 30.  8. 10. 10.  9.  8. 10.  1.  8. 10. 10. 10.  9.] 
adversary cards in hand: [29.  3. 14. 14.  1.] 
adversary cards in discard: [11. 15.  3.  8.  3.  3.  0.  0.  1.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  1  1 15  8 29  3 14 14 11  3] -> size -> 18 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 23.215465545654297



buy possibilites: [-1] 
expected returns: [[20.620743]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0. 0.] 
cards in discard: [29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 5 
card supply: [30. 25. 30. 27. 30.  8. 10. 10.  9.  8. 10.  0.  8. 10. 10. 10.  9.] 
adversary cards in hand: [29.  3. 14. 14.  1.] 
adversary cards in discard: [11. 15.  3.  8.  3.  3.  0.  0.  1.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  1  1 15  8 29  3 14 14 11  3] -> size -> 18 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.  80.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: 77.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 45.916038513183594






Player: 1 
cards in hand: [29.  3. 14. 14.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 14. 14.  1.] 
cards in discard: [11. 15.  3.  8.  3.  3.  0.  0.  1.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8  1  1 15  8 29  3 14 14 11  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 27. 30.  8. 10. 10.  9.  8. 10.  0.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  3.  0.  0. 29.] 
adversary cards in discard: [29. 29. 29. 29. 29.  0.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29] -> size -> 23 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3. 14. 14.  1.] 
cards in discard: [11. 15.  3.  8.  3.  3.  0.  0.  1.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8  1  1 15  8 29  3 14 14 11  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 25. 30. 27. 30.  8. 10. 10.  9.  8. 10.  0.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  3.  0.  0. 29.] 
adversary cards in discard: [29. 29. 29. 29. 29.  0.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29] -> size -> 23 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3. 14. 14.  1.] 
cards in discard: [11. 15.  3.  8.  3.  3.  0.  0.  1.  0.  8.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8  1  1 15  8 29  3 14 14 11  3  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 27. 30.  8. 10. 10.  9.  7. 10.  0.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  3.  0.  0. 29.] 
adversary cards in discard: [29. 29. 29. 29. 29.  0.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29] -> size -> 23 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[49.869118]
 [69.96877 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  0. 29.] 
cards in discard: [29. 29. 29. 29. 29.  0.  1.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 25. 30. 27. 30.  8. 10. 10.  9.  7. 10.  0.  8. 10. 10. 10.  9.] 
adversary cards in hand: [1. 3. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  1  1 15  8 29  3 14 14 11  3  8] -> size -> 19 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 20.620742797851562



action possibilites: [-1.] 
expected returns: [[81.38853]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [29. 29. 29. 29. 29.  0.  1.  3.  0.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 25. 30. 27. 30.  8. 10. 10.  9.  7. 10.  0.  8. 10. 10. 10.  9.] 
adversary cards in hand: [1. 3. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  1  1 15  8 29  3 14 14 11  3  8] -> size -> 19 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 61.73244857788086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[80.77853 ]
 [95.900406]
 [87.44171 ]
 [11.495347]
 [92.27777 ]
 [83.639305]
 [89.51618 ]
 [82.05311 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [29. 29. 29. 29. 29.  0.  1.  3.  0.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 25. 30. 27. 30.  8. 10. 10.  9.  7. 10.  0.  8. 10. 10. 10.  9.] 
adversary cards in hand: [1. 3. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  1  1 15  8 29  3 14 14 11  3  8] -> size -> 19 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 81.3885269165039



buy possibilites: [-1] 
expected returns: [[91.341835]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [29. 29. 29. 29. 29.  0.  1.  3.  0.  0.  1.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 24. 30. 27. 30.  8. 10. 10.  9.  7. 10.  0.  8. 10. 10. 10.  9.] 
adversary cards in hand: [1. 3. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  1  1 15  8 29  3 14 14 11  3  8] -> size -> 19 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 95.9004135131836






Player: 1 
cards in hand: [1. 3. 1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 1. 3. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8  1  1 15  8 29  3 14 14 11  3  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 24. 30. 27. 30.  8. 10. 10.  9.  7. 10.  0.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 1.  3.  0. 29. 29.] 
adversary cards in discard: [29. 29. 29. 29. 29.  0.  1.  3.  0.  0.  1.  1. 29.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1] -> size -> 24 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1. 3. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8  1  1 15  8 29  3 14 14 11  3  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 24. 30. 27. 30.  8. 10. 10.  9.  7. 10.  0.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 1.  3.  0. 29. 29.] 
adversary cards in discard: [29. 29. 29. 29. 29.  0.  1.  3.  0.  0.  1.  1. 29.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1] -> size -> 24 
adversary victory points: 4
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 1.  3.  0. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[32.570866]
 [51.021706]
 [51.021706]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0. 29. 29.] 
cards in discard: [29. 29. 29. 29. 29.  0.  1.  3.  0.  0.  1.  1. 29.  3.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 24. 30. 27. 30.  8. 10. 10.  9.  7. 10.  0.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 15.  8.  3. 14.] 
adversary cards in discard: [1. 3. 1. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  1  1 15  8 29  3 14 14 11  3  8] -> size -> 19 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 91.34183502197266



action possibilites: [-1. 29. 29.] 
expected returns: [[59.61078]
 [78.38848]
 [78.38848]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29. 29.] 
cards in discard: [29. 29. 29. 29. 29.  0.  1.  3.  0.  0.  1.  1. 29.  3.  3.  0.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 24. 30. 27. 30.  8. 10. 10.  9.  7. 10.  0.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 15.  8.  3. 14.] 
adversary cards in discard: [1. 3. 1. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  1  1 15  8 29  3 14 14 11  3  8] -> size -> 19 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 45.49913024902344



action possibilites: [-1.] 
expected returns: [[35.82246]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [29. 29. 29. 29. 29.  0.  1.  3.  0.  0.  1.  1. 29.  3.  3.  0.  0.  1.
 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 24. 30. 27. 30.  8. 10. 10.  9.  7. 10.  0.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 15.  8.  3. 14.] 
adversary cards in discard: [1. 3. 1. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  1  1 15  8 29  3 14 14 11  3  8] -> size -> 19 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 72.76847076416016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[ 33.23228 ]
 [ 47.667957]
 [ 39.774258]
 [-32.804874]
 [ 42.231102]
 [ 44.098072]
 [ 35.175034]
 [ 42.36161 ]
 [ 41.835773]
 [ 47.135925]
 [ 35.722   ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [29. 29. 29. 29. 29.  0.  1.  3.  0.  0.  1.  1. 29.  3.  3.  0.  0.  1.
 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 24. 30. 27. 30.  8. 10. 10.  9.  7. 10.  0.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 15.  8.  3. 14.] 
adversary cards in discard: [1. 3. 1. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  1  1 15  8 29  3 14 14 11  3  8] -> size -> 19 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 35.82246017456055



buy possibilites: [-1] 
expected returns: [[22.394363]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [29. 29. 29. 29. 29.  0.  1.  3.  0.  0.  1.  1. 29.  3.  3.  0.  0.  1.
 29.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 23. 30. 27. 30.  8. 10. 10.  9.  7. 10.  0.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 15.  8.  3. 14.] 
adversary cards in discard: [1. 3. 1. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  1  1 15  8 29  3 14 14 11  3  8] -> size -> 19 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5.    0.    0.  -30.    0.    0.   40.    0.    0.    0.    0.    0.
   0.    0.   13.5   0. ] 
sum of rewards: 18.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 47.6679573059082






Player: 1 
cards in hand: [ 3. 15.  8.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  8.  3. 14.] 
cards in discard: [1. 3. 1. 3. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8  1  1 15  8 29  3 14 14 11  3  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 23. 30. 27. 30.  8. 10. 10.  9.  7. 10.  0.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1] -> size -> 25 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  8.  3.] 
cards in discard: [1. 3. 1. 3. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  8  1  1 15  8 29  3 14 14 11  3  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 23. 30. 27. 30.  8. 10. 10.  9.  7. 10.  0.  8. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0.] 
adversary cards in discard: [ 0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1] -> size -> 25 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  8.  3.] 
cards in discard: [1. 3. 1. 3. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  8  1  1 15  8 29  3 14 14 11  3  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 23. 30. 27. 30.  8. 10. 10.  9.  7. 10.  0.  8. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0.] 
adversary cards in discard: [ 0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1] -> size -> 25 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  8.  3.] 
cards in discard: [1. 3. 1. 3. 0. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  8  1  1 15  8 29  3 14 14 11  3  8  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 23. 30. 27. 30.  8. 10. 10.  9.  7. 10.  0.  8. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0.] 
adversary cards in discard: [ 0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1] -> size -> 25 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[3.8316195]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [ 0. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 23. 30. 27. 30.  8. 10. 10.  9.  7. 10.  0.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 11.  8.  0.  0.] 
adversary cards in discard: [ 1.  3.  1.  3.  0.  0. 14.  3. 15.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  1  1 15  8 29  3 14 14 11  3  8  0] -> size -> 20 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0 593   0] 
sum of rewards: 558 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 53.01144790649414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[  2.2757099]
 [  8.643227 ]
 [-61.032436 ]
 [  4.390867 ]
 [  3.5431283]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 0. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 23. 30. 27. 30.  8. 10. 10.  9.  7. 10.  0.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 11.  8.  0.  0.] 
adversary cards in discard: [ 1.  3.  1.  3.  0.  0. 14.  3. 15.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  1  1 15  8 29  3 14 14 11  3  8  0] -> size -> 20 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 2.2095491886138916



buy possibilites: [-1] 
expected returns: [[10.995249]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 0. 29.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 23. 30. 26. 30.  8. 10. 10.  9.  7. 10.  0.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 11.  8.  0.  0.] 
adversary cards in discard: [ 1.  3.  1.  3.  0.  0. 14.  3. 15.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8  1  1 15  8 29  3 14 14 11  3  8  0] -> size -> 20 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 16  0] 
sum of rewards: 11 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 8.64322280883789






Player: 1 
cards in hand: [ 3. 11.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  8.  0.  0.] 
cards in discard: [ 1.  3.  1.  3.  0.  0. 14.  3. 15.  8.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8  1  1 15  8 29  3 14 14 11  3  8  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 23. 30. 26. 30.  8. 10. 10.  9.  7. 10.  0.  8. 10. 10. 10.  9.] 
adversary cards in hand: [29.  0. 29.  3.  1.] 
adversary cards in discard: [ 0. 29.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3] -> size -> 26 
adversary victory points: 5
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [ 1.  3.  1.  3.  0.  0. 14.  3. 15.  8.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  8  1  1 15  8 29  3 14 14  3  8  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 23. 30. 26. 30.  8. 10. 10.  9.  7. 10.  0.  8. 10. 10. 10.  9.] 
adversary cards in hand: [29.  0. 29.  3.  1.] 
adversary cards in discard: [ 0. 29.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3] -> size -> 26 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 1.  3.  1.  3.  0.  0. 14.  3. 15.  8.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  8  1  1 15  8 29  3 14 14  3  8  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 23. 30. 26. 30.  8. 10. 10.  9.  7. 10.  0.  8. 10. 10. 10.  9.] 
adversary cards in hand: [29.  0. 29.  3.  1.] 
adversary cards in discard: [ 0. 29.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3] -> size -> 26 
adversary victory points: 5
player victory points: 5 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [29.  0. 29.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[-11.753276]
 [  7.550145]
 [  7.550145]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29.  3.  1.] 
cards in discard: [ 0. 29.  3.  0.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 23. 30. 26. 30.  8. 10. 10.  9.  7. 10.  0.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  8. 14. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  8  1  1 15  8 29  3 14 14  3  8  0] -> size -> 18 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 10.995248794555664



action possibilites: [-1. 29.] 
expected returns: [[18.821026]
 [38.547733]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1. 29.] 
cards in discard: [ 0. 29.  3.  0.  3.  0. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 23. 30. 26. 30.  8. 10. 10.  9.  7. 10.  0.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  8. 14. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  8  1  1 15  8 29  3 14 14  3  8  0] -> size -> 18 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -1.3159925937652588



action possibilites: [-1. 29.] 
expected returns: [[ 5.758397]
 [23.5495  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.] 
cards in discard: [ 0. 29.  3.  0.  3.  0. 29.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 23. 30. 26. 30.  8. 10. 10.  9.  7. 10.  0.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  8. 14. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  8  1  1 15  8 29  3 14 14  3  8  0] -> size -> 18 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 32.606754302978516



action possibilites: [-1.] 
expected returns: [[73.81054]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [ 0. 29.  3.  0.  3.  0. 29.  1.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 3 
card supply: [29. 23. 30. 26. 30.  8. 10. 10.  9.  7. 10.  0.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  8. 14. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  8  1  1 15  8 29  3 14 14  3  8  0] -> size -> 18 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 18.19434928894043





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[ 62.568424]
 [ 80.17209 ]
 [ 70.52576 ]
 [-29.062347]
 [ 75.21617 ]
 [ 75.448044]
 [ 64.965706]
 [ 74.73649 ]
 [ 74.52104 ]
 [ 78.38991 ]
 [ 73.09252 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 0. 29.  3.  0.  3.  0. 29.  1.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 23. 30. 26. 30.  8. 10. 10.  9.  7. 10.  0.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  8. 14. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  8  1  1 15  8 29  3 14 14  3  8  0] -> size -> 18 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 73.81053924560547



buy possibilites: [-1] 
expected returns: [[52.547283]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 0. 29.  3.  0.  3.  0. 29.  1.  1.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 22. 30. 26. 30.  8. 10. 10.  9.  7. 10.  0.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  8. 14. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  8  1  1 15  8 29  3 14 14  3  8  0] -> size -> 18 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  60.   0.   0.   0.   0.   0.   0.   0.
 13.5  0. ] 
sum of rewards: 68.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 80.17204284667969






Player: 1 
cards in hand: [ 3.  0.  8. 14. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8. 14. 29.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  8  1  1 15  8 29  3 14 14  3  8  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 22. 30. 26. 30.  8. 10. 10.  9.  7. 10.  0.  8. 10. 10. 10.  9.] 
adversary cards in hand: [29. 29.  1.  0.  1.] 
adversary cards in discard: [ 0. 29.  3.  0.  3.  0. 29.  1.  1.  1. 29. 29. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1] -> size -> 27 
adversary victory points: 5
player victory points: 5 


action possibilites: [-1.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 14.  0.] 
cards in discard: [3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  3  8  1  1 15  8 29  3 14 14  3  8  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 22. 30. 26. 30.  8. 10. 10.  9.  7. 10.  0.  8. 10. 10. 10.  9.] 
adversary cards in hand: [29. 29.  1.  0.  1.] 
adversary cards in discard: [ 0. 29.  3.  0.  3.  0. 29.  1.  1.  1. 29. 29. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1] -> size -> 27 
adversary victory points: 5
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0.] 
cards in discard: [3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  0  3  3  3  8  1  1 15  8 29  3 14 14  3  8  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 22. 30. 26. 30.  8. 10. 10.  9.  7. 10.  0.  8. 10. 10. 10.  9.] 
adversary cards in hand: [29.  0.  1.] 
adversary cards in discard: [ 0. 29.  3.  0.  3.  0. 29.  1.  1.  1. 29. 29. 29.  0.  3. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1] -> size -> 27 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  0  3  3  3  8  1  1 15  8 29  3 14 14  3  8  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 22. 30. 26. 30.  8. 10. 10.  9.  7. 10.  0.  8. 10. 10. 10.  9.] 
adversary cards in hand: [29.  0.  1.] 
adversary cards in discard: [ 0. 29.  3.  0.  3.  0. 29.  1.  1.  1. 29. 29. 29.  0.  3. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1] -> size -> 27 
adversary victory points: 5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [ 3. 16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  0  3  3  3  8  1  1 15  8 29  3 14 14  3  8  0 16] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 22. 30. 26. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  9.] 
adversary cards in hand: [29.  0.  1.] 
adversary cards in discard: [ 0. 29.  3.  0.  3.  0. 29.  1.  1.  1. 29. 29. 29.  0.  3. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1] -> size -> 27 
adversary victory points: 5
player victory points: 5 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [29.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 4.045906]
 [22.739033]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  1.] 
cards in discard: [ 0. 29.  3.  0.  3.  0. 29.  1.  1.  1. 29. 29. 29.  0.  3. 29.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 22. 30. 26. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  1.  1. 14.  8.] 
adversary cards in discard: [ 3. 16. 29. 14.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  8  1  1 15  8 29  3 14 14  3  8  0 16] -> size -> 19 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 620   0] 
sum of rewards: 615 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -19.98094367980957



action possibilites: [-1.] 
expected returns: [[5.640044]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [ 0. 29.  3.  0.  3.  0. 29.  1.  1.  1. 29. 29. 29.  0.  3. 29.  1.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 22. 30. 26. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  1.  1. 14.  8.] 
adversary cards in discard: [ 3. 16. 29. 14.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  8  1  1 15  8 29  3 14 14  3  8  0 16] -> size -> 19 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 17.13641929626465





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[  3.1845562]
 [ 10.027641 ]
 [-59.62506  ]
 [  6.145525 ]
 [  4.6746454]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 0. 29.  3.  0.  3.  0. 29.  1.  1.  1. 29. 29. 29.  0.  3. 29.  1.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 22. 30. 26. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  1.  1. 14.  8.] 
adversary cards in discard: [ 3. 16. 29. 14.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  8  1  1 15  8 29  3 14 14  3  8  0 16] -> size -> 19 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 5.640044212341309



buy possibilites: [-1] 
expected returns: [[-19.203825]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 0. 29.  3.  0.  3.  0. 29.  1.  1.  1. 29. 29. 29.  0.  3. 29.  1.  1.
  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 22. 30. 25. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  1.  1. 14.  8.] 
adversary cards in discard: [ 3. 16. 29. 14.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  8  1  1 15  8 29  3 14 14  3  8  0 16] -> size -> 19 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 61 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 10.027647018432617






Player: 1 
cards in hand: [ 3.  1.  1. 14.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  1. 14.  8.] 
cards in discard: [ 3. 16. 29. 14.  0.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  8  1  1 15  8 29  3 14 14  3  8  0 16] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 22. 30. 25. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 1.  3. 29.  0. 29.] 
adversary cards in discard: [ 0. 29.  3.  0.  3.  0. 29.  1.  1.  1. 29. 29. 29.  0.  3. 29.  1.  1.
  3. 29.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3] -> size -> 28 
adversary victory points: 6
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 1. 8.] 
cards in discard: [ 3. 16. 29. 14.  0.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  3  8  1  1 15  8 29  3 14 14  3  8  0 16] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 22. 30. 25. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 1.  3. 29.] 
adversary cards in discard: [ 0. 29.  3.  0.  3.  0. 29.  1.  1.  1. 29. 29. 29.  0.  3. 29.  1.  1.
  3. 29.  0.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3] -> size -> 28 
adversary victory points: 6
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 1. 8.] 
cards in discard: [ 3. 16. 29. 14.  0.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  3  8  1  1 15  8 29  3 14 14  3  8  0 16] -> size -> 19 
action values: 0 
buys: 1 
player value: 6 
card supply: [29. 22. 30. 25. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 1.  3. 29.] 
adversary cards in discard: [ 0. 29.  3.  0.  3.  0. 29.  1.  1.  1. 29. 29. 29.  0.  3. 29.  1.  1.
  3. 29.  0.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3] -> size -> 28 
adversary victory points: 6
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 1. 8.] 
cards in discard: [ 3. 16. 29. 14.  0.  8.  0. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  3  8  1  1 15  8 29  3 14 14  3  8  0 16 15] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 22. 30. 25. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 1.  3. 29.] 
adversary cards in discard: [ 0. 29.  3.  0.  3.  0. 29.  1.  1.  1. 29. 29. 29.  0.  3. 29.  1.  1.
  3. 29.  0.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3] -> size -> 28 
adversary victory points: 6
player victory points: 5 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 1.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-23.685476]
 [ -5.700893]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 29.] 
cards in discard: [ 0. 29.  3.  0.  3.  0. 29.  1.  1.  1. 29. 29. 29.  0.  3. 29.  1.  1.
  3. 29.  0.  3. 29.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 22. 30. 25. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [3. 3. 3. 0. 8.] 
adversary cards in discard: [ 3. 16. 29. 14.  0.  8.  0. 15. 14.  3.  1.  1.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  8  1  1 15  8 29  3 14 14  3  8  0 16 15] -> size -> 20 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[ -5   0   0  30   0   0   0   0   0   0   0   0   0   0 628   0] 
sum of rewards: 653 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 19.629467010498047



action possibilites: [-1.] 
expected returns: [[-21.10116]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [ 0. 29.  3.  0.  3.  0. 29.  1.  1.  1. 29. 29. 29.  0.  3. 29.  1.  1.
  3. 29.  0.  3. 29.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 22. 30. 25. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [3. 3. 3. 0. 8.] 
adversary cards in discard: [ 3. 16. 29. 14.  0.  8.  0. 15. 14.  3.  1.  1.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  8  1  1 15  8 29  3 14 14  3  8  0 16 15] -> size -> 20 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -11.085034370422363





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-22.521305]
 [-16.56049 ]
 [-75.46309 ]
 [-20.877169]
 [-21.072382]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 0. 29.  3.  0.  3.  0. 29.  1.  1.  1. 29. 29. 29.  0.  3. 29.  1.  1.
  3. 29.  0.  3. 29.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 22. 30. 25. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [3. 3. 3. 0. 8.] 
adversary cards in discard: [ 3. 16. 29. 14.  0.  8.  0. 15. 14.  3.  1.  1.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  8  1  1 15  8 29  3 14 14  3  8  0 16 15] -> size -> 20 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -21.101160049438477



buy possibilites: [-1] 
expected returns: [[-23.433159]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 0. 29.  3.  0.  3.  0. 29.  1.  1.  1. 29. 29. 29.  0.  3. 29.  1.  1.
  3. 29.  0.  3. 29.  0.  1.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 22. 30. 24. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [3. 3. 3. 0. 8.] 
adversary cards in discard: [ 3. 16. 29. 14.  0.  8.  0. 15. 14.  3.  1.  1.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  8  1  1 15  8 29  3 14 14  3  8  0 16 15] -> size -> 20 
adversary victory points: 5
player victory points: 7 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 91 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -16.56049346923828






Player: 1 
cards in hand: [3. 3. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0. 8.] 
cards in discard: [ 3. 16. 29. 14.  0.  8.  0. 15. 14.  3.  1.  1.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  8  1  1 15  8 29  3 14 14  3  8  0 16 15] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 22. 30. 24. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [29.  1. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3] -> size -> 29 
adversary victory points: 7
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 3. 16. 29. 14.  0.  8.  0. 15. 14.  3.  1.  1.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  8  1  1 15  8 29  3 14 14  3  8  0 16 15] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 22. 30. 24. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [29.  1. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3] -> size -> 29 
adversary victory points: 7
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3. 16. 29. 14.  0.  8.  0. 15. 14.  3.  1.  1.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  8  1  1 15  8 29  3 14 14  3  8  0 16 15] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 22. 30. 24. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [29.  1. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3] -> size -> 29 
adversary victory points: 7
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3. 16. 29. 14.  0.  8.  0. 15. 14.  3.  1.  1.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  8  1  1 15  8 29  3 14 14  3  8  0 16 15  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 22. 30. 24. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [29.  1. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3] -> size -> 29 
adversary victory points: 7
player victory points: 2 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [29.  1. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[-13.688843]
 [  3.203338]
 [  3.203338]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 22. 30. 24. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [14.  3.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  1  1 15  8 29  3 14 14  3  8  0 16 15  0] -> size -> 17 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: -23.43315887451172



action possibilites: [-1. 29.] 
expected returns: [[ 4.3700867]
 [21.98789  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  1.] 
cards in discard: [1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 22. 30. 24. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [14.  3.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  1  1 15  8 29  3 14 14  3  8  0 16 15  0] -> size -> 17 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -4.121933937072754



action possibilites: [-1.] 
expected returns: [[18.920748]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [1. 1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 22. 30. 24. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [14.  3.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  1  1 15  8 29  3 14 14  3  8  0 16 15  0] -> size -> 17 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 16.57360076904297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[ 19.406525]
 [ 33.686825]
 [ 25.435844]
 [-48.533527]
 [ 27.679207]
 [ 29.677067]
 [ 21.319405]
 [ 27.796896]
 [ 27.227547]
 [ 33.04148 ]
 [ 20.607782]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [1. 1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 22. 30. 24. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [14.  3.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  1  1 15  8 29  3 14 14  3  8  0 16 15  0] -> size -> 17 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 18.920747756958008



buy possibilites: [-1] 
expected returns: [[24.693493]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [1. 1. 1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 21. 30. 24. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [14.  3.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  8  1  1 15  8 29  3 14 14  3  8  0 16 15  0] -> size -> 17 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5.    0.    0.  150.    0.    0.   40.    0.    0.    0.    0.    0.
   0.    0.   13.5   0. ] 
sum of rewards: 198.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 33.68682098388672






Player: 1 
cards in hand: [14.  3.  0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0.  0. 15.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  1  1 15  8 29  3 14 14  3  8  0 16 15  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 21. 30. 24. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  1. 29. 29.  3.] 
adversary cards in discard: [ 1.  1.  1. 29. 29.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1] -> size -> 30 
adversary victory points: 7
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  8  1  1 15  8 29  3 14 14  3  8  0 16 15  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 21. 30. 24. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  1. 29. 29.  3.] 
adversary cards in discard: [ 1.  1.  1. 29. 29.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1] -> size -> 30 
adversary victory points: 7
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  8  1  1 15  8 29  3 14 14  3  8  0 16 15  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 21. 30. 24. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  1. 29. 29.  3.] 
adversary cards in discard: [ 1.  1.  1. 29. 29.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1] -> size -> 30 
adversary victory points: 7
player victory points: 2 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 3.  1. 29. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[51.577045]
 [71.2838  ]
 [71.2838  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 29. 29.  3.] 
cards in discard: [ 1.  1.  1. 29. 29.  3.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 21. 30. 24. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 8. 29.  0.  3.  1.] 
adversary cards in discard: [15. 14.  3.  0.] 
adversary owned cards: [ 0  8  1  1 15  8 29  3 14 14  3  8  0 16 15  0] -> size -> 16 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 24.693492889404297



action possibilites: [-1. 29.] 
expected returns: [[32.70481 ]
 [53.072666]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  3.  3.] 
cards in discard: [ 1.  1.  1. 29. 29.  3.  0.  0.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 21. 30. 24. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 8. 29.  0.  3.  1.] 
adversary cards in discard: [15. 14.  3.  0.] 
adversary owned cards: [ 0  8  1  1 15  8 29  3 14 14  3  8  0 16 15  0] -> size -> 16 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 64.47561645507812



action possibilites: [-1. 29.] 
expected returns: [[ 7.265396]
 [27.085157]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 29.] 
cards in discard: [ 1.  1.  1. 29. 29.  3.  0.  0.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 21. 30. 24. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 8. 29.  0.  3.  1.] 
adversary cards in discard: [15. 14.  3.  0.] 
adversary owned cards: [ 0  8  1  1 15  8 29  3 14 14  3  8  0 16 15  0] -> size -> 16 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 46.992183685302734



action possibilites: [-1.] 
expected returns: [[19.703781]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [ 1.  1.  1. 29. 29.  3.  0.  0.  3.  3.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 3 
card supply: [28. 21. 30. 24. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 8. 29.  0.  3.  1.] 
adversary cards in discard: [15. 14.  3.  0.] 
adversary owned cards: [ 0  8  1  1 15  8 29  3 14 14  3  8  0 16 15  0] -> size -> 16 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 150   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 21.106966018676758





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[ 19.31395 ]
 [ 33.89612 ]
 [ 25.503124]
 [-44.08705 ]
 [ 27.732016]
 [ 29.998188]
 [ 21.657173]
 [ 27.940857]
 [ 27.317862]
 [ 33.42482 ]
 [ 20.074343]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 1.  1.  1. 29. 29.  3.  0.  0.  3.  3.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 21. 30. 24. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 8. 29.  0.  3.  1.] 
adversary cards in discard: [15. 14.  3.  0.] 
adversary owned cards: [ 0  8  1  1 15  8 29  3 14 14  3  8  0 16 15  0] -> size -> 16 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 150   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 19.703781127929688



buy possibilites: [-1] 
expected returns: [[16.19851]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 1.  1.  1. 29. 29.  3.  0.  0.  3.  3.  1.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 20. 30. 24. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 8. 29.  0.  3.  1.] 
adversary cards in discard: [15. 14.  3.  0.] 
adversary owned cards: [ 0  8  1  1 15  8 29  3 14 14  3  8  0 16 15  0] -> size -> 16 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5.    0.    0.  150.    0.    0.   60.    0.    0.    0.    0.    0.
   0.    0.   13.5   0. ] 
sum of rewards: 218.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 33.896121978759766






Player: 1 
cards in hand: [ 8. 29.  0.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  0.  3.  1.] 
cards in discard: [15. 14.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  1  1 15  8 29  3 14 14  3  8  0 16 15  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 20. 30. 24. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  0.  3. 29.  1.] 
adversary cards in discard: [ 1.  1.  1. 29. 29.  3.  0.  0.  3.  3.  1.  1. 29. 29. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1] -> size -> 31 
adversary victory points: 7
player victory points: 2 


action possibilites: [-1.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  1. 15.] 
cards in discard: [15. 14.  3.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  8  1  1 15  8 29  3 14 14  3  8  0 16 15  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 20. 30. 24. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  0.  3. 29.  1.] 
adversary cards in discard: [ 1.  1.  1. 29. 29.  3.  0.  0.  3.  3.  1.  1. 29. 29. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1] -> size -> 31 
adversary victory points: 7
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [15. 14.  3.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 8  1  8 29  3 14 14  3  8  0 16 15  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 20. 30. 24. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  0.  3. 29.  1.] 
adversary cards in discard: [ 1.  1.  1. 29. 29.  3.  0.  0.  3.  3.  1.  1. 29. 29. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1] -> size -> 31 
adversary victory points: 7
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [15. 14.  3.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 8  1  8 29  3 14 14  3  8  0 16 15  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 20. 30. 24. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  0.  3. 29.  1.] 
adversary cards in discard: [ 1.  1.  1. 29. 29.  3.  0.  0.  3.  3.  1.  1. 29. 29. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1] -> size -> 31 
adversary victory points: 7
player victory points: 2 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  3. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-28.676994]
 [-10.32457 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 29.  1.] 
cards in discard: [ 1.  1.  1. 29. 29.  3.  0.  0.  3.  3.  1.  1. 29. 29. 29.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 20. 30. 24. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  1. 14.  8.  8.] 
adversary cards in discard: [15. 14.  3.  0.  3. 29.  8.] 
adversary owned cards: [ 8  1  8 29  3 14 14  3  8  0 16 15  0] -> size -> 13 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 16.198509216308594



action possibilites: [-1.] 
expected returns: [[38.95078]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 1.] 
cards in discard: [ 1.  1.  1. 29. 29.  3.  0.  0.  3.  3.  1.  1. 29. 29. 29.  3.  0.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 20. 30. 24. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  1. 14.  8.  8.] 
adversary cards in discard: [15. 14.  3.  0.  3. 29.  8.] 
adversary owned cards: [ 8  1  8 29  3 14 14  3  8  0 16 15  0] -> size -> 13 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -15.823709487915039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[ 37.153255]
 [ 52.816883]
 [ 43.81029 ]
 [-31.314274]
 [ 46.26261 ]
 [ 48.584747]
 [ 39.55488 ]
 [ 46.44904 ]
 [ 45.802303]
 [ 52.238556]
 [ 38.28287 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 1.] 
cards in discard: [ 1.  1.  1. 29. 29.  3.  0.  0.  3.  3.  1.  1. 29. 29. 29.  3.  0.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 20. 30. 24. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  1. 14.  8.  8.] 
adversary cards in discard: [15. 14.  3.  0.  3. 29.  8.] 
adversary owned cards: [ 8  1  8 29  3 14 14  3  8  0 16 15  0] -> size -> 13 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 38.95077896118164



buy possibilites: [-1] 
expected returns: [[-33.918804]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 1.] 
cards in discard: [ 1.  1.  1. 29. 29.  3.  0.  0.  3.  3.  1.  1. 29. 29. 29.  3.  0.  1.
  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 19. 30. 24. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  1. 14.  8.  8.] 
adversary cards in discard: [15. 14.  3.  0.  3. 29.  8.] 
adversary owned cards: [ 8  1  8 29  3 14 14  3  8  0 16 15  0] -> size -> 13 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[ -5.    0.    0.  150.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.   13.5   0. ] 
sum of rewards: 178.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 52.81686782836914






Player: 1 
cards in hand: [ 0.  1. 14.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 14.  8.  8.] 
cards in discard: [15. 14.  3.  0.  3. 29.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  8 29  3 14 14  3  8  0 16 15  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 19. 30. 24. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [29.  3. 29.  0.  0.] 
adversary cards in discard: [ 1.  1.  1. 29. 29.  3.  0.  0.  3.  3.  1.  1. 29. 29. 29.  3.  0.  1.
  1. 29.  3.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1] -> size -> 32 
adversary victory points: 7
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 14.  8.  8.] 
cards in discard: [15. 14.  3.  0.  3. 29.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  8 29  3 14 14  3  8  0 16 15  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 19. 30. 24. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [29.  3. 29.  0.  0.] 
adversary cards in discard: [ 1.  1.  1. 29. 29.  3.  0.  0.  3.  3.  1.  1. 29. 29. 29.  3.  0.  1.
  1. 29.  3.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1] -> size -> 32 
adversary victory points: 7
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 14.  8.  8.] 
cards in discard: [15. 14.  3.  0.  3. 29.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  8 29  3 14 14  3  8  0 16 15  0  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 19. 30. 23. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [29.  3. 29.  0.  0.] 
adversary cards in discard: [ 1.  1.  1. 29. 29.  3.  0.  0.  3.  3.  1.  1. 29. 29. 29.  3.  0.  1.
  1. 29.  3.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1] -> size -> 32 
adversary victory points: 7
player victory points: 3 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [29.  3. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[-139.37979]
 [-175.78198]
 [-175.78198]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 29.  0.  0.] 
cards in discard: [ 1.  1.  1. 29. 29.  3.  0.  0.  3.  3.  1.  1. 29. 29. 29.  3.  0.  1.
  1. 29.  3.  0.  3.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 19. 30. 23. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 1.  3. 14.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1  8 29  3 14 14  3  8  0 16 15  0  3] -> size -> 14 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: -33.91880416870117





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-165.44704]
 [-158.43323]
 [-262.31152]
 [-168.30685]
 [-139.57182]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3. 29.  0.  0.] 
cards in discard: [ 1.  1.  1. 29. 29.  3.  0.  0.  3.  3.  1.  1. 29. 29. 29.  3.  0.  1.
  1. 29.  3.  0.  3.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 19. 30. 23. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 1.  3. 14.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1  8 29  3 14 14  3  8  0 16 15  0  3] -> size -> 14 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -139.37977600097656



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 1.  3. 14.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 16.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 14.  8. 16.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  8 29  3 14 14  3  8  0 16 15  0  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 19. 30. 23. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  0.  1. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1] -> size -> 32 
adversary victory points: 7
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  8. 16.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  1  8 29  3 14 14  3  8  0 16 15  0  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 19. 30. 23. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  1. 29.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1] -> size -> 32 
adversary victory points: 7
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  8. 16.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  1  8 29  3 14 14  3  8  0 16 15  0  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 19. 30. 23. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  1. 29.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1] -> size -> 32 
adversary victory points: 7
player victory points: 3 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 3.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-12.826872 ]
 [  6.1239405]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 29.] 
cards in discard: [0. 0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 19. 30. 23. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 8. 29.  8. 15.  3.] 
adversary cards in discard: [14.  1.  3.  8. 16.] 
adversary owned cards: [ 8  1  8 29  3 14 14  3  8  0 16 15  0  3] -> size -> 14 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0 760   0] 
sum of rewards: 875 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -2.4850707054138184



action possibilites: [-1.] 
expected returns: [[33.4994]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [0. 0. 1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 19. 30. 23. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 8. 29.  8. 15.  3.] 
adversary cards in discard: [14.  1.  3.  8. 16.] 
adversary owned cards: [ 8  1  8 29  3 14 14  3  8  0 16 15  0  3] -> size -> 14 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -1.6402558088302612





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 33.198402]
 [ 39.67902 ]
 [-32.59526 ]
 [ 35.354946]
 [ 35.069744]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [0. 0. 1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 19. 30. 23. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 8. 29.  8. 15.  3.] 
adversary cards in discard: [14.  1.  3.  8. 16.] 
adversary owned cards: [ 8  1  8 29  3 14 14  3  8  0 16 15  0  3] -> size -> 14 
adversary victory points: 3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 33.4994010925293



buy possibilites: [-1] 
expected returns: [[15.232407]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [0. 0. 1. 3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 19. 30. 22. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 8. 29.  8. 15.  3.] 
adversary cards in discard: [14.  1.  3.  8. 16.] 
adversary owned cards: [ 8  1  8 29  3 14 14  3  8  0 16 15  0  3] -> size -> 14 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 181 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 39.67903518676758






Player: 1 
cards in hand: [ 8. 29.  8. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  8. 15.  3.] 
cards in discard: [14.  1.  3.  8. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1  8 29  3 14 14  3  8  0 16 15  0  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 19. 30. 22. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [ 0.  0.  1.  3. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3] -> size -> 33 
adversary victory points: 8
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 15.] 
cards in discard: [14.  1.  3.  8. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  8 29 14 14  3  8  0 16 15  0  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 19. 30. 22. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [ 0.  0.  1.  3. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3] -> size -> 33 
adversary victory points: 8
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 15.] 
cards in discard: [14.  1.  3.  8. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  8 29 14 14  3  8  0 16 15  0  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 19. 30. 22. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [ 0.  0.  1.  3. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3] -> size -> 33 
adversary victory points: 8
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 15.] 
cards in discard: [14.  1.  3.  8. 16.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  8 29 14 14  3  8  0 16 15  0  3  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 19. 30. 22. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 0. 1. 0.] 
adversary cards in discard: [ 0.  0.  1.  3. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3] -> size -> 33 
adversary victory points: 8
player victory points: 2 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[11.485346]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [ 0.  0.  1.  3. 29.  3.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 19. 30. 22. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  0.  3.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8 29 14 14  3  8  0 16 15  0  3  0] -> size -> 13 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 15.232406616210938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[  9.887865 ]
 [ 24.29688  ]
 [-20.608624 ]
 [ 15.950495 ]
 [-17.243727 ]
 [-63.16235  ]
 [ 18.256783 ]
 [ 20.39412  ]
 [ 12.290189 ]
 [ 25.457523 ]
 [ 18.427519 ]
 [ 23.556297 ]
 [ 17.83198  ]
 [  6.8326597]
 [ 23.761604 ]
 [ 10.9079075]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [ 0.  0.  1.  3. 29.  3.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 6 
card supply: [27. 19. 30. 22. 30.  8. 10.  9.  9.  7. 10.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  0.  3.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8 29 14 14  3  8  0 16 15  0  3  0] -> size -> 13 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 10.097328186035156



buy possibilites: [-1] 
expected returns: [[20.444714]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [ 0.  0.  1.  3. 29.  3.  0. 25.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 19. 30. 22. 30.  8. 10.  9.  9.  7.  9.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  0.  3.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8 29 14 14  3  8  0 16 15  0  3  0] -> size -> 13 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[ -5.    0.    0.  180.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 237.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 25.457504272460938






Player: 1 
cards in hand: [ 3.  0.  3.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  0. 14.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8 29 14 14  3  8  0 16 15  0  3  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 19. 30. 22. 30.  8. 10.  9.  9.  7.  9.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 1.  1.  3.  1. 29.] 
adversary cards in discard: [ 0.  0.  1.  3. 29.  3.  0. 25.  0.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25] -> size -> 34 
adversary victory points: 8
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 1  8 29 14 14  3  8  0 16 15  0  3  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 19. 30. 22. 30.  8. 10.  9.  9.  7.  9.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  1. 29.] 
adversary cards in discard: [ 0.  0.  1.  3. 29.  3.  0. 25.  0.  0.  0.  1.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25] -> size -> 34 
adversary victory points: 8
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 1  8 29 14 14  3  8  0 16 15  0  3  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 19. 30. 22. 30.  8. 10.  9.  9.  7.  9.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  1. 29.] 
adversary cards in discard: [ 0.  0.  1.  3. 29.  3.  0. 25.  0.  0.  0.  1.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25] -> size -> 34 
adversary victory points: 8
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 1  8 29 14 14  3  8  0 16 15  0  3  0  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 18. 30. 22. 30.  8. 10.  9.  9.  7.  9.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  1. 29.] 
adversary cards in discard: [ 0.  0.  1.  3. 29.  3.  0. 25.  0.  0.  0.  1.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25] -> size -> 34 
adversary victory points: 8
player victory points: 2 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 3.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[10.847464]
 [35.86018 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 29.] 
cards in discard: [ 0.  0.  1.  3. 29.  3.  0. 25.  0.  0.  0.  1.  0.  1.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 18. 30. 22. 30.  8. 10.  9.  9.  7.  9.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [16.  0.  8.  1. 15.] 
adversary cards in discard: [ 1. 14.  3.  0.  3.  0.] 
adversary owned cards: [ 1  8 29 14 14  3  8  0 16 15  0  3  0  1] -> size -> 14 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0 901   0] 
sum of rewards: 1076 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 0.9363911151885986



action possibilites: [-1.] 
expected returns: [[4.337714]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1.] 
cards in discard: [ 0.  0.  1.  3. 29.  3.  0. 25.  0.  0.  0.  1.  0.  1.  1.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 18. 30. 22. 30.  8. 10.  9.  9.  7.  9.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [16.  0.  8.  1. 15.] 
adversary cards in discard: [ 1. 14.  3.  0.  3.  0.] 
adversary owned cards: [ 1  8 29 14 14  3  8  0 16 15  0  3  0  1] -> size -> 14 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 28.37714385986328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[  1.5776861]
 [ 16.808794 ]
 [  8.221225 ]
 [-26.50657  ]
 [-64.292885 ]
 [ 10.484596 ]
 [ 13.007872 ]
 [  4.1553783]
 [ 18.315489 ]
 [ 10.7796   ]
 [ 16.192629 ]
 [ 10.104835 ]
 [ -1.3389394]
 [ 16.500208 ]
 [  2.2594535]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1.] 
cards in discard: [ 0.  0.  1.  3. 29.  3.  0. 25.  0.  0.  0.  1.  0.  1.  1.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25] -> size -> 34 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 18. 30. 22. 30.  8. 10.  9.  9.  7.  9.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [16.  0.  8.  1. 15.] 
adversary cards in discard: [ 1. 14.  3.  0.  3.  0.] 
adversary owned cards: [ 1  8 29 14 14  3  8  0 16 15  0  3  0  1] -> size -> 14 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 4.337714195251465



buy possibilites: [-1] 
expected returns: [[13.44883]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1.] 
cards in discard: [ 0.  0.  1.  3. 29.  3.  0. 25.  0.  0.  0.  1.  0.  1.  1.  3. 25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 18. 30. 22. 30.  8. 10.  9.  9.  7.  8.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [16.  0.  8.  1. 15.] 
adversary cards in discard: [ 1. 14.  3.  0.  3.  0.] 
adversary owned cards: [ 1  8 29 14 14  3  8  0 16 15  0  3  0  1] -> size -> 14 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 445 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 18.315465927124023






Player: 1 
cards in hand: [16.  0.  8.  1. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  8.  1. 15.] 
cards in discard: [ 1. 14.  3.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8 29 14 14  3  8  0 16 15  0  3  0  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 18. 30. 22. 30.  8. 10.  9.  9.  7.  8.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  3. 29. 29.  1.] 
adversary cards in discard: [ 0.  0.  1.  3. 29.  3.  0. 25.  0.  0.  0.  1.  0.  1.  1.  3. 25. 29.
  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25] -> size -> 35 
adversary victory points: 8
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 15.] 
cards in discard: [ 1. 14.  3.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 29 14 14  3  8 16 15  0  3  0  1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 18. 30. 22. 30.  8. 10.  9.  9.  7.  8.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  3. 29. 29.  1.] 
adversary cards in discard: [ 0.  0.  1.  3. 29.  3.  0. 25.  0.  0.  0.  1.  0.  1.  1.  3. 25. 29.
  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25] -> size -> 35 
adversary victory points: 8
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 15.] 
cards in discard: [ 1. 14.  3.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 29 14 14  3  8 16 15  0  3  0  1] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 18. 30. 22. 30.  8. 10.  9.  9.  7.  8.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  3. 29. 29.  1.] 
adversary cards in discard: [ 0.  0.  1.  3. 29.  3.  0. 25.  0.  0.  0.  1.  0.  1.  1.  3. 25. 29.
  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25] -> size -> 35 
adversary victory points: 8
player victory points: 2 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 3.  3. 29. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[-51.275963]
 [-35.73283 ]
 [-35.73283 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29. 29.  1.] 
cards in discard: [ 0.  0.  1.  3. 29.  3.  0. 25.  0.  0.  0.  1.  0.  1.  1.  3. 25. 29.
  1.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 18. 30. 22. 30.  8. 10.  9.  9.  7.  8.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3. 14.  8. 14. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 29 14 14  3  8 16 15  0  3  0  1] -> size -> 12 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 13.448829650878906



action possibilites: [-1. 29.] 
expected returns: [[-107.44485]
 [ -92.97296]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29.  3.] 
cards in discard: [ 0.  0.  1.  3. 29.  3.  0. 25.  0.  0.  0.  1.  0.  1.  1.  3. 25. 29.
  1.  1.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 18. 30. 22. 30.  8. 10.  9.  9.  7.  8.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3. 14.  8. 14. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 29 14 14  3  8 16 15  0  3  0  1] -> size -> 12 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -38.7650032043457



action possibilites: [-1. 29.] 
expected returns: [[-22.861618 ]
 [ -3.4976497]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29.] 
cards in discard: [ 0.  0.  1.  3. 29.  3.  0. 25.  0.  0.  0.  1.  0.  1.  1.  3. 25. 29.
  1.  1.  1.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25] -> size -> 35 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 18. 30. 22. 30.  8. 10.  9.  9.  7.  8.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3. 14.  8. 14. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 29 14 14  3  8 16 15  0  3  0  1] -> size -> 12 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -96.411865234375



action possibilites: [-1.] 
expected returns: [[-6.744339]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [ 0.  0.  1.  3. 29.  3.  0. 25.  0.  0.  0.  1.  0.  1.  1.  3. 25. 29.
  1.  1.  1.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25] -> size -> 35 
action values: 1 
buys: 0 
player value: 3 
card supply: [27. 18. 30. 22. 30.  8. 10.  9.  9.  7.  8.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3. 14.  8. 14. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 29 14 14  3  8 16 15  0  3  0  1] -> size -> 12 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 180   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: discard_n_cards - action 0
Learning step: 0
desired expected reward: -23.993410110473633





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ -8.440361  ]
 [  6.242893  ]
 [ -1.987258  ]
 [-75.672226  ]
 [  2.4995973 ]
 [ -6.2470717 ]
 [ -0.08633995]
 [ -7.0747404 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [ 0.  0.  1.  3. 29.  3.  0. 25.  0.  0.  0.  1.  0.  1.  1.  3. 25. 29.
  1.  1.  1.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25] -> size -> 35 
action values: 1 
buys: 1 
player value: 3 
card supply: [27. 18. 30. 22. 30.  8. 10.  9.  9.  7.  8.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3. 14.  8. 14. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 29 14 14  3  8 16 15  0  3  0  1] -> size -> 12 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 180   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -6.7443389892578125



buy possibilites: [-1] 
expected returns: [[-6.1604056]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [ 0.  0.  1.  3. 29.  3.  0. 25.  0.  0.  0.  1.  0.  1.  1.  3. 25. 29.
  1.  1.  1.  3.  3.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 17. 30. 22. 30.  8. 10.  9.  9.  7.  8.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3. 14.  8. 14. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 29 14 14  3  8 16 15  0  3  0  1] -> size -> 12 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 180   0   0  60   0   0   0   0 -10   0   0  54   0] 
sum of rewards: 279 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 6.242892265319824






Player: 1 
cards in hand: [ 3. 14.  8. 14. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 14. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  8. 14. 29.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 29 14 14  3  8 16 15  0  3  0  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 17. 30. 22. 30.  8. 10.  9.  9.  7.  8.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 1. 29. 29.  3. 29.] 
adversary cards in discard: [ 0.  0.  1.  3. 29.  3.  0. 25.  0.  0.  0.  1.  0.  1.  1.  3. 25. 29.
  1.  1.  1.  3.  3.  1. 29. 29. 29.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1] -> size -> 36 
adversary victory points: 8
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  8. 14. 29.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 29 14 14  3  8 16 15  0  3  0  1] -> size -> 12 
action values: 1 
buys: 1 
player value: 0 
card supply: [27. 17. 30. 22. 30.  8. 10.  9.  9.  7.  8.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 1. 29. 29.  3. 29.] 
adversary cards in discard: [ 0.  0.  1.  3. 29.  3.  0. 25.  0.  0.  0.  1.  0.  1.  1.  3. 25. 29.
  1.  1.  1.  3.  3.  1. 29. 29. 29.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1] -> size -> 36 
adversary victory points: 8
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  8. 14. 29.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 29 14 14  3  8 16 15  0  3  0  1  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 17. 30. 22. 30.  8. 10.  9.  9.  7.  8.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 1. 29. 29.  3. 29.] 
adversary cards in discard: [ 0.  0.  1.  3. 29.  3.  0. 25.  0.  0.  0.  1.  0.  1.  1.  3. 25. 29.
  1.  1.  1.  3.  3.  1. 29. 29. 29.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1] -> size -> 36 
adversary victory points: 8
player victory points: 2 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 1. 29. 29.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[-33.730534]
 [-25.111284]
 [-25.111284]
 [-25.111284]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 29.  3. 29.] 
cards in discard: [ 0.  0.  1.  3. 29.  3.  0. 25.  0.  0.  0.  1.  0.  1.  1.  3. 25. 29.
  1.  1.  1.  3.  3.  1. 29. 29. 29.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 17. 30. 22. 30.  8. 10.  9.  9.  7.  8.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 1.  8. 16.  0.  0.] 
adversary cards in discard: [ 0.  3. 14.  8. 14. 29.] 
adversary owned cards: [ 8 29 14 14  3  8 16 15  0  3  0  1  0] -> size -> 13 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: -6.16040563583374



action possibilites: [-1. 29. 29. 29.] 
expected returns: [[-45.148716]
 [-34.393738]
 [-34.393738]
 [-34.393738]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 29. 29.] 
cards in discard: [ 0.  0.  1.  3. 29.  3.  0. 25.  0.  0.  0.  1.  0.  1.  1.  3. 25. 29.
  1.  1.  1.  3.  3.  1. 29. 29. 29.  3.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 17. 30. 22. 30.  8. 10.  9.  9.  7.  8.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 1.  8. 16.  0.  0.] 
adversary cards in discard: [ 0.  3. 14.  8. 14. 29.] 
adversary owned cards: [ 8 29 14 14  3  8 16 15  0  3  0  1  0] -> size -> 13 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -27.36933135986328



action possibilites: [-1. 29.] 
expected returns: [[-25.691769]
 [ -6.581119]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  1.] 
cards in discard: [ 0.  0.  1.  3. 29.  3.  0. 25.  0.  0.  0.  1.  0.  1.  1.  3. 25. 29.
  1.  1.  1.  3.  3.  1. 29. 29. 29.  3.  3.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 17. 30. 22. 30.  8. 10.  9.  9.  7.  8.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 1.  8. 16.  0.  0.] 
adversary cards in discard: [ 0.  3. 14.  8. 14. 29.] 
adversary owned cards: [ 8 29 14 14  3  8 16 15  0  3  0  1  0] -> size -> 13 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -37.63193893432617



action possibilites: [-1.] 
expected returns: [[12.244337]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1.] 
cards in discard: [3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 3 
card supply: [26. 17. 30. 22. 30.  8. 10.  9.  9.  7.  8.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 1.  8. 16.  0.  0.] 
adversary cards in discard: [ 0.  3. 14.  8. 14. 29.] 
adversary owned cards: [ 8 29 14 14  3  8 16 15  0  3  0  1  0] -> size -> 13 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 180   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -12.301799774169922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 12.899731]
 [ 27.032478]
 [-15.535115]
 [ 19.112679]
 [-12.391931]
 [-47.5499  ]
 [ 21.375484]
 [ 23.237099]
 [ 14.514502]
 [ 27.976358]
 [ 21.478312]
 [ 26.260647]
 [ 20.945713]
 [ 10.491321]
 [ 26.407461]
 [ 14.755566]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1.] 
cards in discard: [3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1] -> size -> 36 
action values: 0 
buys: 1 
player value: 7 
card supply: [26. 17. 30. 22. 30.  8. 10.  9.  9.  7.  8.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 1.  8. 16.  0.  0.] 
adversary cards in discard: [ 0.  3. 14.  8. 14. 29.] 
adversary owned cards: [ 8 29 14 14  3  8 16 15  0  3  0  1  0] -> size -> 13 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 180   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 12.24433708190918



buy possibilites: [-1] 
expected returns: [[33.565228]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1.] 
cards in discard: [ 3. 25.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 17. 30. 22. 30.  8. 10.  9.  9.  7.  7.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 1.  8. 16.  0.  0.] 
adversary cards in discard: [ 0.  3. 14.  8. 14. 29.] 
adversary owned cards: [ 8 29 14 14  3  8 16 15  0  3  0  1  0] -> size -> 13 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[ -5.    0.    0.  180.    0.    0.   60.    0.    0.    0.    0.  -20.
   0.    0.   62.5   0. ] 
sum of rewards: 277.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 27.976356506347656






Player: 1 
cards in hand: [ 1.  8. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8. 16.  0.  0.] 
cards in discard: [ 0.  3. 14.  8. 14. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 29 14 14  3  8 16 15  0  3  0  1  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 17. 30. 22. 30.  8. 10.  9.  9.  7.  7.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 3. 1. 1.] 
adversary cards in discard: [ 3. 25. 29. 29. 29.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25] -> size -> 37 
adversary victory points: 8
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0.  3. 14.  8. 14. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 29 14 14  3  8 15  3  0  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 17. 30. 22. 30.  8. 10.  9.  9.  7.  7.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 3. 1. 1.] 
adversary cards in discard: [ 3. 25. 29. 29. 29.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25] -> size -> 37 
adversary victory points: 8
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  3. 14.  8. 14. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 29 14 14  3  8 15  3  0  0] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 17. 30. 22. 30.  8. 10.  9.  9.  7.  7.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 3. 1. 1.] 
adversary cards in discard: [ 3. 25. 29. 29. 29.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25] -> size -> 37 
adversary victory points: 8
player victory points: 2 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 1. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.93946004]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 1. 1.] 
cards in discard: [ 3. 25. 29. 29. 29.  1.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 17. 30. 22. 30.  8. 10.  9.  9.  7.  7.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  8.  3.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 29 14 14  3  8 15  3  0  0] -> size -> 10 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 33.56522750854492





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ -2.998364 ]
 [ 11.508868 ]
 [-32.69971  ]
 [  2.9987586]
 [-30.567518 ]
 [-75.81547  ]
 [  5.2000675]
 [  7.363393 ]
 [ -0.8933239]
 [ 12.650574 ]
 [  5.350254 ]
 [ 10.696778 ]
 [  4.740635 ]
 [ -5.76297  ]
 [ 10.8888035]
 [ -2.3472762]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 1.] 
cards in discard: [ 3. 25. 29. 29. 29.  1.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25] -> size -> 37 
action values: 0 
buys: 1 
player value: 6 
card supply: [26. 17. 30. 22. 30.  8. 10.  9.  9.  7.  7.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  8.  3.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 29 14 14  3  8 15  3  0  0] -> size -> 10 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -1.792711853981018



buy possibilites: [-1] 
expected returns: [[24.765442]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 1.] 
cards in discard: [ 3. 25. 29. 29. 29.  1.  1. 25.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 17. 30. 22. 30.  8. 10.  9.  9.  7.  6.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  8.  3.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 29 14 14  3  8 15  3  0  0] -> size -> 10 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[ -5.    0.    0.  180.    0.    0.    0.    0.    0.    0.    0.  -30.
   0.    0.   62.5   0. ] 
sum of rewards: 207.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 12.650562286376953






Player: 1 
cards in hand: [ 0.  8.  3.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  3.  3. 15.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 29 14 14  3  8 15  3  0  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 17. 30. 22. 30.  8. 10.  9.  9.  7.  6.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 25.  3.  0. 29.] 
adversary cards in discard: [ 3. 25. 29. 29. 29.  1.  1. 25.  0.  0.  3.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25] -> size -> 38 
adversary victory points: 8
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8 29 14 14  3  8 15  3  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 17. 30. 22. 30.  8. 10.  9.  9.  7.  6.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 25.  3.  0. 29.] 
adversary cards in discard: [ 3. 25. 29. 29. 29.  1.  1. 25.  0.  0.  3.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25] -> size -> 38 
adversary victory points: 8
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8 29 14 14  3  8 15  3  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 17. 30. 22. 30.  8. 10.  9.  9.  7.  6.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 25.  3.  0. 29.] 
adversary cards in discard: [ 3. 25. 29. 29. 29.  1.  1. 25.  0.  0.  3.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25] -> size -> 38 
adversary victory points: 8
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8 29 14 14  3  8 15  3  0  1] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 16. 30. 22. 30.  8. 10.  9.  9.  7.  6.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 25.  3.  0. 29.] 
adversary cards in discard: [ 3. 25. 29. 29. 29.  1.  1. 25.  0.  0.  3.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25] -> size -> 38 
adversary victory points: 8
player victory points: 2 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[40.159817]
 [52.699055]
 [56.890327]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3.  0. 29.] 
cards in discard: [ 3. 25. 29. 29. 29.  1.  1. 25.  0.  0.  3.  1.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 16. 30. 22. 30.  8. 10.  9.  9.  7.  6.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 8. 14. 29.  0. 14.] 
adversary cards in discard: [ 1. 15.  8.  3.  3.] 
adversary owned cards: [ 8 29 14 14  3  8 15  3  0  1] -> size -> 10 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 24.76544189453125



action possibilites: [-1. 25.] 
expected returns: [[ 1.550689]
 [16.718395]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.  0.] 
cards in discard: [ 3. 25. 29. 29. 29.  1.  1. 25.  0.  0.  3.  1.  1.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 16. 30. 22. 30.  8. 10.  9.  9.  7.  6.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 8. 14. 29.  0. 14.] 
adversary cards in discard: [ 1. 15.  8.  3.  3.] 
adversary owned cards: [ 8 29 14 14  3  8 15  3  0  1] -> size -> 10 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 51.877262115478516



action possibilites: [-1] 
expected returns: [[25.190186]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 3. 25. 29. 29. 29.  1.  1. 25.  0.  0.  3.  1.  1.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 16. 30. 22. 30.  8.  9.  9.  9.  7.  6.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 8. 14. 29.  0. 14.] 
adversary cards in discard: [ 1. 15.  8.  3.  3.  6.] 
adversary owned cards: [ 8 29 14 14  3  8 15  3  0  1  6] -> size -> 11 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 16.718395233154297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[ 18.853956]
 [ 33.151676]
 [ 25.13462 ]
 [-45.550747]
 [ 27.597124]
 [ 29.444592]
 [ 20.960705]
 [ 27.706276]
 [ 27.177765]
 [ 32.547993]
 [ 20.965668]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 3. 25. 29. 29. 29.  1.  1. 25.  0.  0.  3.  1.  1.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25] -> size -> 38 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 16. 30. 22. 30.  8.  9.  9.  9.  7.  6.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 8. 14. 29.  0. 14.] 
adversary cards in discard: [ 1. 15.  8.  3.  3.  6.] 
adversary owned cards: [ 8 29 14 14  3  8 15  3  0  1  6] -> size -> 11 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1
Learning step: 0
desired expected reward: 25.190185546875



buy possibilites: [-1] 
expected returns: [[7.7345448]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 3. 25. 29. 29. 29.  1.  1. 25.  0.  0.  3.  1.  1.  3.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 15. 30. 22. 30.  8.  9.  9.  9.  7.  6.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 8. 14. 29.  0. 14.] 
adversary cards in discard: [ 1. 15.  8.  3.  3.  6.] 
adversary owned cards: [ 8 29 14 14  3  8 15  3  0  1  6] -> size -> 11 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[ -5.    0.    0.  180.    0.    0.   40.    0.    0.    0.    0.  -40.
   0.    0.   13.5   0. ] 
sum of rewards: 188.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 33.15165710449219






Player: 1 
cards in hand: [ 8. 14. 29.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 29. 14.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14. 29.  0. 14.] 
cards in discard: [ 1. 15.  8.  3.  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 29 14 14  3  8 15  3  0  1  6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 15. 30. 22. 30.  8.  9.  9.  9.  7.  6.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [29.  1. 29.  1.  1.] 
adversary cards in discard: [ 3. 25. 29. 29. 29.  1.  1. 25.  0.  0.  3.  1.  1.  3.  1. 29. 25.  0.
  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1] -> size -> 39 
adversary victory points: 8
player victory points: 1 


action possibilites: [-1.  8. 14. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  0. 14.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8 29 14 14  3  8 15  3  0  1  6] -> size -> 11 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 15. 30. 22. 30.  8.  9.  9.  9.  7.  6.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [29.  1. 29.  1.  1.] 
adversary cards in discard: [ 3. 25. 29. 29. 29.  1.  1. 25.  0.  0.  3.  1.  1.  3.  1. 29. 25.  0.
  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1] -> size -> 39 
adversary victory points: 8
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 14.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 8 29 14 14  3  8 15  3  1  6] -> size -> 10 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 15. 30. 22. 30.  8.  9.  9.  9.  7.  6.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [29.  1. 29.  1.  1.] 
adversary cards in discard: [ 3. 25. 29. 29. 29.  1.  1. 25.  0.  0.  3.  1.  1.  3.  1. 29. 25.  0.
  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1] -> size -> 39 
adversary victory points: 8
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 14.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 8 29 14 14  3  8 15  3  1  6] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 15. 30. 22. 30.  8.  9.  9.  9.  7.  6.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [29.  1. 29.  1.  1.] 
adversary cards in discard: [ 3. 25. 29. 29. 29.  1.  1. 25.  0.  0.  3.  1.  1.  3.  1. 29. 25.  0.
  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1] -> size -> 39 
adversary victory points: 8
player victory points: 1 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [29.  1. 29.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[-20.434464 ]
 [ -2.1997685]
 [ -2.1997685]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1. 29.  1.  1.] 
cards in discard: [ 3. 25. 29. 29. 29.  1.  1. 25.  0.  0.  3.  1.  1.  3.  1. 29. 25.  0.
  0.  0.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 15. 30. 22. 30.  8.  9.  9.  9.  7.  6.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3. 15.  8.  3.  6.] 
adversary cards in discard: [ 1. 29.  8. 14. 14.] 
adversary owned cards: [ 8 29 14 14  3  8 15  3  1  6] -> size -> 10 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 7.73454475402832



action possibilites: [-1. 29.] 
expected returns: [[-4.2381954]
 [14.3234005]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1.  1. 29.] 
cards in discard: [ 3. 25. 29. 29. 29.  1.  1. 25.  0.  0.  3.  1.  1.  3.  1. 29. 25.  0.
  0.  0.  3.  3. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 15. 30. 22. 30.  8.  9.  9.  9.  7.  6.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3. 15.  8.  3.  6.] 
adversary cards in discard: [ 1. 29.  8. 14. 14.] 
adversary owned cards: [ 8 29 14 14  3  8 15  3  1  6] -> size -> 10 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -7.659523963928223



action possibilites: [-1.] 
expected returns: [[39.661575]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 1.] 
cards in discard: [ 3. 25. 29. 29. 29.  1.  1. 25.  0.  0.  3.  1.  1.  3.  1. 29. 25.  0.
  0.  0.  3.  3. 29.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 15. 30. 22. 30.  8.  9.  9.  9.  7.  6.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3. 15.  8.  3.  6.] 
adversary cards in discard: [ 1. 29.  8. 14. 14.] 
adversary owned cards: [ 8 29 14 14  3  8 15  3  1  6] -> size -> 10 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: discard_n_cards - action 0
Learning step: 0
desired expected reward: -5.66556453704834





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 41.31208 ]
 [ 55.673676]
 [ 13.030138]
 [ 47.524204]
 [ 16.490364]
 [ 54.91895 ]
 [-18.910046]
 [ 49.730507]
 [ 51.733646]
 [ 42.993443]
 [ 56.713657]
 [ 49.85781 ]
 [ 54.889233]
 [ 49.289772]
 [ 38.917507]
 [ 55.058823]
 [ 42.68531 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 1.] 
cards in discard: [ 3. 25. 29. 29. 29.  1.  1. 25.  0.  0.  3.  1.  1.  3.  1. 29. 25.  0.
  0.  0.  3.  3. 29.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 8 
card supply: [26. 15. 30. 22. 30.  8.  9.  9.  9.  7.  6.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3. 15.  8.  3.  6.] 
adversary cards in discard: [ 1. 29.  8. 14. 14.] 
adversary owned cards: [ 8 29 14 14  3  8 15  3  1  6] -> size -> 10 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 39.66157531738281



buy possibilites: [-1] 
expected returns: [[-0.16604781]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 1.] 
cards in discard: [ 3. 25. 29. 29. 29.  1.  1. 25.  0.  0.  3.  1.  1.  3.  1. 29. 25.  0.
  0.  0.  3.  3. 29.  1. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25] -> size -> 40 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 15. 30. 22. 30.  8.  9.  9.  9.  7.  5.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3. 15.  8.  3.  6.] 
adversary cards in discard: [ 1. 29.  8. 14. 14.] 
adversary owned cards: [ 8 29 14 14  3  8 15  3  1  6] -> size -> 10 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[ -5.    0.    0.  210.    0.    0.   40.    0.    0.    0.    0.  -50.
   0.    0.   62.5   0. ] 
sum of rewards: 257.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 56.713661193847656






Player: 1 
cards in hand: [ 3. 15.  8.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  8.  3.  6.] 
cards in discard: [ 1. 29.  8. 14. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 29 14 14  3  8 15  3  1  6] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 15. 30. 22. 30.  8.  9.  9.  9.  7.  5.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  1.  0. 29.  3.] 
adversary cards in discard: [ 3. 25. 29. 29. 29.  1.  1. 25.  0.  0.  3.  1.  1.  3.  1. 29. 25.  0.
  0.  0.  3.  3. 29.  1. 25. 29. 29.  1.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25] -> size -> 40 
adversary victory points: 8
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  8.  3.  6.] 
cards in discard: [ 1. 29.  8. 14. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 29 14 14  3  8 15  3  1  6] -> size -> 10 
action values: 1 
buys: 1 
player value: 0 
card supply: [26. 15. 30. 22. 30.  8.  9.  9.  9.  7.  5.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  1.  0. 29.  3.] 
adversary cards in discard: [ 3. 25. 29. 29. 29.  1.  1. 25.  0.  0.  3.  1.  1.  3.  1. 29. 25.  0.
  0.  0.  3.  3. 29.  1. 25. 29. 29.  1.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25] -> size -> 40 
adversary victory points: 8
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 0.  1.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-35.195534]
 [-18.190987]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0. 29.  3.] 
cards in discard: [ 3. 25. 29. 29. 29.  1.  1. 25.  0.  0.  3.  1.  1.  3.  1. 29. 25.  0.
  0.  0.  3.  3. 29.  1. 25. 29. 29.  1.  1.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 15. 30. 22. 30.  8.  9.  9.  9.  7.  5.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 8.  6.  3. 29.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 29 14 14  3  8 15  3  1  6] -> size -> 10 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.1660478115081787



action possibilites: [-1. 25.] 
expected returns: [[-20.347181]
 [ -8.034251]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 25.] 
cards in discard: [ 3. 25. 29. 29. 29.  1.  1. 25.  0.  0.  3.  1.  1.  3.  1. 29. 25.  0.
  0.  0.  3.  3. 29.  1. 25. 29. 29.  1.  1.  1.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 15. 30. 22. 30.  8.  9.  9.  9.  7.  5.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 8.  6.  3. 29.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 29 14 14  3  8 15  3  1  6] -> size -> 10 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -22.920787811279297



action possibilites: [-1] 
expected returns: [[-37.491905]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  1. 29.] 
cards in discard: [ 3. 25. 29. 29. 29.  1.  1. 25.  0.  0.  3.  1.  1.  3.  1. 29. 25.  0.
  0.  0.  3.  3. 29.  1. 25. 29. 29.  1.  1.  1.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 15. 30. 22. 30.  8.  8.  9.  9.  7.  5.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 8.  6.  3. 29.  1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 8 29 14 14  3  8 15  3  1  6  6] -> size -> 11 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -8.03425121307373





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ -45.657753]
 [ -30.514889]
 [ -38.79914 ]
 [ -81.14327 ]
 [-111.8579  ]
 [ -35.122784]
 [ -35.15204 ]
 [ -45.220493]
 [ -30.762136]
 [ -35.63712 ]
 [ -31.975971]
 [ -35.784023]
 [ -48.970837]
 [ -32.21219 ]
 [ -37.4919  ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  1. 29.] 
cards in discard: [ 3. 25. 29. 29. 29.  1.  1. 25.  0.  0.  3.  1.  1.  3.  1. 29. 25.  0.
  0.  0.  3.  3. 29.  1. 25. 29. 29.  1.  1.  1.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25] -> size -> 40 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 15. 30. 22. 30.  8.  8.  9.  9.  7.  5.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 8.  6.  3. 29.  1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 8 29 14 14  3  8 15  3  1  6  6] -> size -> 11 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action -1
Learning step: 0
desired expected reward: -37.491905212402344



buy possibilites: [-1] 
expected returns: [[-36.938416]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  1. 29.] 
cards in discard: [ 3. 25. 29. 29. 29.  1.  1. 25.  0.  0.  3.  1.  1.  3.  1. 29. 25.  0.
  0.  0.  3.  3. 29.  1. 25. 29. 29.  1.  1.  1.  1.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 14. 30. 22. 30.  8.  8.  9.  9.  7.  5.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 8.  6.  3. 29.  1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 8 29 14 14  3  8 15  3  1  6  6] -> size -> 11 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[ -5.    0.    0.  210.    0.    0.   40.    0.    0.    0.    0.  -60.
   0.    0.   13.5   0. ] 
sum of rewards: 198.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -30.514888763427734






Player: 1 
cards in hand: [ 8.  6.  3. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6.  3. 29.  1.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 29 14 14  3  8 15  3  1  6  6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 14. 30. 22. 30.  8.  8.  9.  9.  7.  5.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [29.  1. 25.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1] -> size -> 41 
adversary victory points: 8
player victory points: 0 


action possibilites: [-1.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6.  1. 14.] 
cards in discard: [6. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8 29 14 14  3  8 15  3  1  6  6] -> size -> 11 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 14. 30. 22. 30.  8.  8.  9.  9.  7.  5.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [29.  1. 25.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1] -> size -> 41 
adversary victory points: 8
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [6. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 8 29 14  3  8 15  3  1  6] -> size -> 9 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 14. 30. 22. 30.  8.  8.  9.  9.  7.  5.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [29.  1. 25.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1] -> size -> 41 
adversary victory points: 8
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [6. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 8 29 14  3  8 15  3  1  6] -> size -> 9 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 14. 30. 22. 30.  8.  8.  9.  9.  7.  5.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [29.  1. 25.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1] -> size -> 41 
adversary victory points: 8
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [6. 3. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 8 29 14  3  8 15  3  1  6  8] -> size -> 10 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 14. 30. 22. 30.  8.  8.  9.  9.  6.  5.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [29.  1. 25.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1] -> size -> 41 
adversary victory points: 8
player victory points: 1 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [29.  1. 25.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[-5.417608 ]
 [10.32662  ]
 [ 6.3737335]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1. 25.  3.  3.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 14. 30. 22. 30.  8.  8.  9.  9.  6.  5.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 8.  8.  3. 15. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 29 14  3  8 15  3  1  6  8] -> size -> 10 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: -36.93841552734375



action possibilites: [-1. 25. 25.] 
expected returns: [[21.631752]
 [35.752384]
 [35.752384]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25.  3. 25.] 
cards in discard: [3.] 
cards in deck: 35 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 14. 30. 22. 30.  8.  8.  9.  9.  6.  5.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 8.  8.  3. 15. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 29 14  3  8 15  3  1  6  8] -> size -> 10 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 4.478732109069824



action possibilites: [-1] 
expected returns: [[-26.598896]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 25. 29.  0.] 
cards in discard: [3.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 14. 30. 22. 30.  8.  7.  9.  9.  6.  5.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 8.  8.  3. 15. 14.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 8 29 14  3  8 15  3  1  6  8  6] -> size -> 11 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 35.752376556396484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[-33.46163 ]
 [-19.637976]
 [-27.530872]
 [-96.81597 ]
 [-25.264973]
 [-23.43348 ]
 [-31.664495]
 [-25.14755 ]
 [-25.671408]
 [-20.303595]
 [-31.77325 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 25. 29.  0.] 
cards in discard: [3.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 14. 30. 22. 30.  8.  7.  9.  9.  6.  5.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 8.  8.  3. 15. 14.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 8 29 14  3  8 15  3  1  6  8  6] -> size -> 11 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action -1
Learning step: 0
desired expected reward: -26.598896026611328



buy possibilites: [-1] 
expected returns: [[-2.6878195]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 25. 29.  0.] 
cards in discard: [3. 1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 13. 30. 22. 30.  8.  7.  9.  9.  6.  5.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 8.  8.  3. 15. 14.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 8 29 14  3  8 15  3  1  6  8  6] -> size -> 11 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[ -5.    0.    0.  210.    0.    0.   40.    0.    0.    0.    0.  -70.
   0.    0.   13.5   0. ] 
sum of rewards: 188.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -19.637971878051758






Player: 1 
cards in hand: [ 8.  8.  3. 15. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 15. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  3. 15. 14.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 29 14  3  8 15  3  1  6  8  6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 13. 30. 22. 30.  8.  7.  9.  9.  6.  5.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [29.  1.  1.  3.  0.] 
adversary cards in discard: [ 3.  1. 29. 25.  1.  3. 25. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1] -> size -> 42 
adversary victory points: 8
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8.  3. 15. 14.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 29 14  3  8 15  3  1  6  8  6] -> size -> 11 
action values: 1 
buys: 1 
player value: 0 
card supply: [26. 13. 30. 22. 30.  8.  7.  9.  9.  6.  5.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [29.  1.  1.  3.  0.] 
adversary cards in discard: [ 3.  1. 29. 25.  1.  3. 25. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1] -> size -> 42 
adversary victory points: 8
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8.  3. 15. 14.] 
cards in discard: [6. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 29 14  3  8 15  3  1  6  8  6  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 13. 30. 22. 30.  8.  7.  9.  9.  6.  5.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [29.  1.  1.  3.  0.] 
adversary cards in discard: [ 3.  1. 29. 25.  1.  3. 25. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1] -> size -> 42 
adversary victory points: 8
player victory points: 0 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [29.  1.  1.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[23.818766]
 [44.184284]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  1.  3.  0.] 
cards in discard: [ 3.  1. 29. 25.  1.  3. 25. 29.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 13. 30. 22. 30.  8.  7.  9.  9.  6.  5.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  1.  6. 29.  8.] 
adversary cards in discard: [ 6.  0.  8.  8.  3. 15. 14.] 
adversary owned cards: [ 8 29 14  3  8 15  3  1  6  8  6  0] -> size -> 12 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: -2.687819480895996



action possibilites: [-1.] 
expected returns: [[-5.1985855]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 1.] 
cards in discard: [ 3.  1. 29. 25.  1.  3. 25. 29.  0.  1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 13. 30. 22. 30.  8.  7.  9.  9.  6.  5.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  1.  6. 29.  8.] 
adversary cards in discard: [ 6.  0.  8.  8.  3. 15. 14.] 
adversary owned cards: [ 8 29 14  3  8 15  3  1  6  8  6  0] -> size -> 12 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 38.072566986083984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ -7.2524366 ]
 [  6.450309  ]
 [-35.854702  ]
 [ -1.2700193 ]
 [-32.93022   ]
 [-67.1629    ]
 [  0.95154357]
 [  2.80349   ]
 [ -5.4537306 ]
 [  7.4110928 ]
 [  1.0687611 ]
 [  5.723734  ]
 [  0.5434532 ]
 [ -9.790875  ]
 [  5.8801975 ]
 [ -5.5642405 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 1.] 
cards in discard: [ 3.  1. 29. 25.  1.  3. 25. 29.  0.  1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1] -> size -> 42 
action values: 0 
buys: 1 
player value: 6 
card supply: [25. 13. 30. 22. 30.  8.  7.  9.  9.  6.  5.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  1.  6. 29.  8.] 
adversary cards in discard: [ 6.  0.  8.  8.  3. 15. 14.] 
adversary owned cards: [ 8 29 14  3  8 15  3  1  6  8  6  0] -> size -> 12 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -5.198585510253906



buy possibilites: [-1] 
expected returns: [[-16.693224]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 1.] 
cards in discard: [ 3.  1. 29. 25.  1.  3. 25. 29.  0.  1. 25.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 13. 30. 22. 30.  8.  7.  9.  9.  6.  4.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  1.  6. 29.  8.] 
adversary cards in discard: [ 6.  0.  8.  8.  3. 15. 14.] 
adversary owned cards: [ 8 29 14  3  8 15  3  1  6  8  6  0] -> size -> 12 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5.    0.    0.  240.    0.    0.   20.    0.    0.    0.    0.  -80.
   0.    0.   62.5   0. ] 
sum of rewards: 237.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 7.41108512878418






Player: 1 
cards in hand: [ 3.  1.  6. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  6. 29.  8.] 
cards in discard: [ 6.  0.  8.  8.  3. 15. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 29 14  3  8 15  3  1  6  8  6  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 13. 30. 22. 30.  8.  7.  9.  9.  6.  4.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [29.  0. 25.  0.  3.] 
adversary cards in discard: [ 3.  1. 29. 25.  1.  3. 25. 29.  0.  1. 25. 29.  1.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25] -> size -> 43 
adversary victory points: 8
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.] 
cards in discard: [ 6.  0.  8.  8.  3. 15. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 29 14  8 15  3  1  8  6  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 13. 30. 22. 30.  8.  7.  9.  9.  6.  4.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [29.  0. 25.  0.  3.] 
adversary cards in discard: [ 3.  1. 29. 25.  1.  3. 25. 29.  0.  1. 25. 29.  1.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25] -> size -> 43 
adversary victory points: 8
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.] 
cards in discard: [ 6.  0.  8.  8.  3. 15. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 29 14  8 15  3  1  8  6  0] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 13. 30. 22. 30.  8.  7.  9.  9.  6.  4.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [29.  0. 25.  0.  3.] 
adversary cards in discard: [ 3.  1. 29. 25.  1.  3. 25. 29.  0.  1. 25. 29.  1.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25] -> size -> 43 
adversary victory points: 8
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.] 
cards in discard: [ 6.  0.  8.  8.  3. 15. 14.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 29 14  8 15  3  1  8  6  0  8] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 13. 30. 22. 30.  8.  7.  9.  9.  5.  4.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [29.  0. 25.  0.  3.] 
adversary cards in discard: [ 3.  1. 29. 25.  1.  3. 25. 29.  0.  1. 25. 29.  1.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25] -> size -> 43 
adversary victory points: 8
player victory points: 0 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [29.  0. 25.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[49.828564]
 [68.5516  ]
 [64.26806 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 25.  0.  3.] 
cards in discard: [ 3.  1. 29. 25.  1.  3. 25. 29.  0.  1. 25. 29.  1.  3.  0.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 13. 30. 22. 30.  8.  7.  9.  9.  5.  4.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  1.  8. 15. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 29 14  8 15  3  1  8  6  0  8] -> size -> 11 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.69322395324707



action possibilites: [-1. 25.] 
expected returns: [[-19.131927 ]
 [ -6.3823204]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.  3.] 
cards in discard: [ 3.  1. 29. 25.  1.  3. 25. 29.  0.  1. 25. 29.  1.  3.  0.  1.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25] -> size -> 43 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 13. 30. 22. 30.  8.  7.  9.  9.  5.  4.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  1.  8. 15. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 29 14  8 15  3  1  8  6  0  8] -> size -> 11 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 62.95010757446289



action possibilites: [-1] 
expected returns: [[35.63523]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 1. 3.] 
cards in discard: [ 3.  1. 29. 25.  1.  3. 25. 29.  0.  1. 25. 29.  1.  3.  0.  1.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 13. 30. 22. 30.  8.  6.  9.  9.  5.  4.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  1.  8. 15. 29.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 8 29 14  8 15  3  1  8  6  0  8  6] -> size -> 12 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -6.382328987121582





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 28.174759]
 [ 43.665924]
 [ 34.909134]
 [ -1.499985]
 [-42.719013]
 [ 37.39068 ]
 [ 39.584755]
 [ 30.392303]
 [ 44.844692]
 [ 37.557297]
 [ 42.88172 ]
 [ 36.943333]
 [ 25.215664]
 [ 43.086437]
 [ 29.80495 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 3.] 
cards in discard: [ 3.  1. 29. 25.  1.  3. 25. 29.  0.  1. 25. 29.  1.  3.  0.  1.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25] -> size -> 43 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 13. 30. 22. 30.  8.  6.  9.  9.  5.  4.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  1.  8. 15. 29.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 8 29 14  8 15  3  1  8  6  0  8  6] -> size -> 12 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1
Learning step: 0
desired expected reward: 35.635231018066406



buy possibilites: [-1] 
expected returns: [[-65.065384]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 3.] 
cards in discard: [ 3.  1. 29. 25.  1.  3. 25. 29.  0.  1. 25. 29.  1.  3.  0.  1.  1. 25.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 13. 30. 22. 30.  8.  6.  9.  9.  5.  3.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  1.  8. 15. 29.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 8 29 14  8 15  3  1  8  6  0  8  6] -> size -> 12 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0 -90   0   0 250   0] 
sum of rewards: 435 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 44.84469223022461






Player: 1 
cards in hand: [ 3.  1.  8. 15. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  8. 15. 29.] 
cards in discard: [6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 29 14  8 15  3  1  8  6  0  8  6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 13. 30. 22. 30.  8.  6.  9.  9.  5.  3.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 1. 25.  3. 29. 29.] 
adversary cards in discard: [ 3.  1. 29. 25.  1.  3. 25. 29.  0.  1. 25. 29.  1.  3.  0.  1.  1. 25.
 29. 25.  0.  0.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25] -> size -> 44 
adversary victory points: 8
player victory points: -1 


action possibilites: [-1.  8. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  8. 15.] 
cards in discard: [ 6. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8 29 14  8 15  3  1  8  6  0  8  6] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 13. 30. 22. 30.  8.  6.  9.  9.  5.  3.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 1. 25.  3. 29. 29.] 
adversary cards in discard: [ 3.  1. 29. 25.  1.  3. 25. 29.  0.  1. 25. 29.  1.  3.  0.  1.  1. 25.
 29. 25.  0.  0.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25] -> size -> 44 
adversary victory points: 8
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  8. 15.] 
cards in discard: [ 6. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8 29 14  8 15  3  1  8  6  0  8  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 13. 30. 22. 30.  8.  6.  9.  9.  5.  3.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 1. 25.  3. 29. 29.] 
adversary cards in discard: [ 3.  1. 29. 25.  1.  3. 25. 29.  0.  1. 25. 29.  1.  3.  0.  1.  1. 25.
 29. 25.  0.  0.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25] -> size -> 44 
adversary victory points: 8
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  8. 15.] 
cards in discard: [ 6. 14.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8 29 14  8 15  3  1  8  6  0  8  6  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 13. 30. 22. 30.  8.  6.  9.  9.  5.  3.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 1. 25.  3. 29. 29.] 
adversary cards in discard: [ 3.  1. 29. 25.  1.  3. 25. 29.  0.  1. 25. 29.  1.  3.  0.  1.  1. 25.
 29. 25.  0.  0.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25] -> size -> 44 
adversary victory points: 8
player victory points: -1 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 1. 25.  3. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 29.] 
expected returns: [[-32.985283]
 [-20.4156  ]
 [-16.257431]
 [-16.257431]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25.  3. 29. 29.] 
cards in discard: [ 3.  1. 29. 25.  1.  3. 25. 29.  0.  1. 25. 29.  1.  3.  0.  1.  1. 25.
 29. 25.  0.  0.  3.  1.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 13. 30. 22. 30.  8.  6.  9.  9.  5.  3.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [8. 8. 8. 6. 0.] 
adversary cards in discard: [ 6. 14.  0. 29.  3.  1.  8. 15.] 
adversary owned cards: [ 8 29 14  8 15  3  1  8  6  0  8  6  0] -> size -> 13 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: -65.06538391113281



action possibilites: [-1. 25. 29.] 
expected returns: [[-33.13547 ]
 [-20.330383]
 [-16.098164]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25. 29.  1.] 
cards in discard: [ 3.  1. 29. 25.  1.  3. 25. 29.  0.  1. 25. 29.  1.  3.  0.  1.  1. 25.
 29. 25.  0.  0.  3.  1.  3.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25] -> size -> 44 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 13. 30. 22. 30.  8.  6.  9.  9.  5.  3.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [8. 8. 8. 6. 0.] 
adversary cards in discard: [ 6. 14.  0. 29.  3.  1.  8. 15.] 
adversary owned cards: [ 8 29 14  8 15  3  1  8  6  0  8  6  0] -> size -> 13 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -21.272573471069336



action possibilites: [-1. 25.] 
expected returns: [[-32.681694]
 [-18.1414  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1. 25.] 
cards in discard: [ 3.  1. 29. 25.  1.  3. 25. 29.  0.  1. 25. 29.  1.  3.  0.  1.  1. 25.
 29. 25.  0.  0.  3.  1.  3.  3. 25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25] -> size -> 44 
action values: 1 
buys: 0 
player value: 2 
card supply: [24. 13. 30. 22. 30.  8.  6.  9.  9.  5.  3.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [8. 8. 8. 6. 0.] 
adversary cards in discard: [ 6. 14.  0. 29.  3.  1.  8. 15.] 
adversary owned cards: [ 8 29 14  8 15  3  1  8  6  0  8  6  0] -> size -> 13 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -21.168476104736328



action possibilites: [-1] 
expected returns: [[-22.277182]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1. 29.  0.] 
cards in discard: [ 3.  1. 29. 25.  1.  3. 25. 29.  0.  1. 25. 29.  1.  3.  0.  1.  1. 25.
 29. 25.  0.  0.  3.  1.  3.  3. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25] -> size -> 44 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 13. 30. 22. 30.  8.  5.  9.  9.  5.  3.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [8. 8. 8. 6. 0.] 
adversary cards in discard: [ 6. 14.  0. 29.  3.  1.  8. 15.  6.] 
adversary owned cards: [ 8 29 14  8 15  3  1  8  6  0  8  6  0  6] -> size -> 14 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -18.141393661499023





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-24.63389 ]
 [-10.50624 ]
 [-54.51912 ]
 [-18.268885]
 [-53.345985]
 [-92.93063 ]
 [-15.961504]
 [-14.203908]
 [-23.216942]
 [ -9.634497]
 [-15.87776 ]
 [-11.271656]
 [-16.384577]
 [-26.907717]
 [-11.142243]
 [-22.277184]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1. 29.  0.] 
cards in discard: [ 3.  1. 29. 25.  1.  3. 25. 29.  0.  1. 25. 29.  1.  3.  0.  1.  1. 25.
 29. 25.  0.  0.  3.  1.  3.  3. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25] -> size -> 44 
action values: 0 
buys: 1 
player value: 7 
card supply: [24. 13. 30. 22. 30.  8.  5.  9.  9.  5.  3.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [8. 8. 8. 6. 0.] 
adversary cards in discard: [ 6. 14.  0. 29.  3.  1.  8. 15.  6.] 
adversary owned cards: [ 8 29 14  8 15  3  1  8  6  0  8  6  0  6] -> size -> 14 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: take_action - action -1
Learning step: 0
desired expected reward: -22.27718162536621



buy possibilites: [-1] 
expected returns: [[-67.07708]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1. 29.  0.] 
cards in discard: [ 3.  1. 29. 25.  1.  3. 25. 29.  0.  1. 25. 29.  1.  3.  0.  1.  1. 25.
 29. 25.  0.  0.  3.  1.  3.  3. 25. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25] -> size -> 45 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 13. 30. 22. 30.  8.  5.  9.  9.  5.  2.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [8. 8. 8. 6. 0.] 
adversary cards in discard: [ 6. 14.  0. 29.  3.  1.  8. 15.  6.] 
adversary owned cards: [ 8 29 14  8 15  3  1  8  6  0  8  6  0  6] -> size -> 14 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[  -5.     0.     0.   270.     0.     0.    60.     0.     0.     0.
    0.  -100.     0.     0.    62.5    0. ] 
sum of rewards: 287.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: -9.634495735168457






Player: 1 
cards in hand: [8. 8. 8. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 8. 6. 0.] 
cards in discard: [ 6. 14.  0. 29.  3.  1.  8. 15.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 29 14  8 15  3  1  8  6  0  8  6  0  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 13. 30. 22. 30.  8.  5.  9.  9.  5.  2.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 1.  1. 29. 29.  0.] 
adversary cards in discard: [ 3.  1. 29. 25.  1.  3. 25. 29.  0.  1. 25. 29.  1.  3.  0.  1.  1. 25.
 29. 25.  0.  0.  3.  1.  3.  3. 25. 25. 29. 29. 25.  1.  1. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25] -> size -> 45 
adversary victory points: 8
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [ 6. 14.  0. 29.  3.  1.  8. 15.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 14  8 15  3  1  8  0  8  6  0  6] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 13. 30. 22. 30.  8.  5.  9.  9.  5.  2.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 1.  1. 29. 29.  0.] 
adversary cards in discard: [ 3.  1. 29. 25.  1.  3. 25. 29.  0.  1. 25. 29.  1.  3.  0.  1.  1. 25.
 29. 25.  0.  0.  3.  1.  3.  3. 25. 25. 29. 29. 25.  1.  1. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25] -> size -> 45 
adversary victory points: 8
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [ 6. 14.  0. 29.  3.  1.  8. 15.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 14  8 15  3  1  8  0  8  6  0  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 13. 30. 22. 30.  8.  5.  9.  9.  5.  2.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 1.  1. 29. 29.  0.] 
adversary cards in discard: [ 3.  1. 29. 25.  1.  3. 25. 29.  0.  1. 25. 29.  1.  3.  0.  1.  1. 25.
 29. 25.  0.  0.  3.  1.  3.  3. 25. 25. 29. 29. 25.  1.  1. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25] -> size -> 45 
adversary victory points: 8
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [ 6. 14.  0. 29.  3.  1.  8. 15.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 14  8 15  3  1  8  0  8  6  0  6  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 13. 30. 22. 30.  8.  5.  9.  9.  5.  2.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 1.  1. 29. 29.  0.] 
adversary cards in discard: [ 3.  1. 29. 25.  1.  3. 25. 29.  0.  1. 25. 29.  1.  3.  0.  1.  1. 25.
 29. 25.  0.  0.  3.  1.  3.  3. 25. 25. 29. 29. 25.  1.  1. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25] -> size -> 45 
adversary victory points: 8
player victory points: -1 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 1.  1. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[-32.33287 ]
 [-14.560816]
 [-14.560816]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1. 29. 29.  0.] 
cards in discard: [ 3.  1. 29. 25.  1.  3. 25. 29.  0.  1. 25. 29.  1.  3.  0.  1.  1. 25.
 29. 25.  0.  0.  3.  1.  3.  3. 25. 25. 29. 29. 25.  1.  1. 29.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 13. 30. 22. 30.  8.  5.  9.  9.  5.  2.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [14.  8. 15.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29 14  8 15  3  1  8  0  8  6  0  6  0] -> size -> 13 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: -67.07707977294922



action possibilites: [-1. 29.] 
expected returns: [[-23.419767 ]
 [ -6.3385153]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  0.  3.] 
cards in discard: [ 3.  1. 29. 25.  1.  3. 25. 29.  0.  1. 25. 29.  1.  3.  0.  1.  1. 25.
 29. 25.  0.  0.  3.  1.  3.  3. 25. 25. 29. 29. 25.  1.  1. 29.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25] -> size -> 45 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 13. 30. 22. 30.  8.  5.  9.  9.  5.  2.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [14.  8. 15.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29 14  8 15  3  1  8  0  8  6  0  6  0] -> size -> 13 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -19.87990951538086



action possibilites: [-1.] 
expected returns: [[-16.431725]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1.] 
cards in discard: [ 3.  1. 29. 25.  1.  3. 25. 29.  0.  1. 25. 29.  1.  3.  0.  1.  1. 25.
 29. 25.  0.  0.  3.  1.  3.  3. 25. 25. 29. 29. 25.  1.  1. 29.  0.  1.
  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25] -> size -> 45 
action values: 1 
buys: 0 
player value: 2 
card supply: [23. 13. 30. 22. 30.  8.  5.  9.  9.  5.  2.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [14.  8. 15.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29 14  8 15  3  1  8  0  8  6  0  6  0] -> size -> 13 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -11.020316123962402





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-17.87763  ]
 [ -4.0944624]
 [-11.988428 ]
 [-41.771614 ]
 [-73.536385 ]
 [ -9.820994 ]
 [ -7.986418 ]
 [-16.305363 ]
 [ -3.1899655]
 [ -9.73723  ]
 [ -4.903633 ]
 [-10.267421 ]
 [-20.248587 ]
 [ -4.7712197]
 [-16.431734 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1.] 
cards in discard: [ 3.  1. 29. 25.  1.  3. 25. 29.  0.  1. 25. 29.  1.  3.  0.  1.  1. 25.
 29. 25.  0.  0.  3.  1.  3.  3. 25. 25. 29. 29. 25.  1.  1. 29.  0.  1.
  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25] -> size -> 45 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 13. 30. 22. 30.  8.  5.  9.  9.  5.  2.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [14.  8. 15.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29 14  8 15  3  1  8  0  8  6  0  6  0] -> size -> 13 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.431724548339844



buy possibilites: [-1] 
expected returns: [[-22.613817]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1.] 
cards in discard: [ 3.  1. 29. 25.  1.  3. 25. 29.  0.  1. 25. 29.  1.  3.  0.  1.  1. 25.
 29. 25.  0.  0.  3.  1.  3.  3. 25. 25. 29. 29. 25.  1.  1. 29.  0.  1.
  1. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 13. 30. 22. 30.  8.  5.  9.  9.  5.  1.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [14.  8. 15.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29 14  8 15  3  1  8  0  8  6  0  6  0] -> size -> 13 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[  -5    0    0  270    0    0   40    0    0    0    0 -110    0    0
  250    0] 
sum of rewards: 445 

action type: buy - action 25.0
Learning step: 0
desired expected reward: -3.1899654865264893






Player: 1 
cards in hand: [14.  8. 15.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 15.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8. 15.  8.  8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [29 14  8 15  3  1  8  0  8  6  0  6  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 13. 30. 22. 30.  8.  5.  9.  9.  5.  1.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [25.  0.  1.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25] -> size -> 46 
adversary victory points: 8
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8 15  3  1  8  0  8  6  0  6  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 13. 30. 22. 30.  8.  5.  9.  9.  5.  1.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [25.  0.  1.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25] -> size -> 46 
adversary victory points: 8
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8.  8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8 15  3  1  8  0  8  6  0  6  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 13. 30. 22. 30.  8.  5.  9.  9.  5.  1.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [25.  0.  1.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25] -> size -> 46 
adversary victory points: 8
player victory points: -1 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [25.  0.  1.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[6.4843388 ]
 [0.21526647]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  1.  3.  0.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 13. 30. 22. 30.  8.  5.  9.  9.  5.  1.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [29.  0.  0.  6.  3.] 
adversary cards in discard: [ 8. 15.  8.  8.] 
adversary owned cards: [29  8 15  3  1  8  0  8  6  0  6  0] -> size -> 12 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: -22.61381721496582





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[ -5.0511527]
 [  8.813202 ]
 [  2.957834 ]
 [-97.42754  ]
 [  7.6540136]
 [  5.746462 ]
 [ -7.6663523]
 [  6.724245 ]
 [  7.0203524]
 [  6.3961926]
 [  9.338264 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  1.  3.  0.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25] -> size -> 46 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 13. 30. 22. 30.  8.  5.  9.  9.  5.  1.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [29.  0.  0.  6.  3.] 
adversary cards in discard: [ 8. 15.  8.  8.] 
adversary owned cards: [29  8 15  3  1  8  0  8  6  0  6  0] -> size -> 12 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 7.162824630737305



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [29.  0.  0.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  6.  3.] 
cards in discard: [ 8. 15.  8.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [29  8 15  3  1  8  0  8  6  0  6  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 13. 30. 22. 30.  8.  5.  9.  9.  5.  1.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [25. 25. 29. 29.  1.] 
adversary cards in discard: [25.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25] -> size -> 46 
adversary victory points: 8
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  6.  3.] 
cards in discard: [ 8. 15.  8.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [29  8 15  3  1  8  0  8  6  0  6  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 13. 30. 22. 30.  8.  5.  9.  9.  5.  1.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [25. 25. 29. 29.  1.] 
adversary cards in discard: [25.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25] -> size -> 46 
adversary victory points: 8
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  6.  3.] 
cards in discard: [ 8. 15.  8.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [29  8 15  3  1  8  0  8  6  0  6  0  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 13. 30. 21. 30.  8.  5.  9.  9.  5.  1.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [25. 25. 29. 29.  1.] 
adversary cards in discard: [25.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25] -> size -> 46 
adversary victory points: 8
player victory points: 0 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [25. 25. 29. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 29. 29.] 
expected returns: [[-38.740067]
 [-31.150518]
 [-31.150518]
 [-27.064552]
 [-27.064552]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25. 29. 29.  1.] 
cards in discard: [25.  0.  1.  3.  0.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 13. 30. 21. 30.  8.  5.  9.  9.  5.  1.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [8. 3. 0. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [29  8 15  3  1  8  0  8  6  0  6  0  3] -> size -> 13 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 9.3382568359375



action possibilites: [-1. 25. 25.] 
expected returns: [[-24.363949]
 [-11.029718]
 [-11.029718]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25.  1.  0.] 
cards in discard: [25.  0.  1.  3.  0. 29.] 
cards in deck: 35 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25] -> size -> 46 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 13. 30. 21. 30.  8.  5.  9.  9.  5.  1.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [8. 3. 0. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [29  8 15  3  1  8  0  8  6  0  6  0  3] -> size -> 13 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -30.579740524291992



action possibilites: [-1] 
expected returns: [[-19.477476]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  0.  1.  0.] 
cards in discard: [25.  0.  1.  3.  0. 29.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25] -> size -> 46 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 13. 30. 21. 30.  8.  4.  9.  9.  5.  1.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [8. 3. 0. 6. 1.] 
adversary cards in discard: [6.] 
adversary owned cards: [29  8 15  3  1  8  0  8  6  0  6  0  3  6] -> size -> 14 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -11.029720306396484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-21.249094 ]
 [ -7.6645784]
 [-48.457577 ]
 [-15.363315 ]
 [-47.095512 ]
 [-86.20336  ]
 [-13.234001 ]
 [-11.483982 ]
 [-19.924458 ]
 [ -6.819872 ]
 [-13.164512 ]
 [ -8.47161  ]
 [-13.673414 ]
 [-23.392124 ]
 [ -8.354055 ]
 [-19.59027  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1.  0.  1.  0.] 
cards in discard: [25.  0.  1.  3.  0. 29.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25] -> size -> 46 
action values: 0 
buys: 1 
player value: 7 
card supply: [23. 13. 30. 21. 30.  8.  4.  9.  9.  5.  1.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [8. 3. 0. 6. 1.] 
adversary cards in discard: [6.] 
adversary owned cards: [29  8 15  3  1  8  0  8  6  0  6  0  3  6] -> size -> 14 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1
Learning step: 0
desired expected reward: -19.477476119995117



buy possibilites: [-1] 
expected returns: [[-8.933978]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1.  0.  1.  0.] 
cards in discard: [25.  0.  1.  3.  0. 29. 25.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25] -> size -> 47 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 13. 30. 21. 30.  8.  4.  9.  9.  5.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [8. 3. 0. 6. 1.] 
adversary cards in discard: [6.] 
adversary owned cards: [29  8 15  3  1  8  0  8  6  0  6  0  3  6] -> size -> 14 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[  -5.     0.     0.   240.     0.     0.    40.     0.     0.     0.
    0.  -120.     0.     0.    62.5    0. ] 
sum of rewards: 217.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: -6.819868087768555






Player: 1 
cards in hand: [8. 3. 0. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 6. 1.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [29  8 15  3  1  8  0  8  6  0  6  0  3  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 13. 30. 21. 30.  8.  4.  9.  9.  5.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [29.  3.  0.  1. 29.] 
adversary cards in discard: [25.  0.  1.  3.  0. 29. 25. 29. 25. 25.  1.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25] -> size -> 47 
adversary victory points: 8
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 1.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8 15  1  8  0  8  6  0  6  0  3  6] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 13. 30. 21. 30.  8.  4.  9.  9.  5.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [29.  3.  0.  1. 29.] 
adversary cards in discard: [25.  0.  1.  3.  0. 29. 25. 29. 25. 25.  1.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25] -> size -> 47 
adversary victory points: 8
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 1.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8 15  1  8  0  8  6  0  6  0  3  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 13. 30. 21. 30.  8.  4.  9.  9.  5.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [29.  3.  0.  1. 29.] 
adversary cards in discard: [25.  0.  1.  3.  0. 29. 25. 29. 25. 25.  1.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25] -> size -> 47 
adversary victory points: 8
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 1.] 
cards in discard: [6. 8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8 15  1  8  0  8  6  0  6  0  3  6  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 13. 30. 21. 30.  8.  4.  9.  9.  4.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [29.  3.  0.  1. 29.] 
adversary cards in discard: [25.  0.  1.  3.  0. 29. 25. 29. 25. 25.  1.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25] -> size -> 47 
adversary victory points: 8
player victory points: -2 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [29.  3.  0.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[-35.61583 ]
 [-19.242605]
 [-19.242605]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  1. 29.] 
cards in discard: [25.  0.  1.  3.  0. 29. 25. 29. 25. 25.  1.  0.  1.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 13. 30. 21. 30.  8.  4.  9.  9.  4.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 15.  3.  8.  8.] 
adversary cards in discard: [6. 8. 8. 0. 6. 1.] 
adversary owned cards: [29  8 15  1  8  0  8  6  0  6  0  3  6  8] -> size -> 14 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: -8.933978080749512



action possibilites: [-1. 29. 25.] 
expected returns: [[-59.87292 ]
 [-63.107292]
 [-61.56947 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 25.] 
cards in discard: [25.  0.  1.  3.  0. 29. 25. 29. 25. 25.  1.  0.  1.  0.  3.  1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25] -> size -> 47 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 13. 30. 21. 30.  8.  4.  9.  9.  4.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 15.  3.  8.  8.] 
adversary cards in discard: [6. 8. 8. 0. 6. 1.] 
adversary owned cards: [29  8 15  1  8  0  8  6  0  6  0  3  6  8] -> size -> 14 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -24.2346134185791





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ -71.09383 ]
 [ -64.47537 ]
 [-118.364426]
 [ -70.713554]
 [ -59.66895 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 25.] 
cards in discard: [25.  0.  1.  3.  0. 29. 25. 29. 25. 25.  1.  0.  1.  0.  3.  1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 13. 30. 21. 30.  8.  4.  9.  9.  4.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 15.  3.  8.  8.] 
adversary cards in discard: [6. 8. 8. 0. 6. 1.] 
adversary owned cards: [29  8 15  1  8  0  8  6  0  6  0  3  6  8] -> size -> 14 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -59.8729362487793






Player: 1 
cards in hand: [ 0. 15.  3.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3.  8.  8.] 
cards in discard: [6. 8. 8. 0. 6. 1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [29  8 15  1  8  0  8  6  0  6  0  3  6  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 13. 30. 21. 30.  8.  4.  9.  9.  4.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 1. 29.  3. 25.  1.] 
adversary cards in discard: [25.  0.  1.  3.  0. 29. 25. 29. 25. 25.  1.  0.  1.  0.  3.  1. 29.  0.
 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25] -> size -> 47 
adversary victory points: 8
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  3.  8.  8.] 
cards in discard: [6. 8. 8. 0. 6. 1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [29  8 15  1  8  0  8  6  0  6  0  3  6  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 13. 30. 21. 30.  8.  4.  9.  9.  4.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 1. 29.  3. 25.  1.] 
adversary cards in discard: [25.  0.  1.  3.  0. 29. 25. 29. 25. 25.  1.  0.  1.  0.  3.  1. 29.  0.
 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25] -> size -> 47 
adversary victory points: 8
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  3.  8.  8.] 
cards in discard: [6. 8. 8. 0. 6. 1. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [29  8 15  1  8  0  8  6  0  6  0  3  6  8  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 13. 30. 21. 30.  8.  4.  9.  9.  4.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 1. 29.  3. 25.  1.] 
adversary cards in discard: [25.  0.  1.  3.  0. 29. 25. 29. 25. 25.  1.  0.  1.  0.  3.  1. 29.  0.
 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25] -> size -> 47 
adversary victory points: 8
player victory points: -2 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [ 1. 29.  3. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[-58.800793]
 [-51.518215]
 [-54.486465]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  3. 25.  1.] 
cards in discard: [25.  0.  1.  3.  0. 29. 25. 29. 25. 25.  1.  0.  1.  0.  3.  1. 29.  0.
 29. 25.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 13. 30. 21. 30.  8.  4.  9.  9.  4.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 8.  6.  0.  6. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29  8 15  1  8  0  8  6  0  6  0  3  6  8  0] -> size -> 15 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -59.66896438598633



action possibilites: [-1. 25.] 
expected returns: [[-77.46517]
 [-80.13449]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  1.] 
cards in discard: [25.  0.  1.  3.  0. 29. 25. 29. 25. 25.  1.  0.  1.  0.  3.  1. 29.  0.
 29. 25.  3.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25] -> size -> 47 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 13. 30. 21. 30.  8.  4.  9.  9.  4.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 8.  6.  0.  6. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29  8 15  1  8  0  8  6  0  6  0  3  6  8  0] -> size -> 15 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -53.68690872192383





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ -93.27794 ]
 [ -78.244644]
 [ -84.49495 ]
 [-151.53062 ]
 [-191.83105 ]
 [ -79.53095 ]
 [ -81.04775 ]
 [ -93.721924]
 [ -80.310356]
 [ -79.427345]
 [ -80.08707 ]
 [ -96.89026 ]
 [ -80.03649 ]
 [ -77.46517 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1.  1.] 
cards in discard: [25.  0.  1.  3.  0. 29. 25. 29. 25. 25.  1.  0.  1.  0.  3.  1. 29.  0.
 29. 25.  3.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25] -> size -> 47 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 13. 30. 21. 30.  8.  4.  9.  9.  4.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 8.  6.  0.  6. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29  8 15  1  8  0  8  6  0  6  0  3  6  8  0] -> size -> 15 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -77.4651870727539






Player: 1 
cards in hand: [ 8.  6.  0.  6. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6.  0.  6. 29.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [29  8 15  1  8  0  8  6  0  6  0  3  6  8  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 13. 30. 21. 30.  8.  4.  9.  9.  4.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3. 25. 29. 25. 25.] 
adversary cards in discard: [25.  0.  1.  3.  0. 29. 25. 29. 25. 25.  1.  0.  1.  0.  3.  1. 29.  0.
 29. 25.  3.  1. 29. 25.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25] -> size -> 47 
adversary victory points: 8
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6.  0.  6. 29.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [29  8 15  1  8  0  8  6  0  6  0  3  6  8  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 13. 30. 21. 30.  8.  4.  9.  9.  4.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3. 25. 29. 25. 25.] 
adversary cards in discard: [25.  0.  1.  3.  0. 29. 25. 29. 25. 25.  1.  0.  1.  0.  3.  1. 29.  0.
 29. 25.  3.  1. 29. 25.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25] -> size -> 47 
adversary victory points: 8
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6.  0.  6. 29.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [29  8 15  1  8  0  8  6  0  6  0  3  6  8  0  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 13. 30. 21. 30.  8.  4.  9.  9.  4.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3. 25. 29. 25. 25.] 
adversary cards in discard: [25.  0.  1.  3.  0. 29. 25. 29. 25. 25.  1.  0.  1.  0.  3.  1. 29.  0.
 29. 25.  3.  1. 29. 25.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25] -> size -> 47 
adversary victory points: 8
player victory points: -2 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [ 3. 25. 29. 25. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25. 25.] 
expected returns: [[-50.253155]
 [-56.026794]
 [-56.1642  ]
 [-56.026794]
 [-56.026794]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 29. 25. 25.] 
cards in discard: [25.  0.  1.  3.  0. 29. 25. 29. 25. 25.  1.  0.  1.  0.  3.  1. 29.  0.
 29. 25.  3.  1. 29. 25.  1.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 13. 30. 21. 30.  8.  4.  9.  9.  4.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [8. 3. 0. 1. 8.] 
adversary cards in discard: [ 0.  8.  6.  0.  6. 29.] 
adversary owned cards: [29  8 15  1  8  0  8  6  0  6  0  3  6  8  0  0] -> size -> 16 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -77.4651870727539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -65.020294]
 [-119.62631 ]
 [ -50.25315 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25. 29. 25. 25.] 
cards in discard: [25.  0.  1.  3.  0. 29. 25. 29. 25. 25.  1.  0.  1.  0.  3.  1. 29.  0.
 29. 25.  3.  1. 29. 25.  1.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25] -> size -> 47 
action values: 1 
buys: 1 
player value: 0 
card supply: [21. 13. 30. 21. 30.  8.  4.  9.  9.  4.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [8. 3. 0. 1. 8.] 
adversary cards in discard: [ 0.  8.  6.  0.  6. 29.] 
adversary owned cards: [29  8 15  1  8  0  8  6  0  6  0  3  6  8  0  0] -> size -> 16 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -50.25313949584961



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8. 3. 0. 1. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 1. 8.] 
cards in discard: [ 0.  8.  6.  0.  6. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [29  8 15  1  8  0  8  6  0  6  0  3  6  8  0  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 13. 30. 21. 30.  8.  4.  9.  9.  4.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 1.  0.  1.  1. 29.] 
adversary cards in discard: [25.  0.  1.  3.  0. 29. 25. 29. 25. 25.  1.  0.  1.  0.  3.  1. 29.  0.
 29. 25.  3.  1. 29. 25.  1.  1.  3. 25. 29. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25] -> size -> 47 
adversary victory points: 8
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [ 0.  8.  6.  0.  6. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8 15  8  8  6  0  6  0  6  8  0  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 13. 30. 21. 30.  8.  4.  9.  9.  4.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 1.  0.  1.  1. 29.] 
adversary cards in discard: [25.  0.  1.  3.  0. 29. 25. 29. 25. 25.  1.  0.  1.  0.  3.  1. 29.  0.
 29. 25.  3.  1. 29. 25.  1.  1.  3. 25. 29. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25] -> size -> 47 
adversary victory points: 8
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [ 0.  8.  6.  0.  6. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8 15  8  8  6  0  6  0  6  8  0  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 13. 30. 21. 30.  8.  4.  9.  9.  4.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 1.  0.  1.  1. 29.] 
adversary cards in discard: [25.  0.  1.  3.  0. 29. 25. 29. 25. 25.  1.  0.  1.  0.  3.  1. 29.  0.
 29. 25.  3.  1. 29. 25.  1.  1.  3. 25. 29. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25] -> size -> 47 
adversary victory points: 8
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [ 0.  8.  6.  0.  6. 29.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8 15  8  8  6  0  6  0  6  8  0  0  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 13. 30. 21. 30.  8.  4.  9.  9.  4.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 1.  0.  1.  1. 29.] 
adversary cards in discard: [25.  0.  1.  3.  0. 29. 25. 29. 25. 25.  1.  0.  1.  0.  3.  1. 29.  0.
 29. 25.  3.  1. 29. 25.  1.  1.  3. 25. 29. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25] -> size -> 47 
adversary victory points: 8
player victory points: -3 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [ 1.  0.  1.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-32.472343]
 [-17.346478]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  1.  1. 29.] 
cards in discard: [25.  0.  1.  3.  0. 29. 25. 29. 25. 25.  1.  0.  1.  0.  3.  1. 29.  0.
 29. 25.  3.  1. 29. 25.  1.  1.  3. 25. 29. 25. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 13. 30. 21. 30.  8.  4.  9.  9.  4.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [15.  0.  6.  0.  8.] 
adversary cards in discard: [ 0.  8.  6.  0.  6. 29.  0.  8.  8.] 
adversary owned cards: [29  8 15  8  8  6  0  6  0  6  8  0  0  0] -> size -> 14 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -50.25313949584961



action possibilites: [-1.] 
expected returns: [[-31.280725]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 1.] 
cards in discard: [25.  0.  1.  3.  0. 29. 25. 29. 25. 25.  1.  0.  1.  0.  3.  1. 29.  0.
 29. 25.  3.  1. 29. 25.  1.  1.  3. 25. 29. 25. 25.  0. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25] -> size -> 47 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 13. 30. 21. 30.  8.  4.  9.  9.  4.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [15.  0.  6.  0.  8.] 
adversary cards in discard: [ 0.  8.  6.  0.  6. 29.  0.  8.  8.] 
adversary owned cards: [29  8 15  8  8  6  0  6  0  6  8  0  0  0] -> size -> 14 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -20.651382446289062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-33.02178 ]
 [-19.50527 ]
 [-60.35941 ]
 [-27.190039]
 [-59.545277]
 [-89.09145 ]
 [-25.051073]
 [-23.36717 ]
 [-31.768913]
 [-25.007748]
 [-20.340668]
 [-25.504547]
 [-35.15634 ]
 [-20.242537]
 [-31.280724]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 1.] 
cards in discard: [25.  0.  1.  3.  0. 29. 25. 29. 25. 25.  1.  0.  1.  0.  3.  1. 29.  0.
 29. 25.  3.  1. 29. 25.  1.  1.  3. 25. 29. 25. 25.  0. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25] -> size -> 47 
action values: 0 
buys: 1 
player value: 7 
card supply: [20. 13. 30. 21. 30.  8.  4.  9.  9.  4.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [15.  0.  6.  0.  8.] 
adversary cards in discard: [ 0.  8.  6.  0.  6. 29.  0.  8.  8.] 
adversary owned cards: [29  8 15  8  8  6  0  6  0  6  8  0  0  0] -> size -> 14 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -31.280725479125977



buy possibilites: [-1] 
expected returns: [[-15.966137]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 1.] 
cards in discard: [25.  0.  1.  3.  0. 29. 25. 29. 25. 25.  1.  0.  1.  0.  3.  1. 29.  0.
 29. 25.  3.  1. 29. 25.  1.  1.  3. 25. 29. 25. 25.  0. 29.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1] -> size -> 48 
action values: 0 
buys: 0 
player value: 4 
card supply: [20. 12. 30. 21. 30.  8.  4.  9.  9.  4.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [15.  0.  6.  0.  8.] 
adversary cards in discard: [ 0.  8.  6.  0.  6. 29.  0.  8.  8.] 
adversary owned cards: [29  8 15  8  8  6  0  6  0  6  8  0  0  0] -> size -> 14 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[  -5.     0.     0.   330.     0.     0.    20.     0.     0.     0.
    0.  -130.     0.     0.    13.5    0. ] 
sum of rewards: 228.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -19.505266189575195






Player: 1 
cards in hand: [15.  0.  6.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  6.  0.  8.] 
cards in discard: [ 0.  8.  6.  0.  6. 29.  0.  8.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29  8 15  8  8  6  0  6  0  6  8  0  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 12. 30. 21. 30.  8.  4.  9.  9.  4.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  3.  1.  1. 29.] 
adversary cards in discard: [25.  0.  1.  3.  0. 29. 25. 29. 25. 25.  1.  0.  1.  0.  3.  1. 29.  0.
 29. 25.  3.  1. 29. 25.  1.  1.  3. 25. 29. 25. 25.  0. 29.  1. 29.  1.
  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1] -> size -> 48 
adversary victory points: 8
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.] 
cards in discard: [ 0.  8.  6.  0.  6. 29.  0.  8.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8 15  8  8  6  0  6  8  0  0  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 12. 30. 21. 30.  8.  4.  9.  9.  4.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  3.  1.  1. 29.] 
adversary cards in discard: [25.  0.  1.  3.  0. 29. 25. 29. 25. 25.  1.  0.  1.  0.  3.  1. 29.  0.
 29. 25.  3.  1. 29. 25.  1.  1.  3. 25. 29. 25. 25.  0. 29.  1. 29.  1.
  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1] -> size -> 48 
adversary victory points: 8
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.] 
cards in discard: [ 0.  8.  6.  0.  6. 29.  0.  8.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8 15  8  8  6  0  6  8  0  0  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 12. 30. 21. 30.  8.  4.  9.  9.  4.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  3.  1.  1. 29.] 
adversary cards in discard: [25.  0.  1.  3.  0. 29. 25. 29. 25. 25.  1.  0.  1.  0.  3.  1. 29.  0.
 29. 25.  3.  1. 29. 25.  1.  1.  3. 25. 29. 25. 25.  0. 29.  1. 29.  1.
  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1] -> size -> 48 
adversary victory points: 8
player victory points: -2 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  1.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-29.398266]
 [-12.82747 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  1.  1. 29.] 
cards in discard: [25.  0.  1.  3.  0. 29. 25. 29. 25. 25.  1.  0.  1.  0.  3.  1. 29.  0.
 29. 25.  3.  1. 29. 25.  1.  1.  3. 25. 29. 25. 25.  0. 29.  1. 29.  1.
  1.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 12. 30. 21. 30.  8.  4.  9.  9.  4.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [0. 8. 8. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [29  8 15  8  8  6  0  6  8  0  0  0] -> size -> 12 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: -15.966136932373047



action possibilites: [-1.] 
expected returns: [[-30.412392]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3.] 
cards in discard: [25.  0.  1.  3.  0. 29. 25. 29. 25. 25.  1.  0.  1.  0.  3.  1. 29.  0.
 29. 25.  3.  1. 29. 25.  1.  1.  3. 25. 29. 25. 25.  0. 29.  1. 29.  1.
  1.  1.  1.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1] -> size -> 48 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 12. 30. 21. 30.  8.  4.  9.  9.  4.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [0. 8. 8. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [29  8 15  8  8  6  0  6  8  0  0  0] -> size -> 12 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -17.473960876464844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -38.704403]
 [-104.67133 ]
 [ -30.412395]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3.] 
cards in discard: [25.  0.  1.  3.  0. 29. 25. 29. 25. 25.  1.  0.  1.  0.  3.  1. 29.  0.
 29. 25.  3.  1. 29. 25.  1.  1.  3. 25. 29. 25. 25.  0. 29.  1. 29.  1.
  1.  1.  1.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1] -> size -> 48 
action values: 1 
buys: 1 
player value: 1 
card supply: [20. 12. 30. 21. 30.  8.  4.  9.  9.  4.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [0. 8. 8. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [29  8 15  8  8  6  0  6  8  0  0  0] -> size -> 12 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -30.412391662597656






Player: 1 
cards in hand: [0. 8. 8. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 6. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [29  8 15  8  8  6  0  6  8  0  0  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 12. 30. 21. 30.  8.  4.  9.  9.  4.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  1. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1] -> size -> 48 
adversary victory points: 8
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8. 6. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [29  8 15  8  8  6  0  6  8  0  0  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 12. 30. 21. 30.  8.  4.  9.  9.  4.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  1. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1] -> size -> 48 
adversary victory points: 8
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8. 6. 0.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [29  8 15  8  8  6  0  6  8  0  0  0  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 12. 30. 21. 30.  8.  4.  9.  9.  3.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  1. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1] -> size -> 48 
adversary victory points: 8
player victory points: -2 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [ 0.  1. 25.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[-5.6384683]
 [ 3.2315962]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 25.  3.  0.] 
cards in discard: [] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 12. 30. 21. 30.  8.  4.  9.  9.  3.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [29.  6.  0. 15.  8.] 
adversary cards in discard: [8. 0. 8. 8. 6. 0.] 
adversary owned cards: [29  8 15  8  8  6  0  6  8  0  0  0  8] -> size -> 13 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -30.412391662597656



action possibilites: [-1] 
expected returns: [[-11.347069]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 12. 30. 21. 30.  8.  3.  9.  9.  3.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [29.  6.  0. 15.  8.] 
adversary cards in discard: [8. 0. 8. 8. 6. 0. 6.] 
adversary owned cards: [29  8 15  8  8  6  0  6  8  0  0  0  8  6] -> size -> 14 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 3.231558084487915





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-11.39995  ]
 [  2.760311 ]
 [ -5.3910346]
 [-35.626175 ]
 [-71.04464  ]
 [ -3.2067404]
 [ -1.2577906]
 [ -9.720016 ]
 [ -3.0995796]
 [  1.9299028]
 [ -3.66478  ]
 [-13.8431425]
 [  2.0717208]
 [-10.221388 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1] -> size -> 48 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 12. 30. 21. 30.  8.  3.  9.  9.  3.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [29.  6.  0. 15.  8.] 
adversary cards in discard: [8. 0. 8. 8. 6. 0. 6.] 
adversary owned cards: [29  8 15  8  8  6  0  6  8  0  0  0  8  6] -> size -> 14 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: -11.347068786621094



buy possibilites: [-1] 
expected returns: [[16.709164]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3.  0. 29.  0.] 
cards in discard: [1.] 
cards in deck: 41 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1] -> size -> 49 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 11. 30. 21. 30.  8.  3.  9.  9.  3.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [29.  6.  0. 15.  8.] 
adversary cards in discard: [8. 0. 8. 8. 6. 0. 6.] 
adversary owned cards: [29  8 15  8  8  6  0  6  8  0  0  0  8  6] -> size -> 14 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[  -5.     0.     0.   300.     0.     0.    20.     0.     0.     0.
    0.  -140.     0.     0.    13.5    0. ] 
sum of rewards: 188.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 2.7603037357330322






Player: 1 
cards in hand: [29.  6.  0. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6.  0. 15.  8.] 
cards in discard: [8. 0. 8. 8. 6. 0. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [29  8 15  8  8  6  0  6  8  0  0  0  8  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 11. 30. 21. 30.  8.  3.  9.  9.  3.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 1.  0. 25.  3. 25.] 
adversary cards in discard: [ 1. 25.  0.  1.  3.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1] -> size -> 49 
adversary victory points: 8
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6.  0. 15.  8.] 
cards in discard: [8. 0. 8. 8. 6. 0. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [29  8 15  8  8  6  0  6  8  0  0  0  8  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 11. 30. 21. 30.  8.  3.  9.  9.  3.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 1.  0. 25.  3. 25.] 
adversary cards in discard: [ 1. 25.  0.  1.  3.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1] -> size -> 49 
adversary victory points: 8
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6.  0. 15.  8.] 
cards in discard: [8. 0. 8. 8. 6. 0. 6. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [29  8 15  8  8  6  0  6  8  0  0  0  8  6  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 11. 30. 21. 30.  8.  3.  9.  9.  3.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 1.  0. 25.  3. 25.] 
adversary cards in discard: [ 1. 25.  0.  1.  3.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1] -> size -> 49 
adversary victory points: 8
player victory points: -3 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [ 1.  0. 25.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[-77.6612 ]
 [-86.54525]
 [-86.54525]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 25.  3. 25.] 
cards in discard: [ 1. 25.  0.  1.  3.  0. 29.  0.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 11. 30. 21. 30.  8.  3.  9.  9.  3.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [8. 6. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [29  8 15  8  8  6  0  6  8  0  0  0  8  6  0] -> size -> 15 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 16.709163665771484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ -94.06563]
 [ -82.51021]
 [ -87.72376]
 [-160.93327]
 [ -86.26987]
 [ -96.78245]
 [ -83.7872 ]
 [ -77.07789]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 25.  3. 25.] 
cards in discard: [ 1. 25.  0.  1.  3.  0. 29.  0.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1] -> size -> 49 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 11. 30. 21. 30.  8.  3.  9.  9.  3.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [8. 6. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [29  8 15  8  8  6  0  6  8  0  0  0  8  6  0] -> size -> 15 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -77.66120147705078



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8. 6. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [29  8 15  8  8  6  0  6  8  0  0  0  8  6  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 11. 30. 21. 30.  8.  3.  9.  9.  3.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [25. 29.  3.  0.  1.] 
adversary cards in discard: [ 1. 25.  0.  1.  3.  0. 29.  0.  1.  0. 25.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1] -> size -> 49 
adversary victory points: 8
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 15  8  8  6  6  8  0  0  0  8  6  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 11. 30. 21. 30.  8.  3.  9.  9.  3.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [25. 29.  3.  0.  1.] 
adversary cards in discard: [ 1. 25.  0.  1.  3.  0. 29.  0.  1.  0. 25.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1] -> size -> 49 
adversary victory points: 8
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 15  8  8  6  6  8  0  0  0  8  6  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 11. 30. 21. 30.  8.  3.  9.  9.  3.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [25. 29.  3.  0.  1.] 
adversary cards in discard: [ 1. 25.  0.  1.  3.  0. 29.  0.  1.  0. 25.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1] -> size -> 49 
adversary victory points: 8
player victory points: -3 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [25. 29.  3.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[-27.400448]
 [-13.142322]
 [ -8.630576]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29.  3.  0.  1.] 
cards in discard: [ 1. 25.  0.  1.  3.  0. 29.  0.  1.  0. 25.  3. 25.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 11. 30. 21. 30.  8.  3.  9.  9.  3.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  6.  8. 29.  0.] 
adversary cards in discard: [8. 6. 0.] 
adversary owned cards: [29 15  8  8  6  6  8  0  0  0  8  6  0] -> size -> 13 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -77.07786560058594



action possibilites: [-1. 25.] 
expected returns: [[-64.97775 ]
 [-55.780922]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 25.] 
cards in discard: [ 1. 25.  0.  1.  3.  0. 29.  0.  1.  0. 25.  3. 25. 25.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1] -> size -> 49 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 11. 30. 21. 30.  8.  3.  9.  9.  3.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  6.  8. 29.  0.] 
adversary cards in discard: [8. 6. 0.] 
adversary owned cards: [29 15  8  8  6  6  8  0  0  0  8  6  0] -> size -> 13 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -14.285226821899414



action possibilites: [-1] 
expected returns: [[-25.275719]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  3. 29.] 
cards in discard: [ 1. 25.  0.  1.  3.  0. 29.  0.  1.  0. 25.  3. 25. 25.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1] -> size -> 49 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 11. 30. 21. 30.  8.  2.  9.  9.  3.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  6.  8. 29.  0.] 
adversary cards in discard: [8. 6. 0. 6.] 
adversary owned cards: [29 15  8  8  6  6  8  0  0  0  8  6  0  6] -> size -> 14 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 365 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -55.78092956542969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ -28.378979]
 [ -14.850357]
 [ -22.29949 ]
 [-100.46613 ]
 [ -18.252855]
 [ -26.945904]
 [ -20.486933]
 [ -26.541767]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  3. 29.] 
cards in discard: [ 1. 25.  0.  1.  3.  0. 29.  0.  1.  0. 25.  3. 25. 25.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1] -> size -> 49 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 11. 30. 21. 30.  8.  2.  9.  9.  3.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  6.  8. 29.  0.] 
adversary cards in discard: [8. 6. 0. 6.] 
adversary owned cards: [29 15  8  8  6  6  8  0  0  0  8  6  0  6] -> size -> 14 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 365 

action type: take_action - action -1
Learning step: 0
desired expected reward: -25.275718688964844



buy possibilites: [-1] 
expected returns: [[-77.20757]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  3. 29.] 
cards in discard: [ 1. 25.  0.  1.  3.  0. 29.  0.  1.  0. 25.  3. 25. 25.  0.  1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 10. 30. 21. 30.  8.  2.  9.  9.  3.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  6.  8. 29.  0.] 
adversary cards in discard: [8. 6. 0. 6.] 
adversary owned cards: [29 15  8  8  6  6  8  0  0  0  8  6  0  6] -> size -> 14 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[  -5    0    0  330    0    0   40    0    0    0    0 -150    0    0
   54    0] 
sum of rewards: 269 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -14.850369453430176






Player: 1 
cards in hand: [ 0.  6.  8. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  8. 29.  0.] 
cards in discard: [8. 6. 0. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  8  8  6  6  8  0  0  0  8  6  0  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 10. 30. 21. 30.  8.  2.  9.  9.  3.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  3.  1. 25.  1.] 
adversary cards in discard: [ 1. 25.  0.  1.  3.  0. 29.  0.  1.  0. 25.  3. 25. 25.  0.  1. 29. 25.
  3.  1.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1] -> size -> 50 
adversary victory points: 8
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29.] 
cards in discard: [8. 6. 0. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 15  8  8  6  6  8  0  8  6  0  6] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 10. 30. 21. 30.  8.  2.  9.  9.  3.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  3.  1. 25.  1.] 
adversary cards in discard: [ 1. 25.  0.  1.  3.  0. 29.  0.  1.  0. 25.  3. 25. 25.  0.  1. 29. 25.
  3.  1.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1] -> size -> 50 
adversary victory points: 8
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 29.] 
cards in discard: [8. 6. 0. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 15  8  8  6  6  8  0  8  6  0  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 10. 30. 21. 30.  8.  2.  9.  9.  3.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  3.  1. 25.  1.] 
adversary cards in discard: [ 1. 25.  0.  1.  3.  0. 29.  0.  1.  0. 25.  3. 25. 25.  0.  1. 29. 25.
  3.  1.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1] -> size -> 50 
adversary victory points: 8
player victory points: -4 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  1. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[-18.190844]
 [ -4.871748]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  1. 25.  1.] 
cards in discard: [ 1. 25.  0.  1.  3.  0. 29.  0.  1.  0. 25.  3. 25. 25.  0.  1. 29. 25.
  3.  1.  3. 29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 10. 30. 21. 30.  8.  2.  9.  9.  3.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 6.  0. 15.  8.  8.] 
adversary cards in discard: [ 8.  6.  0.  6.  8.  6. 29.] 
adversary owned cards: [29 15  8  8  6  6  8  0  8  6  0  6] -> size -> 12 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1
Learning step: 0
desired expected reward: -77.20757293701172



action possibilites: [-1] 
expected returns: [[-58.220005]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  1.  1.  1. 25.] 
cards in discard: [ 1. 25.  0.  1.  3.  0. 29.  0.  1.  0. 25.  3. 25. 25.  0.  1. 29. 25.
  3.  1.  3. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 10. 30. 21. 30.  8.  1.  9.  9.  3.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 6.  0. 15.  8.  8.] 
adversary cards in discard: [ 8.  6.  0.  6.  8.  6. 29.  6.] 
adversary owned cards: [29 15  8  8  6  6  8  0  8  6  0  6  6] -> size -> 13 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -4.871737480163574





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ -65.60756 ]
 [ -47.749996]
 [-110.7289  ]
 [ -57.7981  ]
 [-109.78976 ]
 [-136.15717 ]
 [ -53.479816]
 [ -52.511326]
 [ -62.91076 ]
 [ -53.74918 ]
 [ -49.043503]
 [ -54.124035]
 [ -70.85071 ]
 [ -49.192375]
 [ -58.219967]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  1.  1.  1. 25.] 
cards in discard: [ 1. 25.  0.  1.  3.  0. 29.  0.  1.  0. 25.  3. 25. 25.  0.  1. 29. 25.
  3.  1.  3. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1] -> size -> 50 
action values: 0 
buys: 1 
player value: 6 
card supply: [19. 10. 30. 21. 30.  8.  1.  9.  9.  3.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 6.  0. 15.  8.  8.] 
adversary cards in discard: [ 8.  6.  0.  6.  8.  6. 29.  6.] 
adversary owned cards: [29 15  8  8  6  6  8  0  8  6  0  6  6] -> size -> 13 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action -1
Learning step: 0
desired expected reward: -58.22000503540039



buy possibilites: [-1] 
expected returns: [[-106.526695]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  1.  1.  1. 25.] 
cards in discard: [ 1. 25.  0.  1.  3.  0. 29.  0.  1.  0. 25.  3. 25. 25.  0.  1. 29. 25.
  3.  1.  3. 29.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1] -> size -> 51 
action values: 0 
buys: 0 
player value: 3 
card supply: [19.  9. 30. 21. 30.  8.  1.  9.  9.  3.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 6.  0. 15.  8.  8.] 
adversary cards in discard: [ 8.  6.  0.  6.  8.  6. 29.  6.] 
adversary owned cards: [29 15  8  8  6  6  8  0  8  6  0  6  6] -> size -> 13 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[  -5.     0.     0.   360.     0.     0.    20.     0.     0.     0.
    0.  -160.     0.     0.    13.5    0. ] 
sum of rewards: 228.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -47.75000762939453






Player: 1 
cards in hand: [ 6.  0. 15.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 15.  8.  8.] 
cards in discard: [ 8.  6.  0.  6.  8.  6. 29.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  8  8  6  6  8  0  8  6  0  6  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [19.  9. 30. 21. 30.  8.  1.  9.  9.  3.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  1.  1.  1. 25.] 
adversary cards in discard: [ 1. 25.  0.  1.  3.  0. 29.  0.  1.  0. 25.  3. 25. 25.  0.  1. 29. 25.
  3.  1.  3. 29.  1. 25.  3.  3.  1.  1.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1] -> size -> 51 
adversary victory points: 8
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 8.] 
cards in discard: [ 8.  6.  0.  6.  8.  6. 29.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [29 15  8  8  6  6  8  8  6  0  6  6] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [19.  9. 30. 21. 30.  8.  1.  9.  9.  3.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  1.  1.  1. 25.] 
adversary cards in discard: [ 1. 25.  0.  1.  3.  0. 29.  0.  1.  0. 25.  3. 25. 25.  0.  1. 29. 25.
  3.  1.  3. 29.  1. 25.  3.  3.  1.  1.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1] -> size -> 51 
adversary victory points: 8
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 8.] 
cards in discard: [ 8.  6.  0.  6.  8.  6. 29.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [29 15  8  8  6  6  8  8  6  0  6  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [19.  9. 30. 21. 30.  8.  1.  9.  9.  3.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  1.  1.  1. 25.] 
adversary cards in discard: [ 1. 25.  0.  1.  3.  0. 29.  0.  1.  0. 25.  3. 25. 25.  0.  1. 29. 25.
  3.  1.  3. 29.  1. 25.  3.  3.  1.  1.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1] -> size -> 51 
adversary victory points: 8
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 8.] 
cards in discard: [ 8.  6.  0.  6.  8.  6. 29.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [29 15  8  8  6  6  8  8  6  0  6  6  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [18.  9. 30. 21. 30.  8.  1.  9.  9.  3.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  1.  1.  1. 25.] 
adversary cards in discard: [ 1. 25.  0.  1.  3.  0. 29.  0.  1.  0. 25.  3. 25. 25.  0.  1. 29. 25.
  3.  1.  3. 29.  1. 25.  3.  3.  1.  1.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1] -> size -> 51 
adversary victory points: 8
player victory points: -5 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [ 3.  1.  1.  1. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[ -7.1526127]
 [-14.336126 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  1.  1. 25.] 
cards in discard: [ 1. 25.  0.  1.  3.  0. 29.  0.  1.  0. 25.  3. 25. 25.  0.  1. 29. 25.
  3.  1.  3. 29.  1. 25.  3.  3.  1.  1.  1. 25.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [18.  9. 30. 21. 30.  8.  1.  9.  9.  3.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [29.  8.  0.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29 15  8  8  6  6  8  8  6  0  6  6  0] -> size -> 13 
adversary victory points: -5
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1
Learning step: 0
desired expected reward: -106.52669525146484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ -23.523375 ]
 [ -10.9793825]
 [ -61.094566 ]
 [ -16.785074 ]
 [ -63.104076 ]
 [-108.6641   ]
 [ -11.71644  ]
 [ -14.881235 ]
 [ -25.681847 ]
 [ -13.090754 ]
 [ -12.981246 ]
 [ -12.571212 ]
 [ -27.057026 ]
 [ -14.067717 ]
 [  -7.1526127]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  1.  1. 25.] 
cards in discard: [ 1. 25.  0.  1.  3.  0. 29.  0.  1.  0. 25.  3. 25. 25.  0.  1. 29. 25.
  3.  1.  3. 29.  1. 25.  3.  3.  1.  1.  1. 25.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1] -> size -> 51 
action values: 0 
buys: 1 
player value: 6 
card supply: [18.  9. 30. 21. 30.  8.  1.  9.  9.  3.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [29.  8.  0.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29 15  8  8  6  6  8  8  6  0  6  6  0] -> size -> 13 
adversary victory points: -5
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -7.152612686157227



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [29.  8.  0.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  0.  6.  8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  8  8  6  6  8  8  6  0  6  6  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [18.  9. 30. 21. 30.  8.  1.  9.  9.  3.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 29.  1.  3. 29.] 
adversary cards in discard: [ 1. 25.  0.  1.  3.  0. 29.  0.  1.  0. 25.  3. 25. 25.  0.  1. 29. 25.
  3.  1.  3. 29.  1. 25.  3.  3.  1.  1.  1. 25.  3.  1.  1.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1] -> size -> 51 
adversary victory points: 8
player victory points: -5 


action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8.] 
cards in discard: [6. 8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 15  8  8  6  6  8  8  6  0  6  6  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [18.  9. 30. 21. 30.  8.  1.  9.  9.  3.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 29.  1.  3. 29.] 
adversary cards in discard: [ 1. 25.  0.  1.  3.  0. 29.  0.  1.  0. 25.  3. 25. 25.  0.  1. 29. 25.
  3.  1.  3. 29.  1. 25.  3.  3.  1.  1.  1. 25.  3.  1.  1.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1] -> size -> 51 
adversary victory points: 8
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8.] 
cards in discard: [6. 8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 15  8  8  6  6  8  8  6  0  6  6  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [18.  9. 30. 21. 30.  8.  1.  9.  9.  3.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 29.  1.  3. 29.] 
adversary cards in discard: [ 1. 25.  0.  1.  3.  0. 29.  0.  1.  0. 25.  3. 25. 25.  0.  1. 29. 25.
  3.  1.  3. 29.  1. 25.  3.  3.  1.  1.  1. 25.  3.  1.  1.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1] -> size -> 51 
adversary victory points: 8
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8.] 
cards in discard: [6. 8. 8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 15  8  8  6  6  8  8  6  0  6  6  0  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [18.  9. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 29.  1.  3. 29.] 
adversary cards in discard: [ 1. 25.  0.  1.  3.  0. 29.  0.  1.  0. 25.  3. 25. 25.  0.  1. 29. 25.
  3.  1.  3. 29.  1. 25.  3.  3.  1.  1.  1. 25.  3.  1.  1.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1] -> size -> 51 
adversary victory points: 8
player victory points: -5 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  1.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[-9.61069  ]
 [ 7.8020515]
 [ 7.8020515]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  1.  3. 29.] 
cards in discard: [ 1. 25.  0.  1.  3.  0. 29.  0.  1.  0. 25.  3. 25. 25.  0.  1. 29. 25.
  3.  1.  3. 29.  1. 25.  3.  3.  1.  1.  1. 25.  3.  1.  1.  1. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [18.  9. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [6. 6. 0. 8. 6.] 
adversary cards in discard: [ 6.  8.  8. 29.  0.  8.  8.] 
adversary owned cards: [29 15  8  8  6  6  8  8  6  0  6  6  0  8] -> size -> 14 
adversary victory points: -5
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -7.152612686157227



action possibilites: [-1. 29.] 
expected returns: [[-40.905933]
 [-24.111343]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 29.] 
cards in discard: [ 1. 25.  0.  1.  3.  0. 29.  0.  1.  0. 25.  3. 25. 25.  0.  1. 29. 25.
  3.  1.  3. 29.  1. 25.  3.  3.  1.  1.  1. 25.  3.  1.  1.  1. 25.  0.
 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1] -> size -> 51 
action values: 1 
buys: 0 
player value: 1 
card supply: [18.  9. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [6. 6. 0. 8. 6.] 
adversary cards in discard: [ 6.  8.  8. 29.  0.  8.  8.] 
adversary owned cards: [29 15  8  8  6  6  8  8  6  0  6  6  0  8] -> size -> 14 
adversary victory points: -5
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 2.5525119304656982



action possibilites: [-1.] 
expected returns: [[-56.173603]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 1. 25.  0.  1.  3.  0. 29.  0.  1.  0. 25.  3. 25. 25.  0.  1. 29. 25.
  3.  1.  3. 29.  1. 25.  3.  3.  1.  1.  1. 25.  3.  1.  1.  1. 25.  0.
 29.  1.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1] -> size -> 51 
action values: 1 
buys: 0 
player value: 2 
card supply: [18.  9. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [6. 6. 0. 8. 6.] 
adversary cards in discard: [ 6.  8.  8. 29.  0.  8.  8.] 
adversary owned cards: [29 15  8  8  6  6  8  8  6  0  6  6  0  8] -> size -> 14 
adversary victory points: -5
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 390   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 425 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -28.809932708740234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ -61.057957]
 [ -56.22199 ]
 [-101.73125 ]
 [ -59.541874]
 [ -56.17361 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 1. 25.  0.  1.  3.  0. 29.  0.  1.  0. 25.  3. 25. 25.  0.  1. 29. 25.
  3.  1.  3. 29.  1. 25.  3.  3.  1.  1.  1. 25.  3.  1.  1.  1. 25.  0.
 29.  1.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1] -> size -> 51 
action values: 1 
buys: 1 
player value: 2 
card supply: [18.  9. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [6. 6. 0. 8. 6.] 
adversary cards in discard: [ 6.  8.  8. 29.  0.  8.  8.] 
adversary owned cards: [29 15  8  8  6  6  8  8  6  0  6  6  0  8] -> size -> 14 
adversary victory points: -5
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 390   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 425 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -56.17360305786133






Player: 1 
cards in hand: [6. 6. 0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 8. 6.] 
cards in discard: [ 6.  8.  8. 29.  0.  8.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  8  8  6  6  8  8  6  0  6  6  0  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [18.  9. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [25. 29.  1. 29.  0.] 
adversary cards in discard: [ 1. 25.  0.  1.  3.  0. 29.  0.  1.  0. 25.  3. 25. 25.  0.  1. 29. 25.
  3.  1.  3. 29.  1. 25.  3.  3.  1.  1.  1. 25.  3.  1.  1.  1. 25.  0.
 29.  1.  1. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1] -> size -> 51 
adversary victory points: 8
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 6.  8.  8. 29.  0.  8.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 15  8  8  8  8  0  6  6  0  8] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [18.  9. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [25. 29.  1. 29.  0.] 
adversary cards in discard: [ 1. 25.  0.  1.  3.  0. 29.  0.  1.  0. 25.  3. 25. 25.  0.  1. 29. 25.
  3.  1.  3. 29.  1. 25.  3.  3.  1.  1.  1. 25.  3.  1.  1.  1. 25.  0.
 29.  1.  1. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1] -> size -> 51 
adversary victory points: 8
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 6.  8.  8. 29.  0.  8.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 15  8  8  8  8  0  6  6  0  8] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [18.  9. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [25. 29.  1. 29.  0.] 
adversary cards in discard: [ 1. 25.  0.  1.  3.  0. 29.  0.  1.  0. 25.  3. 25. 25.  0.  1. 29. 25.
  3.  1.  3. 29.  1. 25.  3.  3.  1.  1.  1. 25.  3.  1.  1.  1. 25.  0.
 29.  1.  1. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1] -> size -> 51 
adversary victory points: 8
player victory points: -2 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [25. 29.  1. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 29.] 
expected returns: [[-73.03744 ]
 [-75.52732 ]
 [-75.188774]
 [-75.188774]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29.  1. 29.  0.] 
cards in discard: [ 1. 25.  0.  1.  3.  0. 29.  0.  1.  0. 25.  3. 25. 25.  0.  1. 29. 25.
  3.  1.  3. 29.  1. 25.  3.  3.  1.  1.  1. 25.  3.  1.  1.  1. 25.  0.
 29.  1.  1. 29. 29.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [18.  9. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  8.  8.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [29 15  8  8  8  8  0  6  6  0  8] -> size -> 11 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -56.17360305786133





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ -86.70538 ]
 [ -73.42115 ]
 [ -79.525925]
 [-136.62135 ]
 [ -76.6146  ]
 [ -87.30885 ]
 [ -75.648445]
 [ -73.03744 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 29.  1. 29.  0.] 
cards in discard: [ 1. 25.  0.  1.  3.  0. 29.  0.  1.  0. 25.  3. 25. 25.  0.  1. 29. 25.
  3.  1.  3. 29.  1. 25.  3.  3.  1.  1.  1. 25.  3.  1.  1.  1. 25.  0.
 29.  1.  1. 29. 29.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1] -> size -> 51 
action values: 0 
buys: 1 
player value: 3 
card supply: [18.  9. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  8.  8.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [29 15  8  8  8  8  0  6  6  0  8] -> size -> 11 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -73.0374526977539



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  8.  8.  6. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  8.  6. 15.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  8  8  8  8  0  6  6  0  8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [18.  9. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [29.  1.  1. 25. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1] -> size -> 51 
adversary victory points: 8
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  8.  6. 15.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  8  8  8  8  0  6  6  0  8] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [18.  9. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [29.  1.  1. 25. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1] -> size -> 51 
adversary victory points: 8
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  8.  6. 15.] 
cards in discard: [0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  8  8  8  8  0  6  6  0  8  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [17.  9. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [29.  1.  1. 25. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1] -> size -> 51 
adversary victory points: 8
player victory points: -2 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [29.  1.  1. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29.] 
expected returns: [[-31.179142 ]
 [-15.0705805]
 [-19.086744 ]
 [-15.0705805]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  1. 25. 29.] 
cards in discard: [] 
cards in deck: 46 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [17.  9. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 8. 29.  8.  0.  6.] 
adversary cards in discard: [ 0.  0.  8.  8.  6. 15.] 
adversary owned cards: [29 15  8  8  8  8  0  6  6  0  8  0] -> size -> 12 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -73.0374526977539



action possibilites: [-1. 25. 29. 29.] 
expected returns: [[-31.944359]
 [-20.373606]
 [-16.358948]
 [-16.358948]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 29.] 
cards in discard: [1. 1.] 
cards in deck: 45 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1] -> size -> 51 
action values: 1 
buys: 0 
player value: 1 
card supply: [17.  9. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 8. 29.  8.  0.  6.] 
adversary cards in discard: [ 0.  0.  8.  8.  6. 15.] 
adversary owned cards: [29 15  8  8  8  8  0  6  6  0  8  0] -> size -> 12 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -19.89444351196289



action possibilites: [-1. 29.] 
expected returns: [[-17.41847  ]
 [ -1.5412556]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.] 
cards in discard: [ 1.  1. 25.  1.] 
cards in deck: 44 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1] -> size -> 51 
action values: 1 
buys: 0 
player value: 2 
card supply: [17.  9. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 8. 29.  8.  0.  6.] 
adversary cards in discard: [ 0.  0.  8.  8.  6. 15.] 
adversary owned cards: [29 15  8  8  8  8  0  6  6  0  8  0] -> size -> 12 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -21.02801513671875



action possibilites: [-1.] 
expected returns: [[-23.493967]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 1.  1. 25.  1. 25.] 
cards in deck: 43 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1] -> size -> 51 
action values: 1 
buys: 0 
player value: 3 
card supply: [17.  9. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 8. 29.  8.  0.  6.] 
adversary cards in discard: [ 0.  0.  8.  8.  6. 15.] 
adversary owned cards: [29 15  8  8  8  8  0  6  6  0  8  0] -> size -> 12 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: discard_n_cards - action 0
Learning step: 0
desired expected reward: -19.464567184448242





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ -37.81897 ]
 [ -26.987103]
 [ -30.471802]
 [-114.215065]
 [ -28.99362 ]
 [ -40.597645]
 [ -26.558027]
 [ -23.396566]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 1.  1. 25.  1. 25.] 
cards in deck: 43 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1] -> size -> 51 
action values: 1 
buys: 1 
player value: 3 
card supply: [17.  9. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 8. 29.  8.  0.  6.] 
adversary cards in discard: [ 0.  0.  8.  8.  6. 15.] 
adversary owned cards: [29 15  8  8  8  8  0  6  6  0  8  0] -> size -> 12 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -23.493967056274414






Player: 1 
cards in hand: [ 8. 29.  8.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  8.  0.  6.] 
cards in discard: [ 0.  0.  8.  8.  6. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  8  8  8  8  0  6  6  0  8  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [17.  9. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 25.  1. 29.  0.] 
adversary cards in discard: [ 1.  1. 25.  1. 25. 29. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1] -> size -> 51 
adversary victory points: 8
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.] 
cards in discard: [ 0.  0.  8.  8.  6. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 15  8  8  8  0  6  0  8  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [17.  9. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 25.  1. 29.  0.] 
adversary cards in discard: [ 1.  1. 25.  1. 25. 29. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1] -> size -> 51 
adversary victory points: 8
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.] 
cards in discard: [ 0.  0.  8.  8.  6. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 15  8  8  8  0  6  0  8  0] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [17.  9. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 25.  1. 29.  0.] 
adversary cards in discard: [ 1.  1. 25.  1. 25. 29. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1] -> size -> 51 
adversary victory points: 8
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.] 
cards in discard: [ 0.  0.  8.  8.  6. 15.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 15  8  8  8  0  6  0  8  0  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [16.  9. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 25.  1. 29.  0.] 
adversary cards in discard: [ 1.  1. 25.  1. 25. 29. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1] -> size -> 51 
adversary victory points: 8
player victory points: -1 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  1. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[-41.83983 ]
 [-30.785843]
 [-27.399818]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  1. 29.  0.] 
cards in discard: [ 1.  1. 25.  1. 25. 29. 29. 29.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [16.  9. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [0. 6. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [29 15  8  8  8  0  6  0  8  0  0] -> size -> 11 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -23.39655113220215



action possibilites: [-1.] 
expected returns: [[-13.246644]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3.] 
cards in discard: [ 1.  1. 25.  1. 25. 29. 29. 29. 25.  0.] 
cards in deck: 37 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1] -> size -> 51 
action values: 1 
buys: 0 
player value: 1 
card supply: [16.  9. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [0. 6. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [29 15  8  8  8  0  6  0  8  0  0] -> size -> 11 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -31.415184020996094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[-18.564013 ]
 [ -3.7391112]
 [-12.076647 ]
 [-77.17927  ]
 [ -9.69704  ]
 [ -7.665866 ]
 [-16.622696 ]
 [ -9.560029 ]
 [-10.133618 ]
 [ -4.3351355]
 [-16.802626 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3.] 
cards in discard: [ 1.  1. 25.  1. 25. 29. 29. 29. 25.  0.] 
cards in deck: 37 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1] -> size -> 51 
action values: 0 
buys: 1 
player value: 4 
card supply: [16.  9. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [0. 6. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [29 15  8  8  8  0  6  0  8  0  0] -> size -> 11 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -13.246644020080566



buy possibilites: [-1] 
expected returns: [[2.4196246]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3.] 
cards in discard: [ 1.  1. 25.  1. 25. 29. 29. 29. 25.  0.  1.] 
cards in deck: 37 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1  1] -> size -> 52 
action values: 0 
buys: 0 
player value: 1 
card supply: [16.  8. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [0. 6. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [29 15  8  8  8  0  6  0  8  0  0] -> size -> 11 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[  -5.     0.     0.   270.     0.     0.    20.     0.     0.     0.
    0.  -170.     0.     0.    13.5    0. ] 
sum of rewards: 128.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -3.739100456237793






Player: 1 
cards in hand: [0. 6. 0. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 8. 8.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  8  8  8  0  6  0  8  0  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [16.  8. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [1. 0. 3. 3. 1.] 
adversary cards in discard: [ 1.  1. 25.  1. 25. 29. 29. 29. 25.  0.  1. 29.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1  1] -> size -> 52 
adversary victory points: 8
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 8. 8.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  8  8  8  0  6  0  8  0  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [16.  8. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [1. 0. 3. 3. 1.] 
adversary cards in discard: [ 1.  1. 25.  1. 25. 29. 29. 29. 25.  0.  1. 29.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1  1] -> size -> 52 
adversary victory points: 8
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [1. 0. 3. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-51.628693]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 3. 1.] 
cards in discard: [ 1.  1. 25.  1. 25. 29. 29. 29. 25.  0.  1. 29.  1.  0.  3.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1  1] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [16.  8. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [29.  8.  8.  0. 15.] 
adversary cards in discard: [0. 6. 0. 8. 8.] 
adversary owned cards: [29 15  8  8  8  0  6  0  8  0  0] -> size -> 11 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 2.4196245670318604





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-54.563404]
 [-42.899563]
 [-49.106678]
 [-74.48972 ]
 [-77.20757 ]
 [-46.870884]
 [-45.762436]
 [-53.326054]
 [-46.879528]
 [-43.552135]
 [-47.217796]
 [-56.83299 ]
 [-43.513454]
 [-51.15085 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 3. 1.] 
cards in discard: [ 1.  1. 25.  1. 25. 29. 29. 29. 25.  0.  1. 29.  1.  0.  3.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1  1] -> size -> 52 
action values: 0 
buys: 1 
player value: 5 
card supply: [16.  8. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [29.  8.  8.  0. 15.] 
adversary cards in discard: [0. 6. 0. 8. 8.] 
adversary owned cards: [29 15  8  8  8  0  6  0  8  0  0] -> size -> 11 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -51.628692626953125



buy possibilites: [-1] 
expected returns: [[-27.257221]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 3. 1.] 
cards in discard: [ 1.  1. 25.  1. 25. 29. 29. 29. 25.  0.  1. 29.  1.  0.  3.  1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1  1  1] -> size -> 53 
action values: 0 
buys: 0 
player value: 2 
card supply: [16.  7. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [29.  8.  8.  0. 15.] 
adversary cards in discard: [0. 6. 0. 8. 8.] 
adversary owned cards: [29 15  8  8  8  0  6  0  8  0  0] -> size -> 11 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[  -5.     0.     0.   270.     0.     0.     0.     0.     0.     0.
    0.  -180.     0.     0.    13.5    0. ] 
sum of rewards: 98.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -42.89956283569336






Player: 1 
cards in hand: [29.  8.  8.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.  8. 15.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  8.  0. 15.] 
cards in discard: [0. 6. 0. 8. 8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  8  8  8  0  6  0  8  0  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [16.  7. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 1.  3. 25.  1.  1.] 
adversary cards in discard: [ 1.  1. 25.  1. 25. 29. 29. 29. 25.  0.  1. 29.  1.  0.  3.  1.  1.  0.
  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1  1  1] -> size -> 53 
adversary victory points: 8
player victory points: -1 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [ 0.  6.  0.  8.  8.  8. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 15  8  8  8  0  6  0  8  0  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 1 
card supply: [16.  7. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 1.  3. 25.  1.  1.] 
adversary cards in discard: [ 1.  1. 25.  1. 25. 29. 29. 29. 25.  0.  1. 29.  1.  0.  3.  1.  1.  0.
  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1  1  1] -> size -> 53 
adversary victory points: 8
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0.  6.  0.  8.  8.  8. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 15  8  8  8  6  0  8  0  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 1 
card supply: [16.  7. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 1.  3. 25.  1.  1.] 
adversary cards in discard: [ 1.  1. 25.  1. 25. 29. 29. 29. 25.  0.  1. 29.  1.  0.  3.  1.  1.  0.
  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1  1  1] -> size -> 53 
adversary victory points: 8
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  6.  0.  8.  8.  8. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 15  8  8  8  6  0  8  0  0] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [16.  7. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 1.  3. 25.  1.  1.] 
adversary cards in discard: [ 1.  1. 25.  1. 25. 29. 29. 29. 25.  0.  1. 29.  1.  0.  3.  1.  1.  0.
  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1  1  1] -> size -> 53 
adversary victory points: 8
player victory points: -1 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [ 1.  3. 25.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[-152.02104]
 [-209.60649]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 25.  1.  1.] 
cards in discard: [ 1.  1. 25.  1. 25. 29. 29. 29. 25.  0.  1. 29.  1.  0.  3.  1.  1.  0.
  3.  3.  1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1  1  1] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [16.  7. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 8. 15. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29 15  8  8  8  6  0  8  0  0] -> size -> 10 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: -27.257221221923828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-187.67715]
 [-202.0749 ]
 [-205.08002]
 [-187.95575]
 [-226.51697]
 [-228.40077]
 [-182.53181]
 [-192.82103]
 [-191.67323]
 [-184.52682]
 [-201.48183]
 [-182.01154]
 [-191.12639]
 [-203.32639]
 [-152.02104]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 25.  1.  1.] 
cards in discard: [ 1.  1. 25.  1. 25. 29. 29. 29. 25.  0.  1. 29.  1.  0.  3.  1.  1.  0.
  3.  3.  1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1  1  1] -> size -> 53 
action values: 0 
buys: 1 
player value: 6 
card supply: [16.  7. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 8. 15. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29 15  8  8  8  6  0  8  0  0] -> size -> 10 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -152.02102661132812



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8. 15. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  8  8  8  6  0  8  0  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [16.  7. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 25. 29.  1. 25.] 
adversary cards in discard: [ 1.  1. 25.  1. 25. 29. 29. 29. 25.  0.  1. 29.  1.  0.  3.  1.  1.  0.
  3.  3.  1.  1.  3. 25.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1  1  1] -> size -> 53 
adversary victory points: 8
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  8  8  8  6  0  8  0  0] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [16.  7. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 25. 29.  1. 25.] 
adversary cards in discard: [ 1.  1. 25.  1. 25. 29. 29. 29. 25.  0.  1. 29.  1.  0.  3.  1.  1.  0.
  3.  3.  1.  1.  3. 25.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1  1  1] -> size -> 53 
adversary victory points: 8
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [ 0. 25. 29.  1. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25.] 
expected returns: [[-62.005676]
 [-59.46593 ]
 [-57.084755]
 [-59.46593 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 29.  1. 25.] 
cards in discard: [ 1.  1. 25.  1. 25. 29. 29. 29. 25.  0.  1. 29.  1.  0.  3.  1.  1.  0.
  3.  3.  1.  1.  3. 25.  1.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1  1  1] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [16.  7. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [0. 6. 8. 8. 8.] 
adversary cards in discard: [ 8. 15. 29.  0.  0.] 
adversary owned cards: [29 15  8  8  8  6  0  8  0  0] -> size -> 10 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -152.02102661132812



action possibilites: [-1. 25.] 
expected returns: [[-112.24264]
 [-132.17308]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 25.] 
cards in discard: [ 1.  1. 25.  1. 25. 29. 29. 29. 25.  0.  1. 29.  1.  0.  3.  1.  1.  0.
  3.  3.  1.  1.  3. 25.  1.  1. 25. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1  1  1] -> size -> 53 
action values: 1 
buys: 0 
player value: 1 
card supply: [16.  7. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [0. 6. 8. 8. 8.] 
adversary cards in discard: [ 8. 15. 29.  0.  0.] 
adversary owned cards: [29 15  8  8  8  6  0  8  0  0] -> size -> 10 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -58.37065124511719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[-132.18031 ]
 [-127.5161  ]
 [-124.903496]
 [-190.60365 ]
 [-118.961945]
 [-124.89849 ]
 [-134.47534 ]
 [-120.3538  ]
 [-119.45209 ]
 [-129.34933 ]
 [-112.24264 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 25.] 
cards in discard: [ 1.  1. 25.  1. 25. 29. 29. 29. 25.  0.  1. 29.  1.  0.  3.  1.  1.  0.
  3.  3.  1.  1.  3. 25.  1.  1. 25. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1  1  1] -> size -> 53 
action values: 0 
buys: 1 
player value: 4 
card supply: [16.  7. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [0. 6. 8. 8. 8.] 
adversary cards in discard: [ 8. 15. 29.  0.  0.] 
adversary owned cards: [29 15  8  8  8  6  0  8  0  0] -> size -> 10 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -112.24262237548828






Player: 1 
cards in hand: [0. 6. 8. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8. 8. 8.] 
cards in discard: [ 8. 15. 29.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  8  8  8  6  0  8  0  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [16.  7. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [1. 3. 1. 1. 0.] 
adversary cards in discard: [ 1.  1. 25.  1. 25. 29. 29. 29. 25.  0.  1. 29.  1.  0.  3.  1.  1.  0.
  3.  3.  1.  1.  3. 25.  1.  1. 25. 29. 29.  0.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1  1  1] -> size -> 53 
adversary victory points: 8
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6.] 
cards in discard: [ 8. 15. 29.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 15  8  6  0  8  0  0] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [16.  7. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [1. 3. 1. 1. 0.] 
adversary cards in discard: [ 1.  1. 25.  1. 25. 29. 29. 29. 25.  0.  1. 29.  1.  0.  3.  1.  1.  0.
  3.  3.  1.  1.  3. 25.  1.  1. 25. 29. 29.  0.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1  1  1] -> size -> 53 
adversary victory points: 8
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [ 8. 15. 29.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 15  8  6  0  8  0  0] -> size -> 8 
action values: 0 
buys: 1 
player value: 1 
card supply: [16.  7. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [1. 3. 1. 1. 0.] 
adversary cards in discard: [ 1.  1. 25.  1. 25. 29. 29. 29. 25.  0.  1. 29.  1.  0.  3.  1.  1.  0.
  3.  3.  1.  1.  3. 25.  1.  1. 25. 29. 29.  0.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1  1  1] -> size -> 53 
adversary victory points: 8
player victory points: -1 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [1. 3. 1. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-37.301163]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 1. 1. 0.] 
cards in discard: [ 1.  1. 25.  1. 25. 29. 29. 29. 25.  0.  1. 29.  1.  0.  3.  1.  1.  0.
  3.  3.  1.  1.  3. 25.  1.  1. 25. 29. 29.  0.  1. 25.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1  1  1] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [16.  7. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 8. 15.  8.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 15  8  6  0  8  0  0] -> size -> 8 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -112.24262237548828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-38.2015  ]
 [-23.193989]
 [-69.79308 ]
 [-31.660725]
 [-66.189384]
 [-91.80158 ]
 [-29.54109 ]
 [-27.274858]
 [-36.605392]
 [-29.35343 ]
 [-23.96092 ]
 [-29.982864]
 [-40.332623]
 [-23.738594]
 [-37.301144]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1. 1. 0.] 
cards in discard: [ 1.  1. 25.  1. 25. 29. 29. 29. 25.  0.  1. 29.  1.  0.  3.  1.  1.  0.
  3.  3.  1.  1.  3. 25.  1.  1. 25. 29. 29.  0.  1. 25.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1  1  1] -> size -> 53 
action values: 0 
buys: 1 
player value: 7 
card supply: [16.  7. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 8. 15.  8.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 15  8  6  0  8  0  0] -> size -> 8 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -37.30116271972656



buy possibilites: [-1] 
expected returns: [[-67.20823]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1. 1. 0.] 
cards in discard: [ 1.  1. 25.  1. 25. 29. 29. 29. 25.  0.  1. 29.  1.  0.  3.  1.  1.  0.
  3.  3.  1.  1.  3. 25.  1.  1. 25. 29. 29.  0.  1. 25.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1  1  1  1] -> size -> 54 
action values: 0 
buys: 0 
player value: 4 
card supply: [16.  6. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 8. 15.  8.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 15  8  6  0  8  0  0] -> size -> 8 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[  -5.     0.     0.   270.     0.     0.     0.     0.     0.     0.
    0.  -190.     0.     0.    13.5    0. ] 
sum of rewards: 88.5 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -23.194007873535156






Player: 1 
cards in hand: [ 8. 15.  8.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  8.  0. 29.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [29 15  8  6  0  8  0  0] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [16.  6. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 1.  0. 25. 25.  1.] 
adversary cards in discard: [ 1.  1. 25.  1. 25. 29. 29. 29. 25.  0.  1. 29.  1.  0.  3.  1.  1.  0.
  3.  3.  1.  1.  3. 25.  1.  1. 25. 29. 29.  0.  1. 25.  1.  1.  3.  1.
  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1  1  1  1] -> size -> 54 
adversary victory points: 8
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 0 8 0 0] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [16.  6. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 1.  0. 25. 25.  1.] 
adversary cards in discard: [ 1.  1. 25.  1. 25. 29. 29. 29. 25.  0.  1. 29.  1.  0.  3.  1.  1.  0.
  3.  3.  1.  1.  3. 25.  1.  1. 25. 29. 29.  0.  1. 25.  1.  1.  3.  1.
  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1  1  1  1] -> size -> 54 
adversary victory points: 8
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 0 8 0 0] -> size -> 6 
action values: 0 
buys: 1 
player value: 1 
card supply: [16.  6. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 1.  0. 25. 25.  1.] 
adversary cards in discard: [ 1.  1. 25.  1. 25. 29. 29. 29. 25.  0.  1. 29.  1.  0.  3.  1.  1.  0.
  3.  3.  1.  1.  3. 25.  1.  1. 25. 29. 29.  0.  1. 25.  1.  1.  3.  1.
  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1  1  1  1] -> size -> 54 
adversary victory points: 8
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 0 8 0 0 0] -> size -> 7 
action values: 0 
buys: 0 
player value: 1 
card supply: [15.  6. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [ 1.  0. 25. 25.  1.] 
adversary cards in discard: [ 1.  1. 25.  1. 25. 29. 29. 29. 25.  0.  1. 29.  1.  0.  3.  1.  1.  0.
  3.  3.  1.  1.  3. 25.  1.  1. 25. 29. 29.  0.  1. 25.  1.  1.  3.  1.
  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1  1  1  1] -> size -> 54 
adversary victory points: 8
player victory points: -1 





         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [ 1.  0. 25. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[-97.500626]
 [-94.437126]
 [-94.437126]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 25. 25.  1.] 
cards in discard: [ 1.  1. 25.  1. 25. 29. 29. 29. 25.  0.  1. 29.  1.  0.  3.  1.  1.  0.
  3.  3.  1.  1.  3. 25.  1.  1. 25. 29. 29.  0.  1. 25.  1.  1.  3.  1.
  1.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1  1  1  1] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [15.  6. 30. 21. 30.  8.  1.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [8. 0. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 0 8 0 0 0] -> size -> 7 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: -67.2082290649414



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 20 
Gold: 0 
Estate: 5 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 0 
Chapel: 0 
Witch: 10 
Poacher: 9 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 1.  0. 25.  1.  3.  1.] 
cards in discard: [ 1.  1. 25.  1. 25. 29. 29. 29. 25.  0.  1. 29.  1.  0.  3.  1.  1.  0.
  3.  3.  1.  1.  3. 25.  1.  1. 25. 29. 29.  0.  1. 25.  1.  1.  3.  1.
  1.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 29  1 29 29 29  1  1 29 29 29 29 29  1
  1  3  1  3  3  1  1  1  3 25 25  1 25 25  1 25  1  1 25 25 25 25 25  1
  1  1  1  1  1  1] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [15.  6. 30. 21. 30.  8.  0.  9.  9.  2.  0.  0.  8. 10. 10. 10.  8.] 
adversary cards in hand: [8. 0. 0. 0. 6.] 
adversary cards in discard: [6.] 
adversary owned cards: [8 6 0 8 0 0 0 6] -> size -> 8 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[     -5 3000000       0     270       0       0      20       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000285 

action type: take_action - action 25.0
Learning step: 120015.1796875
desired expected reward: 119920.7421875



