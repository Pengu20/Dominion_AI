 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[20.0933]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    0    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -785 

action type: buy - action 6.0
Learning step: -23.744680404663086
desired expected reward: -17.25531768798828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[18.152994]
 [20.478584]
 [19.13262 ]
 [14.967153]
 [22.17045 ]
 [21.190813]
 [19.844843]
 [20.343222]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5536313652992249
desired expected reward: 19.922504425048828



buy possibilites: [-1] 
expected returns: [[21.779892]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 3. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: -0.04642461612820625
desired expected reward: 22.124025344848633






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [11.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [11.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 3. 3. 0. 3. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [11.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[23.456776]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.  0.  0.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5547509789466858
desired expected reward: 21.225141525268555





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[22.10151 ]
 [24.42707 ]
 [23.081112]
 [18.87833 ]
 [22.828232]
 [26.118935]
 [25.139294]
 [26.30873 ]
 [21.910458]
 [23.79333 ]
 [24.236013]
 [24.291704]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.  0.  0.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6069878339767456
desired expected reward: 23.073562622070312



buy possibilites: [-1] 
expected returns: [[25.310051]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.  0.  0.  3.  0.  3. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 16.0
Learning step: 0.39090847969055176
desired expected reward: 23.21914291381836






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 16] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  8.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [11.  0.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[25.425444]
 [27.25267 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  8.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 3.] 
adversary cards in discard: [16.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6279451847076416
desired expected reward: 24.682106018066406



action possibilites: [-1] 
expected returns: [[24.54086]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  8.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 3.] 
adversary cards in discard: [16.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 7
Learning step: 0.5275643467903137
desired expected reward: 22.531389236450195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[22.518993]
 [23.444866]
 [19.472618]
 [25.398485]
 [24.589012]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16 29] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10.  8.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 3.] 
adversary cards in discard: [16.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.03897663205862045
desired expected reward: 24.501882553100586



buy possibilites: [-1] 
expected returns: [[26.72461]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [29.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16 29  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10.  8.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 3.] 
adversary cards in discard: [16.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 16] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 23 

action type: buy - action 3.0
Learning step: 0.26726245880126953
desired expected reward: 23.712127685546875






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [8. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3. 3.] 
cards in discard: [16.  0.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 16] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10.  8.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  0.  0.  0.] 
adversary cards in discard: [29.  3. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16 29  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [16.  0.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 16] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10.  8.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  0.  0.  0.] 
adversary cards in discard: [29.  3. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16 29  3] -> size -> 14 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [16.  0.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 16] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10.  8.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  0.  0.  0.] 
adversary cards in discard: [29.  3. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16 29  3] -> size -> 14 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [16.  0.  0.  0.  3.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 16  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10.  8.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  0.  0.  0.] 
adversary cards in discard: [29.  3. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16 29  3] -> size -> 14 
adversary victory points: 4
player victory points: 2 





Player: 0 
cards in hand: [16.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[30.158949]
 [28.666723]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.  0.  0.] 
cards in discard: [29.  3. 11.  0.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 16 29  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10.  8.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 16  8] -> size -> 12 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6403746604919434
desired expected reward: 26.0842342376709



action possibilites: [-1] 
expected returns: [[26.646091]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [29.  3. 11.  0.  0.  3.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  8.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 16  8] -> size -> 12 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 19 

action type: gain_card_n - action 1
Learning step: 0.010512599721550941
desired expected reward: 27.986225128173828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[25.056671]
 [27.354275]
 [26.014977]
 [21.972101]
 [29.037706]
 [28.062927]
 [26.723606]
 [27.219458]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [29.  3. 11.  0.  0.  3.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 28. 30.  8. 10.  8.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 16  8] -> size -> 12 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.06638969480991364
desired expected reward: 26.579702377319336



buy possibilites: [-1] 
expected returns: [[29.720999]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [29.  3. 11.  0.  0.  3.  3.  3. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  8.  8.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 16  8] -> size -> 12 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 11.0
Learning step: 0.4299052059650421
desired expected reward: 29.467609405517578






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [8. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 16  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  8.  8.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11] -> size -> 15 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 16  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 28. 30.  8. 10.  8.  8.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11] -> size -> 15 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 0. 0.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 16  8  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  8.  8.  7. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11] -> size -> 15 
adversary victory points: 5
player victory points: 2 





Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[28.112926]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  8.  8.  7. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 16.] 
adversary cards in discard: [8. 8. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 16  8  8] -> size -> 13 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7441272139549255
desired expected reward: 28.976871490478516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[26.1346  ]
 [28.422977]
 [27.096193]
 [22.962698]
 [30.080767]
 [29.119143]
 [27.792326]
 [28.246351]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 28. 30.  8. 10.  8.  8.  7. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 16.] 
adversary cards in discard: [8. 8. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 16  8  8] -> size -> 13 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7059904932975769
desired expected reward: 27.627607345581055



buy possibilites: [-1] 
expected returns: [[28.768305]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 28. 30.  8. 10.  8.  8.  6. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 16.] 
adversary cards in discard: [8. 8. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 16  8  8] -> size -> 13 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: -3.0 

action type: buy - action 8.0
Learning step: -0.6615069508552551
desired expected reward: 28.457632064819336






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 16.] 
cards in discard: [8. 8. 3. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 16  8  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  8.  8.  6. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0. 29.  0. 11.] 
adversary cards in discard: [8. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8] -> size -> 16 
adversary victory points: 5
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [8. 8. 3. 3. 0. 0. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  8 16  8  8  6] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8.  9.  8.  8.  6. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0. 29.  0. 11.] 
adversary cards in discard: [8. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8] -> size -> 16 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [8. 8. 3. 3. 0. 0. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  8 16  8  8  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 28. 30.  8.  9.  8.  8.  6. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0. 29.  0. 11.] 
adversary cards in discard: [8. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8] -> size -> 16 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8.  8.  3.  3.  0.  0.  6. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  8 16  8  8  6 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8.  9.  8.  8.  6. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11.  0. 29.  0. 11.] 
adversary cards in discard: [8. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8] -> size -> 16 
adversary victory points: 5
player victory points: 1 





Player: 0 
cards in hand: [11.  0. 29.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 11.] 
expected returns: [[25.011475]
 [26.824078]
 [27.003313]
 [26.824078]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 29.  0. 11.] 
cards in discard: [8. 0. 0. 3. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8.  9.  8.  8.  6. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8 16  8  8  6 10] -> size -> 14 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7332586646080017
desired expected reward: 28.035045623779297



action possibilites: [-1. 11. 11. 16.] 
expected returns: [[25.07971 ]
 [26.902037]
 [26.902037]
 [23.695177]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 11. 16.] 
cards in discard: [8. 0. 0. 3. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 28. 30.  8.  9.  8.  8.  6. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8 16  8  8  6 10] -> size -> 14 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: -0.0916580781340599
desired expected reward: 27.027280807495117





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[23.123568]
 [25.3832  ]
 [24.073067]
 [20.043032]
 [27.024857]
 [26.07058 ]
 [24.760431]
 [25.208708]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0. 11. 16.] 
cards in discard: [8. 0. 0. 3. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 28. 30.  8.  9.  8.  8.  6. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8 16  8  8  6 10] -> size -> 14 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.04016733169555664
desired expected reward: 25.03954315185547



buy possibilites: [-1] 
expected returns: [[31.520102]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0. 11. 16.] 
cards in discard: [ 8.  0.  0.  3.  3.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8.  9.  8.  7.  6. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8 16  8  8  6 10] -> size -> 14 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 11.0
Learning step: 0.5102154016494751
desired expected reward: 27.535070419311523






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [3. 0. 8. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 8. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8 16  8  8  6 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8.  9.  8.  7.  6. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11] -> size -> 17 
adversary victory points: 5
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  8 16  8  8  6 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8.  9.  8.  7.  6. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11] -> size -> 17 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  8 16  8  8  6 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 30. 30. 28. 30.  8.  9.  8.  7.  6. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11] -> size -> 17 
adversary victory points: 5
player victory points: 1 





Player: 0 
cards in hand: [0. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[28.104822]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8.  9.  8.  7.  6. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  8. 10.] 
adversary cards in discard: [8. 3. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 16  8  8  6 10] -> size -> 13 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7989217638969421
desired expected reward: 30.721179962158203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[26.452562]
 [27.432829]
 [23.219069]
 [29.49504 ]
 [28.60528 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 28. 30.  8.  9.  8.  7.  6. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  8. 10.] 
adversary cards in discard: [8. 3. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 16  8  8  6 10] -> size -> 13 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7085769772529602
desired expected reward: 27.546777725219727



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  8. 10.] 
cards in discard: [8. 3. 8. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 16  8  8  6 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8.  9.  8.  7.  6. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11. 11.  0. 29. 16.] 
adversary cards in discard: [0. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11] -> size -> 17 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  8. 10.] 
cards in discard: [8. 3. 8. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 16  8  8  6 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 28. 30.  8.  9.  8.  7.  6. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11. 11.  0. 29. 16.] 
adversary cards in discard: [0. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11] -> size -> 17 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  8. 10.] 
cards in discard: [8. 3. 8. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 16  8  8  6 10  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 27. 30.  8.  9.  8.  7.  6. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11. 11.  0. 29. 16.] 
adversary cards in discard: [0. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11] -> size -> 17 
adversary victory points: 5
player victory points: 2 





Player: 0 
cards in hand: [11. 11.  0. 29. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 29. 16.] 
expected returns: [[23.722025]
 [25.557049]
 [25.557049]
 [25.735323]
 [22.329145]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0. 29. 16.] 
cards in discard: [0. 3. 3. 3. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 27. 30.  8.  9.  8.  7.  6. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  6. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 16  8  8  6 10  3] -> size -> 14 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.746837854385376
desired expected reward: 27.858440399169922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[21.871086]
 [18.757221]
 [23.977478]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  0. 29. 16.] 
cards in discard: [0. 3. 3. 3. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 30. 30. 27. 30.  8.  9.  8.  7.  6. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  6. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 16  8  8  6 10  3] -> size -> 14 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6327336430549622
desired expected reward: 23.166683197021484



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 3.  6. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 16.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 16  8  8  6 10  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 27. 30.  8.  9.  8.  7.  6. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 11.  0.] 
adversary cards in discard: [ 0.  3.  3.  3.  0. 11. 11.  0. 29. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11] -> size -> 17 
adversary victory points: 5
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0.] 
cards in discard: [8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  8 16  8  8  6 10  3  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 27. 30.  8.  9.  8.  7.  5. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 11.  0.] 
adversary cards in discard: [ 0.  3.  3.  3.  0. 11. 11.  0. 29. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11] -> size -> 17 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0.] 
cards in discard: [8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  8 16  8  8  6 10  3  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 30. 30. 27. 30.  8.  9.  8.  7.  5. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 11.  0.] 
adversary cards in discard: [ 0.  3.  3.  3.  0. 11. 11.  0. 29. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11] -> size -> 17 
adversary victory points: 5
player victory points: 2 





Player: 0 
cards in hand: [ 3.  0.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[26.225307]
 [28.07194 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 11.  0.] 
cards in discard: [ 0.  3.  3.  3.  0. 11. 11.  0. 29. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 27. 30.  8.  9.  8.  7.  5. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 8.] 
adversary cards in discard: [ 8. 16.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8 16  8  8  6 10  3  8] -> size -> 14 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5821999907493591
desired expected reward: 23.39527702331543



action possibilites: [-1] 
expected returns: [[27.615282]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [ 0.  3.  3.  3.  0. 11. 11.  0. 29. 16. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 27. 30.  8.  9.  8.  7.  5. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 8.] 
adversary cards in discard: [ 8. 16.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8 16  8  8  6 10  3  8] -> size -> 14 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 8
Learning step: 0.4154983460903168
desired expected reward: 27.23090171813965





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[25.843878]
 [26.830502]
 [22.618536]
 [28.90603 ]
 [28.010405]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [ 0.  3.  3.  3.  0. 11. 11.  0. 29. 16. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 27. 30.  8.  9.  8.  7.  5. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 8.] 
adversary cards in discard: [ 8. 16.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8 16  8  8  6 10  3  8] -> size -> 14 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.09564404934644699
desired expected reward: 27.519638061523438



buy possibilites: [-1] 
expected returns: [[27.709272]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [ 0.  3.  3.  3.  0. 11. 11.  0. 29. 16. 14.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 26. 30.  8.  9.  8.  7.  5. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 8.] 
adversary cards in discard: [ 8. 16.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8 16  8  8  6 10  3  8] -> size -> 14 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 23 

action type: buy - action 3.0
Learning step: 0.17444348335266113
desired expected reward: 27.00494384765625






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 8.] 
cards in discard: [ 8. 16.  3.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8 16  8  8  6 10  3  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 26. 30.  8.  9.  8.  7.  5. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3] -> size -> 19 
adversary victory points: 6
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [ 8. 16.  3.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  8 16  8  8  6 10  3  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 26. 30.  8.  9.  8.  7.  5. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3] -> size -> 19 
adversary victory points: 6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [ 8. 16.  3.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  8 16  8  8  6 10  3  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 30. 30. 26. 30.  8.  9.  8.  7.  5. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3] -> size -> 19 
adversary victory points: 6
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [ 8. 16.  3.  6.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  8 16  8  8  6 10  3  8  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 26. 30.  8.  9.  8.  7.  5. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3] -> size -> 19 
adversary victory points: 6
player victory points: 2 





Player: 0 
cards in hand: [3. 0. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[27.9656 ]
 [28.91916]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 8. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  9.  8.  7.  5. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  8. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8 16  8  8  6 10  3  8  0] -> size -> 14 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6806600689888
desired expected reward: 27.02861213684082





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[26.02698 ]
 [26.999098]
 [22.80231 ]
 [29.054848]
 [28.102585]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 8. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 26. 30.  8.  9.  8.  7.  5. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  8. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8 16  8  8  6 10  3  8  0] -> size -> 14 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7071253657341003
desired expected reward: 27.344768524169922



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  8. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8. 10.  8.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8 16  8  8  6 10  3  8  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  9.  8.  7.  5. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [3. 0. 3. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3] -> size -> 19 
adversary victory points: 6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  8. 10.  8.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8 16  8  8  6 10  3  8  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 26. 30.  8.  9.  8.  7.  5. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [3. 0. 3. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3] -> size -> 19 
adversary victory points: 6
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  8. 10.  8.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8 16  8  8  6 10  3  8  0  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 26. 30.  8.  9.  8.  7.  5. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [3. 0. 3. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3] -> size -> 19 
adversary victory points: 6
player victory points: 2 





Player: 0 
cards in hand: [ 0.  0.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[28.509716]
 [30.521769]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 11.] 
cards in discard: [3. 0. 3. 8. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8.  9.  8.  7.  5. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 6. 0. 8.] 
adversary cards in discard: [ 0.  3.  0.  8. 10.  8.] 
adversary owned cards: [ 0  0  0  3  3  8 16  8  8  6 10  3  8  0  0] -> size -> 15 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6805593371391296
desired expected reward: 27.422025680541992



action possibilites: [-1] 
expected returns: [[26.40897]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 3.  0.  3.  8.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 26. 30.  8.  9.  8.  7.  5. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 6. 0. 8.] 
adversary cards in discard: [ 0.  3.  0.  8. 10.  8.] 
adversary owned cards: [ 0  0  0  3  3  8 16  8  8  6 10  3  8  0  0] -> size -> 15 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0.03727889806032181
desired expected reward: 32.03778839111328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[24.812674]
 [27.109322]
 [25.772856]
 [21.671986]
 [28.796083]
 [27.81715 ]
 [26.467148]
 [26.862701]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 3.  0.  3.  8.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 26. 30.  8.  9.  8.  7.  5. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 6. 0. 8.] 
adversary cards in discard: [ 0.  3.  0.  8. 10.  8.] 
adversary owned cards: [ 0  0  0  3  3  8 16  8  8  6 10  3  8  0  0] -> size -> 15 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.06202194094657898
desired expected reward: 26.346948623657227



buy possibilites: [-1] 
expected returns: [[27.081696]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 3.  0.  3.  8.  0. 10.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 25. 30.  8.  9.  8.  7.  5. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 6. 0. 8.] 
adversary cards in discard: [ 0.  3.  0.  8. 10.  8.] 
adversary owned cards: [ 0  0  0  3  3  8 16  8  8  6 10  3  8  0  0] -> size -> 15 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 17.0 

action type: buy - action 3.0
Learning step: 0.021172083914279938
desired expected reward: 25.794029235839844






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [0. 3. 6. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 0. 8.] 
cards in discard: [ 0.  3.  0.  8. 10.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8 16  8  8  6 10  3  8  0  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 25. 30.  8.  9.  8.  7.  5. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [16.  3. 11. 14. 29.] 
adversary cards in discard: [ 3.  0.  3.  8.  0. 10.  3. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3] -> size -> 21 
adversary victory points: 7
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 0.  3.  0.  8. 10.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  8 16  8  8 10  3  8  0  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 25. 30.  8.  9.  8.  7.  5. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [16.  3. 11. 14. 29.] 
adversary cards in discard: [ 3.  0.  3.  8.  0. 10.  3. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3] -> size -> 21 
adversary victory points: 7
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 0.  3.  0.  8. 10.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  8 16  8  8 10  3  8  0  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 25. 30.  8.  9.  8.  7.  5. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [16.  3. 11. 14. 29.] 
adversary cards in discard: [ 3.  0.  3.  8.  0. 10.  3. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3] -> size -> 21 
adversary victory points: 7
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 0.  3.  0.  8. 10.  8.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  8 16  8  8 10  3  8  0  0  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 25. 30.  8.  9.  8.  7.  4. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [16.  3. 11. 14. 29.] 
adversary cards in discard: [ 3.  0.  3.  8.  0. 10.  3. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3] -> size -> 21 
adversary victory points: 7
player victory points: 2 





Player: 0 
cards in hand: [16.  3. 11. 14. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11. 14. 29.] 
expected returns: [[27.03461 ]
 [25.690783]
 [28.944096]
 [24.769857]
 [29.111103]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3. 11. 14. 29.] 
cards in discard: [ 3.  0.  3.  8.  0. 10.  3. 11.  0.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 25. 30.  8.  9.  8.  7.  4. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  8.  0.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  8 16  8  8 10  3  8  0  0  8] -> size -> 14 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6733312010765076
desired expected reward: 26.40836524963379



action possibilites: [-1] 
expected returns: [[23.106697]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3. 11. 29.] 
cards in discard: [ 3.  0.  3.  8.  0. 10.  3. 11.  0.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 25. 30.  8.  9.  8.  7.  4. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 0  0  0  3  8 16  8  8 10  3  8  0  0  8] -> size -> 14 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: -0.051200348883867264
desired expected reward: 24.742822647094727





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[21.069656]
 [22.008448]
 [17.989594]
 [23.993702]
 [23.074053]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3. 11. 29.] 
cards in discard: [ 3.  0.  3.  8.  0. 10.  3. 11.  0.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 25. 30.  8.  9.  8.  7.  4. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 0  0  0  3  8 16  8  8 10  3  8  0  0  8] -> size -> 14 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.01114654541015625
desired expected reward: 23.095550537109375



buy possibilites: [-1] 
expected returns: [[23.663216]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3. 11. 29.] 
cards in discard: [ 3.  0.  3.  8.  0. 10.  3. 11.  0.  0.  0.  3.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 25. 30.  8.  8.  8.  7.  4. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 0  0  0  3  8 16  8  8 10  3  8  0  0  8] -> size -> 14 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -285.0 

action type: buy - action 6.0
Learning step: -8.84122371673584
desired expected reward: 9.148369789123535






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.] 
cards in discard: [8. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  8 16  8  8 10  3  8  0  0  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 25. 30.  8.  8.  8.  7.  4. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  3.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6] -> size -> 22 
adversary victory points: 6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.] 
cards in discard: [8. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  8 16  8  8 10  3  8  0  0  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 25. 30.  8.  8.  8.  7.  4. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  3.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6] -> size -> 22 
adversary victory points: 6
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.] 
cards in discard: [8. 3. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  8 16  8  8 10  3  8  0  0  8  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 25. 30.  8.  8.  8.  7.  4. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  3.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6] -> size -> 22 
adversary victory points: 6
player victory points: 2 





Player: 0 
cards in hand: [11.  3.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[24.813591]
 [26.807693]
 [26.807693]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  3. 11.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 25. 30.  8.  8.  8.  7.  4. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  8.  0.] 
adversary cards in discard: [ 8.  3.  0.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  3  8 16  8  8 10  3  8  0  0  8  0] -> size -> 15 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5831552147865295
desired expected reward: 23.080060958862305



action possibilites: [-1] 
expected returns: [[28.636051]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11.  0.] 
cards in discard: [8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 25. 30.  8.  8.  8.  7.  3. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  8.  0.] 
adversary cards in discard: [ 8.  3.  0.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  3  8 16  8  8 10  3  8  0  0  8  0] -> size -> 15 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 19 

action type: gain_card_n - action 6
Learning step: 0.28025510907173157
desired expected reward: 19.961034774780273





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[26.606289]
 [23.391525]
 [28.694294]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 11.  0.] 
cards in discard: [8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 25. 30.  8.  8.  8.  7.  3. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  8.  0.] 
adversary cards in discard: [ 8.  3.  0.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  3  8 16  8  8 10  3  8  0  0  8  0] -> size -> 15 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.12848562002182007
desired expected reward: 28.507566452026367






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  8.  0.] 
cards in discard: [ 8.  3.  0.  0.  0. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  8 16  8  8 10  3  8  0  0  8  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 25. 30.  8.  8.  8.  7.  3. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 8. 11.  3.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8] -> size -> 23 
adversary victory points: 6
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 8.  3.  0.  0.  0. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8 16  8  8  3  8  0  0  8  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 25. 30.  8.  8.  8.  7.  3. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 8. 11.  3.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8] -> size -> 23 
adversary victory points: 6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 8.  3.  0.  0.  0. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8 16  8  8  3  8  0  0  8  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 30. 30. 25. 30.  8.  8.  8.  7.  3. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 8. 11.  3.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8] -> size -> 23 
adversary victory points: 6
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 8.  3.  0.  0.  0. 16.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8 16  8  8  3  8  0  0  8  0  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 25. 30.  8.  8.  8.  7.  3. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 8. 11.  3.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8] -> size -> 23 
adversary victory points: 6
player victory points: 2 





Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[23.711102]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 8. 11.  3.  3. 11.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 25. 30.  8.  8.  8.  7.  3. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 8. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 16  8  8  3  8  0  0  8  0  0] -> size -> 12 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.7615721225738525
desired expected reward: 27.932723999023438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[22.363598]
 [24.64914 ]
 [23.303944]
 [19.296255]
 [23.044659]
 [26.322445]
 [25.352062]
 [26.477325]
 [22.133032]
 [23.993206]
 [24.408522]
 [24.3368  ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 8. 11.  3.  3. 11.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 30. 30. 25. 30.  8.  8.  8.  7.  3. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 8. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 16  8  8  3  8  0  0  8  0  0] -> size -> 12 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.604887068271637
desired expected reward: 23.07731819152832



buy possibilites: [-1] 
expected returns: [[26.0126]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 8. 11.  3.  3. 11.  0.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 30. 30. 25. 30.  8.  8.  8.  7.  2. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 8. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8 16  8  8  3  8  0  0  8  0  0] -> size -> 12 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: -3.0 

action type: buy - action 8.0
Learning step: -0.577429473400116
desired expected reward: 24.77463150024414






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [0. 8. 8. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 3. 8.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8 16  8  8  3  8  0  0  8  0  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 25. 30.  8.  8.  8.  7.  2. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  3. 10.  8.  3.] 
adversary cards in discard: [ 8. 11.  3.  3. 11.  0.  8.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8  8] -> size -> 24 
adversary victory points: 6
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  8  3  8  0  8  0  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 25. 30.  8.  8.  8.  7.  2. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  3. 10.  8.  3.] 
adversary cards in discard: [ 8. 11.  3.  3. 11.  0.  8.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8  8] -> size -> 24 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  8  3  8  0  8  0  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 30. 30. 25. 30.  8.  8.  8.  7.  2. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  3. 10.  8.  3.] 
adversary cards in discard: [ 8. 11.  3.  3. 11.  0.  8.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8  8] -> size -> 24 
adversary victory points: 6
player victory points: 1 





Player: 0 
cards in hand: [11.  3. 10.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8.] 
expected returns: [[23.43452 ]
 [25.296429]
 [23.11633 ]
 [24.381382]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 10.  8.  3.] 
cards in discard: [ 8. 11.  3.  3. 11.  0.  8.  0.  0.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 25. 30.  8.  8.  8.  7.  2. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 8. 0. 8.] 
adversary cards in discard: [8. 8.] 
adversary owned cards: [16  8  8  3  8  0  8  0  0] -> size -> 9 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6746294498443604
desired expected reward: 25.337970733642578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[21.666039]
 [18.812489]
 [23.507915]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 10.  8.  3.] 
cards in discard: [ 8. 11.  3.  3. 11.  0.  8.  0.  0.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8  8] -> size -> 24 
action values: 1 
buys: 1 
player value: 0 
card supply: [26. 30. 30. 25. 30.  8.  8.  8.  7.  2. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 8. 0. 8.] 
adversary cards in discard: [8. 8.] 
adversary owned cards: [16  8  8  3  8  0  8  0  0] -> size -> 9 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6258243918418884
desired expected reward: 22.852611541748047



buy possibilites: [-1] 
expected returns: [[22.138031]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 10.  8.  3.] 
cards in discard: [ 8. 11.  3.  3. 11.  0.  8.  0.  0.  3.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8  8
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 25. 30.  8.  8.  8.  7.  2. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 8. 0. 8.] 
adversary cards in discard: [8. 8.] 
adversary owned cards: [16  8  8  3  8  0  8  0  0] -> size -> 9 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action 0.0
Learning step: -0.5675318837165833
desired expected reward: 21.098508834838867






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [3. 0. 8. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 0. 8.] 
cards in discard: [8. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  8  3  8  0  8  0  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 25. 30.  8.  8.  8.  7.  2. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 29. 14.] 
adversary cards in discard: [ 8. 11.  3.  3. 11.  0.  8.  0.  0.  3.  0.  0.  0. 11.  3. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8  8
  0] -> size -> 25 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0. 8.] 
cards in discard: [8. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  8  3  8  0  8  0  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 30. 30. 25. 30.  8.  8.  8.  7.  2. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 29. 14.] 
adversary cards in discard: [ 8. 11.  3.  3. 11.  0.  8.  0.  0.  3.  0.  0.  0. 11.  3. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8  8
  0] -> size -> 25 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0. 8.] 
cards in discard: [8. 8. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  8  3  8  0  8  0  0  8] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 29. 14.] 
adversary cards in discard: [ 8. 11.  3.  3. 11.  0.  8.  0.  0.  3.  0.  0.  0. 11.  3. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8  8
  0] -> size -> 25 
adversary victory points: 6
player victory points: 1 





Player: 0 
cards in hand: [ 3.  3.  0. 29. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14.] 
expected returns: [[17.34868 ]
 [19.18282 ]
 [15.454744]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 29. 14.] 
cards in discard: [ 8. 11.  3.  3. 11.  0.  8.  0.  0.  3.  0.  0.  0. 11.  3. 10.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8  8
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  0.  3.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  8  3  8  0  8  0  0  8] -> size -> 10 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6285195350646973
desired expected reward: 21.509511947631836



action possibilites: [-1. 14. 16.] 
expected returns: [[23.309612]
 [21.311665]
 [22.138432]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 14. 16.] 
cards in discard: [ 8. 11.  3.  3. 11.  0.  8.  0.  0.  3.  0.  0.  0. 11.  3. 10.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8  8
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  0.  3.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  8  3  8  0  8  0  0  8] -> size -> 10 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0.11095447093248367
desired expected reward: 19.27505111694336



action possibilites: [-1] 
expected returns: [[27.557634]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 16.] 
cards in discard: [ 8. 11.  3.  3. 11.  0.  8.  0.  0.  3.  0.  0.  0. 11.  3. 10.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8  8
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 30. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  0. 16.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [16  8  8  3  8  0  8  0  0  8] -> size -> 10 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 14.0
Learning step: 0.7000052332878113
desired expected reward: 22.011669158935547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[25.822098]
 [27.94536 ]
 [26.705135]
 [22.874619]
 [26.464512]
 [29.485079]
 [28.58524 ]
 [29.628815]
 [25.603132]
 [27.344774]
 [27.726383]
 [27.661139]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 16.] 
cards in discard: [ 8. 11.  3.  3. 11.  0.  8.  0.  0.  3.  0.  0.  0. 11.  3. 10.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8  8
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 30. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  0. 16.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [16  8  8  3  8  0  8  0  0  8] -> size -> 10 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.5135838985443115
desired expected reward: 28.071218490600586



buy possibilites: [-1] 
expected returns: [[25.412167]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 16.] 
cards in discard: [ 8. 11.  3.  3. 11.  0.  8.  0.  0.  3.  0.  0.  0. 11.  3. 10.  8.  3.
 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8  8
  0 14] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  0. 16.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [16  8  8  3  8  0  8  0  0  8] -> size -> 10 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 32  0] 
sum of rewards: 67 

action type: buy - action 14.0
Learning step: 1.5087336301803589
desired expected reward: 27.111867904663086






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 8.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 16.] 
cards in discard: [3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  8  3  8  0  8  0  0  8] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  8. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8  8
  0 14] -> size -> 26 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 16.] 
cards in discard: [3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  8  3  8  0  8  0  0  8] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 30. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  8. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8  8
  0 14] -> size -> 26 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 16.] 
cards in discard: [3. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  8  3  8  0  8  0  0  8  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 30. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  8. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8  8
  0 14] -> size -> 26 
adversary victory points: 6
player victory points: 1 





Player: 0 
cards in hand: [ 0.  3.  8. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[23.102531]
 [24.066174]
 [25.02597 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8. 11.  6.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8  8
  0 14] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [8. 0. 8. 8. 8.] 
adversary cards in discard: [ 3.  0.  0.  8.  0. 16.] 
adversary owned cards: [16  8  8  3  8  0  8  0  0  8  0] -> size -> 11 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6569098234176636
desired expected reward: 24.75525665283203



action possibilites: [-1] 
expected returns: [[24.535055]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 6.] 
cards in discard: [10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8  8
  0 14 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [8. 0. 8. 8. 8.] 
adversary cards in discard: [ 3.  0.  0.  8.  0. 16.] 
adversary owned cards: [16  8  8  3  8  0  8  0  0  8  0] -> size -> 11 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0.18458060920238495
desired expected reward: 26.61916160583496





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[22.683401]
 [19.620213]
 [24.64343 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 6.] 
cards in discard: [10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8  8
  0 14 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 30. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [8. 0. 8. 8. 8.] 
adversary cards in discard: [ 3.  0.  0.  8.  0. 16.] 
adversary owned cards: [16  8  8  3  8  0  8  0  0  8  0] -> size -> 11 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.046848732978105545
desired expected reward: 24.48820686340332



buy possibilites: [-1] 
expected returns: [[24.503426]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 6.] 
cards in discard: [10.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8  8
  0 14 10  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 30. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [8. 0. 8. 8. 8.] 
adversary cards in discard: [ 3.  0.  0.  8.  0. 16.] 
adversary owned cards: [16  8  8  3  8  0  8  0  0  8  0] -> size -> 11 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: 0.026783866807818413
desired expected reward: 22.710186004638672






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [8. 0. 8. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 8. 8.] 
cards in discard: [ 3.  0.  0.  8.  0. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  8  3  8  0  8  0  0  8  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [14.  0. 11. 16.  0.] 
adversary cards in discard: [10.  0. 11.  0.  3.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8  8
  0 14 10  0] -> size -> 28 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8.] 
cards in discard: [ 3.  0.  0.  8.  0. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  3  8  8  0  0  8  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [14.  0. 11. 16.  0.] 
adversary cards in discard: [10.  0. 11.  0.  3.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8  8
  0 14 10  0] -> size -> 28 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8.] 
cards in discard: [ 3.  0.  0.  8.  0. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  3  8  8  0  0  8  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 30. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [14.  0. 11. 16.  0.] 
adversary cards in discard: [10.  0. 11.  0.  3.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8  8
  0 14 10  0] -> size -> 28 
adversary victory points: 6
player victory points: 1 





Player: 0 
cards in hand: [14.  0. 11. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11. 16.] 
expected returns: [[23.639229]
 [21.48634 ]
 [25.572035]
 [22.383053]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0. 11. 16.  0.] 
cards in discard: [10.  0. 11.  0.  3.  8.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8  8
  0 14 10  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  8.  8. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  3  8  8  0  0  8  0] -> size -> 9 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6354378461837769
desired expected reward: 23.86798858642578



action possibilites: [-1] 
expected returns: [[23.56035]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0. 16.  0.] 
cards in discard: [10.  0. 11.  0.  3.  8.  6.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8  8
  0 14 10  0  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  8.  8. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  3  8  8  0  0  8  0] -> size -> 9 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 1
Learning step: 0.2640349268913269
desired expected reward: 23.708993911743164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[21.891235]
 [22.823673]
 [18.757685]
 [24.833937]
 [23.78908 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0. 16.  0.] 
cards in discard: [10.  0. 11.  0.  3.  8.  6.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8  8
  0 14 10  0  1] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  8.  8. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  3  8  8  0  0  8  0] -> size -> 9 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.016338614746928215
desired expected reward: 23.54401206970215



buy possibilites: [-1] 
expected returns: [[23.113539]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0. 16.  0.] 
cards in discard: [10.  0. 11.  0.  3.  8.  6.  1.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8  8
  0 14 10  0  1  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 29. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  8.  8. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  3  8  8  0  0  8  0] -> size -> 9 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: 0.035955045372247696
desired expected reward: 21.92719268798828






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  8. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  8. 16.  0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  3  8  8  0  0  8  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [3. 3. 3. 8. 0.] 
adversary cards in discard: [10.  0. 11.  0.  3.  8.  6.  1.  0. 11. 14.  0. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8  8
  0 14 10  0  1  0] -> size -> 30 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  3  8  8  0  8  0] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [3. 3. 3. 8. 0.] 
adversary cards in discard: [10.  0. 11.  0.  3.  8.  6.  1.  0. 11. 14.  0. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8  8
  0 14 10  0  1  0] -> size -> 30 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 16.  0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  3  8  8  0  8  0] -> size -> 8 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 29. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [3. 3. 3. 8. 0.] 
adversary cards in discard: [10.  0. 11.  0.  3.  8.  6.  1.  0. 11. 14.  0. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8  8
  0 14 10  0  1  0] -> size -> 30 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 16.  0.] 
cards in discard: [0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  3  8  8  0  8  0  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [3. 3. 3. 8. 0.] 
adversary cards in discard: [10.  0. 11.  0.  3.  8.  6.  1.  0. 11. 14.  0. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8  8
  0 14 10  0  1  0] -> size -> 30 
adversary victory points: 6
player victory points: 1 





Player: 0 
cards in hand: [3. 3. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[24.840702]
 [25.850155]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 8. 0.] 
cards in discard: [10.  0. 11.  0.  3.  8.  6.  1.  0. 11. 14.  0. 16.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8  8
  0 14 10  0  1  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 8. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  3  8  8  0  8  0  0] -> size -> 9 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5762226581573486
desired expected reward: 22.537315368652344



action possibilites: [-1] 
expected returns: [[19.05191]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3.] 
cards in discard: [10.  0. 11.  0.  3.  8.  6.  1.  0. 11. 14.  0. 16.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8  8  0
 14 10  0  1  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 8. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  3  8  8  0  8  0  0] -> size -> 9 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 0
Learning step: -0.04389135167002678
desired expected reward: 23.087322235107422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[17.436451]
 [14.704432]
 [19.186016]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3.] 
cards in discard: [10.  0. 11.  0.  3.  8.  6.  1.  0. 11. 14.  0. 16.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8  8  0
 14 10  0  1  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 29. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 8. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  3  8  8  0  8  0  0] -> size -> 9 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.06244863197207451
desired expected reward: 19.11435890197754



buy possibilites: [-1] 
expected returns: [[21.366568]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3.] 
cards in discard: [10.  0. 11.  0.  3.  8.  6.  1.  0. 11. 14.  0. 16.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8  8  0
 14 10  0  1  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 8. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  3  8  8  0  8  0  0] -> size -> 9 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: buy - action 0.0
Learning step: 0.15125547349452972
desired expected reward: 17.587703704833984






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 8. 3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  3  8  8  0  8  0  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  8. 11.  0.  3.] 
adversary cards in discard: [10.  0. 11.  0.  3.  8.  6.  1.  0. 11. 14.  0. 16.  0.  0.  8.  3.  3.
  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8  8  0
 14 10  0  1  0  0] -> size -> 30 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  8  8  0] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  8. 11.  0.  3.] 
adversary cards in discard: [10.  0. 11.  0.  3.  8.  6.  1.  0. 11. 14.  0. 16.  0.  0.  8.  3.  3.
  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8  8  0
 14 10  0  1  0  0] -> size -> 30 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  8  8  0] -> size -> 5 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 29. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  8. 11.  0.  3.] 
adversary cards in discard: [10.  0. 11.  0.  3.  8.  6.  1.  0. 11. 14.  0. 16.  0.  0.  8.  3.  3.
  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8  8  0
 14 10  0  1  0  0] -> size -> 30 
adversary victory points: 6
player victory points: 1 





Player: 0 
cards in hand: [ 0.  8. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[23.163086]
 [24.105492]
 [24.95139 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11.  0.  3.] 
cards in discard: [10.  0. 11.  0.  3.  8.  6.  1.  0. 11. 14.  0. 16.  0.  0.  8.  3.  3.
  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 16 29  3  3 11  8 11 14  3 10  3  6  8  8  0
 14 10  0  1  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  0.  8.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  8  8  0] -> size -> 5 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5364566445350647
desired expected reward: 20.830110549926758



action possibilites: [-1] 
expected returns: [[19.058105]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [10.  0. 11.  0.  3.  8.  6.  1.  0. 11. 14.  0. 16.  0.  0.  8.  3.  3.
  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 16 29  3  3 11  8 11 14  3 10  3  6  8  8  0 14 10  0
  1  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  0.  8.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  8  8  0] -> size -> 5 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 9
Learning step: -0.13047157227993011
desired expected reward: 25.888917922973633





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[17.5798  ]
 [14.796868]
 [19.28888 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [10.  0. 11.  0.  3.  8.  6.  1.  0. 11. 14.  0. 16.  0.  0.  8.  3.  3.
  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 16 29  3  3 11  8 11 14  3 10  3  6  8  8  0 14 10  0
  1  0  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 29. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  0.  8.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  8  8  0] -> size -> 5 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.06342704594135284
desired expected reward: 19.121532440185547



buy possibilites: [-1] 
expected returns: [[21.160648]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [10.  0. 11.  0.  3.  8.  6.  1.  0. 11. 14.  0. 16.  0.  0.  8.  3.  3.
  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 16 29  3  3 11  8 11 14  3 10  3  6  8  8  0 14 10  0
  1  0  0  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 29. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  0.  8.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  8  8  0] -> size -> 5 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: 0.1447928249835968
desired expected reward: 17.724592208862305






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  8.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  8.  8. 16.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  8  8  0] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [10. 29.  0.  3. 14.] 
adversary cards in discard: [10.  0. 11.  0.  3.  8.  6.  1.  0. 11. 14.  0. 16.  0.  0.  8.  3.  3.
  3.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 16 29  3  3 11  8 11 14  3 10  3  6  8  8  0 14 10  0
  1  0  0  0] -> size -> 28 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  8.  8. 16.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  8  8  0] -> size -> 5 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 29. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [10. 29.  0.  3. 14.] 
adversary cards in discard: [10.  0. 11.  0.  3.  8.  6.  1.  0. 11. 14.  0. 16.  0.  0.  8.  3.  3.
  3.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 16 29  3  3 11  8 11 14  3 10  3  6  8  8  0 14 10  0
  1  0  0  0] -> size -> 28 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  8.  8. 16.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  8  8  0  0] -> size -> 6 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 29. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [10. 29.  0.  3. 14.] 
adversary cards in discard: [10.  0. 11.  0.  3.  8.  6.  1.  0. 11. 14.  0. 16.  0.  0.  8.  3.  3.
  3.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 16 29  3  3 11  8 11 14  3 10  3  6  8  8  0 14 10  0
  1  0  0  0] -> size -> 28 
adversary victory points: 5
player victory points: 0 





Player: 0 
cards in hand: [10. 29.  0.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 14.] 
expected returns: [[20.496445]
 [20.252823]
 [22.367239]
 [18.645868]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  0.  3. 14.] 
cards in discard: [10.  0. 11.  0.  3.  8.  6.  1.  0. 11. 14.  0. 16.  0.  0.  8.  3.  3.
  3.  0.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16 29  3  3 11  8 11 14  3 10  3  6  8  8  0 14 10  0
  1  0  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  8.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  8  8  0  0] -> size -> 6 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5662171840667725
desired expected reward: 20.594430923461914



action possibilites: [-1. 10. 14.] 
expected returns: [[20.788448]
 [20.58661 ]
 [19.032482]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3. 14.  3.] 
cards in discard: [10.  0. 11.  0.  3.  8.  6.  1.  0. 11. 14.  0. 16.  0.  0.  8.  3.  3.
  3.  0.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 16 29  3  3 11  8 11 14  3 10  3  6  8  8  0 14 10  0
  1  0  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 29. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  8.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  8  8  0  0] -> size -> 6 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: -0.008613224141299725
desired expected reward: 22.355764389038086



action possibilites: [-1. 14.] 
expected returns: [[16.971968]
 [15.184508]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 14.  3.  1.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  3  3 16 29  3  3 11  8 11 14  3 10  3  6  8  8  0 14 10  0
  1  0  0  0] -> size -> 28 
action values: 2 
buys: 0 
player value: 1 
card supply: [18. 29. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  8.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  8  8  0  0] -> size -> 6 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 10.0
Learning step: 0.603100061416626
desired expected reward: 21.189708709716797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[15.491216]
 [17.452995]
 [16.268854]
 [12.964154]
 [16.048874]
 [18.914507]
 [18.071533]
 [19.035881]
 [15.279343]
 [16.86431 ]
 [17.221743]
 [17.080833]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 14.  3.  1.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  3  3 16 29  3  3 11  8 11 14  3 10  3  6  8  8  0 14 10  0
  1  0  0  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 29. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  8.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  8  8  0  0] -> size -> 6 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.721302330493927
desired expected reward: 17.693267822265625






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  8.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8.  8. 16.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  8  8  0  0] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 11. 11.  0.  8.] 
adversary cards in discard: [29. 10.  0.  3. 14.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  3 16 29  3  3 11  8 11 14  3 10  3  6  8  8  0 14 10  0
  1  0  0  0] -> size -> 28 
adversary victory points: 5
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 11. 11.  0.  8.] 
adversary cards in discard: [29. 10.  0.  3. 14.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  3 16 29  3  3 11  8 11 14  3 10  3  6  8  8  0 14 10  0
  1  0  0  0] -> size -> 28 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8] -> size -> 2 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 29. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 11. 11.  0.  8.] 
adversary cards in discard: [29. 10.  0.  3. 14.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  3 16 29  3  3 11  8 11 14  3 10  3  6  8  8  0 14 10  0
  1  0  0  0] -> size -> 28 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 11. 11.  0.  8.] 
adversary cards in discard: [29. 10.  0.  3. 14.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  3 16 29  3  3 11  8 11 14  3 10  3  6  8  8  0 14 10  0
  1  0  0  0] -> size -> 28 
adversary victory points: 5
player victory points: 0 





Player: 0 
cards in hand: [ 3. 11. 11.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8.] 
expected returns: [[13.308481]
 [14.97778 ]
 [14.97778 ]
 [14.199913]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 11.  0.  8.] 
cards in discard: [29. 10.  0.  3. 14.  3.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16 29  3  3 11  8 11 14  3 10  3  6  8  8  0 14 10  0
  1  0  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0] -> size -> 3 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5100107789039612
desired expected reward: 16.570819854736328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[11.828617]
 [ 9.283104]
 [13.33836 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 11.  0.  8.] 
cards in discard: [29. 10.  0.  3. 14.  3.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16 29  3  3 11  8 11 14  3 10  3  6  8  8  0 14 10  0
  1  0  0  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 29. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0] -> size -> 3 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4258291721343994
desired expected reward: 12.917503356933594



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [8. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  3.  0.] 
adversary cards in discard: [29. 10.  0.  3. 14.  3.  1.  3. 11. 11.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 16 29  3  3 11  8 11 14  3 10  3  6  8  8  0 14 10  0
  1  0  0  0] -> size -> 28 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 29. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  3.  0.] 
adversary cards in discard: [29. 10.  0.  3. 14.  3.  1.  3. 11. 11.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 16 29  3  3 11  8 11 14  3 10  3  6  8  8  0 14 10  0
  1  0  0  0] -> size -> 28 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0] -> size -> 4 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 29. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  3.  0.] 
adversary cards in discard: [29. 10.  0.  3. 14.  3.  1.  3. 11. 11.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 16 29  3  3 11  8 11 14  3 10  3  6  8  8  0 14 10  0
  1  0  0  0] -> size -> 28 
adversary victory points: 5
player victory points: 0 





Player: 0 
cards in hand: [ 0.  0. 16.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[17.931452]
 [16.96409 ]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  3.  0.] 
cards in discard: [29. 10.  0.  3. 14.  3.  1.  3. 11. 11.  0.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16 29  3  3 11  8 11 14  3 10  3  6  8  8  0 14 10  0
  1  0  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 25. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0] -> size -> 4 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.3656221032142639
desired expected reward: 12.972736358642578



action possibilites: [-1] 
expected returns: [[17.150167]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [29. 10.  0.  3. 14.  3.  1.  3. 11. 11.  0.  8.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3 16 29  3  3 11  8 11 14  3 10  3  6  8  8  0 14 10  0  1
  0  0  0  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 24. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0] -> size -> 4 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 19 

action type: gain_card_n - action 1
Learning step: 0.20523479580879211
desired expected reward: 18.366634368896484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[15.659023]
 [16.396837]
 [13.180764]
 [18.003662]
 [17.127796]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [29. 10.  0.  3. 14.  3.  1.  3. 11. 11.  0.  8.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3 16 29  3  3 11  8 11 14  3 10  3  6  8  8  0 14 10  0  1
  0  0  0  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 29. 30. 24. 30.  8.  8.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0] -> size -> 4 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.10832107067108154
desired expected reward: 17.258487701416016



buy possibilites: [-1] 
expected returns: [[17.781496]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [29. 10.  0.  3. 14.  3.  1.  3. 11. 11.  0.  8.  3.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3 16 29  3  3 11  8 11 14  3 10  3  6  8  8  0 14 10  0  1
  0  0  0  3  6] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 29. 30. 24. 30.  8.  7.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0] -> size -> 4 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -285.0 

action type: buy - action 6.0
Learning step: -8.75871753692627
desired expected reward: 4.422045707702637






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [0. 8. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 24. 30.  8.  7.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [14.  6.  0.  0.  8.] 
adversary cards in discard: [29. 10.  0.  3. 14.  3.  1.  3. 11. 11.  0.  8.  3.  6. 16.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3 16 29  3  3 11  8 11 14  3 10  3  6  8  8  0 14 10  0  1
  0  0  0  3  6] -> size -> 29 
adversary victory points: 5
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 24. 30.  8.  7.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [14.  6.  0.  0.  8.] 
adversary cards in discard: [29. 10.  0.  3. 14.  3.  1.  3. 11. 11.  0.  8.  3.  6. 16.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3 16 29  3  3 11  8 11 14  3 10  3  6  8  8  0 14 10  0  1
  0  0  0  3  6] -> size -> 29 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 29. 30. 24. 30.  8.  7.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [14.  6.  0.  0.  8.] 
adversary cards in discard: [29. 10.  0.  3. 14.  3.  1.  3. 11. 11.  0.  8.  3.  6. 16.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3 16 29  3  3 11  8 11 14  3 10  3  6  8  8  0 14 10  0  1
  0  0  0  3  6] -> size -> 29 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 0 0] -> size -> 4 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 29. 30. 24. 30.  8.  7.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [14.  6.  0.  0.  8.] 
adversary cards in discard: [29. 10.  0.  3. 14.  3.  1.  3. 11. 11.  0.  8.  3.  6. 16.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3 16 29  3  3 11  8 11 14  3 10  3  6  8  8  0 14 10  0  1
  0  0  0  3  6] -> size -> 29 
adversary victory points: 5
player victory points: 0 





Player: 0 
cards in hand: [14.  6.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
expected returns: [[14.332235 ]
 [12.57262  ]
 [15.2768135]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6.  0.  0.  8.] 
cards in discard: [29. 10.  0.  3. 14.  3.  1.  3. 11. 11.  0.  8.  3.  6. 16.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 16 29  3  3 11  8 11 14  3 10  3  6  8  8  0 14 10  0  1
  0  0  0  3  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 24. 30.  8.  7.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0] -> size -> 4 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.533197820186615
desired expected reward: 17.24829864501953



action possibilites: [-1] 
expected returns: [[14.421242]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0.] 
cards in discard: [29. 10.  0.  3. 14.  3.  1.  3. 11. 11.  0.  8.  3.  6. 16.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 16 29  3  3 11  8 11  3 10  3  6  8  8  0 14 10  0  1  0
  0  0  3  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 24. 30.  8.  7.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0] -> size -> 4 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 2
Learning step: 0.25162285566329956
desired expected reward: 11.911630630493164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[12.985743]
 [13.7532  ]
 [10.432409]
 [15.415541]
 [14.513604]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [29. 10.  0.  3. 14.  3.  1.  3. 11. 11.  0.  8.  3.  6. 16.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 16 29  3  3 11  8 11  3 10  3  6  8  8  0 14 10  0  1  0
  0  0  3  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 29. 30. 24. 30.  8.  7.  8.  7.  1. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0] -> size -> 4 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.1624642163515091
desired expected reward: 14.58370590209961



buy possibilites: [-1] 
expected returns: [[15.458937]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [29. 10.  0.  3. 14.  3.  1.  3. 11. 11.  0.  8.  3.  6. 16.  0.  3.  0.
  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 16 29  3  3 11  8 11  3 10  3  6  8  8  0 14 10  0  1  0
  0  0  3  6  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 24. 30.  8.  7.  8.  7.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0] -> size -> 4 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 23 

action type: buy - action 8.0
Learning step: 0.3898526430130005
desired expected reward: 15.805391311645508






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [0. 8. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 24. 30.  8.  7.  8.  7.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  8. 10.] 
adversary cards in discard: [29. 10.  0.  3. 14.  3.  1.  3. 11. 11.  0.  8.  3.  6. 16.  0.  3.  0.
  8.  8.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 16 29  3  3 11  8 11  3 10  3  6  8  8  0 14 10  0  1  0
  0  0  3  6  8] -> size -> 29 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 29. 30. 24. 30.  8.  7.  8.  7.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  8. 10.] 
adversary cards in discard: [29. 10.  0.  3. 14.  3.  1.  3. 11. 11.  0.  8.  3.  6. 16.  0.  3.  0.
  8.  8.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 16 29  3  3 11  8 11  3 10  3  6  8  8  0 14 10  0  1  0
  0  0  3  6  8] -> size -> 29 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 8.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 3] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 23. 30.  8.  7.  8.  7.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  8. 10.] 
adversary cards in discard: [29. 10.  0.  3. 14.  3.  1.  3. 11. 11.  0.  8.  3.  6. 16.  0.  3.  0.
  8.  8.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 16 29  3  3 11  8 11  3 10  3  6  8  8  0 14 10  0  1  0
  0  0  3  6  8] -> size -> 29 
adversary victory points: 5
player victory points: 1 





Player: 0 
cards in hand: [ 0.  3.  0.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[12.890549]
 [13.650091]
 [12.725567]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  8. 10.] 
cards in discard: [29. 10.  0.  3. 14.  3.  1.  3. 11. 11.  0.  8.  3.  6. 16.  0.  3.  0.
  8.  8.  6.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 16 29  3  3 11  8 11  3 10  3  6  8  8  0 14 10  0  1  0
  0  0  3  6  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 23. 30.  8.  7.  8.  7.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 3] -> size -> 5 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.47504478693008423
desired expected reward: 14.983891487121582



action possibilites: [-1.  8.] 
expected returns: [[14.2773285]
 [15.115025 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8. 3.] 
cards in discard: [29. 10.  0.  3. 14.  3.  1.  3. 11. 11.  0.  8.  3.  6. 16.  0.  3.  0.
  8.  8.  6.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 16 29  3  3 11  8 11  3 10  3  6  8  8  0 14 10  0  1  0
  0  0  3  6  8] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 23. 30.  8.  7.  8.  7.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 3] -> size -> 5 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.22552813589572906
desired expected reward: 12.880904197692871





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[13.089282]
 [13.768336]
 [10.870047]
 [14.418171]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 8. 3.] 
cards in discard: [29. 10.  0.  3. 14.  3.  1.  3. 11. 11.  0.  8.  3.  6. 16.  0.  3.  0.
  8.  8.  6.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 16 29  3  3 11  8 11  3 10  3  6  8  8  0 14 10  0  1  0
  0  0  3  6  8] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 29. 30. 23. 30.  8.  7.  8.  7.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 3] -> size -> 5 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.16146457195281982
desired expected reward: 14.438793182373047






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [0. 8. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 8. 3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 3] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 23. 30.  8.  7.  8.  7.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [11.  3.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 16 29  3  3 11  8 11  3 10  3  6  8  8  0 14 10  0  1  0
  0  0  3  6  8] -> size -> 29 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 8. 3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 3] -> size -> 5 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 29. 30. 23. 30.  8.  7.  8.  7.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [11.  3.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 16 29  3  3 11  8 11  3 10  3  6  8  8  0 14 10  0  1  0
  0  0  3  6  8] -> size -> 29 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 8. 3.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 3 3] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 22. 30.  8.  7.  8.  7.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [11.  3.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 16 29  3  3 11  8 11  3 10  3  6  8  8  0 14 10  0  1  0
  0  0  3  6  8] -> size -> 29 
adversary victory points: 5
player victory points: 2 





Player: 0 
cards in hand: [11.  3.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[10.168989]
 [11.800949]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  6.  0.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 16 29  3  3 11  8 11  3 10  3  6  8  8  0 14 10  0  1  0
  0  0  3  6  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 22. 30.  8.  7.  8.  7.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 8. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 3 3] -> size -> 6 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.4642285704612732
desired expected reward: 13.95394229888916



action possibilites: [-1] 
expected returns: [[12.747497]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 0.] 
cards in discard: [11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 16 29  3  3 11  8 11  3 10  3  6  8  8  0 14 10  0  1  0
  0  0  3  6  8 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 22. 30.  8.  7.  8.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 8. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 3 3] -> size -> 6 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 5
Learning step: 0.5779851078987122
desired expected reward: 9.773439407348633





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[11.494659 ]
 [12.2181835]
 [ 9.064567 ]
 [12.907695 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0.] 
cards in discard: [11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 16 29  3  3 11  8 11  3 10  3  6  8  8  0 14 10  0  1  0
  0  0  3  6  8 11] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 29. 30. 22. 30.  8.  7.  8.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 8. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 3 3] -> size -> 6 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.19061997532844543
desired expected reward: 12.938117027282715



buy possibilites: [-1] 
expected returns: [[10.328341]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0.] 
cards in discard: [11.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 16 29  3  3 11  8 11  3 10  3  6  8  8  0 14 10  0  1  0
  0  0  3  6  8 11  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 29. 30. 22. 30.  8.  7.  8.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 8. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 3 3] -> size -> 6 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: 0.2136078029870987
desired expected reward: 11.708267211914062






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [3. 0. 8. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 8. 3.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 3 3] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 22. 30.  8.  7.  8.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29.  6.  3.  0.] 
adversary cards in discard: [11.  0. 11.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 16 29  3  3 11  8 11  3 10  3  6  8  8  0 14 10  0  1  0
  0  0  3  6  8 11  0] -> size -> 31 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 8. 3.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 3 3] -> size -> 6 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 29. 30. 22. 30.  8.  7.  8.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29.  6.  3.  0.] 
adversary cards in discard: [11.  0. 11.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 16 29  3  3 11  8 11  3 10  3  6  8  8  0 14 10  0  1  0
  0  0  3  6  8 11  0] -> size -> 31 
adversary victory points: 5
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 29.  6.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[12.983091]
 [14.909091]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  6.  3.  0.] 
cards in discard: [11.  0. 11.  3.  6.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 16 29  3  3 11  8 11  3 10  3  6  8  8  0 14 10  0  1  0
  0  0  3  6  8 11  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 22. 30.  8.  7.  8.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [3. 8. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 3 3] -> size -> 6 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3105449676513672
desired expected reward: 10.01779556274414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[11.595896 ]
 [12.366976 ]
 [ 9.141802 ]
 [13.1257305]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  6.  3.  0.] 
cards in discard: [11.  0. 11.  3.  6.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 16 29  3  3 11  8 11  3 10  3  6  8  8  0 14 10  0  1  0
  0  0  3  6  8 11  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 29. 30. 22. 30.  8.  7.  8.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [3. 8. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 3 3] -> size -> 6 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.41711992025375366
desired expected reward: 12.641807556152344



buy possibilites: [-1] 
expected returns: [[12.042559]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  6.  3.  0.] 
cards in discard: [11.  0. 11.  3.  6.  0.  0.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 16 29  3  3 11  8 11  3 10  3  6  8  8  0 14 10  0  1  0
  0  0  3  6  8 11  0  6] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 29. 30. 22. 30.  8.  6.  8.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [3. 8. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 3 3] -> size -> 6 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.297806739807129
desired expected reward: -0.1560039520263672






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [3. 8. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 8. 3. 0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 3 3] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 22. 30.  8.  6.  8.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 8. 1. 3.] 
adversary cards in discard: [11.  0. 11.  3.  6.  0.  0.  6.  0. 29.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3 16 29  3  3 11  8 11  3 10  3  6  8  8  0 14 10  0  1  0
  0  0  3  6  8 11  0  6] -> size -> 32 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 8. 3. 0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 3 3] -> size -> 6 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 29. 30. 22. 30.  8.  6.  8.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 8. 1. 3.] 
adversary cards in discard: [11.  0. 11.  3.  6.  0.  0.  6.  0. 29.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3 16 29  3  3 11  8 11  3 10  3  6  8  8  0 14 10  0  1  0
  0  0  3  6  8 11  0  6] -> size -> 32 
adversary victory points: 4
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 8. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[17.772997]
 [18.769634]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 1. 3.] 
cards in discard: [11.  0. 11.  3.  6.  0.  0.  6.  0. 29.  6.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 16 29  3  3 11  8 11  3 10  3  6  8  8  0 14 10  0  1  0
  0  0  3  6  8 11  0  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 22. 30.  8.  6.  8.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [8. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 3 3] -> size -> 6 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.31847167015075684
desired expected reward: 11.72408676147461



action possibilites: [-1] 
expected returns: [[8.657914]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [11.  0. 11.  3.  6.  0.  0.  6.  0. 29.  6.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 16 29  3  3 11  8 11  3 10  3  6  8  8  0 14 10  0  0  0  0  3  6
  8 11  0  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 22. 30.  8.  6.  8.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [8. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 3 3] -> size -> 6 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 10
Learning step: 0.012117404490709305
desired expected reward: 17.638473510742188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[7.5245886]
 [5.523128 ]
 [8.720981 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [11.  0. 11.  3.  6.  0.  0.  6.  0. 29.  6.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 16 29  3  3 11  8 11  3 10  3  6  8  8  0 14 10  0  0  0  0  3  6
  8 11  0  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 29. 30. 22. 30.  8.  6.  8.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [8. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 3 3] -> size -> 6 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.26952898502349854
desired expected reward: 8.927443504333496






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [8. 8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 3 3] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 22. 30.  8.  6.  8.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [16. 14.  3.  8.  3.] 
adversary cards in discard: [11.  0. 11.  3.  6.  0.  0.  6.  0. 29.  6.  3.  0.  8.] 
adversary owned cards: [ 0  3 16 29  3  3 11  8 11  3 10  3  6  8  8  0 14 10  0  0  0  0  3  6
  8 11  0  6] -> size -> 28 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 0 3 3] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 22. 30.  8.  6.  8.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [16. 14.  3.  8.  3.] 
adversary cards in discard: [11.  0. 11.  3.  6.  0.  0.  6.  0. 29.  6.  3.  0.  8.] 
adversary owned cards: [ 0  3 16 29  3  3 11  8 11  3 10  3  6  8  8  0 14 10  0  0  0  0  3  6
  8 11  0  6] -> size -> 28 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 0 3 3] -> size -> 5 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 29. 30. 22. 30.  8.  6.  8.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [16. 14.  3.  8.  3.] 
adversary cards in discard: [11.  0. 11.  3.  6.  0.  0.  6.  0. 29.  6.  3.  0.  8.] 
adversary owned cards: [ 0  3 16 29  3  3 11  8 11  3 10  3  6  8  8  0 14 10  0  0  0  0  3  6
  8 11  0  6] -> size -> 28 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [16. 14.  3.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14.  8.] 
expected returns: [[14.9364395]
 [14.050987 ]
 [13.35593  ]
 [15.843475 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 14.  3.  8.  3.] 
cards in discard: [11.  0. 11.  3.  6.  0.  0.  6.  0. 29.  6.  3.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 16 29  3  3 11  8 11  3 10  3  6  8  8  0 14 10  0  0  0  0  3  6
  8 11  0  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 22. 30.  8.  6.  8.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 3. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 3 3] -> size -> 5 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.25592130422592163
desired expected reward: 8.465058326721191



action possibilites: [-1] 
expected returns: [[14.325733]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [11.  0. 11.  3.  6.  0.  0.  6.  0. 29.  6.  3.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 29  3  3 11  8 11  3 10  3  6  8  8  0 10  0  0  0  0  3  6  8 11  0
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 22. 30.  8.  6.  8.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 3. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 3 3] -> size -> 5 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 9
Learning step: 0.08545909821987152
desired expected reward: 17.250829696655273





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[12.8926525]
 [10.42709  ]
 [14.397383 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [11.  0. 11.  3.  6.  0.  0.  6.  0. 29.  6.  3.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 29  3  3 11  8 11  3 10  3  6  8  8  0 10  0  0  0  0  3  6  8 11  0
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 29. 30. 22. 30.  8.  6.  8.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 3. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 3 3] -> size -> 5 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.15607045590877533
desired expected reward: 14.481803894042969






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [0. 8. 3. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 8. 3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 3 3] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 22. 30.  8.  6.  8.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  0.  3. 10. 11.] 
adversary cards in discard: [11.  0. 11.  3.  6.  0.  0.  6.  0. 29.  6.  3.  0.  8.  8.  3.] 
adversary owned cards: [ 0 29  3  3 11  8 11  3 10  3  6  8  8  0 10  0  0  0  0  3  6  8 11  0
  6] -> size -> 25 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 8. 3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 3 3] -> size -> 5 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 29. 30. 22. 30.  8.  6.  8.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  0.  3. 10. 11.] 
adversary cards in discard: [11.  0. 11.  3.  6.  0.  0.  6.  0. 29.  6.  3.  0.  8.  8.  3.] 
adversary owned cards: [ 0 29  3  3 11  8 11  3 10  3  6  8  8  0 10  0  0  0  0  3  6  8 11  0
  6] -> size -> 25 
adversary victory points: 2
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 8.  0.  3. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11.] 
expected returns: [[13.185158 ]
 [14.136456 ]
 [13.0504875]
 [14.904451 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3. 10. 11.] 
cards in discard: [11.  0. 11.  3.  6.  0.  0.  6.  0. 29.  6.  3.  0.  8.  8.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29  3  3 11  8 11  3 10  3  6  8  8  0 10  0  0  0  0  3  6  8 11  0
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 22. 30.  8.  6.  8.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [8. 3. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 3 3] -> size -> 5 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.4341333508491516
desired expected reward: 13.963251113891602



action possibilites: [-1] 
expected returns: [[9.602816]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3. 10.] 
cards in discard: [11.  0. 11.  3.  6.  0.  0.  6.  0. 29.  6.  3.  0.  8.  8.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 29  3  3 11  8 11  3 10  3  6  8  8  0 10  0  0  0  0  3  6  8 11  0
  6  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 21. 30.  8.  6.  8.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [8. 3. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 3 3] -> size -> 5 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 19 

action type: gain_card_n - action 2
Learning step: 0.3463071286678314
desired expected reward: 11.16372013092041





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[8.314428]
 [6.133326]
 [9.659164]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3. 10.] 
cards in discard: [11.  0. 11.  3.  6.  0.  0.  6.  0. 29.  6.  3.  0.  8.  8.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 29  3  3 11  8 11  3 10  3  6  8  8  0 10  0  0  0  0  3  6  8 11  0
  6  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 29. 30. 21. 30.  8.  6.  8.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [8. 3. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 3 3] -> size -> 5 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.24969914555549622
desired expected reward: 9.85251522064209






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [8. 3. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 3 3] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 21. 30.  8.  6.  8.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [11.  3.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29  3  3 11  8 11  3 10  3  6  8  8  0 10  0  0  0  0  3  6  8 11  0
  6  3] -> size -> 26 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 3 3] -> size -> 5 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 29. 30. 21. 30.  8.  6.  8.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [11.  3.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29  3  3 11  8 11  3 10  3  6  8  8  0 10  0  0  0  0  3  6  8 11  0
  6  3] -> size -> 26 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 8. 0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 3 3 0] -> size -> 6 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 29. 30. 21. 30.  8.  6.  8.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [11.  3.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29  3  3 11  8 11  3 10  3  6  8  8  0 10  0  0  0  0  3  6  8 11  0
  6  3] -> size -> 26 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [11.  3.  0.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 10.] 
expected returns: [[3.4839284]
 [4.4805493]
 [4.0347366]
 [3.4043112]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  8. 10.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29  3  3 11  8 11  3 10  3  6  8  8  0 10  0  0  0  0  3  6  8 11  0
  6  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 21. 30.  8.  6.  8.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [8. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 3 3 0] -> size -> 6 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.3978162109851837
desired expected reward: 9.26134967803955



action possibilites: [-1] 
expected returns: [[5.1588297]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  3 11  8 11  3 10  3  6  8  8  0 10  0  0  0  0  3  6  8 11  0  6  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 21. 30.  8.  6.  8.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [8. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 3 3 0] -> size -> 6 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 9
Learning step: 0.35441991686820984
desired expected reward: 5.346011638641357





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[4.3926616]
 [2.9066453]
 [5.246924 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  3 11  8 11  3 10  3  6  8  8  0 10  0  0  0  0  3  6  8 11  0  6  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 29. 30. 21. 30.  8.  6.  8.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [8. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 3 3 0] -> size -> 6 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.3413831293582916
desired expected reward: 5.500212669372559



buy possibilites: [-1] 
expected returns: [[4.9060407]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.] 
cards in discard: [6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  3 11  8 11  3 10  3  6  8  8  0 10  0  0  0  0  3  6  8 11  0  6  3
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 21. 30.  8.  5.  8.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [8. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 3 3 0] -> size -> 6 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -285 

action type: buy - action 6.0
Learning step: -8.585685729980469
desired expected reward: -5.679040431976318






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [8. 0. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 3 3 0] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 21. 30.  8.  5.  8.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  3.  0. 10.  0.] 
adversary cards in discard: [ 6.  8. 11. 10.] 
adversary owned cards: [29  3 11  8 11  3 10  3  6  8  8  0 10  0  0  0  0  3  6  8 11  0  6  3
  6] -> size -> 25 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 3 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 21. 30.  8.  5.  8.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  3.  0. 10.  0.] 
adversary cards in discard: [ 6.  8. 11. 10.] 
adversary owned cards: [29  3 11  8 11  3 10  3  6  8  8  0 10  0  0  0  0  3  6  8 11  0  6  3
  6] -> size -> 25 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 3 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 29. 30. 21. 30.  8.  5.  8.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  3.  0. 10.  0.] 
adversary cards in discard: [ 6.  8. 11. 10.] 
adversary owned cards: [29  3 11  8 11  3 10  3  6  8  8  0 10  0  0  0  0  3  6  8 11  0  6  3
  6] -> size -> 25 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 3 0 0] -> size -> 4 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 29. 30. 21. 30.  8.  5.  8.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  3.  0. 10.  0.] 
adversary cards in discard: [ 6.  8. 11. 10.] 
adversary owned cards: [29  3 11  8 11  3 10  3  6  8  8  0 10  0  0  0  0  3  6  8 11  0  6  3
  6] -> size -> 25 
adversary victory points: 1
player victory points: 1 





Player: 0 
cards in hand: [ 8.  3.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[2.0572164]
 [2.4144616]
 [2.0048418]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0. 10.  0.] 
cards in discard: [ 6.  8. 11. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [29  3 11  8 11  3 10  3  6  8  8  0 10  0  0  0  0  3  6  8 11  0  6  3
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 21. 30.  8.  5.  8.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0 0] -> size -> 4 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.27367883920669556
desired expected reward: 4.632361888885498





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[1.6271524]
 [1.9027272]
 [0.7028029]
 [2.162909 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  0. 10.  0.] 
cards in discard: [ 6.  8. 11. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [29  3 11  8 11  3 10  3  6  8  8  0 10  0  0  0  0  3  6  8 11  0  6  3
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 29. 30. 21. 30.  8.  5.  8.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0 0] -> size -> 4 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.19455429911613464
desired expected reward: 1.8896842002868652



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [0. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 21. 30.  8.  5.  8.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [29. 11.  6.  6.  3.] 
adversary cards in discard: [ 6.  8. 11. 10.  8.  3.  0. 10.  0.] 
adversary owned cards: [29  3 11  8 11  3 10  3  6  8  8  0 10  0  0  0  0  3  6  8 11  0  6  3
  6] -> size -> 25 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 3] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 21. 30.  8.  5.  8.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [29. 11.  6.  6.  3.] 
adversary cards in discard: [ 6.  8. 11. 10.  8.  3.  0. 10.  0.] 
adversary owned cards: [29  3 11  8 11  3 10  3  6  8  8  0 10  0  0  0  0  3  6  8 11  0  6  3
  6] -> size -> 25 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 3] -> size -> 2 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 29. 30. 21. 30.  8.  5.  8.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [29. 11.  6.  6.  3.] 
adversary cards in discard: [ 6.  8. 11. 10.  8.  3.  0. 10.  0.] 
adversary owned cards: [29  3 11  8 11  3 10  3  6  8  8  0 10  0  0  0  0  3  6  8 11  0  6  3
  6] -> size -> 25 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 3 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 29. 30. 21. 30.  8.  5.  8.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [29. 11.  6.  6.  3.] 
adversary cards in discard: [ 6.  8. 11. 10.  8.  3.  0. 10.  0.] 
adversary owned cards: [29  3 11  8 11  3 10  3  6  8  8  0 10  0  0  0  0  3  6  8 11  0  6  3
  6] -> size -> 25 
adversary victory points: 1
player victory points: 1 





Player: 0 
cards in hand: [29. 11.  6.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[8.011259]
 [9.290571]
 [9.219847]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  6.  6.  3.] 
cards in discard: [ 6.  8. 11. 10.  8.  3.  0. 10.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [29  3 11  8 11  3 10  3  6  8  8  0 10  0  0  0  0  3  6  8 11  0  6  3
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 29. 30. 21. 30.  8.  5.  8.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0] -> size -> 3 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.12021584808826447
desired expected reward: 2.0426928997039795





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[7.103706 ]
 [5.3436446]
 [8.112408 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11.  6.  6.  3.] 
cards in discard: [ 6.  8. 11. 10.  8.  3.  0. 10.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [29  3 11  8 11  3 10  3  6  8  8  0 10  0  0  0  0  3  6  8 11  0  6  3
  6] -> size -> 25 
action values: 1 
buys: 1 
player value: 0 
card supply: [11. 29. 30. 21. 30.  8.  5.  8.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0] -> size -> 3 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.3182123899459839
desired expected reward: 7.775646209716797



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 29. 30. 21. 30.  8.  5.  8.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  8.] 
adversary cards in discard: [ 6.  8. 11. 10.  8.  3.  0. 10.  0. 29. 11.  6.  6.  3.] 
adversary owned cards: [29  3 11  8 11  3 10  3  6  8  8  0 10  0  0  0  0  3  6  8 11  0  6  3
  6] -> size -> 25 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 29. 30. 21. 30.  8.  5.  8.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  8.] 
adversary cards in discard: [ 6.  8. 11. 10.  8.  3.  0. 10.  0. 29. 11.  6.  6.  3.] 
adversary owned cards: [29  3 11  8 11  3 10  3  6  8  8  0 10  0  0  0  0  3  6  8 11  0  6  3
  6] -> size -> 25 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 0] -> size -> 4 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 29. 30. 21. 30.  8.  5.  8.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  8.] 
adversary cards in discard: [ 6.  8. 11. 10.  8.  3.  0. 10.  0. 29. 11.  6.  6.  3.] 
adversary owned cards: [29  3 11  8 11  3 10  3  6  8  8  0 10  0  0  0  0  3  6  8 11  0  6  3
  6] -> size -> 25 
adversary victory points: 1
player victory points: 1 





Player: 0 
cards in hand: [ 0. 11.  3.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[10.185198]
 [11.866177]
 [11.115868]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0.  8.] 
cards in discard: [ 6.  8. 11. 10.  8.  3.  0. 10.  0. 29. 11.  6.  6.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [29  3 11  8 11  3 10  3  6  8  8  0 10  0  0  0  0  3  6  8 11  0  6  3
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 21. 30.  8.  5.  8.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0 0] -> size -> 4 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.2746506929397583
desired expected reward: 7.837757110595703



action possibilites: [-1] 
expected returns: [[9.002943]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8.] 
cards in discard: [ 6.  8. 11. 10.  8.  3.  0. 10.  0. 29. 11.  6.  6.  3. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [29  3 11  8 11  3 10  3  6  8  8  0 10  0  0  0  0  3  6  8 11  0  6  3
  6 16] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 21. 30.  8.  5.  7.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0 0] -> size -> 4 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 4
Learning step: 0.8074488639831543
desired expected reward: 8.04351806640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[7.8667707]
 [8.484806 ]
 [5.8082366]
 [9.046709 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 8.] 
cards in discard: [ 6.  8. 11. 10.  8.  3.  0. 10.  0. 29. 11.  6.  6.  3. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [29  3 11  8 11  3 10  3  6  8  8  0 10  0  0  0  0  3  6  8 11  0  6  3
  6 16] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 29. 30. 21. 30.  8.  5.  7.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0 0] -> size -> 4 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.2644434869289398
desired expected reward: 9.267386436462402






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 21. 30.  8.  5.  7.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 8. 3. 3.] 
adversary cards in discard: [ 6.  8. 11. 10.  8.  3.  0. 10.  0. 29. 11.  6.  6.  3. 16. 11.  0.  3.
  0.  8.] 
adversary owned cards: [29  3 11  8 11  3 10  3  6  8  8  0 10  0  0  0  0  3  6  8 11  0  6  3
  6 16] -> size -> 26 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 21. 30.  8.  5.  7.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 8. 3. 3.] 
adversary cards in discard: [ 6.  8. 11. 10.  8.  3.  0. 10.  0. 29. 11.  6.  6.  3. 16. 11.  0.  3.
  0.  8.] 
adversary owned cards: [29  3 11  8 11  3 10  3  6  8  8  0 10  0  0  0  0  3  6  8 11  0  6  3
  6 16] -> size -> 26 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 29. 30. 21. 30.  8.  5.  7.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 8. 3. 3.] 
adversary cards in discard: [ 6.  8. 11. 10.  8.  3.  0. 10.  0. 29. 11.  6.  6.  3. 16. 11.  0.  3.
  0.  8.] 
adversary owned cards: [29  3 11  8 11  3 10  3  6  8  8  0 10  0  0  0  0  3  6  8 11  0  6  3
  6 16] -> size -> 26 
adversary victory points: 1
player victory points: 1 





Player: 0 
cards in hand: [6. 0. 8. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[13.142791]
 [14.134679]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 3. 3.] 
cards in discard: [ 6.  8. 11. 10.  8.  3.  0. 10.  0. 29. 11.  6.  6.  3. 16. 11.  0.  3.
  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [29  3 11  8 11  3 10  3  6  8  8  0 10  0  0  0  0  3  6  8 11  0  6  3
  6 16] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 21. 30.  8.  5.  7.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.276607483625412
desired expected reward: 8.770102500915527



action possibilites: [-1] 
expected returns: [[8.657069]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3.] 
cards in discard: [ 6.  8. 11. 10.  8.  3.  0. 10.  0. 29. 11.  6.  6.  3. 16. 11.  0.  3.
  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 11  8 11  3 10  3  6  8  8 10  0  0  0  0  3  6  8 11  0  6  3  6 16] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 21. 30.  8.  5.  7.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 3
Learning step: 0.16736780107021332
desired expected reward: 12.618414878845215





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[7.498478 ]
 [5.5538793]
 [8.615754 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3.] 
cards in discard: [ 6.  8. 11. 10.  8.  3.  0. 10.  0. 29. 11.  6.  6.  3. 16. 11.  0.  3.
  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 11  8 11  3 10  3  6  8  8 10  0  0  0  0  3  6  8 11  0  6  3  6 16] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 29. 30. 21. 30.  8.  5.  7.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.2690517008304596
desired expected reward: 8.92612075805664






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 21. 30.  8.  5.  7.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 10. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29 11  8 11  3 10  3  6  8  8 10  0  0  0  0  3  6  8 11  0  6  3  6 16] -> size -> 24 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [10. 29. 30. 21. 30.  8.  5.  7.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 10. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29 11  8 11  3 10  3  6  8  8 10  0  0  0  0  3  6  8 11  0  6  3  6 16] -> size -> 24 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 29. 30. 21. 30.  8.  5.  7.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 10. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29 11  8 11  3 10  3  6  8  8 10  0  0  0  0  3  6  8 11  0  6  3  6 16] -> size -> 24 
adversary victory points: 0
player victory points: 0 





Player: 0 
cards in hand: [ 3. 10. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[5.2785435]
 [5.20174  ]
 [6.3887215]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [29 11  8 11  3 10  3  6  8  8 10  0  0  0  0  3  6  8 11  0  6  3  6 16] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 29. 30. 21. 30.  8.  5.  7.  6.  0. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.3465534746646881
desired expected reward: 8.269200325012207



action possibilites: [-1] 
expected returns: [[6.6201906]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  0.] 
cards in discard: [15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [29 11  8 11  3 10  3  6  8  8 10  0  0  0  0  3  6  8 11  0  6  3  6 16
 15] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 29. 30. 21. 30.  8.  5.  7.  6.  0. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 9
Learning step: 0.7819674015045166
desired expected reward: 8.033452987670898





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[5.7006307]
 [4.1306396]
 [6.6396613]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  0.] 
cards in discard: [15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [29 11  8 11  3 10  3  6  8  8 10  0  0  0  0  3  6  8 11  0  6  3  6 16
 15] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 29. 30. 21. 30.  8.  5.  7.  6.  0. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.31145617365837097
desired expected reward: 6.931646823883057



buy possibilites: [-1] 
expected returns: [[5.038202]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  0.] 
cards in discard: [15.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [29 11  8 11  3 10  3  6  8  8 10  0  0  0  0  3  6  8 11  0  6  3  6 16
 15  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 29. 30. 21. 30.  8.  5.  7.  6.  0. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: 0.33188217878341675
desired expected reward: 6.03251314163208






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 29. 30. 21. 30.  8.  5.  7.  6.  0. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 8. 8.] 
adversary cards in discard: [15.  0. 11.  3. 10.  3.  0.] 
adversary owned cards: [29 11  8 11  3 10  3  6  8  8 10  0  0  0  0  3  6  8 11  0  6  3  6 16
 15  0] -> size -> 26 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 29. 30. 21. 30.  8.  5.  7.  6.  0. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 8. 8.] 
adversary cards in discard: [15.  0. 11.  3. 10.  3.  0.] 
adversary owned cards: [29 11  8 11  3 10  3  6  8  8 10  0  0  0  0  3  6  8 11  0  6  3  6 16
 15  0] -> size -> 26 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 29. 30. 21. 30.  8.  5.  7.  6.  0. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 8. 8.] 
adversary cards in discard: [15.  0. 11.  3. 10.  3.  0.] 
adversary owned cards: [29 11  8 11  3 10  3  6  8  8 10  0  0  0  0  3  6  8 11  0  6  3  6 16
 15  0] -> size -> 26 
adversary victory points: 0
player victory points: 0 





Player: 0 
cards in hand: [0. 0. 3. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[5.315971]
 [5.914401]
 [5.914401]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 8.] 
cards in discard: [15.  0. 11.  3. 10.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [29 11  8 11  3 10  3  6  8  8 10  0  0  0  0  3  6  8 11  0  6  3  6 16
 15  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 29. 30. 21. 30.  8.  5.  7.  6.  0. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.2399393767118454
desired expected reward: 4.798262596130371



action possibilites: [-1] 
expected returns: [[5.1559157]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [15.  0. 11.  3. 10.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 11  8 11 10  3  6  8  8 10  0  0  3  6  8 11  0  6  3  6 16 15  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 29. 30. 21. 30.  8.  5.  7.  6.  0. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 9
Learning step: 0.28414803743362427
desired expected reward: 7.6171183586120605





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[4.178945 ]
 [2.8283412]
 [5.0368776]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [15.  0. 11.  3. 10.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 11  8 11 10  3  6  8  8 10  0  0  3  6  8 11  0  6  3  6 16 15  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 29. 30. 21. 30.  8.  5.  7.  6.  0. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.3396236300468445
desired expected reward: 5.49553918838501






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 29. 30. 21. 30.  8.  5.  7.  6.  0. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0. 16.  6. 10.] 
adversary cards in discard: [15.  0. 11.  3. 10.  3.  0.  8.  8.] 
adversary owned cards: [29 11  8 11 10  3  6  8  8 10  0  0  3  6  8 11  0  6  3  6 16 15  0] -> size -> 23 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 8. 29. 30. 21. 30.  8.  5.  7.  6.  0. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0. 16.  6. 10.] 
adversary cards in discard: [15.  0. 11.  3. 10.  3.  0.  8.  8.] 
adversary owned cards: [29 11  8 11 10  3  6  8  8 10  0  0  3  6  8 11  0  6  3  6 16 15  0] -> size -> 23 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 29. 30. 21. 30.  8.  5.  7.  6.  0. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0. 16.  6. 10.] 
adversary cards in discard: [15.  0. 11.  3. 10.  3.  0.  8.  8.] 
adversary owned cards: [29 11  8 11 10  3  6  8  8 10  0  0  3  6  8 11  0  6  3  6 16 15  0] -> size -> 23 
adversary victory points: -1
player victory points: 0 





Player: 0 
cards in hand: [11.  0. 16.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16. 10.] 
expected returns: [[ 8.597415 ]
 [10.036231 ]
 [ 7.9086075]
 [ 8.506484 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 16.  6. 10.] 
cards in discard: [15.  0. 11.  3. 10.  3.  0.  8.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [29 11  8 11 10  3  6  8  8 10  0  0  3  6  8 11  0  6  3  6 16 15  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 29. 30. 21. 30.  8.  5.  7.  6.  0. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.20744717121124268
desired expected reward: 4.89089298248291





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[7.6359696]
 [5.7516904]
 [8.73811  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 16.  6. 10.] 
cards in discard: [15.  0. 11.  3. 10.  3.  0.  8.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [29 11  8 11 10  3  6  8  8 10  0  0  3  6  8 11  0  6  3  6 16 15  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 29. 30. 21. 30.  8.  5.  7.  6.  0. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.3302058279514313
desired expected reward: 8.353394508361816



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 29. 30. 21. 30.  8.  5.  7.  6.  0. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  0.  6. 29. 11.] 
adversary cards in discard: [15.  0. 11.  3. 10.  3.  0.  8.  8. 11.  0. 16.  6. 10.] 
adversary owned cards: [29 11  8 11 10  3  6  8  8 10  0  0  3  6  8 11  0  6  3  6 16 15  0] -> size -> 23 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 29. 30. 21. 30.  8.  5.  7.  6.  0. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  0.  6. 29. 11.] 
adversary cards in discard: [15.  0. 11.  3. 10.  3.  0.  8.  8. 11.  0. 16.  6. 10.] 
adversary owned cards: [29 11  8 11 10  3  6  8  8 10  0  0  3  6  8 11  0  6  3  6 16 15  0] -> size -> 23 
adversary victory points: -1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 8.  0.  6. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 11.] 
expected returns: [[ 9.007909]
 [ 9.765269]
 [10.436257]
 [10.361182]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  6. 29. 11.] 
cards in discard: [15.  0. 11.  3. 10.  3.  0.  8.  8. 11.  0. 16.  6. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [29 11  8 11 10  3  6  8  8 10  0  0  3  6  8 11  0  6  3  6 16 15  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 29. 30. 21. 30.  8.  5.  7.  6.  0. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.30653467774391174
desired expected reward: 8.431575775146484



action possibilites: [-1.  8. 11.] 
expected returns: [[10.54226 ]
 [11.380726]
 [12.043916]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.  6.] 
cards in discard: [15.  0. 11.  3. 10.  3.  0.  8.  8. 11.  0. 16.  6. 10.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 11  8 11 10  3  6  8  8 10  0  0  3  6  8 11  0  6  3  6 16 15  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 7. 29. 30. 21. 30.  8.  5.  7.  6.  0. 10.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 2
Learning step: 0.3521624505519867
desired expected reward: 7.62673282623291



action possibilites: [-1] 
expected returns: [[15.673898]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6.] 
cards in discard: [15.  0. 11.  3. 10.  3.  0.  8.  8. 11.  0. 16.  6. 10.  6. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [29 11  8 11 10  3  6  8  8 10  0  0  3  6  8 11  0  6  3  6 16 15  0 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 29. 30. 21. 30.  8.  5.  7.  6.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  9  0] 
sum of rewards: 44 

action type: gain_card_n - action 8
Learning step: 1.1430821418762207
desired expected reward: 12.526208877563477





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[14.291303]
 [15.000379]
 [11.98105 ]
 [15.631494]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6.] 
cards in discard: [15.  0. 11.  3. 10.  3.  0.  8.  8. 11.  0. 16.  6. 10.  6. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [29 11  8 11 10  3  6  8  8 10  0  0  3  6  8 11  0  6  3  6 16 15  0 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 29. 30. 21. 30.  8.  5.  7.  6.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.7321080565452576
desired expected reward: 16.406005859375






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 29. 30. 21. 30.  8.  5.  7.  6.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [10.  0.  6.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29 11  8 11 10  3  6  8  8 10  0  0  3  6  8 11  0  6  3  6 16 15  0 10] -> size -> 24 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 29. 30. 21. 30.  8.  5.  7.  6.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [10.  0.  6.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29 11  8 11 10  3  6  8  8 10  0  0  3  6  8 11  0  6  3  6 16 15  0 10] -> size -> 24 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 7. 29. 30. 21. 30.  8.  5.  7.  6.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [10.  0.  6.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29 11  8 11 10  3  6  8  8 10  0  0  3  6  8 11  0  6  3  6 16 15  0 10] -> size -> 24 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 29. 30. 21. 30.  8.  5.  7.  6.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [10.  0.  6.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29 11  8 11 10  3  6  8  8 10  0  0  3  6  8 11  0  6  3  6 16 15  0 10] -> size -> 24 
adversary victory points: -1
player victory points: 0 





Player: 0 
cards in hand: [10.  0.  6.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[3.0577457]
 [2.9945664]
 [3.592096 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  6.  3.  8.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [29 11  8 11 10  3  6  8  8 10  0  0  3  6  8 11  0  6  3  6 16 15  0 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 29. 30. 21. 30.  8.  5.  7.  6.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.583521842956543
desired expected reward: 15.047971725463867



action possibilites: [-1] 
expected returns: [[1.707179]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 11  8 11 10  8  8 10  0  3  6  8 11  0  6  3  6 16 15  0 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 29. 30. 21. 30.  8.  5.  7.  6.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 12
Learning step: 0.37955015897750854
desired expected reward: 3.325390338897705





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[1.1874484 ]
 [0.40551654]
 [1.6646299 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 11  8 11 10  8  8 10  0  3  6  8 11  0  6  3  6 16 15  0 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 6. 29. 30. 21. 30.  8.  5.  7.  6.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.411401629447937
desired expected reward: 2.1185805797576904






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 29. 30. 21. 30.  8.  5.  7.  6.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  0.  6.] 
adversary cards in discard: [ 8. 10.] 
adversary owned cards: [29 11  8 11 10  8  8 10  0  3  6  8 11  0  6  3  6 16 15  0 10] -> size -> 21 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 29. 30. 21. 30.  8.  5.  7.  6.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  0.  6.] 
adversary cards in discard: [ 8. 10.] 
adversary owned cards: [29 11  8 11 10  8  8 10  0  3  6  8 11  0  6  3  6 16 15  0 10] -> size -> 21 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 6. 29. 30. 21. 30.  8.  5.  7.  6.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  0.  6.] 
adversary cards in discard: [ 8. 10.] 
adversary owned cards: [29 11  8 11 10  8  8 10  0  3  6  8 11  0  6  3  6 16 15  0 10] -> size -> 21 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 29. 30. 21. 30.  8.  5.  7.  6.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  0.  6.] 
adversary cards in discard: [ 8. 10.] 
adversary owned cards: [29 11  8 11 10  8  8 10  0  3  6  8 11  0  6  3  6 16 15  0 10] -> size -> 21 
adversary victory points: -1
player victory points: 0 





Player: 0 
cards in hand: [ 0. 11.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[4.411985 ]
 [5.3429003]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  6.] 
cards in discard: [ 8. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [29 11  8 11 10  8  8 10  0  3  6  8 11  0  6  3  6 16 15  0 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 29. 30. 21. 30.  8.  5.  7.  6.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.14676138758659363
desired expected reward: 1.5178685188293457





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[3.793673 ]
 [4.7464347]
 [4.175791 ]
 [2.562712 ]
 [5.457538 ]
 [4.4614563]
 [4.5228915]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.  6.] 
cards in discard: [ 8. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [29 11  8 11 10  8  8 10  0  3  6  8 11  0  6  3  6 16 15  0 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 29. 30. 21. 30.  8.  5.  7.  6.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.2378750741481781
desired expected reward: 4.262141704559326



buy possibilites: [-1] 
expected returns: [[4.4293222]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.  6.] 
cards in discard: [ 8. 10. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [29 11  8 11 10  8  8 10  0  3  6  8 11  0  6  3  6 16 15  0 10 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 29. 30. 21. 30.  8.  5.  7.  5.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: 0.27278169989585876
desired expected reward: 5.730319976806641






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 29. 30. 21. 30.  8.  5.  7.  5.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [11.  6.  3. 11. 10.] 
adversary cards in discard: [ 8. 10. 11.  0. 11.  0.  0.  6.] 
adversary owned cards: [29 11  8 11 10  8  8 10  0  3  6  8 11  0  6  3  6 16 15  0 10 11] -> size -> 22 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 29. 30. 21. 30.  8.  5.  7.  5.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [11.  6.  3. 11. 10.] 
adversary cards in discard: [ 8. 10. 11.  0. 11.  0.  0.  6.] 
adversary owned cards: [29 11  8 11 10  8  8 10  0  3  6  8 11  0  6  3  6 16 15  0 10 11] -> size -> 22 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 5. 29. 30. 21. 30.  8.  5.  7.  5.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [11.  6.  3. 11. 10.] 
adversary cards in discard: [ 8. 10. 11.  0. 11.  0.  0.  6.] 
adversary owned cards: [29 11  8 11 10  8  8 10  0  3  6  8 11  0  6  3  6 16 15  0 10 11] -> size -> 22 
adversary victory points: -1
player victory points: 0 





Player: 0 
cards in hand: [11.  6.  3. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10.] 
expected returns: [[2.3336968]
 [3.1665337]
 [3.1665337]
 [2.2798002]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  3. 11. 10.] 
cards in discard: [ 8. 10. 11.  0. 11.  0.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [29 11  8 11 10  8  8 10  0  3  6  8 11  0  6  3  6 16 15  0 10 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 29. 30. 21. 30.  8.  5.  7.  5.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.2528242766857147
desired expected reward: 4.176497936248779



action possibilites: [-1] 
expected returns: [[4.952243]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 11. 10.] 
cards in discard: [ 8. 10. 11.  0. 11.  0.  0.  6.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [29 11  8 11 10  8  8 10  0  3  6  8 11  0  6  3  6 16 15  0 10 11  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 21. 30.  8.  5.  7.  5.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 1
Learning step: 0.6936671733856201
desired expected reward: 3.3047118186950684





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[4.056269 ]
 [2.5351465]
 [4.9686584]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 11. 10.] 
cards in discard: [ 8. 10. 11.  0. 11.  0.  0.  6.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [29 11  8 11 10  8  8 10  0  3  6  8 11  0  6  3  6 16 15  0 10 11  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 5. 28. 30. 21. 30.  8.  5.  7.  5.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.3442350924015045
desired expected reward: 5.296477794647217



buy possibilites: [-1] 
expected returns: [[6.8704844]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 11. 10.] 
cards in discard: [ 8. 10. 11.  0. 11.  0.  0.  6.  1.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [29 11  8 11 10  8  8 10  0  3  6  8 11  0  6  3  6 16 15  0 10 11  1  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 21. 30.  8.  5.  7.  5.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: buy - action 0.0
Learning step: 0.40045198798179626
desired expected reward: 4.456721305847168






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 21. 30.  8.  5.  7.  5.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  8.  6. 15.  8.] 
adversary cards in discard: [ 8. 10. 11.  0. 11.  0.  0.  6.  1.  0. 11.  6.  3. 11. 10.] 
adversary owned cards: [29 11  8 11 10  8  8 10  0  3  6  8 11  0  6  3  6 16 15  0 10 11  1  0] -> size -> 24 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 21. 30.  8.  5.  7.  5.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  8.  6. 15.  8.] 
adversary cards in discard: [ 8. 10. 11.  0. 11.  0.  0.  6.  1.  0. 11.  6.  3. 11. 10.] 
adversary owned cards: [29 11  8 11 10  8  8 10  0  3  6  8 11  0  6  3  6 16 15  0 10 11  1  0] -> size -> 24 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 4. 28. 30. 21. 30.  8.  5.  7.  5.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  8.  6. 15.  8.] 
adversary cards in discard: [ 8. 10. 11.  0. 11.  0.  0.  6.  1.  0. 11.  6.  3. 11. 10.] 
adversary owned cards: [29 11  8 11 10  8  8 10  0  3  6  8 11  0  6  3  6 16 15  0 10 11  1  0] -> size -> 24 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 21. 30.  8.  5.  7.  5.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  8.  6. 15.  8.] 
adversary cards in discard: [ 8. 10. 11.  0. 11.  0.  0.  6.  1.  0. 11.  6.  3. 11. 10.] 
adversary owned cards: [29 11  8 11 10  8  8 10  0  3  6  8 11  0  6  3  6 16 15  0 10 11  1  0] -> size -> 24 
adversary victory points: -1
player victory points: 0 





Player: 0 
cards in hand: [ 8.  8.  6. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 15.  8.] 
expected returns: [[8.482268]
 [9.221124]
 [9.221124]
 [8.639661]
 [9.221124]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  6. 15.  8.] 
cards in discard: [ 8. 10. 11.  0. 11.  0.  0.  6.  1.  0. 11.  6.  3. 11. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [29 11  8 11 10  8  8 10  0  3  6  8 11  0  6  3  6 16 15  0 10 11  1  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 21. 30.  8.  5.  7.  5.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.2611364424228668
desired expected reward: 6.609347820281982





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[7.549298 ]
 [5.7669473]
 [8.567733 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8.  6. 15.  8.] 
cards in discard: [ 8. 10. 11.  0. 11.  0.  0.  6.  1.  0. 11.  6.  3. 11. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [29 11  8 11 10  8  8 10  0  3  6  8 11  0  6  3  6 16 15  0 10 11  1  0] -> size -> 24 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 3. 28. 30. 21. 30.  8.  5.  7.  5.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.3262775242328644
desired expected reward: 8.191885948181152



buy possibilites: [-1] 
expected returns: [[7.34485]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8.  6. 15.  8.] 
cards in discard: [ 8. 10. 11.  0. 11.  0.  0.  6.  1.  0. 11.  6.  3. 11. 10.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [29 11  8 11 10  8  8 10  0  3  6  8 11  0  6  3  6 16 15  0 10 11  1  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 28. 30. 21. 30.  8.  5.  7.  5.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action 0.0
Learning step: -0.29935798048973083
desired expected reward: 7.24993896484375






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 28. 30. 21. 30.  8.  5.  7.  5.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [11. 10. 16.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 11  8 11 10  8  8 10  0  3  6  8 11  0  6  3  6 16 15  0 10 11  1  0
  0] -> size -> 25 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 28. 30. 21. 30.  8.  5.  7.  5.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [11. 10. 16.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 11  8 11 10  8  8 10  0  3  6  8 11  0  6  3  6 16 15  0 10 11  1  0
  0] -> size -> 25 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 2. 28. 30. 21. 30.  8.  5.  7.  5.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [11. 10. 16.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 11  8 11 10  8  8 10  0  3  6  8 11  0  6  3  6 16 15  0 10 11  1  0
  0] -> size -> 25 
adversary victory points: -1
player victory points: 0 





Player: 0 
cards in hand: [11. 10. 16.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 16. 29.] 
expected returns: [[2.5809238]
 [3.444147 ]
 [2.5345237]
 [2.1934526]
 [3.4950523]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 16.  3. 29.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [29 11  8 11 10  8  8 10  0  3  6  8 11  0  6  3  6 16 15  0 10 11  1  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 28. 30. 21. 30.  8.  5.  7.  5.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.33809301257133484
desired expected reward: 7.0067572593688965



action possibilites: [-1] 
expected returns: [[3.3067498]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 29.] 
cards in discard: [16.] 
cards in deck: 20 
card top of deck: [] 
played cards: [16.] 
owned cards: [29 11  8 11 10  8  8 10  0  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0
 16] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 28. 30. 21. 30.  8.  5.  6.  5.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 4
Learning step: 0.927177906036377
desired expected reward: 2.1786105632781982





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[2.3662071]
 [1.2416855]
 [3.1328046]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 29.] 
cards in discard: [16.] 
cards in deck: 20 
card top of deck: [] 
played cards: [16.] 
owned cards: [29 11  8 11 10  8  8 10  0  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0
 16] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 2. 28. 30. 21. 30.  8.  5.  6.  5.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.37625032663345337
desired expected reward: 3.683000087738037



buy possibilites: [-1] 
expected returns: [[2.4322526]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 29.] 
cards in discard: [16.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [16.] 
owned cards: [29 11  8 11 10  8  8 10  0  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0
 16  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 28. 30. 21. 30.  8.  5.  6.  5.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: buy - action 0.0
Learning step: 0.4045524299144745
desired expected reward: 2.770759344100952






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 28. 30. 21. 30.  8.  5.  6.  5.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [6. 8. 6. 0. 8.] 
adversary cards in discard: [16.  0. 16. 11. 10. 29.] 
adversary owned cards: [29 11  8 11 10  8  8 10  0  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0
 16  0] -> size -> 26 
adversary victory points: -2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 28. 30. 21. 30.  8.  5.  6.  5.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [6. 8. 6. 0. 8.] 
adversary cards in discard: [16.  0. 16. 11. 10. 29.] 
adversary owned cards: [29 11  8 11 10  8  8 10  0  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0
 16  0] -> size -> 26 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 1. 28. 30. 21. 30.  8.  5.  6.  5.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [6. 8. 6. 0. 8.] 
adversary cards in discard: [16.  0. 16. 11. 10. 29.] 
adversary owned cards: [29 11  8 11 10  8  8 10  0  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0
 16  0] -> size -> 26 
adversary victory points: -2
player victory points: 0 





Player: 0 
cards in hand: [6. 8. 6. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[6.038119 ]
 [6.6699457]
 [6.6699457]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 6. 0. 8.] 
cards in discard: [16.  0. 16. 11. 10. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [29 11  8 11 10  8  8 10  0  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0
 16  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 28. 30. 21. 30.  8.  5.  6.  5.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.15369389951229095
desired expected reward: 2.2785587310791016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[5.213191 ]
 [3.6653965]
 [6.1007104]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 6. 0. 8.] 
cards in discard: [16.  0. 16. 11. 10. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [29 11  8 11 10  8  8 10  0  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0
 16  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 28. 30. 21. 30.  8.  5.  6.  5.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.27921029925346375
desired expected reward: 5.8529181480407715



buy possibilites: [-1] 
expected returns: [[5.813506]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 6. 0. 8.] 
cards in discard: [16.  0. 16. 11. 10. 29.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [29 11  8 11 10  8  8 10  0  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0
 16  0  6] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 28. 30. 21. 30.  8.  4.  6.  5.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.198143005371094
desired expected reward: -5.532747268676758






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 28. 30. 21. 30.  8.  4.  6.  5.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [10.  0. 10.  1.  8.] 
adversary cards in discard: [16.  0. 16. 11. 10. 29.  6.  6.  8.  6.  0.  8.] 
adversary owned cards: [29 11  8 11 10  8  8 10  0  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0
 16  0  6] -> size -> 27 
adversary victory points: -3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 28. 30. 21. 30.  8.  4.  6.  5.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [10.  0. 10.  1.  8.] 
adversary cards in discard: [16.  0. 16. 11. 10. 29.  6.  6.  8.  6.  0.  8.] 
adversary owned cards: [29 11  8 11 10  8  8 10  0  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0
 16  0  6] -> size -> 27 
adversary victory points: -3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 1. 28. 30. 21. 30.  8.  4.  6.  5.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [10.  0. 10.  1.  8.] 
adversary cards in discard: [16.  0. 16. 11. 10. 29.  6.  6.  8.  6.  0.  8.] 
adversary owned cards: [29 11  8 11 10  8  8 10  0  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0
 16  0  6] -> size -> 27 
adversary victory points: -3
player victory points: 0 





Player: 0 
cards in hand: [10.  0. 10.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.  8.] 
expected returns: [[8.007442 ]
 [7.9520993]
 [7.9520993]
 [8.698627 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  1.  8.] 
cards in discard: [16.  0. 16. 11. 10. 29.  6.  6.  8.  6.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [29 11  8 11 10  8  8 10  0  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0
 16  0  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 28. 30. 21. 30.  8.  4.  6.  5.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.23701517283916473
desired expected reward: 5.576490879058838



action possibilites: [-1. 10.  8.] 
expected returns: [[8.176221]
 [8.112732]
 [8.966908]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  1.  8.  0.] 
cards in discard: [16.  0. 16. 11. 10. 29.  6.  6.  8.  6.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [29 11  8 11 10  8  8 10  0  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0
 16  0  6] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 1. 28. 30. 21. 30.  8.  4.  6.  5.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.29917678236961365
desired expected reward: 8.311514854431152





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[7.176474 ]
 [8.413233 ]
 [7.6397114]
 [5.7056355]
 [7.4987082]
 [9.392857 ]
 [9.464235 ]
 [7.035517 ]
 [8.020172 ]
 [8.243876 ]
 [8.0793   ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  1.  8.  0.] 
cards in discard: [16.  0. 16. 11. 10. 29.  6.  6.  8.  6.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [29 11  8 11 10  8  8 10  0  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0
 16  0  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 1. 28. 30. 21. 30.  8.  4.  6.  5.  0. 10.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.290772408246994
desired expected reward: 8.46699333190918



buy possibilites: [-1] 
expected returns: [[9.069256]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  1.  8.  0.] 
cards in discard: [16.  0. 16. 11. 10. 29.  6.  6.  8.  6.  0.  8. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [29 11  8 11 10  8  8 10  0  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0
 16  0  6 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 28. 30. 21. 30.  8.  4.  6.  5.  0. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 32  0] 
sum of rewards: 47 

action type: buy - action 15.0
Learning step: 1.2579108476638794
desired expected reward: 9.501787185668945






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 28. 30. 21. 30.  8.  4.  6.  5.  0. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [11.  6. 11. 15.  0.] 
adversary cards in discard: [16.  0. 16. 11. 10. 29.  6.  6.  8.  6.  0.  8. 15. 10.  0. 10.  1.  8.
  0.] 
adversary owned cards: [29 11  8 11 10  8  8 10  0  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0
 16  0  6 15] -> size -> 28 
adversary victory points: -3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 1. 28. 30. 21. 30.  8.  4.  6.  5.  0. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [11.  6. 11. 15.  0.] 
adversary cards in discard: [16.  0. 16. 11. 10. 29.  6.  6.  8.  6.  0.  8. 15. 10.  0. 10.  1.  8.
  0.] 
adversary owned cards: [29 11  8 11 10  8  8 10  0  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0
 16  0  6 15] -> size -> 28 
adversary victory points: -3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 21. 30.  8.  4.  6.  5.  0. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [11.  6. 11. 15.  0.] 
adversary cards in discard: [16.  0. 16. 11. 10. 29.  6.  6.  8.  6.  0.  8. 15. 10.  0. 10.  1.  8.
  0.] 
adversary owned cards: [29 11  8 11 10  8  8 10  0  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0
 16  0  6 15] -> size -> 28 
adversary victory points: -3
player victory points: 0 





Player: 0 
cards in hand: [11.  6. 11. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 15.] 
expected returns: [[10.121485]
 [11.389571]
 [11.389571]
 [10.285761]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6. 11. 15.  0.] 
cards in discard: [16.  0. 16. 11. 10. 29.  6.  6.  8.  6.  0.  8. 15. 10.  0. 10.  1.  8.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [29 11  8 11 10  8  8 10  0  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0
 16  0  6 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 21. 30.  8.  4.  6.  5.  0. 10.  9.  8. 10.  6. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3066398799419403
desired expected reward: 8.762616157531738



action possibilites: [-1] 
expected returns: [[5.8019037]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11. 15.  0.] 
cards in discard: [16.  0. 16. 11. 10. 29.  6.  6.  8.  6.  0.  8. 15. 10.  0. 10.  1.  8.
  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [29 11  8 11 10  8  8 10  0  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0
 16  0  6 15 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 21. 30.  8.  4.  6.  5.  0. 10.  9.  8. 10.  5. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 7
Learning step: 0.520588219165802
desired expected reward: 9.198312759399414





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[3.591714]
 [5.775357]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11. 15.  0.] 
cards in discard: [16.  0. 16. 11. 10. 29.  6.  6.  8.  6.  0.  8. 15. 10.  0. 10.  1.  8.
  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [29 11  8 11 10  8  8 10  0  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0
 16  0  6 15 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 28. 30. 21. 30.  8.  4.  6.  5.  0. 10.  9.  8. 10.  5. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.32741278409957886
desired expected reward: 6.129316329956055



buy possibilites: [-1] 
expected returns: [[5.313075]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11. 15.  0.] 
cards in discard: [16.  0. 16. 11. 10. 29.  6.  6.  8.  6.  0.  8. 15. 10.  0. 10.  1.  8.
  0. 10.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [29 11  8 11 10  8  8 10  0  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0
 16  0  6 15 10  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 28. 30. 21. 30.  8.  3.  6.  5.  0. 10.  9.  8. 10.  5. 10.  8.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -285.0 

action type: buy - action 6.0
Learning step: -8.60196304321289
desired expected reward: -5.010249137878418






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 21. 30.  8.  3.  6.  5.  0. 10.  9.  8. 10.  5. 10.  8.] 
adversary cards in hand: [11.  0. 11.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29 11  8 11 10  8  8 10  0  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0
 16  0  6 15 10  6] -> size -> 30 
adversary victory points: -4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 21. 30.  8.  3.  6.  5.  0. 10.  9.  8. 10.  5. 10.  8.] 
adversary cards in hand: [11.  0. 11.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29 11  8 11 10  8  8 10  0  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0
 16  0  6 15 10  6] -> size -> 30 
adversary victory points: -4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 21. 30.  8.  3.  6.  5.  0. 10.  9.  8. 10.  5. 10.  8.] 
adversary cards in hand: [11.  0. 11.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29 11  8 11 10  8  8 10  0  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0
 16  0  6 15 10  6] -> size -> 30 
adversary victory points: -4
player victory points: 0 





Player: 0 
cards in hand: [11.  0. 11.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8.] 
expected returns: [[2.3968718]
 [3.1721776]
 [3.1721776]
 [2.811784 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11.  3.  8.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [29 11  8 11 10  8  8 10  0  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0
 16  0  6 15 10  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 21. 30.  8.  3.  6.  5.  0. 10.  9.  8. 10.  5. 10.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.27757295966148376
desired expected reward: 5.035501956939697



action possibilites: [-1] 
expected returns: [[3.5335188]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  8.] 
cards in discard: [15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [29 11  8 11 10  8  8 10  0  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0
 16  0  6 15 10  6 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 21. 30.  8.  3.  6.  5.  0. 10.  9.  8. 10.  5. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 8
Learning step: 0.8801689743995667
desired expected reward: 3.7779343128204346





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[1.7681855]
 [3.5749097]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  8.] 
cards in discard: [15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [29 11  8 11 10  8  8 10  0  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0
 16  0  6 15 10  6 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 28. 30. 21. 30.  8.  3.  6.  5.  0. 10.  9.  8. 10.  5. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.3739427328109741
desired expected reward: 3.907461643218994






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 21. 30.  8.  3.  6.  5.  0. 10.  9.  8. 10.  5. 10.  7.] 
adversary cards in hand: [ 0.  8. 10. 10. 16.] 
adversary cards in discard: [15. 11.  0. 11.  3.  8.] 
adversary owned cards: [29 11  8 11 10  8  8 10  0  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0
 16  0  6 15 10  6 15] -> size -> 31 
adversary victory points: -4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 21. 30.  8.  3.  6.  5.  0. 10.  9.  8. 10.  5. 10.  7.] 
adversary cards in hand: [ 0.  8. 10. 10. 16.] 
adversary cards in discard: [15. 11.  0. 11.  3.  8.] 
adversary owned cards: [29 11  8 11 10  8  8 10  0  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0
 16  0  6 15 10  6 15] -> size -> 31 
adversary victory points: -4
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  8. 10. 10. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10. 16.] 
expected returns: [[3.7908738]
 [4.3768315]
 [3.744386 ]
 [3.744386 ]
 [3.3272152]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10. 10. 16.] 
cards in discard: [15. 11.  0. 11.  3.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [29 11  8 11 10  8  8 10  0  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0
 16  0  6 15 10  6 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 21. 30.  8.  3.  6.  5.  0. 10.  9.  8. 10.  5. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.21529558300971985
desired expected reward: 3.359614372253418



action possibilites: [-1] 
expected returns: [[3.3588915]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 16.] 
cards in discard: [15. 11.  0. 11.  3.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 11  8 11 10  8  8 10  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0 16
  0  6 15 10  6 15] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 21. 30.  8.  3.  6.  5.  0. 10.  9.  8. 10.  5. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 0
Learning step: 0.387573778629303
desired expected reward: 3.618021249771118





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[1.5322019]
 [3.2461576]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 16.] 
cards in discard: [15. 11.  0. 11.  3.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 11  8 11 10  8  8 10  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0 16
  0  6 15 10  6 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 21. 30.  8.  3.  6.  5.  0. 10.  9.  8. 10.  5. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.3761192858219147
desired expected reward: 3.735010862350464



buy possibilites: [-1] 
expected returns: [[4.8731885]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 16.] 
cards in discard: [15. 11.  0. 11.  3.  8.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 11  8 11 10  8  8 10  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0 16
  0  6 15 10  6 15  6] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 21. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  5. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -5 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -285 

action type: buy - action 6.0
Learning step: -8.54479694366455
desired expected reward: -7.012595176696777






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 21. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  5. 10.  7.] 
adversary cards in hand: [10.  0. 29.  0.  6.] 
adversary cards in discard: [15. 11.  0. 11.  3.  8.  6.  8. 10. 10. 16.] 
adversary owned cards: [29 11  8 11 10  8  8 10  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0 16
  0  6 15 10  6 15  6] -> size -> 31 
adversary victory points: -5
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 21. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  5. 10.  7.] 
adversary cards in hand: [10.  0. 29.  0.  6.] 
adversary cards in discard: [15. 11.  0. 11.  3.  8.  6.  8. 10. 10. 16.] 
adversary owned cards: [29 11  8 11 10  8  8 10  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0 16
  0  6 15 10  6 15  6] -> size -> 31 
adversary victory points: -5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 21. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  5. 10.  7.] 
adversary cards in hand: [10.  0. 29.  0.  6.] 
adversary cards in discard: [15. 11.  0. 11.  3.  8.  6.  8. 10. 10. 16.] 
adversary owned cards: [29 11  8 11 10  8  8 10  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0 16
  0  6 15 10  6 15  6] -> size -> 31 
adversary victory points: -5
player victory points: 0 





Player: 0 
cards in hand: [10.  0. 29.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[7.3296914]
 [7.27883  ]
 [8.745014 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29.  0.  6.] 
cards in discard: [15. 11.  0. 11.  3.  8.  6.  8. 10. 10. 16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [29 11  8 11 10  8  8 10  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0 16
  0  6 15 10  6 15  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 21. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  5. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.211409792304039
desired expected reward: 4.661778926849365



action possibilites: [-1. 10.] 
expected returns: [[4.801187 ]
 [4.7549534]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  6.] 
cards in discard: [15. 11.  0. 11.  3.  8.  6.  8. 10. 10. 16.  0.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 11  8 11 10  8  8 10  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0 16
  0  6 15 10  6 15  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 0. 28. 30. 21. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  5. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0.2674582600593567
desired expected reward: 8.02612590789795





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. -1.] 
expected returns: [[4.343697 ]
 [2.5552921]
 [4.724441 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  6.] 
cards in discard: [15. 11.  0. 11.  3.  8.  6.  8. 10. 10. 16.  0.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 11  8 11 10  8  8 10  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0 16
  0  6 15 10  6 15  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 28. 30. 21. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  5. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.348431259393692
desired expected reward: 5.149618625640869






         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 21. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  5. 10.  7.] 
adversary cards in hand: [16.  8. 10.  6.  6.] 
adversary cards in discard: [15. 11.  0. 11.  3.  8.  6.  8. 10. 10. 16.  0.  6. 29. 10.  0.  6.] 
adversary owned cards: [29 11  8 11 10  8  8 10  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0 16
  0  6 15 10  6 15  6] -> size -> 31 
adversary victory points: -5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 21. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  5. 10.  7.] 
adversary cards in hand: [16.  8. 10.  6.  6.] 
adversary cards in discard: [15. 11.  0. 11.  3.  8.  6.  8. 10. 10. 16.  0.  6. 29. 10.  0.  6.] 
adversary owned cards: [29 11  8 11 10  8  8 10  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0 16
  0  6 15 10  6 15  6] -> size -> 31 
adversary victory points: -5
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [16.  8. 10.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 10.] 
expected returns: [[ 9.672816]
 [ 9.020252]
 [10.481504]
 [ 9.618067]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8. 10.  6.  6.] 
cards in discard: [15. 11.  0. 11.  3.  8.  6.  8. 10. 10. 16.  0.  6. 29. 10.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [29 11  8 11 10  8  8 10  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0 16
  0  6 15 10  6 15  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 21. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  5. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.18766427040100098
desired expected reward: 4.536776542663574



action possibilites: [-1] 
expected returns: [[6.561192]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  6.] 
cards in discard: [15. 11.  0. 11.  3.  8.  6.  8. 10. 10. 16.  0.  6. 29. 10.  0.  6. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [29 11 11 10  8  8 10  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0 16  0
  6 15 10  6 15  6 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 21. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  4. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 7
Learning step: 0.6177181005477905
desired expected reward: 6.323533058166504





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[4.139483 ]
 [6.4737506]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  6.] 
cards in discard: [15. 11.  0. 11.  3.  8.  6.  8. 10. 10. 16.  0.  6. 29. 10.  0.  6. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [29 11 11 10  8  8 10  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0 16  0
  6 15 10  6 15  6 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 21. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  4. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.31133466958999634
desired expected reward: 6.8725266456604






         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 21. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  4. 10.  7.] 
adversary cards in hand: [11.  8.  1. 15. 15.] 
adversary cards in discard: [15. 11.  0. 11.  3.  8.  6.  8. 10. 10. 16.  0.  6. 29. 10.  0.  6. 10.
 16. 10.  6.  6.] 
adversary owned cards: [29 11 11 10  8  8 10  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0 16  0
  6 15 10  6 15  6 10] -> size -> 31 
adversary victory points: -5
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 21. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  4. 10.  7.] 
adversary cards in hand: [11.  8.  1. 15. 15.] 
adversary cards in discard: [15. 11.  0. 11.  3.  8.  6.  8. 10. 10. 16.  0.  6. 29. 10.  0.  6. 10.
 16. 10.  6.  6.] 
adversary owned cards: [29 11 11 10  8  8 10  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0 16  0
  6 15 10  6 15  6 10] -> size -> 31 
adversary victory points: -5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 21. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  4. 10.  7.] 
adversary cards in hand: [11.  8.  1. 15. 15.] 
adversary cards in discard: [15. 11.  0. 11.  3.  8.  6.  8. 10. 10. 16.  0.  6. 29. 10.  0.  6. 10.
 16. 10.  6.  6.] 
adversary owned cards: [29 11 11 10  8  8 10  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0 16  0
  6 15 10  6 15  6 10] -> size -> 31 
adversary victory points: -5
player victory points: 0 





Player: 0 
cards in hand: [11.  8.  1. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 15. 15.] 
expected returns: [[11.498934]
 [13.082775]
 [12.406054]
 [11.712206]
 [11.712206]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  1. 15. 15.] 
cards in discard: [15. 11.  0. 11.  3.  8.  6.  8. 10. 10. 16.  0.  6. 29. 10.  0.  6. 10.
 16. 10.  6.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [29 11 11 10  8  8 10  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0 16  0
  6 15 10  6 15  6 10] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 21. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  4. 10.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.21523982286453247
desired expected reward: 6.258510112762451



action possibilites: [-1] 
expected returns: [[10.790396]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1. 15. 15.] 
cards in discard: [15. 11.  0. 11.  3.  8.  6.  8. 10. 10. 16.  0.  6. 29. 10.  0.  6. 10.
 16. 10.  6.  6. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [29 11 11 10  8  8 10  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0 16  0
  6 15 10  6 15  6 10 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 21. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  4. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 8
Learning step: 0.6710332632064819
desired expected reward: 13.07989501953125





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. -1.] 
expected returns: [[10.295034]
 [ 7.855281]
 [10.778869]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1. 15. 15.] 
cards in discard: [15. 11.  0. 11.  3.  8.  6.  8. 10. 10. 16.  0.  6. 29. 10.  0.  6. 10.
 16. 10.  6.  6. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [29 11 11 10  8  8 10  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0 16  0
  6 15 10  6 15  6 10 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 28. 30. 21. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  4. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.2299254685640335
desired expected reward: 11.020320892333984



buy possibilites: [-1] 
expected returns: [[10.584478]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1. 15. 15.] 
cards in discard: [15. 11.  0. 11.  3.  8.  6.  8. 10. 10. 16.  0.  6. 29. 10.  0.  6. 10.
 16. 10.  6.  6. 15.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [29 11 11 10  8  8 10  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0 16  0
  6 15 10  6 15  6 10 15  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 20. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  4. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 23 

action type: buy - action 3.0
Learning step: 0.4893134832382202
desired expected reward: 10.784347534179688






         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 20. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  4. 10.  6.] 
adversary cards in hand: [ 1.  6.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [29 11 11 10  8  8 10  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0 16  0
  6 15 10  6 15  6 10 15  3] -> size -> 33 
adversary victory points: -4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 20. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  4. 10.  6.] 
adversary cards in hand: [ 1.  6.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [29 11 11 10  8  8 10  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0 16  0
  6 15 10  6 15  6 10 15  3] -> size -> 33 
adversary victory points: -4
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 1.  6.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[3.4418666]
 [4.2532473]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [29 11 11 10  8  8 10  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0 16  0
  6 15 10  6 15  6 10 15  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 20. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  4. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.42548149824142456
desired expected reward: 10.15899658203125





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[3.771373 ]
 [3.2785878]
 [1.8411286]
 [3.1766562]
 [4.3861794]
 [4.4272366]
 [2.8428805]
 [3.5243301]
 [3.6657462]
 [3.5522602]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [29 11 11 10  8  8 10  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0 16  0
  6 15 10  6 15  6 10 15  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 28. 30. 20. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  4. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.21720024943351746
desired expected reward: 3.2977733612060547



buy possibilites: [-1] 
expected returns: [[2.89759]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6.  0.  0. 11.] 
cards in discard: [10.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [29 11 11 10  8  8 10  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0 16  0
  6 15 10  6 15  6 10 15  3 10] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 28. 30. 20. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 10.0
Learning step: -0.09030520915985107
desired expected reward: 3.434025287628174






         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 20. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [ 0.  6. 16. 11.  0.] 
adversary cards in discard: [10.  1.  6.  0.  0. 11.] 
adversary owned cards: [29 11 11 10  8  8 10  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0 16  0
  6 15 10  6 15  6 10 15  3 10] -> size -> 34 
adversary victory points: -4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 20. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [ 0.  6. 16. 11.  0.] 
adversary cards in discard: [10.  1.  6.  0.  0. 11.] 
adversary owned cards: [29 11 11 10  8  8 10  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0 16  0
  6 15 10  6 15  6 10 15  3 10] -> size -> 34 
adversary victory points: -4
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  6. 16. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
expected returns: [[6.746914 ]
 [6.20745  ]
 [7.9799156]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 16. 11.  0.] 
cards in discard: [10.  1.  6.  0.  0. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [29 11 11 10  8  8 10  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0 16  0
  6 15 10  6 15  6 10 15  3 10] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 20. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.16118356585502625
desired expected reward: 2.7364063262939453





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. -1.] 
expected returns: [[6.3369246]
 [4.339387 ]
 [6.73155  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 16. 11.  0.] 
cards in discard: [10.  1.  6.  0.  0. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [29 11 11 10  8  8 10  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0 16  0
  6 15 10  6 15  6 10 15  3 10] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 28. 30. 20. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.29073551297187805
desired expected reward: 6.4963908195495605



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 55 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 20. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [11.  6. 10. 11. 29.] 
adversary cards in discard: [10.  1.  6.  0.  0. 11.  0.  6. 16. 11.  0.] 
adversary owned cards: [29 11 11 10  8  8 10  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0 16  0
  6 15 10  6 15  6 10 15  3 10] -> size -> 34 
adversary victory points: -4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 20. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [11.  6. 10. 11. 29.] 
adversary cards in discard: [10.  1.  6.  0.  0. 11.  0.  6. 16. 11.  0.] 
adversary owned cards: [29 11 11 10  8  8 10  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0 16  0
  6 15 10  6 15  6 10 15  3 10] -> size -> 34 
adversary victory points: -4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 20. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [11.  6. 10. 11. 29.] 
adversary cards in discard: [10.  1.  6.  0.  0. 11.  0.  6. 16. 11.  0.] 
adversary owned cards: [29 11 11 10  8  8 10  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0 16  0
  6 15 10  6 15  6 10 15  3 10] -> size -> 34 
adversary victory points: -4
player victory points: 0 





Player: 0 
cards in hand: [11.  6. 10. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11. 29.] 
expected returns: [[5.399497 ]
 [6.445888 ]
 [5.3640075]
 [6.445888 ]
 [6.4983034]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6. 10. 11. 29.] 
cards in discard: [10.  1.  6.  0.  0. 11.  0.  6. 16. 11.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [29 11 11 10  8  8 10  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0 16  0
  6 15 10  6 15  6 10 15  3 10] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 20. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.2871920168399811
desired expected reward: 6.444358825683594



action possibilites: [-1. 11. 10.] 
expected returns: [[7.249141 ]
 [8.5324745]
 [7.207436 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11. 10.] 
cards in discard: [10.  1.  6.  0.  0. 11.  0.  6. 16. 11.  0. 11. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 11 11 10  8  8 10  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0 16  0
  6 15 10  6 15  6 10 15  3 10] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 0. 28. 30. 20. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0.3606516122817993
desired expected reward: 6.081849098205566





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[4.780036]
 [7.221092]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11. 10.] 
cards in discard: [10.  1.  6.  0.  0. 11.  0.  6. 16. 11.  0. 11. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 11 11 10  8  8 10  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0 16  0
  6 15 10  6 15  6 10 15  3 10] -> size -> 34 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 0. 28. 30. 20. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.29809480905532837
desired expected reward: 7.547235488891602






         -------------------- Turn: 56 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 20. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [ 6. 15.  3. 15. 16.] 
adversary cards in discard: [10.  1.  6.  0.  0. 11.  0.  6. 16. 11.  0. 11. 10. 29.  6. 11. 10.] 
adversary owned cards: [29 11 11 10  8  8 10  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0 16  0
  6 15 10  6 15  6 10 15  3 10] -> size -> 34 
adversary victory points: -4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 20. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [ 6. 15.  3. 15. 16.] 
adversary cards in discard: [10.  1.  6.  0.  0. 11.  0.  6. 16. 11.  0. 11. 10. 29.  6. 11. 10.] 
adversary owned cards: [29 11 11 10  8  8 10  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0 16  0
  6 15 10  6 15  6 10 15  3 10] -> size -> 34 
adversary victory points: -4
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 6. 15.  3. 15. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 16.] 
expected returns: [[10.608254]
 [10.785198]
 [10.785198]
 [10.025486]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  3. 15. 16.] 
cards in discard: [10.  1.  6.  0.  0. 11.  0.  6. 16. 11.  0. 11. 10. 29.  6. 11. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [29 11 11 10  8  8 10  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0 16  0
  6 15 10  6 15  6 10 15  3 10] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 20. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.2548227310180664
desired expected reward: 6.966269016265869



action possibilites: [-1] 
expected returns: [[8.229425]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 15. 16.] 
cards in discard: [10.  1.  6.  0.  0. 11.  0.  6. 16. 11.  0. 11. 10. 29.  6. 11. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [29 11 11 10  8  8 10  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0 16  0
  6 15 10  6 15  6 10 15  3 10] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 20. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: 0.21131165325641632
desired expected reward: 11.047887802124023





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[5.6588697]
 [8.263193 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 15. 16.] 
cards in discard: [10.  1.  6.  0.  0. 11.  0.  6. 16. 11.  0. 11. 10. 29.  6. 11. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [29 11 11 10  8  8 10  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0 16  0
  6 15 10  6 15  6 10 15  3 10] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 20. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.2789425849914551
desired expected reward: 8.508367538452148






         -------------------- Turn: 57 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 20. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [ 3. 15.  0.  8.  8.] 
adversary cards in discard: [10.  1.  6.  0.  0. 11.  0.  6. 16. 11.  0. 11. 10. 29.  6. 11. 10. 15.
  6.  3. 15. 16.] 
adversary owned cards: [29 11 11 10  8  8 10  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0 16  0
  6 15 10  6 15  6 10 15  3 10] -> size -> 34 
adversary victory points: -4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 20. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [ 3. 15.  0.  8.  8.] 
adversary cards in discard: [10.  1.  6.  0.  0. 11.  0.  6. 16. 11.  0. 11. 10. 29.  6. 11. 10. 15.
  6.  3. 15. 16.] 
adversary owned cards: [29 11 11 10  8  8 10  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0 16  0
  6 15 10  6 15  6 10 15  3 10] -> size -> 34 
adversary victory points: -4
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3. 15.  0.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.  8.] 
expected returns: [[13.322313]
 [13.544755]
 [14.237789]
 [14.237789]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0.  8.  8.] 
cards in discard: [10.  1.  6.  0.  0. 11.  0.  6. 16. 11.  0. 11. 10. 29.  6. 11. 10. 15.
  6.  3. 15. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [29 11 11 10  8  8 10  6  8 11  0  6  3  6 16 15  0 10 11  1  0  0 16  0
  6 15 10  6 15  6 10 15  3 10] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 20. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.2516225278377533
desired expected reward: 8.011571884155273



action possibilites: [-1] 
expected returns: [[13.473888]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 8.] 
cards in discard: [10.  1.  6.  0.  0. 11.  0.  6. 16. 11.  0. 11. 10. 29.  6. 11. 10. 15.
  6.  3. 15. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [29 11 11 10  8  8 10  6  8 11  6  3  6 16 15  0 10 11  1  0  0 16  0  6
 15 10  6 15  6 10 15  3 10] -> size -> 33 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0. 28. 30. 20. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: 0.18469204008579254
desired expected reward: 13.74415111541748





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11. 10. -1.] 
expected returns: [[14.018536]
 [12.916048]
 [ 9.988572]
 [15.380145]
 [13.460981]
 [13.523711]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 8.] 
cards in discard: [10.  1.  6.  0.  0. 11.  0.  6. 16. 11.  0. 11. 10. 29.  6. 11. 10. 15.
  6.  3. 15. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [29 11 11 10  8  8 10  6  8 11  6  3  6 16 15  0 10 11  1  0  0 16  0  6
 15 10  6 15  6 10 15  3 10] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 28. 30. 20. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.18908482789993286
desired expected reward: 13.662973403930664



buy possibilites: [-1] 
expected returns: [[14.6511755]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 8.] 
cards in discard: [10.  1.  6.  0.  0. 11.  0.  6. 16. 11.  0. 11. 10. 29.  6. 11. 10. 15.
  6.  3. 15. 16.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [29 11 11 10  8  8 10  6  8 11  6  3  6 16 15  0 10 11  1  0  0 16  0  6
 15 10  6 15  6 10 15  3 10  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 28. 30. 19. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 17.0 

action type: buy - action 3.0
Learning step: 0.2760488986968994
desired expected reward: 13.192095756530762






         -------------------- Turn: 58 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 19. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [10.  8.  6. 10. 10.] 
adversary cards in discard: [10.  1.  6.  0.  0. 11.  0.  6. 16. 11.  0. 11. 10. 29.  6. 11. 10. 15.
  6.  3. 15. 16.  3. 15.  3.  8.  8.] 
adversary owned cards: [29 11 11 10  8  8 10  6  8 11  6  3  6 16 15  0 10 11  1  0  0 16  0  6
 15 10  6 15  6 10 15  3 10  3] -> size -> 34 
adversary victory points: -3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 19. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [10.  8.  6. 10. 10.] 
adversary cards in discard: [10.  1.  6.  0.  0. 11.  0.  6. 16. 11.  0. 11. 10. 29.  6. 11. 10. 15.
  6.  3. 15. 16.  3. 15.  3.  8.  8.] 
adversary owned cards: [29 11 11 10  8  8 10  6  8 11  6  3  6 16 15  0 10 11  1  0  0 16  0  6
 15 10  6 15  6 10 15  3 10  3] -> size -> 34 
adversary victory points: -3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10.  8.  6. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 10. 10.] 
expected returns: [[15.66749  ]
 [15.6243305]
 [16.606667 ]
 [15.6243305]
 [15.6243305]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  6. 10. 10.] 
cards in discard: [10.  1.  6.  0.  0. 11.  0.  6. 16. 11.  0. 11. 10. 29.  6. 11. 10. 15.
  6.  3. 15. 16.  3. 15.  3.  8.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [29 11 11 10  8  8 10  6  8 11  6  3  6 16 15  0 10 11  1  0  0 16  0  6
 15 10  6 15  6 10 15  3 10  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 19. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4216940402984619
desired expected reward: 14.22948169708252



action possibilites: [-1.  8. 10. 10.] 
expected returns: [[16.748375]
 [17.724064]
 [16.705156]
 [16.705156]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6. 10. 10.  6.] 
cards in discard: [10.  1.  6.  0.  0. 11.  0.  6. 16. 11.  0. 11. 10. 29.  6. 11. 10. 15.
  6.  3. 15. 16.  3. 15.  3.  8.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [29 11 11 10  8  8 10  6  8 11  6  3  6 16 15  0 10 11  1  0  0 16  0  6
 15 10  6 15  6 10 15  3 10  3] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 19. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.1610444039106369
desired expected reward: 15.785374641418457



action possibilites: [-1.  8. 10. 15.] 
expected returns: [[17.24569 ]
 [18.225016]
 [17.201317]
 [17.487888]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6. 10.  6. 15.] 
cards in discard: [10.  1.  6.  0.  0. 11.  0.  6. 16. 11.  0. 11. 10. 29.  6. 11. 10. 15.
  6.  3. 15. 16.  3. 15.  3.  8.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [29 11 11 10  8  8 10  6  8 11  6  3  6 16 15  0 10 11  1  0  0 16  0  6
 15 10  6 15  6 10 15  3 10  3] -> size -> 34 
action values: 3 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 19. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 10.0
Learning step: 0.7344536185264587
desired expected reward: 17.439611434936523



action possibilites: [-1.  8. 15.] 
expected returns: [[4.0466266]
 [4.5662513]
 [4.177427 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6.  6. 15.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [10. 10. 10.] 
owned cards: [29 11 11 10  8  8 10  6  8 11  6  3  6 16 15  0 10 11  1  0  0 16  0  6
 15 10  6 15  6 10 15  3 10  3] -> size -> 34 
action values: 4 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 19. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action 10.0
Learning step: 1.1793625354766846
desired expected reward: 18.380680084228516





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[2.138259 ]
 [4.0086827]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6.  6. 15.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [10. 10. 10.] 
owned cards: [29 11 11 10  8  8 10  6  8 11  6  3  6 16 15  0 10 11  1  0  0 16  0  6
 15 10  6 15  6 10 15  3 10  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 28. 30. 19. 30.  8.  2.  6.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 1.5628365278244019
desired expected reward: 5.609463214874268



buy possibilites: [-1] 
expected returns: [[3.5716164]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6.  6. 15.  0.] 
cards in discard: [6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [10. 10. 10.] 
owned cards: [29 11 11 10  8  8 10  6  8 11  6  3  6 16 15  0 10 11  1  0  0 16  0  6
 15 10  6 15  6 10 15  3 10  3  6] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 28. 30. 19. 30.  8.  1.  6.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   60.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -245.0 

action type: buy - action 6.0
Learning step: -7.376645565032959
desired expected reward: -5.238386631011963






         -------------------- Turn: 59 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 19. 30.  8.  1.  6.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [15.  6.  1.  6. 10.] 
adversary cards in discard: [ 6. 10. 10. 10.  8.  6.  6. 15.  0.] 
adversary owned cards: [29 11 11 10  8  8 10  6  8 11  6  3  6 16 15  0 10 11  1  0  0 16  0  6
 15 10  6 15  6 10 15  3 10  3  6] -> size -> 35 
adversary victory points: -4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 19. 30.  8.  1.  6.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [15.  6.  1.  6. 10.] 
adversary cards in discard: [ 6. 10. 10. 10.  8.  6.  6. 15.  0.] 
adversary owned cards: [29 11 11 10  8  8 10  6  8 11  6  3  6 16 15  0 10 11  1  0  0 16  0  6
 15 10  6 15  6 10 15  3 10  3  6] -> size -> 35 
adversary victory points: -4
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [15.  6.  1.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
expected returns: [[6.0105057]
 [6.1883583]
 [5.9778943]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6.  1.  6. 10.] 
cards in discard: [ 6. 10. 10. 10.  8.  6.  6. 15.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [29 11 11 10  8  8 10  6  8 11  6  3  6 16 15  0 10 11  1  0  0 16  0  6
 15 10  6 15  6 10 15  3 10  3  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 19. 30.  8.  1.  6.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.19237728416919708
desired expected reward: 3.379239082336426



action possibilites: [-1. 15. 11.] 
expected returns: [[6.1623917]
 [6.325148 ]
 [7.3238626]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6.  1.  6. 11.] 
cards in discard: [ 6. 10. 10. 10.  8.  6.  6. 15.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [29 11 11 10  8  8 10  6  8 11  6  3  6 16 15  0 10 11  1  0  0 16  0  6
 15 10  6 15  6 10 15  3 10  3  6] -> size -> 35 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 19. 30.  8.  1.  6.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.3389939069747925
desired expected reward: 6.400930881500244





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. -1.] 
expected returns: [[5.7384796]
 [3.8056924]
 [6.1058254]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  6.  1.  6. 11.] 
cards in discard: [ 6. 10. 10. 10.  8.  6.  6. 15.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [29 11 11 10  8  8 10  6  8 11  6  3  6 16 15  0 10 11  1  0  0 16  0  6
 15 10  6 15  6 10 15  3 10  3  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 28. 30. 19. 30.  8.  1.  6.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.32177048921585083
desired expected reward: 6.484162330627441



buy possibilites: [-1] 
expected returns: [[7.9681287]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  6.  1.  6. 11.] 
cards in discard: [ 6. 10. 10. 10.  8.  6.  6. 15.  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [29 11 11 10  8  8 10  6  8 11  6  3  6 16 15  0 10 11  1  0  0 16  0  6
 15 10  6 15  6 10 15  3 10  3  6  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 18. 30.  8.  1.  6.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -1  0  0  8  0] 
sum of rewards: 22 

action type: buy - action 3.0
Learning step: 0.5715109705924988
desired expected reward: 6.309990406036377






         -------------------- Turn: 60 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 18. 30.  8.  1.  6.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [11. 15. 11.  0. 29.] 
adversary cards in discard: [ 6. 10. 10. 10.  8.  6.  6. 15.  0.  3. 10. 15.  6.  1.  6. 11.] 
adversary owned cards: [29 11 11 10  8  8 10  6  8 11  6  3  6 16 15  0 10 11  1  0  0 16  0  6
 15 10  6 15  6 10 15  3 10  3  6  3] -> size -> 36 
adversary victory points: -3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 18. 30.  8.  1.  6.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [11. 15. 11.  0. 29.] 
adversary cards in discard: [ 6. 10. 10. 10.  8.  6.  6. 15.  0.  3. 10. 15.  6.  1.  6. 11.] 
adversary owned cards: [29 11 11 10  8  8 10  6  8 11  6  3  6 16 15  0 10 11  1  0  0 16  0  6
 15 10  6 15  6 10 15  3 10  3  6  3] -> size -> 36 
adversary victory points: -3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11. 15. 11.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 11. 29.] 
expected returns: [[6.7482038]
 [7.9004173]
 [6.916585 ]
 [7.9004173]
 [7.956224 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15. 11.  0. 29.] 
cards in discard: [ 6. 10. 10. 10.  8.  6.  6. 15.  0.  3. 10. 15.  6.  1.  6. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [29 11 11 10  8  8 10  6  8 11  6  3  6 16 15  0 10 11  1  0  0 16  0  6
 15 10  6 15  6 10 15  3 10  3  6  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 18. 30.  8.  1.  6.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.30932915210723877
desired expected reward: 7.658799648284912



action possibilites: [-1. 11. 10.] 
expected returns: [[10.916414]
 [12.387453]
 [10.879536]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10.] 
cards in discard: [ 6. 10. 10. 10.  8.  6.  6. 15.  0.  3. 10. 15.  6.  1.  6. 11. 11. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 11 11 10  8  8 10  6  8 11  6  3  6 16 15  0 10 11  1  0  0 16  0  6
 15 10  6 15  6 10 15  3 10  3  6  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 0. 28. 30. 18. 30.  8.  1.  6.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 6
Learning step: 0.44056999683380127
desired expected reward: 4.81247615814209



action possibilites: [-1] 
expected returns: [[8.570462]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.] 
cards in discard: [ 6. 10. 10. 10.  8.  6.  6. 15.  0.  3. 10. 15.  6.  1.  6. 11. 11. 15.
 16.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [29 11 11 10  8  8 10  6  8 11  6  3  6 16 15  0 10 11  1  0  0 16  0  6
 15 10  6 15  6 10 15  3 10  3  6  3 16] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 28. 30. 18. 30.  8.  1.  5.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0 -2  0  0 16  0] 
sum of rewards: 49 

action type: gain_card_n - action 3
Learning step: 1.2458051443099976
desired expected reward: 11.718623161315918





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. -1.] 
expected returns: [[8.115863 ]
 [5.8158646]
 [8.557774 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.] 
cards in discard: [ 6. 10. 10. 10.  8.  6.  6. 15.  0.  3. 10. 15.  6.  1.  6. 11. 11. 15.
 16.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [29 11 11 10  8  8 10  6  8 11  6  3  6 16 15  0 10 11  1  0  0 16  0  6
 15 10  6 15  6 10 15  3 10  3  6  3 16] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 28. 30. 18. 30.  8.  1.  5.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.8738280534744263
desired expected reward: 9.444290161132812



buy possibilites: [-1] 
expected returns: [[10.356939]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.] 
cards in discard: [ 6. 10. 10. 10.  8.  6.  6. 15.  0.  3. 10. 15.  6.  1.  6. 11. 11. 15.
 16.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [29 11 11 10  8  8 10  6  8 11  6  3  6 16 15  0 10 11  1  0  0 16  0  6
 15 10  6 15  6 10 15  3 10  3  6  3 16  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 17. 30.  8.  1.  5.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0 -3  0  0  8  0] 
sum of rewards: 40 

action type: buy - action 3.0
Learning step: 1.0439239740371704
desired expected reward: 9.87138557434082






         -------------------- Turn: 61 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 17. 30.  8.  1.  5.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [11.  8.  3.  6.  8.] 
adversary cards in discard: [ 6. 10. 10. 10.  8.  6.  6. 15.  0.  3. 10. 15.  6.  1.  6. 11. 11. 15.
 16.  3. 29. 11.  0. 10.] 
adversary owned cards: [29 11 11 10  8  8 10  6  8 11  6  3  6 16 15  0 10 11  1  0  0 16  0  6
 15 10  6 15  6 10 15  3 10  3  6  3 16  3] -> size -> 38 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 17. 30.  8.  1.  5.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [11.  8.  3.  6.  8.] 
adversary cards in discard: [ 6. 10. 10. 10.  8.  6.  6. 15.  0.  3. 10. 15.  6.  1.  6. 11. 11. 15.
 16.  3. 29. 11.  0. 10.] 
adversary owned cards: [29 11 11 10  8  8 10  6  8 11  6  3  6 16 15  0 10 11  1  0  0 16  0  6
 15 10  6 15  6 10 15  3 10  3  6  3 16  3] -> size -> 38 
adversary victory points: -2
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11.  8.  3.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8.] 
expected returns: [[11.044458]
 [12.701674]
 [12.007729]
 [12.007729]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  3.  6.  8.] 
cards in discard: [ 6. 10. 10. 10.  8.  6.  6. 15.  0.  3. 10. 15.  6.  1.  6. 11. 11. 15.
 16.  3. 29. 11.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [29 11 11 10  8  8 10  6  8 11  6  3  6 16 15  0 10 11  1  0  0 16  0  6
 15 10  6 15  6 10 15  3 10  3  6  3 16  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 17. 30.  8.  1.  5.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3337353467941284
desired expected reward: 10.02320384979248



action possibilites: [-1] 
expected returns: [[10.106962]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6.] 
cards in discard: [ 6. 10. 10. 10.  8.  6.  6. 15.  0.  3. 10. 15.  6.  1.  6. 11. 11. 15.
 16.  3. 29. 11.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 11 10  8 10  6  8 11  6  3  6 16 15  0 10 11  1  0  0 16  0  6 15 10
  6 15  6 10 15  3 10  3  6  3 16  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 17. 30.  8.  1.  5.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 9
Learning step: 0.14258794486522675
desired expected reward: 13.927093505859375





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[ 7.60567 ]
 [10.162342]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6.] 
cards in discard: [ 6. 10. 10. 10.  8.  6.  6. 15.  0.  3. 10. 15.  6.  1.  6. 11. 11. 15.
 16.  3. 29. 11.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 11 10  8 10  6  8 11  6  3  6 16 15  0 10 11  1  0  0 16  0  6 15 10
  6 15  6 10 15  3 10  3  6  3 16  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 17. 30.  8.  1.  5.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.2427576780319214
desired expected reward: 10.349720001220703






         -------------------- Turn: 62 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 17. 30.  8.  1.  5.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [ 0. 15.  3.  0.  6.] 
adversary cards in discard: [ 6. 10. 10. 10.  8.  6.  6. 15.  0.  3. 10. 15.  6.  1.  6. 11. 11. 15.
 16.  3. 29. 11.  0. 10.  8.  3.  6.] 
adversary owned cards: [29 11 10  8 10  6  8 11  6  3  6 16 15  0 10 11  1  0  0 16  0  6 15 10
  6 15  6 10 15  3 10  3  6  3 16  3] -> size -> 36 
adversary victory points: -2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 17. 30.  8.  1.  5.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [ 0. 15.  3.  0.  6.] 
adversary cards in discard: [ 6. 10. 10. 10.  8.  6.  6. 15.  0.  3. 10. 15.  6.  1.  6. 11. 11. 15.
 16.  3. 29. 11.  0. 10.  8.  3.  6.] 
adversary owned cards: [29 11 10  8 10  6  8 11  6  3  6 16 15  0 10 11  1  0  0 16  0  6 15 10
  6 15  6 10 15  3 10  3  6  3 16  3] -> size -> 36 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 28. 30. 17. 30.  8.  1.  5.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [ 0. 15.  3.  0.  6.] 
adversary cards in discard: [ 6. 10. 10. 10.  8.  6.  6. 15.  0.  3. 10. 15.  6.  1.  6. 11. 11. 15.
 16.  3. 29. 11.  0. 10.  8.  3.  6.] 
adversary owned cards: [29 11 10  8 10  6  8 11  6  3  6 16 15  0 10 11  1  0  0 16  0  6 15 10
  6 15  6 10 15  3 10  3  6  3 16  3] -> size -> 36 
adversary victory points: -2
player victory points: 0 





Player: 0 
cards in hand: [ 0. 15.  3.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[13.504261]
 [13.726218]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3.  0.  6.] 
cards in discard: [ 6. 10. 10. 10.  8.  6.  6. 15.  0.  3. 10. 15.  6.  1.  6. 11. 11. 15.
 16.  3. 29. 11.  0. 10.  8.  3.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [29 11 10  8 10  6  8 11  6  3  6 16 15  0 10 11  1  0  0 16  0  6 15 10
  6 15  6 10 15  3 10  3  6  3 16  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 17. 30.  8.  1.  5.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.3116771876811981
desired expected reward: 9.850665092468262



action possibilites: [-1] 
expected returns: [[14.2337265]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6.] 
cards in discard: [ 6. 10. 10. 10.  8.  6.  6. 15.  0.  3. 10. 15.  6.  1.  6. 11. 11. 15.
 16.  3. 29. 11.  0. 10.  8.  3.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [29 11 10  8 10  6  8 11  6  3  6 16 15 10 11  1  0  0 16  0  6 15 10  6
 15  6 10 15  3 10  3  6  3 16  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0. 28. 30. 17. 30.  8.  1.  5.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: 0.18766753375530243
desired expected reward: 13.913887023925781





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[14.729095]
 [13.683061]
 [10.625282]
 [13.456787]
 [15.980648]
 [16.049784]
 [12.763772]
 [14.203987]
 [14.502923]
 [14.239245]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6.] 
cards in discard: [ 6. 10. 10. 10.  8.  6.  6. 15.  0.  3. 10. 15.  6.  1.  6. 11. 11. 15.
 16.  3. 29. 11.  0. 10.  8.  3.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [29 11 10  8 10  6  8 11  6  3  6 16 15 10 11  1  0  0 16  0  6 15 10  6
 15  6 10 15  3 10  3  6  3 16  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 28. 30. 17. 30.  8.  1.  5.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.17448978126049042
desired expected reward: 14.40821647644043



buy possibilites: [-1] 
expected returns: [[15.635355]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6.] 
cards in discard: [ 6. 10. 10. 10.  8.  6.  6. 15.  0.  3. 10. 15.  6.  1.  6. 11. 11. 15.
 16.  3. 29. 11.  0. 10.  8.  3.  6.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [29 11 10  8 10  6  8 11  6  3  6 16 15 10 11  1  0  0 16  0  6 15 10  6
 15  6 10 15  3 10  3  6  3 16  3  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 27. 30. 17. 30.  8.  1.  5.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0.  -1.   0.   0.
  4.5  0. ] 
sum of rewards: 18.5 

action type: buy - action 1.0
Learning step: 0.2772983908653259
desired expected reward: 15.006392478942871






         -------------------- Turn: 63 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 27. 30. 17. 30.  8.  1.  5.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [ 6.  3. 16. 10. 16.] 
adversary cards in discard: [] 
adversary owned cards: [29 11 10  8 10  6  8 11  6  3  6 16 15 10 11  1  0  0 16  0  6 15 10  6
 15  6 10 15  3 10  3  6  3 16  3  1] -> size -> 36 
adversary victory points: -2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 27. 30. 17. 30.  8.  1.  5.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [ 6.  3. 16. 10. 16.] 
adversary cards in discard: [] 
adversary owned cards: [29 11 10  8 10  6  8 11  6  3  6 16 15 10 11  1  0  0 16  0  6 15 10  6
 15  6 10 15  3 10  3  6  3 16  3  1] -> size -> 36 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 27. 30. 17. 30.  8.  1.  5.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [ 6.  3. 16. 10. 16.] 
adversary cards in discard: [] 
adversary owned cards: [29 11 10  8 10  6  8 11  6  3  6 16 15 10 11  1  0  0 16  0  6 15 10  6
 15  6 10 15  3 10  3  6  3 16  3  1] -> size -> 36 
adversary victory points: -2
player victory points: 0 





Player: 0 
cards in hand: [ 6.  3. 16. 10. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10. 16.] 
expected returns: [[3.7515771]
 [3.3565516]
 [3.7334228]
 [3.3565516]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 16. 10. 16.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [29 11 10  8 10  6  8 11  6  3  6 16 15 10 11  1  0  0 16  0  6 15 10  6
 15  6 10 15  3 10  3  6  3 16  3  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 27. 30. 17. 30.  8.  1.  5.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5805785059928894
desired expected reward: 15.054776191711426



action possibilites: [-1. 16. 16.] 
expected returns: [[3.9979067]
 [3.5819645]
 [3.5819645]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 16. 16.  3.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [10.] 
owned cards: [29 11 10  8 10  6  8 11  6  3  6 16 15 10 11  1  0  0 16  0  6 15 10  6
 15  6 10 15  3 10  3  6  3 16  3  1] -> size -> 36 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0. 27. 30. 17. 30.  8.  1.  5.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.375434935092926
desired expected reward: 4.182562351226807





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[2.1435587]
 [4.005572 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 16. 16.  3.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [10.] 
owned cards: [29 11 10  8 10  6  8 11  6  3  6 16 15 10 11  1  0  0 16  0  6 15 10  6
 15  6 10 15  3 10  3  6  3 16  3  1] -> size -> 36 
action values: 2 
buys: 1 
player value: 0 
card supply: [ 0. 27. 30. 17. 30.  8.  1.  5.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.36430081725120544
desired expected reward: 4.362207412719727



Player 1 won the game! 



Player 0 bought cards:
Copper: 10 
Silver: 1 
Gold: 0 
Estate: 7 
Duchy: 0 
Province: 0 
Curse: 9 

Remodel: 1 
Workshop: 4 
Chapel: 3 
Witch: 0 
Poacher: 0 
Militia: 1 
Market: 0 
Village: 1 
Library: 0 
Moneylender: 1 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 6.  3. 16. 16.  3.] 
cards in discard: [6.] 
cards in deck: 30 
card top of deck: [] 
played cards: [10.] 
owned cards: [29 11 10  8 10  6  8 11  6  3  6 16 15 10 11  1  0  0 16  0  6 15 10  6
 15  6 10 15  3 10  3  6  3 16  3  1  6] -> size -> 37 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0. 27. 30. 17. 30.  8.  0.  5.  5.  0. 10.  9.  8. 10.  3. 10.  6.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[  -5 -500    0    0    0    0   20    0    0    0    0   -2    0 -300
    0    0] 
sum of rewards: -787 

action type: buy - action 6.0
Learning step: -23.674306869506836
desired expected reward: -21.53074836730957



