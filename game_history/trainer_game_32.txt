 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[360.61237]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500   -3  -70    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -578 

action type: buy - action -1
Learning step: -28.80537986755371
desired expected reward: -30.697763442993164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[335.8768 ]
 [345.07275]
 [343.78156]
 [327.5773 ]
 [342.36545]
 [355.18637]
 [346.41583]
 [356.68646]
 [337.97913]
 [345.12466]
 [348.04086]
 [365.36514]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -10.406757354736328
desired expected reward: 354.6770324707031



buy possibilites: [-1] 
expected returns: [[332.90677]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 30 

action type: buy - action 16.0
Learning step: -8.1278715133667
desired expected reward: 334.23760986328125






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [16.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [16.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [29.  0.  3.  0.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [16.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[343.1374]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [16.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -9.028528213500977
desired expected reward: 323.87823486328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[321.49347]
 [328.9801 ]
 [327.85126]
 [314.26254]
 [336.79712]
 [330.05643]
 [328.92758]
 [345.56705]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [16.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.7011137008667
desired expected reward: 333.26824951171875



buy possibilites: [-1] 
expected returns: [[333.3513]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [16.  0.  0.  0.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 11.0 

action type: buy - action 3.0
Learning step: -8.342159271240234
desired expected reward: 319.50909423828125






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [11.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 3. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [0. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[347.02374]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 3. 11. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 11] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -8.832670211791992
desired expected reward: 324.51861572265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[318.0189 ]
 [325.24878]
 [309.98868]
 [327.70877]
 [345.42172]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 3. 11. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 11] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -10.081219673156738
desired expected reward: 340.3585510253906



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 3. 11. 11.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  0.  3.] 
adversary cards in discard: [0. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 3. 11. 11.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  0.  3.] 
adversary cards in discard: [0. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 3. 11. 11.  0.  0.  0.  3. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 11 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 16.  0.  3.] 
adversary cards in discard: [0. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0. 16.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[346.26398]
 [330.30173]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  0.  3.] 
cards in discard: [0. 3. 3. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 11 11] -> size -> 15 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -9.657415390014648
desired expected reward: 335.76434326171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[329.78073]
 [336.72134]
 [335.46725]
 [322.97302]
 [343.73926]
 [337.74548]
 [336.4915 ]
 [350.90472]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.  0.  3.] 
cards in discard: [0. 3. 3. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 11 11] -> size -> 15 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -9.635472297668457
desired expected reward: 336.0228576660156



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 11 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 11 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 11 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 28. 30.  8. 10.  9.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 11 11  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 5 
card supply: [29. 30. 30. 28. 30.  8. 10.  9.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [ 3.  0. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[332.05463]
 [313.60016]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 16.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10.  9.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  3. 11.  0.  0.] 
adversary cards in discard: [ 0. 29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 11 11  0] -> size -> 16 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -10.193882942199707
desired expected reward: 340.7108459472656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[309.3147 ]
 [316.38867]
 [315.1764 ]
 [302.57938]
 [324.5115 ]
 [317.54773]
 [316.33545]
 [332.4887 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 16.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 28. 30.  8. 10.  9.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  3. 11.  0.  0.] 
adversary cards in discard: [ 0. 29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 11 11  0] -> size -> 16 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -9.521829605102539
desired expected reward: 325.1523132324219



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [11.  3. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 11.  0.  0.] 
cards in discard: [ 0. 29.  0.  3.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 11 11  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10.  9.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.] 
cards in discard: [ 0. 29.  0.  3.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10.  9.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  0.] 
cards in discard: [ 0. 29.  0.  3.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 28. 30.  8. 10.  9.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  0.] 
cards in discard: [ 0. 29.  0.  3.  0.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 28. 30.  8. 10.  9.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[364.52084]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 3.  0. 16.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8. 10.  9.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0] -> size -> 18 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -8.48172664642334
desired expected reward: 324.0069885253906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[346.21567]
 [353.61917]
 [352.4984 ]
 [339.42953]
 [351.3615 ]
 [362.066  ]
 [354.7382 ]
 [363.39255]
 [347.83173]
 [353.61734]
 [356.0164 ]
 [371.03375]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 3.  0. 16.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 28. 30.  8. 10.  9.  7. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0] -> size -> 18 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -10.141112327575684
desired expected reward: 353.97930908203125



buy possibilites: [-1] 
expected returns: [[350.88046]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 3.  0. 16.  0.  0. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 15] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8. 10.  9.  7. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0] -> size -> 18 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 31 

action type: buy - action 15.0
Learning step: -8.356010437011719
desired expected reward: 347.660400390625






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 11.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8. 10.  9.  7. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 15] -> size -> 13 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 28. 30.  8. 10.  9.  7. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 15] -> size -> 13 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3.  3.] 
cards in discard: [0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 30. 30. 28. 30.  8. 10.  9.  7. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 15] -> size -> 13 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[319.73468]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 15] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8. 10.  9.  7. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 11.  3. 11. 29.] 
adversary cards in discard: [ 0.  0.  0. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -10.374723434448242
desired expected reward: 340.5057373046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[294.69193]
 [302.41306]
 [301.2666 ]
 [287.51495]
 [310.56696]
 [303.52438]
 [302.37796]
 [318.70224]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 15] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 28. 30.  8. 10.  9.  7. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 11.  3. 11. 29.] 
adversary cards in discard: [ 0.  0.  0. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -9.146430015563965
desired expected reward: 311.71136474609375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  3. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 29.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3. 11. 29.] 
cards in discard: [ 0.  0.  0. 11.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8. 10.  9.  7. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [15.  3.  0.  3.  0.] 
adversary cards in discard: [0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 15] -> size -> 13 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11. 29.] 
cards in discard: [ 0.  0.  0. 11.  3.  3. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8. 10.  9.  7. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [15.  3.  0.  3.  0.] 
adversary cards in discard: [0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 15] -> size -> 13 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11. 29.] 
cards in discard: [ 0.  0.  0. 11.  3.  3. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 28. 30.  8. 10.  9.  7. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [15.  3.  0.  3.  0.] 
adversary cards in discard: [0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 15] -> size -> 13 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [15.  3.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[304.41083]
 [286.31204]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0.  3.  0.] 
cards in discard: [0. 0. 0. 3. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 15] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8. 10.  9.  7. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  0.  0. 11.  3.  3. 15. 11.  0.  3. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15] -> size -> 20 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -8.28632640838623
desired expected reward: 289.4765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[275.52512]
 [282.50867]
 [267.85352]
 [284.91046]
 [303.69354]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  0.  3.  0.] 
cards in discard: [0. 0. 0. 3. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 15] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 28. 30.  8. 10.  9.  7. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  0.  0. 11.  3.  3. 15. 11.  0.  3. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15] -> size -> 20 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -8.565876960754395
desired expected reward: 292.60760498046875



buy possibilites: [-1] 
expected returns: [[308.92993]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  0.  3.  0.] 
cards in discard: [0. 0. 0. 3. 3. 6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 15  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 30. 30. 28. 30.  8.  9.  9.  7. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  0.  0. 11.  3.  3. 15. 11.  0.  3. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    3.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -312.0 

action type: buy - action 6.0
Learning step: -22.041751861572266
desired expected reward: 245.81173706054688






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0.  0.  0. 11.  3.  3. 15. 11.  0.  3. 11. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8.  9.  9.  7. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  3. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 15  6] -> size -> 14 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0.  0.  0. 11.  3.  3. 15. 11.  0.  3. 11. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 30. 30. 28. 30.  8.  9.  9.  7. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  3. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 15  6] -> size -> 14 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0.  0.  0. 11.  3.  3. 15. 11.  0.  3. 11. 29.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8.  9.  9.  7. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 3.  3. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 15  6] -> size -> 14 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 3.  3. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[325.43033]
 [310.06366]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 16.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 15  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  9.  9.  7. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -8.81923770904541
desired expected reward: 300.1106872558594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[302.27695]
 [307.9608 ]
 [295.24457]
 [310.42432]
 [323.24115]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 16.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 15  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8.  9.  9.  7. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -9.84456729888916
desired expected reward: 316.2023010253906



buy possibilites: [-1] 
expected returns: [[328.99316]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 16.  0.  0.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 15  6  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 28. 30.  8.  8.  9.  7. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1] -> size -> 21 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -323.0 

action type: buy - action 6.0
Learning step: -23.5098819732666
desired expected reward: 271.73468017578125






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  8.  9.  7. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  0.  3.  0. 15.] 
adversary cards in discard: [ 6.  3.  3. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 15  6  6] -> size -> 15 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 28. 30.  8.  8.  9.  7. 10. 10.  9. 10. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  0.  3.  0. 15.] 
adversary cards in discard: [ 6.  3.  3. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 15  6  6] -> size -> 15 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [14.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  8.  9.  7. 10. 10.  9.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  0.  3.  0. 15.] 
adversary cards in discard: [ 6.  3.  3. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 15  6  6] -> size -> 15 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0.  3.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[319.65628]
 [305.28424]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 15.] 
cards in discard: [ 6.  3.  3. 16.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 15  6  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 30.  8.  8.  9.  7. 10. 10.  9.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  0.  0.  3. 15.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14] -> size -> 22 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -10.601222038269043
desired expected reward: 318.3919372558594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[293.06818]
 [299.84546]
 [298.6968 ]
 [286.7242 ]
 [307.8493 ]
 [300.91364]
 [299.765  ]
 [316.60568]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 15.] 
cards in discard: [ 6.  3.  3. 16.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 15  6  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 28. 30.  8.  8.  9.  7. 10. 10.  9.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  0.  0.  3. 15.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14] -> size -> 22 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -10.029990196228027
desired expected reward: 305.5270080566406



buy possibilites: [-1] 
expected returns: [[305.42236]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 15.] 
cards in discard: [ 6.  3.  3. 16.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 15  6  6  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 27. 30.  8.  8.  9.  7. 10. 10.  9.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 0.  0.  0.  3. 15.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -10.0 

action type: buy - action 3.0
Learning step: -8.562835693359375
desired expected reward: 290.1339416503906






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 15.] 
cards in discard: [14.  0.  0.  0.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  8.  9.  7. 10. 10.  9.  9. 10. 10. 10.  8.] 
adversary cards in hand: [3. 3. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 15  6  6  3] -> size -> 16 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [14.  0.  0.  0.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 29. 30. 27. 30.  8.  8.  9.  7. 10. 10.  9.  9. 10. 10. 10.  8.] 
adversary cards in hand: [3. 3. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 15  6  6  3] -> size -> 16 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [14.  0.  0.  0.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 29. 30. 27. 30.  8.  8.  9.  7. 10. 10.  9.  9. 10. 10. 10.  8.] 
adversary cards in hand: [3. 3. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 15  6  6  3] -> size -> 16 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [14.  0.  0.  0.  0.  3. 23.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  8.  9.  7. 10. 10.  9.  9.  9. 10. 10.  8.] 
adversary cards in hand: [3. 3. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 15  6  6  3] -> size -> 16 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [3. 3. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[272.5086]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 15  6  6  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  8.  9.  7. 10. 10.  9.  9.  9. 10. 10.  8.] 
adversary cards in hand: [ 0. 11.  0. 11.  1.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3. 23. 15.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -9.72734546661377
desired expected reward: 295.69500732421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[246.99016]
 [253.67206]
 [239.39117]
 [255.9712 ]
 [271.82693]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 15  6  6  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 27. 30.  8.  8.  9.  7. 10. 10.  9.  9.  9. 10. 10.  8.] 
adversary cards in hand: [ 0. 11.  0. 11.  1.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3. 23. 15.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -8.391590118408203
desired expected reward: 264.66497802734375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  0. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 11.  1.] 
cards in discard: [14.  0.  0.  0.  0.  3. 23. 15.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  8.  9.  7. 10. 10.  9.  9.  9. 10. 10.  8.] 
adversary cards in hand: [15.  3.  0.  6.  3.] 
adversary cards in discard: [3. 3. 6. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 15  6  6  3] -> size -> 16 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  1.] 
cards in discard: [14.  0.  0.  0.  0.  3. 23. 15.  0.  0.  3.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  8.  9.  7.  9. 10.  9.  9.  9. 10. 10.  8.] 
adversary cards in hand: [15.  3.  0.  6.  3.] 
adversary cards in discard: [3. 3. 6. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 15  6  6  3] -> size -> 16 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  1.] 
cards in discard: [14.  0.  0.  0.  0.  3. 23. 15.  0.  0.  3.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 27. 30.  8.  8.  9.  7.  9. 10.  9.  9.  9. 10. 10.  8.] 
adversary cards in hand: [15.  3.  0.  6.  3.] 
adversary cards in discard: [3. 3. 6. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 15  6  6  3] -> size -> 16 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  1.] 
cards in discard: [14.  0.  0.  0.  0.  3. 23. 15.  0.  0.  3.  8. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 16] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  8.  8.  7.  9. 10.  9.  9.  9. 10. 10.  8.] 
adversary cards in hand: [15.  3.  0.  6.  3.] 
adversary cards in discard: [3. 3. 6. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 15  6  6  3] -> size -> 16 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [15.  3.  0.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[309.6986]
 [291.5606]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0.  6.  3.] 
cards in discard: [3. 3. 6. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  3 15  6  6  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  8.  8.  7.  9. 10.  9.  9.  9. 10. 10.  8.] 
adversary cards in hand: [11.  0.  0. 29.  3.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3. 23. 15.  0.  0.  3.  8. 16. 11.  0.  0. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 16] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -7.3710551261901855
desired expected reward: 264.45587158203125



action possibilites: [-1] 
expected returns: [[291.8758]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3.] 
cards in discard: [3. 3. 6. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  3 15  6  6  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 29. 30. 27. 30.  8.  8.  8.  7.  9. 10.  9.  9.  9. 10. 10.  8.] 
adversary cards in hand: [11.  0.  0. 29.  3.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3. 23. 15.  0.  0.  3.  8. 16. 11.  0.  0. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 16] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action 15.0
Learning step: -7.572937965393066
desired expected reward: 283.22991943359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[271.56564]
 [277.9656 ]
 [277.176  ]
 [265.7811 ]
 [285.08975]
 [278.88626]
 [278.09662]
 [292.29825]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3.] 
cards in discard: [3. 3. 6. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  3 15  6  6  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 27. 30.  8.  8.  8.  7.  9. 10.  9.  9.  9. 10. 10.  8.] 
adversary cards in hand: [11.  0.  0. 29.  3.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3. 23. 15.  0.  0.  3.  8. 16. 11.  0.  0. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 16] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action -1
Learning step: -7.811696529388428
desired expected reward: 284.0640869140625






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [11.  0.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 29.  3.] 
cards in discard: [14.  0.  0.  0.  0.  3. 23. 15.  0.  0.  3.  8. 16. 11.  0.  0. 11.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 16] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  8.  8.  7.  9. 10.  9.  9.  9. 10. 10.  8.] 
adversary cards in hand: [ 0.  0.  0.  0. 16.] 
adversary cards in discard: [ 3.  3.  6.  0.  0. 15.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  3 15  6  6  3] -> size -> 15 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  3.] 
cards in discard: [14.  0.  0.  0.  0.  3. 23. 15.  0.  0.  3.  8. 16. 11.  0.  0. 11.  1.
 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 16
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  8.  8.  7.  9. 10.  8.  9.  9. 10. 10.  8.] 
adversary cards in hand: [ 0.  0.  0.  0. 16.] 
adversary cards in discard: [ 3.  3.  6.  0.  0. 15.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  3 15  6  6  3] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  3.] 
cards in discard: [14.  0.  0.  0.  0.  3. 23. 15.  0.  0.  3.  8. 16. 11.  0.  0. 11.  1.
 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 16
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 27. 30.  8.  8.  8.  7.  9. 10.  8.  9.  9. 10. 10.  8.] 
adversary cards in hand: [ 0.  0.  0.  0. 16.] 
adversary cards in discard: [ 3.  3.  6.  0.  0. 15.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  3 15  6  6  3] -> size -> 15 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  3.] 
cards in discard: [14.  0.  0.  0.  0.  3. 23. 15.  0.  0.  3.  8. 16. 11.  0.  0. 11.  1.
 29.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 16
 29  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  8.  8.  7.  8. 10.  8.  9.  9. 10. 10.  8.] 
adversary cards in hand: [ 0.  0.  0.  0. 16.] 
adversary cards in discard: [ 3.  3.  6.  0.  0. 15.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16  3 15  6  6  3] -> size -> 15 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[226.61765]
 [203.7809 ]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 16.] 
cards in discard: [ 3.  3.  6.  0.  0. 15.  3.  6.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16  3 15  6  6  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  8.  8.  7.  8. 10.  8.  9.  9. 10. 10.  8.] 
adversary cards in hand: [ 1.  0.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 16
 29  8] -> size -> 26 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -10.316632270812988
desired expected reward: 281.9815979003906



action possibilites: [-1] 
expected returns: [[188.21622]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3.  3.  6.  0.  0. 15.  3.  6.  3.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3 16  3 15  6  6  3  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  8.  8.  7.  7. 10.  8.  9.  9. 10. 10.  8.] 
adversary cards in hand: [ 1.  0.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 16
 29  8] -> size -> 26 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   4   0] 
sum of rewards: 12 

action type: gain_card_n - action 3
Learning step: -4.086462497711182
desired expected reward: 174.340087890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[173.41179]
 [180.48894]
 [179.65239]
 [166.63098]
 [188.14426]
 [181.48413]
 [180.64758]
 [196.45569]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3.  3.  6.  0.  0. 15.  3.  6.  3.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3 16  3 15  6  6  3  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 27. 30.  8.  8.  8.  7.  7. 10.  8.  9.  9. 10. 10.  8.] 
adversary cards in hand: [ 1.  0.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 16
 29  8] -> size -> 26 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action -1
Learning step: -4.808215141296387
desired expected reward: 183.4080047607422






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 1.  0.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0. 11.  3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 16
 29  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  8.  8.  7.  7. 10.  8.  9.  9. 10. 10.  8.] 
adversary cards in hand: [ 0.  0.  3. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 16  3 15  6  6  3  8] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0. 11.  3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 16
 29  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 27. 30.  8.  8.  8.  7.  7. 10.  8.  9.  9. 10. 10.  8.] 
adversary cards in hand: [ 0.  0.  3. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 16  3 15  6  6  3  8] -> size -> 15 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  0.  3. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[174.50693]
 [161.6426 ]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 16.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 16  3 15  6  6  3  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  8.  8.  7.  7. 10.  8.  9.  9. 10. 10.  8.] 
adversary cards in hand: [ 0. 15. 11. 11.  3.] 
adversary cards in discard: [ 1.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 16
 29  8] -> size -> 26 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -6.496435642242432
desired expected reward: 189.9592742919922



action possibilites: [-1] 
expected returns: [[207.06229]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3 16  3 15  6  6  3  8 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  8.  8.  7.  7. 10.  8.  9.  9.  9. 10.  8.] 
adversary cards in hand: [ 0. 15. 11. 11.  3.] 
adversary cards in discard: [ 1.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 16
 29  8] -> size -> 26 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: 6 

action type: gain_card_n - action 9
Learning step: -8.637337684631348
desired expected reward: 263.2874450683594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[185.97499]
 [191.09006]
 [180.04611]
 [192.93588]
 [204.22551]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3 16  3 15  6  6  3  8 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 27. 30.  8.  8.  8.  7.  7. 10.  8.  9.  9.  9. 10.  8.] 
adversary cards in hand: [ 0. 15. 11. 11.  3.] 
adversary cards in discard: [ 1.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 16
 29  8] -> size -> 26 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: take_action - action -1
Learning step: -6.094703197479248
desired expected reward: 200.96759033203125



buy possibilites: [-1] 
expected returns: [[204.23576]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [10.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3 16  3 15  6  6  3  8 10  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 27. 30.  8.  8.  8.  7.  7. 10.  8.  9.  9.  9. 10.  8.] 
adversary cards in hand: [ 0. 15. 11. 11.  3.] 
adversary cards in discard: [ 1.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 16
 29  8] -> size -> 26 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -20.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -33.0 

action type: buy - action 0.0
Learning step: -6.353445053100586
desired expected reward: 179.62155151367188






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 0. 15. 11. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 11. 11.  3.] 
cards in discard: [ 1.  0.  0. 11.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 16
 29  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  8.  8.  7.  7. 10.  8.  9.  9.  9. 10.  8.] 
adversary cards in hand: [ 3.  0.  8.  6. 15.] 
adversary cards in discard: [10.  0. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  3 15  6  6  3  8 10  0] -> size -> 16 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 11. 11.  3.] 
cards in discard: [ 1.  0.  0. 11.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 16
 29  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 27. 30.  8.  8.  8.  7.  7. 10.  8.  9.  9.  9. 10.  8.] 
adversary cards in hand: [ 3.  0.  8.  6. 15.] 
adversary cards in discard: [10.  0. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  3 15  6  6  3  8 10  0] -> size -> 16 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 11. 11.  3.] 
cards in discard: [ 1.  0.  0. 11.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 16
 29  8  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 27. 30.  8.  8.  8.  7.  7. 10.  8.  9.  9.  9. 10.  8.] 
adversary cards in hand: [ 3.  0.  8.  6. 15.] 
adversary cards in discard: [10.  0. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  3 15  6  6  3  8 10  0] -> size -> 16 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [ 3.  0.  8.  6. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
expected returns: [[138.51642 ]
 [126.94719 ]
 [127.856766]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8.  6. 15.] 
cards in discard: [10.  0. 16.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16  3 15  6  6  3  8 10  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  8.  8.  7.  7. 10.  8.  9.  9.  9. 10.  8.] 
adversary cards in hand: [23. 14.  0.  3. 29.] 
adversary cards in discard: [ 1.  0.  0. 11.  3.  0.  0. 15. 11. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 16
 29  8  0] -> size -> 27 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -8.448368072509766
desired expected reward: 195.7873992919922



action possibilites: [-1] 
expected returns: [[125.93961]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 6.] 
cards in discard: [10.  0. 16.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3 16  3 15  6  6  3  8 10  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 29. 30. 27. 30.  8.  8.  8.  7.  7. 10.  8.  9.  9.  9. 10.  8.] 
adversary cards in hand: [23. 14.  0.  3. 29.] 
adversary cards in discard: [ 1.  0.  0. 11.  3.  0.  0. 15. 11. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 16
 29  8  0] -> size -> 27 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: take_action - action 15.0
Learning step: -3.488384962081909
desired expected reward: 119.95214080810547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[111.91186 ]
 [117.78797 ]
 [116.92954 ]
 [106.198784]
 [124.03805 ]
 [118.63719 ]
 [117.778786]
 [130.33437 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 6.] 
cards in discard: [10.  0. 16.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3 16  3 15  6  6  3  8 10  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 29. 30. 27. 30.  8.  8.  8.  7.  7. 10.  8.  9.  9.  9. 10.  8.] 
adversary cards in hand: [23. 14.  0.  3. 29.] 
adversary cards in discard: [ 1.  0.  0. 11.  3.  0.  0. 15. 11. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 16
 29  8  0] -> size -> 27 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: take_action - action -1
Learning step: -3.6873176097869873
desired expected reward: 122.2522964477539



buy possibilites: [-1] 
expected returns: [[181.39989]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 6.] 
cards in discard: [10.  0. 16.  0.  0.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3 16  3 15  6  6  3  8 10  0  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 29. 30. 27. 30.  8.  7.  8.  7.  7. 10.  8.  9.  9.  9. 10.  8.] 
adversary cards in hand: [23. 14.  0.  3. 29.] 
adversary cards in discard: [ 1.  0.  0. 11.  3.  0.  0. 15. 11. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 16
 29  8  0] -> size -> 27 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -30.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -314.0 

action type: buy - action 6.0
Learning step: -16.928442001342773
desired expected reward: 89.27033233642578






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [23. 14.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 14. 29.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23. 14.  0.  3. 29.] 
cards in discard: [ 1.  0.  0. 11.  3.  0.  0. 15. 11. 11.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 16
 29  8  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  7.  8.  7.  7. 10.  8.  9.  9.  9. 10.  8.] 
adversary cards in hand: [0. 0. 6. 3. 3.] 
adversary cards in discard: [10.  0. 16.  0.  0.  3.  6. 15.  3.  8.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 16  3 15  6  6  3  8 10  0  6] -> size -> 16 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0.  3. 29.] 
cards in discard: [ 1.  0.  0. 11.  3.  0.  0. 15. 11. 11.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 16
 29  8  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 29. 30. 27. 30.  8.  7.  8.  7.  7. 10.  8.  9.  9.  9. 10.  8.] 
adversary cards in hand: [0. 0. 6.] 
adversary cards in discard: [10.  0. 16.  0.  0.  3.  6. 15.  3.  8.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 16  3 15  6  6  3  8 10  0  6] -> size -> 16 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0.  3. 29.] 
cards in discard: [ 1.  0.  0. 11.  3.  0.  0. 15. 11. 11.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 16
 29  8  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 29. 30. 27. 30.  8.  7.  8.  7.  7. 10.  8.  9.  9.  9. 10.  8.] 
adversary cards in hand: [0. 0. 6.] 
adversary cards in discard: [10.  0. 16.  0.  0.  3.  6. 15.  3.  8.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 16  3 15  6  6  3  8 10  0  6] -> size -> 16 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0.  3. 29.] 
cards in discard: [ 1.  0.  0. 11.  3.  0.  0. 15. 11. 11.  3. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 16
 29  8  0 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  7.  8.  7.  7. 10.  8.  9.  9.  8. 10.  8.] 
adversary cards in hand: [0. 0. 6.] 
adversary cards in discard: [10.  0. 16.  0.  0.  3.  6. 15.  3.  8.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 16  3 15  6  6  3  8 10  0  6] -> size -> 16 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[169.53416]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6.] 
cards in discard: [10.  0. 16.  0.  0.  3.  6. 15.  3.  8.  6.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  3 15  6  6  3  8 10  0  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  7.  8.  7.  7. 10.  8.  9.  9.  8. 10.  8.] 
adversary cards in hand: [29. 16.  0.  8.  0.] 
adversary cards in discard: [ 1.  0.  0. 11.  3.  0.  0. 15. 11. 11.  3. 10. 14. 23.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 16
 29  8  0 10] -> size -> 28 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: discard_down_to_3_cards - action 3
Learning step: -5.995800495147705
desired expected reward: 155.33380126953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[148.39845]
 [153.8199 ]
 [142.3732 ]
 [155.53894]
 [168.18295]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [10.  0. 16.  0.  0.  3.  6. 15.  3.  8.  6.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  3 15  6  6  3  8 10  0  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 27. 30.  8.  7.  8.  7.  7. 10.  8.  9.  9.  8. 10.  8.] 
adversary cards in hand: [29. 16.  0.  8.  0.] 
adversary cards in discard: [ 1.  0.  0. 11.  3.  0.  0. 15. 11. 11.  3. 10. 14. 23.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 16
 29  8  0 10] -> size -> 28 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -6.497878551483154
desired expected reward: 161.087890625



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [29. 16.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 16.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 16.  0.  8.  0.] 
cards in discard: [ 1.  0.  0. 11.  3.  0.  0. 15. 11. 11.  3. 10. 14. 23.  0.  3. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 16
 29  8  0 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  7.  8.  7.  7. 10.  8.  9.  9.  8. 10.  8.] 
adversary cards in hand: [10.  6.  3.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 16  3 15  6  6  3  8 10  0  6] -> size -> 16 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1. 16.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  8.  0.  0.] 
cards in discard: [ 1.  0.  0. 11.  3.  0.  0. 15. 11. 11.  3. 10. 14. 23.  0.  3. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 16
 29  8  0 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 27. 30.  8.  7.  8.  7.  7. 10.  8.  9.  9.  8. 10.  8.] 
adversary cards in hand: [10.  6.  3.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 16  3 15  6  6  3  8 10  0  6] -> size -> 16 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 1.  0.  0. 11.  3.  0.  0. 15. 11. 11.  3. 10. 14. 23.  0.  3. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 27. 30.  8.  7.  8.  7.  7. 10.  8.  9.  9.  8. 10.  8.] 
adversary cards in hand: [10.  6.  3.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 16  3 15  6  6  3  8 10  0  6] -> size -> 16 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 1.  0.  0. 11.  3.  0.  0. 15. 11. 11.  3. 10. 14. 23.  0.  3. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 27. 30.  8.  7.  8.  7.  7. 10.  8.  9.  9.  8. 10.  8.] 
adversary cards in hand: [10.  6.  3.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 16  3 15  6  6  3  8 10  0  6] -> size -> 16 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 1.  0.  0. 11.  3.  0.  0. 15. 11. 11.  3. 10. 14. 23.  0.  3. 29.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0
 10  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 29. 30. 27. 30.  8.  7.  8.  7.  7. 10.  8.  9.  9.  8. 10.  8.] 
adversary cards in hand: [10.  6.  3.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 16  3 15  6  6  3  8 10  0  6] -> size -> 16 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [10.  6.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[227.36981]
 [212.46533]
 [213.43407]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  3.  8.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  3 15  6  6  3  8 10  0  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  7.  8.  7.  7. 10.  8.  9.  9.  8. 10.  8.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [ 1.  0.  0. 11.  3.  0.  0. 15. 11. 11.  3. 10. 14. 23.  0.  3. 29.  0.
 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0
 10  0] -> size -> 26 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1.0
Learning step: -5.006043910980225
desired expected reward: 159.7575225830078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[206.72485]
 [200.7744 ]
 [227.88293]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  3.  8.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  3 15  6  6  3  8 10  0  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 29. 30. 27. 30.  8.  7.  8.  7.  7. 10.  8.  9.  9.  8. 10.  8.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [ 1.  0.  0. 11.  3.  0.  0. 15. 11. 11.  3. 10. 14. 23.  0.  3. 29.  0.
 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0
 10  0] -> size -> 26 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -8.04765796661377
desired expected reward: 216.9607391357422



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [8. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [ 1.  0.  0. 11.  3.  0.  0. 15. 11. 11.  3. 10. 14. 23.  0.  3. 29.  0.
 29.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0
 10  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  7.  8.  7.  7. 10.  8.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 6.  0.  3.  3. 15.] 
adversary cards in discard: [10.  6.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 16  3 15  6  6  3  8 10  0  6] -> size -> 16 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [ 1.  0.  0. 11.  3.  0.  0. 15. 11. 11.  3. 10. 14. 23.  0.  3. 29.  0.
 29.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0
 10  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 29. 30. 27. 30.  8.  7.  8.  7.  7. 10.  8.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 6.  0.  3.  3. 15.] 
adversary cards in discard: [10.  6.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 16  3 15  6  6  3  8 10  0  6] -> size -> 16 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [ 1.  0.  0. 11.  3.  0.  0. 15. 11. 11.  3. 10. 14. 23.  0.  3. 29.  0.
 29.  8.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0
 10  0 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  7.  8.  7.  7. 10.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 6.  0.  3.  3. 15.] 
adversary cards in discard: [10.  6.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 16  3 15  6  6  3  8 10  0  6] -> size -> 16 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [ 6.  0.  3.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[218.51439]
 [208.04903]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3.  3. 15.] 
cards in discard: [10.  6.  3.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  3 15  6  6  3  8 10  0  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 27. 30.  8.  7.  8.  7.  7. 10.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 3.  3. 15. 29. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0
 10  0 10] -> size -> 27 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1.0
Learning step: -8.384108543395996
desired expected reward: 219.4988250732422



action possibilites: [-1] 
expected returns: [[165.76312]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3.] 
cards in discard: [10.  6.  3.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3 16  3 15  6  6  3  8 10  0  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 29. 30. 27. 30.  8.  7.  8.  7.  7. 10.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 3.  3. 15. 29. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0
 10  0 10] -> size -> 27 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action 15.0
Learning step: -7.076147556304932
desired expected reward: 195.04022216796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[147.36723]
 [153.73878]
 [152.94144]
 [141.82903]
 [160.70332]
 [154.65065]
 [153.85329]
 [167.7997 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3.] 
cards in discard: [10.  6.  3.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3 16  3 15  6  6  3  8 10  0  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 29. 30. 27. 30.  8.  7.  8.  7.  7. 10.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 3.  3. 15. 29. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0
 10  0 10] -> size -> 27 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1
Learning step: -5.403768539428711
desired expected reward: 160.35935974121094



buy possibilites: [-1] 
expected returns: [[234.09991]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3.] 
cards in discard: [10.  6.  3.  8.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3 16  3 15  6  6  3  8 10  0  6  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 27. 30.  8.  7.  8.  7.  7. 10.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 3.  3. 15. 29. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0
 10  0 10] -> size -> 27 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: 4 

action type: buy - action 1.0
Learning step: -2.2196929454803467
desired expected reward: 151.5191192626953






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 3.  3. 15. 29. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29. 14.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 15. 29. 14.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0
 10  0 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 27. 30.  8.  7.  8.  7.  7. 10.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [16.  3.  0.  0.  0.] 
adversary cards in discard: [10.  6.  3.  8.  0.  1. 15.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3 16  3 15  6  6  3  8 10  0  6  1] -> size -> 16 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29. 14.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0
 10  0 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 27. 30.  8.  7.  8.  7.  7. 10.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [16.  3.  0.  0.  0.] 
adversary cards in discard: [10.  6.  3.  8.  0.  1. 15.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3 16  3 15  6  6  3  8 10  0  6  1] -> size -> 16 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 29. 14.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0
 10  0 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 28. 30. 27. 30.  8.  7.  8.  7.  7. 10.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [16.  3.  0.  0.  0.] 
adversary cards in discard: [10.  6.  3.  8.  0.  1. 15.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3 16  3 15  6  6  3  8 10  0  6  1] -> size -> 16 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [16.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[140.2026 ]
 [122.91488]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  0.  0.  0.] 
cards in discard: [10.  6.  3.  8.  0.  1. 15.  6.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 16  3 15  6  6  3  8 10  0  6  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 27. 30.  8.  7.  8.  7.  7. 10.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 0. 11. 11.  0.  0.] 
adversary cards in discard: [15.  3.  3. 29. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0
 10  0 10] -> size -> 27 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -10.451801300048828
desired expected reward: 223.6481170654297



action possibilites: [-1] 
expected returns: [[102.34074]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [10.  6.  3.  8.  0.  1. 15.  6.  3.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3 16  3 15  6  6  3  8 10  0  6  1 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 27. 30.  8.  7.  8.  7.  7. 10.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [ 0. 11. 11.  0.  0.] 
adversary cards in discard: [15.  3.  3. 29. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0
 10  0 10] -> size -> 27 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -16 

action type: gain_card_n - action 9
Learning step: -4.1467485427856445
desired expected reward: 108.84154510498047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 86.23469 ]
 [ 92.401985]
 [ 91.51187 ]
 [ 80.28508 ]
 [ 98.97552 ]
 [ 93.29421 ]
 [ 92.40409 ]
 [106.54688 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [10.  6.  3.  8.  0.  1. 15.  6.  3.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3 16  3 15  6  6  3  8 10  0  6  1 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 28. 30. 27. 30.  8.  7.  8.  7.  7. 10.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [ 0. 11. 11.  0.  0.] 
adversary cards in discard: [15.  3.  3. 29. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0
 10  0 10] -> size -> 27 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: -4.162943363189697
desired expected reward: 98.17779541015625






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 0. 11. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  0.  0.] 
cards in discard: [15.  3.  3. 29. 14.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0
 10  0 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 27. 30.  8.  7.  8.  7.  7. 10.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [ 3. 16.  0.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 16  3 15  6  6  3  8 10  0  6  1 10] -> size -> 16 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [15.  3.  3. 29. 14. 14.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0
 10  0 10 14] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 27. 30.  8.  7.  8.  7.  7. 10.  8.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 3. 16.  0.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 16  3 15  6  6  3  8 10  0  6  1 10] -> size -> 16 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [15.  3.  3. 29. 14. 14.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0
 10  0 10 14] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 28. 30. 27. 30.  8.  7.  8.  7.  7. 10.  8.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 3. 16.  0.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 16  3 15  6  6  3  8 10  0  6  1 10] -> size -> 16 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [15.  3.  3. 29. 14. 14.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0
 10  0 10 14  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 26. 30.  8.  7.  8.  7.  7. 10.  8.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 3. 16.  0.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 16  3 15  6  6  3  8 10  0  6  1 10] -> size -> 16 
adversary victory points: 0
player victory points: 5 





Player: 0 
cards in hand: [ 3. 16.  0.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[143.35597]
 [127.98426]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  0.  3.  6.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 16  3 15  6  6  3  8 10  0  6  1 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  7.  8.  7.  7. 10.  8.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 3. 29.  8. 11.  0.] 
adversary cards in discard: [15.  3.  3. 29. 14. 14.  3. 11.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0
 10  0 10 14  3] -> size -> 29 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1.0
Learning step: -5.017724514007568
desired expected reward: 101.52916717529297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[121.96056 ]
 [116.363884]
 [142.06042 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  0.  3.  6.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 16  3 15  6  6  3  8 10  0  6  1 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 30. 26. 30.  8.  7.  8.  7.  7. 10.  8.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 3. 29.  8. 11.  0.] 
adversary cards in discard: [15.  3.  3. 29. 14. 14.  3. 11.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0
 10  0 10 14  3] -> size -> 29 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -6.803536891937256
desired expected reward: 133.9322052001953



buy possibilites: [-1] 
expected returns: [[153.76129]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  0.  3.  6.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 16  3 15  6  6  3  8 10  0  6  1 10  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 26. 30.  8.  6.  8.  7.  7. 10.  8.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 3. 29.  8. 11.  0.] 
adversary cards in discard: [15.  3.  3. 29. 14. 14.  3. 11.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0
 10  0 10 14  3] -> size -> 29 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -60.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -366.0 

action type: buy - action 6.0
Learning step: -20.658567428588867
desired expected reward: 95.70531463623047






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 3. 29.  8. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 11.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  8. 11.  0.] 
cards in discard: [15.  3.  3. 29. 14. 14.  3. 11.  0. 11.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0
 10  0 10 14  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  6.  8.  7.  7. 10.  8.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 1.  0.  6.  0. 10.] 
adversary cards in discard: [ 6.  3. 16.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  3 16  3 15  6  6  3  8 10  0  6  1 10  6] -> size -> 17 
adversary victory points: -1
player victory points: 5 


action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 11.  0.  3.] 
cards in discard: [15.  3.  3. 29. 14. 14.  3. 11.  0. 11.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29 11  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0
 10  0 10 14  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 26. 30.  8.  6.  8.  7.  7. 10.  8.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 1.  0.  6.  0. 10.] 
adversary cards in discard: [ 6.  3. 16.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  3 16  3 15  6  6  3  8 10  0  6  1 10  6] -> size -> 17 
adversary victory points: -1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [15.  3.  3. 29. 14. 14.  3. 11.  0. 11.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  3  3 29  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0 10  0 10
 14  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 26. 30.  8.  6.  8.  7.  7. 10.  8.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 1.  0.  6.  0. 10.] 
adversary cards in discard: [ 6.  3. 16.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  3 16  3 15  6  6  3  8 10  0  6  1 10  6] -> size -> 17 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [15.  3.  3. 29. 14. 14.  3. 11.  0. 11.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  3  3 29  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0 10  0 10
 14  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 30. 26. 30.  8.  6.  8.  7.  7. 10.  8.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 1.  0.  6.  0. 10.] 
adversary cards in discard: [ 6.  3. 16.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  3 16  3 15  6  6  3  8 10  0  6  1 10  6] -> size -> 17 
adversary victory points: -1
player victory points: 4 





Player: 0 
cards in hand: [ 1.  0.  6.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[150.43095]
 [135.34883]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  6.  0. 10.] 
cards in discard: [ 6.  3. 16.  0.  3.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 16  3 15  6  6  3  8 10  0  6  1 10  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  6.  8.  7.  7. 10.  8.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 1.  0.  8. 10.  0.] 
adversary cards in discard: [15.  3.  3. 29. 14. 14.  3. 11.  0. 11.  0.  0. 29.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3 29  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0 10  0 10
 14  3] -> size -> 26 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -7.305915832519531
desired expected reward: 146.45538330078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[127.77979]
 [134.58923]
 [133.84703]
 [121.65175]
 [132.68564]
 [142.16812]
 [135.5355 ]
 [143.19986]
 [129.61168]
 [134.7933 ]
 [136.98647]
 [149.97104]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  6.  0. 10.] 
cards in discard: [ 6.  3. 16.  0.  3.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 16  3 15  6  6  3  8 10  0  6  1 10  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 28. 30. 26. 30.  8.  6.  8.  7.  7. 10.  8.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 1.  0.  8. 10.  0.] 
adversary cards in discard: [15.  3.  3. 29. 14. 14.  3. 11.  0. 11.  0.  0. 29.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3 29  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0 10  0 10
 14  3] -> size -> 26 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -6.922580242156982
desired expected reward: 138.901611328125



buy possibilites: [-1] 
expected returns: [[134.2733]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  6.  0. 10.] 
cards in discard: [ 6.  3. 16.  0.  3.  6. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 16  3 15  6  6  3  8 10  0  6  1 10  6 16] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  6.  7.  7.  7. 10.  8.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 1.  0.  8. 10.  0.] 
adversary cards in discard: [15.  3.  3. 29. 14. 14.  3. 11.  0. 11.  0.  0. 29.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3 29  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0 10  0 10
 14  3] -> size -> 26 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: -24 

action type: buy - action 16.0
Learning step: -4.374598979949951
desired expected reward: 119.54035949707031






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 1.  0.  8. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  8. 10.  0.] 
cards in discard: [15.  3.  3. 29. 14. 14.  3. 11.  0. 11.  0.  0. 29.  8.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0 10  0 10
 14  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  6.  7.  7.  7. 10.  8.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 3. 10.  8. 15.  6.] 
adversary cards in discard: [ 6.  3. 16.  0.  3.  6. 16.  1.  0.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  3 16  3 15  6  6  3  8 10  0  6  1 10  6 16] -> size -> 18 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  8. 10.  0.] 
cards in discard: [15.  3.  3. 29. 14. 14.  3. 11.  0. 11.  0.  0. 29.  8.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0 10  0 10
 14  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 28. 30. 26. 30.  8.  6.  7.  7.  7. 10.  8.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 3. 10.  8. 15.  6.] 
adversary cards in discard: [ 6.  3. 16.  0.  3.  6. 16.  1.  0.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  3 16  3 15  6  6  3  8 10  0  6  1 10  6 16] -> size -> 18 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  8. 10.  0.] 
cards in discard: [15.  3.  3. 29. 14. 14.  3. 11.  0. 11.  0.  0. 29.  8.  3. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0 10  0 10
 14  3 16] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  6.  6.  7.  7. 10.  8.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 3. 10.  8. 15.  6.] 
adversary cards in discard: [ 6.  3. 16.  0.  3.  6. 16.  1.  0.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  3 16  3 15  6  6  3  8 10  0  6  1 10  6 16] -> size -> 18 
adversary victory points: -1
player victory points: 4 





Player: 0 
cards in hand: [ 3. 10.  8. 15.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 15.] 
expected returns: [[174.14772]
 [163.03986]
 [163.72615]
 [164.58409]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  8. 15.  6.] 
cards in discard: [ 6.  3. 16.  0.  3.  6. 16.  1.  0.  6.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 16  3 15  6  6  3  8 10  0  6  1 10  6 16] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  6.  6.  7.  7. 10.  8.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 23.  0.] 
adversary cards in discard: [15.  3.  3. 29. 14. 14.  3. 11.  0. 11.  0.  0. 29.  8.  3. 16.  1.  0.
  8. 10.  0.] 
adversary owned cards: [ 0  0  0  3  3 29  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0 10  0 10
 14  3 16] -> size -> 27 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -5.727586269378662
desired expected reward: 128.54571533203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[156.47548]
 [151.58334]
 [172.78072]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  8. 15.  6.] 
cards in discard: [ 6.  3. 16.  0.  3.  6. 16.  1.  0.  6.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 16  3 15  6  6  3  8 10  0  6  1 10  6 16] -> size -> 18 
action values: 1 
buys: 1 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  6.  6.  7.  7. 10.  8.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 23.  0.] 
adversary cards in discard: [15.  3.  3. 29. 14. 14.  3. 11.  0. 11.  0.  0. 29.  8.  3. 16.  1.  0.
  8. 10.  0.] 
adversary owned cards: [ 0  0  0  3  3 29  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0 10  0 10
 14  3 16] -> size -> 27 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -7.74160623550415
desired expected reward: 165.35154724121094



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 23.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 23.  0.] 
cards in discard: [15.  3.  3. 29. 14. 14.  3. 11.  0. 11.  0.  0. 29.  8.  3. 16.  1.  0.
  8. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0 10  0 10
 14  3 16] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  6.  6.  7.  7. 10.  8.  8.  9.  6. 10.  8.] 
adversary cards in hand: [10.  3.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 16  3 15  6  6  3  8 10  0  6  1 10  6 16] -> size -> 18 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [15.  3.  3. 29. 14. 14.  3. 11.  0. 11.  0.  0. 29.  8.  3. 16.  1.  0.
  8. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  3  3 29  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0 10  0 10
 14  3 16] -> size -> 27 
action values: 1 
buys: 1 
player value: 1 
card supply: [23. 28. 30. 26. 30.  8.  6.  6.  7.  7. 10.  8.  8.  9.  6. 10.  8.] 
adversary cards in hand: [10.  3.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 16  3 15  6  6  3  8 10  0  6  1 10  6 16] -> size -> 18 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [15.  3.  3. 29. 14. 14.  3. 11.  0. 11.  0.  0. 29.  8.  3. 16.  1.  0.
  8. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  3  3 29  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0 10  0 10
 14  3 16] -> size -> 27 
action values: 0 
buys: 2 
player value: 5 
card supply: [23. 28. 30. 26. 30.  8.  6.  6.  7.  7. 10.  8.  8.  9.  6. 10.  8.] 
adversary cards in hand: [10.  3.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 16  3 15  6  6  3  8 10  0  6  1 10  6 16] -> size -> 18 
adversary victory points: -1
player victory points: 4 


buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [15.  3.  3. 29. 14. 14.  3. 11.  0. 11.  0.  0. 29.  8.  3. 16.  1.  0.
  8. 10.  0.  4.] 
cards in deck: 0 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  3  3 29  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0 10  0 10
 14  3 16  4] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 28. 30. 26. 29.  8.  6.  6.  7.  7. 10.  8.  8.  9.  6. 10.  8.] 
adversary cards in hand: [10.  3.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 16  3 15  6  6  3  8 10  0  6  1 10  6 16] -> size -> 18 
adversary victory points: -1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [15.  3.  3. 29. 14. 14.  3. 11.  0. 11.  0.  0. 29.  8.  3. 16.  1.  0.
  8. 10.  0.  4.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  3  3 29  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0 10  0 10
 14  3 16  4  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 29.  8.  6.  6.  7.  7. 10.  8.  8.  9.  6. 10.  8.] 
adversary cards in hand: [10.  3.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 16  3 15  6  6  3  8 10  0  6  1 10  6 16] -> size -> 18 
adversary victory points: -1
player victory points: 7 





Player: 0 
cards in hand: [10.  3.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[191.02812]
 [177.06508]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 16  3 15  6  6  3  8 10  0  6  1 10  6 16] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 29.  8.  6.  6.  7.  7. 10.  8.  8.  9.  6. 10.  8.] 
adversary cards in hand: [10. 29.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0 10  0 10
 14  3 16  4  0] -> size -> 29 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1.0
Learning step: -8.84271240234375
desired expected reward: 163.93800354003906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[172.90663]
 [178.44234]
 [166.6133 ]
 [180.33488]
 [193.31226]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 16  3 15  6  6  3  8 10  0  6  1 10  6 16] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 26. 29.  8.  6.  6.  7.  7. 10.  8.  8.  9.  6. 10.  8.] 
adversary cards in hand: [10. 29.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0 10  0 10
 14  3 16  4  0] -> size -> 29 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: take_action - action -1.0
Learning step: -9.477879524230957
desired expected reward: 176.8848419189453



buy possibilites: [-1] 
expected returns: [[151.04709]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  3.  0.] 
cards in discard: [8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 16  3 15  6  6  3  8 10  0  6  1 10  6 16  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 29.  8.  6.  6.  7.  6. 10.  8.  8.  9.  6. 10.  8.] 
adversary cards in hand: [10. 29.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0 10  0 10
 14  3 16  4  0] -> size -> 29 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -78 

action type: buy - action 8.0
Learning step: -9.518184661865234
desired expected reward: 170.8166961669922






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [10. 29.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0 10  0 10
 14  3 16  4  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 29.  8.  6.  6.  7.  6. 10.  8.  8.  9.  6. 10.  8.] 
adversary cards in hand: [6. 3. 6. 8. 0.] 
adversary cards in discard: [ 8. 10.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3 16  3 15  6  6  3  8 10  0  6  1 10  6 16  8] -> size -> 19 
adversary victory points: -1
player victory points: 7 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 29  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0 10  0 10
 14  3 16  4  0] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 29.  8.  6.  6.  7.  6. 10.  8.  8.  9.  6. 10.  8.] 
adversary cards in hand: [6. 3. 6. 8. 0.] 
adversary cards in discard: [ 8. 10.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3 16  3 15  6  6  3  8 10  0  6  1 10  6 16  8] -> size -> 19 
adversary victory points: -1
player victory points: 7 


action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 15.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  3  3 29  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0 10  0 10
 14  3 16  4  0] -> size -> 29 
action values: 2 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 26. 29.  8.  6.  6.  7.  6. 10.  8.  8.  9.  6. 10.  8.] 
adversary cards in hand: [6. 3. 6. 8. 0.] 
adversary cards in discard: [ 8. 10.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3 16  3 15  6  6  3  8 10  0  6  1 10  6 16  8] -> size -> 19 
adversary victory points: -1
player victory points: 7 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [10. 29. 15.] 
owned cards: [ 0  0  3  3 29  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0 10  0 10 14
  3 16  4  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 4 
card supply: [22. 28. 30. 26. 29.  8.  6.  6.  7.  6. 10.  8.  8.  9.  6. 10.  8.] 
adversary cards in hand: [6. 3. 6. 8. 0.] 
adversary cards in discard: [ 8. 10.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3 16  3 15  6  6  3  8 10  0  6  1 10  6 16  8] -> size -> 19 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [10. 29. 15.] 
owned cards: [ 0  0  3  3 29  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0 10  0 10 14
  3 16  4  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 6 
card supply: [22. 28. 30. 26. 29.  8.  6.  6.  7.  6. 10.  8.  8.  9.  6. 10.  8.] 
adversary cards in hand: [6. 3. 6. 8. 0.] 
adversary cards in discard: [ 8. 10.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3 16  3 15  6  6  3  8 10  0  6  1 10  6 16  8] -> size -> 19 
adversary victory points: -1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10. 29. 15.] 
owned cards: [ 0  0  3  3 29  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0 10  0 10 14
  3 16  4  0  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 4 
card supply: [22. 28. 30. 26. 29.  8.  6.  6.  7.  5. 10.  8.  8.  9.  6. 10.  8.] 
adversary cards in hand: [6. 3. 6. 8. 0.] 
adversary cards in discard: [ 8. 10.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3 16  3 15  6  6  3  8 10  0  6  1 10  6 16  8] -> size -> 19 
adversary victory points: -1
player victory points: 7 





Player: 0 
cards in hand: [6. 3. 6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[148.57748]
 [138.55276]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 6. 8. 0.] 
cards in discard: [ 8. 10.  3.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 16  3 15  6  6  3  8 10  0  6  1 10  6 16  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 29.  8.  6.  6.  7.  5. 10.  8.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 0.  3. 10.  0. 14.] 
adversary cards in discard: [ 8. 10. 29. 15.  3.  0.  0.] 
adversary owned cards: [ 0  0  3  3 29  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0 10  0 10 14
  3 16  4  0  8] -> size -> 29 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1
Learning step: -8.630194664001465
desired expected reward: 142.41690063476562



action possibilites: [-1] 
expected returns: [[224.33315]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 8. 10.  3.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 16  3 15  3  8 10  0  6  1 10  6 16  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 29.  8.  6.  6.  7.  5. 10.  8.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 0.  3. 10.  0. 14.] 
adversary cards in discard: [ 8. 10. 29. 15.  3.  0.  0.] 
adversary owned cards: [ 0  0  3  3 29  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0 10  0 10 14
  3 16  4  0  8] -> size -> 29 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: trash_cards_n_from_hand - action 11
Learning step: -4.114658832550049
desired expected reward: 135.12843322753906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[210.86552]
 [204.72418]
 [229.32072]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 8. 10.  3.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 16  3 15  3  8 10  0  6  1 10  6 16  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 28. 30. 26. 29.  8.  6.  6.  7.  5. 10.  8.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 0.  3. 10.  0. 14.] 
adversary cards in discard: [ 8. 10. 29. 15.  3.  0.  0.] 
adversary owned cards: [ 0  0  3  3 29  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0 10  0 10 14
  3 16  4  0  8] -> size -> 29 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1
Learning step: -8.45727825164795
desired expected reward: 215.87586975097656






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 10.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  0. 14.] 
cards in discard: [ 8. 10. 29. 15.  3.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 29  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0 10  0 10 14
  3 16  4  0  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 29.  8.  6.  6.  7.  5. 10.  8.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 1.  6. 16.  0. 15.] 
adversary cards in discard: [ 8. 10.  3.  0.  3.  0.  8.  3.] 
adversary owned cards: [ 0  0  3 16  3 15  3  8 10  0  6  1 10  6 16  8] -> size -> 16 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0. 14.] 
cards in discard: [ 8. 10. 29. 15.  3.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 29  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0 10  0 10 14
  3 16  4  0  8] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 26. 29.  8.  6.  6.  7.  5. 10.  8.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 1.  6. 16.  0. 15.] 
adversary cards in discard: [ 8. 10.  3.  0.  3.  0.  8.  3.] 
adversary owned cards: [ 0  0  3 16  3 15  3  8 10  0  6  1 10  6 16  8] -> size -> 16 
adversary victory points: 1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0. 14.] 
cards in discard: [ 8. 10. 29. 15.  3.  0.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 29  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0 10  0 10 14
  3 16  4  0  8  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 28. 30. 26. 29.  8.  6.  6.  7.  5. 10.  8.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 1.  6. 16.  0. 15.] 
adversary cards in discard: [ 8. 10.  3.  0.  3.  0.  8.  3.] 
adversary owned cards: [ 0  0  3 16  3 15  3  8 10  0  6  1 10  6 16  8] -> size -> 16 
adversary victory points: 1
player victory points: 7 





Player: 0 
cards in hand: [ 1.  6. 16.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 15.] 
expected returns: [[123.84902]
 [109.73239]
 [113.21743]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6. 16.  0. 15.] 
cards in discard: [ 8. 10.  3.  0.  3.  0.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 16  3 15  3  8 10  0  6  1 10  6 16  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 26. 29.  8.  6.  6.  7.  5. 10.  8.  8.  9.  6. 10.  8.] 
adversary cards in hand: [23.  8.  3. 14. 16.] 
adversary cards in discard: [ 8. 10. 29. 15.  3.  0.  0.  0.  0.  3. 10.  0. 14.] 
adversary owned cards: [ 0  0  3  3 29  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0 10  0 10 14
  3 16  4  0  8  0] -> size -> 30 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: buy - action -1.0
Learning step: -12.035459518432617
desired expected reward: 217.28526306152344



action possibilites: [-1] 
expected returns: [[67.01153]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 15.] 
cards in discard: [ 8. 10.  3.  0.  3.  0.  8.  3. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3 16  3 15  3  8 10  0  6 10  6 16  8 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 26. 29.  8.  6.  6.  7.  5. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [23.  8.  3. 14. 16.] 
adversary cards in discard: [ 8. 10. 29. 15.  3.  0.  0.  0.  0.  3. 10.  0. 14.] 
adversary owned cards: [ 0  0  3  3 29  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0 10  0 10 14
  3 16  4  0  8  0] -> size -> 30 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -28 

action type: gain_card_n - action 9
Learning step: -8.116947174072266
desired expected reward: 156.37718200683594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[59.47212 ]
 [56.710842]
 [68.87206 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 15.] 
cards in discard: [ 8. 10.  3.  0.  3.  0.  8.  3. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3 16  3 15  3  8 10  0  6 10  6 16  8 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 28. 30. 26. 29.  8.  6.  6.  7.  5. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [23.  8.  3. 14. 16.] 
adversary cards in discard: [ 8. 10. 29. 15.  3.  0.  0.  0.  0.  3. 10.  0. 14.] 
adversary owned cards: [ 0  0  3  3 29  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0 10  0 10 14
  3 16  4  0  8  0] -> size -> 30 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1
Learning step: -4.101287841796875
desired expected reward: 62.910240173339844



buy possibilites: [-1] 
expected returns: [[103.82298]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 15.] 
cards in discard: [ 8. 10.  3.  0.  3.  0.  8.  3. 29.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3 16  3 15  3  8 10  0  6 10  6 16  8 29  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 28. 30. 26. 29.  8.  5.  6.  7.  5. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [23.  8.  3. 14. 16.] 
adversary cards in discard: [ 8. 10. 29. 15.  3.  0.  0.  0.  0.  3. 10.  0. 14.] 
adversary owned cards: [ 0  0  3  3 29  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0 10  0 10 14
  3 16  4  0  8  0] -> size -> 30 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -70.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -355.0 

action type: buy - action 6.0
Learning step: -17.975452423095703
desired expected reward: 38.735374450683594






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [23.  8.  3. 14. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8. 14. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  8.  3. 14. 16.] 
cards in discard: [ 8. 10. 29. 15.  3.  0.  0.  0.  0.  3. 10.  0. 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 29  3 11 11  0  0  0  0 15  1 14 23  8 29  8  0 10  0 10 14
  3 16  4  0  8  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 26. 29.  8.  5.  6.  7.  5. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [15. 16.  6. 16. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 16  3 15  3  8 10  0  6 10  6 16  8 29  6] -> size -> 17 
adversary victory points: 0
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  3. 16.] 
cards in discard: [ 8. 10. 29. 15.  3.  0.  0.  0.  0.  3. 10.  0. 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3
 16  4  0  8  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 26. 29.  8.  5.  6.  7.  5. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [15. 16.  6. 16. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 16  3 15  3  8 10  0  6 10  6 16  8 29  6] -> size -> 17 
adversary victory points: 0
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  3. 16.] 
cards in discard: [ 8. 10. 29. 15.  3.  0.  0.  0.  0.  3. 10.  0. 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3
 16  4  0  8  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 28. 30. 26. 29.  8.  5.  6.  7.  5. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [15. 16.  6. 16. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 16  3 15  3  8 10  0  6 10  6 16  8 29  6] -> size -> 17 
adversary victory points: 0
player victory points: 7 





Player: 0 
cards in hand: [15. 16.  6. 16. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16. 16. 10.] 
expected returns: [[121.841385]
 [111.50319 ]
 [108.16525 ]
 [108.16525 ]
 [109.79789 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 16.  6. 16. 10.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 16  3 15  3  8 10  0  6 10  6 16  8 29  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 26. 29.  8.  5.  6.  7.  5. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 1. 29.  0. 11.  0.] 
adversary cards in discard: [ 8. 10. 29. 15.  3.  0.  0.  0.  0.  3. 10.  0. 14.  8. 23.  3. 16.] 
adversary owned cards: [ 0  0  3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3
 16  4  0  8  0] -> size -> 29 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: buy - action -1
Learning step: -6.434510707855225
desired expected reward: 97.38847351074219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[104.02386]
 [ 99.73852]
 [121.01891]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 16.  6. 16. 10.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 16  3 15  3  8 10  0  6 10  6 16  8 29  6] -> size -> 17 
action values: 1 
buys: 1 
player value: 0 
card supply: [21. 28. 30. 26. 29.  8.  5.  6.  7.  5. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 1. 29.  0. 11.  0.] 
adversary cards in discard: [ 8. 10. 29. 15.  3.  0.  0.  0.  0.  3. 10.  0. 14.  8. 23.  3. 16.] 
adversary owned cards: [ 0  0  3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3
 16  4  0  8  0] -> size -> 29 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1.0
Learning step: -7.077444553375244
desired expected reward: 110.36772155761719



buy possibilites: [-1] 
expected returns: [[102.07988]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 16.  6. 16. 10.] 
cards in discard: [0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 16  3 15  3  8 10  0  6 10  6 16  8 29  6  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 26. 29.  8.  5.  6.  7.  5. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 1. 29.  0. 11.  0.] 
adversary cards in discard: [ 8. 10. 29. 15.  3.  0.  0.  0.  0.  3. 10.  0. 14.  8. 23.  3. 16.] 
adversary owned cards: [ 0  0  3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3
 16  4  0  8  0] -> size -> 29 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -105 

action type: buy - action 0.0
Learning step: -8.154396057128906
desired expected reward: 95.86946105957031






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 1. 29.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  0. 11.  0.] 
cards in discard: [ 8. 10. 29. 15.  3.  0.  0.  0.  0.  3. 10.  0. 14.  8. 23.  3. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3
 16  4  0  8  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 26. 29.  8.  5.  6.  7.  5. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 3. 10.  0.  0.  3.] 
adversary cards in discard: [ 0. 15. 16.  6. 16. 10.] 
adversary owned cards: [ 0  0  3 16  3 15  3  8 10  0  6 10  6 16  8 29  6  0] -> size -> 18 
adversary victory points: 0
player victory points: 7 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 11.  0.  3.] 
cards in discard: [ 8. 10. 29. 15.  3.  0.  0.  0.  0.  3. 10.  0. 14.  8. 23.  3. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3
 16  4  0  8  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 26. 29.  8.  5.  6.  7.  5. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 3. 10.  0.  0.  3.] 
adversary cards in discard: [ 0. 15. 16.  6. 16. 10.] 
adversary owned cards: [ 0  0  3 16  3 15  3  8 10  0  6 10  6 16  8 29  6  0] -> size -> 18 
adversary victory points: 0
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 11.  0.  3.] 
cards in discard: [ 8. 10. 29. 15.  3.  0.  0.  0.  0.  3. 10.  0. 14.  8. 23.  3. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3
 16  4  0  8  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 28. 30. 26. 29.  8.  5.  6.  7.  5. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 3. 10.  0.  0.  3.] 
adversary cards in discard: [ 0. 15. 16.  6. 16. 10.] 
adversary owned cards: [ 0  0  3 16  3 15  3  8 10  0  6 10  6 16  8 29  6  0] -> size -> 18 
adversary victory points: 0
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 11.  0.  3.] 
cards in discard: [ 8. 10. 29. 15.  3.  0.  0.  0.  0.  3. 10.  0. 14.  8. 23.  3. 16.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3
 16  4  0  8  0  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 28. 30. 25. 29.  8.  5.  6.  7.  5. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 3. 10.  0.  0.  3.] 
adversary cards in discard: [ 0. 15. 16.  6. 16. 10.] 
adversary owned cards: [ 0  0  3 16  3 15  3  8 10  0  6 10  6 16  8 29  6  0] -> size -> 18 
adversary victory points: 0
player victory points: 8 





Player: 0 
cards in hand: [ 3. 10.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[154.97072]
 [142.25763]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.  3.] 
cards in discard: [ 0. 15. 16.  6. 16. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 16  3 15  3  8 10  0  6 10  6 16  8 29  6  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 25. 29.  8.  5.  6.  7.  5. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [0. 8. 0. 4. 0.] 
adversary cards in discard: [ 8. 10. 29. 15.  3.  0.  0.  0.  0.  3. 10.  0. 14.  8. 23.  3. 16.  3.
 29.  1.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3
 16  4  0  8  0  3] -> size -> 30 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: buy - action -1
Learning step: -6.008565425872803
desired expected reward: 96.0713119506836



action possibilites: [-1.] 
expected returns: [[113.14893]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 6.] 
cards in discard: [ 0. 15. 16.  6. 16. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3 16  3 15  3  8 10  0  6 10  6 16  8 29  6  0] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 25. 29.  8.  5.  6.  7.  5. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [0. 8. 0. 4. 0.] 
adversary cards in discard: [ 8. 10. 29. 15.  3.  0.  0.  0.  0.  3. 10.  0. 14.  8. 23.  3. 16.  3.
 29.  1.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3
 16  4  0  8  0  3] -> size -> 30 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action 10.0
Learning step: -7.699979305267334
desired expected reward: 132.2166290283203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 97.645454]
 [102.33726 ]
 [ 92.71103 ]
 [103.716125]
 [114.7605  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 6.] 
cards in discard: [ 0. 15. 16.  6. 16. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3 16  3 15  3  8 10  0  6 10  6 16  8 29  6  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 28. 30. 25. 29.  8.  5.  6.  7.  5. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [0. 8. 0. 4. 0.] 
adversary cards in discard: [ 8. 10. 29. 15.  3.  0.  0.  0.  0.  3. 10.  0. 14.  8. 23.  3. 16.  3.
 29.  1.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3
 16  4  0  8  0  3] -> size -> 30 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: -6.500207424163818
desired expected reward: 106.64872741699219






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [0. 8. 0. 4. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 4. 0.] 
cards in discard: [ 8. 10. 29. 15.  3.  0.  0.  0.  0.  3. 10.  0. 14.  8. 23.  3. 16.  3.
 29.  1.  0. 11.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3
 16  4  0  8  0  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 25. 29.  8.  5.  6.  7.  5. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 8.  8. 29.  0.  3.] 
adversary cards in discard: [ 0. 15. 16.  6. 16. 10. 10.  3.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  3 16  3 15  3  8 10  0  6 10  6 16  8 29  6  0] -> size -> 18 
adversary victory points: 0
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 4. 0.] 
cards in discard: [ 8. 10. 29. 15.  3.  0.  0.  0.  0.  3. 10.  0. 14.  8. 23.  3. 16.  3.
 29.  1.  0. 11.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3
 16  4  0  8  0  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 28. 30. 25. 29.  8.  5.  6.  7.  5. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 8.  8. 29.  0.  3.] 
adversary cards in discard: [ 0. 15. 16.  6. 16. 10. 10.  3.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  3 16  3 15  3  8 10  0  6 10  6 16  8 29  6  0] -> size -> 18 
adversary victory points: 0
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 4. 0.] 
cards in discard: [ 8. 10. 29. 15.  3.  0.  0.  0.  0.  3. 10.  0. 14.  8. 23.  3. 16.  3.
 29.  1.  0. 11.  0.  3.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3
 16  4  0  8  0  3  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 25. 29.  8.  5.  6.  7.  5. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 8.  8. 29.  0.  3.] 
adversary cards in discard: [ 0. 15. 16.  6. 16. 10. 10.  3.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  3 16  3 15  3  8 10  0  6 10  6 16  8 29  6  0] -> size -> 18 
adversary victory points: 0
player victory points: 8 





Player: 0 
cards in hand: [ 8.  8. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 29.] 
expected returns: [[89.22867 ]
 [79.160614]
 [79.160614]
 [83.945946]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 29.  0.  3.] 
cards in discard: [ 0. 15. 16.  6. 16. 10. 10.  3.  0.  0.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 16  3 15  3  8 10  0  6 10  6 16  8 29  6  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 25. 29.  8.  5.  6.  7.  5. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 3.  8.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3
 16  4  0  8  0  3  1] -> size -> 31 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: buy - action -1.0
Learning step: -8.069092750549316
desired expected reward: 106.69139862060547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[73.919785]
 [70.77902 ]
 [88.13906 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8. 29.  0.  3.] 
cards in discard: [ 0. 15. 16.  6. 16. 10. 10.  3.  0.  0.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 16  3 15  3  8 10  0  6 10  6 16  8 29  6  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 27. 30. 25. 29.  8.  5.  6.  7.  5. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 3.  8.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3
 16  4  0  8  0  3  1] -> size -> 31 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: take_action - action -1.0
Learning step: -6.875256538391113
desired expected reward: 82.3534164428711



buy possibilites: [-1] 
expected returns: [[109.60246]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8. 29.  0.  3.] 
cards in discard: [ 0. 15. 16.  6. 16. 10. 10.  3.  0.  0.  3.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 16  3 15  3  8 10  0  6 10  6 16  8 29  6  0  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 27. 30. 25. 29.  8.  5.  6.  7.  5. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 3.  8.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3
 16  4  0  8  0  3  1] -> size -> 31 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -80.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -115.0 

action type: buy - action 0.0
Learning step: -6.979934215545654
desired expected reward: 66.93984985351562






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [ 3.  8.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3
 16  4  0  8  0  3  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 25. 29.  8.  5.  6.  7.  5. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 8.  6. 15.  8.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 16  3 15  3  8 10  0  6 10  6 16  8 29  6  0  0] -> size -> 19 
adversary victory points: 0
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3
 16  4  0  8  0  3  1  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 24. 29.  8.  5.  6.  7.  5. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 8.  6. 15.  8.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 16  3 15  3  8 10  0  6 10  6 16  8 29  6  0  0] -> size -> 19 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3
 16  4  0  8  0  3  1  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 27. 30. 24. 29.  8.  5.  6.  7.  5. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 8.  6. 15.  8.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 16  3 15  3  8 10  0  6 10  6 16  8 29  6  0  0] -> size -> 19 
adversary victory points: 0
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [3. 8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3
 16  4  0  8  0  3  1  3  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 24. 29.  8.  5.  6.  7.  4. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 8.  6. 15.  8.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 16  3 15  3  8 10  0  6 10  6 16  8 29  6  0  0] -> size -> 19 
adversary victory points: 0
player victory points: 9 





Player: 0 
cards in hand: [ 8.  6. 15.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.  8.] 
expected returns: [[96.46546]
 [89.02152]
 [89.24609]
 [89.02152]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6. 15.  8.  6.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 16  3 15  3  8 10  0  6 10  6 16  8 29  6  0  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 24. 29.  8.  5.  6.  7.  4. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [29.  0. 10. 16.  0.] 
adversary cards in discard: [ 3.  8. 11.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3
 16  4  0  8  0  3  1  3  8] -> size -> 33 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: -8.187858581542969
desired expected reward: 101.41460418701172



action possibilites: [-1] 
expected returns: [[127.124794]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 24. 29.  8.  5.  6.  7.  4. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [29.  0. 10. 16.  0.] 
adversary cards in discard: [ 3.  8. 11.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3
 16  4  0  8  0  3  1  3  8] -> size -> 33 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: trash_cards_n_from_hand - action 3
Learning step: -4.621958255767822
desired expected reward: 81.02336120605469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[110.56899]
 [106.33559]
 [127.97906]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 27. 30. 24. 29.  8.  5.  6.  7.  4. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [29.  0. 10. 16.  0.] 
adversary cards in discard: [ 3.  8. 11.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3
 16  4  0  8  0  3  1  3  8] -> size -> 33 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: take_action - action -1
Learning step: -6.858443737030029
desired expected reward: 120.26634979248047



buy possibilites: [-1] 
expected returns: [[98.85941]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6.] 
cards in discard: [0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 24. 29.  8.  5.  6.  7.  4. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [29.  0. 10. 16.  0.] 
adversary cards in discard: [ 3.  8. 11.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3
 16  4  0  8  0  3  1  3  8] -> size -> 33 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -94 

action type: buy - action 0.0
Learning step: -8.00411319732666
desired expected reward: 102.56488037109375






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [29.  0. 10. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 16.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 10. 16.  0.] 
cards in discard: [ 3.  8. 11.  3.  8.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3
 16  4  0  8  0  3  1  3  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 24. 29.  8.  5.  6.  7.  4. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 0. 29.  3. 10.  3.] 
adversary cards in discard: [0. 8. 8. 6.] 
adversary owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0] -> size -> 18 
adversary victory points: 1
player victory points: 9 


action possibilites: [-1. 10. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 16.  0.  3.] 
cards in discard: [ 3.  8. 11.  3.  8.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3
 16  4  0  8  0  3  1  3  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 27. 30. 24. 29.  8.  5.  6.  7.  4. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 0. 29.  3. 10.  3.] 
adversary cards in discard: [0. 8. 8. 6.] 
adversary owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0] -> size -> 18 
adversary victory points: 1
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.] 
cards in discard: [ 3.  8. 11.  3.  8.  0.  0.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0  3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3 16
  4  0  8  0  3  1  3  8  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 27. 30. 24. 29.  8.  5.  6.  7.  3. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 0. 29.  3. 10.  3.] 
adversary cards in discard: [0. 8. 8. 6.] 
adversary owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0] -> size -> 18 
adversary victory points: 1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.] 
cards in discard: [ 3.  8. 11.  3.  8.  0.  0.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0  3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3 16
  4  0  8  0  3  1  3  8  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 27. 30. 24. 29.  8.  5.  6.  7.  3. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 0. 29.  3. 10.  3.] 
adversary cards in discard: [0. 8. 8. 6.] 
adversary owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0] -> size -> 18 
adversary victory points: 1
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.] 
cards in discard: [ 3.  8. 11.  3.  8.  0.  0.  8.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0  3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3 16
  4  0  8  0  3  1  3  8  8  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 23. 29.  8.  5.  6.  7.  3. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 0. 29.  3. 10.  3.] 
adversary cards in discard: [0. 8. 8. 6.] 
adversary owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0] -> size -> 18 
adversary victory points: 1
player victory points: 10 





Player: 0 
cards in hand: [ 0. 29.  3. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[136.27634]
 [130.35   ]
 [124.54694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3. 10.  3.] 
cards in discard: [0. 8. 8. 6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 23. 29.  8.  5.  6.  7.  3. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [11. 15.  0.  0.  8.] 
adversary cards in discard: [ 3.  8. 11.  3.  8.  0.  0.  8.  3. 29. 16. 10.  0.  3.] 
adversary owned cards: [ 0  3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3 16
  4  0  8  0  3  1  3  8  8  3] -> size -> 34 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -94 

action type: buy - action -1
Learning step: -6.7160539627075195
desired expected reward: 92.14335632324219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[117.074066]
 [113.395676]
 [132.06519 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3. 10.  3.] 
cards in discard: [0. 8. 8. 6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 27. 30. 23. 29.  8.  5.  6.  7.  3. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [11. 15.  0.  0.  8.] 
adversary cards in discard: [ 3.  8. 11.  3.  8.  0.  0.  8.  3. 29. 16. 10.  0.  3.] 
adversary owned cards: [ 0  3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3 16
  4  0  8  0  3  1  3  8  8  3] -> size -> 34 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -94 

action type: take_action - action -1.0
Learning step: -8.563204765319824
desired expected reward: 124.99749755859375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [11. 15.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15.  0.  0.  8.] 
cards in discard: [ 3.  8. 11.  3.  8.  0.  0.  8.  3. 29. 16. 10.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3 16
  4  0  8  0  3  1  3  8  8  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 23. 29.  8.  5.  6.  7.  3. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  0. 16.] 
adversary cards in discard: [ 0.  8.  8.  6.  0. 29.  3. 10.  3.] 
adversary owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0] -> size -> 18 
adversary victory points: 1
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15.  0.] 
cards in discard: [ 3.  8. 11.  3.  8.  0.  0.  8.  3. 29. 16. 10.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3 16  4
  0  8  0  3  1  3  8  8  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 23. 29.  8.  5.  6.  7.  3. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  0. 16.] 
adversary cards in discard: [ 0.  8.  8.  6.  0. 29.  3. 10.  3.] 
adversary owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0] -> size -> 18 
adversary victory points: 1
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 15.  0.] 
cards in discard: [ 3.  8. 11.  3.  8.  0.  0.  8.  3. 29. 16. 10.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3 16  4
  0  8  0  3  1  3  8  8  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 27. 30. 23. 29.  8.  5.  6.  7.  3. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  0. 16.] 
adversary cards in discard: [ 0.  8.  8.  6.  0. 29.  3. 10.  3.] 
adversary owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0] -> size -> 18 
adversary victory points: 1
player victory points: 10 





Player: 0 
cards in hand: [ 0. 10.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
expected returns: [[79.98657 ]
 [73.690605]
 [72.98416 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0. 16.] 
cards in discard: [ 0.  8.  8.  6.  0. 29.  3. 10.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 23. 29.  8.  5.  6.  7.  3. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 0.  1. 10.  4.  8.] 
adversary cards in discard: [ 3.  8. 11.  3.  8.  0.  0.  8.  3. 29. 16. 10.  0.  3.  8. 11. 15.  0.] 
adversary owned cards: [ 3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3 16  4
  0  8  0  3  1  3  8  8  3] -> size -> 33 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -94 

action type: buy - action -1.0
Learning step: -8.93087387084961
desired expected reward: 110.44290161132812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[70.68656 ]
 [73.40271 ]
 [72.99126 ]
 [68.22602 ]
 [76.552124]
 [73.80657 ]
 [73.39436 ]
 [80.72732 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0. 16.] 
cards in discard: [ 0.  8.  8.  6.  0. 29.  3. 10.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 27. 30. 23. 29.  8.  5.  6.  7.  3. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 0.  1. 10.  4.  8.] 
adversary cards in discard: [ 3.  8. 11.  3.  8.  0.  0.  8.  3. 29. 16. 10.  0.  3.  8. 11. 15.  0.] 
adversary owned cards: [ 3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3 16  4
  0  8  0  3  1  3  8  8  3] -> size -> 33 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -94 

action type: take_action - action -1.0
Learning step: -6.980739593505859
desired expected reward: 73.00581359863281



buy possibilites: [-1] 
expected returns: [[71.443886]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0. 16.] 
cards in discard: [ 0.  8.  8.  6.  0. 29.  3. 10.  3.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [18. 27. 30. 23. 29.  8.  4.  6.  7.  3. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 0.  1. 10.  4.  8.] 
adversary cards in discard: [ 3.  8. 11.  3.  8.  0.  0.  8.  3. 29. 16. 10.  0.  3.  8. 11. 15.  0.] 
adversary owned cards: [ 3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3 16  4
  0  8  0  3  1  3  8  8  3] -> size -> 33 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0. -100.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -405.0 

action type: buy - action 6.0
Learning step: -22.053813934326172
desired expected reward: 46.17220687866211






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 0.  1. 10.  4.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 10.  4.  8.] 
cards in discard: [ 3.  8. 11.  3.  8.  0.  0.  8.  3. 29. 16. 10.  0.  3.  8. 11. 15.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3 16  4
  0  8  0  3  1  3  8  8  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 23. 29.  8.  4.  6.  7.  3. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 0.  6.  0. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6] -> size -> 19 
adversary victory points: 0
player victory points: 10 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 4. 8. 3.] 
cards in discard: [ 3.  8. 11.  3.  8.  0.  0.  8.  3. 29. 16. 10.  0.  3.  8. 11. 15.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3 16  4
  0  8  0  3  1  3  8  8  3] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 23. 29.  8.  4.  6.  7.  3. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 0.  6.  0. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6] -> size -> 19 
adversary victory points: 0
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 4. 8. 3.] 
cards in discard: [ 3.  8. 11.  3.  8.  0.  0.  8.  3. 29. 16. 10.  0.  3.  8. 11. 15.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3 16  4
  0  8  0  3  1  3  8  8  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 27. 30. 23. 29.  8.  4.  6.  7.  3. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 0.  6.  0. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6] -> size -> 19 
adversary victory points: 0
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 4. 8. 3.] 
cards in discard: [ 3.  8. 11.  3.  8.  0.  0.  8.  3. 29. 16. 10.  0.  3.  8. 11. 15.  0.
  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3 16  4
  0  8  0  3  1  3  8  8  3  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 23. 29.  8.  4.  6.  7.  3. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 0.  6.  0. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6] -> size -> 19 
adversary victory points: 0
player victory points: 10 





Player: 0 
cards in hand: [ 0.  6.  0. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[100.81548 ]
 [ 89.591835]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 16.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 23. 29.  8.  4.  6.  7.  3. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 3.  0.  3. 23. 14.] 
adversary cards in discard: [ 3.  8. 11.  3.  8.  0.  0.  8.  3. 29. 16. 10.  0.  3.  8. 11. 15.  0.
  1. 10.  0.  1.  4.  8.  3.] 
adversary owned cards: [ 3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3 16  4
  0  8  0  3  1  3  8  8  3  1] -> size -> 34 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: buy - action -1
Learning step: -6.641286373138428
desired expected reward: 64.80259704589844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 86.36402]
 [ 90.32525]
 [ 81.75358]
 [ 91.77245]
 [100.95212]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 16.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 26. 30. 23. 29.  8.  4.  6.  7.  3. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 3.  0.  3. 23. 14.] 
adversary cards in discard: [ 3.  8. 11.  3.  8.  0.  0.  8.  3. 29. 16. 10.  0.  3.  8. 11. 15.  0.
  1. 10.  0.  1.  4.  8.  3.] 
adversary owned cards: [ 3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3 16  4
  0  8  0  3  1  3  8  8  3  1] -> size -> 34 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1.0
Learning step: -8.148768424987793
desired expected reward: 92.26236724853516



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  3. 23. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 14.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 23. 14.] 
cards in discard: [ 3.  8. 11.  3.  8.  0.  0.  8.  3. 29. 16. 10.  0.  3.  8. 11. 15.  0.
  1. 10.  0.  1.  4.  8.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3 16  4
  0  8  0  3  1  3  8  8  3  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 23. 29.  8.  4.  6.  7.  3. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 8. 10.  8.  0.  3.] 
adversary cards in discard: [ 0.  6.  0. 16.  3.] 
adversary owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6] -> size -> 19 
adversary victory points: 0
player victory points: 10 


action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 14.  0.] 
cards in discard: [ 3.  8. 11.  3.  8.  0.  0.  8.  3. 29. 16. 10.  0.  3.  8. 11. 15.  0.
  1. 10.  0.  1.  4.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3 16  4
  0  8  0  3  1  3  8  8  3  1] -> size -> 34 
action values: 1 
buys: 1 
player value: 1 
card supply: [18. 26. 30. 23. 29.  8.  4.  6.  7.  3. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [ 8. 10.  8.  0.  3.] 
adversary cards in discard: [ 0.  6.  0. 16.  3.] 
adversary owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6] -> size -> 19 
adversary victory points: 0
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [ 3.  8. 11.  3.  8.  0.  0.  8.  3. 29. 16. 10.  0.  3.  8. 11. 15.  0.
  1. 10.  0.  1.  4.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [23. 14.] 
owned cards: [ 3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3 16  4
  0  8  0  3  1  3  8  8  3  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 26. 30. 23. 29.  8.  4.  6.  7.  3. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [8. 0. 3.] 
adversary cards in discard: [ 0.  6.  0. 16.  3. 10.  8.] 
adversary owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6] -> size -> 19 
adversary victory points: 0
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [ 3.  8. 11.  3.  8.  0.  0.  8.  3. 29. 16. 10.  0.  3.  8. 11. 15.  0.
  1. 10.  0.  1.  4.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [23. 14.] 
owned cards: [ 3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3 16  4
  0  8  0  3  1  3  8  8  3  1] -> size -> 34 
action values: 0 
buys: 2 
player value: 5 
card supply: [18. 26. 30. 23. 29.  8.  4.  6.  7.  3. 10.  7.  8.  9.  6. 10.  8.] 
adversary cards in hand: [8. 0. 3.] 
adversary cards in discard: [ 0.  6.  0. 16.  3. 10.  8.] 
adversary owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6] -> size -> 19 
adversary victory points: 0
player victory points: 10 


buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [ 3.  8. 11.  3.  8.  0.  0.  8.  3. 29. 16. 10.  0.  3.  8. 11. 15.  0.
  1. 10.  0.  1.  4.  8.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [23. 14.] 
owned cards: [ 3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3 16  4
  0  8  0  3  1  3  8  8  3  1 10] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 26. 30. 23. 29.  8.  4.  6.  7.  3. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [8. 0. 3.] 
adversary cards in discard: [ 0.  6.  0. 16.  3. 10.  8.] 
adversary owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6] -> size -> 19 
adversary victory points: 0
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [ 3.  8. 11.  3.  8.  0.  0.  8.  3. 29. 16. 10.  0.  3.  8. 11. 15.  0.
  1. 10.  0.  1.  4.  8.  3. 10.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [23. 14.] 
owned cards: [ 3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3 16  4
  0  8  0  3  1  3  8  8  3  1 10  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 22. 29.  8.  4.  6.  7.  3. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [8. 0. 3.] 
adversary cards in discard: [ 0.  6.  0. 16.  3. 10.  8.] 
adversary owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6] -> size -> 19 
adversary victory points: 0
player victory points: 11 





Player: 0 
cards in hand: [8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[82.136116]
 [76.730644]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3.] 
cards in discard: [ 0.  6.  0. 16.  3. 10.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 22. 29.  8.  4.  6.  7.  3. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [ 3. 15.  1.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3 16  4
  0  8  0  3  1  3  8  8  3  1 10  3] -> size -> 36 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: discard_down_to_3_cards - action 1
Learning step: -5.9474287033081055
desired expected reward: 34.2077751159668





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[74.59028]
 [72.2745 ]
 [82.91047]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3.] 
cards in discard: [ 0.  6.  0. 16.  3. 10.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 26. 30. 22. 29.  8.  4.  6.  7.  3. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [ 3. 15.  1.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3 16  4
  0  8  0  3  1  3  8  8  3  1 10  3] -> size -> 36 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: take_action - action -1.0
Learning step: -8.0795316696167
desired expected reward: 74.05659484863281



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [ 3. 15.  1.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  1.  0. 29.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3 16  4
  0  8  0  3  1  3  8  8  3  1 10  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 22. 29.  8.  4.  6.  7.  3. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [ 6.  0. 10.  3. 29.] 
adversary cards in discard: [ 0.  6.  0. 16.  3. 10.  8.  8.  0.  3.] 
adversary owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6] -> size -> 19 
adversary victory points: 0
player victory points: 11 


action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  1.  0.  3.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3 16  4
  0  8  0  3  1  3  8  8  3  1 10  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 26. 30. 22. 29.  8.  4.  6.  7.  3. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [ 6.  0. 10.  3. 29.] 
adversary cards in discard: [ 0.  6.  0. 16.  3. 10.  8.  8.  0.  3.] 
adversary owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6] -> size -> 19 
adversary victory points: 0
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  1.  0.  3.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3 16  4
  0  8  0  3  1  3  8  8  3  1 10  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 26. 30. 22. 29.  8.  4.  6.  7.  3. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [ 6.  0. 10.  3. 29.] 
adversary cards in discard: [ 0.  6.  0. 16.  3. 10.  8.  8.  0.  3.] 
adversary owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6] -> size -> 19 
adversary victory points: 0
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  1.  0.  3.] 
cards in discard: [11.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3 16  4
  0  8  0  3  1  3  8  8  3  1 10  3 11] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 26. 30. 22. 29.  8.  4.  6.  6.  3. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [ 6.  0. 10.  3. 29.] 
adversary cards in discard: [ 0.  6.  0. 16.  3. 10.  8.  8.  0.  3.] 
adversary owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6] -> size -> 19 
adversary victory points: 0
player victory points: 11 





Player: 0 
cards in hand: [ 6.  0. 10.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[115.7579 ]
 [110.35486]
 [113.51871]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10.  3. 29.] 
cards in discard: [ 0.  6.  0. 16.  3. 10.  8.  8.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 22. 29.  8.  4.  6.  6.  3. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [ 3. 23. 11.  8.  0.] 
adversary cards in discard: [11. 29.  3. 15.  1.  0.  3.] 
adversary owned cards: [ 3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3 16  4
  0  8  0  3  1  3  8  8  3  1 10  3 11] -> size -> 37 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: buy - action -1.0
Learning step: -7.326534271240234
desired expected reward: 75.58395385742188



action possibilites: [-1. 10.] 
expected returns: [[98.85973]
 [90.13958]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10.  3.  6.] 
cards in discard: [ 0.  6.  0. 16.  3. 10.  8.  8.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 26. 30. 22. 29.  8.  4.  6.  6.  3. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [ 3. 23. 11.  8.  0.] 
adversary cards in discard: [11. 29.  3. 15.  1.  0.  3.] 
adversary owned cards: [ 3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3 16  4
  0  8  0  3  1  3  8  8  3  1 10  3 11] -> size -> 37 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -95 

action type: take_action - action 29.0
Learning step: -8.262460708618164
desired expected reward: 105.25627136230469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[85.33753]
 [88.56467]
 [81.70355]
 [89.6506 ]
 [97.68814]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 10.  3.  6.] 
cards in discard: [ 0.  6.  0. 16.  3. 10.  8.  8.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 26. 30. 22. 29.  8.  4.  6.  6.  3. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [ 3. 23. 11.  8.  0.] 
adversary cards in discard: [11. 29.  3. 15.  1.  0.  3.] 
adversary owned cards: [ 3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3 16  4
  0  8  0  3  1  3  8  8  3  1 10  3 11] -> size -> 37 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: -7.622030735015869
desired expected reward: 91.2376937866211






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 3. 23. 11.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 23. 11.  8.  0.] 
cards in discard: [11. 29.  3. 15.  1.  0.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  3 11 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3 16  4
  0  8  0  3  1  3  8  8  3  1 10  3 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 22. 29.  8.  4.  6.  6.  3. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [ 3.  0.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6] -> size -> 19 
adversary victory points: 0
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 23.  0.] 
cards in discard: [11. 29.  3. 15.  1.  0.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 29  3 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3 16  4  0
  8  0  3  1  3  8  8  3  1 10  3 11] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 22. 29.  8.  4.  6.  6.  3. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [ 3.  0.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6] -> size -> 19 
adversary victory points: 0
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 23.  0.] 
cards in discard: [11. 29.  3. 15.  1.  0.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 29  3 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3 16  4  0
  8  0  3  1  3  8  8  3  1 10  3 11] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 26. 30. 22. 29.  8.  4.  6.  6.  3. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [ 3.  0.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6] -> size -> 19 
adversary victory points: 0
player victory points: 11 





Player: 0 
cards in hand: [ 3.  0.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[66.715614]
 [58.999554]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 16.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 22. 29.  8.  4.  6.  6.  3. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [ 0.  0. 14.  3. 11.] 
adversary cards in discard: [11. 29.  3. 15.  1.  0.  3.  8.  3. 23.  0.] 
adversary owned cards: [ 3  3 29  3 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3 16  4  0
  8  0  3  1  3  8  8  3  1 10  3 11] -> size -> 36 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: buy - action -1.0
Learning step: -9.205428123474121
desired expected reward: 88.48271942138672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[56.510426]
 [59.681465]
 [59.236057]
 [53.538025]
 [63.08665 ]
 [60.133984]
 [59.68766 ]
 [66.49642 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 16.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 26. 30. 22. 29.  8.  4.  6.  6.  3. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [ 0.  0. 14.  3. 11.] 
adversary cards in discard: [11. 29.  3. 15.  1.  0.  3.  8.  3. 23.  0.] 
adversary owned cards: [ 3  3 29  3 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3 16  4  0
  8  0  3  1  3  8  8  3  1 10  3 11] -> size -> 36 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: take_action - action -1.0
Learning step: -7.6425628662109375
desired expected reward: 58.261375427246094



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 14.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  3. 11.] 
cards in discard: [11. 29.  3. 15.  1.  0.  3.  8.  3. 23.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  3 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3 16  4  0
  8  0  3  1  3  8  8  3  1 10  3 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 22. 29.  8.  4.  6.  6.  3. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [ 0.  8. 10.  0.  6.] 
adversary cards in discard: [ 3.  0.  0.  0. 16.] 
adversary owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6] -> size -> 19 
adversary victory points: 0
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  3. 11.] 
cards in discard: [11. 29.  3. 15.  1.  0.  3.  8.  3. 23.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  3 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3 16  4  0
  8  0  3  1  3  8  8  3  1 10  3 11] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 26. 30. 22. 29.  8.  4.  6.  6.  3. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [ 0.  8. 10.  0.  6.] 
adversary cards in discard: [ 3.  0.  0.  0. 16.] 
adversary owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6] -> size -> 19 
adversary victory points: 0
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  3. 11.] 
cards in discard: [11. 29.  3. 15.  1.  0.  3.  8.  3. 23.  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  3 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3 16  4  0
  8  0  3  1  3  8  8  3  1 10  3 11  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 21. 29.  8.  4.  6.  6.  3. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [ 0.  8. 10.  0.  6.] 
adversary cards in discard: [ 3.  0.  0.  0. 16.] 
adversary owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6] -> size -> 19 
adversary victory points: 0
player victory points: 12 





Player: 0 
cards in hand: [ 0.  8. 10.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[48.81503]
 [41.12395]
 [40.7434 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.  0.  6.] 
cards in discard: [ 3.  0.  0.  0. 16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 21. 29.  8.  4.  6.  6.  3. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [16.  8.  3.  1.  0.] 
adversary cards in discard: [11. 29.  3. 15.  1.  0.  3.  8.  3. 23.  0.  3.  0.  0. 14.  3. 11.] 
adversary owned cards: [ 3  3 29  3 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3 16  4  0
  8  0  3  1  3  8  8  3  1 10  3 11  3] -> size -> 37 
adversary victory points: 12
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: -8.549834251403809
desired expected reward: 57.94659423828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[39.10861 ]
 [42.12095 ]
 [35.93272 ]
 [42.921215]
 [50.38031 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10.  0.  6.] 
cards in discard: [ 3.  0.  0.  0. 16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 26. 30. 21. 29.  8.  4.  6.  6.  3. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [16.  8.  3.  1.  0.] 
adversary cards in discard: [11. 29.  3. 15.  1.  0.  3.  8.  3. 23.  0.  3.  0.  0. 14.  3. 11.] 
adversary owned cards: [ 3  3 29  3 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3 16  4  0
  8  0  3  1  3  8  8  3  1 10  3 11  3] -> size -> 37 
adversary victory points: 12
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: take_action - action -1.0
Learning step: -7.672890663146973
desired expected reward: 41.14213180541992



buy possibilites: [-1] 
expected returns: [[73.20345]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10.  0.  6.] 
cards in discard: [ 3.  0.  0.  0. 16.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 21. 29.  8.  4.  6.  6.  2. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [16.  8.  3.  1.  0.] 
adversary cards in discard: [11. 29.  3. 15.  1.  0.  3.  8.  3. 23.  0.  3.  0.  0. 14.  3. 11.] 
adversary owned cards: [ 3  3 29  3 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3 16  4  0
  8  0  3  1  3  8  8  3  1 10  3 11  3] -> size -> 37 
adversary victory points: 12
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    8    0] 
sum of rewards: -117 

action type: buy - action 8.0
Learning step: -6.1357855796813965
desired expected reward: 36.78542709350586






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [16.  8.  3.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8.  3.  1.  0.] 
cards in discard: [11. 29.  3. 15.  1.  0.  3.  8.  3. 23.  0.  3.  0.  0. 14.  3. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 29  3 11  0  0  0  0 15  1 23  8 29  8  0 10  0 10 14  3 16  4  0
  8  0  3  1  3  8  8  3  1 10  3 11  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 21. 29.  8.  4.  6.  6.  2. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [ 3. 16.  3.  6.  8.] 
adversary cards in discard: [ 3.  0.  0.  0. 16.  8.  0.  8. 10.  0.  6.] 
adversary owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6  8] -> size -> 20 
adversary victory points: 0
player victory points: 12 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.] 
cards in discard: [11. 29.  3. 15.  1.  0.  3.  8.  3. 23.  0.  3.  0.  0. 14.  3. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 29  3 11  0  0  0 15 23  8 29  8  0 10  0 10 14  3 16  4  0  8  0  3
  1  3  8  8  3  1 10  3 11  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 21. 29.  8.  4.  6.  6.  2. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [ 3. 16.  3.  6.  8.] 
adversary cards in discard: [ 3.  0.  0.  0. 16.  8.  0.  8. 10.  0.  6.] 
adversary owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6  8] -> size -> 20 
adversary victory points: 0
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.] 
cards in discard: [11. 29.  3. 15.  1.  0.  3.  8.  3. 23.  0.  3.  0.  0. 14.  3. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 29  3 11  0  0  0 15 23  8 29  8  0 10  0 10 14  3 16  4  0  8  0  3
  1  3  8  8  3  1 10  3 11  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 26. 30. 21. 29.  8.  4.  6.  6.  2. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [ 3. 16.  3.  6.  8.] 
adversary cards in discard: [ 3.  0.  0.  0. 16.  8.  0.  8. 10.  0.  6.] 
adversary owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6  8] -> size -> 20 
adversary victory points: 0
player victory points: 11 





Player: 0 
cards in hand: [ 3. 16.  3.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
expected returns: [[86.300606]
 [79.742325]
 [80.9366  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  3.  6.  8.] 
cards in discard: [ 3.  0.  0.  0. 16.  8.  0.  8. 10.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 21. 29.  8.  4.  6.  6.  2. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [ 3. 10.  8.  8.  8.] 
adversary cards in discard: [11. 29.  3. 15.  1.  0.  3.  8.  3. 23.  0.  3.  0.  0. 14.  3. 11.  8.
 16.] 
adversary owned cards: [ 3 29  3 11  0  0  0 15 23  8 29  8  0 10  0 10 14  3 16  4  0  8  0  3
  1  3  8  8  3  1 10  3 11  3] -> size -> 34 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: buy - action -1
Learning step: -7.52388858795166
desired expected reward: 65.6795654296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[78.05565 ]
 [75.51902 ]
 [86.580864]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  3.  6.  8.] 
cards in discard: [ 3.  0.  0.  0. 16.  8.  0.  8. 10.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6  8] -> size -> 20 
action values: 1 
buys: 1 
player value: 0 
card supply: [18. 26. 30. 21. 29.  8.  4.  6.  6.  2. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [ 3. 10.  8.  8.  8.] 
adversary cards in discard: [11. 29.  3. 15.  1.  0.  3.  8.  3. 23.  0.  3.  0.  0. 14.  3. 11.  8.
 16.] 
adversary owned cards: [ 3 29  3 11  0  0  0 15 23  8 29  8  0 10  0 10 14  3 16  4  0  8  0  3
  1  3  8  8  3  1 10  3 11  3] -> size -> 34 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: take_action - action -1.0
Learning step: -8.208108901977539
desired expected reward: 78.09251403808594



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [ 3. 10.  8.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  8.  8.  8.] 
cards in discard: [11. 29.  3. 15.  1.  0.  3.  8.  3. 23.  0.  3.  0.  0. 14.  3. 11.  8.
 16.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  3 11  0  0  0 15 23  8 29  8  0 10  0 10 14  3 16  4  0  8  0  3
  1  3  8  8  3  1 10  3 11  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 21. 29.  8.  4.  6.  6.  2. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [ 8.  6.  0. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6  8] -> size -> 20 
adversary victory points: 0
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.] 
cards in discard: [11. 29.  3. 15.  1.  0.  3.  8.  3. 23.  0.  3.  0.  0. 14.  3. 11.  8.
 16.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 21. 29.  8.  4.  6.  6.  2. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [ 8.  6.  0. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6  8] -> size -> 20 
adversary victory points: 0
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.] 
cards in discard: [11. 29.  3. 15.  1.  0.  3.  8.  3. 23.  0.  3.  0.  0. 14.  3. 11.  8.
 16.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 26. 30. 21. 29.  8.  4.  6.  6.  2. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [ 8.  6.  0. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6  8] -> size -> 20 
adversary victory points: 0
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.] 
cards in discard: [11. 29.  3. 15.  1.  0.  3.  8.  3. 23.  0.  3.  0.  0. 14.  3. 11.  8.
 16.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 21. 29.  8.  4.  6.  6.  2. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [ 8.  6.  0. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6  8] -> size -> 20 
adversary victory points: 0
player victory points: 11 





Player: 0 
cards in hand: [ 8.  6.  0. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 10.] 
expected returns: [[54.52326 ]
 [48.151386]
 [51.21462 ]
 [47.762035]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6.  0. 29. 10.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 21. 29.  8.  4.  6.  6.  2. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [ 0.  1.  3.  3. 10.] 
adversary cards in discard: [11. 29.  3. 15.  1.  0.  3.  8.  3. 23.  0.  3.  0.  0. 14.  3. 11.  8.
 16.  0.  8.  3. 10.] 
adversary owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0] -> size -> 33 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: buy - action -1.0
Learning step: -8.915412902832031
desired expected reward: 77.66545867919922



action possibilites: [-1.  8. 10.] 
expected returns: [[101.29057]
 [ 95.21002]
 [ 94.71948]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 26. 30. 21. 29.  8.  4.  6.  6.  2. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [ 0.  1.  3.  3. 10.] 
adversary cards in discard: [11. 29.  3. 15.  1.  0.  3.  8.  3. 23.  0.  3.  0.  0. 14.  3. 11.  8.
 16.  0.  8.  3. 10.] 
adversary owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0] -> size -> 33 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -110    0    0   20    0    0    0    0    0    0    0
    0    1] 
sum of rewards: -94 

action type: take_action - action 29.0
Learning step: -5.030519962310791
desired expected reward: 45.98316955566406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[88.53423 ]
 [91.72257 ]
 [91.14764 ]
 [85.39519 ]
 [94.99376 ]
 [92.19887 ]
 [91.621254]
 [98.19236 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 26. 30. 21. 29.  8.  4.  6.  6.  2. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [ 0.  1.  3.  3. 10.] 
adversary cards in discard: [11. 29.  3. 15.  1.  0.  3.  8.  3. 23.  0.  3.  0.  0. 14.  3. 11.  8.
 16.  0.  8.  3. 10.] 
adversary owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0] -> size -> 33 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: -7.695476531982422
desired expected reward: 93.59510803222656






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [ 0.  1.  3.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3.  3. 10.] 
cards in discard: [11. 29.  3. 15.  1.  0.  3.  8.  3. 23.  0.  3.  0.  0. 14.  3. 11.  8.
 16.  0.  8.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 21. 29.  8.  4.  6.  6.  2. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [3. 6. 0. 8. 0.] 
adversary cards in discard: [29.  8.  6.  0. 10.  0.] 
adversary owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6  8] -> size -> 20 
adversary victory points: 0
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3.  3. 10.] 
cards in discard: [11. 29.  3. 15.  1.  0.  3.  8.  3. 23.  0.  3.  0.  0. 14.  3. 11.  8.
 16.  0.  8.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 26. 30. 21. 29.  8.  4.  6.  6.  2. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [3. 6. 0. 8. 0.] 
adversary cards in discard: [29.  8.  6.  0. 10.  0.] 
adversary owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6  8] -> size -> 20 
adversary victory points: 0
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3.  3. 10.] 
cards in discard: [11. 29.  3. 15.  1.  0.  3.  8.  3. 23.  0.  3.  0.  0. 14.  3. 11.  8.
 16.  0.  8.  3. 10. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 21. 29.  8.  4.  6.  5.  2. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [3. 6. 0. 8. 0.] 
adversary cards in discard: [29.  8.  6.  0. 10.  0.] 
adversary owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6  8] -> size -> 20 
adversary victory points: 0
player victory points: 11 





Player: 0 
cards in hand: [3. 6. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[104.83598]
 [ 98.4064 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 8. 0.] 
cards in discard: [29.  8.  6.  0. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 21. 29.  8.  4.  6.  5.  2. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [ 4. 10.  0.  0. 29.] 
adversary cards in discard: [11. 29.  3. 15.  1.  0.  3.  8.  3. 23.  0.  3.  0.  0. 14.  3. 11.  8.
 16.  0.  8.  3. 10. 11.  0.  1.  3.  3. 10.] 
adversary owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11] -> size -> 34 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: buy - action -1.0
Learning step: -8.345686912536621
desired expected reward: 89.84666442871094



action possibilites: [-1] 
expected returns: [[49.383938]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0.] 
cards in discard: [29.  8.  6.  0. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 21. 29.  8.  4.  6.  5.  2. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [ 4. 10.  0.  0. 29.] 
adversary cards in discard: [11. 29.  3. 15.  1.  0.  3.  8.  3. 23.  0.  3.  0.  0. 14.  3. 11.  8.
 16.  0.  8.  3. 10. 11.  0.  1.  3.  3. 10.] 
adversary owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11] -> size -> 34 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -95 

action type: trash_cards_n_from_hand - action 1
Learning step: -8.648699760437012
desired expected reward: 91.54808044433594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[40.758747]
 [38.1409  ]
 [50.201244]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0.] 
cards in discard: [29.  8.  6.  0. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 26. 30. 21. 29.  8.  4.  6.  5.  2. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [ 4. 10.  0.  0. 29.] 
adversary cards in discard: [11. 29.  3. 15.  1.  0.  3.  8.  3. 23.  0.  3.  0.  0. 14.  3. 11.  8.
 16.  0.  8.  3. 10. 11.  0.  1.  3.  3. 10.] 
adversary owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11] -> size -> 34 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -95 

action type: take_action - action -1
Learning step: -6.189731121063232
desired expected reward: 43.19420623779297



buy possibilites: [-1] 
expected returns: [[57.36942]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0.] 
cards in discard: [29.  8.  6.  0. 10.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6  8  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 26. 30. 21. 29.  8.  3.  6.  5.  2. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [ 4. 10.  0.  0. 29.] 
adversary cards in discard: [11. 29.  3. 15.  1.  0.  3.  8.  3. 23.  0.  3.  0.  0. 14.  3. 11.  8.
 16.  0.  8.  3. 10. 11.  0.  1.  3.  3. 10.] 
adversary owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11] -> size -> 34 
adversary victory points: 11
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1. -120.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -406.0 

action type: buy - action 6.0
Learning step: -20.91623306274414
desired expected reward: 17.22466278076172






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [ 4. 10.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4. 10.  0.  0. 29.] 
cards in discard: [11. 29.  3. 15.  1.  0.  3.  8.  3. 23.  0.  3.  0.  0. 14.  3. 11.  8.
 16.  0.  8.  3. 10. 11.  0.  1.  3.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 21. 29.  8.  3.  6.  5.  2. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [ 8.  3. 10.  3.  6.] 
adversary cards in discard: [29.  8.  6.  0. 10.  0.  6.  8.  3.  6.  0.] 
adversary owned cards: [ 0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6  8  6] -> size -> 20 
adversary victory points: -1
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4. 10.  0.  0. 29.] 
cards in discard: [11. 29.  3. 15.  1.  0.  3.  8.  3. 23.  0.  3.  0.  0. 14.  3. 11.  8.
 16.  0.  8.  3. 10. 11.  0.  1.  3.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 26. 30. 21. 29.  8.  3.  6.  5.  2. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [ 8.  3. 10.  3.  6.] 
adversary cards in discard: [29.  8.  6.  0. 10.  0.  6.  8.  3.  6.  0.] 
adversary owned cards: [ 0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6  8  6] -> size -> 20 
adversary victory points: -1
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4. 10.  0.  0. 29.] 
cards in discard: [11. 29.  3. 15.  1.  0.  3.  8.  3. 23.  0.  3.  0.  0. 14.  3. 11.  8.
 16.  0.  8.  3. 10. 11.  0.  1.  3.  3. 10.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 20. 29.  8.  3.  6.  5.  2. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [ 8.  3. 10.  3.  6.] 
adversary cards in discard: [29.  8.  6.  0. 10.  0.  6.  8.  3.  6.  0.] 
adversary owned cards: [ 0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6  8  6] -> size -> 20 
adversary victory points: -1
player victory points: 12 





Player: 0 
cards in hand: [ 8.  3. 10.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[31.110586]
 [26.000204]
 [25.737417]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 10.  3.  6.] 
cards in discard: [29.  8.  6.  0. 10.  0.  6.  8.  3.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 16  3  3  8 10  0 10  6 16  8 29  6  0  0  0  6  8  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 20. 29.  8.  3.  6.  5.  2. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [ 1.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11  3] -> size -> 35 
adversary victory points: 12
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -136 

action type: buy - action -1
Learning step: -9.017267227172852
desired expected reward: 48.352149963378906



action possibilites: [-1] 
expected returns: [[30.289488]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.] 
cards in discard: [29.  8.  6.  0. 10.  0.  6.  8.  3.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 16  3  8 10  0 10  6 16  8 29  6  0  0  0  6  8  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 20. 29.  8.  3.  6.  5.  2. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [ 1.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11  3] -> size -> 35 
adversary victory points: 12
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -138 

action type: trash_cards_n_from_hand - action 4
Learning step: -7.344137668609619
desired expected reward: 15.16887092590332





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[25.752697]
 [24.604269]
 [30.064812]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.] 
cards in discard: [29.  8.  6.  0. 10.  0.  6.  8.  3.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 16  3  8 10  0 10  6 16  8 29  6  0  0  0  6  8  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 26. 30. 20. 29.  8.  3.  6.  5.  2. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [ 1.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11  3] -> size -> 35 
adversary victory points: 12
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -138 

action type: take_action - action -1
Learning step: -7.783492565155029
desired expected reward: 22.50599479675293



buy possibilites: [-1] 
expected returns: [[65.971985]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.] 
cards in discard: [29.  8.  6.  0. 10.  0.  6.  8.  3.  6.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 16  3  8 10  0 10  6 16  8 29  6  0  0  0  6  8  6  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 20. 29.  8.  2.  6.  5.  2. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [ 1.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11  3] -> size -> 35 
adversary victory points: 12
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -160    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -449 

action type: buy - action 6.0
Learning step: -22.195844650268555
desired expected reward: 2.408428192138672






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [ 1.  3. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 20. 29.  8.  2.  6.  5.  2. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 16. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16  3  8 10  0 10  6 16  8 29  6  0  0  0  6  8  6  6] -> size -> 19 
adversary victory points: -4
player victory points: 12 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 26. 30. 20. 29.  8.  2.  6.  5.  2. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 16. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16  3  8 10  0 10  6 16  8 29  6  0  0  0  6  8  6  6] -> size -> 19 
adversary victory points: -4
player victory points: 12 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 29.  0.  0.] 
cards in discard: [8.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11  3  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 26. 30. 20. 29.  8.  2.  6.  5.  1. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 16. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16  3  8 10  0 10  6 16  8 29  6  0  0  0  6  8  6  6] -> size -> 19 
adversary victory points: -4
player victory points: 12 





Player: 0 
cards in hand: [ 0.  0.  0. 16. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.] 
expected returns: [[77.09709]
 [70.55812]
 [70.55812]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 16. 16.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  3  8 10  0 10  6 16  8 29  6  0  0  0  6  8  6  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 20. 29.  8.  2.  6.  5.  1. 10.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [10.  3. 10.  1.  0.] 
adversary cards in discard: [ 8.  1.  3. 29.  0.  0.] 
adversary owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11  3  8] -> size -> 36 
adversary victory points: 12
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -160    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -169 

action type: buy - action -1
Learning step: -10.085158348083496
desired expected reward: 55.88682556152344



action possibilites: [-1] 
expected returns: [[89.6998]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  8 10  0 10  6 16  8 29  6  0  0  0  6  8  6  6 25] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 20. 29.  8.  2.  6.  5.  1.  9.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [10.  3. 10.  1.  0.] 
adversary cards in discard: [ 8.  1.  3. 29.  0.  0.] 
adversary owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11  3  8] -> size -> 36 
adversary victory points: 12
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -160    0    0   20    0    0    0    0    0    0    0
   25    0] 
sum of rewards: -124 

action type: gain_card_n - action 9
Learning step: -7.124915599822998
desired expected reward: 51.73830032348633





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[72.610794]
 [75.67779 ]
 [75.301476]
 [69.839264]
 [79.1144  ]
 [76.11728 ]
 [75.733765]
 [82.67899 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  8 10  0 10  6 16  8 29  6  0  0  0  6  8  6  6 25] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 26. 30. 20. 29.  8.  2.  6.  5.  1.  9.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [10.  3. 10.  1.  0.] 
adversary cards in discard: [ 8.  1.  3. 29.  0.  0.] 
adversary owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11  3  8] -> size -> 36 
adversary victory points: 12
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -160    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -149 

action type: take_action - action -1
Learning step: -10.169569969177246
desired expected reward: 79.53022766113281



buy possibilites: [-1] 
expected returns: [[51.64652]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [25. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  8 10  0 10  6 16  8 29  6  0  0  0  6  8  6  6 25 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 20. 29.  8.  2.  6.  4.  1.  9.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [10.  3. 10.  1.  0.] 
adversary cards in discard: [ 8.  1.  3. 29.  0.  0.] 
adversary owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11  3  8] -> size -> 36 
adversary victory points: 12
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -160    0    0   20    0    0    0    0    0    0    0
   18    0] 
sum of rewards: -131 

action type: buy - action 11.0
Learning step: -9.343673706054688
desired expected reward: 69.77074432373047






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [10.  3. 10.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10.  1.  0.] 
cards in discard: [ 8.  1.  3. 29.  0.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11  3  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 20. 29.  8.  2.  6.  4.  1.  9.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [ 6.  0.  6. 10.  6.] 
adversary cards in discard: [25. 11. 16.  0.  0.  0.] 
adversary owned cards: [ 0  3  8 10  0 10  6 16  8 29  6  0  0  0  6  8  6  6 25 11] -> size -> 20 
adversary victory points: -4
player victory points: 12 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  1.  0.  0.] 
cards in discard: [ 8.  1.  3. 29.  0.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11  3  8] -> size -> 36 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 20. 29.  8.  2.  6.  4.  1.  9.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [ 6.  0.  6. 10.  6.] 
adversary cards in discard: [25. 11. 16.  0.  0.  0.] 
adversary owned cards: [ 0  3  8 10  0 10  6 16  8 29  6  0  0  0  6  8  6  6 25 11] -> size -> 20 
adversary victory points: -4
player victory points: 12 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  1.  0.  0.] 
cards in discard: [ 8.  1.  3. 29.  0.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11  3  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 26. 30. 20. 29.  8.  2.  6.  4.  1.  9.  7.  8.  9.  5. 10.  8.] 
adversary cards in hand: [ 6.  0.  6. 10.  6.] 
adversary cards in discard: [25. 11. 16.  0.  0.  0.] 
adversary owned cards: [ 0  3  8 10  0 10  6 16  8 29  6  0  0  0  6  8  6  6 25 11] -> size -> 20 
adversary victory points: -4
player victory points: 12 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  1.  0.  0.] 
cards in discard: [ 8.  1.  3. 29.  0.  0. 14.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11  3  8 14] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 20. 29.  8.  2.  6.  4.  1.  9.  7.  7.  9.  5. 10.  8.] 
adversary cards in hand: [ 6.  0.  6. 10.  6.] 
adversary cards in discard: [25. 11. 16.  0.  0.  0.] 
adversary owned cards: [ 0  3  8 10  0 10  6 16  8 29  6  0  0  0  6  8  6  6 25 11] -> size -> 20 
adversary victory points: -4
player victory points: 12 





Player: 0 
cards in hand: [ 6.  0.  6. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[55.574463]
 [51.738712]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  6. 10.  6.] 
cards in discard: [25. 11. 16.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8 10  0 10  6 16  8 29  6  0  0  0  6  8  6  6 25 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 20. 29.  8.  2.  6.  4.  1.  9.  7.  7.  9.  5. 10.  8.] 
adversary cards in hand: [15.  3.  3.  0. 11.] 
adversary cards in discard: [ 8.  1.  3. 29.  0.  0. 14. 10.  3. 10.  1.  0.  0.] 
adversary owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11  3  8 14] -> size -> 37 
adversary victory points: 12
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -160    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -169 

action type: buy - action -1
Learning step: -9.808674812316895
desired expected reward: 41.83784484863281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[49.958176]
 [48.54812 ]
 [55.68342 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  6. 10.  6.] 
cards in discard: [25. 11. 16.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8 10  0 10  6 16  8 29  6  0  0  0  6  8  6  6 25 11] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 26. 30. 20. 29.  8.  2.  6.  4.  1.  9.  7.  7.  9.  5. 10.  8.] 
adversary cards in hand: [15.  3.  3.  0. 11.] 
adversary cards in discard: [ 8.  1.  3. 29.  0.  0. 14. 10.  3. 10.  1.  0.  0.] 
adversary owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11  3  8 14] -> size -> 37 
adversary victory points: 12
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -160    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -169 

action type: take_action - action -1.0
Learning step: -10.03569221496582
desired expected reward: 45.53877258300781



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [15.  3.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  3.  0. 11.] 
cards in discard: [ 8.  1.  3. 29.  0.  0. 14. 10.  3. 10.  1.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11  3  8 14] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 20. 29.  8.  2.  6.  4.  1.  9.  7.  7.  9.  5. 10.  8.] 
adversary cards in hand: [10.  8. 29.  3.  0.] 
adversary cards in discard: [25. 11. 16.  0.  0.  0.  6.  0.  6. 10.  6.] 
adversary owned cards: [ 0  3  8 10  0 10  6 16  8 29  6  0  0  0  6  8  6  6 25 11] -> size -> 20 
adversary victory points: -4
player victory points: 12 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  3.  0.] 
cards in discard: [ 8.  1.  3. 29.  0.  0. 14. 10.  3. 10.  1.  0.  0. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11  3  8 14 11] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 20. 29.  8.  2.  6.  3.  1.  9.  7.  7.  9.  5. 10.  8.] 
adversary cards in hand: [10.  8. 29.  3.  0.] 
adversary cards in discard: [25. 11. 16.  0.  0.  0.  6.  0.  6. 10.  6.] 
adversary owned cards: [ 0  3  8 10  0 10  6 16  8 29  6  0  0  0  6  8  6  6 25 11] -> size -> 20 
adversary victory points: -4
player victory points: 12 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  3.  0.] 
cards in discard: [ 8.  1.  3. 29.  0.  0. 14. 10.  3. 10.  1.  0.  0. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11  3  8 14 11] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 26. 30. 20. 29.  8.  2.  6.  3.  1.  9.  7.  7.  9.  5. 10.  8.] 
adversary cards in hand: [10.  8. 29.  3.  0.] 
adversary cards in discard: [25. 11. 16.  0.  0.  0.  6.  0.  6. 10.  6.] 
adversary owned cards: [ 0  3  8 10  0 10  6 16  8 29  6  0  0  0  6  8  6  6 25 11] -> size -> 20 
adversary victory points: -4
player victory points: 12 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  3.  0.] 
cards in discard: [ 8.  1.  3. 29.  0.  0. 14. 10.  3. 10.  1.  0.  0. 11.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11  3  8 14 11  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 26. 30. 20. 29.  8.  2.  6.  3.  1.  9.  7.  7.  9.  5. 10.  8.] 
adversary cards in hand: [10.  8. 29.  3.  0.] 
adversary cards in discard: [25. 11. 16.  0.  0.  0.  6.  0.  6. 10.  6.] 
adversary owned cards: [ 0  3  8 10  0 10  6 16  8 29  6  0  0  0  6  8  6  6 25 11] -> size -> 20 
adversary victory points: -4
player victory points: 12 





Player: 0 
cards in hand: [10.  8. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 29.] 
expected returns: [[56.93614 ]
 [51.6619  ]
 [51.962208]
 [54.60043 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 29.  3.  0.] 
cards in discard: [25. 11. 16.  0.  0.  0.  6.  0.  6. 10.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8 10  0 10  6 16  8 29  6  0  0  0  6  8  6  6 25 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 20. 29.  8.  2.  6.  3.  1.  9.  7.  7.  9.  5. 10.  8.] 
adversary cards in hand: [ 3.  0. 10.  3.  4.] 
adversary cards in discard: [ 8.  1.  3. 29.  0.  0. 14. 10.  3. 10.  1.  0.  0. 11.  0. 11. 15.  3.
  3.  0.] 
adversary owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11  3  8 14 11  0] -> size -> 39 
adversary victory points: 12
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -160    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -169 

action type: buy - action -1.0
Learning step: -9.997027397155762
desired expected reward: 45.68639373779297



action possibilites: [-1. 10.  8.] 
expected returns: [[72.115036]
 [64.854126]
 [65.27896 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  3.  0.  6.] 
cards in discard: [25. 11. 16.  0.  0.  0.  6.  0.  6. 10.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  8 10  0 10  6 16  8 29  6  0  0  0  6  8  6  6 25 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 26. 30. 20. 29.  8.  2.  6.  3.  1.  9.  7.  7.  9.  5. 10.  8.] 
adversary cards in hand: [ 3.  0. 10.  3.  4.] 
adversary cards in discard: [ 8.  1.  3. 29.  0.  0. 14. 10.  3. 10.  1.  0.  0. 11.  0. 11. 15.  3.
  3.  0.] 
adversary owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11  3  8 14 11  0] -> size -> 39 
adversary victory points: 12
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -160    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -149 

action type: take_action - action 29.0
Learning step: -8.623031616210938
desired expected reward: 45.977394104003906



action possibilites: [-1] 
expected returns: [[27.669983]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6.] 
cards in discard: [25. 11. 16.  0.  0.  0.  6.  0.  6. 10.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  8  0 10  6 16  8 29  6  0  0  0  6  8  6  6 25 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 26. 30. 20. 29.  8.  2.  6.  3.  1.  9.  7.  7.  9.  5. 10.  8.] 
adversary cards in hand: [ 3.  0. 10.  3.  4.] 
adversary cards in discard: [ 8.  1.  3. 29.  0.  0. 14. 10.  3. 10.  1.  0.  0. 11.  0. 11. 15.  3.
  3.  0.] 
adversary owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11  3  8 14 11  0] -> size -> 39 
adversary victory points: 12
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -170    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -140 

action type: trash_cards_n_from_hand - action 9
Learning step: -9.82575511932373
desired expected reward: 59.14083480834961





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[27.102608]
 [27.769453]
 [26.506327]
 [28.157091]
 [29.59965 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [25. 11. 16.  0.  0.  0.  6.  0.  6. 10.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  8  0 10  6 16  8 29  6  0  0  0  6  8  6  6 25 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 26. 30. 20. 29.  8.  2.  6.  3.  1.  9.  7.  7.  9.  5. 10.  8.] 
adversary cards in hand: [ 3.  0. 10.  3.  4.] 
adversary cards in discard: [ 8.  1.  3. 29.  0.  0. 14. 10.  3. 10.  1.  0.  0. 11.  0. 11. 15.  3.
  3.  0.] 
adversary owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11  3  8 14 11  0] -> size -> 39 
adversary victory points: 12
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -170    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -140 

action type: take_action - action -1
Learning step: -7.742253303527832
desired expected reward: 19.927730560302734



buy possibilites: [-1] 
expected returns: [[16.118471]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [25. 11. 16.  0.  0.  0.  6.  0.  6. 10.  6.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  8  0 10  6 16  8 29  6  0  0  0  6  8  6  6 25 11  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 20. 29.  8.  2.  6.  3.  0.  9.  7.  7.  9.  5. 10.  8.] 
adversary cards in hand: [ 3.  0. 10.  3.  4.] 
adversary cards in discard: [ 8.  1.  3. 29.  0.  0. 14. 10.  3. 10.  1.  0.  0. 11.  0. 11. 15.  3.
  3.  0.] 
adversary owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11  3  8 14 11  0] -> size -> 39 
adversary victory points: 12
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -170    0    0   40    0    0    0    0    0    0    0
    8    0] 
sum of rewards: -132 

action type: buy - action 8.0
Learning step: -7.6451897621154785
desired expected reward: 20.51190948486328






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 10.  3.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  3.  4.] 
cards in discard: [ 8.  1.  3. 29.  0.  0. 14. 10.  3. 10.  1.  0.  0. 11.  0. 11. 15.  3.
  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11  3  8 14 11  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 20. 29.  8.  2.  6.  3.  0.  9.  7.  7.  9.  5. 10.  8.] 
adversary cards in hand: [6. 6. 8. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  0 10  6 16  8 29  6  0  0  0  6  8  6  6 25 11  8] -> size -> 19 
adversary victory points: -5
player victory points: 12 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  3.  4.] 
cards in discard: [ 8.  1.  3. 29.  0.  0. 14. 10.  3. 10.  1.  0.  0. 11.  0. 11. 15.  3.
  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11  3  8 14 11  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 26. 30. 20. 29.  8.  2.  6.  3.  0.  9.  7.  7.  9.  5. 10.  8.] 
adversary cards in hand: [6. 6. 8. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  0 10  6 16  8 29  6  0  0  0  6  8  6  6 25 11  8] -> size -> 19 
adversary victory points: -5
player victory points: 12 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  3.  4.] 
cards in discard: [ 8.  1.  3. 29.  0.  0. 14. 10.  3. 10.  1.  0.  0. 11.  0. 11. 15.  3.
  3.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11  3  8 14 11  0  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 26. 30. 20. 29.  8.  2.  6.  3.  0.  9.  7.  7.  9.  5. 10.  8.] 
adversary cards in hand: [6. 6. 8. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  0 10  6 16  8 29  6  0  0  0  6  8  6  6 25 11  8] -> size -> 19 
adversary victory points: -5
player victory points: 12 





Player: 0 
cards in hand: [6. 6. 8. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[74.15091]
 [67.55148]
 [67.55148]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 8. 6. 8.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0 10  6 16  8 29  6  0  0  0  6  8  6  6 25 11  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 20. 29.  8.  2.  6.  3.  0.  9.  7.  7.  9.  5. 10.  8.] 
adversary cards in hand: [11. 14. 23.  0.  8.] 
adversary cards in discard: [ 8.  1.  3. 29.  0.  0. 14. 10.  3. 10.  1.  0.  0. 11.  0. 11. 15.  3.
  3.  0.  0.  3.  0. 10.  3.  4.] 
adversary owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11  3  8 14 11  0  0] -> size -> 40 
adversary victory points: 12
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -170    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -180 

action type: buy - action -1
Learning step: -8.19894790649414
desired expected reward: 7.919523239135742



action possibilites: [-1] 
expected returns: [[27.855577]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 10 16  8 29  0  0  0  6  8  6  6 25 11  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 20. 29.  8.  2.  6.  3.  0.  9.  7.  7.  9.  5. 10.  8.] 
adversary cards in hand: [11. 14. 23.  0.  8.] 
adversary cards in discard: [ 8.  1.  3. 29.  0.  0. 14. 10.  3. 10.  1.  0.  0. 11.  0. 11. 15.  3.
  3.  0.  0.  3.  0. 10.  3.  4.] 
adversary owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11  3  8 14 11  0  0] -> size -> 40 
adversary victory points: 12
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -138 

action type: trash_cards_n_from_hand - action 5
Learning step: -9.49876594543457
desired expected reward: 58.33623504638672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[19.597574]
 [18.194967]
 [25.092882]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 10 16  8 29  0  0  0  6  8  6  6 25 11  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 26. 30. 20. 29.  8.  2.  6.  3.  0.  9.  7.  7.  9.  5. 10.  8.] 
adversary cards in hand: [11. 14. 23.  0.  8.] 
adversary cards in discard: [ 8.  1.  3. 29.  0.  0. 14. 10.  3. 10.  1.  0.  0. 11.  0. 11. 15.  3.
  3.  0.  0.  3.  0. 10.  3.  4.] 
adversary owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11  3  8 14 11  0  0] -> size -> 40 
adversary victory points: 12
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -138 

action type: take_action - action -1
Learning step: -7.78585958480835
desired expected reward: 20.069717407226562



buy possibilites: [-1] 
expected returns: [[21.964937]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 10 16  8 29  0  0  0  6  8  6  6 25 11  8  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 20. 29.  8.  1.  6.  3.  0.  9.  7.  7.  9.  5. 10.  8.] 
adversary cards in hand: [11. 14. 23.  0.  8.] 
adversary cards in discard: [ 8.  1.  3. 29.  0.  0. 14. 10.  3. 10.  1.  0.  0. 11.  0. 11. 15.  3.
  3.  0.  0.  3.  0. 10.  3.  4.] 
adversary owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11  3  8 14 11  0  0] -> size -> 40 
adversary victory points: 12
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -160    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -449 

action type: buy - action 6.0
Learning step: -22.865537643432617
desired expected reward: -4.67057991027832






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [11. 14. 23.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14. 23.  8.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 14. 23.  0.  8.] 
cards in discard: [ 8.  1.  3. 29.  0.  0. 14. 10.  3. 10.  1.  0.  0. 11.  0. 11. 15.  3.
  3.  0.  0.  3.  0. 10.  3.  4.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11  3  8 14 11  0  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 20. 29.  8.  1.  6.  3.  0.  9.  7.  7.  9.  5. 10.  8.] 
adversary cards in hand: [ 6.  8.  0.  6. 25.] 
adversary cards in discard: [6. 8. 6.] 
adversary owned cards: [ 0  0 10 16  8 29  0  0  0  6  8  6  6 25 11  8  6] -> size -> 17 
adversary victory points: -4
player victory points: 12 


action possibilites: [-1. 11. 14.  8.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 14.  0.  8.  8.] 
cards in discard: [ 8.  1.  3. 29.  0.  0. 14. 10.  3. 10.  1.  0.  0. 11.  0. 11. 15.  3.
  3.  0.  0.  3.  0. 10.  3.  4.] 
cards in deck: 8 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11  3  8 14 11  0  0] -> size -> 40 
action values: 1 
buys: 1 
player value: 1 
card supply: [15. 26. 30. 20. 29.  8.  1.  6.  3.  0.  9.  7.  7.  9.  5. 10.  8.] 
adversary cards in hand: [ 6.  8.  0.  6. 25.] 
adversary cards in discard: [6. 8. 6.] 
adversary owned cards: [ 0  0 10 16  8 29  0  0  0  6  8  6  6 25 11  8  6] -> size -> 17 
adversary victory points: -4
player victory points: 12 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  8.  8.] 
cards in discard: [ 8.  1.  3. 29.  0.  0. 14. 10.  3. 10.  1.  0.  0. 11.  0. 11. 15.  3.
  3.  0.  0.  3.  0. 10.  3.  4. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [23. 11.] 
owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11  3  8 14 11  0  0 14] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 26. 30. 20. 29.  8.  1.  6.  3.  0.  9.  7.  6.  9.  5. 10.  8.] 
adversary cards in hand: [ 6.  8.  0.  6. 25.] 
adversary cards in discard: [6. 8. 6.] 
adversary owned cards: [ 0  0 10 16  8 29  0  0  0  6  8  6  6 25 11  8  6] -> size -> 17 
adversary victory points: -4
player victory points: 12 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  8.  8.] 
cards in discard: [ 8.  1.  3. 29.  0.  0. 14. 10.  3. 10.  1.  0.  0. 11.  0. 11. 15.  3.
  3.  0.  0.  3.  0. 10.  3.  4. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [23. 11.] 
owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11  3  8 14 11  0  0 14] -> size -> 41 
action values: 0 
buys: 2 
player value: 2 
card supply: [15. 26. 30. 20. 29.  8.  1.  6.  3.  0.  9.  7.  6.  9.  5. 10.  8.] 
adversary cards in hand: [ 6.  8.  0.  6. 25.] 
adversary cards in discard: [6. 8. 6.] 
adversary owned cards: [ 0  0 10 16  8 29  0  0  0  6  8  6  6 25 11  8  6] -> size -> 17 
adversary victory points: -4
player victory points: 12 





Player: 0 
cards in hand: [ 6.  8.  0.  6. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
expected returns: [[25.734404]
 [21.690767]
 [25.609692]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  0.  6. 25.] 
cards in discard: [6. 8. 6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10 16  8 29  0  0  0  6  8  6  6 25 11  8  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 20. 29.  8.  1.  6.  3.  0.  9.  7.  6.  9.  5. 10.  8.] 
adversary cards in hand: [11. 29.  8.  0. 16.] 
adversary cards in discard: [ 8.  1.  3. 29.  0.  0. 14. 10.  3. 10.  1.  0.  0. 11.  0. 11. 15.  3.
  3.  0.  0.  3.  0. 10.  3.  4. 14. 23. 11. 14.  0.  8.  8.] 
adversary owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11  3  8 14 11  0  0 14] -> size -> 41 
adversary victory points: 12
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -160    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -169 

action type: buy - action -1
Learning step: -8.988619804382324
desired expected reward: 12.976317405700684



action possibilites: [-1] 
expected returns: [[8.786132]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [6. 8. 6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 10 16  8 29  0  0  0  8  6 11  8  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 20. 29.  8.  1.  6.  3.  0.  9.  7.  6.  9.  5. 10.  8.] 
adversary cards in hand: [11. 29.  8.  0. 16.] 
adversary cards in discard: [ 8.  1.  3. 29.  0.  0. 14. 10.  3. 10.  1.  0.  0. 11.  0. 11. 15.  3.
  3.  0.  0.  3.  0. 10.  3.  4. 14. 23. 11. 14.  0.  8.  8.] 
adversary owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11  3  8 14 11  0  0 14] -> size -> 41 
adversary victory points: 12
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -140    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -127 

action type: trash_cards_n_from_hand - action 9
Learning step: -7.369118690490723
desired expected reward: 16.967002868652344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[3.0444267]
 [1.6735983]
 [7.320709 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [6. 8. 6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 10 16  8 29  0  0  0  8  6 11  8  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 26. 30. 20. 29.  8.  1.  6.  3.  0.  9.  7.  6.  9.  5. 10.  8.] 
adversary cards in hand: [11. 29.  8.  0. 16.] 
adversary cards in discard: [ 8.  1.  3. 29.  0.  0. 14. 10.  3. 10.  1.  0.  0. 11.  0. 11. 15.  3.
  3.  0.  0.  3.  0. 10.  3.  4. 14. 23. 11. 14.  0.  8.  8.] 
adversary owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11  3  8 14 11  0  0 14] -> size -> 41 
adversary victory points: 12
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -140    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -127 

action type: take_action - action -1
Learning step: -6.6707682609558105
desired expected reward: 2.115363597869873






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [11. 29.  8.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  8.  0. 16.] 
cards in discard: [ 8.  1.  3. 29.  0.  0. 14. 10.  3. 10.  1.  0.  0. 11.  0. 11. 15.  3.
  3.  0.  0.  3.  0. 10.  3.  4. 14. 23. 11. 14.  0.  8.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  8  0  3  1  3
  8  8  3  1 10  3 11  3  0 11  3  8 14 11  0  0 14] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 20. 29.  8.  1.  6.  3.  0.  9.  7.  6.  9.  5. 10.  8.] 
adversary cards in hand: [29. 16. 11.  0.  8.] 
adversary cards in discard: [6. 8. 6. 8. 0.] 
adversary owned cards: [ 0  0 10 16  8 29  0  0  0  8  6 11  8  6] -> size -> 14 
adversary victory points: -2
player victory points: 12 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  0.] 
cards in discard: [ 8.  1.  3. 29.  0.  0. 14. 10.  3. 10.  1.  0.  0. 11.  0. 11. 15.  3.
  3.  0.  0.  3.  0. 10.  3.  4. 14. 23. 11. 14.  0.  8.  8.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8
  8  3  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 20. 29.  8.  0.  6.  3.  0.  9.  7.  6.  9.  5. 10.  8.] 
adversary cards in hand: [29. 16. 11.  0.  8.] 
adversary cards in discard: [6. 8. 6. 8. 0.] 
adversary owned cards: [ 0  0 10 16  8 29  0  0  0  8  6 11  8  6] -> size -> 14 
adversary victory points: -2
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29.  0.] 
cards in discard: [ 8.  1.  3. 29.  0.  0. 14. 10.  3. 10.  1.  0.  0. 11.  0. 11. 15.  3.
  3.  0.  0.  3.  0. 10.  3.  4. 14. 23. 11. 14.  0.  8.  8.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8
  8  3  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 26. 30. 20. 29.  8.  0.  6.  3.  0.  9.  7.  6.  9.  5. 10.  8.] 
adversary cards in hand: [29. 16. 11.  0.  8.] 
adversary cards in discard: [6. 8. 6. 8. 0.] 
adversary owned cards: [ 0  0 10 16  8 29  0  0  0  8  6 11  8  6] -> size -> 14 
adversary victory points: -2
player victory points: 11 





Player: 0 
cards in hand: [29. 16. 11.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 16. 11.  8.] 
expected returns: [[70.37259 ]
 [69.54576 ]
 [67.668755]
 [69.26624 ]
 [68.28312 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 16. 11.  0.  8.] 
cards in discard: [6. 8. 6. 8. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10 16  8 29  0  0  0  8  6 11  8  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 20. 29.  8.  0.  6.  3.  0.  9.  7.  6.  9.  5. 10.  8.] 
adversary cards in hand: [3. 1. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8
  8  3  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6] -> size -> 41 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -137 

action type: buy - action -1.0
Learning step: -5.651432991027832
desired expected reward: 1.6692790985107422



action possibilites: [-1. 16. 11.] 
expected returns: [[87.10438]
 [79.81093]
 [83.88301]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 11.  0.] 
cards in discard: [6. 8. 6. 8. 0. 8. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 10 16  8 29  0  0  0  8  6 11  8  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [15. 26. 30. 20. 29.  8.  0.  6.  3.  0.  9.  7.  6.  9.  5. 10.  8.] 
adversary cards in hand: [3. 1. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8
  8  3  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6] -> size -> 41 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -130    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -117 

action type: discard_n_cards - action 3
Learning step: -7.324620723724365
desired expected reward: 60.386165618896484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[75.74588]
 [78.14408]
 [85.09645]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 11.  0.] 
cards in discard: [6. 8. 6. 8. 0. 8. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 10 16  8 29  0  0  0  8  6 11  8  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 26. 30. 20. 29.  8.  0.  6.  3.  0.  9.  7.  6.  9.  5. 10.  8.] 
adversary cards in hand: [3. 1. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8
  8  3  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6] -> size -> 41 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -130    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -117 

action type: take_action - action -1.0
Learning step: -8.366414070129395
desired expected reward: 78.73798370361328






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [3. 1. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8
  8  3  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 20. 29.  8.  0.  6.  3.  0.  9.  7.  6.  9.  5. 10.  8.] 
adversary cards in hand: [ 0.  6.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 10 16  8 29  0  0  0  8  6 11  8  6] -> size -> 14 
adversary victory points: -2
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8
  8  3  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 26. 30. 20. 29.  8.  0.  6.  3.  0.  9.  7.  6.  9.  5. 10.  8.] 
adversary cards in hand: [ 0.  6.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 10 16  8 29  0  0  0  8  6 11  8  6] -> size -> 14 
adversary victory points: -2
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 3. 3.] 
cards in discard: [0.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8
  8  3  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 26. 30. 20. 29.  8.  0.  6.  3.  0.  9.  7.  6.  9.  5. 10.  8.] 
adversary cards in hand: [ 0.  6.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 10 16  8 29  0  0  0  8  6 11  8  6] -> size -> 14 
adversary victory points: -2
player victory points: 11 





Player: 0 
cards in hand: [ 0.  6.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[22.688982]
 [16.865929]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10 16  8 29  0  0  0  8  6 11  8  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 20. 29.  8.  0.  6.  3.  0.  9.  7.  6.  9.  5. 10.  8.] 
adversary cards in hand: [ 0.  0. 11. 14. 10.] 
adversary cards in discard: [0. 3. 1. 3. 3. 3.] 
adversary owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8
  8  3  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0] -> size -> 42 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -137 

action type: buy - action -1.0
Learning step: -10.651618003845215
desired expected reward: 74.4448471069336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[10.886463]
 [13.436014]
 [13.069633]
 [16.324194]
 [13.440066]
 [19.29666 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10 16  8 29  0  0  0  8  6 11  8  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 26. 30. 20. 29.  8.  0.  6.  3.  0.  9.  7.  6.  9.  5. 10.  8.] 
adversary cards in hand: [ 0.  0. 11. 14. 10.] 
adversary cards in discard: [0. 3. 1. 3. 3. 3.] 
adversary owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8
  8  3  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0] -> size -> 42 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -137 

action type: take_action - action -1.0
Learning step: -7.580893039703369
desired expected reward: 14.35574722290039



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 11. 14. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14. 10.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 14. 10.] 
cards in discard: [0. 3. 1. 3. 3. 3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8
  8  3  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 20. 29.  8.  0.  6.  3.  0.  9.  7.  6.  9.  5. 10.  8.] 
adversary cards in hand: [11. 16.  6.  8. 29.] 
adversary cards in discard: [ 0.  6.  0.  0. 10.] 
adversary owned cards: [ 0  0 10 16  8 29  0  0  0  8  6 11  8  6] -> size -> 14 
adversary victory points: -2
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 10.] 
cards in discard: [0. 3. 1. 3. 3. 3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8
  8  3  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 26. 30. 20. 29.  8.  0.  6.  3.  0.  9.  7.  6.  9.  5. 10.  8.] 
adversary cards in hand: [16.  6. 29.] 
adversary cards in discard: [ 0.  6.  0.  0. 10. 11.  8.] 
adversary owned cards: [ 0  0 10 16  8 29  0  0  0  8  6 11  8  6] -> size -> 14 
adversary victory points: -2
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 10.] 
cards in discard: [0. 3. 1. 3. 3. 3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8
  8  3  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 26. 30. 20. 29.  8.  0.  6.  3.  0.  9.  7.  6.  9.  5. 10.  8.] 
adversary cards in hand: [16.  6. 29.] 
adversary cards in discard: [ 0.  6.  0.  0. 10. 11.  8.] 
adversary owned cards: [ 0  0 10 16  8 29  0  0  0  8  6 11  8  6] -> size -> 14 
adversary victory points: -2
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 10.] 
cards in discard: [ 0.  3.  1.  3.  3.  3. 11.] 
cards in deck: 31 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8
  8  3  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 26. 30. 20. 29.  8.  0.  6.  2.  0.  9.  7.  6.  9.  5. 10.  8.] 
adversary cards in hand: [16.  6. 29.] 
adversary cards in discard: [ 0.  6.  0.  0. 10. 11.  8.] 
adversary owned cards: [ 0  0 10 16  8 29  0  0  0  8  6 11  8  6] -> size -> 14 
adversary victory points: -2
player victory points: 11 





Player: 0 
cards in hand: [16.  6. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29.] 
expected returns: [[49.027615]
 [47.266838]
 [48.529873]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6. 29.] 
cards in discard: [ 0.  6.  0.  0. 10. 11.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10 16  8 29  0  0  0  8  6 11  8  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 20. 29.  8.  0.  6.  2.  0.  9.  7.  6.  9.  5. 10.  8.] 
adversary cards in hand: [ 4.  6.  0. 16. 29.] 
adversary cards in discard: [ 0.  3.  1.  3.  3.  3. 11. 14.  0.  0. 11. 10.] 
adversary owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8
  8  3  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11] -> size -> 43 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -137 

action type: discard_down_to_3_cards - action 9
Learning step: -6.430144786834717
desired expected reward: 7.024972438812256





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[47.531353]
 [49.89214 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6. 29.] 
cards in discard: [ 0.  6.  0.  0. 10. 11.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10 16  8 29  0  0  0  8  6 11  8  6] -> size -> 14 
action values: 1 
buys: 1 
player value: 0 
card supply: [14. 26. 30. 20. 29.  8.  0.  6.  2.  0.  9.  7.  6.  9.  5. 10.  8.] 
adversary cards in hand: [ 4.  6.  0. 16. 29.] 
adversary cards in discard: [ 0.  3.  1.  3.  3.  3. 11. 14.  0.  0. 11. 10.] 
adversary owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8
  8  3  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11] -> size -> 43 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -137 

action type: take_action - action -1.0
Learning step: -8.19528579711914
desired expected reward: 40.83232116699219



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [ 4.  6.  0. 16. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4.  6.  0. 16. 29.] 
cards in discard: [ 0.  3.  1.  3.  3.  3. 11. 14.  0.  0. 11. 10.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8
  8  3  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 20. 29.  8.  0.  6.  2.  0.  9.  7.  6.  9.  5. 10.  8.] 
adversary cards in hand: [8. 8. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 10 16  8 29  0  0  0  8  6 11  8  6] -> size -> 14 
adversary victory points: -2
player victory points: 11 


action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4.  0. 16.] 
cards in discard: [ 0.  3.  1.  3.  3.  3. 11. 14.  0.  0. 11. 10.  6.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3 29  3 11  0  0  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8
  8  3  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11] -> size -> 43 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 26. 30. 20. 29.  8.  0.  6.  2.  0.  9.  7.  6.  9.  5. 10.  8.] 
adversary cards in hand: [8. 8. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 10 16  8 29  0  0  0  8  6 11  8  6] -> size -> 14 
adversary victory points: -2
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4.] 
cards in discard: [ 0.  3.  1.  3.  3.  3. 11. 14.  0.  0. 11. 10.  6.  3.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 3 29  3 11  0  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8
  3  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 26. 30. 20. 29.  8.  0.  6.  2.  0.  9.  7.  6.  9.  5. 10.  8.] 
adversary cards in hand: [8. 8. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 10 16  8 29  0  0  0  8  6 11  8  6] -> size -> 14 
adversary victory points: -2
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4.] 
cards in discard: [ 0.  3.  1.  3.  3.  3. 11. 14.  0.  0. 11. 10.  6.  3.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 3 29  3 11  0  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8
  3  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 26. 30. 20. 29.  8.  0.  6.  2.  0.  9.  7.  6.  9.  5. 10.  8.] 
adversary cards in hand: [8. 8. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 10 16  8 29  0  0  0  8  6 11  8  6] -> size -> 14 
adversary victory points: -2
player victory points: 11 





Player: 0 
cards in hand: [8. 8. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
expected returns: [[ 1.0513654]
 [-1.9837679]
 [-1.9837679]
 [-1.9837679]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10 16  8 29  0  0  0  8  6 11  8  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 20. 29.  8.  0.  6.  2.  0.  9.  7.  6.  9.  5. 10.  8.] 
adversary cards in hand: [ 0. 11.  3.  0. 15.] 
adversary cards in discard: [ 0.  3.  1.  3.  3.  3. 11. 14.  0.  0. 11. 10.  6.  3.  0. 29. 16.  4.] 
adversary owned cards: [ 3 29  3 11  0  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8
  3  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0] -> size -> 43 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -137 

action type: buy - action -1.0
Learning step: -9.354299545288086
desired expected reward: 40.537841796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-2.0332837]
 [-2.0332837]
 [-2.0210185]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10 16  8 29  0  0  0  8  6 11  8  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 26. 30. 20. 29.  8.  0.  6.  2.  0.  9.  7.  6.  9.  5. 10.  8.] 
adversary cards in hand: [ 0. 11.  3.  0. 15.] 
adversary cards in discard: [ 0.  3.  1.  3.  3.  3. 11. 14.  0.  0. 11. 10.  6.  3.  0. 29. 16.  4.] 
adversary owned cards: [ 3 29  3 11  0  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8
  3  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0] -> size -> 43 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -137 

action type: take_action - action -1.0
Learning step: -6.793923377990723
desired expected reward: -8.827207565307617



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  3.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0. 15.] 
cards in discard: [ 0.  3.  1.  3.  3.  3. 11. 14.  0.  0. 11. 10.  6.  3.  0. 29. 16.  4.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  3 11  0  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8
  3  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 20. 29.  8.  0.  6.  2.  0.  9.  7.  6.  9.  5. 10.  8.] 
adversary cards in hand: [ 6. 29.  0.  0.  0.] 
adversary cards in discard: [8. 8. 8. 0. 0.] 
adversary owned cards: [ 0  0 10 16  8 29  0  0  0  8  6 11  8  6] -> size -> 14 
adversary victory points: -2
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 15.] 
cards in discard: [ 0.  3.  1.  3.  3.  3. 11. 14.  0.  0. 11. 10.  6.  3.  0. 29. 16.  4.
 14.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 29  3 11  0  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8
  3  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 20. 29.  8.  0.  6.  2.  0.  9.  7.  5.  9.  5. 10.  8.] 
adversary cards in hand: [ 6. 29.  0.  0.  0.] 
adversary cards in discard: [8. 8. 8. 0. 0.] 
adversary owned cards: [ 0  0 10 16  8 29  0  0  0  8  6 11  8  6] -> size -> 14 
adversary victory points: -2
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 15.] 
cards in discard: [ 0.  3.  1.  3.  3.  3. 11. 14.  0.  0. 11. 10.  6.  3.  0. 29. 16.  4.
 14.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 29  3 11  0  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8
  3  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 26. 30. 20. 29.  8.  0.  6.  2.  0.  9.  7.  5.  9.  5. 10.  8.] 
adversary cards in hand: [ 6. 29.  0.  0.  0.] 
adversary cards in discard: [8. 8. 8. 0. 0.] 
adversary owned cards: [ 0  0 10 16  8 29  0  0  0  8  6 11  8  6] -> size -> 14 
adversary victory points: -2
player victory points: 11 





Player: 0 
cards in hand: [ 6. 29.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[1.4854437]
 [1.2333101]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29.  0.  0.  0.] 
cards in discard: [8. 8. 8. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10 16  8 29  0  0  0  8  6 11  8  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 20. 29.  8.  0.  6.  2.  0.  9.  7.  5.  9.  5. 10.  8.] 
adversary cards in hand: [8. 8. 8. 0. 0.] 
adversary cards in discard: [ 0.  3.  1.  3.  3.  3. 11. 14.  0.  0. 11. 10.  6.  3.  0. 29. 16.  4.
 14. 11.  0.  3.  0. 15.] 
adversary owned cards: [ 3 29  3 11  0  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8
  3  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14] -> size -> 44 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -137 

action type: buy - action -1.0
Learning step: -6.717286586761475
desired expected reward: -8.738304138183594



action possibilites: [-1.] 
expected returns: [[22.504627]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0.] 
cards in discard: [ 8.  8.  8.  0.  0.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 10 16  8 29  0  0  0  8  6 11  8  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [13. 26. 30. 20. 29.  8.  0.  6.  2.  0.  9.  7.  5.  9.  5. 10.  8.] 
adversary cards in hand: [8. 8. 8. 0. 0.] 
adversary cards in discard: [ 0.  3.  1.  3.  3.  3. 11. 14.  0.  0. 11. 10.  6.  3.  0. 29. 16.  4.
 14. 11.  0.  3.  0. 15.] 
adversary owned cards: [ 3 29  3 11  0  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8
  3  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14] -> size -> 44 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -130    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -117 

action type: discard_n_cards - action 1
Learning step: -5.37654447555542
desired expected reward: -4.718578815460205





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[19.061338]
 [19.887962]
 [19.731583]
 [20.797258]
 [19.859472]
 [21.659145]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [ 8.  8.  8.  0.  0.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 10 16  8 29  0  0  0  8  6 11  8  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 26. 30. 20. 29.  8.  0.  6.  2.  0.  9.  7.  5.  9.  5. 10.  8.] 
adversary cards in hand: [8. 8. 8. 0. 0.] 
adversary cards in discard: [ 0.  3.  1.  3.  3.  3. 11. 14.  0.  0. 11. 10.  6.  3.  0. 29. 16.  4.
 14. 11.  0.  3.  0. 15.] 
adversary owned cards: [ 3 29  3 11  0  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8
  3  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14] -> size -> 44 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -130    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -117 

action type: take_action - action -1.0
Learning step: -6.5087432861328125
desired expected reward: 15.99588394165039



buy possibilites: [-1] 
expected returns: [[8.701967]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [ 8.  8.  8.  0.  0.  0. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 10 16  8 29  0  0  0  8  6 11  8  6  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [12. 26. 30. 20. 29.  8.  0.  6.  2.  0.  9.  7.  5.  9.  5. 10.  8.] 
adversary cards in hand: [8. 8. 8. 0. 0.] 
adversary cards in discard: [ 0.  3.  1.  3.  3.  3. 11. 14.  0.  0. 11. 10.  6.  3.  0. 29. 16.  4.
 14. 11.  0.  3.  0. 15.] 
adversary owned cards: [ 3 29  3 11  0  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8
  3  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14] -> size -> 44 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2. -130.    0.    0.   20.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -147.0 

action type: buy - action 0.0
Learning step: -8.107272148132324
desired expected reward: 10.954060554504395






         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [8. 8. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 8. 0. 0.] 
cards in discard: [ 0.  3.  1.  3.  3.  3. 11. 14.  0.  0. 11. 10.  6.  3.  0. 29. 16.  4.
 14. 11.  0.  3.  0. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  3 11  0  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8
  3  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 20. 29.  8.  0.  6.  2.  0.  9.  7.  5.  9.  5. 10.  8.] 
adversary cards in hand: [ 0.  8.  6. 11. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 10 16  8 29  0  0  0  8  6 11  8  6  0] -> size -> 15 
adversary victory points: -2
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0.] 
cards in discard: [ 0.  3.  1.  3.  3.  3. 11. 14.  0.  0. 11. 10.  6.  3.  0. 29. 16.  4.
 14. 11.  0.  3.  0. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 29  3 11  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3
  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 20. 29.  8.  0.  6.  2.  0.  9.  7.  5.  9.  5. 10.  8.] 
adversary cards in hand: [ 0.  8.  6. 11. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 10 16  8 29  0  0  0  8  6 11  8  6  0] -> size -> 15 
adversary victory points: -2
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0.] 
cards in discard: [ 0.  3.  1.  3.  3.  3. 11. 14.  0.  0. 11. 10.  6.  3.  0. 29. 16.  4.
 14. 11.  0.  3.  0. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 29  3 11  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3
  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 26. 30. 20. 29.  8.  0.  6.  2.  0.  9.  7.  5.  9.  5. 10.  8.] 
adversary cards in hand: [ 0.  8.  6. 11. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 10 16  8 29  0  0  0  8  6 11  8  6  0] -> size -> 15 
adversary victory points: -2
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0.] 
cards in discard: [ 0.  3.  1.  3.  3.  3. 11. 14.  0.  0. 11. 10.  6.  3.  0. 29. 16.  4.
 14. 11.  0.  3.  0. 15.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 29  3 11  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3
  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 26. 30. 20. 29.  8.  0.  6.  2.  0.  9.  7.  5.  9.  5. 10.  8.] 
adversary cards in hand: [ 0.  8.  6. 11. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 10 16  8 29  0  0  0  8  6 11  8  6  0] -> size -> 15 
adversary victory points: -2
player victory points: 11 





Player: 0 
cards in hand: [ 0.  8.  6. 11. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 16.] 
expected returns: [[4.003068 ]
 [2.2501364]
 [2.9115543]
 [1.8935593]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  6. 11. 16.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10 16  8 29  0  0  0  8  6 11  8  6  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 20. 29.  8.  0.  6.  2.  0.  9.  7.  5.  9.  5. 10.  8.] 
adversary cards in hand: [ 3. 23. 10. 14.  3.] 
adversary cards in discard: [ 0.  3.  1.  3.  3.  3. 11. 14.  0.  0. 11. 10.  6.  3.  0. 29. 16.  4.
 14. 11.  0.  3.  0. 15.  0.  8.  8.  8.  0.] 
adversary owned cards: [ 3 29  3 11  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3
  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14  0] -> size -> 44 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -137 

action type: buy - action -1
Learning step: -7.212319374084473
desired expected reward: 1.4896478652954102



action possibilites: [-1] 
expected returns: [[36.67747]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 10  8 29  0  0  0  8  6 11  8  6  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 20. 29.  8.  0.  6.  2.  0.  9.  7.  5.  9.  5. 10.  8.] 
adversary cards in hand: [ 3. 23. 10. 14.  3.] 
adversary cards in discard: [ 0.  3.  1.  3.  3.  3. 11. 14.  0.  0. 11. 10.  6.  3.  0. 29. 16.  4.
 14. 11.  0.  3.  0. 15.  0.  8.  8.  8.  0.] 
adversary owned cards: [ 3 29  3 11  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3
  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14  0] -> size -> 44 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -130    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -117 

action type: trash_cards_n_from_hand - action 4
Learning step: -5.12459135055542
desired expected reward: -3.1279072761535645





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[28.220901]
 [35.8836  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 10  8 29  0  0  0  8  6 11  8  6  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [11. 26. 30. 20. 29.  8.  0.  6.  2.  0.  9.  7.  5.  9.  5. 10.  8.] 
adversary cards in hand: [ 3. 23. 10. 14.  3.] 
adversary cards in discard: [ 0.  3.  1.  3.  3.  3. 11. 14.  0.  0. 11. 10.  6.  3.  0. 29. 16.  4.
 14. 11.  0.  3.  0. 15.  0.  8.  8.  8.  0.] 
adversary owned cards: [ 3 29  3 11  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3
  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14  0] -> size -> 44 
adversary victory points: 11
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -130    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -117 

action type: take_action - action -1
Learning step: -6.929978847503662
desired expected reward: 29.74749183654785






         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [ 3. 23. 10. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 10. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 23. 10. 14.  3.] 
cards in discard: [ 0.  3.  1.  3.  3.  3. 11. 14.  0.  0. 11. 10.  6.  3.  0. 29. 16.  4.
 14. 11.  0.  3.  0. 15.  0.  8.  8.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  3 11  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3
  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 20. 29.  8.  0.  6.  2.  0.  9.  7.  5.  9.  5. 10.  8.] 
adversary cards in hand: [10. 29.  8.  6.  0.] 
adversary cards in discard: [ 8.  6. 11.] 
adversary owned cards: [ 0 10  8 29  0  0  0  8  6 11  8  6  0] -> size -> 13 
adversary victory points: -2
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 23. 10.  3.] 
cards in discard: [ 0.  3.  1.  3.  3.  3. 11. 14.  0.  0. 11. 10.  6.  3.  0. 29. 16.  4.
 14. 11.  0.  3.  0. 15.  0.  8.  8.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 29  3 11  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3
  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 26. 30. 20. 29.  8.  0.  6.  2.  0.  9.  7.  5.  9.  5. 10.  8.] 
adversary cards in hand: [29.  8.  0.] 
adversary cards in discard: [ 8.  6. 11. 10.  6.] 
adversary owned cards: [ 0 10  8 29  0  0  0  8  6 11  8  6  0] -> size -> 13 
adversary victory points: -2
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 23. 10.  3.] 
cards in discard: [ 0.  3.  1.  3.  3.  3. 11. 14.  0.  0. 11. 10.  6.  3.  0. 29. 16.  4.
 14. 11.  0.  3.  0. 15.  0.  8.  8.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 29  3 11  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3
  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14  0] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 26. 30. 20. 29.  8.  0.  6.  2.  0.  9.  7.  5.  9.  5. 10.  8.] 
adversary cards in hand: [29.  8.  0.] 
adversary cards in discard: [ 8.  6. 11. 10.  6.] 
adversary owned cards: [ 0 10  8 29  0  0  0  8  6 11  8  6  0] -> size -> 13 
adversary victory points: -2
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 23. 10.  3.] 
cards in discard: [ 0.  3.  1.  3.  3.  3. 11. 14.  0.  0. 11. 10.  6.  3.  0. 29. 16.  4.
 14. 11.  0.  3.  0. 15.  0.  8.  8.  8.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 29  3 11  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3
  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14  0  3] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 19. 29.  8.  0.  6.  2.  0.  9.  7.  5.  9.  5. 10.  8.] 
adversary cards in hand: [29.  8.  0.] 
adversary cards in discard: [ 8.  6. 11. 10.  6.] 
adversary owned cards: [ 0 10  8 29  0  0  0  8  6 11  8  6  0] -> size -> 13 
adversary victory points: -2
player victory points: 12 





Player: 0 
cards in hand: [29.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[12.160085]
 [11.16692 ]
 [ 9.926966]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  0.] 
cards in discard: [ 8.  6. 11. 10.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10  8 29  0  0  0  8  6 11  8  6  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 19. 29.  8.  0.  6.  2.  0.  9.  7.  5.  9.  5. 10.  8.] 
adversary cards in hand: [10.  0.  0.  0.  3.] 
adversary cards in discard: [ 0.  3.  1.  3.  3.  3. 11. 14.  0.  0. 11. 10.  6.  3.  0. 29. 16.  4.
 14. 11.  0.  3.  0. 15.  0.  8.  8.  8.  0.  3. 14.  3. 23. 10.  3.] 
adversary owned cards: [ 3 29  3 11  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3
  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14  0  3] -> size -> 45 
adversary victory points: 12
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -147 

action type: discard_down_to_3_cards - action 6
Learning step: -7.5426859855651855
desired expected reward: 1.4827942848205566





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 6.671894]
 [10.069992]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8.  0.] 
cards in discard: [ 8.  6. 11. 10.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10  8 29  0  0  0  8  6 11  8  6  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 26. 30. 19. 29.  8.  0.  6.  2.  0.  9.  7.  5.  9.  5. 10.  8.] 
adversary cards in hand: [10.  0.  0.  0.  3.] 
adversary cards in discard: [ 0.  3.  1.  3.  3.  3. 11. 14.  0.  0. 11. 10.  6.  3.  0. 29. 16.  4.
 14. 11.  0.  3.  0. 15.  0.  8.  8.  8.  0.  3. 14.  3. 23. 10.  3.] 
adversary owned cards: [ 3 29  3 11  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3
  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14  0  3] -> size -> 45 
adversary victory points: 12
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -147 

action type: take_action - action -1.0
Learning step: -7.755148410797119
desired expected reward: 4.4049391746521



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [10.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  3.] 
cards in discard: [ 0.  3.  1.  3.  3.  3. 11. 14.  0.  0. 11. 10.  6.  3.  0. 29. 16.  4.
 14. 11.  0.  3.  0. 15.  0.  8.  8.  8.  0.  3. 14.  3. 23. 10.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  3 11  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3
  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14  0  3] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 19. 29.  8.  0.  6.  2.  0.  9.  7.  5.  9.  5. 10.  8.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [ 8.  6. 11. 10.  6. 29.  8.  0.] 
adversary owned cards: [ 0 10  8 29  0  0  0  8  6 11  8  6  0] -> size -> 13 
adversary victory points: -2
player victory points: 12 


action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 14.] 
cards in discard: [ 0.  3.  1.  3.  3.  3. 11. 14.  0.  0. 11. 10.  6.  3.  0. 29. 16.  4.
 14. 11.  0.  3.  0. 15.  0.  8.  8.  8.  0.  3. 14.  3. 23. 10.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 29  3 11  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3
  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14  0  3] -> size -> 45 
action values: 2 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 19. 29.  8.  0.  6.  2.  0.  9.  7.  5.  9.  5. 10.  8.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [ 8.  6. 11. 10.  6. 29.  8.  0.] 
adversary owned cards: [ 0 10  8 29  0  0  0  8  6 11  8  6  0] -> size -> 13 
adversary victory points: -2
player victory points: 12 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 0.  3.  1.  3.  3.  3. 11. 14.  0.  0. 11. 10.  6.  3.  0. 29. 16.  4.
 14. 11.  0.  3.  0. 15.  0.  8.  8.  8.  0.  3. 14.  3. 23. 10.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 3 29  3 11  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3
  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14  0  3] -> size -> 45 
action values: 1 
buys: 0 
player value: 2 
card supply: [11. 26. 30. 19. 29.  8.  0.  6.  2.  0.  9.  7.  5.  9.  5. 10.  8.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 8.  6. 11. 10.  6. 29.  8.  0.  8.  0.] 
adversary owned cards: [ 0 10  8 29  0  0  0  8  6 11  8  6  0] -> size -> 13 
adversary victory points: -2
player victory points: 12 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 0.  3.  1.  3.  3.  3. 11. 14.  0.  0. 11. 10.  6.  3.  0. 29. 16.  4.
 14. 11.  0.  3.  0. 15.  0.  8.  8.  8.  0.  3. 14.  3. 23. 10.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 3 29  3 11  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3
  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14  0  3] -> size -> 45 
action values: 0 
buys: 1 
player value: 5 
card supply: [11. 26. 30. 19. 29.  8.  0.  6.  2.  0.  9.  7.  5.  9.  5. 10.  8.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 8.  6. 11. 10.  6. 29.  8.  0.  8.  0.] 
adversary owned cards: [ 0 10  8 29  0  0  0  8  6 11  8  6  0] -> size -> 13 
adversary victory points: -2
player victory points: 12 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 0.  3.  1.  3.  3.  3. 11. 14.  0.  0. 11. 10.  6.  3.  0. 29. 16.  4.
 14. 11.  0.  3.  0. 15.  0.  8.  8.  8.  0.  3. 14.  3. 23. 10.  3. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 3 29  3 11  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3
  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14  0  3 10] -> size -> 46 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 26. 30. 19. 29.  8.  0.  6.  2.  0.  9.  7.  5.  9.  4. 10.  8.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [ 8.  6. 11. 10.  6. 29.  8.  0.  8.  0.] 
adversary owned cards: [ 0 10  8 29  0  0  0  8  6 11  8  6  0] -> size -> 13 
adversary victory points: -2
player victory points: 12 





Player: 0 
cards in hand: [0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[2.5509114]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8.  6. 11. 10.  6. 29.  8.  0.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10  8 29  0  0  0  8  6 11  8  6  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 19. 29.  8.  0.  6.  2.  0.  9.  7.  5.  9.  4. 10.  8.] 
adversary cards in hand: [10. 11. 11.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29  3 11  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3
  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14  0  3 10] -> size -> 46 
adversary victory points: 12
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -147 

action type: discard_down_to_3_cards - action 1
Learning step: -7.887704372406006
desired expected reward: 4.014282703399658





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-1.6378478 ]
 [-1.1716033 ]
 [-1.3191487 ]
 [-0.64517945]
 [-1.2270155 ]
 [ 0.00342178]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8.  6. 11. 10.  6. 29.  8.  0.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10  8 29  0  0  0  8  6 11  8  6  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 26. 30. 19. 29.  8.  0.  6.  2.  0.  9.  7.  5.  9.  4. 10.  8.] 
adversary cards in hand: [10. 11. 11.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29  3 11  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3
  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14  0  3 10] -> size -> 46 
adversary victory points: 12
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -147 

action type: take_action - action -1.0
Learning step: -7.491471290588379
desired expected reward: -4.9405598640441895



buy possibilites: [-1] 
expected returns: [[54.93783]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8.  6. 11. 10.  6. 29.  8.  0.  8.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10  8 29  0  0  0  8  6 11  8  6  0 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 19. 29.  8.  0.  6.  1.  0.  9.  7.  5.  9.  4. 10.  8.] 
adversary cards in hand: [10. 11. 11.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29  3 11  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3
  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14  0  3 10] -> size -> 46 
adversary victory points: 12
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -140    0    0    0    0    0    0    0    0    0    0
   18    0] 
sum of rewards: -129 

action type: buy - action 11.0
Learning step: -5.1119513511657715
desired expected reward: -7.150907516479492






         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [10. 11. 11.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11. 29.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11.  1. 29.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  3 11  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3
  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14  0  3 10] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 19. 29.  8.  0.  6.  1.  0.  9.  7.  5.  9.  4. 10.  8.] 
adversary cards in hand: [0. 8. 8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 10  8 29  0  0  0  8  6 11  8  6  0 11] -> size -> 14 
adversary victory points: -2
player victory points: 12 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  1. 29.] 
cards in discard: [29.] 
cards in deck: 41 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 29  3 11  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3
  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14  0  3 10 29] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 19. 29.  8.  0.  6.  1.  0.  9.  6.  5.  9.  4. 10.  8.] 
adversary cards in hand: [0. 8. 8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 10  8 29  0  0  0  8  6 11  8  6  0 11] -> size -> 14 
adversary victory points: -2
player victory points: 12 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  1. 29.] 
cards in discard: [29.] 
cards in deck: 41 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 29  3 11  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3
  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14  0  3 10 29] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 26. 30. 19. 29.  8.  0.  6.  1.  0.  9.  6.  5.  9.  4. 10.  8.] 
adversary cards in hand: [0. 8. 8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 10  8 29  0  0  0  8  6 11  8  6  0 11] -> size -> 14 
adversary victory points: -2
player victory points: 12 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  1. 29.] 
cards in discard: [29.  0.] 
cards in deck: 41 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 29  3 11  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3
  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14  0  3 10 29  0] -> size -> 48 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 26. 30. 19. 29.  8.  0.  6.  1.  0.  9.  6.  5.  9.  4. 10.  8.] 
adversary cards in hand: [0. 8. 8. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 10  8 29  0  0  0  8  6 11  8  6  0 11] -> size -> 14 
adversary victory points: -2
player victory points: 12 





Player: 0 
cards in hand: [0. 8. 8. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[6.3842187]
 [4.272348 ]
 [4.272348 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 0. 6.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10  8 29  0  0  0  8  6 11  8  6  0 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 19. 29.  8.  0.  6.  1.  0.  9.  6.  5.  9.  4. 10.  8.] 
adversary cards in hand: [10.  3.  0. 16.  3.] 
adversary cards in discard: [29.  0. 11. 10. 11.  1. 29.] 
adversary owned cards: [ 3 29  3 11  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3
  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14  0  3 10 29  0] -> size -> 48 
adversary victory points: 12
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -147 

action type: buy - action -1
Learning step: -9.972902297973633
desired expected reward: 44.964927673339844



action possibilites: [-1] 
expected returns: [[39.170517]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 29  0  0  8 11  8  6  0 11] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 19. 29.  8.  0.  6.  1.  0.  9.  6.  5.  9.  4. 10.  8.] 
adversary cards in hand: [10.  3.  0. 16.  3.] 
adversary cards in discard: [29.  0. 11. 10. 11.  1. 29.] 
adversary owned cards: [ 3 29  3 11  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3
  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14  0  3 10 29  0] -> size -> 48 
adversary victory points: 12
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -130    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -116 

action type: trash_cards_n_from_hand - action 12
Learning step: -5.117023944854736
desired expected reward: -1.1498126983642578





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[34.217823]
 [38.81498 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 29  0  0  8 11  8  6  0 11] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 26. 30. 19. 29.  8.  0.  6.  1.  0.  9.  6.  5.  9.  4. 10.  8.] 
adversary cards in hand: [10.  3.  0. 16.  3.] 
adversary cards in discard: [29.  0. 11. 10. 11.  1. 29.] 
adversary owned cards: [ 3 29  3 11  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3
  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14  0  3 10 29  0] -> size -> 48 
adversary victory points: 12
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -130    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -116 

action type: take_action - action -1
Learning step: -6.917277812957764
desired expected reward: 32.253238677978516






         -------------------- Turn: 55 -------------------- 
Player: 1 
cards in hand: [10.  3.  0. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0. 16.  3.] 
cards in discard: [29.  0. 11. 10. 11.  1. 29.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  3 11  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3
  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14  0  3 10 29  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 19. 29.  8.  0.  6.  1.  0.  9.  6.  5.  9.  4. 10.  8.] 
adversary cards in hand: [ 0.  0. 11.  8. 11.] 
adversary cards in discard: [8.] 
adversary owned cards: [10 29  0  0  8 11  8  6  0 11] -> size -> 10 
adversary victory points: -1
player victory points: 12 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0. 16.  3.] 
cards in discard: [29.  0. 11. 10. 11.  1. 29.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  3 11  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3
  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14  0  3 10 29  0] -> size -> 48 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 26. 30. 19. 29.  8.  0.  6.  1.  0.  9.  6.  5.  9.  4. 10.  8.] 
adversary cards in hand: [ 0.  0. 11.  8. 11.] 
adversary cards in discard: [8.] 
adversary owned cards: [10 29  0  0  8 11  8  6  0 11] -> size -> 10 
adversary victory points: -1
player victory points: 12 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  0. 11.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 11.] 
expected returns: [[18.206114]
 [15.907112]
 [13.834215]
 [15.907112]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  8. 11.] 
cards in discard: [8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10 29  0  0  8 11  8  6  0 11] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 19. 29.  8.  0.  6.  1.  0.  9.  6.  5.  9.  4. 10.  8.] 
adversary cards in hand: [ 0.  3.  0. 10.  8.] 
adversary cards in discard: [29.  0. 11. 10. 11.  1. 29. 10.  3.  0. 16.  3.] 
adversary owned cards: [ 3 29  3 11  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3
  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14  0  3 10 29  0] -> size -> 48 
adversary victory points: 12
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -136 

action type: buy - action -1.0
Learning step: -8.362418174743652
desired expected reward: 30.452560424804688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[10.981869]
 [12.240723]
 [16.2127  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  8. 11.] 
cards in discard: [8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10 29  0  0  8 11  8  6  0 11] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 26. 30. 19. 29.  8.  0.  6.  1.  0.  9.  6.  5.  9.  4. 10.  8.] 
adversary cards in hand: [ 0.  3.  0. 10.  8.] 
adversary cards in discard: [29.  0. 11. 10. 11.  1. 29. 10.  3.  0. 16.  3.] 
adversary owned cards: [ 3 29  3 11  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3
  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14  0  3 10 29  0] -> size -> 48 
adversary victory points: 12
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -136 

action type: take_action - action -1.0
Learning step: -7.388345241546631
desired expected reward: 10.817777633666992



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 56 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10.  8.] 
cards in discard: [29.  0. 11. 10. 11.  1. 29. 10.  3.  0. 16.  3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  3 11  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3
  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14  0  3 10 29  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 19. 29.  8.  0.  6.  1.  0.  9.  6.  5.  9.  4. 10.  8.] 
adversary cards in hand: [ 0.  0.  6. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10 29  0  0  8 11  8  6  0 11] -> size -> 10 
adversary victory points: -1
player victory points: 12 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8. 0.] 
cards in discard: [29.  0. 11. 10. 11.  1. 29. 10.  3.  0. 16.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 29  3 11  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3
  1 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14  0  3 10 29  0] -> size -> 48 
action values: 2 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 19. 29.  8.  0.  6.  1.  0.  9.  6.  5.  9.  4. 10.  8.] 
adversary cards in hand: [ 0.  0.  6. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10 29  0  0  8 11  8  6  0 11] -> size -> 10 
adversary victory points: -1
player victory points: 12 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [29.  0. 11. 10. 11.  1. 29. 10.  3.  0. 16.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [29  3 11  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3  1
 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14  0  3 10 29  0] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 19. 29.  8.  0.  6.  1.  0.  9.  6.  5.  9.  4. 10.  8.] 
adversary cards in hand: [ 0.  0.  6. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10 29  0  0  8 11  8  6  0 11] -> size -> 10 
adversary victory points: -1
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [29.  0. 11. 10. 11.  1. 29. 10.  3.  0. 16.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [29  3 11  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3  1
 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14  0  3 10 29  0] -> size -> 47 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 26. 30. 19. 29.  8.  0.  6.  1.  0.  9.  6.  5.  9.  4. 10.  8.] 
adversary cards in hand: [ 0.  0.  6. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10 29  0  0  8 11  8  6  0 11] -> size -> 10 
adversary victory points: -1
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [29.  0. 11. 10. 11.  1. 29. 10.  3.  0. 16.  3.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [29  3 11  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3  1
 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14  0  3 10 29  0  3] -> size -> 48 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 26. 30. 18. 29.  8.  0.  6.  1.  0.  9.  6.  5.  9.  4. 10.  8.] 
adversary cards in hand: [ 0.  0.  6. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10 29  0  0  8 11  8  6  0 11] -> size -> 10 
adversary victory points: -1
player victory points: 12 





Player: 0 
cards in hand: [ 0.  0.  6. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[9.377998 ]
 [8.421604 ]
 [6.9084363]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6. 29. 10.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10 29  0  0  8 11  8  6  0 11] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 18. 29.  8.  0.  6.  1.  0.  9.  6.  5.  9.  4. 10.  8.] 
adversary cards in hand: [ 8.  3.  3. 23.  0.] 
adversary cards in discard: [29.  0. 11. 10. 11.  1. 29. 10.  3.  0. 16.  3.  3. 10.  8.  0.  0.  0.] 
adversary owned cards: [29  3 11  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3  1
 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14  0  3 10 29  0  3] -> size -> 48 
adversary victory points: 12
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -136 

action type: buy - action -1.0
Learning step: -7.43530797958374
desired expected reward: 8.777397155761719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[4.0783157]
 [5.084211 ]
 [7.7530313]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6. 29. 10.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10 29  0  0  8 11  8  6  0 11] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 26. 30. 18. 29.  8.  0.  6.  1.  0.  9.  6.  5.  9.  4. 10.  8.] 
adversary cards in hand: [ 8.  3.  3. 23.  0.] 
adversary cards in discard: [29.  0. 11. 10. 11.  1. 29. 10.  3.  0. 16.  3.  3. 10.  8.  0.  0.  0.] 
adversary owned cards: [29  3 11  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3  1
 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14  0  3 10 29  0  3] -> size -> 48 
adversary victory points: 12
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -136 

action type: take_action - action -1.0
Learning step: -7.080120086669922
desired expected reward: 1.4207630157470703



buy possibilites: [-1] 
expected returns: [[33.710854]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6. 29. 10.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10 29  0  0  8 11  8  6  0 11  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 26. 30. 18. 29.  8.  0.  6.  1.  0.  9.  6.  5.  9.  4. 10.  8.] 
adversary cards in hand: [ 8.  3.  3. 23.  0.] 
adversary cards in discard: [29.  0. 11. 10. 11.  1. 29. 10.  3.  0. 16.  3.  3. 10.  8.  0.  0.  0.] 
adversary owned cards: [29  3 11  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3  1
 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14  0  3 10 29  0  3] -> size -> 48 
adversary victory points: 12
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1. -130.    0.    0.    0.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -166.0 

action type: buy - action 0.0
Learning step: -7.745420932769775
desired expected reward: -3.667107105255127






         -------------------- Turn: 57 -------------------- 
Player: 1 
cards in hand: [ 8.  3.  3. 23.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  3. 23.  0.] 
cards in discard: [29.  0. 11. 10. 11.  1. 29. 10.  3.  0. 16.  3.  3. 10.  8.  0.  0.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [29  3 11  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3  1
 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14  0  3 10 29  0  3] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 18. 29.  8.  0.  6.  1.  0.  9.  6.  5.  9.  4. 10.  8.] 
adversary cards in hand: [ 0.  8. 11.  8. 11.] 
adversary cards in discard: [ 0.  0.  0.  6. 29. 10.] 
adversary owned cards: [10 29  0  0  8 11  8  6  0 11  0] -> size -> 11 
adversary victory points: -1
player victory points: 12 


action possibilites: [-1.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  3.  0. 14.] 
cards in discard: [29.  0. 11. 10. 11.  1. 29. 10.  3.  0. 16.  3.  3. 10.  8.  0.  0.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [23.] 
owned cards: [29  3 11  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3  1
 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14  0  3 10 29  0  3] -> size -> 48 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 9. 26. 30. 18. 29.  8.  0.  6.  1.  0.  9.  6.  5.  9.  4. 10.  8.] 
adversary cards in hand: [ 0.  8. 11.  8. 11.] 
adversary cards in discard: [ 0.  0.  0.  6. 29. 10.] 
adversary owned cards: [10 29  0  0  8 11  8  6  0 11  0] -> size -> 11 
adversary victory points: -1
player victory points: 12 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 0.] 
cards in discard: [29.  0. 11. 10. 11.  1. 29. 10.  3.  0. 16.  3.  3. 10.  8.  0.  0.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [23. 14.] 
owned cards: [29  3 11  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3  1
 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14  0  3 10 29  0  3] -> size -> 48 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 26. 30. 18. 29.  8.  0.  6.  1.  0.  9.  6.  5.  9.  4. 10.  8.] 
adversary cards in hand: [ 0. 11. 11.] 
adversary cards in discard: [ 0.  0.  0.  6. 29. 10.  8.  8.] 
adversary owned cards: [10 29  0  0  8 11  8  6  0 11  0] -> size -> 11 
adversary victory points: -1
player victory points: 12 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 0.] 
cards in discard: [29.  0. 11. 10. 11.  1. 29. 10.  3.  0. 16.  3.  3. 10.  8.  0.  0.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [23. 14.] 
owned cards: [29  3 11  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3  1
 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14  0  3 10 29  0  3] -> size -> 48 
action values: 0 
buys: 2 
player value: 4 
card supply: [ 9. 26. 30. 18. 29.  8.  0.  6.  1.  0.  9.  6.  5.  9.  4. 10.  8.] 
adversary cards in hand: [ 0. 11. 11.] 
adversary cards in discard: [ 0.  0.  0.  6. 29. 10.  8.  8.] 
adversary owned cards: [10 29  0  0  8 11  8  6  0 11  0] -> size -> 11 
adversary victory points: -1
player victory points: 12 





Player: 0 
cards in hand: [ 0. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[-2.0389557]
 [-2.0389557]
 [-2.0389557]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.] 
cards in discard: [ 0.  0.  0.  6. 29. 10.  8.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10 29  0  0  8 11  8  6  0 11  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 18. 29.  8.  0.  6.  1.  0.  9.  6.  5.  9.  4. 10.  8.] 
adversary cards in hand: [11.  8.  0. 15.  6.] 
adversary cards in discard: [29.  0. 11. 10. 11.  1. 29. 10.  3.  0. 16.  3.  3. 10.  8.  0.  0.  0.
 23. 14.  8.  3.  3.  0.] 
adversary owned cards: [29  3 11  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3  1
 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14  0  3 10 29  0  3] -> size -> 48 
adversary victory points: 12
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -136 

action type: discard_down_to_3_cards - action 0
Learning step: -6.745235443115234
desired expected reward: -8.758054733276367





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-2.0389557]
 [-2.0389557]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 11.] 
cards in discard: [ 0.  0.  0.  6. 29. 10.  8.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10 29  0  0  8 11  8  6  0 11  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 26. 30. 18. 29.  8.  0.  6.  1.  0.  9.  6.  5.  9.  4. 10.  8.] 
adversary cards in hand: [11.  8.  0. 15.  6.] 
adversary cards in discard: [29.  0. 11. 10. 11.  1. 29. 10.  3.  0. 16.  3.  3. 10.  8.  0.  0.  0.
 23. 14.  8.  3.  3.  0.] 
adversary owned cards: [29  3 11  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3  1
 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14  0  3 10 29  0  3] -> size -> 48 
adversary victory points: 12
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -136 

action type: take_action - action -1.0
Learning step: -6.7439284324646
desired expected reward: -8.78288459777832



buy possibilites: [-1] 
expected returns: [[10.330093]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 11.] 
cards in discard: [ 0.  0.  0.  6. 29. 10.  8.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10 29  0  0  8 11  8  6  0 11  0  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 26. 30. 18. 29.  8.  0.  6.  1.  0.  9.  6.  5.  9.  4. 10.  8.] 
adversary cards in hand: [11.  8.  0. 15.  6.] 
adversary cards in discard: [29.  0. 11. 10. 11.  1. 29. 10.  3.  0. 16.  3.  3. 10.  8.  0.  0.  0.
 23. 14.  8.  3.  3.  0.] 
adversary owned cards: [29  3 11  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3  1
 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14  0  3 10 29  0  3] -> size -> 48 
adversary victory points: 12
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1. -130.    0.    0.    0.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -166.0 

action type: buy - action 0.0
Learning step: -7.965625286102295
desired expected reward: -10.004581451416016






         -------------------- Turn: 58 -------------------- 
Player: 1 
cards in hand: [11.  8.  0. 15.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0. 15.  6.] 
cards in discard: [29.  0. 11. 10. 11.  1. 29. 10.  3.  0. 16.  3.  3. 10.  8.  0.  0.  0.
 23. 14.  8.  3.  3.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [29  3 11  0 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3  1
 10  3 11  3  0 11  3  8 14 11  0  0 14  6  0 11  0 14  0  3 10 29  0  3] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 18. 29.  8.  0.  6.  1.  0.  9.  6.  5.  9.  4. 10.  8.] 
adversary cards in hand: [10.  0.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10 29  0  0  8 11  8  6  0 11  0  0] -> size -> 12 
adversary victory points: -1
player victory points: 12 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.] 
cards in discard: [29.  0. 11. 10. 11.  1. 29. 10.  3.  0. 16.  3.  3. 10.  8.  0.  0.  0.
 23. 14.  8.  3.  3.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  3 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3  1 10  3
 11  3  0 11  3  8 14 11  0  0 14  0 11  0 14  0  3 10 29  0  3] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 18. 29.  8.  0.  6.  1.  0.  9.  6.  5.  9.  4. 10.  8.] 
adversary cards in hand: [10.  0.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10 29  0  0  8 11  8  6  0 11  0  0] -> size -> 12 
adversary victory points: -1
player victory points: 13 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [29.  0. 11. 10. 11.  1. 29. 10.  3.  0. 16.  3.  3. 10.  8.  0.  0.  0.
 23. 14.  8.  3.  3.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  3 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3  1 10  3
 11  3  0 11  3  8 14 11  0  0 14  0 11  0 14  0  3 10 29  0  3] -> size -> 45 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 26. 30. 18. 29.  8.  0.  6.  1.  0.  9.  6.  5.  9.  4. 10.  8.] 
adversary cards in hand: [10.  0.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10 29  0  0  8 11  8  6  0 11  0  0] -> size -> 12 
adversary victory points: -1
player victory points: 13 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [29.  0. 11. 10. 11.  1. 29. 10.  3.  0. 16.  3.  3. 10.  8.  0.  0.  0.
 23. 14.  8.  3.  3.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  3 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3  1 10  3
 11  3  0 11  3  8 14 11  0  0 14  0 11  0 14  0  3 10 29  0  3  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 18. 29.  8.  0.  6.  1.  0.  9.  6.  5.  9.  4. 10.  8.] 
adversary cards in hand: [10.  0.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10 29  0  0  8 11  8  6  0 11  0  0] -> size -> 12 
adversary victory points: -1
player victory points: 13 





Player: 0 
cards in hand: [10.  0.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[22.117985]
 [18.695738]
 [19.032486]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [10 29  0  0  8 11  8  6  0 11  0  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 18. 29.  8.  0.  6.  1.  0.  9.  6.  5.  9.  4. 10.  8.] 
adversary cards in hand: [ 0.  3.  3. 14. 10.] 
adversary cards in discard: [29.  0. 11. 10. 11.  1. 29. 10.  3.  0. 16.  3.  3. 10.  8.  0.  0.  0.
 23. 14.  8.  3.  3.  0.  0.  8. 15.] 
adversary owned cards: [29  3 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3  1 10  3
 11  3  0 11  3  8 14 11  0  0 14  0 11  0 14  0  3 10 29  0  3  0] -> size -> 46 
adversary victory points: 13
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -146 

action type: buy - action -1
Learning step: -7.3637847900390625
desired expected reward: 2.96630859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[15.966013]
 [17.682552]
 [17.351614]
 [19.421618]
 [17.606176]
 [21.028429]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [10 29  0  0  8 11  8  6  0 11  0  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 26. 30. 18. 29.  8.  0.  6.  1.  0.  9.  6.  5.  9.  4. 10.  8.] 
adversary cards in hand: [ 0.  3.  3. 14. 10.] 
adversary cards in discard: [29.  0. 11. 10. 11.  1. 29. 10.  3.  0. 16.  3.  3. 10.  8.  0.  0.  0.
 23. 14.  8.  3.  3.  0.  0.  8. 15.] 
adversary owned cards: [29  3 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3  1 10  3
 11  3  0 11  3  8 14 11  0  0 14  0 11  0 14  0  3 10 29  0  3  0] -> size -> 46 
adversary victory points: 13
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -146 

action type: take_action - action -1.0
Learning step: -7.940019130706787
desired expected reward: 13.526769638061523



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 59 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  3. 14. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 14. 10.] 
cards in discard: [29.  0. 11. 10. 11.  1. 29. 10.  3.  0. 16.  3.  3. 10.  8.  0.  0.  0.
 23. 14.  8.  3.  3.  0.  0.  8. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [29  3 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3  1 10  3
 11  3  0 11  3  8 14 11  0  0 14  0 11  0 14  0  3 10 29  0  3  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 18. 29.  8.  0.  6.  1.  0.  9.  6.  5.  9.  4. 10.  8.] 
adversary cards in hand: [ 8.  0.  0. 29. 11.] 
adversary cards in discard: [10.  0.  0.  0.  8.] 
adversary owned cards: [10 29  0  0  8 11  8  6  0 11  0  0] -> size -> 12 
adversary victory points: -1
player victory points: 13 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 10.] 
cards in discard: [29.  0. 11. 10. 11.  1. 29. 10.  3.  0. 16.  3.  3. 10.  8.  0.  0.  0.
 23. 14.  8.  3.  3.  0.  0.  8. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [29  3 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3  1 10  3
 11  3  0 11  3  8 14 11  0  0 14  0 11  0 14  0  3 10 29  0  3  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 7. 26. 30. 18. 29.  8.  0.  6.  1.  0.  9.  6.  5.  9.  4. 10.  8.] 
adversary cards in hand: [ 8.  0. 11.] 
adversary cards in discard: [10.  0.  0.  0.  8.  0. 29.] 
adversary owned cards: [10 29  0  0  8 11  8  6  0 11  0  0] -> size -> 12 
adversary victory points: -1
player victory points: 13 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 10.] 
cards in discard: [29.  0. 11. 10. 11.  1. 29. 10.  3.  0. 16.  3.  3. 10.  8.  0.  0.  0.
 23. 14.  8.  3.  3.  0.  0.  8. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [29  3 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3  1 10  3
 11  3  0 11  3  8 14 11  0  0 14  0 11  0 14  0  3 10 29  0  3  0] -> size -> 46 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 26. 30. 18. 29.  8.  0.  6.  1.  0.  9.  6.  5.  9.  4. 10.  8.] 
adversary cards in hand: [ 8.  0. 11.] 
adversary cards in discard: [10.  0.  0.  0.  8.  0. 29.] 
adversary owned cards: [10 29  0  0  8 11  8  6  0 11  0  0] -> size -> 12 
adversary victory points: -1
player victory points: 13 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 10.] 
cards in discard: [29.  0. 11. 10. 11.  1. 29. 10.  3.  0. 16.  3.  3. 10.  8.  0.  0.  0.
 23. 14.  8.  3.  3.  0.  0.  8. 15.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [29  3 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3  1 10  3
 11  3  0 11  3  8 14 11  0  0 14  0 11  0 14  0  3 10 29  0  3  0  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30. 18. 29.  8.  0.  6.  1.  0.  9.  6.  5.  9.  4. 10.  8.] 
adversary cards in hand: [ 8.  0. 11.] 
adversary cards in discard: [10.  0.  0.  0.  8.  0. 29.] 
adversary owned cards: [10 29  0  0  8 11  8  6  0 11  0  0] -> size -> 12 
adversary victory points: -1
player victory points: 13 





Player: 0 
cards in hand: [ 8.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[-0.9621599]
 [-2.0485938]
 [-2.0485938]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.] 
cards in discard: [10.  0.  0.  0.  8.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10 29  0  0  8 11  8  6  0 11  0  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30. 18. 29.  8.  0.  6.  1.  0.  9.  6.  5.  9.  4. 10.  8.] 
adversary cards in hand: [ 4.  0.  0. 14.  3.] 
adversary cards in discard: [29.  0. 11. 10. 11.  1. 29. 10.  3.  0. 16.  3.  3. 10.  8.  0.  0.  0.
 23. 14.  8.  3.  3.  0.  0.  8. 15.  1. 14.  0.  3.  3. 10.] 
adversary owned cards: [29  3 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3  1 10  3
 11  3  0 11  3  8 14 11  0  0 14  0 11  0 14  0  3 10 29  0  3  0  1] -> size -> 47 
adversary victory points: 13
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -146 

action type: discard_down_to_3_cards - action 1
Learning step: -7.240625858306885
desired expected reward: -9.063304901123047





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-2.0485938 ]
 [-0.40975678]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11.] 
cards in discard: [10.  0.  0.  0.  8.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10 29  0  0  8 11  8  6  0 11  0  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 25. 30. 18. 29.  8.  0.  6.  1.  0.  9.  6.  5.  9.  4. 10.  8.] 
adversary cards in hand: [ 4.  0.  0. 14.  3.] 
adversary cards in discard: [29.  0. 11. 10. 11.  1. 29. 10.  3.  0. 16.  3.  3. 10.  8.  0.  0.  0.
 23. 14.  8.  3.  3.  0.  0.  8. 15.  1. 14.  0.  3.  3. 10.] 
adversary owned cards: [29  3 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3  1 10  3
 11  3  0 11  3  8 14 11  0  0 14  0 11  0 14  0  3 10 29  0  3  0  1] -> size -> 47 
adversary victory points: 13
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -146 

action type: take_action - action -1.0
Learning step: -7.272550106048584
desired expected reward: -8.234722137451172



buy possibilites: [-1] 
expected returns: [[-0.98705804]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11.] 
cards in discard: [10.  0.  0.  0.  8.  0. 29.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10 29  0  0  8 11  8  6  0 11  0  0  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 25. 30. 18. 29.  8.  0.  6.  1.  0.  9.  6.  5.  9.  4. 10.  8.] 
adversary cards in hand: [ 4.  0.  0. 14.  3.] 
adversary cards in discard: [29.  0. 11. 10. 11.  1. 29. 10.  3.  0. 16.  3.  3. 10.  8.  0.  0.  0.
 23. 14.  8.  3.  3.  0.  0.  8. 15.  1. 14.  0.  3.  3. 10.] 
adversary owned cards: [29  3 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3  1 10  3
 11  3  0 11  3  8 14 11  0  0 14  0 11  0 14  0  3 10 29  0  3  0  1] -> size -> 47 
adversary victory points: 13
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1. -140.    0.    0.    0.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -176.0 

action type: buy - action 0.0
Learning step: -8.719779014587402
desired expected reward: -10.768372535705566






         -------------------- Turn: 60 -------------------- 
Player: 1 
cards in hand: [ 4.  0.  0. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4.  0.  0. 14.  3.] 
cards in discard: [29.  0. 11. 10. 11.  1. 29. 10.  3.  0. 16.  3.  3. 10.  8.  0.  0.  0.
 23. 14.  8.  3.  3.  0.  0.  8. 15.  1. 14.  0.  3.  3. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [29  3 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3  1 10  3
 11  3  0 11  3  8 14 11  0  0 14  0 11  0 14  0  3 10 29  0  3  0  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 18. 29.  8.  0.  6.  1.  0.  9.  6.  5.  9.  4. 10.  8.] 
adversary cards in hand: [11.  8.  0. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [10 29  0  0  8 11  8  6  0 11  0  0  0] -> size -> 13 
adversary victory points: -1
player victory points: 13 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4.  0.  0. 14.  3.] 
cards in discard: [29.  0. 11. 10. 11.  1. 29. 10.  3.  0. 16.  3.  3. 10.  8.  0.  0.  0.
 23. 14.  8.  3.  3.  0.  0.  8. 15.  1. 14.  0.  3.  3. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [29  3 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3  1 10  3
 11  3  0 11  3  8 14 11  0  0 14  0 11  0 14  0  3 10 29  0  3  0  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 25. 30. 18. 29.  8.  0.  6.  1.  0.  9.  6.  5.  9.  4. 10.  8.] 
adversary cards in hand: [11.  8.  0. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [10 29  0  0  8 11  8  6  0 11  0  0  0] -> size -> 13 
adversary victory points: -1
player victory points: 13 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4.  0.  0. 14.  3.] 
cards in discard: [29.  0. 11. 10. 11.  1. 29. 10.  3.  0. 16.  3.  3. 10.  8.  0.  0.  0.
 23. 14.  8.  3.  3.  0.  0.  8. 15.  1. 14.  0.  3.  3. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [29  3 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3  1 10  3
 11  3  0 11  3  8 14 11  0  0 14  0 11  0 14  0  3 10 29  0  3  0  1  0] -> size -> 48 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 5. 25. 30. 18. 29.  8.  0.  6.  1.  0.  9.  6.  5.  9.  4. 10.  8.] 
adversary cards in hand: [11.  8.  0. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [10 29  0  0  8 11  8  6  0 11  0  0  0] -> size -> 13 
adversary victory points: -1
player victory points: 13 





Player: 0 
cards in hand: [11.  8.  0. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 11.] 
expected returns: [[22.564983]
 [21.513924]
 [20.66014 ]
 [21.513924]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0. 11.  6.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [10 29  0  0  8 11  8  6  0 11  0  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 25. 30. 18. 29.  8.  0.  6.  1.  0.  9.  6.  5.  9.  4. 10.  8.] 
adversary cards in hand: [ 3.  0. 29.  0. 11.] 
adversary cards in discard: [29.  0. 11. 10. 11.  1. 29. 10.  3.  0. 16.  3.  3. 10.  8.  0.  0.  0.
 23. 14.  8.  3.  3.  0.  0.  8. 15.  1. 14.  0.  3.  3. 10.  0.  4.  0.
  0. 14.  3.] 
adversary owned cards: [29  3 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3  1 10  3
 11  3  0 11  3  8 14 11  0  0 14  0 11  0 14  0  3 10 29  0  3  0  1  0] -> size -> 48 
adversary victory points: 13
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -146 

action type: buy - action -1
Learning step: -6.7569193840026855
desired expected reward: -7.7439775466918945





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[19.343534]
 [21.8069  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  0. 11.  6.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [10 29  0  0  8 11  8  6  0 11  0  0  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 25. 30. 18. 29.  8.  0.  6.  1.  0.  9.  6.  5.  9.  4. 10.  8.] 
adversary cards in hand: [ 3.  0. 29.  0. 11.] 
adversary cards in discard: [29.  0. 11. 10. 11.  1. 29. 10.  3.  0. 16.  3.  3. 10.  8.  0.  0.  0.
 23. 14.  8.  3.  3.  0.  0.  8. 15.  1. 14.  0.  3.  3. 10.  0.  4.  0.
  0. 14.  3.] 
adversary owned cards: [29  3 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3  1 10  3
 11  3  0 11  3  8 14 11  0  0 14  0 11  0 14  0  3 10 29  0  3  0  1  0] -> size -> 48 
adversary victory points: 13
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -146 

action type: take_action - action -1.0
Learning step: -7.954789161682129
desired expected reward: 14.61019229888916



buy possibilites: [-1] 
expected returns: [[-2.0485938]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  0. 11.  6.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [10 29  0  0  8 11  8  6  0 11  0  0  0  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 25. 30. 18. 29.  8.  0.  6.  1.  0.  9.  6.  5.  9.  4. 10.  8.] 
adversary cards in hand: [ 3.  0. 29.  0. 11.] 
adversary cards in discard: [29.  0. 11. 10. 11.  1. 29. 10.  3.  0. 16.  3.  3. 10.  8.  0.  0.  0.
 23. 14.  8.  3.  3.  0.  0.  8. 15.  1. 14.  0.  3.  3. 10.  0.  4.  0.
  0. 14.  3.] 
adversary owned cards: [29  3 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3  1 10  3
 11  3  0 11  3  8 14 11  0  0 14  0 11  0 14  0  3 10 29  0  3  0  1  0] -> size -> 48 
adversary victory points: 13
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1. -140.    0.    0.    0.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -176.0 

action type: buy - action 0.0
Learning step: -9.81326961517334
desired expected reward: 9.530266761779785






         -------------------- Turn: 61 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 29.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  0. 11.] 
cards in discard: [29.  0. 11. 10. 11.  1. 29. 10.  3.  0. 16.  3.  3. 10.  8.  0.  0.  0.
 23. 14.  8.  3.  3.  0.  0.  8. 15.  1. 14.  0.  3.  3. 10.  0.  4.  0.
  0. 14.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [29  3 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3  1 10  3
 11  3  0 11  3  8 14 11  0  0 14  0 11  0 14  0  3 10 29  0  3  0  1  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 18. 29.  8.  0.  6.  1.  0.  9.  6.  5.  9.  4. 10.  8.] 
adversary cards in hand: [10.  0.  0.  0.  8.] 
adversary cards in discard: [ 0. 11.  8.  0. 11.  6.] 
adversary owned cards: [10 29  0  0  8 11  8  6  0 11  0  0  0  0] -> size -> 14 
adversary victory points: -1
player victory points: 13 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  0.] 
cards in discard: [29.  0. 11. 10. 11.  1. 29. 10.  3.  0. 16.  3.  3. 10.  8.  0.  0.  0.
 23. 14.  8.  3.  3.  0.  0.  8. 15.  1. 14.  0.  3.  3. 10.  0.  4.  0.
  0. 14.  3. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [29  3 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3  1 10  3
 11  3  0 11  3  8 14 11  0  0 14  0 11  0 14  0  3 10 29  0  3  0  1  0
 14] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 18. 29.  8.  0.  6.  1.  0.  9.  6.  4.  9.  4. 10.  8.] 
adversary cards in hand: [10.  0.  0.  0.  8.] 
adversary cards in discard: [ 0. 11.  8.  0. 11.  6.] 
adversary owned cards: [10 29  0  0  8 11  8  6  0 11  0  0  0  0] -> size -> 14 
adversary victory points: -1
player victory points: 13 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  0.] 
cards in discard: [29.  0. 11. 10. 11.  1. 29. 10.  3.  0. 16.  3.  3. 10.  8.  0.  0.  0.
 23. 14.  8.  3.  3.  0.  0.  8. 15.  1. 14.  0.  3.  3. 10.  0.  4.  0.
  0. 14.  3. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [29  3 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3  1 10  3
 11  3  0 11  3  8 14 11  0  0 14  0 11  0 14  0  3 10 29  0  3  0  1  0
 14] -> size -> 49 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 25. 30. 18. 29.  8.  0.  6.  1.  0.  9.  6.  4.  9.  4. 10.  8.] 
adversary cards in hand: [10.  0.  0.  0.  8.] 
adversary cards in discard: [ 0. 11.  8.  0. 11.  6.] 
adversary owned cards: [10 29  0  0  8 11  8  6  0 11  0  0  0  0] -> size -> 14 
adversary victory points: -1
player victory points: 13 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  0.] 
cards in discard: [29.  0. 11. 10. 11.  1. 29. 10.  3.  0. 16.  3.  3. 10.  8.  0.  0.  0.
 23. 14.  8.  3.  3.  0.  0.  8. 15.  1. 14.  0.  3.  3. 10.  0.  4.  0.
  0. 14.  3. 14.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [29  3 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3  1 10  3
 11  3  0 11  3  8 14 11  0  0 14  0 11  0 14  0  3 10 29  0  3  0  1  0
 14  3] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 17. 29.  8.  0.  6.  1.  0.  9.  6.  4.  9.  4. 10.  8.] 
adversary cards in hand: [10.  0.  0.  0.  8.] 
adversary cards in discard: [ 0. 11.  8.  0. 11.  6.] 
adversary owned cards: [10 29  0  0  8 11  8  6  0 11  0  0  0  0] -> size -> 14 
adversary victory points: -1
player victory points: 14 





Player: 0 
cards in hand: [10.  0.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[34.93544 ]
 [30.861862]
 [31.156578]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  8.] 
cards in discard: [ 0. 11.  8.  0. 11.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [10 29  0  0  8 11  8  6  0 11  0  0  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 17. 29.  8.  0.  6.  1.  0.  9.  6.  4.  9.  4. 10.  8.] 
adversary cards in hand: [10.  3. 14.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [29  3 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3  1 10  3
 11  3  0 11  3  8 14 11  0  0 14  0 11  0 14  0  3 10 29  0  3  0  1  0
 14  3] -> size -> 50 
adversary victory points: 14
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -156 

action type: buy - action -1
Learning step: -6.948062896728516
desired expected reward: -8.99665641784668





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[30.52509 ]
 [32.45928 ]
 [32.17619 ]
 [34.560364]
 [32.456142]
 [36.529724]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  8.] 
cards in discard: [ 0. 11.  8.  0. 11.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [10 29  0  0  8 11  8  6  0 11  0  0  0  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 25. 30. 17. 29.  8.  0.  6.  1.  0.  9.  6.  4.  9.  4. 10.  8.] 
adversary cards in hand: [10.  3. 14.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [29  3 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3  1 10  3
 11  3  0 11  3  8 14 11  0  0 14  0 11  0 14  0  3 10 29  0  3  0  1  0
 14  3] -> size -> 50 
adversary victory points: 14
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -156 

action type: take_action - action -1.0
Learning step: -8.772485733032227
desired expected reward: 26.162973403930664



Player 1 won the game! 



Player 0 bought cards:
Copper: 9 
Silver: 1 
Gold: 0 
Estate: 2 
Duchy: 0 
Province: 0 
Curse: 9 

Remodel: 2 
Workshop: 3 
Chapel: 3 
Witch: 0 
Poacher: 0 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 1 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [10.  0.  0.  0.  8.] 
cards in discard: [ 0. 11.  8.  0. 11.  6. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [10 29  0  0  8 11  8  6  0 11  0  0  0  0 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 17. 29.  8.  0.  6.  0.  0.  9.  6.  4.  9.  4. 10.  8.] 
adversary cards in hand: [10.  3. 14.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [29  3 15 23 29  0 10  0 10 14  3 16  4  0  0  3  1  3  8  8  3  1 10  3
 11  3  0 11  3  8 14 11  0  0 14  0 11  0 14  0  3 10 29  0  3  0  1  0
 14  3] -> size -> 50 
adversary victory points: 14
player victory points: -1 

Reward from previous game state: 
[  -5 -500   -1 -150    0    0    0    0    0    0    0    0    0    0
    9    0] 
sum of rewards: -647 

action type: buy - action 11.0
Learning step: -34.07801818847656
desired expected reward: 0.4823646545410156



