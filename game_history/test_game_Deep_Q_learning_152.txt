 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[30.424751]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -330        0        0        0        0
        0        0        0     -210        0        0        0        0] 
sum of rewards: -3000545 

action type: buy - action 0.0
Learning step: -120018.5234375
desired expected reward: -120100.2734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 23.701431  ]
 [ 41.222763  ]
 [ 34.508118  ]
 [-17.62734   ]
 [ 44.031887  ]
 [ 43.443935  ]
 [ 32.432392  ]
 [ 48.7821    ]
 [ -0.19719887]
 [ 38.02504   ]
 [ 27.44545   ]
 [ 30.685349  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 30.388652801513672



buy possibilites: [-1] 
expected returns: [[42.374256]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 48.78208923339844






Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[23.4333]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 42.3742561340332





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 17.064308]
 [ 34.73212 ]
 [ 27.859547]
 [-29.254642]
 [ 36.609184]
 [ 25.774181]
 [ 31.700615]
 [ 22.956284]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 22.22168731689453



buy possibilites: [-1] 
expected returns: [[27.105766]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [29.  0.  0.  0.  0.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 36.609169006347656






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  0.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  0.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  0.  0.  3.  3.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[36.96909 ]
 [56.126045]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 27.10576629638672



action possibilites: [-1.] 
expected returns: [[13.460666]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 55.71966552734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[  7.214452 ]
 [ 25.218563 ]
 [  6.7961473]
 [ 18.25037  ]
 [ -9.8788395]
 [-32.703033 ]
 [ 27.904408 ]
 [ 27.257954 ]
 [ 15.841399 ]
 [ 38.171093 ]
 [ 32.910553 ]
 [-16.066727 ]
 [ 20.515842 ]
 [ 21.873665 ]
 [ -3.6988206]
 [ 11.149432 ]
 [ 14.282754 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 13.460665702819824



buy possibilites: [-1] 
expected returns: [[23.085201]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 77.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 38.171085357666016






Player: 1 
cards in hand: [3. 0. 0. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 1. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [25. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [25. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 3.] 
cards in discard: [14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 14] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [25. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[27.79065]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [25. 29.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  0.] 
adversary cards in discard: [14.  3.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 14] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 23.085201263427734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[24.631874]
 [34.12036 ]
 [-8.994317]
 [32.3841  ]
 [29.16299 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [25. 29.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  0.] 
adversary cards in discard: [14.  3.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 14] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 28.972999572753906



buy possibilites: [-1] 
expected returns: [[7.8663588]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [25. 29.  0.  0.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  0.] 
adversary cards in discard: [14.  3.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 14] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0 16  0] 
sum of rewards: 41 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 34.12035369873047






Player: 1 
cards in hand: [ 0.  0.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.  0.] 
cards in discard: [14.  3.  0.  0.  1.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 14] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  8. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [14.  3.  0.  0.  1.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 14  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  8. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3] -> size -> 14 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [14.  3.  0.  0.  1.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 14  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  8. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3] -> size -> 14 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [14.  3.  0.  0.  1.  3.  6.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 14  6  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  8.  9.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3] -> size -> 14 
adversary victory points: 4
player victory points: 2 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[ 3.8106966]
 [12.019408 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  8.  9.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 6. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 14  6  8] -> size -> 15 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 7.866358757019043



action possibilites: [-1] 
expected returns: [[10.198112]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  7.  9.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 6. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 14  6  8] -> size -> 15 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 102 

action type: gain_card_n - action 5
Learning step: 0
desired expected reward: 19.27526092529297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[  6.339692]
 [ 22.323181]
 [ 15.53918 ]
 [-39.636124]
 [ 24.351562]
 [ 23.12257 ]
 [ 13.919602]
 [ 28.129135]
 [-16.70065 ]
 [ 18.304718]
 [  8.422698]
 [ 11.300548]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  7.  9.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 6. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 14  6  8] -> size -> 15 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 10.198111534118652



buy possibilites: [-1] 
expected returns: [[13.872615]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [11. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  7.  9.  9.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 6. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 14  6  8] -> size -> 15 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 203 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 28.129135131835938






Player: 1 
cards in hand: [0. 6. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 14  6  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  7.  9.  9.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  3.  3.] 
adversary cards in discard: [11. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29] -> size -> 16 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 14  6  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8.  9. 10.  7.  9.  9.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  3.  3.] 
adversary cards in discard: [11. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29] -> size -> 16 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 14  6  8  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7.  9.  9.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  3.  3.] 
adversary cards in discard: [11. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29] -> size -> 16 
adversary victory points: 4
player victory points: 2 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 29.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[36.83734 ]
 [57.173645]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  3.  3.] 
cards in discard: [11. 29. 11.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7.  9.  9.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 14.  8.  3.] 
adversary cards in discard: [0. 0. 6. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 14  6  8  0] -> size -> 16 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 13.872614860534668



action possibilites: [-1.] 
expected returns: [[16.512066]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [11. 29. 11.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7.  9.  9.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 14.  8.  3.] 
adversary cards in discard: [0. 0. 6. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 14  6  8  0] -> size -> 16 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 56.03530502319336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 14.219659]
 [ 28.51086 ]
 [ 22.632294]
 [-19.6021  ]
 [ 30.747013]
 [ 22.046833]
 [ 26.745876]
 [ 19.060078]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [11. 29. 11.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7.  9.  9.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 14.  8.  3.] 
adversary cards in discard: [0. 0. 6. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 14  6  8  0] -> size -> 16 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 16.512065887451172



buy possibilites: [-1] 
expected returns: [[5.2860136]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [11. 29. 11.  0.  0.  0.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  6.  9.  9.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 14.  8.  3.] 
adversary cards in discard: [0. 0. 6. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 14  6  8  0] -> size -> 16 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 129 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 30.747013092041016






Player: 1 
cards in hand: [ 0.  0. 14.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  8.  3.] 
cards in discard: [0. 0. 6. 0. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  1 14  6  8  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  6.  9.  9.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11. 11.  3. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11] -> size -> 17 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [0. 0. 6. 0. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  6  8  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  6.  9.  9.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11. 11.  3. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11] -> size -> 17 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [0. 0. 6. 0. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  6  8  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  6.  9.  9.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11. 11.  3. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11] -> size -> 17 
adversary victory points: 4
player victory points: 2 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [11. 11.  3. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 25.] 
expected returns: [[27.250591]
 [37.77981 ]
 [37.77981 ]
 [46.515255]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  3. 25.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  6.  9.  9.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  1.] 
adversary cards in discard: [0. 0. 6. 0. 3. 0. 8. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  6  8  0] -> size -> 14 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 5.286013603210449



action possibilites: [-1] 
expected returns: [[14.555209]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  3.  0.  3. 29.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  6.  9.  9.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  1.] 
adversary cards in discard: [0. 0. 6. 0. 3. 0. 8. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  6  8  0  6] -> size -> 15 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 46.48525619506836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[  8.625711]
 [-27.256332]
 [ 13.782737]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  3.  0.  3. 29.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  6.  9.  9.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  1.] 
adversary cards in discard: [0. 0. 6. 0. 3. 0. 8. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  6  8  0  6] -> size -> 15 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 14.555209159851074






Player: 1 
cards in hand: [11.  0.  3.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0.  1.] 
cards in discard: [0. 0. 6. 0. 3. 0. 8. 0. 3. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  6  8  0  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  6.  9.  9.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11.  0.] 
adversary cards in discard: [25. 11. 11.  3.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11] -> size -> 17 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 1.] 
cards in discard: [ 0.  0.  6.  0.  3.  0.  8.  0.  3.  6. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  6  8  0  6 15] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  6.  9.  9.  8.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 11.  0.] 
adversary cards in discard: [25. 11. 11.  3.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11] -> size -> 17 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1.] 
cards in discard: [ 0.  0.  6.  0.  3.  0.  8.  0.  3.  6. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  6  8  0  6 15] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  6.  9.  9.  8.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 11.  0.] 
adversary cards in discard: [25. 11. 11.  3.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11] -> size -> 17 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1.] 
cards in discard: [ 0.  0.  6.  0.  3.  0.  8.  0.  3.  6. 15.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  6  8  0  6 15  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 28. 30.  8.  8. 10.  6.  9.  9.  8.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 11.  0.] 
adversary cards in discard: [25. 11. 11.  3.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11] -> size -> 17 
adversary victory points: 4
player victory points: 2 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[ 1.9374609]
 [11.487407 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11.  0.] 
cards in discard: [25. 11. 11.  3.  0.  3. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  8. 10.  6.  9.  9.  8.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  6. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  6  8  0  6 15  3] -> size -> 17 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 13.782740592956543



action possibilites: [-1] 
expected returns: [[30.35252]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [25. 11. 11.  3.  0.  3. 29. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  8. 10.  5.  9.  9.  8.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  6. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  6  8  0  6 15  3] -> size -> 17 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 102 

action type: gain_card_n - action 5
Learning step: 0
desired expected reward: 15.568745613098145





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[24.781384]
 [39.55809 ]
 [34.181873]
 [-9.956703]
 [41.41889 ]
 [32.012238]
 [38.048138]
 [30.746853]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [25. 11. 11.  3.  0.  3. 29. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 28. 30.  8.  8. 10.  5.  9.  9.  8.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  6. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  6  8  0  6 15  3] -> size -> 17 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 30.352519989013672



buy possibilites: [-1] 
expected returns: [[16.06491]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [25. 11. 11.  3.  0.  3. 29. 11. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  8. 10.  4.  9.  9.  8.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  6. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  6  8  0  6 15  3] -> size -> 17 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 129 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 41.41887664794922






Player: 1 
cards in hand: [ 3.  6. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 15.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  6  8  0  6 15  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8.  8. 10.  4.  9.  9.  8.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 29.  0.] 
adversary cards in discard: [25. 11. 11.  3.  0.  3. 29. 11. 11. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11] -> size -> 19 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 15.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  6  8  0  6 15  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 28. 30.  8.  8. 10.  4.  9.  9.  8.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 29.  0.] 
adversary cards in discard: [25. 11. 11.  3.  0.  3. 29. 11. 11. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11] -> size -> 19 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 15.  0.  0.] 
cards in discard: [3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  6  8  0  6 15  3  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  8. 10.  4.  9.  9.  8.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 29.  0.] 
adversary cards in discard: [25. 11. 11.  3.  0.  3. 29. 11. 11. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11] -> size -> 19 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[47.26183]
 [62.57167]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 29.  0.] 
cards in discard: [25. 11. 11.  3.  0.  3. 29. 11. 11. 11.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  8. 10.  4.  9.  9.  8.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  6. 11.] 
adversary cards in discard: [ 3.  3.  6. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  6  8  0  6 15  3  3] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 16.064910888671875



action possibilites: [-1. 11.] 
expected returns: [[19.059555]
 [29.829071]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 27. 30.  8.  8. 10.  4.  9.  9.  8.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  6. 11.] 
adversary cards in discard: [ 3.  3.  6. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  6  8  0  6 15  3  3] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 61.93952941894531



action possibilites: [-1] 
expected returns: [[31.843613]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 27. 30.  8.  8. 10.  4.  9.  9.  8.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  6. 11.] 
adversary cards in discard: [ 3.  3.  6. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  6  8  0  6 15  3  3] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 92 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 33.193092346191406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[30.035118 ]
 [45.056316 ]
 [37.81057  ]
 [-5.9381027]
 [46.827545 ]
 [45.002476 ]
 [37.36728  ]
 [50.416283 ]
 [ 8.0341215]
 [40.722813 ]
 [31.785324 ]
 [33.766026 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 27. 30.  8.  8. 10.  4.  9.  9.  8.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  6. 11.] 
adversary cards in discard: [ 3.  3.  6. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  6  8  0  6 15  3  3] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 31.843612670898438



buy possibilites: [-1] 
expected returns: [[37.42876]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  8. 10.  4.  9.  9.  7.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  6. 11.] 
adversary cards in discard: [ 3.  3.  6. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  6  8  0  6 15  3  3] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  30   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 193 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 50.416290283203125






Player: 1 
cards in hand: [ 3.  0.  0.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  6. 11.] 
cards in discard: [ 3.  3.  6. 15.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  6  8  0  6 15  3  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  8. 10.  4.  9.  9.  7.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  0. 11.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29] -> size -> 21 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  6. 11.] 
cards in discard: [ 3.  3.  6. 15.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  6  8  0  6 15  3  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 27. 30.  8.  8. 10.  4.  9.  9.  7.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  0. 11.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29] -> size -> 21 
adversary victory points: 4
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[13.082492]
 [22.664112]
 [22.664112]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0. 11.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  8. 10.  4.  9.  9.  7.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 1. 3. 0.] 
adversary cards in discard: [ 3.  3.  6. 15.  0.  0.  3.  0.  0.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  6  8  0  6 15  3  3] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 37.42876052856445



action possibilites: [-1] 
expected returns: [[28.542671]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8.  8. 10.  4.  9.  9.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 1. 3. 0.] 
adversary cards in discard: [ 3.  3.  6. 15.  0.  0.  3.  0.  0.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  6  8  0  6 15  3  3] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 23.011444091796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[23.508308]
 [31.730938]
 [-9.800335]
 [30.294888]
 [28.899784]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 27. 30.  8.  8. 10.  4.  9.  9.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 1. 3. 0.] 
adversary cards in discard: [ 3.  3.  6. 15.  0.  0.  3.  0.  0.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  6  8  0  6 15  3  3] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 28.54267120361328



buy possibilites: [-1] 
expected returns: [[51.06677]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 30.  8.  8. 10.  4.  9.  9.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 1. 3. 0.] 
adversary cards in discard: [ 3.  3.  6. 15.  0.  0.  3.  0.  0.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  6  8  0  6 15  3  3] -> size -> 18 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 91 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 31.730934143066406






Player: 1 
cards in hand: [3. 0. 1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 3. 0.] 
cards in discard: [ 3.  3.  6. 15.  0.  0.  3.  0.  0.  6. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  6  8  0  6 15  3  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 30.  8.  8. 10.  4.  9.  9.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0.  3.  0. 25.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10.  3. 11.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3] -> size -> 23 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 3. 0.] 
cards in discard: [ 3.  3.  6. 15.  0.  0.  3.  0.  0.  6. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  6  8  0  6 15  3  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 26. 30.  8.  8. 10.  4.  9.  9.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0.  3.  0. 25.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10.  3. 11.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3] -> size -> 23 
adversary victory points: 5
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 3. 0.] 
cards in discard: [ 3.  3.  6. 15.  0.  0.  3.  0.  0.  6. 11.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  6  8  0  6 15  3  3  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 26. 30.  8.  8. 10.  4.  8.  9.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0.  3.  0. 25.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10.  3. 11.  3.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3] -> size -> 23 
adversary victory points: 5
player victory points: 3 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [11.  0.  3.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[24.35757]
 [36.78379]
 [44.60923]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0. 25.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10.  3. 11.  3.  0.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 30.  8.  8. 10.  4.  8.  9.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  6  8  0  6 15  3  3  8] -> size -> 19 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 51.066768646240234



action possibilites: [-1] 
expected returns: [[28.654453]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0. 11. 29.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10.  3. 11.  3.  0.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 30.  8.  7. 10.  4.  8.  9.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 3. 8. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  6  8  0  6 15  3  3  8  6] -> size -> 20 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 44.983402252197266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 23.65281 ]
 [ 37.248497]
 [-23.878277]
 [ 34.211403]
 [ 29.876488]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  0. 11. 29.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10.  3. 11.  3.  0.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 26. 30.  8.  7. 10.  4.  8.  9.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 3. 8. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  6  8  0  6 15  3  3  8  6] -> size -> 20 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 28.65445327758789



buy possibilites: [-1] 
expected returns: [[27.27827]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  0. 11. 29.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10.  3. 11.  3.  0.  0. 11.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 25. 30.  8.  7. 10.  4.  8.  9.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 3. 8. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  6  8  0  6 15  3  3  8  6] -> size -> 20 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 121 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 37.24848937988281






Player: 1 
cards in hand: [0. 3. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 8. 0.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11  1  6  8  0  6 15  3  3  8  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 25. 30.  8.  7. 10.  4.  8.  9.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [29.  3.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3] -> size -> 24 
adversary victory points: 6
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 11  1  6  8  0  6 15  3  3  8  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 25. 30.  8.  7. 10.  4.  8.  9.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [29.  3.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3] -> size -> 24 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 11  1  6  8  0  6 15  3  3  8  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 25. 30.  8.  7. 10.  4.  8.  9.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [29.  3.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3] -> size -> 24 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [29.  3.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 3.7070436]
 [16.169518 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 25. 30.  8.  7. 10.  4.  8.  9.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 6. 3. 3. 0.] 
adversary cards in discard: [6. 8. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  1  6  8  0  6 15  3  3  8  6] -> size -> 18 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 27.278270721435547



action possibilites: [-1.] 
expected returns: [[25.249737]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 25. 30.  8.  7. 10.  4.  8.  9.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 6. 3. 3. 0.] 
adversary cards in discard: [6. 8. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  1  6  8  0  6 15  3  3  8  6] -> size -> 18 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 15.779875755310059





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[24.224258]
 [36.46645 ]
 [29.049118]
 [-6.669389]
 [35.45503 ]
 [30.298283]
 [31.419601]
 [26.591187]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 25. 30.  8.  7. 10.  4.  8.  9.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 6. 3. 3. 0.] 
adversary cards in discard: [6. 8. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  1  6  8  0  6 15  3  3  8  6] -> size -> 18 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 25.249736785888672



buy possibilites: [-1] 
expected returns: [[18.681248]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 25. 30.  8.  7. 10.  4.  8.  9.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 6. 3. 3. 0.] 
adversary cards in discard: [6. 8. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  1  6  8  0  6 15  3  3  8  6] -> size -> 18 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 219 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 36.46644592285156






Player: 1 
cards in hand: [0. 6. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 3. 0.] 
cards in discard: [6. 8. 3. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  1  6  8  0  6 15  3  3  8  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 25. 30.  8.  7. 10.  4.  8.  9.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 11. 10.  0. 29.] 
adversary cards in discard: [ 1. 29.  3.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1] -> size -> 25 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 3. 0.] 
cards in discard: [6. 8. 3. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  1  6  8  0  6 15  3  3  8  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 25. 30.  8.  7. 10.  4.  8.  9.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 11. 10.  0. 29.] 
adversary cards in discard: [ 1. 29.  3.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1] -> size -> 25 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 3. 0.] 
cards in discard: [6. 8. 3. 0. 8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  1  6  8  0  6 15  3  3  8  6  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 25. 30.  8.  7. 10.  4.  7.  9.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 11. 10.  0. 29.] 
adversary cards in discard: [ 1. 29.  3.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1] -> size -> 25 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 10.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29.] 
expected returns: [[13.748904]
 [25.892082]
 [22.17244 ]
 [29.71682 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.  0. 29.] 
cards in discard: [ 1. 29.  3.  0.  0.  3.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 25. 30.  8.  7. 10.  4.  7.  9.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [11.  3.  1. 15.  6.] 
adversary cards in discard: [6. 8. 3. 0. 8. 0. 6. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  1  6  8  0  6 15  3  3  8  6  8] -> size -> 19 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 18.68124771118164



action possibilites: [-1. 11. 10. 11.] 
expected returns: [[29.640839]
 [39.190872]
 [36.025726]
 [39.190872]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.  0. 11.] 
cards in discard: [ 1. 29.  3.  0.  0.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 25. 30.  8.  7. 10.  4.  7.  9.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [11.  3.  1. 15.  6.] 
adversary cards in discard: [6. 8. 3. 0. 8. 0. 6. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  1  6  8  0  6 15  3  3  8  6  8] -> size -> 19 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 27.69485092163086



action possibilites: [-1] 
expected returns: [[27.138786]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 11.] 
cards in discard: [ 1. 29.  3.  0.  0.  3.  3. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 25. 30.  8.  7. 10.  4.  7.  9.  7.  9. 10.  7. 10.  9.] 
adversary cards in hand: [11.  3.  1. 15.  6.] 
adversary cards in discard: [6. 8. 3. 0. 8. 0. 6. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  1  6  8  0  6 15  3  3  8  6  8] -> size -> 19 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 212 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 40.620628356933594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 23.931065]
 [ 37.137676]
 [ 30.265694]
 [-10.933517]
 [ 37.09344 ]
 [ 30.293858]
 [ 32.378315]
 [ 28.008904]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 11.] 
cards in discard: [ 1. 29.  3.  0.  0.  3.  3. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 25. 30.  8.  7. 10.  4.  7.  9.  7.  9. 10.  7. 10.  9.] 
adversary cards in hand: [11.  3.  1. 15.  6.] 
adversary cards in discard: [6. 8. 3. 0. 8. 0. 6. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  1  6  8  0  6 15  3  3  8  6  8] -> size -> 19 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: 27.13878631591797



buy possibilites: [-1] 
expected returns: [[33.531826]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 11.] 
cards in discard: [ 1. 29.  3.  0.  0.  3.  3. 10.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 25. 30.  8.  7. 10.  4.  7.  9.  7.  9. 10.  7. 10.  9.] 
adversary cards in hand: [11.  3.  1. 15.  6.] 
adversary cards in discard: [6. 8. 3. 0. 8. 0. 6. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  1  6  8  0  6 15  3  3  8  6  8] -> size -> 19 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 239 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 37.137672424316406






Player: 1 
cards in hand: [11.  3.  1. 15.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  1. 15.  6.] 
cards in discard: [6. 8. 3. 0. 8. 0. 6. 3. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  1  6  8  0  6 15  3  3  8  6  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 25. 30.  8.  7. 10.  4.  7.  9.  7.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  3. 11. 10. 11.] 
adversary cards in discard: [ 1. 29.  3.  0.  0.  3.  3. 10.  1. 29. 11.  0. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1] -> size -> 27 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 15.  6.] 
cards in discard: [ 6.  8.  3.  0.  8.  0.  6.  3.  3.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11  1  6  8  0  6 15  3  3  8  6  8 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 25. 30.  8.  7. 10.  3.  7.  9.  7.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  3. 11. 10. 11.] 
adversary cards in discard: [ 1. 29.  3.  0.  0.  3.  3. 10.  1. 29. 11.  0. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1] -> size -> 27 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 15.  6.] 
cards in discard: [ 6.  8.  3.  0.  8.  0.  6.  3.  3.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11  1  6  8  0  6 15  3  3  8  6  8 11] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 27. 30. 25. 30.  8.  7. 10.  3.  7.  9.  7.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  3. 11. 10. 11.] 
adversary cards in discard: [ 1. 29.  3.  0.  0.  3.  3. 10.  1. 29. 11.  0. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1] -> size -> 27 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 3.  3. 11. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11.] 
expected returns: [[59.349106]
 [72.005936]
 [67.0242  ]
 [72.005936]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11. 10. 11.] 
cards in discard: [ 1. 29.  3.  0.  0.  3.  3. 10.  1. 29. 11.  0. 10.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 25. 30.  8.  7. 10.  3.  7.  9.  7.  9. 10.  7. 10.  9.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  1  6  8  0  6 15  3  3  8  6  8 11] -> size -> 20 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 33.53182601928711



action possibilites: [-1] 
expected returns: [[16.699108]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10. 11.] 
cards in discard: [ 1. 29.  3.  0.  0.  3.  3. 10.  1. 29. 11.  0. 10.  0. 11. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 25. 30.  8.  7. 10.  3.  7.  9.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  1  6  8  0  6 15  3  3  8  6  8 11] -> size -> 20 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 192 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 71.91169738769531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 10.055472]
 [-31.200993]
 [ 17.271084]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10. 11.] 
cards in discard: [ 1. 29.  3.  0.  0.  3.  3. 10.  1. 29. 11.  0. 10.  0. 11. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 27. 30. 25. 30.  8.  7. 10.  3.  7.  9.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  1  6  8  0  6 15  3  3  8  6  8 11] -> size -> 20 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 16.699108123779297






Player: 1 
cards in hand: [3. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  1  6  8  0  6 15  3  3  8  6  8 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 25. 30.  8.  7. 10.  3.  7.  9.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 25.  3.  0.  0.] 
adversary cards in discard: [ 1. 29.  3.  0.  0.  3.  3. 10.  1. 29. 11.  0. 10.  0. 11. 10. 11.  3.
  3. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10] -> size -> 28 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  1  6  8  0  6 15  3  3  8  6  8 11] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 27. 30. 25. 30.  8.  7. 10.  3.  7.  9.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 25.  3.  0.  0.] 
adversary cards in discard: [ 1. 29.  3.  0.  0.  3.  3. 10.  1. 29. 11.  0. 10.  0. 11. 10. 11.  3.
  3. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10] -> size -> 28 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  1  6  8  0  6 15  3  3  8  6  8 11  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 27. 30. 25. 30.  8.  7. 10.  3.  7.  9.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 25.  3.  0.  0.] 
adversary cards in discard: [ 1. 29.  3.  0.  0.  3.  3. 10.  1. 29. 11.  0. 10.  0. 11. 10. 11.  3.
  3. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10] -> size -> 28 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[45.55208 ]
 [60.619316]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3.  0.  0.] 
cards in discard: [ 1. 29.  3.  0.  0.  3.  3. 10.  1. 29. 11.  0. 10.  0. 11. 10. 11.  3.
  3. 10. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 25. 30.  8.  7. 10.  3.  7.  9.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8. 15.  3.  0.  6.] 
adversary cards in discard: [0. 3. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  1  6  8  0  6 15  3  3  8  6  8 11  0] -> size -> 21 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 17.27106475830078



action possibilites: [-1] 
expected returns: [[12.941468]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 29. 11.] 
cards in discard: [ 1. 29.  3.  0.  0.  3.  3. 10.  1. 29. 11.  0. 10.  0. 11. 10. 11.  3.
  3. 10. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 25. 30.  8.  6. 10.  3.  7.  9.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8. 15.  3.  0.  6.] 
adversary cards in discard: [0. 3. 8. 0. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  1  6  8  0  6 15  3  3  8  6  8 11  0  6] -> size -> 22 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 60.61930847167969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[  5.3168163]
 [ 20.004421 ]
 [ 14.793801 ]
 [-28.931702 ]
 [ 21.40332  ]
 [ 10.934686 ]
 [ 15.953317 ]
 [ 14.629045 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 29. 11.] 
cards in discard: [ 1. 29.  3.  0.  0.  3.  3. 10.  1. 29. 11.  0. 10.  0. 11. 10. 11.  3.
  3. 10. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 27. 30. 25. 30.  8.  6. 10.  3.  7.  9.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8. 15.  3.  0.  6.] 
adversary cards in discard: [0. 3. 8. 0. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  1  6  8  0  6 15  3  3  8  6  8 11  0  6] -> size -> 22 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 12.941468238830566



buy possibilites: [-1] 
expected returns: [[1.8768826]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 29. 11.] 
cards in discard: [ 1. 29.  3.  0.  0.  3.  3. 10.  1. 29. 11.  0. 10.  0. 11. 10. 11.  3.
  3. 10. 11. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 25. 30.  8.  6. 10.  2.  7.  9.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8. 15.  3.  0.  6.] 
adversary cards in discard: [0. 3. 8. 0. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11  1  6  8  0  6 15  3  3  8  6  8 11  0  6] -> size -> 22 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 219 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 21.40331268310547






Player: 1 
cards in hand: [ 8. 15.  3.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  3.  0.  6.] 
cards in discard: [0. 3. 8. 0. 0. 0. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11  1  6  8  0  6 15  3  3  8  6  8 11  0  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 25. 30.  8.  6. 10.  2.  7.  9.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11] -> size -> 29 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [0. 3. 8. 0. 0. 0. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 25. 30.  8.  6. 10.  2.  7.  9.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11] -> size -> 29 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0. 3. 8. 0. 0. 0. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 27. 30. 25. 30.  8.  6. 10.  2.  7.  9.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11] -> size -> 29 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0. 3. 8. 0. 0. 0. 6. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 25. 30.  8.  6. 10.  2.  7.  9.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11] -> size -> 29 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[ 8.914571]
 [18.179768]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 25. 30.  8.  6. 10.  2.  7.  9.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  8.  0.  6. 11.] 
adversary cards in discard: [0. 3. 8. 0. 0. 0. 6. 0. 8.] 
adversary owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0] -> size -> 19 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 1.876882553100586



action possibilites: [-1] 
expected returns: [[17.990147]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 25. 30.  8.  6. 10.  2.  7.  9.  7.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  8.  0.  6. 11.] 
adversary cards in discard: [0. 3. 8. 0. 0. 0. 6. 0. 8.] 
adversary owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0] -> size -> 19 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 222 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 20.258628845214844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 10.934117]
 [ 24.884983]
 [ 17.781029]
 [-27.267578]
 [ 25.474094]
 [ 18.583813]
 [ 21.237778]
 [ 16.537739]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 27. 30. 25. 30.  8.  6. 10.  2.  7.  9.  7.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  8.  0.  6. 11.] 
adversary cards in discard: [0. 3. 8. 0. 0. 0. 6. 0. 8.] 
adversary owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0] -> size -> 19 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 17.99014663696289



buy possibilites: [-1] 
expected returns: [[8.310815]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10. 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 25. 30.  8.  6. 10.  1.  7.  9.  7.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  8.  0.  6. 11.] 
adversary cards in discard: [0. 3. 8. 0. 0. 0. 6. 0. 8.] 
adversary owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0] -> size -> 19 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 249 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 25.47408676147461






Player: 1 
cards in hand: [ 3.  8.  0.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0.  6. 11.] 
cards in discard: [0. 3. 8. 0. 0. 0. 6. 0. 8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 25. 30.  8.  6. 10.  1.  7.  9.  7.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 3. 10. 11. 10.  0.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11] -> size -> 31 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  0.  6. 11.] 
cards in discard: [0. 3. 8. 0. 0. 0. 6. 0. 8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 27. 30. 25. 30.  8.  6. 10.  1.  7.  9.  7.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 3. 10. 11. 10.  0.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11] -> size -> 31 
adversary victory points: 6
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.] 
expected returns: [[ 3.4265862]
 [ 7.7371874]
 [12.34621  ]
 [ 7.7371874]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11. 10.  0.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 25. 30.  8.  6. 10.  1.  7.  9.  7.  9. 10.  5. 10.  9.] 
adversary cards in hand: [11.  1.  0.  3.  6.] 
adversary cards in discard: [ 0.  3.  8.  0.  0.  0.  6.  0.  8.  3.  8.  0.  6. 11.] 
adversary owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0] -> size -> 19 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 8.31081485748291



action possibilites: [-1] 
expected returns: [[7.36954]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10.  0.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 25. 30.  8.  6. 10.  1.  7.  9.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [11.  1.  0.  3.  6.] 
adversary cards in discard: [ 0.  3.  8.  0.  0.  0.  6.  0.  8.  3.  8.  0.  6. 11.] 
adversary owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0] -> size -> 19 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 222 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 14.898299217224121





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[  3.3465176]
 [-26.467552 ]
 [  7.61481  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 10.  0.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 27. 30. 25. 30.  8.  6. 10.  1.  7.  9.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [11.  1.  0.  3.  6.] 
adversary cards in discard: [ 0.  3.  8.  0.  0.  0.  6.  0.  8.  3.  8.  0.  6. 11.] 
adversary owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0] -> size -> 19 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 7.369540214538574






Player: 1 
cards in hand: [11.  1.  0.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  0.  3.  6.] 
cards in discard: [ 0.  3.  8.  0.  0.  0.  6.  0.  8.  3.  8.  0.  6. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 25. 30.  8.  6. 10.  1.  7.  9.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [29. 11.  0.  3.  3.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0. 10. 11.  3. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10] -> size -> 32 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 6.] 
cards in discard: [ 0.  3.  8.  0.  0.  0.  6.  0.  8.  3.  8.  0.  6. 11.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 25. 30.  8.  6. 10.  1.  7.  9.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [29. 11.  0.  3.  3.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0. 10. 11.  3. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10] -> size -> 32 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 6.] 
cards in discard: [ 0.  3.  8.  0.  0.  0.  6.  0.  8.  3.  8.  0.  6. 11.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 26. 30. 25. 30.  8.  6. 10.  1.  7.  9.  7.  9. 10.  4. 10.  9.] 
adversary cards in hand: [29. 11.  0.  3.  3.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0. 10. 11.  3. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10] -> size -> 32 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 6.] 
cards in discard: [ 0.  3.  8.  0.  0.  0.  6.  0.  8.  3.  8.  0.  6. 11.  1. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 25. 30.  8.  6. 10.  1.  7.  9.  7.  9. 10.  3. 10.  9.] 
adversary cards in hand: [29. 11.  0.  3.  3.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0. 10. 11.  3. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10] -> size -> 32 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [29. 11.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[ 2.2734756]
 [12.409686 ]
 [ 9.093972 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  0.  3.  3.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0. 10. 11.  3. 10. 10.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 25. 30.  8.  6. 10.  1.  7.  9.  7.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10] -> size -> 21 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 7.614808082580566



action possibilites: [-1. 11. 29.] 
expected returns: [[27.165821]
 [34.536423]
 [38.488186]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  3. 29.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0. 10. 11.  3. 10. 10.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 25. 30.  8.  6. 10.  1.  7.  9.  7.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10] -> size -> 21 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 12.409708976745605



action possibilites: [-1. 11.] 
expected returns: [[48.194763]
 [55.94876 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  3.  0.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0. 10. 11.  3. 10. 10.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 26. 30. 25. 30.  8.  6. 10.  1.  7.  9.  7.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10] -> size -> 21 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 38.488197326660156



action possibilites: [-1] 
expected returns: [[44.136497]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0. 10. 11.  3. 10. 10.  0. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 26. 30. 25. 30.  8.  6. 10.  1.  7.  9.  7.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10] -> size -> 21 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  60   0   0   0   0   0   0   0  27   0] 
sum of rewards: 262 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 57.15045928955078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[39.521366 ]
 [53.210957 ]
 [47.39361  ]
 [ 5.9597864]
 [55.712784 ]
 [54.17361  ]
 [46.02673  ]
 [58.350433 ]
 [19.027962 ]
 [49.924156 ]
 [40.746628 ]
 [45.520218 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0. 10. 11.  3. 10. 10.  0. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 26. 30. 25. 30.  8.  6. 10.  1.  7.  9.  7.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10] -> size -> 21 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action -1
Learning step: 0
desired expected reward: 44.136497497558594



buy possibilites: [-1] 
expected returns: [[49.60448]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0. 10. 11.  3. 10. 10.  0. 10. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 25. 30.  8.  6. 10.  1.  7.  9.  6.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10] -> size -> 21 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 363 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 58.350440979003906






Player: 1 
cards in hand: [ 3.  0. 10.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  6.  3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 25. 30.  8.  6. 10.  1.  7.  9.  6.  9. 10.  2. 10.  9.] 
adversary cards in hand: [25.  1. 29. 10. 11.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0. 10. 11.  3. 10. 10.  0. 10. 29. 29. 29. 11.
  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29] -> size -> 34 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  6.  3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 26. 30. 25. 30.  8.  6. 10.  1.  7.  9.  6.  9. 10.  2. 10.  9.] 
adversary cards in hand: [25.  1. 29. 10. 11.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0. 10. 11.  3. 10. 10.  0. 10. 29. 29. 29. 11.
  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29] -> size -> 34 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  6.  3.] 
cards in discard: [0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 25. 30.  8.  6. 10.  1.  7.  9.  6.  9. 10.  2. 10.  9.] 
adversary cards in hand: [25.  1. 29. 10. 11.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0. 10. 11.  3. 10. 10.  0. 10. 29. 29. 29. 11.
  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29] -> size -> 34 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [25.  1. 29. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 10. 11.] 
expected returns: [[39.346214]
 [53.908844]
 [50.146008]
 [40.14841 ]
 [45.10817 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1. 29. 10. 11.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0. 10. 11.  3. 10. 10.  0. 10. 29. 29. 29. 11.
  0.  3.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 25. 30.  8.  6. 10.  1.  7.  9.  6.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 8.  0.  0.  8. 11.] 
adversary cards in discard: [ 0.  3.  0. 10.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0] -> size -> 22 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 49.6044807434082



action possibilites: [-1] 
expected returns: [[47.518166]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 10. 11.  0. 11.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0. 10. 11.  3. 10. 10.  0. 10. 29. 29. 29. 11.
  0.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 25. 30.  8.  5. 10.  1.  7.  9.  6.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 8.  0.  0.  8. 11.] 
adversary cards in discard: [ 0.  3.  0. 10.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6] -> size -> 23 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 53.908843994140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 38.39326 ]
 [ 52.509884]
 [ 45.823307]
 [-14.332529]
 [ 53.018963]
 [ 45.170544]
 [ 48.10398 ]
 [ 48.796864]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29. 10. 11.  0. 11.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0. 10. 11.  3. 10. 10.  0. 10. 29. 29. 29. 11.
  0.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 26. 30. 25. 30.  8.  5. 10.  1.  7.  9.  6.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 8.  0.  0.  8. 11.] 
adversary cards in discard: [ 0.  3.  0. 10.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6] -> size -> 23 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 47.518165588378906



buy possibilites: [-1] 
expected returns: [[41.845577]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29. 10. 11.  0. 11.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0. 10. 11.  3. 10. 10.  0. 10. 29. 29. 29. 11.
  0.  3.  3.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 25. 30.  8.  5. 10.  0.  7.  9.  6.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 8.  0.  0.  8. 11.] 
adversary cards in discard: [ 0.  3.  0. 10.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6] -> size -> 23 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 249 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 53.01893997192383






Player: 1 
cards in hand: [ 8.  0.  0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0.  8. 11.] 
cards in discard: [ 0.  3.  0. 10.  6.  3.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 25. 30.  8.  5. 10.  0.  7.  9.  6.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 3. 11. 10.  1.  3.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0. 10. 11.  3. 10. 10.  0. 10. 29. 29. 29. 11.
  0.  3.  3.  0. 11. 25.  1. 29. 10. 11.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11] -> size -> 35 
adversary victory points: 6
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 8.] 
cards in discard: [ 0.  3.  0. 10.  6.  3.  6. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 25. 30.  8.  5. 10.  0.  7.  9.  5.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 3. 11. 10.  1.  3.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0. 10. 11.  3. 10. 10.  0. 10. 29. 29. 29. 11.
  0.  3.  3.  0. 11. 25.  1. 29. 10. 11.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11] -> size -> 35 
adversary victory points: 6
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 8.] 
cards in discard: [ 0.  3.  0. 10.  6.  3.  6. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 26. 30. 25. 30.  8.  5. 10.  0.  7.  9.  5.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 3. 11. 10.  1.  3.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0. 10. 11.  3. 10. 10.  0. 10. 29. 29. 29. 11.
  0.  3.  3.  0. 11. 25.  1. 29. 10. 11.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11] -> size -> 35 
adversary victory points: 6
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 8.] 
cards in discard: [ 0.  3.  0. 10.  6.  3.  6. 29.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 24. 30.  8.  5. 10.  0.  7.  9.  5.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 3. 11. 10.  1.  3.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0. 10. 11.  3. 10. 10.  0. 10. 29. 29. 29. 11.
  0.  3.  3.  0. 11. 25.  1. 29. 10. 11.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11] -> size -> 35 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 3. 11. 10.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[48.104485]
 [53.57847 ]
 [49.08744 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10.  1.  3.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0. 10. 11.  3. 10. 10.  0. 10. 29. 29. 29. 11.
  0.  3.  3.  0. 11. 25.  1. 29. 10. 11.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 24. 30.  8.  5. 10.  0.  7.  9.  5.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 1. 11.  8.  3.  6.] 
adversary cards in discard: [ 0.  3.  0. 10.  6.  3.  6. 29.  3. 11.  8.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29
  3] -> size -> 25 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 41.845577239990234



action possibilites: [-1] 
expected returns: [[44.097015]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  1.  3.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0. 10. 11.  3. 10. 10.  0. 10. 29. 29. 29. 11.
  0.  3.  3.  0. 11. 25.  1. 29. 10. 11.  0. 11. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 24. 30.  8.  5. 10.  0.  7.  9.  5.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 1. 11.  8.  3.  6.] 
adversary cards in discard: [ 0.  3.  0. 10.  6.  3.  6. 29.  3. 11.  8.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29
  3] -> size -> 25 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0 -10   0   0  64   0] 
sum of rewards: 249 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 56.493568420410156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[33.455948 ]
 [41.619366 ]
 [ 1.6266704]
 [38.859615 ]
 [44.09703  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  1.  3.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0. 10. 11.  3. 10. 10.  0. 10. 29. 29. 29. 11.
  0.  3.  3.  0. 11. 25.  1. 29. 10. 11.  0. 11. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 26. 30. 24. 30.  8.  5. 10.  0.  7.  9.  5.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 1. 11.  8.  3.  6.] 
adversary cards in discard: [ 0.  3.  0. 10.  6.  3.  6. 29.  3. 11.  8.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29
  3] -> size -> 25 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 44.097015380859375






Player: 1 
cards in hand: [ 1. 11.  8.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  8.  3.  6.] 
cards in discard: [ 0.  3.  0. 10.  6.  3.  6. 29.  3. 11.  8.  0.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 24. 30.  8.  5. 10.  0.  7.  9.  5.  9. 10.  2. 10.  8.] 
adversary cards in hand: [11. 10. 29.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15] -> size -> 36 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  8.  3.  6.] 
cards in discard: [ 0.  3.  0. 10.  6.  3.  6. 29.  3. 11.  8.  0.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 26. 30. 24. 30.  8.  5. 10.  0.  7.  9.  5.  9. 10.  2. 10.  8.] 
adversary cards in hand: [11. 10. 29.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15] -> size -> 36 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  8.  3.  6.] 
cards in discard: [ 0.  3.  0. 10.  6.  3.  6. 29.  3. 11.  8.  0.  0.  8.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29
  3  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 23. 30.  8.  5. 10.  0.  7.  9.  5.  9. 10.  2. 10.  8.] 
adversary cards in hand: [11. 10. 29.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15] -> size -> 36 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [11. 10. 29.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29. 29.] 
expected returns: [[12.7099085]
 [21.471123 ]
 [16.832321 ]
 [23.767197 ]
 [23.767197 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 29.  3. 29.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 23. 30.  8.  5. 10.  0.  7.  9.  5.  9. 10.  2. 10.  8.] 
adversary cards in hand: [6. 1. 0. 0. 0.] 
adversary cards in discard: [ 0.  3.  0. 10.  6.  3.  6. 29.  3. 11.  8.  0.  0.  8.  3.  1. 11.  8.
  3.  6.] 
adversary owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29
  3  3] -> size -> 26 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 44.097015380859375



action possibilites: [-1. 11. 10. 29.] 
expected returns: [[33.037136]
 [41.807648]
 [37.50995 ]
 [45.614166]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  3. 29.] 
cards in discard: [1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 23. 30.  8.  5. 10.  0.  7.  9.  5.  9. 10.  2. 10.  8.] 
adversary cards in hand: [6. 1. 0. 0. 0.] 
adversary cards in discard: [ 0.  3.  0. 10.  6.  3.  6. 29.  3. 11.  8.  0.  0.  8.  3.  1. 11.  8.
  3.  6.] 
adversary owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29
  3  3] -> size -> 26 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 19.79574966430664



action possibilites: [-1. 11. 10.] 
expected returns: [[31.87716 ]
 [38.555714]
 [33.508846]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  3.] 
cards in discard: [1. 3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 26. 30. 23. 30.  8.  5. 10.  0.  7.  9.  5.  9. 10.  2. 10.  8.] 
adversary cards in hand: [6. 1. 0. 0. 0.] 
adversary cards in discard: [ 0.  3.  0. 10.  6.  3.  6. 29.  3. 11.  8.  0.  0.  8.  3.  1. 11.  8.
  3.  6.] 
adversary owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29
  3  3] -> size -> 26 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 39.80473327636719



action possibilites: [-1] 
expected returns: [[29.634296]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.] 
cards in discard: [ 1.  3. 15.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 26. 30. 23. 30.  8.  5. 10.  0.  7.  9.  5.  9. 10.  2. 10.  7.] 
adversary cards in hand: [6. 1. 0. 0. 0.] 
adversary cards in discard: [ 0.  3.  0. 10.  6.  3.  6. 29.  3. 11.  8.  0.  0.  8.  3.  1. 11.  8.
  3.  6.] 
adversary owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29
  3  3] -> size -> 26 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  60   0   0   0   0 -20   0   0  64   0] 
sum of rewards: 249 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 40.81163787841797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 22.747776]
 [ 29.972565]
 [-12.760843]
 [ 29.657402]
 [ 29.644905]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.] 
cards in discard: [ 1.  3. 15.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 26. 30. 23. 30.  8.  5. 10.  0.  7.  9.  5.  9. 10.  2. 10.  7.] 
adversary cards in hand: [6. 1. 0. 0. 0.] 
adversary cards in discard: [ 0.  3.  0. 10.  6.  3.  6. 29.  3. 11.  8.  0.  0.  8.  3.  1. 11.  8.
  3.  6.] 
adversary owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29
  3  3] -> size -> 26 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: take_action - action -1
Learning step: 0
desired expected reward: 29.634296417236328



buy possibilites: [-1] 
expected returns: [[48.411003]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.] 
cards in discard: [ 1.  3. 15.  3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 22. 30.  8.  5. 10.  0.  7.  9.  5.  9. 10.  2. 10.  7.] 
adversary cards in hand: [6. 1. 0. 0. 0.] 
adversary cards in discard: [ 0.  3.  0. 10.  6.  3.  6. 29.  3. 11.  8.  0.  0.  8.  3.  1. 11.  8.
  3.  6.] 
adversary owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29
  3  3] -> size -> 26 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0  60   0   0   0   0 -30   0   0  16   0] 
sum of rewards: 221 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 29.972557067871094






Player: 1 
cards in hand: [6. 1. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 0. 0. 0.] 
cards in discard: [ 0.  3.  0. 10.  6.  3.  6. 29.  3. 11.  8.  0.  0.  8.  3.  1. 11.  8.
  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29
  3  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 22. 30.  8.  5. 10.  0.  7.  9.  5.  9. 10.  2. 10.  7.] 
adversary cards in hand: [ 0. 15. 11. 10. 10.] 
adversary cards in discard: [ 1.  3. 15.  3. 29. 29. 11. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3] -> size -> 38 
adversary victory points: 7
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 0. 0. 0.] 
cards in discard: [ 0.  3.  0. 10.  6.  3.  6. 29.  3. 11.  8.  0.  0.  8.  3.  1. 11.  8.
  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29
  3  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 26. 30. 22. 30.  8.  5. 10.  0.  7.  9.  5.  9. 10.  2. 10.  7.] 
adversary cards in hand: [ 0. 15. 11. 10. 10.] 
adversary cards in discard: [ 1.  3. 15.  3. 29. 29. 11. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3] -> size -> 38 
adversary victory points: 7
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 0. 0. 0.] 
cards in discard: [ 0.  3.  0. 10.  6.  3.  6. 29.  3. 11.  8.  0.  0.  8.  3.  1. 11.  8.
  3.  6. 22.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29
  3  3 22] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 22. 30.  8.  5. 10.  0.  7.  9.  5.  9. 10.  2.  9.  7.] 
adversary cards in hand: [ 0. 15. 11. 10. 10.] 
adversary cards in discard: [ 1.  3. 15.  3. 29. 29. 11. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3] -> size -> 38 
adversary victory points: 7
player victory points: 1 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 0. 15. 11. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 10. 10.] 
expected returns: [[16.379444]
 [10.395949]
 [26.155952]
 [20.899075]
 [20.899075]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 11. 10. 10.] 
cards in discard: [ 1.  3. 15.  3. 29. 29. 11. 10.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 22. 30.  8.  5. 10.  0.  7.  9.  5.  9. 10.  2.  9.  7.] 
adversary cards in hand: [3. 1. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29
  3  3 22] -> size -> 27 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 48.41100311279297



action possibilites: [-1] 
expected returns: [[23.358002]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 10. 10.] 
cards in discard: [ 1.  3. 15.  3. 29. 29. 11. 10.  3. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 22. 30.  8.  5. 10.  0.  7.  9.  5.  9. 10.  2.  9.  6.] 
adversary cards in hand: [3. 1. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29
  3  3 22] -> size -> 27 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0 -40   0   0  64   0] 
sum of rewards: 219 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 27.638092041015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 17.091354]
 [-16.582596]
 [ 24.270908]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 10. 10.] 
cards in discard: [ 1.  3. 15.  3. 29. 29. 11. 10.  3. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 26. 30. 22. 30.  8.  5. 10.  0.  7.  9.  5.  9. 10.  2.  9.  6.] 
adversary cards in hand: [3. 1. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29
  3  3 22] -> size -> 27 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 23.358001708984375






Player: 1 
cards in hand: [3. 1. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29
  3  3 22] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 22. 30.  8.  5. 10.  0.  7.  9.  5.  9. 10.  2.  9.  6.] 
adversary cards in hand: [ 0.  1. 29.  3. 10.] 
adversary cards in discard: [ 1.  3. 15.  3. 29. 29. 11. 10.  3. 15. 11.  0. 15. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15] -> size -> 39 
adversary victory points: 7
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29
  3  3 22] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 26. 30. 22. 30.  8.  5. 10.  0.  7.  9.  5.  9. 10.  2.  9.  6.] 
adversary cards in hand: [ 0.  1. 29.  3. 10.] 
adversary cards in discard: [ 1.  3. 15.  3. 29. 29. 11. 10.  3. 15. 11.  0. 15. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15] -> size -> 39 
adversary victory points: 7
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 3. 0.] 
cards in discard: [14.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29
  3  3 22 14] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 22. 30.  8.  5. 10.  0.  7.  9.  5.  8. 10.  2.  9.  6.] 
adversary cards in hand: [ 0.  1. 29.  3. 10.] 
adversary cards in discard: [ 1.  3. 15.  3. 29. 29. 11. 10.  3. 15. 11.  0. 15. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15] -> size -> 39 
adversary victory points: 7
player victory points: 1 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 0.  1. 29.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[30.19392 ]
 [43.47088 ]
 [35.053318]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 29.  3. 10.] 
cards in discard: [ 1.  3. 15.  3. 29. 29. 11. 10.  3. 15. 11.  0. 15. 10. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 22. 30.  8.  5. 10.  0.  7.  9.  5.  8. 10.  2.  9.  6.] 
adversary cards in hand: [ 0. 11.  1.  0. 11.] 
adversary cards in discard: [14.  3.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29
  3  3 22 14] -> size -> 28 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 24.270904541015625



action possibilites: [-1. 10. 11.] 
expected returns: [[16.337059]
 [23.551868]
 [26.073261]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10. 11.] 
cards in discard: [ 1.  3. 15.  3. 29. 29. 11. 10.  3. 15. 11.  0. 15. 10. 10.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 22. 30.  8.  5. 10.  0.  7.  9.  5.  8. 10.  2.  9.  6.] 
adversary cards in hand: [ 0. 11.  1.  0. 11.] 
adversary cards in discard: [14.  3.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29
  3  3 22 14] -> size -> 28 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 38.23067855834961



action possibilites: [-1] 
expected returns: [[47.85755]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.] 
cards in discard: [ 1.  3. 15.  3. 29. 29. 11. 10.  3. 15. 11.  0. 15. 10. 10.  1.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 22. 30.  8.  5. 10.  0.  6.  9.  5.  8. 10.  2.  9.  6.] 
adversary cards in hand: [ 0. 11.  1.  0. 11.] 
adversary cards in discard: [14.  3.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29
  3  3 22 14] -> size -> 28 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0 -50   0   0   8   0] 
sum of rewards: 173 

action type: gain_card_n - action 5
Learning step: 0
desired expected reward: 28.37329864501953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[43.031693]
 [50.25613 ]
 [ 8.048908]
 [49.864857]
 [48.033318]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.] 
cards in discard: [ 1.  3. 15.  3. 29. 29. 11. 10.  3. 15. 11.  0. 15. 10. 10.  1.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 26. 30. 22. 30.  8.  5. 10.  0.  6.  9.  5.  8. 10.  2.  9.  6.] 
adversary cards in hand: [ 0. 11.  1.  0. 11.] 
adversary cards in discard: [14.  3.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29
  3  3 22 14] -> size -> 28 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1
Learning step: 0
desired expected reward: 47.85755157470703



buy possibilites: [-1] 
expected returns: [[76.71055]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.] 
cards in discard: [ 1.  3. 15.  3. 29. 29. 11. 10.  3. 15. 11.  0. 15. 10. 10.  1.  8.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 21. 30.  8.  5. 10.  0.  6.  9.  5.  8. 10.  2.  9.  6.] 
adversary cards in hand: [ 0. 11.  1.  0. 11.] 
adversary cards in discard: [14.  3.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29
  3  3 22 14] -> size -> 28 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0 -60   0   0  16   0] 
sum of rewards: 201 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 50.25612258911133






Player: 1 
cards in hand: [ 0. 11.  1.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  1.  0. 11.] 
cards in discard: [14.  3.  1.  0.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29
  3  3 22 14] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 21. 30.  8.  5. 10.  0.  6.  9.  5.  8. 10.  2.  9.  6.] 
adversary cards in hand: [ 3. 11. 11.  0.  3.] 
adversary cards in discard: [ 1.  3. 15.  3. 29. 29. 11. 10.  3. 15. 11.  0. 15. 10. 10.  1.  8.  3.
 29. 11.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3] -> size -> 41 
adversary victory points: 8
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0. 11.] 
cards in discard: [14.  3.  1.  0.  3.  0. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29
  3  3 22 14 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 21. 30.  8.  5. 10.  0.  6.  9.  5.  8. 10.  2.  9.  5.] 
adversary cards in hand: [ 3. 11. 11.  0.  3.] 
adversary cards in discard: [ 1.  3. 15.  3. 29. 29. 11. 10.  3. 15. 11.  0. 15. 10. 10.  1.  8.  3.
 29. 11.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3] -> size -> 41 
adversary victory points: 8
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0. 11.] 
cards in discard: [14.  3.  1.  0.  3.  0. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29
  3  3 22 14 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 26. 30. 21. 30.  8.  5. 10.  0.  6.  9.  5.  8. 10.  2.  9.  5.] 
adversary cards in hand: [ 3. 11. 11.  0.  3.] 
adversary cards in discard: [ 1.  3. 15.  3. 29. 29. 11. 10.  3. 15. 11.  0. 15. 10. 10.  1.  8.  3.
 29. 11.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3] -> size -> 41 
adversary victory points: 8
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0. 11.] 
cards in discard: [14.  3.  1.  0.  3.  0. 15. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29
  3  3 22 14 15 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 21. 30.  8.  5. 10.  0.  6.  9.  5.  8. 10.  1.  9.  5.] 
adversary cards in hand: [ 3. 11. 11.  0.  3.] 
adversary cards in discard: [ 1.  3. 15.  3. 29. 29. 11. 10.  3. 15. 11.  0. 15. 10. 10.  1.  8.  3.
 29. 11.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3] -> size -> 41 
adversary victory points: 8
player victory points: 1 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 3. 11. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[49.038994]
 [54.18189 ]
 [54.18189 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 11.  0.  3.] 
cards in discard: [ 1.  3. 15.  3. 29. 29. 11. 10.  3. 15. 11.  0. 15. 10. 10.  1.  8.  3.
 29. 11.  0.  3. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 21. 30.  8.  5. 10.  0.  6.  9.  5.  8. 10.  1.  9.  5.] 
adversary cards in hand: [3. 6. 0. 8. 3.] 
adversary cards in discard: [14.  3.  1.  0.  3.  0. 15. 10. 11.  0.  1.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29
  3  3 22 14 15 10] -> size -> 30 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 76.7105484008789



action possibilites: [-1] 
expected returns: [[76.83025]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  3.] 
cards in discard: [ 1.  3. 15.  3. 29. 29. 11. 10.  3. 15. 11.  0. 15. 10. 10.  1.  8.  3.
 29. 11.  0.  3. 10. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 21. 30.  8.  5. 10.  0.  6.  9.  5.  8. 10.  1.  9.  4.] 
adversary cards in hand: [3. 6. 0. 8. 3.] 
adversary cards in discard: [14.  3.  1.  0.  3.  0. 15. 10. 11.  0.  1.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29
  3  3 22 14 15 10] -> size -> 30 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0 -70   0   0  64   0] 
sum of rewards: 219 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 55.27708435058594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[68.82046]
 [32.64823]
 [77.39276]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  3.] 
cards in discard: [ 1.  3. 15.  3. 29. 29. 11. 10.  3. 15. 11.  0. 15. 10. 10.  1.  8.  3.
 29. 11.  0.  3. 10. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 26. 30. 21. 30.  8.  5. 10.  0.  6.  9.  5.  8. 10.  1.  9.  4.] 
adversary cards in hand: [3. 6. 0. 8. 3.] 
adversary cards in discard: [14.  3.  1.  0.  3.  0. 15. 10. 11.  0.  1.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29
  3  3 22 14 15 10] -> size -> 30 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 76.83025360107422






Player: 1 
cards in hand: [3. 6. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 8. 3.] 
cards in discard: [14.  3.  1.  0.  3.  0. 15. 10. 11.  0.  1.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29
  3  3 22 14 15 10] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 21. 30.  8.  5. 10.  0.  6.  9.  5.  8. 10.  1.  9.  4.] 
adversary cards in hand: [ 3.  0. 10. 11. 11.] 
adversary cards in discard: [ 1.  3. 15.  3. 29. 29. 11. 10.  3. 15. 11.  0. 15. 10. 10.  1.  8.  3.
 29. 11.  0.  3. 10. 15. 11.  3. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15] -> size -> 42 
adversary victory points: 8
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3.] 
cards in discard: [14.  3.  1.  0.  3.  0. 15. 10. 11.  0.  1.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29  3  3
 22 14 15 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 21. 30.  8.  5. 10.  0.  6.  9.  5.  8. 10.  1.  9.  4.] 
adversary cards in hand: [ 3.  0. 10. 11. 11.] 
adversary cards in discard: [ 1.  3. 15.  3. 29. 29. 11. 10.  3. 15. 11.  0. 15. 10. 10.  1.  8.  3.
 29. 11.  0.  3. 10. 15. 11.  3. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15] -> size -> 42 
adversary victory points: 8
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3.] 
cards in discard: [14.  3.  1.  0.  3.  0. 15. 10. 11.  0.  1.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29  3  3
 22 14 15 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 26. 30. 21. 30.  8.  5. 10.  0.  6.  9.  5.  8. 10.  1.  9.  4.] 
adversary cards in hand: [ 3.  0. 10. 11. 11.] 
adversary cards in discard: [ 1.  3. 15.  3. 29. 29. 11. 10.  3. 15. 11.  0. 15. 10. 10.  1.  8.  3.
 29. 11.  0.  3. 10. 15. 11.  3. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15] -> size -> 42 
adversary victory points: 8
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3.] 
cards in discard: [14.  3.  1.  0.  3.  0. 15. 10. 11.  0.  1.  0. 11.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29  3  3
 22 14 15 10  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 21. 30.  8.  5. 10.  0.  6.  9.  5.  8. 10.  1.  9.  4.] 
adversary cards in hand: [ 3.  0. 10. 11. 11.] 
adversary cards in discard: [ 1.  3. 15.  3. 29. 29. 11. 10.  3. 15. 11.  0. 15. 10. 10.  1.  8.  3.
 29. 11.  0.  3. 10. 15. 11.  3. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15] -> size -> 42 
adversary victory points: 8
player victory points: 0 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 10. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11.] 
expected returns: [[44.160645]
 [44.97743 ]
 [49.42856 ]
 [49.42856 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10. 11. 11.] 
cards in discard: [ 1.  3. 15.  3. 29. 29. 11. 10.  3. 15. 11.  0. 15. 10. 10.  1.  8.  3.
 29. 11.  0.  3. 10. 15. 11.  3. 11.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 21. 30.  8.  5. 10.  0.  6.  9.  5.  8. 10.  1.  9.  4.] 
adversary cards in hand: [ 0. 10.  8.  0.  0.] 
adversary cards in discard: [14.  3.  1.  0.  3.  0. 15. 10. 11.  0.  1.  0. 11.  0.  8.  6.  3.] 
adversary owned cards: [ 0  0  0 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29  3  3
 22 14 15 10  0] -> size -> 29 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 77.39273834228516



action possibilites: [-1] 
expected returns: [[78.82142]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10. 11.] 
cards in discard: [ 1.  3. 15.  3. 29. 29. 11. 10.  3. 15. 11.  0. 15. 10. 10.  1.  8.  3.
 29. 11.  0.  3. 10. 15. 11.  3. 11.  0.  3. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 21. 30.  8.  5. 10.  0.  6.  9.  5.  8. 10.  1.  9.  3.] 
adversary cards in hand: [ 0. 10.  8.  0.  0.] 
adversary cards in discard: [14.  3.  1.  0.  3.  0. 15. 10. 11.  0.  1.  0. 11.  0.  8.  6.  3.] 
adversary owned cards: [ 0  0  0 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29  3  3
 22 14 15 10  0] -> size -> 29 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0 -80   0   0  64   0] 
sum of rewards: 239 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 50.964691162109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[70.57211 ]
 [33.517723]
 [78.82142 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10. 11.] 
cards in discard: [ 1.  3. 15.  3. 29. 29. 11. 10.  3. 15. 11.  0. 15. 10. 10.  1.  8.  3.
 29. 11.  0.  3. 10. 15. 11.  3. 11.  0.  3. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 26. 30. 21. 30.  8.  5. 10.  0.  6.  9.  5.  8. 10.  1.  9.  3.] 
adversary cards in hand: [ 0. 10.  8.  0.  0.] 
adversary cards in discard: [14.  3.  1.  0.  3.  0. 15. 10. 11.  0.  1.  0. 11.  0.  8.  6.  3.] 
adversary owned cards: [ 0  0  0 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29  3  3
 22 14 15 10  0] -> size -> 29 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 78.82141876220703






Player: 1 
cards in hand: [ 0. 10.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8.  0.  0.] 
cards in discard: [14.  3.  1.  0.  3.  0. 15. 10. 11.  0.  1.  0. 11.  0.  8.  6.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29  3  3
 22 14 15 10  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 21. 30.  8.  5. 10.  0.  6.  9.  5.  8. 10.  1.  9.  3.] 
adversary cards in hand: [ 0. 10.  0. 25. 10.] 
adversary cards in discard: [ 1.  3. 15.  3. 29. 29. 11. 10.  3. 15. 11.  0. 15. 10. 10.  1.  8.  3.
 29. 11.  0.  3. 10. 15. 11.  3. 11.  0.  3. 15. 11.  3.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15] -> size -> 43 
adversary victory points: 8
player victory points: 0 


action possibilites: [-1.  8. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0.  0. 22.] 
cards in discard: [14.  3.  1.  0.  3.  0. 15. 10. 11.  0.  1.  0. 11.  0.  8.  6.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29  3  3
 22 14 15 10  0] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 21. 30.  8.  5. 10.  0.  6.  9.  5.  8. 10.  1.  9.  3.] 
adversary cards in hand: [ 0. 10.  0. 25. 10.] 
adversary cards in discard: [ 1.  3. 15.  3. 29. 29. 11. 10.  3. 15. 11.  0. 15. 10. 10.  1.  8.  3.
 29. 11.  0.  3. 10. 15. 11.  3. 11.  0.  3. 15. 11.  3.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15] -> size -> 43 
adversary victory points: 8
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0.  0. 22.] 
cards in discard: [14.  3.  1.  0.  3.  0. 15. 10. 11.  0.  1.  0. 11.  0.  8.  6.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29  3  3
 22 14 15 10  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 26. 30. 21. 30.  8.  5. 10.  0.  6.  9.  5.  8. 10.  1.  9.  3.] 
adversary cards in hand: [ 0. 10.  0. 25. 10.] 
adversary cards in discard: [ 1.  3. 15.  3. 29. 29. 11. 10.  3. 15. 11.  0. 15. 10. 10.  1.  8.  3.
 29. 11.  0.  3. 10. 15. 11.  3. 11.  0.  3. 15. 11.  3.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15] -> size -> 43 
adversary victory points: 8
player victory points: 0 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  0. 25. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 10.] 
expected returns: [[19.140678]
 [20.071045]
 [31.499336]
 [20.071045]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 25. 10.] 
cards in discard: [ 1.  3. 15.  3. 29. 29. 11. 10.  3. 15. 11.  0. 15. 10. 10.  1.  8.  3.
 29. 11.  0.  3. 10. 15. 11.  3. 11.  0.  3. 15. 11.  3.  0. 10. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 21. 30.  8.  5. 10.  0.  6.  9.  5.  8. 10.  1.  9.  3.] 
adversary cards in hand: [ 6.  6.  3.  8. 29.] 
adversary cards in discard: [14.  3.  1.  0.  3.  0. 15. 10. 11.  0.  1.  0. 11.  0.  8.  6.  3. 10.
  0.  8.  0.  0. 22.] 
adversary owned cards: [ 0  0  0 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29  3  3
 22 14 15 10  0] -> size -> 29 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 78.82141876220703



action possibilites: [-1] 
expected returns: [[22.149292]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 10. 11.  0.] 
cards in discard: [ 1.  3. 15.  3. 29. 29. 11. 10.  3. 15. 11.  0. 15. 10. 10.  1.  8.  3.
 29. 11.  0.  3. 10. 15. 11.  3. 11.  0.  3. 15. 11.  3.  0. 10. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 21. 30.  8.  4. 10.  0.  6.  9.  5.  8. 10.  1.  9.  3.] 
adversary cards in hand: [ 6.  6.  3.  8. 29.] 
adversary cards in discard: [14.  3.  1.  0.  3.  0. 15. 10. 11.  0.  1.  0. 11.  0.  8.  6.  3. 10.
  0.  8.  0.  0. 22.  6.] 
adversary owned cards: [ 0  0  0 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29  3  3
 22 14 15 10  0  6] -> size -> 30 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 31.49932861328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[ 14.777299]
 [ 27.39864 ]
 [ 21.876106]
 [-20.52124 ]
 [ 21.830273]
 [ 25.39542 ]
 [ 22.149292]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 10. 11.  0.] 
cards in discard: [ 1.  3. 15.  3. 29. 29. 11. 10.  3. 15. 11.  0. 15. 10. 10.  1.  8.  3.
 29. 11.  0.  3. 10. 15. 11.  3. 11.  0.  3. 15. 11.  3.  0. 10. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15] -> size -> 43 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 26. 30. 21. 30.  8.  4. 10.  0.  6.  9.  5.  8. 10.  1.  9.  3.] 
adversary cards in hand: [ 6.  6.  3.  8. 29.] 
adversary cards in discard: [14.  3.  1.  0.  3.  0. 15. 10. 11.  0.  1.  0. 11.  0.  8.  6.  3. 10.
  0.  8.  0.  0. 22.  6.] 
adversary owned cards: [ 0  0  0 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29  3  3
 22 14 15 10  0  6] -> size -> 30 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 22.1492919921875



buy possibilites: [-1] 
expected returns: [[7.0520515]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 10. 11.  0.] 
cards in discard: [ 1.  3. 15.  3. 29. 29. 11. 10.  3. 15. 11.  0. 15. 10. 10.  1.  8.  3.
 29. 11.  0.  3. 10. 15. 11.  3. 11.  0.  3. 15. 11.  3.  0. 10. 11.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 21. 30.  8.  4. 10.  0.  6.  9.  5.  8. 10.  1.  9.  3.] 
adversary cards in hand: [ 6.  6.  3.  8. 29.] 
adversary cards in discard: [14.  3.  1.  0.  3.  0. 15. 10. 11.  0.  1.  0. 11.  0.  8.  6.  3. 10.
  0.  8.  0.  0. 22.  6.] 
adversary owned cards: [ 0  0  0 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29  3  3
 22 14 15 10  0  6] -> size -> 30 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0 -90   0   0  54   0] 
sum of rewards: 219 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 27.39862060546875






Player: 1 
cards in hand: [ 6.  6.  3.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  3.  8. 29.] 
cards in discard: [14.  3.  1.  0.  3.  0. 15. 10. 11.  0.  1.  0. 11.  0.  8.  6.  3. 10.
  0.  8.  0.  0. 22.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6 29  3  3
 22 14 15 10  0  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 21. 30.  8.  4. 10.  0.  6.  9.  5.  8. 10.  1.  9.  3.] 
adversary cards in hand: [10.  8. 11. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1] -> size -> 44 
adversary victory points: 8
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 3.] 
cards in discard: [14.  3.  1.  0.  3.  0. 15. 10. 11.  0.  1.  0. 11.  0.  8.  6.  3. 10.
  0.  8.  0.  0. 22.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6  3  3 22
 14 15 10  0  6] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 21. 30.  8.  4. 10.  0.  6.  9.  5.  8. 10.  1.  9.  3.] 
adversary cards in hand: [10.  8. 11. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1] -> size -> 44 
adversary victory points: 8
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3.] 
cards in discard: [14.  3.  1.  0.  3.  0. 15. 10. 11.  0.  1.  0. 11.  0.  8.  6.  3. 10.
  0.  8.  0.  0. 22.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6  3  3 22
 14 15 10  0  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 25. 30. 21. 30.  8.  4. 10.  0.  6.  9.  5.  8. 10.  1.  9.  3.] 
adversary cards in hand: [10.  8. 11. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1] -> size -> 44 
adversary victory points: 8
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3.] 
cards in discard: [14.  3.  1.  0.  3.  0. 15. 10. 11.  0.  1.  0. 11.  0.  8.  6.  3. 10.
  0.  8.  0.  0. 22.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6  3  3 22
 14 15 10  0  6  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 21. 30.  8.  4. 10.  0.  6.  9.  5.  8. 10.  1.  9.  3.] 
adversary cards in hand: [10.  8. 11. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1] -> size -> 44 
adversary victory points: 8
player victory points: -1 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [10.  8. 11. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11. 11. 29.] 
expected returns: [[27.37223 ]
 [27.331573]
 [25.688587]
 [32.674236]
 [32.674236]
 [36.675568]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 11. 11. 29.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 21. 30.  8.  4. 10.  0.  6.  9.  5.  8. 10.  1.  9.  3.] 
adversary cards in hand: [11.  0.  0. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6  3  3 22
 14 15 10  0  6  0] -> size -> 30 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 7.052051544189453



action possibilites: [-1. 10.  8. 11. 11.] 
expected returns: [[38.969357]
 [41.671593]
 [38.744396]
 [46.651398]
 [46.651398]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 11. 11.] 
cards in discard: [1.] 
cards in deck: 38 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1] -> size -> 44 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 25. 30. 21. 30.  8.  4. 10.  0.  6.  9.  5.  8. 10.  1.  9.  3.] 
adversary cards in hand: [11.  0.  0. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6  3  3 22
 14 15 10  0  6  0] -> size -> 30 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 32.625144958496094



action possibilites: [-1] 
expected returns: [[73.71556]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 11.] 
cards in discard: [ 1. 15.] 
cards in deck: 38 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15] -> size -> 45 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 25. 30. 21. 30.  8.  4. 10.  0.  6.  9.  5.  8. 10.  1.  9.  2.] 
adversary cards in hand: [11.  0.  0. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6  3  3 22
 14 15 10  0  6  0] -> size -> 30 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[  -5    0    0  270    0    0   40    0    0    0    0 -100    0    0
   64    0] 
sum of rewards: 269 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 49.43975830078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[63.566544]
 [26.169426]
 [73.88512 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 11.] 
cards in discard: [ 1. 15.] 
cards in deck: 38 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 25. 30. 21. 30.  8.  4. 10.  0.  6.  9.  5.  8. 10.  1.  9.  2.] 
adversary cards in hand: [11.  0.  0. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6  3  3 22
 14 15 10  0  6  0] -> size -> 30 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action -1
Learning step: 0
desired expected reward: 73.71556091308594






Player: 1 
cards in hand: [11.  0.  0. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 11.  6.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6  3  3 22
 14 15 10  0  6  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 21. 30.  8.  4. 10.  0.  6.  9.  5.  8. 10.  1.  9.  2.] 
adversary cards in hand: [15.  0. 15.  3.  3.] 
adversary cards in discard: [ 1. 15. 29. 11. 10.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15] -> size -> 45 
adversary victory points: 8
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  6.] 
cards in discard: [10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6  3  3 22
 14 15 10  0  6  0 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 21. 30.  8.  4. 10.  0.  6.  9.  5.  8. 10.  0.  9.  2.] 
adversary cards in hand: [15.  0. 15.  3.  3.] 
adversary cards in discard: [ 1. 15. 29. 11. 10.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15] -> size -> 45 
adversary victory points: 8
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  6.] 
cards in discard: [10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6  3  3 22
 14 15 10  0  6  0 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 25. 30. 21. 30.  8.  4. 10.  0.  6.  9.  5.  8. 10.  0.  9.  2.] 
adversary cards in hand: [15.  0. 15.  3.  3.] 
adversary cards in discard: [ 1. 15. 29. 11. 10.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15] -> size -> 45 
adversary victory points: 8
player victory points: -1 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [15.  0. 15.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
expected returns: [[21.484768]
 [14.248393]
 [14.248393]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 15.  3.  3.] 
cards in discard: [ 1. 15. 29. 11. 10.  8. 11.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 21. 30.  8.  4. 10.  0.  6.  9.  5.  8. 10.  0.  9.  2.] 
adversary cards in hand: [ 6.  8. 10.  0.  3.] 
adversary cards in discard: [10. 11.  0.  0. 11.  6.] 
adversary owned cards: [ 0  0  0 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6  3  3 22
 14 15 10  0  6  0 10] -> size -> 31 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 73.88510131835938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 14.273189]
 [-17.774094]
 [ 21.444878]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0. 15.  3.  3.] 
cards in discard: [ 1. 15. 29. 11. 10.  8. 11.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 25. 30. 21. 30.  8.  4. 10.  0.  6.  9.  5.  8. 10.  0.  9.  2.] 
adversary cards in hand: [ 6.  8. 10.  0.  3.] 
adversary cards in discard: [10. 11.  0.  0. 11.  6.] 
adversary owned cards: [ 0  0  0 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6  3  3 22
 14 15 10  0  6  0 10] -> size -> 31 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 21.484779357910156



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 6.  8. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8. 10.  0.  3.] 
cards in discard: [10. 11.  0.  0. 11.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11  1  8  0  6  3  3  8  6  8 11  0  6  0  1 10  0  6  3  3 22
 14 15 10  0  6  0 10] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 21. 30.  8.  4. 10.  0.  6.  9.  5.  8. 10.  0.  9.  2.] 
adversary cards in hand: [10.  0.  0. 10. 10.] 
adversary cards in discard: [ 1. 15. 29. 11. 10.  8. 11. 15.  0. 15.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15] -> size -> 45 
adversary victory points: 8
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [10. 11.  0.  0. 11.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 11  1  8  0  3  3  8  6  8 11  0  6  0  1  0  6  3  3 22 14 15
 10  0  6  0 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 21. 30.  8.  4. 10.  0.  6.  9.  5.  8. 10.  0.  9.  2.] 
adversary cards in hand: [10.  0.  0. 10. 10.] 
adversary cards in discard: [ 1. 15. 29. 11. 10.  8. 11. 15.  0. 15.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15] -> size -> 45 
adversary victory points: 8
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [10. 11.  0.  0. 11.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 11  1  8  0  3  3  8  6  8 11  0  6  0  1  0  6  3  3 22 14 15
 10  0  6  0 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 25. 30. 21. 30.  8.  4. 10.  0.  6.  9.  5.  8. 10.  0.  9.  2.] 
adversary cards in hand: [10.  0.  0. 10. 10.] 
adversary cards in discard: [ 1. 15. 29. 11. 10.  8. 11. 15.  0. 15.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15] -> size -> 45 
adversary victory points: 8
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [10. 11.  0.  0. 11.  6.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 11  1  8  0  3  3  8  6  8 11  0  6  0  1  0  6  3  3 22 14 15
 10  0  6  0 10  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 25. 30. 21. 30.  8.  4. 10.  0.  6.  9.  5.  8. 10.  0.  9.  2.] 
adversary cards in hand: [10.  0.  0. 10. 10.] 
adversary cards in discard: [ 1. 15. 29. 11. 10.  8. 11. 15.  0. 15.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15] -> size -> 45 
adversary victory points: 8
player victory points: 0 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [10.  0.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10.] 
expected returns: [[64.99911]
 [67.97665]
 [67.97665]
 [67.97665]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 10. 10.] 
cards in discard: [ 1. 15. 29. 11. 10.  8. 11. 15.  0. 15.  3.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 21. 30.  8.  4. 10.  0.  6.  9.  5.  8. 10.  0.  9.  2.] 
adversary cards in hand: [15.  3.  0. 14.  6.] 
adversary cards in discard: [10. 11.  0.  0. 11.  6.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0 11  1  8  0  3  3  8  6  8 11  0  6  0  1  0  6  3  3 22 14 15
 10  0  6  0 10  0] -> size -> 30 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 21.44489288330078



action possibilites: [-1. 10. 10.] 
expected returns: [[61.97412]
 [65.29909]
 [65.29909]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 10.  0.] 
cards in discard: [ 1. 15. 29. 11. 10.  8. 11. 15.  0. 15.  3.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15] -> size -> 45 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 21. 30.  8.  4. 10.  0.  6.  9.  5.  8. 10.  0.  9.  2.] 
adversary cards in hand: [15.  3.  0. 14.  6.] 
adversary cards in discard: [10. 11.  0.  0. 11.  6.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0 11  1  8  0  3  3  8  6  8 11  0  6  0  1  0  6  3  3 22 14 15
 10  0  6  0 10  0] -> size -> 30 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 67.97665405273438



action possibilites: [-1. 10. 11.] 
expected returns: [[71.504974]
 [72.963974]
 [78.14007 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0. 11.] 
cards in discard: [ 1. 15. 29. 11. 10.  8. 11. 15.  0. 15.  3.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15] -> size -> 45 
action values: 3 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 21. 30.  8.  4. 10.  0.  6.  9.  5.  8. 10.  0.  9.  2.] 
adversary cards in hand: [15.  3.  0. 14.  6.] 
adversary cards in discard: [10. 11.  0.  0. 11.  6.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0 11  1  8  0  3  3  8  6  8 11  0  6  0  1  0  6  3  3 22 14 15
 10  0  6  0 10  0] -> size -> 30 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 65.2990951538086



action possibilites: [-1. 10.] 
expected returns: [[63.80571]
 [65.29512]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.] 
cards in discard: [ 1. 15. 29. 11. 10.  8. 11. 15.  0. 15.  3.  3.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [10. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1] -> size -> 46 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 21. 30.  8.  4. 10.  0.  6.  9.  5.  8. 10.  0.  9.  2.] 
adversary cards in hand: [15.  3.  0. 14.  6.] 
adversary cards in discard: [10. 11.  0.  0. 11.  6.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0 11  1  8  0  3  3  8  6  8 11  0  6  0  1  0  6  3  3 22 14 15
 10  0  6  0 10  0] -> size -> 30 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[  -5    0    0  240    0    0   60    0    0    0    0 -110    0    0
   27    0] 
sum of rewards: 212 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 77.61647033691406



action possibilites: [-1. 29.] 
expected returns: [[57.642223]
 [70.32439 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.] 
cards in discard: [ 1. 15. 29. 11. 10.  8. 11. 15.  0. 15.  3.  3.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10. 10. 11. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1] -> size -> 46 
action values: 3 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 21. 30.  8.  4. 10.  0.  6.  9.  5.  8. 10.  0.  9.  2.] 
adversary cards in hand: [15.  3.  0. 14.  6.] 
adversary cards in discard: [10. 11.  0.  0. 11.  6.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0 11  1  8  0  3  3  8  6  8 11  0  6  0  1  0  6  3  3 22 14 15
 10  0  6  0 10  0] -> size -> 30 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 65.29512786865234



action possibilites: [-1. 10.] 
expected returns: [[96.04151]
 [97.73831]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.] 
cards in discard: [ 1. 15. 29. 11. 10.  8. 11. 15.  0. 15.  3.  3.  1.  0.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10. 10. 11. 10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1] -> size -> 46 
action values: 3 
buys: 0 
player value: 1 
card supply: [23. 24. 30. 21. 30.  8.  4. 10.  0.  6.  9.  5.  8. 10.  0.  9.  2.] 
adversary cards in hand: [15.  3.  0. 14.  6.] 
adversary cards in discard: [10. 11.  0.  0. 11.  6.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0 11  1  8  0  3  3  8  6  8 11  0  6  0  1  0  6  3  3 22 14 15
 10  0  6  0 10  0] -> size -> 30 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 62.36305236816406



action possibilites: [-1. 15.] 
expected returns: [[99.88341 ]
 [91.489624]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.] 
cards in discard: [ 1. 15. 29. 11. 10.  8. 11. 15.  0. 15.  3.  3.  1.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10. 10. 11. 10. 29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1] -> size -> 46 
action values: 4 
buys: 0 
player value: 1 
card supply: [23. 24. 30. 21. 30.  8.  4. 10.  0.  6.  9.  5.  8. 10.  0.  9.  2.] 
adversary cards in hand: [15.  3.  0. 14.  6.] 
adversary cards in discard: [10. 11.  0.  0. 11.  6.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0 11  1  8  0  3  3  8  6  8 11  0  6  0  1  0  6  3  3 22 14 15
 10  0  6  0 10  0] -> size -> 30 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0 120   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 97.73831176757812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[91.56233 ]
 [99.242645]
 [57.196815]
 [97.53557 ]
 [99.66459 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.] 
cards in discard: [ 1. 15. 29. 11. 10.  8. 11. 15.  0. 15.  3.  3.  1.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10. 10. 11. 10. 29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 24. 30. 21. 30.  8.  4. 10.  0.  6.  9.  5.  8. 10.  0.  9.  2.] 
adversary cards in hand: [15.  3.  0. 14.  6.] 
adversary cards in discard: [10. 11.  0.  0. 11.  6.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0 11  1  8  0  3  3  8  6  8 11  0  6  0  1  0  6  3  3 22 14 15
 10  0  6  0 10  0] -> size -> 30 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0 120   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 99.88338470458984






Player: 1 
cards in hand: [15.  3.  0. 14.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0. 14.  6.] 
cards in discard: [10. 11.  0.  0. 11.  6.  0.  8.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11  1  8  0  3  3  8  6  8 11  0  6  0  1  0  6  3  3 22 14 15
 10  0  6  0 10  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 21. 30.  8.  4. 10.  0.  6.  9.  5.  8. 10.  0.  9.  2.] 
adversary cards in hand: [29.  1. 25.  1.  0.] 
adversary cards in discard: [ 1. 15. 29. 11. 10.  8. 11. 15.  0. 15.  3.  3.  1.  0.  0. 10. 10. 11.
 10. 29. 10.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1] -> size -> 46 
adversary victory points: 8
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  0. 14.  6.] 
cards in discard: [10. 11.  0.  0. 11.  6.  0.  8.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11  1  8  0  3  3  8  6  8 11  0  6  0  1  0  6  3  3 22 14 15
 10  0  6  0 10  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 24. 30. 21. 30.  8.  4. 10.  0.  6.  9.  5.  8. 10.  0.  9.  2.] 
adversary cards in hand: [29.  1. 25.  1.  0.] 
adversary cards in discard: [ 1. 15. 29. 11. 10.  8. 11. 15.  0. 15.  3.  3.  1.  0.  0. 10. 10. 11.
 10. 29. 10.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1] -> size -> 46 
adversary victory points: 8
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  0. 14.  6.] 
cards in discard: [10. 11.  0.  0. 11.  6.  0.  8.  0.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11  1  8  0  3  3  8  6  8 11  0  6  0  1  0  6  3  3 22 14 15
 10  0  6  0 10  0  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 24. 30. 21. 30.  8.  4. 10.  0.  6.  9.  5.  8. 10.  0.  9.  2.] 
adversary cards in hand: [29.  1. 25.  1.  0.] 
adversary cards in discard: [ 1. 15. 29. 11. 10.  8. 11. 15.  0. 15.  3.  3.  1.  0.  0. 10. 10. 11.
 10. 29. 10.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1] -> size -> 46 
adversary victory points: 8
player victory points: 0 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [29.  1. 25.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[79.32353 ]
 [88.65689 ]
 [93.044754]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1. 25.  1.  0.] 
cards in discard: [ 1. 15. 29. 11. 10.  8. 11. 15.  0. 15.  3.  3.  1.  0.  0. 10. 10. 11.
 10. 29. 10.  0. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 21. 30.  8.  4. 10.  0.  6.  9.  5.  8. 10.  0.  9.  2.] 
adversary cards in hand: [ 1. 22.  3.  0.  6.] 
adversary cards in discard: [10. 11.  0.  0. 11.  6.  0.  8.  0.  3.  0. 15.  3.  0. 14.  6.] 
adversary owned cards: [ 0  0  0 11  1  8  0  3  3  8  6  8 11  0  6  0  1  0  6  3  3 22 14 15
 10  0  6  0 10  0  0] -> size -> 31 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 99.66458892822266



action possibilites: [-1] 
expected returns: [[62.042114]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  1.  0.  3. 15.] 
cards in discard: [ 1. 15. 29. 11. 10.  8. 11. 15.  0. 15.  3.  3.  1.  0.  0. 10. 10. 11.
 10. 29. 10.  0. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 21. 30.  8.  3. 10.  0.  6.  9.  5.  8. 10.  0.  9.  2.] 
adversary cards in hand: [ 1. 22.  3.  0.  6.] 
adversary cards in discard: [10. 11.  0.  0. 11.  6.  0.  8.  0.  3.  0. 15.  3.  0. 14.  6.  6.] 
adversary owned cards: [ 0  0  0 11  1  8  0  3  3  8  6  8 11  0  6  0  1  0  6  3  3 22 14 15
 10  0  6  0 10  0  0  6] -> size -> 32 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 93.0447769165039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[52.96733 ]
 [66.05861 ]
 [59.95733 ]
 [37.96416 ]
 [19.3461  ]
 [68.08925 ]
 [58.67824 ]
 [74.30292 ]
 [69.84965 ]
 [32.203514]
 [58.97785 ]
 [41.21214 ]
 [52.509132]
 [62.04212 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  1.  0.  3. 15.] 
cards in discard: [ 1. 15. 29. 11. 10.  8. 11. 15.  0. 15.  3.  3.  1.  0.  0. 10. 10. 11.
 10. 29. 10.  0. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1] -> size -> 46 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 24. 30. 21. 30.  8.  3. 10.  0.  6.  9.  5.  8. 10.  0.  9.  2.] 
adversary cards in hand: [ 1. 22.  3.  0.  6.] 
adversary cards in discard: [10. 11.  0.  0. 11.  6.  0.  8.  0.  3.  0. 15.  3.  0. 14.  6.  6.] 
adversary owned cards: [ 0  0  0 11  1  8  0  3  3  8  6  8 11  0  6  0  1  0  6  3  3 22 14 15
 10  0  6  0 10  0  0  6] -> size -> 32 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 62.0421142578125



buy possibilites: [-1] 
expected returns: [[54.078003]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  1.  0.  3. 15.] 
cards in discard: [ 1. 15. 29. 11. 10.  8. 11. 15.  0. 15.  3.  3.  1.  0.  0. 10. 10. 11.
 10. 29. 10.  0. 15. 25.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 21. 30.  8.  3. 10.  0.  6.  8.  5.  8. 10.  0.  9.  2.] 
adversary cards in hand: [ 1. 22.  3.  0.  6.] 
adversary cards in discard: [10. 11.  0.  0. 11.  6.  0.  8.  0.  3.  0. 15.  3.  0. 14.  6.  6.] 
adversary owned cards: [ 0  0  0 11  1  8  0  3  3  8  6  8 11  0  6  0  1  0  6  3  3 22 14 15
 10  0  6  0 10  0  0  6] -> size -> 32 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[  -5    0    0  240    0    0   20    0    0    0    0 -120    0    0
  250    0] 
sum of rewards: 385 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 74.30292510986328






Player: 1 
cards in hand: [ 1. 22.  3.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 22.  3.  0.  6.] 
cards in discard: [10. 11.  0.  0. 11.  6.  0.  8.  0.  3.  0. 15.  3.  0. 14.  6.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11  1  8  0  3  3  8  6  8 11  0  6  0  1  0  6  3  3 22 14 15
 10  0  6  0 10  0  0  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 21. 30.  8.  3. 10.  0.  6.  8.  5.  8. 10.  0.  9.  2.] 
adversary cards in hand: [ 3. 10. 11.  3.  3.] 
adversary cards in discard: [ 1. 15. 29. 11. 10.  8. 11. 15.  0. 15.  3.  3.  1.  0.  0. 10. 10. 11.
 10. 29. 10.  0. 15. 25. 25. 29.  1.  1.  0.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25] -> size -> 47 
adversary victory points: 8
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 6. 8. 0. 0.] 
cards in discard: [10. 11.  0.  0. 11.  6.  0.  8.  0.  3.  0. 15.  3.  0. 14.  6.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0 11  1  8  0  3  3  8  6  8 11  0  6  0  1  0  6  3  3 22 14 15
 10  0  6  0 10  0  0  6] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 21. 30.  8.  3. 10.  0.  6.  8.  5.  8. 10.  0.  9.  2.] 
adversary cards in hand: [ 3. 10. 11.  3.  3.] 
adversary cards in discard: [ 1. 15. 29. 11. 10.  8. 11. 15.  0. 15.  3.  3.  1.  0.  0. 10. 10. 11.
 10. 29. 10.  0. 15. 25. 25. 29.  1.  1.  0.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25] -> size -> 47 
adversary victory points: 8
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 6. 8. 0. 0.] 
cards in discard: [10. 11.  0.  0. 11.  6.  0.  8.  0.  3.  0. 15.  3.  0. 14.  6.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0 11  1  8  0  3  3  8  6  8 11  0  6  0  1  0  6  3  3 22 14 15
 10  0  6  0 10  0  0  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 24. 30. 21. 30.  8.  3. 10.  0.  6.  8.  5.  8. 10.  0.  9.  2.] 
adversary cards in hand: [ 3. 10. 11.  3.  3.] 
adversary cards in discard: [ 1. 15. 29. 11. 10.  8. 11. 15.  0. 15.  3.  3.  1.  0.  0. 10. 10. 11.
 10. 29. 10.  0. 15. 25. 25. 29.  1.  1.  0.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25] -> size -> 47 
adversary victory points: 8
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 6. 8. 0. 0.] 
cards in discard: [10. 11.  0.  0. 11.  6.  0.  8.  0.  3.  0. 15.  3.  0. 14.  6.  6. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0 11  1  8  0  3  3  8  6  8 11  0  6  0  1  0  6  3  3 22 14 15
 10  0  6  0 10  0  0  6 14] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 24. 30. 21. 30.  8.  3. 10.  0.  6.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [ 3. 10. 11.  3.  3.] 
adversary cards in discard: [ 1. 15. 29. 11. 10.  8. 11. 15.  0. 15.  3.  3.  1.  0.  0. 10. 10. 11.
 10. 29. 10.  0. 15. 25. 25. 29.  1.  1.  0.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25] -> size -> 47 
adversary victory points: 8
player victory points: -1 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 11.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[57.049118]
 [55.307632]
 [59.774216]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11.  3.  3.] 
cards in discard: [ 1. 15. 29. 11. 10.  8. 11. 15.  0. 15.  3.  3.  1.  0.  0. 10. 10. 11.
 10. 29. 10.  0. 15. 25. 25. 29.  1.  1.  0.  3. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 21. 30.  8.  3. 10.  0.  6.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [3. 1. 0. 8. 6.] 
adversary cards in discard: [10. 11.  0.  0. 11.  6.  0.  8.  0.  3.  0. 15.  3.  0. 14.  6.  6. 14.
 22.  1.  3.  0.  6.  8.  0.  0.] 
adversary owned cards: [ 0  0  0 11  1  8  0  3  3  8  6  8 11  0  6  0  1  0  6  3  3 22 14 15
 10  0  6  0 10  0  0  6 14] -> size -> 33 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 54.0780029296875



action possibilites: [-1] 
expected returns: [[56.873405]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  3.] 
cards in discard: [ 1. 15. 29. 11. 10.  8. 11. 15.  0. 15.  3.  3.  1.  0.  0. 10. 10. 11.
 10. 29. 10.  0. 15. 25. 25. 29.  1.  1.  0.  3. 15.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 21. 30.  8.  3. 10.  0.  6.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [3. 1. 0. 8. 6.] 
adversary cards in discard: [10. 11.  0.  0. 11.  6.  0.  8.  0.  3.  0. 15.  3.  0. 14.  6.  6. 14.
 22.  1.  3.  0.  6.  8.  0.  0.] 
adversary owned cards: [ 0  0  0 11  1  8  0  3  3  8  6  8 11  0  6  0  1  0  6  3  3 22 14 15
 10  0  6  0 10  0  0  6 14] -> size -> 33 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[  -5    0    0  270    0    0   20    0    0    0    0 -130    0    0
   27    0] 
sum of rewards: 182 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 61.214691162109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[48.45086 ]
 [13.447127]
 [56.873436]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  3.] 
cards in discard: [ 1. 15. 29. 11. 10.  8. 11. 15.  0. 15.  3.  3.  1.  0.  0. 10. 10. 11.
 10. 29. 10.  0. 15. 25. 25. 29.  1.  1.  0.  3. 15.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1] -> size -> 48 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 23. 30. 21. 30.  8.  3. 10.  0.  6.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [3. 1. 0. 8. 6.] 
adversary cards in discard: [10. 11.  0.  0. 11.  6.  0.  8.  0.  3.  0. 15.  3.  0. 14.  6.  6. 14.
 22.  1.  3.  0.  6.  8.  0.  0.] 
adversary owned cards: [ 0  0  0 11  1  8  0  3  3  8  6  8 11  0  6  0  1  0  6  3  3 22 14 15
 10  0  6  0 10  0  0  6 14] -> size -> 33 
adversary victory points: -1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 56.87340545654297






Player: 1 
cards in hand: [3. 1. 0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 8. 6.] 
cards in discard: [10. 11.  0.  0. 11.  6.  0.  8.  0.  3.  0. 15.  3.  0. 14.  6.  6. 14.
 22.  1.  3.  0.  6.  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11  1  8  0  3  3  8  6  8 11  0  6  0  1  0  6  3  3 22 14 15
 10  0  6  0 10  0  0  6 14] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 21. 30.  8.  3. 10.  0.  6.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [ 0. 29.  3. 10.  0.] 
adversary cards in discard: [ 1. 15. 29. 11. 10.  8. 11. 15.  0. 15.  3.  3.  1.  0.  0. 10. 10. 11.
 10. 29. 10.  0. 15. 25. 25. 29.  1.  1.  0.  3. 15.  1. 11.  3. 10.  3.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1] -> size -> 48 
adversary victory points: 8
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [10. 11.  0.  0. 11.  6.  0.  8.  0.  3.  0. 15.  3.  0. 14.  6.  6. 14.
 22.  1.  3.  0.  6.  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 14 15 10  0  6
  0 10  0  0  6 14] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 21. 30.  8.  3. 10.  0.  6.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [ 0. 29.  3. 10.  0.] 
adversary cards in discard: [ 1. 15. 29. 11. 10.  8. 11. 15.  0. 15.  3.  3.  1.  0.  0. 10. 10. 11.
 10. 29. 10.  0. 15. 25. 25. 29.  1.  1.  0.  3. 15.  1. 11.  3. 10.  3.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1] -> size -> 48 
adversary victory points: 8
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [10. 11.  0.  0. 11.  6.  0.  8.  0.  3.  0. 15.  3.  0. 14.  6.  6. 14.
 22.  1.  3.  0.  6.  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 14 15 10  0  6
  0 10  0  0  6 14] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 23. 30. 21. 30.  8.  3. 10.  0.  6.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [ 0. 29.  3. 10.  0.] 
adversary cards in discard: [ 1. 15. 29. 11. 10.  8. 11. 15.  0. 15.  3.  3.  1.  0.  0. 10. 10. 11.
 10. 29. 10.  0. 15. 25. 25. 29.  1.  1.  0.  3. 15.  1. 11.  3. 10.  3.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1] -> size -> 48 
adversary victory points: 8
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [10. 11.  0.  0. 11.  6.  0.  8.  0.  3.  0. 15.  3.  0. 14.  6.  6. 14.
 22.  1.  3.  0.  6.  8.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 14 15 10  0  6
  0 10  0  0  6 14  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 21. 30.  8.  3. 10.  0.  6.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [ 0. 29.  3. 10.  0.] 
adversary cards in discard: [ 1. 15. 29. 11. 10.  8. 11. 15.  0. 15.  3.  3.  1.  0.  0. 10. 10. 11.
 10. 29. 10.  0. 15. 25. 25. 29.  1.  1.  0.  3. 15.  1. 11.  3. 10.  3.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1] -> size -> 48 
adversary victory points: 8
player victory points: 0 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[25.931221]
 [39.761917]
 [33.380913]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3. 10.  0.] 
cards in discard: [ 1. 15. 29. 11. 10.  8. 11. 15.  0. 15.  3.  3.  1.  0.  0. 10. 10. 11.
 10. 29. 10.  0. 15. 25. 25. 29.  1.  1.  0.  3. 15.  1. 11.  3. 10.  3.
  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 21. 30.  8.  3. 10.  0.  6.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [ 0. 10.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 14 15 10  0  6
  0 10  0  0  6 14  0] -> size -> 31 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 56.87340545654297



action possibilites: [-1. 15.] 
expected returns: [[24.376137]
 [19.95214 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15.] 
cards in discard: [ 1. 15. 29. 11. 10.  8. 11. 15.  0. 15.  3.  3.  1.  0.  0. 10. 10. 11.
 10. 29. 10.  0. 15. 25. 25. 29.  1.  1.  0.  3. 15.  1. 11.  3. 10.  3.
  3.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1] -> size -> 48 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 23. 30. 21. 30.  8.  3. 10.  0.  6.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [ 0. 10.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 14 15 10  0  6
  0 10  0  0  6 14  0] -> size -> 31 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 36.166534423828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[18.442749]
 [25.600483]
 [-9.681257]
 [23.523903]
 [24.376137]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 15.] 
cards in discard: [ 1. 15. 29. 11. 10.  8. 11. 15.  0. 15.  3.  3.  1.  0.  0. 10. 10. 11.
 10. 29. 10.  0. 15. 25. 25. 29.  1.  1.  0.  3. 15.  1. 11.  3. 10.  3.
  3.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1] -> size -> 48 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 23. 30. 21. 30.  8.  3. 10.  0.  6.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [ 0. 10.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 14 15 10  0  6
  0 10  0  0  6 14  0] -> size -> 31 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 24.376140594482422



buy possibilites: [-1] 
expected returns: [[-12.2292795]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 15.] 
cards in discard: [ 1. 15. 29. 11. 10.  8. 11. 15.  0. 15.  3.  3.  1.  0.  0. 10. 10. 11.
 10. 29. 10.  0. 15. 25. 25. 29.  1.  1.  0.  3. 15.  1. 11.  3. 10.  3.
  3.  0. 10.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 20. 30.  8.  3. 10.  0.  6.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [ 0. 10.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 14 15 10  0  6
  0 10  0  0  6 14  0] -> size -> 31 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  270    0    0   20    0    0    0    0 -140    0    0
   16    0] 
sum of rewards: 161 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 25.60049819946289






Player: 1 
cards in hand: [ 0. 10.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 14 15 10  0  6
  0 10  0  0  6 14  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 20. 30.  8.  3. 10.  0.  6.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [ 3. 11. 11. 11. 11.] 
adversary cards in discard: [ 1. 15. 29. 11. 10.  8. 11. 15.  0. 15.  3.  3.  1.  0.  0. 10. 10. 11.
 10. 29. 10.  0. 15. 25. 25. 29.  1.  1.  0.  3. 15.  1. 11.  3. 10.  3.
  3.  0. 10.  3. 29.  3.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3] -> size -> 49 
adversary victory points: 9
player victory points: 0 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  6.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 14 15 10  0  6
  0 10  0  0  6 14  0] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 20. 30.  8.  3. 10.  0.  6.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [ 3. 11. 11. 11. 11.] 
adversary cards in discard: [ 1. 15. 29. 11. 10.  8. 11. 15.  0. 15.  3.  3.  1.  0.  0. 10. 10. 11.
 10. 29. 10.  0. 15. 25. 25. 29.  1.  1.  0.  3. 15.  1. 11.  3. 10.  3.
  3.  0. 10.  3. 29.  3.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3] -> size -> 49 
adversary victory points: 9
player victory points: 0 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 14 15 10  0  6
  0 10  0  0  6 14  0] -> size -> 31 
action values: 3 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 20. 30.  8.  3. 10.  0.  6.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [ 3. 11. 11. 11. 11.] 
adversary cards in discard: [ 1. 15. 29. 11. 10.  8. 11. 15.  0. 15.  3.  3.  1.  0.  0. 10. 10. 11.
 10. 29. 10.  0. 15. 25. 25. 29.  1.  1.  0.  3. 15.  1. 11.  3. 10.  3.
  3.  0. 10.  3. 29.  3.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3] -> size -> 49 
adversary victory points: 9
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 14 15 10  0  6
  0 10  0  0  6 14  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 23. 30. 20. 30.  8.  3. 10.  0.  6.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [ 3. 11. 11. 11. 11.] 
adversary cards in discard: [ 1. 15. 29. 11. 10.  8. 11. 15.  0. 15.  3.  3.  1.  0.  0. 10. 10. 11.
 10. 29. 10.  0. 15. 25. 25. 29.  1.  1.  0.  3. 15.  1. 11.  3. 10.  3.
  3.  0. 10.  3. 29.  3.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3] -> size -> 49 
adversary victory points: 9
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 14 15 10  0  6
  0 10  0  0  6 14  0  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 23. 30. 19. 30.  8.  3. 10.  0.  6.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [ 3. 11. 11. 11. 11.] 
adversary cards in discard: [ 1. 15. 29. 11. 10.  8. 11. 15.  0. 15.  3.  3.  1.  0.  0. 10. 10. 11.
 10. 29. 10.  0. 15. 25. 25. 29.  1.  1.  0.  3. 15.  1. 11.  3. 10.  3.
  3.  0. 10.  3. 29.  3.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3] -> size -> 49 
adversary victory points: 9
player victory points: 1 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 3. 11. 11. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11. 11.] 
expected returns: [[ 5.1094112]
 [10.074141 ]
 [10.074141 ]
 [10.074141 ]
 [10.074141 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 11. 11. 11.] 
cards in discard: [ 1. 15. 29. 11. 10.  8. 11. 15.  0. 15.  3.  3.  1.  0.  0. 10. 10. 11.
 10. 29. 10.  0. 15. 25. 25. 29.  1.  1.  0.  3. 15.  1. 11.  3. 10.  3.
  3.  0. 10.  3. 29.  3.  0. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 19. 30.  8.  3. 10.  0.  6.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [ 6.  0.  0. 11.  0.] 
adversary cards in discard: [ 3. 10. 10.  0.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 14 15 10  0  6
  0 10  0  0  6 14  0  3] -> size -> 32 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: -12.229279518127441



action possibilites: [-1] 
expected returns: [[9.643707]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 11. 11.] 
cards in discard: [ 1. 15. 29. 11. 10.  8. 11. 15.  0. 15.  3.  3.  1.  0.  0. 10. 10. 11.
 10. 29. 10.  0. 15. 25. 25. 29.  1.  1.  0.  3. 15.  1. 11.  3. 10.  3.
  3.  0. 10.  3. 29.  3.  0. 15.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 19. 30.  8.  3. 10.  0.  6.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [ 6.  0.  0. 11.  0.] 
adversary cards in discard: [ 3. 10. 10.  0.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 14 15 10  0  6
  0 10  0  0  6 14  0  3] -> size -> 32 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  240    0    0   20    0    0    0    0 -150    0    0
   27    0] 
sum of rewards: 132 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 9.887925148010254





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-3.2596111e-02]
 [-4.3349228e+01]
 [ 9.6437216e+00]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 11. 11.] 
cards in discard: [ 1. 15. 29. 11. 10.  8. 11. 15.  0. 15.  3.  3.  1.  0.  0. 10. 10. 11.
 10. 29. 10.  0. 15. 25. 25. 29.  1.  1.  0.  3. 15.  1. 11.  3. 10.  3.
  3.  0. 10.  3. 29.  3.  0. 15.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1] -> size -> 50 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 22. 30. 19. 30.  8.  3. 10.  0.  6.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [ 6.  0.  0. 11.  0.] 
adversary cards in discard: [ 3. 10. 10.  0.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 14 15 10  0  6
  0 10  0  0  6 14  0  3] -> size -> 32 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 9.643707275390625






Player: 1 
cards in hand: [ 6.  0.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 11.  0.] 
cards in discard: [ 3. 10. 10.  0.  0.  0.  6.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 14 15 10  0  6
  0 10  0  0  6 14  0  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 19. 30.  8.  3. 10.  0.  6.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [11.  1. 11. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1] -> size -> 50 
adversary victory points: 9
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0. 11.  0.] 
cards in discard: [ 3. 10. 10.  0.  0.  0.  6.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 14 15 10  0  6
  0 10  0  0  6 14  0  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 22. 30. 19. 30.  8.  3. 10.  0.  6.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [11.  1. 11. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1] -> size -> 50 
adversary victory points: 9
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0. 11.  0.] 
cards in discard: [ 3. 10. 10.  0.  0.  0.  6.  0.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 14 15 10  0  6
  0 10  0  0  6 14  0  3  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 22. 30. 19. 30.  8.  3. 10.  0.  5.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [11.  1. 11. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1] -> size -> 50 
adversary victory points: 9
player victory points: 1 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [11.  1. 11. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10.] 
expected returns: [[34.276825]
 [41.000046]
 [41.000046]
 [35.43691 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1. 11. 10.  3.] 
cards in discard: [] 
cards in deck: 45 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 19. 30.  8.  3. 10.  0.  5.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [ 3. 14. 11.  0.  3.] 
adversary cards in discard: [ 3. 10. 10.  0.  0.  0.  6.  0.  8.  6.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 14 15 10  0  6
  0 10  0  0  6 14  0  3  8] -> size -> 33 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 9.643707275390625



action possibilites: [-1] 
expected returns: [[28.073048]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11. 10.  3.] 
cards in discard: [1.] 
cards in deck: 45 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 19. 30.  8.  3. 10.  0.  5.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [ 3. 14. 11.  0.  3.] 
adversary cards in discard: [ 3. 10. 10.  0.  0.  0.  6.  0.  8.  6.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 14 15 10  0  6
  0 10  0  0  6 14  0  3  8] -> size -> 33 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  240    0    0   20    0    0    0    0 -160    0    0
   27    0] 
sum of rewards: 122 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 39.75335693359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 21.318916]
 [ 27.40247 ]
 [-16.2613  ]
 [ 28.859447]
 [ 26.834908]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11. 10.  3.] 
cards in discard: [1.] 
cards in deck: 45 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1] -> size -> 51 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 21. 30. 19. 30.  8.  3. 10.  0.  5.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [ 3. 14. 11.  0.  3.] 
adversary cards in discard: [ 3. 10. 10.  0.  0.  0.  6.  0.  8.  6.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 14 15 10  0  6
  0 10  0  0  6 14  0  3  8] -> size -> 33 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 28.073047637939453



buy possibilites: [-1] 
expected returns: [[26.347115]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11. 10.  3.] 
cards in discard: [1. 8.] 
cards in deck: 45 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 19. 30.  8.  3. 10.  0.  4.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [ 3. 14. 11.  0.  3.] 
adversary cards in discard: [ 3. 10. 10.  0.  0.  0.  6.  0.  8.  6.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 14 15 10  0  6
  0 10  0  0  6 14  0  3  8] -> size -> 33 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  240    0    0   20    0    0    0    0 -170    0    0
   16    0] 
sum of rewards: 101 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 28.85944366455078






Player: 1 
cards in hand: [ 3. 14. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14. 11.  0.  3.] 
cards in discard: [ 3. 10. 10.  0.  0.  0.  6.  0.  8.  6.  0.  0. 11.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 14 15 10  0  6
  0 10  0  0  6 14  0  3  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 19. 30.  8.  3. 10.  0.  4.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [15.  8. 29.  0. 11.] 
adversary cards in discard: [ 1.  8. 11.  1. 11. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8] -> size -> 52 
adversary victory points: 9
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14. 11.  0.  3.] 
cards in discard: [ 3. 10. 10.  0.  0.  0.  6.  0.  8.  6.  0.  0. 11.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 14 15 10  0  6
  0 10  0  0  6 14  0  3  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 21. 30. 19. 30.  8.  3. 10.  0.  4.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [15.  8. 29.  0. 11.] 
adversary cards in discard: [ 1.  8. 11.  1. 11. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8] -> size -> 52 
adversary victory points: 9
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [15.  8. 29.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 29. 11.] 
expected returns: [[62.56865 ]
 [58.715977]
 [62.01284 ]
 [73.66339 ]
 [70.75153 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8. 29.  0. 11.] 
cards in discard: [ 1.  8. 11.  1. 11. 10.  3.] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 19. 30.  8.  3. 10.  0.  4.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [ 8.  0. 22.  6. 14.] 
adversary cards in discard: [ 3. 10. 10.  0.  0.  0.  6.  0.  8.  6.  0.  0. 11.  0.  3. 14. 11.  0.
  3.] 
adversary owned cards: [ 0  0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 14 15 10  0  6
  0 10  0  0  6 14  0  3  8] -> size -> 33 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 26.34711456298828



action possibilites: [-1.  8. 11.] 
expected returns: [[23.860287]
 [21.064396]
 [30.997337]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.] 
cards in discard: [ 1.  8. 11.  1. 11. 10.  3. 15. 15.] 
cards in deck: 39 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8] -> size -> 52 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 21. 30. 19. 30.  8.  3. 10.  0.  4.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [ 8.  0. 22.  6. 14.] 
adversary cards in discard: [ 3. 10. 10.  0.  0.  0.  6.  0.  8.  6.  0.  0. 11.  0.  3. 14. 11.  0.
  3.] 
adversary owned cards: [ 0  0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 14 15 10  0  6
  0 10  0  0  6 14  0  3  8] -> size -> 33 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 71.10348510742188



action possibilites: [-1] 
expected returns: [[35.470215]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [ 1.  8. 11.  1. 11. 10.  3. 15. 15.  8.] 
cards in deck: 39 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8] -> size -> 53 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 21. 30. 19. 30.  8.  3. 10.  0.  3.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [ 8.  0. 22.  6. 14.] 
adversary cards in discard: [ 3. 10. 10.  0.  0.  0.  6.  0.  8.  6.  0.  0. 11.  0.  3. 14. 11.  0.
  3.] 
adversary owned cards: [ 0  0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 14 15 10  0  6
  0 10  0  0  6 14  0  3  8] -> size -> 33 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  240    0    0   40    0    0    0    0 -180    0    0
    8    0] 
sum of rewards: 103 

action type: gain_card_n - action 5
Learning step: 0
desired expected reward: 29.936222076416016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[29.933468  ]
 [36.248547  ]
 [ 0.62284136]
 [34.908024  ]
 [35.913803  ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [ 1.  8. 11.  1. 11. 10.  3. 15. 15.  8.] 
cards in deck: 39 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8] -> size -> 53 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 21. 30. 19. 30.  8.  3. 10.  0.  3.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [ 8.  0. 22.  6. 14.] 
adversary cards in discard: [ 3. 10. 10.  0.  0.  0.  6.  0.  8.  6.  0.  0. 11.  0.  3. 14. 11.  0.
  3.] 
adversary owned cards: [ 0  0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 14 15 10  0  6
  0 10  0  0  6 14  0  3  8] -> size -> 33 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1
Learning step: 0
desired expected reward: 35.47021484375



buy possibilites: [-1] 
expected returns: [[34.760674]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [ 1.  8. 11.  1. 11. 10.  3. 15. 15.  8.  3.] 
cards in deck: 39 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 18. 30.  8.  3. 10.  0.  3.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [ 8.  0. 22.  6. 14.] 
adversary cards in discard: [ 3. 10. 10.  0.  0.  0.  6.  0.  8.  6.  0.  0. 11.  0.  3. 14. 11.  0.
  3.] 
adversary owned cards: [ 0  0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 14 15 10  0  6
  0 10  0  0  6 14  0  3  8] -> size -> 33 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  270    0    0   40    0    0    0    0 -190    0    0
   16    0] 
sum of rewards: 131 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 36.24853515625






Player: 1 
cards in hand: [ 8.  0. 22.  6. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 22.  6. 14.] 
cards in discard: [ 3. 10. 10.  0.  0.  0.  6.  0.  8.  6.  0.  0. 11.  0.  3. 14. 11.  0.
  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 14 15 10  0  6
  0 10  0  0  6 14  0  3  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 18. 30.  8.  3. 10.  0.  3.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [ 1.  3. 25. 11.  3.] 
adversary cards in discard: [ 1.  8. 11.  1. 11. 10.  3. 15. 15.  8.  3. 29. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3] -> size -> 54 
adversary victory points: 10
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  6.] 
cards in discard: [ 3. 10. 10.  0.  0.  0.  6.  0.  8.  6.  0.  0. 11.  0.  3. 14. 11.  0.
  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 15 10  0  6  0 10
  0  0  6 14  0  3  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 18. 30.  8.  3. 10.  0.  3.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [ 1.  3. 25. 11.  3.] 
adversary cards in discard: [ 1.  8. 11.  1. 11. 10.  3. 15. 15.  8.  3. 29. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3] -> size -> 54 
adversary victory points: 10
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  6.] 
cards in discard: [ 3. 10. 10.  0.  0.  0.  6.  0.  8.  6.  0.  0. 11.  0.  3. 14. 11.  0.
  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 15 10  0  6  0 10
  0  0  6 14  0  3  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 21. 30. 18. 30.  8.  3. 10.  0.  3.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [ 1.  3. 25. 11.  3.] 
adversary cards in discard: [ 1.  8. 11.  1. 11. 10.  3. 15. 15.  8.  3. 29. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3] -> size -> 54 
adversary victory points: 10
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  6.] 
cards in discard: [ 3. 10. 10.  0.  0.  0.  6.  0.  8.  6.  0.  0. 11.  0.  3. 14. 11.  0.
  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 15 10  0  6  0 10
  0  0  6 14  0  3  8  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 18. 30.  8.  3. 10.  0.  3.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [ 1.  3. 25. 11.  3.] 
adversary cards in discard: [ 1.  8. 11.  1. 11. 10.  3. 15. 15.  8.  3. 29. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3] -> size -> 54 
adversary victory points: 10
player victory points: 1 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 1.  3. 25. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[33.896023]
 [49.625206]
 [40.977345]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 25. 11.  3.] 
cards in discard: [ 1.  8. 11.  1. 11. 10.  3. 15. 15.  8.  3. 29. 11.  8.  0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 18. 30.  8.  3. 10.  0.  3.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [15.  8.  6.  8.  0.] 
adversary cards in discard: [ 3. 10. 10.  0.  0.  0.  6.  0.  8.  6.  0.  0. 11.  0.  3. 14. 11.  0.
  3.  0.  8. 22.  6.] 
adversary owned cards: [ 0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 15 10  0  6  0 10
  0  0  6 14  0  3  8  0] -> size -> 32 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 34.76067352294922



action possibilites: [-1] 
expected returns: [[41.274315]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 11.  3. 11.  3.] 
cards in discard: [ 1.  8. 11.  1. 11. 10.  3. 15. 15.  8.  3. 29. 11.  8.  0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 18. 30.  8.  2. 10.  0.  3.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [15.  8.  6.  8.  0.] 
adversary cards in discard: [ 3. 10. 10.  0.  0.  0.  6.  0.  8.  6.  0.  0. 11.  0.  3. 14. 11.  0.
  3.  0.  8. 22.  6.  6.] 
adversary owned cards: [ 0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 15 10  0  6  0 10
  0  0  6 14  0  3  8  0  6] -> size -> 33 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 49.625205993652344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[32.673542 ]
 [40.939873 ]
 [-3.2762842]
 [39.832333 ]
 [41.27433  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 11.  3. 11.  3.] 
cards in discard: [ 1.  8. 11.  1. 11. 10.  3. 15. 15.  8.  3. 29. 11.  8.  0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3] -> size -> 54 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 21. 30. 18. 30.  8.  2. 10.  0.  3.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [15.  8.  6.  8.  0.] 
adversary cards in discard: [ 3. 10. 10.  0.  0.  0.  6.  0.  8.  6.  0.  0. 11.  0.  3. 14. 11.  0.
  3.  0.  8. 22.  6.  6.] 
adversary owned cards: [ 0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 15 10  0  6  0 10
  0  0  6 14  0  3  8  0  6] -> size -> 33 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 41.274314880371094






Player: 1 
cards in hand: [15.  8.  6.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  6.  8.  0.] 
cards in discard: [ 3. 10. 10.  0.  0.  0.  6.  0.  8.  6.  0.  0. 11.  0.  3. 14. 11.  0.
  3.  0.  8. 22.  6.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 15 10  0  6  0 10
  0  0  6 14  0  3  8  0  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 18. 30.  8.  2. 10.  0.  3.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [10.  0.  3. 11. 29.] 
adversary cards in discard: [ 1.  8. 11.  1. 11. 10.  3. 15. 15.  8.  3. 29. 11.  8.  0. 25.  1.  3.
 11.  3. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3] -> size -> 54 
adversary victory points: 10
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0.] 
cards in discard: [ 3. 10. 10.  0.  0.  0.  6.  0.  8.  6.  0.  0. 11.  0.  3. 14. 11.  0.
  3.  0.  8. 22.  6.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 10  0  6  0 10  0
  0  6 14  0  3  8  0  6] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 18. 30.  8.  2. 10.  0.  3.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [10.  0.  3. 11. 29.] 
adversary cards in discard: [ 1.  8. 11.  1. 11. 10.  3. 15. 15.  8.  3. 29. 11.  8.  0. 25.  1.  3.
 11.  3. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3] -> size -> 54 
adversary victory points: 10
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0.] 
cards in discard: [ 3. 10. 10.  0.  0.  0.  6.  0.  8.  6.  0.  0. 11.  0.  3. 14. 11.  0.
  3.  0.  8. 22.  6.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 10  0  6  0 10  0
  0  6 14  0  3  8  0  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 21. 30. 18. 30.  8.  2. 10.  0.  3.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [10.  0.  3. 11. 29.] 
adversary cards in discard: [ 1.  8. 11.  1. 11. 10.  3. 15. 15.  8.  3. 29. 11.  8.  0. 25.  1.  3.
 11.  3. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3] -> size -> 54 
adversary victory points: 10
player victory points: 0 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [10.  0.  3. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 29.] 
expected returns: [[23.208015]
 [22.694866]
 [26.826931]
 [32.054146]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3. 11. 29.] 
cards in discard: [ 1.  8. 11.  1. 11. 10.  3. 15. 15.  8.  3. 29. 11.  8.  0. 25.  1.  3.
 11.  3. 11.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 18. 30.  8.  2. 10.  0.  3.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [0. 0. 3. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 10  0  6  0 10  0
  0  6 14  0  3  8  0  6] -> size -> 32 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 41.274314880371094



action possibilites: [-1. 10. 11. 11.] 
expected returns: [[52.490875]
 [51.646435]
 [56.401043]
 [56.401043]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11.] 
cards in discard: [ 1.  8. 11.  1. 11. 10.  3. 15. 15.  8.  3. 29. 11.  8.  0. 25.  1.  3.
 11.  3. 11.  3.  0.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3] -> size -> 54 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 21. 30. 18. 30.  8.  2. 10.  0.  3.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [0. 0. 3. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 10  0  6  0 10  0
  0  6 14  0  3  8  0  6] -> size -> 32 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 27.247100830078125



action possibilites: [-1] 
expected returns: [[25.862442]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.] 
cards in discard: [ 1.  8. 11.  1. 11. 10.  3. 15. 15.  8.  3. 29. 11.  8.  0. 25.  1.  3.
 11.  3. 11.  3.  0.  3.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1] -> size -> 55 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 20. 30. 18. 30.  8.  2. 10.  0.  3.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [0. 0. 3. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 10  0  6  0 10  0
  0  6 14  0  3  8  0  6] -> size -> 32 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  300    0    0   40    0    0    0    0 -200    0    0
   27    0] 
sum of rewards: 162 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 55.936798095703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 17.320473]
 [-12.980945]
 [ 25.862453]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.] 
cards in discard: [ 1.  8. 11.  1. 11. 10.  3. 15. 15.  8.  3. 29. 11.  8.  0. 25.  1.  3.
 11.  3. 11.  3.  0.  3.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1] -> size -> 55 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 20. 30. 18. 30.  8.  2. 10.  0.  3.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [0. 0. 3. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 10  0  6  0 10  0
  0  6 14  0  3  8  0  6] -> size -> 32 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: take_action - action -1
Learning step: 0
desired expected reward: 25.862442016601562






Player: 1 
cards in hand: [0. 0. 3. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 1.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 10  0  6  0 10  0
  0  6 14  0  3  8  0  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 18. 30.  8.  2. 10.  0.  3.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [15.  0. 10.  1.  0.] 
adversary cards in discard: [ 1.  8. 11.  1. 11. 10.  3. 15. 15.  8.  3. 29. 11.  8.  0. 25.  1.  3.
 11.  3. 11.  3.  0.  3.  1. 29. 11. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1] -> size -> 55 
adversary victory points: 10
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 1.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 10  0  6  0 10  0
  0  6 14  0  3  8  0  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 20. 30. 18. 30.  8.  2. 10.  0.  3.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [15.  0. 10.  1.  0.] 
adversary cards in discard: [ 1.  8. 11.  1. 11. 10.  3. 15. 15.  8.  3. 29. 11.  8.  0. 25.  1.  3.
 11.  3. 11.  3.  0.  3.  1. 29. 11. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1] -> size -> 55 
adversary victory points: 10
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 1.] 
cards in discard: [3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 10  0  6  0 10  0
  0  6 14  0  3  8  0  6  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 20. 30. 17. 30.  8.  2. 10.  0.  3.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [15.  0. 10.  1.  0.] 
adversary cards in discard: [ 1.  8. 11.  1. 11. 10.  3. 15. 15.  8.  3. 29. 11.  8.  0. 25.  1.  3.
 11.  3. 11.  3.  0.  3.  1. 29. 11. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1] -> size -> 55 
adversary victory points: 10
player victory points: 1 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [15.  0. 10.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
expected returns: [[-21.708214 ]
 [ -8.440394 ]
 [ -1.3274541]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 10.  1.  0.] 
cards in discard: [ 1.  8. 11.  1. 11. 10.  3. 15. 15.  8.  3. 29. 11.  8.  0. 25.  1.  3.
 11.  3. 11.  3.  0.  3.  1. 29. 11. 10. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 17. 30.  8.  2. 10.  0.  3.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [ 8.  3. 14. 22.  0.] 
adversary cards in discard: [3. 0. 0. 3. 3. 1.] 
adversary owned cards: [ 0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 10  0  6  0 10  0
  0  6 14  0  3  8  0  6  3] -> size -> 33 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 25.862442016601562



action possibilites: [-1. 15. 10.] 
expected returns: [[-17.776073]
 [ -2.984614]
 [  4.648177]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  1.  0. 10.] 
cards in discard: [ 1.  8. 11.  1. 11. 10.  3. 15. 15.  8.  3. 29. 11.  8.  0. 25.  1.  3.
 11.  3. 11.  3.  0.  3.  1. 29. 11. 10. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1] -> size -> 55 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 17. 30.  8.  2. 10.  0.  3.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [ 8.  3. 14. 22.  0.] 
adversary cards in discard: [3. 0. 0. 3. 3. 1.] 
adversary owned cards: [ 0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 10  0  6  0 10  0
  0  6 14  0  3  8  0  6  3] -> size -> 33 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: -1.3274710178375244



action possibilites: [-1. 15. 11.] 
expected returns: [[-17.482876 ]
 [ -2.5359612]
 [ 14.188163 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  1.  0. 11.] 
cards in discard: [ 1.  8. 11.  1. 11. 10.  3. 15. 15.  8.  3. 29. 11.  8.  0. 25.  1.  3.
 11.  3. 11.  3.  0.  3.  1. 29. 11. 10. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1] -> size -> 55 
action values: 3 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 17. 30.  8.  2. 10.  0.  3.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [ 8.  3. 14. 22.  0.] 
adversary cards in discard: [3. 0. 0. 3. 3. 1.] 
adversary owned cards: [ 0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 10  0  6  0 10  0
  0  6 14  0  3  8  0  6  3] -> size -> 33 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 4.6481733322143555



action possibilites: [-1. 15.] 
expected returns: [[47.31819]
 [36.3161 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  1.  0.] 
cards in discard: [ 1.  8. 11.  1. 11. 10.  3. 15. 15.  8.  3. 29. 11.  8.  0. 25.  1.  3.
 11.  3. 11.  3.  0.  3.  1. 29. 11. 10. 11.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1  8] -> size -> 56 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 17. 30.  8.  2. 10.  0.  2.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [ 8.  3. 14. 22.  0.] 
adversary cards in discard: [3. 0. 0. 3. 3. 1.] 
adversary owned cards: [ 0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 10  0  6  0 10  0
  0  6 14  0  3  8  0  6  3] -> size -> 33 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  270    0    0   60    0    0    0    0 -210    0    0
    8    0] 
sum of rewards: 123 

action type: gain_card_n - action 5
Learning step: 0
desired expected reward: 19.375225067138672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
expected returns: [[ 38.162014 ]
 [ 51.295334 ]
 [ 44.403976 ]
 [-22.124126 ]
 [ 54.12011  ]
 [ 44.87704  ]
 [ 55.263584 ]
 [  4.0061684]
 [ 36.3161   ]
 [ 47.31819  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  1.  0.] 
cards in discard: [ 1.  8. 11.  1. 11. 10.  3. 15. 15.  8.  3. 29. 11.  8.  0. 25.  1.  3.
 11.  3. 11.  3.  0.  3.  1. 29. 11. 10. 11.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1  8] -> size -> 56 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 20. 30. 17. 30.  8.  2. 10.  0.  2.  8.  5.  7. 10.  0.  9.  2.] 
adversary cards in hand: [ 8.  3. 14. 22.  0.] 
adversary cards in discard: [3. 0. 0. 3. 3. 1.] 
adversary owned cards: [ 0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 10  0  6  0 10  0
  0  6 14  0  3  8  0  6  3] -> size -> 33 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 270   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 47.318206787109375



buy possibilites: [-1] 
expected returns: [[39.735943]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  1.  0.] 
cards in discard: [ 1.  8. 11.  1. 11. 10.  3. 15. 15.  8.  3. 29. 11.  8.  0. 25.  1.  3.
 11.  3. 11.  3.  0.  3.  1. 29. 11. 10. 11.  8. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1  8 29] -> size -> 57 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 17. 30.  8.  2. 10.  0.  2.  8.  4.  7. 10.  0.  9.  2.] 
adversary cards in hand: [ 8.  3. 14. 22.  0.] 
adversary cards in discard: [3. 0. 0. 3. 3. 1.] 
adversary owned cards: [ 0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 10  0  6  0 10  0
  0  6 14  0  3  8  0  6  3] -> size -> 33 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  270    0    0   60    0    0    0    0 -220    0    0
  128    0] 
sum of rewards: 233 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 55.26359558105469






Player: 1 
cards in hand: [ 8.  3. 14. 22.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 22.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 14. 22.  0.] 
cards in discard: [3. 0. 0. 3. 3. 1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  8  0  3  3  8  8 11  0  6  0  1  0  6  3  3 22 10  0  6  0 10  0
  0  6 14  0  3  8  0  6  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 17. 30.  8.  2. 10.  0.  2.  8.  4.  7. 10.  0.  9.  2.] 
adversary cards in hand: [1. 1. 0. 0. 1.] 
adversary cards in discard: [ 1.  8. 11.  1. 11. 10.  3. 15. 15.  8.  3. 29. 11.  8.  0. 25.  1.  3.
 11.  3. 11.  3.  0.  3.  1. 29. 11. 10. 11.  8. 29. 10. 10. 11. 15.  0.
  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1  8 29] -> size -> 57 
adversary victory points: 10
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.] 
cards in discard: [3. 0. 0. 3. 3. 1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 11  8  0  3  8  8 11  0  6  0  1  0  6  3  3 10  0  6  0 10  0  0  6
 14  0  3  8  0  6  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 17. 30.  8.  2. 10.  0.  2.  8.  4.  7. 10.  0.  9.  2.] 
adversary cards in hand: [1. 1. 0. 0. 1.] 
adversary cards in discard: [ 1.  8. 11.  1. 11. 10.  3. 15. 15.  8.  3. 29. 11.  8.  0. 25.  1.  3.
 11.  3. 11.  3.  0.  3.  1. 29. 11. 10. 11.  8. 29. 10. 10. 11. 15.  0.
  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1  8 29] -> size -> 57 
adversary victory points: 10
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.] 
cards in discard: [3. 0. 0. 3. 3. 1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 11  8  0  3  8  8 11  0  6  0  1  0  6  3  3 10  0  6  0 10  0  0  6
 14  0  3  8  0  6  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 20. 30. 17. 30.  8.  2. 10.  0.  2.  8.  4.  7. 10.  0.  9.  2.] 
adversary cards in hand: [1. 1. 0. 0. 1.] 
adversary cards in discard: [ 1.  8. 11.  1. 11. 10.  3. 15. 15.  8.  3. 29. 11.  8.  0. 25.  1.  3.
 11.  3. 11.  3.  0.  3.  1. 29. 11. 10. 11.  8. 29. 10. 10. 11. 15.  0.
  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1  8 29] -> size -> 57 
adversary victory points: 10
player victory points: 0 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [1. 1. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-45.390614]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 0. 0. 1.] 
cards in discard: [ 1.  8. 11.  1. 11. 10.  3. 15. 15.  8.  3. 29. 11.  8.  0. 25.  1.  3.
 11.  3. 11.  3.  0.  3.  1. 29. 11. 10. 11.  8. 29. 10. 10. 11. 15.  0.
  1.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1  8 29] -> size -> 57 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 17. 30.  8.  2. 10.  0.  2.  8.  4.  7. 10.  0.  9.  2.] 
adversary cards in hand: [11.  6.  0. 11.  0.] 
adversary cards in discard: [ 3.  0.  0.  3.  3.  1.  8. 14.  0.] 
adversary owned cards: [ 0 11  8  0  3  8  8 11  0  6  0  1  0  6  3  3 10  0  6  0 10  0  0  6
 14  0  3  8  0  6  3] -> size -> 31 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 39.73594284057617





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[ -61.933975]
 [ -50.959297]
 [ -67.29532 ]
 [ -62.662388]
 [ -85.17744 ]
 [ -54.29444 ]
 [-100.17592 ]
 [ -36.167393]
 [ -48.14967 ]
 [ -25.987541]
 [ -32.82305 ]
 [ -83.68176 ]
 [ -56.046207]
 [ -81.50755 ]
 [ -62.75054 ]
 [ -45.39062 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 0. 1.] 
cards in discard: [ 1.  8. 11.  1. 11. 10.  3. 15. 15.  8.  3. 29. 11.  8.  0. 25.  1.  3.
 11.  3. 11.  3.  0.  3.  1. 29. 11. 10. 11.  8. 29. 10. 10. 11. 15.  0.
  1.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1  8 29] -> size -> 57 
action values: 0 
buys: 1 
player value: 8 
card supply: [20. 20. 30. 17. 30.  8.  2. 10.  0.  2.  8.  4.  7. 10.  0.  9.  2.] 
adversary cards in hand: [11.  6.  0. 11.  0.] 
adversary cards in discard: [ 3.  0.  0.  3.  3.  1.  8. 14.  0.] 
adversary owned cards: [ 0 11  8  0  3  8  8 11  0  6  0  1  0  6  3  3 10  0  6  0 10  0  0  6
 14  0  3  8  0  6  3] -> size -> 31 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -45.3906135559082



buy possibilites: [-1] 
expected returns: [[-41.6093]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 0. 1.] 
cards in discard: [ 1.  8. 11.  1. 11. 10.  3. 15. 15.  8.  3. 29. 11.  8.  0. 25.  1.  3.
 11.  3. 11.  3.  0.  3.  1. 29. 11. 10. 11.  8. 29. 10. 10. 11. 15.  0.
  1.  0. 25.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1  8 29 25] -> size -> 58 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 20. 30. 17. 30.  8.  2. 10.  0.  2.  7.  4.  7. 10.  0.  9.  2.] 
adversary cards in hand: [11.  6.  0. 11.  0.] 
adversary cards in discard: [ 3.  0.  0.  3.  3.  1.  8. 14.  0.] 
adversary owned cards: [ 0 11  8  0  3  8  8 11  0  6  0  1  0  6  3  3 10  0  6  0 10  0  0  6
 14  0  3  8  0  6  3] -> size -> 31 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[  -5.     0.     0.   300.     0.     0.     0.     0.     0.     0.
    0.  -230.     0.     0.    62.5    0. ] 
sum of rewards: 127.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: -25.987548828125






Player: 1 
cards in hand: [11.  6.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0. 11.  0.] 
cards in discard: [ 3.  0.  0.  3.  3.  1.  8. 14.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  8  0  3  8  8 11  0  6  0  1  0  6  3  3 10  0  6  0 10  0  0  6
 14  0  3  8  0  6  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 17. 30.  8.  2. 10.  0.  2.  7.  4.  7. 10.  0.  9.  2.] 
adversary cards in hand: [15.  0.  3.  3. 29.] 
adversary cards in discard: [ 1.  8. 11.  1. 11. 10.  3. 15. 15.  8.  3. 29. 11.  8.  0. 25.  1.  3.
 11.  3. 11.  3.  0.  3.  1. 29. 11. 10. 11.  8. 29. 10. 10. 11. 15.  0.
  1.  0. 25.  1.  1.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1  8 29 25] -> size -> 58 
adversary victory points: 10
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 11.  0.] 
cards in discard: [ 3.  0.  0.  3.  3.  1.  8. 14.  0.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 11  8  0  3  8  8 11  0  6  0  1  0  6  3  3 10  0  6  0 10  0  0  6
 14  0  3  8  0  6  3  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 17. 30.  8.  2. 10.  0.  1.  7.  4.  7. 10.  0.  9.  2.] 
adversary cards in hand: [15.  0.  3.  3. 29.] 
adversary cards in discard: [ 1.  8. 11.  1. 11. 10.  3. 15. 15.  8.  3. 29. 11.  8.  0. 25.  1.  3.
 11.  3. 11.  3.  0.  3.  1. 29. 11. 10. 11.  8. 29. 10. 10. 11. 15.  0.
  1.  0. 25.  1.  1.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1  8 29 25] -> size -> 58 
adversary victory points: 10
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 11.  0.] 
cards in discard: [ 3.  0.  0.  3.  3.  1.  8. 14.  0.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 11  8  0  3  8  8 11  0  6  0  1  0  6  3  3 10  0  6  0 10  0  0  6
 14  0  3  8  0  6  3  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 20. 30. 17. 30.  8.  2. 10.  0.  1.  7.  4.  7. 10.  0.  9.  2.] 
adversary cards in hand: [15.  0.  3.  3. 29.] 
adversary cards in discard: [ 1.  8. 11.  1. 11. 10.  3. 15. 15.  8.  3. 29. 11.  8.  0. 25.  1.  3.
 11.  3. 11.  3.  0.  3.  1. 29. 11. 10. 11.  8. 29. 10. 10. 11. 15.  0.
  1.  0. 25.  1.  1.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1  8 29 25] -> size -> 58 
adversary victory points: 10
player victory points: 0 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [15.  0.  3.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
expected returns: [[-10.413429]
 [-17.07372 ]
 [ -0.61585 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  3.  3. 29.] 
cards in discard: [ 1.  8. 11.  1. 11. 10.  3. 15. 15.  8.  3. 29. 11.  8.  0. 25.  1.  3.
 11.  3. 11.  3.  0.  3.  1. 29. 11. 10. 11.  8. 29. 10. 10. 11. 15.  0.
  1.  0. 25.  1.  1.  0.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1  8 29 25] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 17. 30.  8.  2. 10.  0.  1.  7.  4.  7. 10.  0.  9.  2.] 
adversary cards in hand: [ 0.  6. 10.  8.  3.] 
adversary cards in discard: [ 3.  0.  0.  3.  3.  1.  8. 14.  0.  8. 11.  6.  0. 11.  0.] 
adversary owned cards: [ 0 11  8  0  3  8  8 11  0  6  0  1  0  6  3  3 10  0  6  0 10  0  0  6
 14  0  3  8  0  6  3  8] -> size -> 32 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: -41.60929870605469



action possibilites: [-1. 15. 10.] 
expected returns: [[-28.461464]
 [-35.447872]
 [-25.761524]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 10.] 
cards in discard: [ 1.  8. 11.  1. 11. 10.  3. 15. 15.  8.  3. 29. 11.  8.  0. 25.  1.  3.
 11.  3. 11.  3.  0.  3.  1. 29. 11. 10. 11.  8. 29. 10. 10. 11. 15.  0.
  1.  0. 25.  1.  1.  0.  0.  1.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1  8 29 25] -> size -> 58 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 20. 30. 17. 30.  8.  2. 10.  0.  1.  7.  4.  7. 10.  0.  9.  2.] 
adversary cards in hand: [ 0.  6. 10.  8.  3.] 
adversary cards in discard: [ 3.  0.  0.  3.  3.  1.  8. 14.  0.  8. 11.  6.  0. 11.  0.] 
adversary owned cards: [ 0 11  8  0  3  8  8 11  0  6  0  1  0  6  3  3 10  0  6  0 10  0  0  6
 14  0  3  8  0  6  3  8] -> size -> 32 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -5.468841075897217



action possibilites: [-1. 15. 15.] 
expected returns: [[-29.940506]
 [-38.43342 ]
 [-38.43342 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 15.] 
cards in discard: [ 1.  8. 11.  1. 11. 10.  3. 15. 15.  8.  3. 29. 11.  8.  0. 25.  1.  3.
 11.  3. 11.  3.  0.  3.  1. 29. 11. 10. 11.  8. 29. 10. 10. 11. 15.  0.
  1.  0. 25.  1.  1.  0.  0.  1.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1  8 29 25] -> size -> 58 
action values: 2 
buys: 0 
player value: 1 
card supply: [20. 20. 30. 17. 30.  8.  2. 10.  0.  1.  7.  4.  7. 10.  0.  9.  2.] 
adversary cards in hand: [ 0.  6. 10.  8.  3.] 
adversary cards in discard: [ 3.  0.  0.  3.  3.  1.  8. 14.  0.  8. 11.  6.  0. 11.  0.] 
adversary owned cards: [ 0 11  8  0  3  8  8 11  0  6  0  1  0  6  3  3 10  0  6  0 10  0  0  6
 14  0  3  8  0  6  3  8] -> size -> 32 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: -25.761531829833984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-39.279903]
 [-66.00379 ]
 [-29.940506]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3. 15.] 
cards in discard: [ 1.  8. 11.  1. 11. 10.  3. 15. 15.  8.  3. 29. 11.  8.  0. 25.  1.  3.
 11.  3. 11.  3.  0.  3.  1. 29. 11. 10. 11.  8. 29. 10. 10. 11. 15.  0.
  1.  0. 25.  1.  1.  0.  0.  1.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1  8 29 25] -> size -> 58 
action values: 2 
buys: 1 
player value: 1 
card supply: [20. 20. 30. 17. 30.  8.  2. 10.  0.  1.  7.  4.  7. 10.  0.  9.  2.] 
adversary cards in hand: [ 0.  6. 10.  8.  3.] 
adversary cards in discard: [ 3.  0.  0.  3.  3.  1.  8. 14.  0.  8. 11.  6.  0. 11.  0.] 
adversary owned cards: [ 0 11  8  0  3  8  8 11  0  6  0  1  0  6  3  3 10  0  6  0 10  0  0  6
 14  0  3  8  0  6  3  8] -> size -> 32 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -29.940513610839844






Player: 1 
cards in hand: [ 0.  6. 10.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 10.  8.  3.] 
cards in discard: [ 3.  0.  0.  3.  3.  1.  8. 14.  0.  8. 11.  6.  0. 11.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  8  0  3  8  8 11  0  6  0  1  0  6  3  3 10  0  6  0 10  0  0  6
 14  0  3  8  0  6  3  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 17. 30.  8.  2. 10.  0.  1.  7.  4.  7. 10.  0.  9.  2.] 
adversary cards in hand: [15. 10. 25.  3. 29.] 
adversary cards in discard: [ 1.  8. 11.  1. 11. 10.  3. 15. 15.  8.  3. 29. 11.  8.  0. 25.  1.  3.
 11.  3. 11.  3.  0.  3.  1. 29. 11. 10. 11.  8. 29. 10. 10. 11. 15.  0.
  1.  0. 25.  1.  1.  0.  0.  1.  0.  3. 29. 10. 15.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1  8 29 25] -> size -> 58 
adversary victory points: 10
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [ 3.  0.  0.  3.  3.  1.  8. 14.  0.  8. 11.  6.  0. 11.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  8  0  8  8 11  0  0  1  0  6  3  3 10  0  6  0 10  0  0  6 14  0  3
  8  0  6  3  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 17. 30.  8.  2. 10.  0.  1.  7.  4.  7. 10.  0.  9.  2.] 
adversary cards in hand: [15. 10. 25.  3. 29.] 
adversary cards in discard: [ 1.  8. 11.  1. 11. 10.  3. 15. 15.  8.  3. 29. 11.  8.  0. 25.  1.  3.
 11.  3. 11.  3.  0.  3.  1. 29. 11. 10. 11.  8. 29. 10. 10. 11. 15.  0.
  1.  0. 25.  1.  1.  0.  0.  1.  0.  3. 29. 10. 15.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1  8 29 25] -> size -> 58 
adversary victory points: 10
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [ 3.  0.  0.  3.  3.  1.  8. 14.  0.  8. 11.  6.  0. 11.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  8  0  8  8 11  0  0  1  0  6  3  3 10  0  6  0 10  0  0  6 14  0  3
  8  0  6  3  8] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 20. 30. 17. 30.  8.  2. 10.  0.  1.  7.  4.  7. 10.  0.  9.  2.] 
adversary cards in hand: [15. 10. 25.  3. 29.] 
adversary cards in discard: [ 1.  8. 11.  1. 11. 10.  3. 15. 15.  8.  3. 29. 11.  8.  0. 25.  1.  3.
 11.  3. 11.  3.  0.  3.  1. 29. 11. 10. 11.  8. 29. 10. 10. 11. 15.  0.
  1.  0. 25.  1.  1.  0.  0.  1.  0.  3. 29. 10. 15.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1  8 29 25] -> size -> 58 
adversary victory points: 10
player victory points: 0 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [15. 10. 25.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 25. 29.] 
expected returns: [[28.994091]
 [22.95697 ]
 [31.198902]
 [41.973793]
 [38.18423 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 25.  3. 29.] 
cards in discard: [ 1.  8. 11.  1. 11. 10.  3. 15. 15.  8.  3. 29. 11.  8.  0. 25.  1.  3.
 11.  3. 11.  3.  0.  3.  1. 29. 11. 10. 11.  8. 29. 10. 10. 11. 15.  0.
  1.  0. 25.  1.  1.  0.  0.  1.  0.  3. 29. 10. 15.  3. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1  8 29 25] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 17. 30.  8.  2. 10.  0.  1.  7.  4.  7. 10.  0.  9.  2.] 
adversary cards in hand: [0. 0. 6. 6. 0.] 
adversary cards in discard: [ 3.  0.  0.  3.  3.  1.  8. 14.  0.  8. 11.  6.  0. 11.  0.  8. 10.] 
adversary owned cards: [11  8  0  8  8 11  0  0  1  0  6  3  3 10  0  6  0 10  0  0  6 14  0  3
  8  0  6  3  8] -> size -> 29 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -29.940513610839844



action possibilites: [-1] 
expected returns: [[-0.92436266]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  3. 29. 10.  3.] 
cards in discard: [ 1.  8. 11.  1. 11. 10.  3. 15. 15.  8.  3. 29. 11.  8.  0. 25.  1.  3.
 11.  3. 11.  3.  0.  3.  1. 29. 11. 10. 11.  8. 29. 10. 10. 11. 15.  0.
  1.  0. 25.  1.  1.  0.  0.  1.  0.  3. 29. 10. 15.  3. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1  8 29 25] -> size -> 58 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 17. 30.  8.  1. 10.  0.  1.  7.  4.  7. 10.  0.  9.  2.] 
adversary cards in hand: [0. 0. 6. 6. 0.] 
adversary cards in discard: [ 3.  0.  0.  3.  3.  1.  8. 14.  0.  8. 11.  6.  0. 11.  0.  8. 10.  6.] 
adversary owned cards: [11  8  0  8  8 11  0  0  1  0  6  3  3 10  0  6  0 10  0  0  6 14  0  3
  8  0  6  3  8  6] -> size -> 30 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 41.973785400390625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -7.808517 ]
 [-55.991898 ]
 [ -0.9243603]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10.  3. 29. 10.  3.] 
cards in discard: [ 1.  8. 11.  1. 11. 10.  3. 15. 15.  8.  3. 29. 11.  8.  0. 25.  1.  3.
 11.  3. 11.  3.  0.  3.  1. 29. 11. 10. 11.  8. 29. 10. 10. 11. 15.  0.
  1.  0. 25.  1.  1.  0.  0.  1.  0.  3. 29. 10. 15.  3. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1  8 29 25] -> size -> 58 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 20. 30. 17. 30.  8.  1. 10.  0.  1.  7.  4.  7. 10.  0.  9.  2.] 
adversary cards in hand: [0. 0. 6. 6. 0.] 
adversary cards in discard: [ 3.  0.  0.  3.  3.  1.  8. 14.  0.  8. 11.  6.  0. 11.  0.  8. 10.  6.] 
adversary owned cards: [11  8  0  8  8 11  0  0  1  0  6  3  3 10  0  6  0 10  0  0  6 14  0  3
  8  0  6  3  8  6] -> size -> 30 
adversary victory points: 0
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: -0.9243626594543457






Player: 1 
cards in hand: [0. 0. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 6. 0.] 
cards in discard: [ 3.  0.  0.  3.  3.  1.  8. 14.  0.  8. 11.  6.  0. 11.  0.  8. 10.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [11  8  0  8  8 11  0  0  1  0  6  3  3 10  0  6  0 10  0  0  6 14  0  3
  8  0  6  3  8  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 17. 30.  8.  1. 10.  0.  1.  7.  4.  7. 10.  0.  9.  2.] 
adversary cards in hand: [11.  0. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1  8 29 25] -> size -> 58 
adversary victory points: 10
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6. 0.] 
cards in discard: [ 3.  0.  0.  3.  3.  1.  8. 14.  0.  8. 11.  6.  0. 11.  0.  8. 10.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [11  8  0  8  8 11  0  0  1  0  6  3  3 10  0  6  0 10  0  0  6 14  0  3
  8  0  6  3  8  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 20. 30. 17. 30.  8.  1. 10.  0.  1.  7.  4.  7. 10.  0.  9.  2.] 
adversary cards in hand: [11.  0. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1  8 29 25] -> size -> 58 
adversary victory points: 10
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6. 0.] 
cards in discard: [ 3.  0.  0.  3.  3.  1.  8. 14.  0.  8. 11.  6.  0. 11.  0.  8. 10.  6.
  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [11  8  0  8  8 11  0  0  1  0  6  3  3 10  0  6  0 10  0  0  6 14  0  3
  8  0  6  3  8  6  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 19. 30. 17. 30.  8.  1. 10.  0.  1.  7.  4.  7. 10.  0.  9.  2.] 
adversary cards in hand: [11.  0. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1  8 29 25] -> size -> 58 
adversary victory points: 10
player victory points: -1 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [11.  0. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[29.369045]
 [35.299267]
 [35.299267]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 53 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1  8 29 25] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 19. 30. 17. 30.  8.  1. 10.  0.  1.  7.  4.  7. 10.  0.  9.  2.] 
adversary cards in hand: [6. 8. 3. 8. 0.] 
adversary cards in discard: [ 3.  0.  0.  3.  3.  1.  8. 14.  0.  8. 11.  6.  0. 11.  0.  8. 10.  6.
  1.  0.  0.  6.  6.  0.] 
adversary owned cards: [11  8  0  8  8 11  0  0  1  0  6  3  3 10  0  6  0 10  0  0  6 14  0  3
  8  0  6  3  8  6  1] -> size -> 31 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -0.9243626594543457



action possibilites: [-1] 
expected returns: [[23.559254]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0.] 
cards in discard: [1.] 
cards in deck: 53 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1  8 29 25  1] -> size -> 59 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 18. 30. 17. 30.  8.  1. 10.  0.  1.  7.  4.  7. 10.  0.  9.  2.] 
adversary cards in hand: [6. 8. 3. 8. 0.] 
adversary cards in discard: [ 3.  0.  0.  3.  3.  1.  8. 14.  0.  8. 11.  6.  0. 11.  0.  8. 10.  6.
  1.  0.  0.  6.  6.  0.] 
adversary owned cards: [11  8  0  8  8 11  0  0  1  0  6  3  3 10  0  6  0 10  0  0  6 14  0  3
  8  0  6  3  8  6  1] -> size -> 31 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  330    0    0   20    0    0    0    0 -240    0    0
   27    0] 
sum of rewards: 132 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 34.36518096923828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[  6.626973]
 [ 15.284308]
 [-52.327213]
 [ 22.157978]
 [ 26.561394]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  0.] 
cards in discard: [1.] 
cards in deck: 53 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1  8 29 25  1] -> size -> 59 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 18. 30. 17. 30.  8.  1. 10.  0.  1.  7.  4.  7. 10.  0.  9.  2.] 
adversary cards in hand: [6. 8. 3. 8. 0.] 
adversary cards in discard: [ 3.  0.  0.  3.  3.  1.  8. 14.  0.  8. 11.  6.  0. 11.  0.  8. 10.  6.
  1.  0.  0.  6.  6.  0.] 
adversary owned cards: [11  8  0  8  8 11  0  0  1  0  6  3  3 10  0  6  0 10  0  0  6 14  0  3
  8  0  6  3  8  6  1] -> size -> 31 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: 23.559253692626953






Player: 1 
cards in hand: [6. 8. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 3. 8. 0.] 
cards in discard: [ 3.  0.  0.  3.  3.  1.  8. 14.  0.  8. 11.  6.  0. 11.  0.  8. 10.  6.
  1.  0.  0.  6.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [11  8  0  8  8 11  0  0  1  0  6  3  3 10  0  6  0 10  0  0  6 14  0  3
  8  0  6  3  8  6  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 18. 30. 17. 30.  8.  1. 10.  0.  1.  7.  4.  7. 10.  0.  9.  2.] 
adversary cards in hand: [ 0.  0. 29.  1.  1.] 
adversary cards in discard: [ 1. 11.  0. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1  8 29 25  1] -> size -> 59 
adversary victory points: 10
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 3. 8. 0.] 
cards in discard: [ 3.  0.  0.  3.  3.  1.  8. 14.  0.  8. 11.  6.  0. 11.  0.  8. 10.  6.
  1.  0.  0.  6.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [11  8  0  8  8 11  0  0  1  0  6  3  3 10  0  6  0 10  0  0  6 14  0  3
  8  0  6  3  8  6  1] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 18. 30. 17. 30.  8.  1. 10.  0.  1.  7.  4.  7. 10.  0.  9.  2.] 
adversary cards in hand: [ 0.  0. 29.  1.  1.] 
adversary cards in discard: [ 1. 11.  0. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1  8 29 25  1] -> size -> 59 
adversary victory points: 10
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 29.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[88.88356]
 [96.97328]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  1.  1.] 
cards in discard: [ 1. 11.  0. 11.  3.  0.] 
cards in deck: 48 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1  8 29 25  1] -> size -> 59 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 18. 30. 17. 30.  8.  1. 10.  0.  1.  7.  4.  7. 10.  0.  9.  2.] 
adversary cards in hand: [ 1.  3.  6.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [11  8  0  8  8 11  0  0  1  0  6  3  3 10  0  6  0 10  0  0  6 14  0  3
  8  0  6  3  8  6  1] -> size -> 31 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 26.561378479003906



action possibilites: [-1.] 
expected returns: [[47.63865]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 1.] 
cards in discard: [ 1. 11.  0. 11.  3.  0.  0. 10.] 
cards in deck: 47 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1  8 29 25  1] -> size -> 59 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 18. 30. 17. 30.  8.  1. 10.  0.  1.  7.  4.  7. 10.  0.  9.  2.] 
adversary cards in hand: [ 1.  3.  6.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [11  8  0  8  8 11  0  0  1  0  6  3  3 10  0  6  0 10  0  0  6 14  0  3
  8  0  6  3  8  6  1] -> size -> 31 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 90.91712188720703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[ 22.895897 ]
 [ 36.989323 ]
 [ 20.847355 ]
 [ 30.81234  ]
 [ -3.6805515]
 [-39.661053 ]
 [ 52.186127 ]
 [ 39.304787 ]
 [ 59.20395  ]
 [ 54.19449  ]
 [ -4.6685686]
 [ 34.473602 ]
 [  6.3076487]
 [ 23.414001 ]
 [ 47.25607  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1.] 
cards in discard: [ 1. 11.  0. 11.  3.  0.  0. 10.] 
cards in deck: 47 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1  8 29 25  1] -> size -> 59 
action values: 0 
buys: 1 
player value: 6 
card supply: [20. 18. 30. 17. 30.  8.  1. 10.  0.  1.  7.  4.  7. 10.  0.  9.  2.] 
adversary cards in hand: [ 1.  3.  6.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [11  8  0  8  8 11  0  0  1  0  6  3  3 10  0  6  0 10  0  0  6 14  0  3
  8  0  6  3  8  6  1] -> size -> 31 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 47.638648986816406



buy possibilites: [-1] 
expected returns: [[50.759487]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1.] 
cards in discard: [ 1. 11.  0. 11.  3.  0.  0. 10. 25.] 
cards in deck: 47 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1  8 29 25  1 25] -> size -> 60 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 18. 30. 17. 30.  8.  1. 10.  0.  1.  6.  4.  7. 10.  0.  9.  2.] 
adversary cards in hand: [ 1.  3.  6.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [11  8  0  8  8 11  0  0  1  0  6  3  3 10  0  6  0 10  0  0  6 14  0  3
  8  0  6  3  8  6  1] -> size -> 31 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[  -5.     0.     0.   330.     0.     0.    20.     0.     0.     0.
    0.  -250.     0.     0.    62.5    0. ] 
sum of rewards: 157.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 59.20393371582031






Player: 1 
cards in hand: [ 1.  3.  6.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  6.  0. 10.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [11  8  0  8  8 11  0  0  1  0  6  3  3 10  0  6  0 10  0  0  6 14  0  3
  8  0  6  3  8  6  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 18. 30. 17. 30.  8.  1. 10.  0.  1.  6.  4.  7. 10.  0.  9.  2.] 
adversary cards in hand: [25.  1.  3. 29.  8.] 
adversary cards in discard: [ 1. 11.  0. 11.  3.  0.  0. 10. 25. 29.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1  8 29 25  1 25] -> size -> 60 
adversary victory points: 10
player victory points: -1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 6. 0. 1.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [11  8  0  8  8 11  0  0  1  0  6  3  3 10  0  6  0 10  0  0  6 14  0  3
  8  0  6  3  8  6  1] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 18. 30. 17. 30.  8.  1. 10.  0.  1.  6.  4.  7. 10.  0.  9.  2.] 
adversary cards in hand: [25.  1.  3. 29.  8.] 
adversary cards in discard: [ 1. 11.  0. 11.  3.  0.  0. 10. 25. 29.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1  8 29 25  1 25] -> size -> 60 
adversary victory points: 10
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 6. 0. 1.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [11  8  0  8  8 11  0  0  1  0  6  3  3 10  0  6  0 10  0  0  6 14  0  3
  8  0  6  3  8  6  1] -> size -> 31 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 18. 30. 17. 30.  8.  1. 10.  0.  1.  6.  4.  7. 10.  0.  9.  2.] 
adversary cards in hand: [25.  1.  3. 29.  8.] 
adversary cards in discard: [ 1. 11.  0. 11.  3.  0.  0. 10. 25. 29.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1  8 29 25  1 25] -> size -> 60 
adversary victory points: 10
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 6. 0. 1.] 
cards in discard: [25.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [11  8  0  8  8 11  0  0  1  0  6  3  3 10  0  6  0 10  0  0  6 14  0  3
  8  0  6  3  8  6  1 25] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 18. 30. 17. 30.  8.  1. 10.  0.  1.  5.  4.  7. 10.  0.  9.  2.] 
adversary cards in hand: [25.  1.  3. 29.  8.] 
adversary cards in discard: [ 1. 11.  0. 11.  3.  0.  0. 10. 25. 29.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1  8 29 25  1 25] -> size -> 60 
adversary victory points: 10
player victory points: -1 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [25.  1.  3. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.  8.] 
expected returns: [[26.728554]
 [40.631485]
 [35.67313 ]
 [24.327713]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  3. 29.  8.] 
cards in discard: [ 1. 11.  0. 11.  3.  0.  0. 10. 25. 29.  0.  1.  1.] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1  8 29 25  1 25] -> size -> 60 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 18. 30. 17. 30.  8.  1. 10.  0.  1.  5.  4.  7. 10.  0.  9.  2.] 
adversary cards in hand: [8. 6. 8. 8. 8.] 
adversary cards in discard: [25. 10.  1.  3.  6.  0.  1.] 
adversary owned cards: [11  8  0  8  8 11  0  0  1  0  6  3  3 10  0  6  0 10  0  0  6 14  0  3
  8  0  6  3  8  6  1 25] -> size -> 32 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 50.75948715209961



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 3 
Gold: 0 
Estate: 7 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 6 
Chapel: 1 
Witch: 4 
Poacher: 5 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 1.  3. 29.  8.  3. 29.] 
cards in discard: [ 1. 11.  0. 11.  3.  0.  0. 10. 25. 29.  0.  1.  1.] 
cards in deck: 40 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 25  3 11 29 11 11 11 10 29 10  3  3
  1 10  1 10 11 10 11 10 10 29 11 15 15  3 15  8  3 15 15  1 15  1 25  1
  3  1  1  8  8  3  1  8 29 25  1 25] -> size -> 60 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 18. 30. 17. 30.  8.  0. 10.  0.  1.  5.  4.  7. 10.  0.  9.  2.] 
adversary cards in hand: [8. 6. 8. 8. 8.] 
adversary cards in discard: [25. 10.  1.  3.  6.  0.  1.  6.] 
adversary owned cards: [11  8  0  8  8 11  0  0  1  0  6  3  3 10  0  6  0 10  0  0  6 14  0  3
  8  0  6  3  8  6  1 25  6] -> size -> 33 
adversary victory points: -1
player victory points: 10 

Reward from previous game state: 
[     -5 3000000       0     330       0       0      20       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000345 

action type: take_action - action 25.0
Learning step: 120012.1640625
desired expected reward: 120052.796875



