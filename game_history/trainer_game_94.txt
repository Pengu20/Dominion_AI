 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[276.03424]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500   -1  -40    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -546 

action type: buy - action -1
Learning step: -26.828611373901367
desired expected reward: -36.25638961791992





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[253.21117]
 [270.43546]
 [263.389  ]
 [230.27722]
 [217.76111]
 [260.73306]
 [280.26654]
 [265.48914]
 [292.7734 ]
 [265.5729 ]
 [236.35442]
 [245.57712]
 [261.63373]
 [226.89891]
 [253.35979]
 [283.09503]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.022989273071289
desired expected reward: 272.5823974609375



buy possibilites: [-1] 
expected returns: [[213.44026]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 50  0] 
sum of rewards: 48 

action type: buy - action 25.0
Learning step: -7.4362688064575195
desired expected reward: 285.33721923828125






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [0. 0. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[259.9771]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [25.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -4.912870407104492
desired expected reward: 208.5273895263672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[246.03986]
 [252.71571]
 [212.6834 ]
 [257.73453]
 [266.05408]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [25.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -7.386932373046875
desired expected reward: 253.0194091796875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  0.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[229.98021]
 [241.26006]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 25.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -8.037816047668457
desired expected reward: 258.01629638671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[211.70158]
 [225.08618]
 [218.2185 ]
 [185.66411]
 [217.25714]
 [231.44707]
 [221.15556]
 [220.79396]
 [197.61089]
 [215.85857]
 [209.60973]
 [232.44783]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 25.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -6.655284404754639
desired expected reward: 224.5623321533203



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3. 0. 3. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [ 0.  0.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3. 0. 3. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [ 0.  0.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 3.  0.  3.  0.  3. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [ 0.  0.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[315.8579]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [ 0.  0.  0. 25.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -4.55551290512085
desired expected reward: 227.89231872558594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[297.02475]
 [305.5337 ]
 [261.74448]
 [308.86572]
 [321.4131 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [ 0.  0.  0. 25.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.093832015991211
desired expected reward: 309.4341125488281



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[281.6425]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [14.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -9.893411636352539
desired expected reward: 311.5196533203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[259.71024]
 [270.8399 ]
 [265.59286]
 [245.07501]
 [236.66629]
 [264.64948]
 [275.83105]
 [267.5088 ]
 [284.84247]
 [267.4342 ]
 [248.00026]
 [254.17302]
 [263.84686]
 [242.4015 ]
 [258.5273 ]
 [277.6749 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25] -> size -> 11 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [14.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -7.951966762542725
desired expected reward: 271.03656005859375



buy possibilites: [-1] 
expected returns: [[267.71872]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6] -> size -> 12 
action values: 0 
buys: 0 
player value: 5 
card supply: [29. 30. 30. 30. 30.  8.  9. 10. 10. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [14.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -313.0 

action type: buy - action 6.0
Learning step: -21.459644317626953
desired expected reward: 215.20663452148438






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [14.  0.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9. 10. 10. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.  3.  3.] 
adversary cards in discard: [6. 0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6] -> size -> 12 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [14.  0.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8.  9. 10. 10. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.  3.  3.] 
adversary cards in discard: [6. 0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6] -> size -> 12 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [14.  0.  3.  0.  0.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8.  9. 10. 10.  9.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.  3.  3.] 
adversary cards in discard: [6. 0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6] -> size -> 12 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [ 0. 25.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[308.88943]
 [322.5382 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.  3.  3.] 
cards in discard: [6. 0. 0. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9. 10. 10.  9.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -6.874539852142334
desired expected reward: 260.84417724609375



action possibilites: [-1] 
expected returns: [[263.1157]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 6. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  8. 10. 10.  9.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action 25.0
Learning step: -9.8458251953125
desired expected reward: 312.4727478027344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[237.5298 ]
 [246.00731]
 [206.68407]
 [249.2057 ]
 [262.20337]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 6. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8.  8. 10. 10.  9.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action -1
Learning step: -7.197198390960693
desired expected reward: 255.91848754882812



buy possibilites: [-1] 
expected returns: [[274.4453]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 6. 3.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8.  7. 10. 10.  9.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -20.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -304.0 

action type: buy - action 6.0
Learning step: -19.359182357788086
desired expected reward: 187.32489013671875






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.  0.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  7. 10. 10.  9.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 6. 25.  0.  0.  3.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6] -> size -> 13 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29.  0.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8.  7. 10. 10.  9.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 6. 25.  0.  0.  3.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6] -> size -> 13 
adversary victory points: 1
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[217.40904]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 6. 25.  0.  0.  3.  3.  6.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  7. 10. 10.  9.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 6.  0.  0.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6] -> size -> 15 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1
Learning step: -9.524931907653809
desired expected reward: 264.9203796386719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[175.9868 ]
 [192.24252]
 [185.79037]
 [154.7409 ]
 [143.81415]
 [182.9927 ]
 [199.5773 ]
 [186.62941]
 [211.29665]
 [186.4681 ]
 [159.4466 ]
 [169.23898]
 [182.20619]
 [151.70271]
 [174.74875]
 [200.89082]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 6. 25.  0.  0.  3.  3.  6.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 30. 30.  8.  7. 10. 10.  9.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 6.  0.  0.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6] -> size -> 15 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -6.573904514312744
desired expected reward: 197.2926025390625



buy possibilites: [-1] 
expected returns: [[216.29169]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 6. 25.  0.  0.  3.  3.  6.  3. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  7. 10. 10.  9.  8.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [ 6.  0.  0.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6] -> size -> 15 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0  50   0] 
sum of rewards: 36 

action type: buy - action 25.0
Learning step: -3.898271322250366
desired expected reward: 207.39840698242188






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 6.  0.  0.  0. 29.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  7. 10. 10.  9.  8.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  6. 25.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25] -> size -> 14 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 6.  0.  0.  0. 29.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8.  7. 10. 10.  9.  8.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  6. 25.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25] -> size -> 14 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [ 6.  0.  0.  0. 29.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8.  7. 10. 10.  9.  8.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  6. 25.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25] -> size -> 14 
adversary victory points: 1
player victory points: 2 





Player: 0 
cards in hand: [ 3.  6. 25.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[257.53244]
 [271.83575]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 25.  6.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  7. 10. 10.  9.  8.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  8. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6  0] -> size -> 16 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1
Learning step: -5.535813331604004
desired expected reward: 210.75587463378906



action possibilites: [-1] 
expected returns: [[183.3143]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  6. 10. 10.  9.  8.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  8. 14.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6  0  6] -> size -> 17 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: 7 

action type: take_action - action 25.0
Learning step: -9.024147033691406
desired expected reward: 260.9502258300781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[163.06277]
 [122.54336]
 [185.15173]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8.  6. 10. 10.  9.  8.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  8. 14.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6  0  6] -> size -> 17 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: take_action - action -1
Learning step: -5.075320720672607
desired expected reward: 178.23898315429688






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  8. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 14.  3.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6  0  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  6. 10. 10.  9.  8.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [25.  3.  6.  6.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25] -> size -> 14 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 14.  3.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6  0  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 30. 30.  8.  6. 10. 10.  9.  8.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [25.  3.  6.  6.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25] -> size -> 14 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 14.  3.] 
cards in discard: [6. 8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6  0  6  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  6. 10. 10.  8.  8.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [25.  3.  6.  6.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25] -> size -> 14 
adversary victory points: 1
player victory points: 1 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[181.8569]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [25.  3.  6.  6.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  6. 10. 10.  8.  8.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  0.] 
adversary cards in discard: [ 6.  8.  0.  0.  8. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6  0  6  8] -> size -> 18 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1.0
Learning step: -5.394305229187012
desired expected reward: 179.75743103027344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[155.65782]
 [171.85133]
 [165.43582]
 [134.972  ]
 [124.57042]
 [162.56061]
 [179.36937]
 [166.15402]
 [191.03954]
 [166.0323 ]
 [139.50505]
 [149.14392]
 [161.8568 ]
 [132.18861]
 [154.52893]
 [181.05347]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [25.  3.  6.  6.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 30. 30. 30. 30.  8.  6. 10. 10.  8.  8.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  0.] 
adversary cards in discard: [ 6.  8.  0.  0.  8. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6  0  6  8] -> size -> 18 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: take_action - action -1.0
Learning step: -5.363999843597412
desired expected reward: 175.22630310058594



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.  0.] 
cards in discard: [ 6.  8.  0.  0.  8. 14.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6  0  6  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  6. 10. 10.  8.  8.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25] -> size -> 14 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29.  0.] 
cards in discard: [ 6.  8.  0.  0.  8. 14.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6  0  6  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 30. 30.  8.  6. 10. 10.  8.  8.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25] -> size -> 14 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29.  0.] 
cards in discard: [ 6.  8.  0.  0.  8. 14.  3. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6  0  6  8 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8.  6. 10. 10.  8.  8.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25] -> size -> 14 
adversary victory points: 1
player victory points: 1 





Player: 0 
cards in hand: [ 0.  3.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[199.97893]
 [210.10217]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 25.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  6. 10. 10.  8.  8.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 6.] 
adversary cards in discard: [ 6.  8.  0.  0.  8. 14.  3. 10.  0.  0.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6  0  6  8 10] -> size -> 19 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1.0
Learning step: -4.616814136505127
desired expected reward: 176.43661499023438



action possibilites: [-1] 
expected returns: [[192.27927]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  5. 10. 10.  8.  8.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 6.] 
adversary cards in discard: [ 6.  8.  0.  0.  8. 14.  3. 10.  0.  0.  0. 29.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6  0  6  8 10  6] -> size -> 20 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  2] 
sum of rewards: 18 

action type: take_action - action 25.0
Learning step: -5.225233554840088
desired expected reward: 203.8050994873047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[168.99129]
 [184.63908]
 [175.92947]
 [149.69112]
 [139.11298]
 [175.93817]
 [190.01265]
 [180.49715]
 [204.41573]
 [179.87933]
 [152.30919]
 [159.79256]
 [173.44089]
 [145.48299]
 [165.6494 ]
 [189.50937]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 30. 30. 30. 30.  8.  5. 10. 10.  8.  8.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 6.] 
adversary cards in discard: [ 6.  8.  0.  0.  8. 14.  3. 10.  0.  0.  0. 29.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6  0  6  8 10  6] -> size -> 20 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: take_action - action -1
Learning step: -4.659660816192627
desired expected reward: 187.61959838867188



buy possibilites: [-1] 
expected returns: [[236.2663]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 5 
card supply: [27. 30. 30. 30. 30.  8.  5. 10. 10.  8.  8.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 6.] 
adversary cards in discard: [ 6.  8.  0.  0.  8. 14.  3. 10.  0.  0.  0. 29.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6  0  6  8 10  6] -> size -> 20 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1.   0.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -14.0 

action type: buy - action 0.0
Learning step: -3.8335728645324707
desired expected reward: 165.15771484375






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 6.] 
cards in discard: [ 6.  8.  0.  0.  8. 14.  3. 10.  0.  0.  0. 29.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6  0  6  8 10  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8.  5. 10. 10.  8.  8.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 6. 3. 3.] 
adversary cards in discard: [ 0. 25.  0.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0] -> size -> 15 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 6.] 
cards in discard: [ 6.  8.  0.  0.  8. 14.  3. 10.  0.  0.  0. 29.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6  0  6  8 10  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 30. 30.  8.  5. 10. 10.  8.  8.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 6. 3. 3.] 
adversary cards in discard: [ 0. 25.  0.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0] -> size -> 15 
adversary victory points: 1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 6. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[202.61493]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 3. 3.] 
cards in discard: [ 0. 25.  0.  3.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8.  5. 10. 10.  8.  8.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6  0  6  8 10  6] -> size -> 20 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1
Learning step: -6.990235805511475
desired expected reward: 229.27606201171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[180.81078]
 [189.25137]
 [152.92175]
 [190.40106]
 [205.29356]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 3.] 
cards in discard: [ 0. 25.  0.  3.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 30. 30.  8.  5. 10. 10.  8.  8.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6  0  6  8 10  6] -> size -> 20 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: -5.418921947479248
desired expected reward: 195.6068115234375



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6  0  6  8 10  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8.  5. 10. 10.  8.  8.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 25.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0] -> size -> 15 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6  0  6  8 10  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 30. 30.  8.  5. 10. 10.  8.  8.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 25.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0] -> size -> 15 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6  0  6  8 10  6  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  5. 10. 10.  8.  8.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 25.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0] -> size -> 15 
adversary victory points: 1
player victory points: 0 





Player: 0 
cards in hand: [ 3.  0.  0. 25.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[133.20006]
 [142.68776]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 25.  6.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  5. 10. 10.  8.  8.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  6. 14. 29.  0.] 
adversary cards in discard: [1. 3. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6  0  6  8 10  6  1] -> size -> 21 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1.0
Learning step: -6.884366512298584
desired expected reward: 198.40921020507812



action possibilites: [-1] 
expected returns: [[180.47043]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 6. 6. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  4. 10. 10.  8.  8.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  6. 14. 29.  0.] 
adversary cards in discard: [1. 3. 0. 0. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6  0  6  8 10  6  1  6] -> size -> 22 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 27 

action type: take_action - action 25.0
Learning step: -1.580424189567566
desired expected reward: 138.23974609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[150.25746]
 [165.20291]
 [157.59373]
 [118.88378]
 [171.04085]
 [160.99208]
 [155.14769]
 [171.39627]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 6. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 30. 30.  8.  4. 10. 10.  8.  8.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  6. 14. 29.  0.] 
adversary cards in discard: [1. 3. 0. 0. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6  0  6  8 10  6  1  6] -> size -> 22 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: take_action - action -1
Learning step: -4.0677103996276855
desired expected reward: 176.40272521972656



buy possibilites: [-1] 
expected returns: [[193.6882]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 6. 0.] 
cards in discard: [1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8.  4. 10. 10.  8.  8.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  6. 14. 29.  0.] 
adversary cards in discard: [1. 3. 0. 0. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6  0  6  8 10  6  1  6] -> size -> 22 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 44 

action type: buy - action 1.0
Learning step: -1.3699272871017456
desired expected reward: 157.1883087158203






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 0.  6. 14. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 14. 29.  0.] 
cards in discard: [1. 3. 0. 0. 0. 3. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6  0  6  8 10  6  1  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8.  4. 10. 10.  8.  8.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 25.  0.  0.] 
adversary cards in discard: [ 1. 25.  3.  0.  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1] -> size -> 16 
adversary victory points: 1
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 29.  0.] 
cards in discard: [1. 3. 0. 0. 0. 3. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6  0  6  8 10  6  1  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 30. 30.  8.  4. 10. 10.  8.  8.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 25.  0.] 
adversary cards in discard: [ 1. 25.  3.  0.  0.  6.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1] -> size -> 16 
adversary victory points: 1
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 29.  0.] 
cards in discard: [1. 3. 0. 0. 0. 3. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6  0  6  8 10  6  1  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 28. 30. 30. 30.  8.  4. 10. 10.  8.  8.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 25.  0.] 
adversary cards in discard: [ 1. 25.  3.  0.  0.  6.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1] -> size -> 16 
adversary victory points: 1
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 29.  0.] 
cards in discard: [1. 3. 0. 0. 0. 3. 6. 8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6  0  6  8 10  6  1  6  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 30. 30.  8.  4. 10. 10.  7.  8.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 25.  0.] 
adversary cards in discard: [ 1. 25.  3.  0.  0.  6.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1] -> size -> 16 
adversary victory points: 1
player victory points: -1 





Player: 0 
cards in hand: [ 3. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[117.20129]
 [127.87006]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  0.] 
cards in discard: [ 1. 25.  3.  0.  0.  6.  6.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8.  4. 10. 10.  7.  8.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 8. 6. 6.] 
adversary cards in discard: [ 1.  3.  0.  0.  0.  3.  6.  8. 14.  0.  6. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6  0  6  8 10  6  1  6  8] -> size -> 23 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  1 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: discard_down_to_3_cards - action 1
Learning step: -3.993349552154541
desired expected reward: 147.6625518798828



action possibilites: [-1] 
expected returns: [[149.35086]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [ 1. 25.  3.  0.  0.  6.  6.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8.  3. 10. 10.  7.  8.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 8. 6. 6.] 
adversary cards in discard: [ 1.  3.  0.  0.  0.  3.  6.  8. 14.  0.  6. 29.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6  0  6  8 10  6  1  6  8  6] -> size -> 24 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  1 20  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 37 

action type: take_action - action 25.0
Learning step: -1.1381183862686157
desired expected reward: 125.83213806152344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[126.7494  ]
 [135.99113 ]
 [ 96.788124]
 [136.0434  ]
 [149.45213 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [ 1. 25.  3.  0.  0.  6.  6.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 30. 30.  8.  3. 10. 10.  7.  8.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 8. 6. 6.] 
adversary cards in discard: [ 1.  3.  0.  0.  0.  3.  6.  8. 14.  0.  6. 29.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6  0  6  8 10  6  1  6  8  6] -> size -> 24 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  1 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 36 

action type: take_action - action -1
Learning step: -2.5768392086029053
desired expected reward: 146.77401733398438






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 6. 6.] 
cards in discard: [ 1.  3.  0.  0.  0.  3.  6.  8. 14.  0.  6. 29.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6  0  6  8 10  6  1  6  8  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8.  3. 10. 10.  7.  8.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1] -> size -> 16 
adversary victory points: 1
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 6. 6.] 
cards in discard: [ 1.  3.  0.  0.  0.  3.  6.  8. 14.  0.  6. 29.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6  0  6  8 10  6  1  6  8  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 30. 30.  8.  3. 10. 10.  7.  8.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1] -> size -> 16 
adversary victory points: 1
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 6. 6.] 
cards in discard: [ 1.  3.  0.  0.  0.  3.  6.  8. 14.  0.  6. 29.  0.  6.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6  0  6  8 10  6  1  6  8  6
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8.  3. 10. 10.  6.  8.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1] -> size -> 16 
adversary victory points: 1
player victory points: -2 





Player: 0 
cards in hand: [0. 3. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[78.946785]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8.  3. 10. 10.  6.  8.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  0.  3. 10.  0.] 
adversary cards in discard: [ 1.  3.  0.  0.  0.  3.  6.  8. 14.  0.  6. 29.  0.  6.  8.  0.  0.  8.
  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6  0  6  8 10  6  1  6  8  6
  8] -> size -> 25 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  1 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: buy - action -1.0
Learning step: -4.439259052276611
desired expected reward: 145.01287841796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[60.77251 ]
 [73.03216 ]
 [65.42356 ]
 [39.297092]
 [78.06877 ]
 [70.12645 ]
 [64.28403 ]
 [78.55995 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 30. 30.  8.  3. 10. 10.  6.  8.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  0.  3. 10.  0.] 
adversary cards in discard: [ 1.  3.  0.  0.  0.  3.  6.  8. 14.  0.  6. 29.  0.  6.  8.  0.  0.  8.
  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6  0  6  8 10  6  1  6  8  6
  8] -> size -> 25 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  1 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: take_action - action -1.0
Learning step: -0.948743462562561
desired expected reward: 76.08893585205078



buy possibilites: [-1] 
expected returns: [[117.34502]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 0.] 
cards in discard: [8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 30. 30.  8.  3. 10. 10.  5.  8.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  0.  3. 10.  0.] 
adversary cards in discard: [ 1.  3.  0.  0.  0.  3.  6.  8. 14.  0.  6. 29.  0.  6.  8.  0.  0.  8.
  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6  0  6  8 10  6  1  6  8  6
  8] -> size -> 25 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5.  0.  1. 30.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 28.0 

action type: buy - action 8.0
Learning step: 0.5339401364326477
desired expected reward: 70.66039276123047






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3. 10.  0.] 
cards in discard: [ 1.  3.  0.  0.  0.  3.  6.  8. 14.  0.  6. 29.  0.  6.  8.  0.  0.  8.
  6.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29 14  8  6  0  6  8 10  6  1  6  8  6
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8.  3. 10. 10.  5.  8.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [8. 0. 3. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8] -> size -> 17 
adversary victory points: 1
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 1.  3.  0.  0.  0.  3.  6.  8. 14.  0.  6. 29.  0.  6.  8.  0.  0.  8.
  6.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 29 14  8  6  0  6  8  6  1  6  8  6  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8.  3. 10. 10.  5.  8.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [8. 0. 3. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8] -> size -> 17 
adversary victory points: 1
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 1.  3.  0.  0.  0.  3.  6.  8. 14.  0.  6. 29.  0.  6.  8.  0.  0.  8.
  6.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 29 14  8  6  0  6  8  6  1  6  8  6  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 30. 30.  8.  3. 10. 10.  5.  8.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [8. 0. 3. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8] -> size -> 17 
adversary victory points: 1
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 1.  3.  0.  0.  0.  3.  6.  8. 14.  0.  6. 29.  0.  6.  8.  0.  0.  8.
  6.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 29 14  8  6  0  6  8  6  1  6  8  6  8  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 30. 30.  8.  3. 10. 10.  5.  8.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [8. 0. 3. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8] -> size -> 17 
adversary victory points: 1
player victory points: -3 





Player: 0 
cards in hand: [0. 0. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[233.45628]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [8. 0. 3. 0. 6. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8.  3. 10. 10.  5.  8.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 6.  0.  8.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 29 14  8  6  0  6  8  6  1  6  8  6  8  0] -> size -> 23 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[-5  0  1 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 36 

action type: buy - action -1
Learning step: 1.1284202337265015
desired expected reward: 118.47343444824219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[211.94664]
 [224.55305]
 [218.52191]
 [194.91402]
 [185.33125]
 [217.5368 ]
 [229.78728]
 [220.56366]
 [238.41934]
 [220.50392]
 [198.06197]
 [205.3225 ]
 [216.34267]
 [191.78914]
 [210.12599]
 [230.40698]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [8. 0. 3. 0. 6. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 28. 30. 30. 30.  8.  3. 10. 10.  5.  8.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 6.  0.  8.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 29 14  8  6  0  6  8  6  1  6  8  6  8  0] -> size -> 23 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[-5  0  1 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 36 

action type: take_action - action -1.0
Learning step: -4.714509010314941
desired expected reward: 226.20419311523438



buy possibilites: [-1] 
expected returns: [[167.7375]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [ 8.  0.  3.  0.  6.  0. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8.  3. 10. 10.  5.  7.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 6.  0.  8.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 29 14  8  6  0  6  8  6  1  6  8  6  8  0] -> size -> 23 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[-5  0  1 40  0  0  0  0  0  0  0  0  0  0 50  0] 
sum of rewards: 86 

action type: buy - action 25.0
Learning step: -3.8468728065490723
desired expected reward: 234.57244873046875






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 6.  0.  8.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  8.  3. 29.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 29 14  8  6  0  6  8  6  1  6  8  6  8  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8.  3. 10. 10.  5.  7.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [25.  0.  3.  0.  6.] 
adversary cards in discard: [ 8.  0.  3.  0.  6.  0. 25.  0.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25] -> size -> 18 
adversary victory points: 1
player victory points: -3 


action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 3. 8.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 29 14  8  6  0  6  8  6  1  6  8  6  8  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 30. 30.  8.  3. 10. 10.  5.  7.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [25.  0.  3.  0.  6.] 
adversary cards in discard: [ 8.  0.  3.  0.  6.  0. 25.  0.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25] -> size -> 18 
adversary victory points: 1
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 3. 8.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 29 14  8  6  0  6  8  6  1  6  8  6  8  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 30. 30.  8.  3. 10. 10.  5.  7.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [25.  0.  3.  0.  6.] 
adversary cards in discard: [ 8.  0.  3.  0.  6.  0. 25.  0.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25] -> size -> 18 
adversary victory points: 1
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 3. 8.] 
cards in discard: [8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 29 14  8  6  0  6  8  6  1  6  8  6  8  0  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8.  3. 10. 10.  4.  7.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [25.  0.  3.  0.  6.] 
adversary cards in discard: [ 8.  0.  3.  0.  6.  0. 25.  0.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25] -> size -> 18 
adversary victory points: 1
player victory points: -3 





Player: 0 
cards in hand: [25.  0.  3.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[130.4768 ]
 [140.55748]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  3.  0.  6.] 
cards in discard: [ 8.  0.  3.  0.  6.  0. 25.  0.  0.  3.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8.  3. 10. 10.  4.  7.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 6. 0. 6.] 
adversary cards in discard: [ 8. 29.  6.  0.  8.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 29 14  8  6  0  6  8  6  1  6  8  6  8  0  8] -> size -> 24 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[-5  0  1 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 36 

action type: buy - action -1
Learning step: -3.503744602203369
desired expected reward: 164.2337646484375



action possibilites: [-1] 
expected returns: [[61.400593]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  6.  0. 25.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8.  2. 10. 10.  4.  7.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 6. 0. 6.] 
adversary cards in discard: [ 8. 29.  6.  0.  8.  3.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 29 14  8  6  0  6  8  6  1  6  8  6  8  0  8
  6] -> size -> 25 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[-5  0  1 40  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 57 

action type: take_action - action 25.0
Learning step: -2.7689895629882812
desired expected reward: 137.24105834960938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[50.371204]
 [58.433666]
 [55.233776]
 [38.111084]
 [62.867054]
 [55.731712]
 [53.77772 ]
 [64.09053 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  6.  0. 25.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 30. 30.  8.  2. 10. 10.  4.  7.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 6. 0. 6.] 
adversary cards in discard: [ 8. 29.  6.  0.  8.  3.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 29 14  8  6  0  6  8  6  1  6  8  6  8  0  8
  6] -> size -> 25 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[-5  0  1 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 56 

action type: take_action - action -1
Learning step: 1.0487943887710571
desired expected reward: 62.44938659667969



buy possibilites: [-1] 
expected returns: [[82.81361]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  6.  0. 25.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 28. 30. 30. 30.  8.  2. 10. 10.  4.  7.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 6. 0. 6.] 
adversary cards in discard: [ 8. 29.  6.  0.  8.  3.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 29 14  8  6  0  6  8  6  1  6  8  6  8  0  8
  6] -> size -> 25 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1.  40.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 26.0 

action type: buy - action 0.0
Learning step: 0.6447458267211914
desired expected reward: 51.01594924926758






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [0. 0. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 6.] 
cards in discard: [ 8. 29.  6.  0.  8.  3.  8.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 29 14  8  6  0  6  8  6  1  6  8  6  8  0  8
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 30.  8.  2. 10. 10.  4.  7.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [6. 1. 0. 8. 0.] 
adversary cards in discard: [ 0. 25.  0.  3.  0.  6.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0] -> size -> 19 
adversary victory points: 1
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 6.] 
cards in discard: [ 8. 29.  6.  0.  8.  3.  8.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 29 14  8  6  0  6  8  6  1  6  8  6  8  0  8
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 30. 30.  8.  2. 10. 10.  4.  7.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [6. 1. 0. 8. 0.] 
adversary cards in discard: [ 0. 25.  0.  3.  0.  6.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0] -> size -> 19 
adversary victory points: 1
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 6.] 
cards in discard: [ 8. 29.  6.  0.  8.  3.  8.  6.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 29 14  8  6  0  6  8  6  1  6  8  6  8  0  8
  6  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 30. 30.  8.  2. 10. 10.  3.  7.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [6. 1. 0. 8. 0.] 
adversary cards in discard: [ 0. 25.  0.  3.  0.  6.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0] -> size -> 19 
adversary victory points: 1
player victory points: -4 





Player: 0 
cards in hand: [6. 1. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[125.18224]
 [111.50326]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 0. 8. 0.] 
cards in discard: [ 0. 25.  0.  3.  0.  6.  0. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 30.  8.  2. 10. 10.  3.  7.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 6.] 
adversary cards in discard: [ 8. 29.  6.  0.  8.  3.  8.  6.  8.  0.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 29 14  8  6  0  6  8  6  1  6  8  6  8  0  8
  6  8] -> size -> 26 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[-5  0  1 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 46 

action type: buy - action -1
Learning step: 0.8166522979736328
desired expected reward: 83.63025665283203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[101.576454]
 [113.6628  ]
 [109.73614 ]
 [ 80.01752 ]
 [106.70467 ]
 [119.949135]
 [108.97458 ]
 [109.04103 ]
 [ 91.16884 ]
 [106.99981 ]
 [101.895744]
 [122.53891 ]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 0. 8. 0.] 
cards in discard: [ 0. 25.  0.  3.  0.  6.  0. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 28. 30. 30. 30.  8.  2. 10. 10.  3.  7.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 6.] 
adversary cards in discard: [ 8. 29.  6.  0.  8.  3.  8.  6.  8.  0.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 29 14  8  6  0  6  8  6  1  6  8  6  8  0  8
  6  8] -> size -> 26 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[-5  0  1 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 46 

action type: take_action - action -1.0
Learning step: -1.0395115613937378
desired expected reward: 116.49943542480469



buy possibilites: [-1] 
expected returns: [[86.3916]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 0. 8. 0.] 
cards in discard: [ 0. 25.  0.  3.  0.  6.  0. 25. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 30.  8.  2. 10. 10.  3.  7.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 6.] 
adversary cards in discard: [ 8. 29.  6.  0.  8.  3.  8.  6.  8.  0.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 29 14  8  6  0  6  8  6  1  6  8  6  8  0  8
  6  8] -> size -> 26 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[-5  0  1 50  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 78 

action type: buy - action 14.0
Learning step: 1.2853691577911377
desired expected reward: 92.45420837402344






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [0. 0. 1. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 6.] 
cards in discard: [ 8. 29.  6.  0.  8.  3.  8.  6.  8.  0.  0.  6.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 29 14  8  6  0  6  8  6  1  6  8  6  8  0  8
  6  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 30. 30.  8.  2. 10. 10.  3.  7.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [25.  3.  0.  3.  0.] 
adversary cards in discard: [ 0. 25.  0.  3.  0.  6.  0. 25. 14.  6.  1.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14] -> size -> 20 
adversary victory points: 1
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 6.] 
cards in discard: [ 8. 29.  6.  0.  8.  3.  8.  6.  8.  0.  0.  6.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 29 14  8  6  0  6  8  6  1  6  8  6  8  0  8
  6  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 28. 30. 30. 30.  8.  2. 10. 10.  3.  7.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [25.  3.  0.  3.  0.] 
adversary cards in discard: [ 0. 25.  0.  3.  0.  6.  0. 25. 14.  6.  1.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14] -> size -> 20 
adversary victory points: 1
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 6.] 
cards in discard: [ 8. 29.  6.  0.  8.  3.  8.  6.  8.  0.  0.  6.  0.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 29 14  8  6  0  6  8  6  1  6  8  6  8  0  8
  6  8  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 5 
card supply: [24. 28. 30. 30. 30.  8.  2. 10. 10.  3.  7.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [25.  3.  0.  3.  0.] 
adversary cards in discard: [ 0. 25.  0.  3.  0.  6.  0. 25. 14.  6.  1.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14] -> size -> 20 
adversary victory points: 1
player victory points: -4 





Player: 0 
cards in hand: [25.  3.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[37.417213]
 [47.977016]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0.  3.  0.] 
cards in discard: [ 0. 25.  0.  3.  0.  6.  0. 25. 14.  6.  1.  0.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 30. 30.  8.  2. 10. 10.  3.  7.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  6.  0. 14.] 
adversary cards in discard: [ 8. 29.  6.  0.  8.  3.  8.  6.  8.  0.  0.  6.  0.  6.  0.  0.  0.  1.
  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 29 14  8  6  0  6  8  6  1  6  8  6  8  0  8
  6  8  0] -> size -> 27 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[-5  0  1 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 46 

action type: buy - action -1
Learning step: -1.0103248357772827
desired expected reward: 85.38127899169922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[20.85808 ]
 [25.126825]
 [10.637382]
 [24.251162]
 [33.57982 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3.  0.  3.  0.] 
cards in discard: [ 0. 25.  0.  3.  0.  6.  0. 25. 14.  6.  1.  0.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 30. 30.  8.  2. 10. 10.  3.  7.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  6.  0. 14.] 
adversary cards in discard: [ 8. 29.  6.  0.  8.  3.  8.  6.  8.  0.  0.  6.  0.  6.  0.  0.  0.  1.
  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 29 14  8  6  0  6  8  6  1  6  8  6  8  0  8
  6  8  0] -> size -> 27 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[-5  0  1 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 46 

action type: take_action - action -1.0
Learning step: 1.0425083637237549
desired expected reward: 38.45973205566406



buy possibilites: [-1] 
expected returns: [[72.98251]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3.  0.  3.  0.] 
cards in discard: [ 0. 25.  0.  3.  0.  6.  0. 25. 14.  6.  1.  0.  8.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  2. 10. 10.  3.  7.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  6.  0. 14.] 
adversary cards in discard: [ 8. 29.  6.  0.  8.  3.  8.  6.  8.  0.  0.  6.  0.  6.  0.  0.  0.  1.
  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 29 14  8  6  0  6  8  6  1  6  8  6  8  0  8
  6  8  0] -> size -> 27 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[-5  0  2 60  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 65 

action type: buy - action 3.0
Learning step: 3.635765552520752
desired expected reward: 28.762590408325195






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  6.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  6.  0. 14.] 
cards in discard: [ 8. 29.  6.  0.  8.  3.  8.  6.  8.  0.  0.  6.  0.  6.  0.  0.  0.  1.
  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 29 14  8  6  0  6  8  6  1  6  8  6  8  0  8
  6  8  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  2. 10. 10.  3.  7.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [25.  3.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3] -> size -> 21 
adversary victory points: 2
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 0.] 
cards in discard: [ 8. 29.  6.  0.  8.  3.  8.  6.  8.  0.  0.  6.  0.  6.  0.  0.  0.  1.
  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 29 14  8  6  0  6  8  6  1  6  8  6  8  0  8
  6  8  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 28. 30. 29. 30.  8.  2. 10. 10.  3.  7.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [25.  3.  0.] 
adversary cards in discard: [3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3] -> size -> 21 
adversary victory points: 2
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0.] 
cards in discard: [ 8. 29.  6.  0.  8.  3.  8.  6.  8.  0.  0.  6.  0.  6.  0.  0.  0.  1.
  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 29 14  8  6  0  6  8  6  1  6  8  6  8  0  8
  6  8  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 28. 30. 29. 30.  8.  2. 10. 10.  3.  7.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [25.  3.  0.] 
adversary cards in discard: [3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3] -> size -> 21 
adversary victory points: 2
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0.] 
cards in discard: [ 8. 29.  6.  0.  8.  3.  8.  6.  8.  0.  0.  6.  0.  6.  0.  0.  0.  1.
  0.  6. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 29 14  8  6  0  6  8  6  1  6  8  6  8  0  8
  6  8  0 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 29. 30.  8.  2. 10. 10.  3.  7.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [25.  3.  0.] 
adversary cards in discard: [3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3] -> size -> 21 
adversary victory points: 2
player victory points: -4 





Player: 0 
cards in hand: [25.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[68.227455]
 [75.680954]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0.] 
cards in discard: [3. 3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  2. 10. 10.  3.  7.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  8. 29.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 29 14  8  6  0  6  8  6  1  6  8  6  8  0  8
  6  8  0 10] -> size -> 28 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[-5  0  2 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 57 

action type: discard_down_to_3_cards - action 1
Learning step: 2.6193740367889404
desired expected reward: 38.400291442871094



action possibilites: [-1] 
expected returns: [[89.18927]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 25.  6.] 
cards in discard: [3. 3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  1. 10. 10.  3.  7.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  8. 29.  8.  8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 29 14  8  6  0  6  8  6  1  6  8  6  8  0  8
  6  8  0 10  6] -> size -> 29 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[-5  0  2 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 77 

action type: take_action - action 25.0
Learning step: 2.2894628047943115
desired expected reward: 73.6353759765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 84.17637]
 [ 61.76707]
 [100.49787]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 25.  6.] 
cards in discard: [3. 3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 28. 30. 29. 30.  8.  1. 10. 10.  3.  7.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  8. 29.  8.  8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 29 14  8  6  0  6  8  6  1  6  8  6  8  0  8
  6  8  0 10  6] -> size -> 29 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[-5  0  2 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 77 

action type: take_action - action -1
Learning step: 1.4076553583145142
desired expected reward: 90.596923828125






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 0.  8. 29.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.  8.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 29.  8.  8.] 
cards in discard: [6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 29 14  8  6  0  6  8  6  1  6  8  6  8  0  8
  6  8  0 10  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  1. 10. 10.  3.  7.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [25.  0.  0.  3.  6.] 
adversary cards in discard: [ 3.  3. 25.  3.  0. 25.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3] -> size -> 21 
adversary victory points: 2
player victory points: -5 


action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 8. 0.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 29 14  8  6  0  6  8  6  1  6  8  6  8  0  8
  6  8  0 10  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 29. 30.  8.  1. 10. 10.  3.  7.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [25.  0.  0.  3.  6.] 
adversary cards in discard: [ 3.  3. 25.  3.  0. 25.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3] -> size -> 21 
adversary victory points: 2
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  3  3  0 29 14  6  0  6  8  6  1  6  8  6  8  0  8  6  8
  0 10  6] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 29. 30.  8.  1. 10. 10.  3.  7.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [25.  0.  0.  3.  6.] 
adversary cards in discard: [ 3.  3. 25.  3.  0. 25.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3] -> size -> 21 
adversary victory points: 2
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  3  3  0 29 14  6  0  6  8  6  1  6  8  6  8  0  8  6  8
  0 10  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 29. 30.  8.  1. 10. 10.  3.  7.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [25.  0.  0.  3.  6.] 
adversary cards in discard: [ 3.  3. 25.  3.  0. 25.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3] -> size -> 21 
adversary victory points: 2
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [6. 8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  3  3  0 29 14  6  0  6  8  6  1  6  8  6  8  0  8  6  8
  0 10  6  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  1. 10. 10.  2.  7.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [25.  0.  0.  3.  6.] 
adversary cards in discard: [ 3.  3. 25.  3.  0. 25.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3] -> size -> 21 
adversary victory points: 2
player victory points: -5 





Player: 0 
cards in hand: [25.  0.  0.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[72.34523]
 [77.69663]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.  3.  6.] 
cards in discard: [ 3.  3. 25.  3.  0. 25.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  1. 10. 10.  2.  7.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [6. 3. 0. 6. 0.] 
adversary cards in discard: [ 6.  8. 29.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 29 14  6  0  6  8  6  1  6  8  6  8  0  8  6  8
  0 10  6  8] -> size -> 28 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[-5  0  2 70  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 67 

action type: buy - action -1.0
Learning step: 0.0009067535283975303
desired expected reward: 100.49879455566406



action possibilites: [-1] 
expected returns: [[101.24657]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 6. 0. 0.] 
cards in discard: [ 3.  3. 25.  3.  0. 25.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  0. 10. 10.  2.  7.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [6. 3. 0. 6. 0.] 
adversary cards in discard: [ 6.  8. 29.  8.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 29 14  6  0  6  8  6  1  6  8  6  8  0  8  6  8
  0 10  6  8  6] -> size -> 29 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[-5  0  2 70  0  0 20  0  0  0  0  0  0  0  0  2] 
sum of rewards: 89 

action type: take_action - action 25.0
Learning step: 2.9256362915039062
desired expected reward: 78.97386932373047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 93.453514]
 [104.19397 ]
 [100.69669 ]
 [ 97.847206]
 [108.79374 ]
 [ 99.67951 ]
 [ 99.667274]
 [ 84.458534]
 [ 97.59228 ]
 [ 93.09644 ]
 [109.29137 ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 0. 0.] 
cards in discard: [ 3.  3. 25.  3.  0. 25.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 28. 30. 29. 30.  8.  0. 10. 10.  2.  7.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [6. 3. 0. 6. 0.] 
adversary cards in discard: [ 6.  8. 29.  8.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 29 14  6  0  6  8  6  1  6  8  6  8  0  8  6  8
  0 10  6  8  6] -> size -> 29 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[-5  0  2 70  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 87 

action type: take_action - action -1
Learning step: 1.609565019607544
desired expected reward: 102.85613250732422



buy possibilites: [-1] 
expected returns: [[49.21314]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 0. 0.] 
cards in discard: [ 3.  3. 25.  3.  0. 25.  6. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  0.  9. 10.  2.  7.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [6. 3. 0. 6. 0.] 
adversary cards in discard: [ 6.  8. 29.  8.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 29 14  6  0  6  8  6  1  6  8  6  8  0  8  6  8
  0 10  6  8  6] -> size -> 29 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[-5  0  2 70  0  0 20  0  0  0  0  0  0  0 32  0] 
sum of rewards: 119 

action type: buy - action 16.0
Learning step: 2.164935350418091
desired expected reward: 100.01213073730469






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [6. 3. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 6. 0.] 
cards in discard: [ 6.  8. 29.  8.  8.  0.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 29 14  6  0  6  8  6  1  6  8  6  8  0  8  6  8
  0 10  6  8  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  0.  9. 10.  2.  7.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [ 3.  3. 25.  3.  0. 25.  6. 16. 25.  0.  0.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16] -> size -> 22 
adversary victory points: 2
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 6. 0.] 
cards in discard: [ 6.  8. 29.  8.  8.  0.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 29 14  6  0  6  8  6  1  6  8  6  8  0  8  6  8
  0 10  6  8  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 29. 30.  8.  0.  9. 10.  2.  7.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [ 3.  3. 25.  3.  0. 25.  6. 16. 25.  0.  0.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16] -> size -> 22 
adversary victory points: 2
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 6. 0.] 
cards in discard: [ 6.  8. 29.  8.  8.  0.  6.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 29 14  6  0  6  8  6  1  6  8  6  8  0  8  6  8
  0 10  6  8  6  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  0.  9. 10.  1.  7.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [ 3.  3. 25.  3.  0. 25.  6. 16. 25.  0.  0.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16] -> size -> 22 
adversary victory points: 2
player victory points: -6 





Player: 0 
cards in hand: [8. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[ 7.089264 ]
 [-7.4704714]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [ 3.  3. 25.  3.  0. 25.  6. 16. 25.  0.  0.  3.  6.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  0.  9. 10.  1.  7.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  8.  0. 10.] 
adversary cards in discard: [ 6.  8. 29.  8.  8.  0.  6.  8.  6.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 29 14  6  0  6  8  6  1  6  8  6  8  0  8  6  8
  0 10  6  8  6  8] -> size -> 30 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[-5  0  2 80  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 77 

action type: buy - action -1
Learning step: 1.4520219564437866
desired expected reward: 50.6651611328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ -7.4409766 ]
 [  6.8246393 ]
 [  3.4156196 ]
 [ -2.0053034 ]
 [ 13.154379  ]
 [ -0.34059286]
 [ -0.15102434]
 [-11.728463  ]
 [ -2.234019  ]
 [ -6.737205  ]
 [ 14.857498  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [ 3.  3. 25.  3.  0. 25.  6. 16. 25.  0.  0.  3.  6.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 28. 30. 29. 30.  8.  0.  9. 10.  1.  7.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  8.  0. 10.] 
adversary cards in discard: [ 6.  8. 29.  8.  8.  0.  6.  8.  6.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 29 14  6  0  6  8  6  1  6  8  6  8  0  8  6  8
  0 10  6  8  6  8] -> size -> 30 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[-5  0  2 80  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 77 

action type: take_action - action -1.0
Learning step: 3.641418933868408
desired expected reward: 10.730674743652344



buy possibilites: [-1] 
expected returns: [[20.783632]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [ 3.  3. 25.  3.  0. 25.  6. 16. 25.  0.  0.  3.  6.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 4 
card supply: [23. 28. 30. 29. 30.  8.  0.  9. 10.  1.  7.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  8.  0. 10.] 
adversary cards in discard: [ 6.  8. 29.  8.  8.  0.  6.  8.  6.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 29 14  6  0  6  8  6  1  6  8  6  8  0  8  6  8
  0 10  6  8  6  8] -> size -> 30 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2.  80.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 47.0 

action type: buy - action 0.0
Learning step: 3.19180965423584
desired expected reward: -4.249171733856201






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8.  0. 10.] 
cards in discard: [ 6.  8. 29.  8.  8.  0.  6.  8.  6.  3.  0.  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 29 14  6  0  6  8  6  1  6  8  6  8  0  8  6  8
  0 10  6  8  6  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 29. 30.  8.  0.  9. 10.  1.  7.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 25.  0. 14.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16  0] -> size -> 23 
adversary victory points: 2
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8.  0. 10.] 
cards in discard: [ 6.  8. 29.  8.  8.  0.  6.  8.  6.  3.  0.  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 29 14  6  0  6  8  6  1  6  8  6  8  0  8  6  8
  0 10  6  8  6  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 28. 30. 29. 30.  8.  0.  9. 10.  1.  7.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 25.  0. 14.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16  0] -> size -> 23 
adversary victory points: 2
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8.  0. 10.] 
cards in discard: [ 6.  8. 29.  8.  8.  0.  6.  8.  6.  3.  0.  6.  0.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 29 14  6  0  6  8  6  1  6  8  6  8  0  8  6  8
  0 10  6  8  6  8  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 29. 30.  8.  0.  9. 10.  1.  7.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 25.  0. 14.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16  0] -> size -> 23 
adversary victory points: 2
player victory points: -6 





Player: 0 
cards in hand: [ 3. 25.  0. 14.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 14.] 
expected returns: [[16.393435 ]
 [13.719336 ]
 [ 5.1100993]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  0. 14.  1.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 29. 30.  8.  0.  9. 10.  1.  7.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [6. 8. 6. 8. 6.] 
adversary cards in discard: [ 6.  8. 29.  8.  8.  0.  6.  8.  6.  3.  0.  6.  0.  1.  0.  0.  8.  0.
 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 29 14  6  0  6  8  6  1  6  8  6  8  0  8  6  8
  0 10  6  8  6  8  1] -> size -> 31 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[-5  0  2 80  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 77 

action type: buy - action -1
Learning step: 3.088979721069336
desired expected reward: 23.87261199951172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[ 5.6270385]
 [ 7.649056 ]
 [ 9.879187 ]
 [11.24786  ]
 [ 5.281593 ]
 [ 8.203556 ]
 [15.656273 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25.  0. 14.  1.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 27. 30. 29. 30.  8.  0.  9. 10.  1.  7.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [6. 8. 6. 8. 6.] 
adversary cards in discard: [ 6.  8. 29.  8.  8.  0.  6.  8.  6.  3.  0.  6.  0.  1.  0.  0.  8.  0.
 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 29 14  6  0  6  8  6  1  6  8  6  8  0  8  6  8
  0 10  6  8  6  8  1] -> size -> 31 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[-5  0  2 80  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 77 

action type: take_action - action -1.0
Learning step: 3.345546007156372
desired expected reward: 18.729948043823242



buy possibilites: [-1] 
expected returns: [[38.475487]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25.  0. 14.  1.] 
cards in discard: [3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 28. 30.  8.  0.  9. 10.  1.  7.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [6. 8. 6. 8. 6.] 
adversary cards in discard: [ 6.  8. 29.  8.  8.  0.  6.  8.  6.  3.  0.  6.  0.  1.  0.  0.  8.  0.
 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 29 14  6  0  6  8  6  1  6  8  6  8  0  8  6  8
  0 10  6  8  6  8  1] -> size -> 31 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3. 90.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 90.0 

action type: buy - action 3.0
Learning step: 4.871738910675049
desired expected reward: 14.750925064086914






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [6. 8. 6. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 6. 8. 6.] 
cards in discard: [ 6.  8. 29.  8.  8.  0.  6.  8.  6.  3.  0.  6.  0.  1.  0.  0.  8.  0.
 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 29 14  6  0  6  8  6  1  6  8  6  8  0  8  6  8
  0 10  6  8  6  8  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 28. 30.  8.  0.  9. 10.  1.  7.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  6. 25.  6.] 
adversary cards in discard: [ 3.  3. 25.  0. 14.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3] -> size -> 24 
adversary victory points: 3
player victory points: -6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6.] 
cards in discard: [ 6.  8. 29.  8.  8.  0.  6.  8.  6.  3.  0.  6.  0.  1.  0.  0.  8.  0.
 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  0 29 14  6  0  6  6  1  6  8  6  8  0  8  6  8  0
 10  6  8  6  8  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 28. 30.  8.  0.  9. 10.  1.  7.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  6. 25.  6.] 
adversary cards in discard: [ 3.  3. 25.  0. 14.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3] -> size -> 24 
adversary victory points: 3
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6.] 
cards in discard: [ 6.  8. 29.  8.  8.  0.  6.  8.  6.  3.  0.  6.  0.  1.  0.  0.  8.  0.
 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  0 29 14  6  0  6  6  1  6  8  6  8  0  8  6  8  0
 10  6  8  6  8  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 27. 30. 28. 30.  8.  0.  9. 10.  1.  7.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  6. 25.  6.] 
adversary cards in discard: [ 3.  3. 25.  0. 14.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3] -> size -> 24 
adversary victory points: 3
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6.] 
cards in discard: [ 6.  8. 29.  8.  8.  0.  6.  8.  6.  3.  0.  6.  0.  1.  0.  0.  8.  0.
 10.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  0 29 14  6  0  6  6  1  6  8  6  8  0  8  6  8  0
 10  6  8  6  8  1  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 28. 30.  8.  0.  9. 10.  1.  7.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  6. 25.  6.] 
adversary cards in discard: [ 3.  3. 25.  0. 14.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3] -> size -> 24 
adversary victory points: 3
player victory points: -6 





Player: 0 
cards in hand: [ 0.  3.  6. 25.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[27.402622]
 [28.977455]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  6. 25.  6.] 
cards in discard: [ 3.  3. 25.  0. 14.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 28. 30.  8.  0.  9. 10.  1.  7.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  0.  6.  3. 14.] 
adversary cards in discard: [ 6.  8. 29.  8.  8.  0.  6.  8.  6.  3.  0.  6.  0.  1.  0.  0.  8.  0.
 10.  0.  8.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 29 14  6  0  6  6  1  6  8  6  8  0  8  6  8  0
 10  6  8  6  8  1  0] -> size -> 31 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[-5  0  3 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 88 

action type: buy - action -1
Learning step: 3.1177449226379395
desired expected reward: 41.593231201171875



action possibilites: [-1] 
expected returns: [[23.437613]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 6. 0. 8.] 
cards in discard: [ 3.  3. 25.  0. 14.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 28. 30.  8.  0.  9. 10.  1.  7.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  0.  6.  3. 14.] 
adversary cards in discard: [ 6.  8. 29.  8.  8.  0.  6.  8.  6.  3.  0.  6.  0.  1.  0.  0.  8.  0.
 10.  0.  8.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 29 14  6  0  6  6  1  6  8  6  8  0  8  6  8  0
 10  6  8  6  8  1  0] -> size -> 31 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[-5  0  3 90  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 109 

action type: take_action - action 25.0
Learning step: 4.5284743309021
desired expected reward: 33.50590896606445





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[15.655968]
 [19.105705]
 [19.554262]
 [24.059898]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 6. 0. 8.] 
cards in discard: [ 3.  3. 25.  0. 14.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 27. 30. 28. 30.  8.  0.  9. 10.  1.  7.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  0.  6.  3. 14.] 
adversary cards in discard: [ 6.  8. 29.  8.  8.  0.  6.  8.  6.  3.  0.  6.  0.  1.  0.  0.  8.  0.
 10.  0.  8.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 29 14  6  0  6  6  1  6  8  6  8  0  8  6  8  0
 10  6  8  6  8  1  0] -> size -> 31 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[-5  0  3 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 108 

action type: take_action - action -1
Learning step: 4.7100653648376465
desired expected reward: 28.14767837524414






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 1.  0.  6.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  6.  3. 14.] 
cards in discard: [ 6.  8. 29.  8.  8.  0.  6.  8.  6.  3.  0.  6.  0.  1.  0.  0.  8.  0.
 10.  0.  8.  6.  6.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 29 14  6  0  6  6  1  6  8  6  8  0  8  6  8  0
 10  6  8  6  8  1  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 28. 30.  8.  0.  9. 10.  1.  7.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 25.  0.  3.] 
adversary cards in discard: [ 3.  3. 25.  0. 14.  1. 25.  0.  3.  6.  6.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3] -> size -> 24 
adversary victory points: 3
player victory points: -6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 6. 3.] 
cards in discard: [ 6.  8. 29.  8.  8.  0.  6.  8.  6.  3.  0.  6.  0.  1.  0.  0.  8.  0.
 10.  0.  8.  6.  6.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  0 29 14  6  0  6  6  1  6  8  6  8  0  8  6  8  0
 10  6  8  6  8  1  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 27. 30. 28. 30.  8.  0.  9. 10.  1.  7.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.] 
adversary cards in discard: [ 3.  3. 25.  0. 14.  1. 25.  0.  3.  6.  6.  0.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3] -> size -> 24 
adversary victory points: 3
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6. 3.] 
cards in discard: [ 6.  8. 29.  8.  8.  0.  6.  8.  6.  3.  0.  6.  0.  1.  0.  0.  8.  0.
 10.  0.  8.  6.  6.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  0 29 14  6  0  6  6  1  6  8  6  8  0  8  6  8  0
 10  6  8  6  8  1  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 27. 30. 28. 30.  8.  0.  9. 10.  1.  7.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.] 
adversary cards in discard: [ 3.  3. 25.  0. 14.  1. 25.  0.  3.  6.  6.  0.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3] -> size -> 24 
adversary victory points: 3
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6. 3.] 
cards in discard: [ 6.  8. 29.  8.  8.  0.  6.  8.  6.  3.  0.  6.  0.  1.  0.  0.  8.  0.
 10.  0.  8.  6.  6.  6. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  0 29 14  6  0  6  6  1  6  8  6  8  0  8  6  8  0
 10  6  8  6  8  1  0 16] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 28. 30.  8.  0.  8. 10.  1.  7.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.] 
adversary cards in discard: [ 3.  3. 25.  0. 14.  1. 25.  0.  3.  6.  6.  0.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3] -> size -> 24 
adversary victory points: 3
player victory points: -6 





Player: 0 
cards in hand: [ 0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[30.97382]
 [37.00621]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.] 
cards in discard: [ 3.  3. 25.  0. 14.  1. 25.  0.  3.  6.  6.  0.  8.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 28. 30.  8.  0.  8. 10.  1.  7.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 29 14  6  0  6  6  1  6  8  6  8  0  8  6  8  0
 10  6  8  6  8  1  0 16] -> size -> 32 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[-5  0  3 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 88 

action type: discard_down_to_3_cards - action 7
Learning step: 4.214199542999268
desired expected reward: 23.780637741088867





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[23.282253]
 [26.716194]
 [27.769577]
 [31.049778]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  0.] 
cards in discard: [ 3.  3. 25.  0. 14.  1. 25.  0.  3.  6.  6.  0.  8.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 27. 30. 28. 30.  8.  0.  8. 10.  1.  7.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 29 14  6  0  6  6  1  6  8  6  8  0  8  6  8  0
 10  6  8  6  8  1  0 16] -> size -> 32 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[-5  0  3 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 88 

action type: take_action - action -1.0
Learning step: 3.4987831115722656
desired expected reward: 34.472591400146484



buy possibilites: [-1] 
expected returns: [[56.65775]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  0.] 
cards in discard: [ 3.  3. 25.  0. 14.  1. 25.  0.  3.  6.  6.  0.  8.  3.  3.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 28. 30.  8.  0.  8. 10.  0.  7.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 29 14  6  0  6  6  1  6  8  6  8  0  8  6  8  0
 10  6  8  6  8  1  0 16] -> size -> 32 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[-5  0  3 90  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 96 

action type: buy - action 8.0
Learning step: 4.686320781707764
desired expected reward: 32.45589065551758






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [0. 8. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 29 14  6  0  6  6  1  6  8  6  8  0  8  6  8  0
 10  6  8  6  8  1  0 16] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 28. 30.  8.  0.  8. 10.  0.  7.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  0.  0.] 
adversary cards in discard: [ 3.  3. 25.  0. 14.  1. 25.  0.  3.  6.  6.  0.  8.  3.  3.  8.  0. 25.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3
  8] -> size -> 25 
adversary victory points: 3
player victory points: -6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  8  6  8  0  8  6  8  0 10  6  8  6
  8  1  0 16] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 28. 30.  8.  0.  8. 10.  0.  7.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  0.  0.] 
adversary cards in discard: [ 3.  3. 25.  0. 14.  1. 25.  0.  3.  6.  6.  0.  8.  3.  3.  8.  0. 25.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3
  8] -> size -> 25 
adversary victory points: 3
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  8  6  8  0  8  6  8  0 10  6  8  6
  8  1  0 16] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 27. 30. 28. 30.  8.  0.  8. 10.  0.  7.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  0.  0.] 
adversary cards in discard: [ 3.  3. 25.  0. 14.  1. 25.  0.  3.  6.  6.  0.  8.  3.  3.  8.  0. 25.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3
  8] -> size -> 25 
adversary victory points: 3
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  8  6  8  0  8  6  8  0 10  6  8  6
  8  1  0 16  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 28. 30.  8.  0.  8. 10.  0.  7.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  0.  0.] 
adversary cards in discard: [ 3.  3. 25.  0. 14.  1. 25.  0.  3.  6.  6.  0.  8.  3.  3.  8.  0. 25.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3
  8] -> size -> 25 
adversary victory points: 3
player victory points: -5 





Player: 0 
cards in hand: [ 0. 16.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[40.72231]
 [34.58851]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  0.  0.] 
cards in discard: [ 3.  3. 25.  0. 14.  1. 25.  0.  3.  6.  6.  0.  8.  3.  3.  8.  0. 25.
  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 28. 30.  8.  0.  8. 10.  0.  7.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 8. 29.  6.  6.  8.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  8  6  8  0  8  6  8  0 10  6  8  6
  8  1  0 16  0] -> size -> 29 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[-5  0  3 80  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 78 

action type: buy - action -1
Learning step: 1.9425718784332275
desired expected reward: 58.60032272338867





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[30.109707]
 [37.007538]
 [34.342545]
 [33.01599 ]
 [39.39704 ]
 [34.125435]
 [23.18986 ]
 [32.090214]
 [29.122524]
 [39.252197]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  0.  0.] 
cards in discard: [ 3.  3. 25.  0. 14.  1. 25.  0.  3.  6.  6.  0.  8.  3.  3.  8.  0. 25.
  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 27. 30. 28. 30.  8.  0.  8. 10.  0.  7.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 8. 29.  6.  6.  8.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  8  6  8  0  8  6  8  0 10  6  8  6
  8  1  0 16  0] -> size -> 29 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[-5  0  3 80  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 78 

action type: take_action - action -1.0
Learning step: 2.6674301624298096
desired expected reward: 43.38973617553711



buy possibilites: [-1] 
expected returns: [[63.059593]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  0.  0.] 
cards in discard: [ 3.  3. 25.  0. 14.  1. 25.  0.  3.  6.  6.  0.  8.  3.  3.  8.  0. 25.
  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3
  8 29] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 28. 30.  8.  0.  8. 10.  0.  7.  8.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 8. 29.  6.  6.  8.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  8  6  8  0  8  6  8  0 10  6  8  6
  8  1  0 16  0] -> size -> 29 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[-5  0  3 80  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 110 

action type: buy - action 29.0
Learning step: 5.212569236755371
desired expected reward: 39.33800506591797






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 8. 29.  6.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  6.  6.  8.] 
cards in discard: [0. 8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  8  6  8  0  8  6  8  0 10  6  8  6
  8  1  0 16  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 28. 30.  8.  0.  8. 10.  0.  7.  8.  8. 10.  8. 10. 10.] 
adversary cards in hand: [25.  0.  0. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3
  8 29] -> size -> 26 
adversary victory points: 3
player victory points: -5 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 1.] 
cards in discard: [0. 8. 6. 8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  8  6  8  0  8  6  8  0 10  6  8  6
  8  1  0 16  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 27. 30. 28. 30.  8.  0.  8. 10.  0.  7.  8.  8. 10.  8. 10. 10.] 
adversary cards in hand: [25.  0.  0. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3
  8 29] -> size -> 26 
adversary victory points: 3
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 1.] 
cards in discard: [0. 8. 6. 8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  8  6  8  0  8  6  8  0 10  6  8  6
  8  1  0 16  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 27. 30. 28. 30.  8.  0.  8. 10.  0.  7.  8.  8. 10.  8. 10. 10.] 
adversary cards in hand: [25.  0.  0. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3
  8 29] -> size -> 26 
adversary victory points: 3
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 1.] 
cards in discard: [ 0.  8.  6.  8. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  8  6  8  0  8  6  8  0 10  6  8  6
  8  1  0 16  0 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 28. 30.  8.  0.  8.  9.  0.  7.  8.  8. 10.  8. 10. 10.] 
adversary cards in hand: [25.  0.  0. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3
  8 29] -> size -> 26 
adversary victory points: 3
player victory points: -5 





Player: 0 
cards in hand: [25.  0.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 16.] 
expected returns: [[58.327072]
 [62.181534]
 [51.219624]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0. 16.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3
  8 29] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 28. 30.  8.  0.  8.  9.  0.  7.  8.  8. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 8.] 
adversary cards in discard: [ 0.  8.  6.  8. 11. 29.  6.  8.  1.] 
adversary owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  8  6  8  0  8  6  8  0 10  6  8  6
  8  1  0 16  0 11] -> size -> 30 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[-5  0  3 80  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 78 

action type: buy - action -1
Learning step: 2.0820095539093018
desired expected reward: 65.1416015625



action possibilites: [-1] 
expected returns: [[48.10084]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  0.  0.  6.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3
  8 29] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 28. 30.  8.  0.  8.  9.  0.  7.  8.  8. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 8.] 
adversary cards in discard: [ 0.  8.  6.  8. 11. 29.  6.  8.  1.] 
adversary owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  8  6  8  0  8  6  8  0 10  6  8  6
  8  1  0 16  0 11] -> size -> 30 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[-5  0  3 80  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 99 

action type: take_action - action 25.0
Learning step: 2.919236421585083
desired expected reward: 65.17988586425781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[36.98188 ]
 [44.536465]
 [41.53994 ]
 [39.960827]
 [48.379032]
 [41.262573]
 [28.14935 ]
 [39.340065]
 [36.39595 ]
 [49.62013 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.  0.  0.  6.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3
  8 29] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 27. 30. 28. 30.  8.  0.  8.  9.  0.  7.  8.  8. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 8.] 
adversary cards in discard: [ 0.  8.  6.  8. 11. 29.  6.  8.  1.] 
adversary owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  8  6  8  0  8  6  8  0 10  6  8  6
  8  1  0 16  0 11] -> size -> 30 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[-5  0  3 80  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 98 

action type: take_action - action -1
Learning step: 3.491655111312866
desired expected reward: 51.59249496459961






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 6. 8.] 
cards in discard: [ 0.  8.  6.  8. 11. 29.  6.  8.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  8  6  8  0  8  6  8  0 10  6  8  6
  8  1  0 16  0 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 28. 30.  8.  0.  8.  9.  0.  7.  8.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  1.  3.  3. 25.] 
adversary cards in discard: [25.  0.  0. 16.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3
  8 29] -> size -> 26 
adversary victory points: 3
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 8.] 
cards in discard: [ 0.  8.  6.  8. 11. 29.  6.  8.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  8  6  8  0  8  6  8  0 10  6  8  6
  8  1  0 16  0 11] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 27. 30. 28. 30.  8.  0.  8.  9.  0.  7.  8.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  1.  3.  3. 25.] 
adversary cards in discard: [25.  0.  0. 16.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3
  8 29] -> size -> 26 
adversary victory points: 3
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 8.] 
cards in discard: [ 0.  8.  6.  8. 11. 29.  6.  8.  1.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  8  6  8  0  8  6  8  0 10  6  8  6
  8  1  0 16  0 11  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  0.  8.  9.  0.  7.  8.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  1.  3.  3. 25.] 
adversary cards in discard: [25.  0.  0. 16.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3
  8 29] -> size -> 26 
adversary victory points: 3
player victory points: -4 





Player: 0 
cards in hand: [ 0.  1.  3.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[46.87294]
 [53.11287]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3.  3. 25.] 
cards in discard: [25.  0.  0. 16.  0.  0.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3
  8 29] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  0.  8.  9.  0.  7.  8.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 14.  0.  6.  0.] 
adversary cards in discard: [ 0.  8.  6.  8. 11. 29.  6.  8.  1.  3.  0.  3.  0.  6.  8.] 
adversary owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  8  6  8  0  8  6  8  0 10  6  8  6
  8  1  0 16  0 11  3] -> size -> 31 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[-5  0  3 70  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 68 

action type: buy - action -1.0
Learning step: 1.8501771688461304
desired expected reward: 55.917449951171875



action possibilites: [-1] 
expected returns: [[55.287914]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 3. 0. 0.] 
cards in discard: [25.  0.  0. 16.  0.  0.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3
  8 29] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  0.  8.  9.  0.  7.  8.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 14.  0.  6.  0.] 
adversary cards in discard: [ 0.  8.  6.  8. 11. 29.  6.  8.  1.  3.  0.  3.  0.  6.  8.] 
adversary owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  8  6  8  0  8  6  8  0 10  6  8  6
  8  1  0 16  0 11  3] -> size -> 31 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[-5  0  3 70  0  0 20  0  0  0  0  0  0  0  0  2] 
sum of rewards: 90 

action type: take_action - action 25.0
Learning step: 3.088334560394287
desired expected reward: 56.20120620727539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[38.482655]
 [47.648575]
 [44.147102]
 [29.501019]
 [42.452217]
 [51.349796]
 [59.34502 ]
 [43.96259 ]
 [31.187988]
 [35.784668]
 [41.344746]
 [28.35538 ]
 [37.38601 ]
 [52.453323]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 3. 0. 0.] 
cards in discard: [25.  0.  0. 16.  0.  0.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3
  8 29] -> size -> 26 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 27. 30. 27. 30.  8.  0.  8.  9.  0.  7.  8.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 14.  0.  6.  0.] 
adversary cards in discard: [ 0.  8.  6.  8. 11. 29.  6.  8.  1.  3.  0.  3.  0.  6.  8.] 
adversary owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  8  6  8  0  8  6  8  0 10  6  8  6
  8  1  0 16  0 11  3] -> size -> 31 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[-5  0  3 70  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 88 

action type: take_action - action -1
Learning step: 2.7357919216156006
desired expected reward: 58.023704528808594



buy possibilites: [-1] 
expected returns: [[13.014196]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 3. 0. 0.] 
cards in discard: [25.  0.  0. 16.  0.  0.  6. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3
  8 29 29] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 27. 30. 27. 30.  8.  0.  8.  9.  0.  7.  7.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 14.  0.  6.  0.] 
adversary cards in discard: [ 0.  8.  6.  8. 11. 29.  6.  8.  1.  3.  0.  3.  0.  6.  8.] 
adversary owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  8  6  8  0  8  6  8  0 10  6  8  6
  8  1  0 16  0 11  3] -> size -> 31 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3. 70.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  8.  0.] 
sum of rewards: 96.0 

action type: buy - action 29.0
Learning step: 2.8946900367736816
desired expected reward: 46.857276916503906






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 0. 14.  0.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  6.  0.] 
cards in discard: [ 0.  8.  6.  8. 11. 29.  6.  8.  1.  3.  0.  3.  0.  6.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  8  6  8  0  8  6  8  0 10  6  8  6
  8  1  0 16  0 11  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  0.  8.  9.  0.  7.  7.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  8.  3.] 
adversary cards in discard: [25.  0.  0. 16.  0.  0.  6. 29. 25.  0.  1.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3
  8 29 29] -> size -> 27 
adversary victory points: 3
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  6.  0.] 
cards in discard: [ 0.  8.  6.  8. 11. 29.  6.  8.  1.  3.  0.  3.  0.  6.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  8  6  8  0  8  6  8  0 10  6  8  6
  8  1  0 16  0 11  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 27. 30. 27. 30.  8.  0.  8.  9.  0.  7.  7.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  8.  3.] 
adversary cards in discard: [25.  0.  0. 16.  0.  0.  6. 29. 25.  0.  1.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3
  8 29 29] -> size -> 27 
adversary victory points: 3
player victory points: -4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3. 29.  0.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[44.713696]
 [38.8502  ]
 [38.950535]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  8.  3.] 
cards in discard: [25.  0.  0. 16.  0.  0.  6. 29. 25.  0.  1.  3.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3
  8 29 29] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  0.  8.  9.  0.  7.  7.  8. 10.  8. 10. 10.] 
adversary cards in hand: [10.  6.  0.  6.  6.] 
adversary cards in discard: [ 0.  8.  6.  8. 11. 29.  6.  8.  1.  3.  0.  3.  0.  6.  8.  0. 14.  0.
  6.  0.] 
adversary owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  8  6  8  0  8  6  8  0 10  6  8  6
  8  1  0 16  0 11  3] -> size -> 31 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[-5  0  3 70  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 68 

action type: buy - action -1
Learning step: 3.7037994861602783
desired expected reward: 16.71799659729004



action possibilites: [-1] 
expected returns: [[21.776886]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.] 
cards in discard: [25.  0.  0. 16.  0.  0.  6. 29. 25.  0.  1.  3.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3  8 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  0.  8.  9.  0.  7.  7.  8. 10.  8. 10. 10.] 
adversary cards in hand: [10.  6.  0.  6.  6.] 
adversary cards in discard: [ 0.  8.  6.  8. 11. 29.  6.  8.  1.  3.  0.  3.  0.  6.  8.  0. 14.  0.
  6.  0.] 
adversary owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  8  6  8  0  8  6  8  0 10  6  8  6
  8  1  0 16  0 11  3] -> size -> 31 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[-5  0  1 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 66 

action type: trash_cards_n_from_hand - action 10
Learning step: 1.7917152643203735
desired expected reward: 41.75700759887695





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[17.007244]
 [23.063423]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.] 
cards in discard: [25.  0.  0. 16.  0.  0.  6. 29. 25.  0.  1.  3.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3  8 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  0.  8.  9.  0.  7.  7.  8. 10.  8. 10. 10.] 
adversary cards in hand: [10.  6.  0.  6.  6.] 
adversary cards in discard: [ 0.  8.  6.  8. 11. 29.  6.  8.  1.  3.  0.  3.  0.  6.  8.  0. 14.  0.
  6.  0.] 
adversary owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  8  6  8  0  8  6  8  0 10  6  8  6
  8  1  0 16  0 11  3] -> size -> 31 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[-5  0  1 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 66 

action type: take_action - action -1
Learning step: 2.6898059844970703
desired expected reward: 24.466691970825195






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [10.  6.  0.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  0.  6.  6.] 
cards in discard: [ 0.  8.  6.  8. 11. 29.  6.  8.  1.  3.  0.  3.  0.  6.  8.  0. 14.  0.
  6.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  8  6  8  0  8  6  8  0 10  6  8  6
  8  1  0 16  0 11  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  0.  8.  9.  0.  7.  7.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  0. 25.  3.  0.] 
adversary cards in discard: [25.  0.  0. 16.  0.  0.  6. 29. 25.  0.  1.  3.  3.  0.  0.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3  8 29 29] -> size -> 24 
adversary victory points: 1
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  0.  6.  6.] 
cards in discard: [ 0.  8.  6.  8. 11. 29.  6.  8.  1.  3.  0.  3.  0.  6.  8.  0. 14.  0.
  6.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  8  6  8  0  8  6  8  0 10  6  8  6
  8  1  0 16  0 11  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 27. 30. 27. 30.  8.  0.  8.  9.  0.  7.  7.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  0. 25.  3.  0.] 
adversary cards in discard: [25.  0.  0. 16.  0.  0.  6. 29. 25.  0.  1.  3.  3.  0.  0.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3  8 29 29] -> size -> 24 
adversary victory points: 1
player victory points: -4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 8.  0. 25.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
expected returns: [[-18.053652]
 [-18.232216]
 [-18.015493]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 25.  3.  0.] 
cards in discard: [25.  0.  0. 16.  0.  0.  6. 29. 25.  0.  1.  3.  3.  0.  0.  8. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3  8 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  0.  8.  9.  0.  7.  7.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  1. 16.  8.  0.] 
adversary cards in discard: [ 0.  8.  6.  8. 11. 29.  6.  8.  1.  3.  0.  3.  0.  6.  8.  0. 14.  0.
  6.  0. 10.  6.  0.  6.  6.] 
adversary owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  8  6  8  0  8  6  8  0 10  6  8  6
  8  1  0 16  0 11  3] -> size -> 31 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[-5  0  1 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 46 

action type: buy - action -1.0
Learning step: 0.7403509020805359
desired expected reward: 23.80375862121582



action possibilites: [-1] 
expected returns: [[10.170798]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3.  0.  6. 14.] 
cards in discard: [25.  0.  0. 16.  0.  0.  6. 29. 25.  0.  1.  3.  3.  0.  0.  8. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3  8 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  0.  8.  9.  0.  7.  7.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  1. 16.  8.  0.] 
adversary cards in discard: [ 0.  8.  6.  8. 11. 29.  6.  8.  1.  3.  0.  3.  0.  6.  8.  0. 14.  0.
  6.  0. 10.  6.  0.  6.  6.] 
adversary owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  8  6  8  0  8  6  8  0 10  6  8  6
  8  1  0 16  0 11  3] -> size -> 31 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[-5  0  1 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 66 

action type: take_action - action 25.0
Learning step: 4.429617881774902
desired expected reward: -13.585875511169434





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[ 8.165881]
 [ 9.614696]
 [11.095819]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3.  0.  6. 14.] 
cards in discard: [25.  0.  0. 16.  0.  0.  6. 29. 25.  0.  1.  3.  3.  0.  0.  8. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3  8 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 27. 30. 27. 30.  8.  0.  8.  9.  0.  7.  7.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  1. 16.  8.  0.] 
adversary cards in discard: [ 0.  8.  6.  8. 11. 29.  6.  8.  1.  3.  0.  3.  0.  6.  8.  0. 14.  0.
  6.  0. 10.  6.  0.  6.  6.] 
adversary owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  8  6  8  0  8  6  8  0 10  6  8  6
  8  1  0 16  0 11  3] -> size -> 31 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[-5  0  1 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 66 

action type: take_action - action -1
Learning step: 3.0215587615966797
desired expected reward: 13.192357063293457






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [ 3.  1. 16.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 16.  8.  0.] 
cards in discard: [ 0.  8.  6.  8. 11. 29.  6.  8.  1.  3.  0.  3.  0.  6.  8.  0. 14.  0.
  6.  0. 10.  6.  0.  6.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  8  6  8  0  8  6  8  0 10  6  8  6
  8  1  0 16  0 11  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  0.  8.  9.  0.  7.  7.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  0.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3  8 29 29] -> size -> 24 
adversary victory points: 1
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0.] 
cards in discard: [ 0.  8.  6.  8. 11. 29.  6.  8.  1.  3.  0.  3.  0.  6.  8.  0. 14.  0.
  6.  0. 10.  6.  0.  6.  6. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8
  1  0 16  0 11  3 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  0.  8.  9.  0.  7.  7.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  0.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3  8 29 29] -> size -> 24 
adversary victory points: 1
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0.] 
cards in discard: [ 0.  8.  6.  8. 11. 29.  6.  8.  1.  3.  0.  3.  0.  6.  8.  0. 14.  0.
  6.  0. 10.  6.  0.  6.  6. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8
  1  0 16  0 11  3 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 27. 30. 27. 30.  8.  0.  8.  9.  0.  7.  7.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  0.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3  8 29 29] -> size -> 24 
adversary victory points: 1
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0.] 
cards in discard: [ 0.  8.  6.  8. 11. 29.  6.  8.  1.  3.  0.  3.  0.  6.  8.  0. 14.  0.
  6.  0. 10.  6.  0.  6.  6. 15. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8
  1  0 16  0 11  3 15 10] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  0.  8.  9.  0.  7.  7.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  0.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3  8 29 29] -> size -> 24 
adversary victory points: 1
player victory points: -4 





Player: 0 
cards in hand: [ 8.  0.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[-4.7407436]
 [-5.595439 ]
 [-5.52952  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3  8 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  0.  8.  9.  0.  7.  7.  8. 10.  7. 10.  9.] 
adversary cards in hand: [16.  6. 11.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8
  1  0 16  0 11  3 15 10] -> size -> 32 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[-5  0  1 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 46 

action type: buy - action -1.0
Learning step: 1.63080632686615
desired expected reward: 12.726625442504883





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-4.7407436]
 [-5.4927154]
 [-4.9824495]
 [-5.618944 ]
 [-4.778007 ]
 [-5.8138   ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3  8 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 27. 30. 27. 30.  8.  0.  8.  9.  0.  7.  7.  8. 10.  7. 10.  9.] 
adversary cards in hand: [16.  6. 11.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8
  1  0 16  0 11  3 15 10] -> size -> 32 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[-5  0  1 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 46 

action type: take_action - action -1.0
Learning step: 2.4237594604492188
desired expected reward: -2.316984176635742



buy possibilites: [-1] 
expected returns: [[0.690593]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0.  0. 29.] 
cards in discard: [0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3  8 29 29
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 27. 30. 27. 30.  8.  0.  8.  9.  0.  7.  7.  8. 10.  7. 10.  9.] 
adversary cards in hand: [16.  6. 11.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8
  1  0 16  0 11  3 15 10] -> size -> 32 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1.  50.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 16.0 

action type: buy - action 0.0
Learning step: 1.0525754690170288
desired expected reward: -3.6881680488586426






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [16.  6. 11.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6. 11.  0.  8.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8
  1  0 16  0 11  3 15 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 27. 30.  8.  0.  8.  9.  0.  7.  7.  8. 10.  7. 10.  9.] 
adversary cards in hand: [25. 14.  0.  0.  0.] 
adversary cards in discard: [ 0.  8.  0.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3  8 29 29
  0] -> size -> 25 
adversary victory points: 1
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6. 11.  0.  8.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8
  1  0 16  0 11  3 15 10] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 27. 30. 27. 30.  8.  0.  8.  9.  0.  7.  7.  8. 10.  7. 10.  9.] 
adversary cards in hand: [25. 14.  0.  0.  0.] 
adversary cards in discard: [ 0.  8.  0.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3  8 29 29
  0] -> size -> 25 
adversary victory points: 1
player victory points: -4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [25. 14.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 14.] 
expected returns: [[  0.13710284]
 [  6.0872107 ]
 [-31.461205  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 14.  0.  0.  0.] 
cards in discard: [ 0.  8.  0.  0.  0. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3  8 29 29
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 27. 30.  8.  0.  8.  9.  0.  7.  7.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 29.  6.] 
adversary cards in discard: [16.  6. 11.  0.  8.] 
adversary owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8
  1  0 16  0 11  3 15 10] -> size -> 32 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[-5  0  1 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 46 

action type: buy - action -1
Learning step: 2.2095749378204346
desired expected reward: 2.900167942047119



action possibilites: [-1] 
expected returns: [[-7.7454844]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  0.  0.  6.] 
cards in discard: [ 0.  8.  0.  0.  0. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3  8 29 29
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 27. 30.  8.  0.  8.  9.  0.  7.  7.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 29.  6.] 
adversary cards in discard: [16.  6. 11.  0.  8.] 
adversary owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8
  1  0 16  0 11  3 15 10] -> size -> 32 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[-5  0  1 50  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 67 

action type: take_action - action 25.0
Learning step: 2.785668134689331
desired expected reward: 8.872885704040527





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[-12.722127 ]
 [ -8.96748  ]
 [ -8.757802 ]
 [-11.395853 ]
 [ -6.0001135]
 [-10.831047 ]
 [-13.47246  ]
 [-10.2548485]
 [-11.429165 ]
 [ -5.19091  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  0.  0.  6.] 
cards in discard: [ 0.  8.  0.  0.  0. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3  8 29 29
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 27. 30. 27. 30.  8.  0.  8.  9.  0.  7.  7.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 29.  6.] 
adversary cards in discard: [16.  6. 11.  0.  8.] 
adversary owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8
  1  0 16  0 11  3 15 10] -> size -> 32 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[-5  0  1 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 66 

action type: take_action - action -1
Learning step: 3.507814407348633
desired expected reward: -4.237669944763184



buy possibilites: [-1] 
expected returns: [[45.08142]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  0.  0.  6.] 
cards in discard: [ 0.  8.  0.  0.  0. 29. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3  8 29 29
  0 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 27. 30. 27. 30.  8.  0.  8.  8.  0.  7.  7.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 29.  6.] 
adversary cards in discard: [16.  6. 11.  0.  8.] 
adversary owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8
  1  0 16  0 11  3 15 10] -> size -> 32 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[-5.   0.   1.  50.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 70.5 

action type: buy - action 11.0
Learning step: 4.8393378257751465
desired expected reward: -1.1607766151428223






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  0. 29.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 29.  6.] 
cards in discard: [16.  6. 11.  0.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8
  1  0 16  0 11  3 15 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 27. 30.  8.  0.  8.  8.  0.  7.  7.  8. 10.  7. 10.  9.] 
adversary cards in hand: [29.  6.  3. 25. 16.] 
adversary cards in discard: [ 0.  8.  0.  0.  0. 29. 11. 25. 14.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3  8 29 29
  0 11] -> size -> 26 
adversary victory points: 1
player victory points: -4 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 1.] 
cards in discard: [16.  6. 11.  0.  8.  0.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8
  1  0 16  0 11  3 15 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 27. 30. 27. 30.  8.  0.  8.  8.  0.  7.  7.  8. 10.  7. 10.  9.] 
adversary cards in hand: [29.  6.  3. 25. 16.] 
adversary cards in discard: [ 0.  8.  0.  0.  0. 29. 11. 25. 14.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3  8 29 29
  0 11] -> size -> 26 
adversary victory points: 1
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 1.] 
cards in discard: [16.  6. 11.  0.  8.  0.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8
  1  0 16  0 11  3 15 10] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 27. 30. 27. 30.  8.  0.  8.  8.  0.  7.  7.  8. 10.  7. 10.  9.] 
adversary cards in hand: [29.  6.  3. 25. 16.] 
adversary cards in discard: [ 0.  8.  0.  0.  0. 29. 11. 25. 14.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3  8 29 29
  0 11] -> size -> 26 
adversary victory points: 1
player victory points: -4 





Player: 0 
cards in hand: [29.  6.  3. 25. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 16.] 
expected returns: [[42.452347]
 [33.349545]
 [46.350006]
 [32.288982]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6.  3. 25. 16.] 
cards in discard: [ 0.  8.  0.  0.  0. 29. 11. 25. 14.  0.  0.  0.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 25  6  6 25  0  1  8 25  0 14  3 16  0  3  8 29 29
  0 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 27. 30.  8.  0.  8.  8.  0.  7.  7.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  6. 10.  8.  8.] 
adversary cards in discard: [16.  6. 11.  0.  8.  0.  6. 29.  8.  0.  1.] 
adversary owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8
  1  0 16  0 11  3 15 10] -> size -> 32 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[-5  0  1 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 46 

action type: buy - action -1
Learning step: 0.9858574271202087
desired expected reward: 46.06727981567383



action possibilites: [-1] 
expected returns: [[22.467495]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6. 25.] 
cards in discard: [ 0.  8.  0.  0.  0. 29. 11. 25. 14.  0.  0.  0.  0.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0 25  6  6 25  0  1  8 25  0 14  3 16  0  3  8 29 29  0
 11  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 27. 30.  8.  0.  8.  8.  0.  7.  7.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  6. 10.  8.  8.] 
adversary cards in discard: [16.  6. 11.  0.  8.  0.  6. 29.  8.  0.  1.] 
adversary owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8
  1  0 16  0 11  3 15 10] -> size -> 32 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0  40   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: gain_card_n - action 0
Learning step: 0.3830140233039856
desired expected reward: 27.83310890197754





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[12.347274]
 [23.893538]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6. 25.] 
cards in discard: [ 0.  8.  0.  0.  0. 29. 11. 25. 14.  0.  0.  0.  0.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0 25  6  6 25  0  1  8 25  0 14  3 16  0  3  8 29 29  0
 11  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 27. 30. 27. 30.  8.  0.  8.  8.  0.  7.  7.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  6. 10.  8.  8.] 
adversary cards in discard: [16.  6. 11.  0.  8.  0.  6. 29.  8.  0.  1.] 
adversary owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8
  1  0 16  0 11  3 15 10] -> size -> 32 
adversary victory points: -4
player victory points: 0 

Reward from previous game state: 
[-5  0  0 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 2.0874414443969727
desired expected reward: 24.554935455322266






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 0.  6. 10.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 10.  8.  8.] 
cards in discard: [16.  6. 11.  0.  8.  0.  6. 29.  8.  0.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 29 14  0  6  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8
  1  0 16  0 11  3 15 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 27. 30.  8.  0.  8.  8.  0.  7.  7.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  3. 25.  1.  0.] 
adversary cards in discard: [ 0.  8.  0.  0.  0. 29. 11. 25. 14.  0.  0.  0.  0.  6.  0. 16. 29.  6.
 25.] 
adversary owned cards: [ 0  0  0  0  0  0 25  6  6 25  0  1  8 25  0 14  3 16  0  3  8 29 29  0
 11  0] -> size -> 26 
adversary victory points: 0
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8.] 
cards in discard: [16.  6. 11.  0.  8.  0.  6. 29.  8.  0.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  0 29 14  0  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8  1
  0 16  0 11  3 15 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 27. 30.  8.  0.  8.  8.  0.  7.  7.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  3. 25.  1.  0.] 
adversary cards in discard: [ 0.  8.  0.  0.  0. 29. 11. 25. 14.  0.  0.  0.  0.  6.  0. 16. 29.  6.
 25.] 
adversary owned cards: [ 0  0  0  0  0  0 25  6  6 25  0  1  8 25  0 14  3 16  0  3  8 29 29  0
 11  0] -> size -> 26 
adversary victory points: 0
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  8.] 
cards in discard: [16.  6. 11.  0.  8.  0.  6. 29.  8.  0.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  0 29 14  0  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8  1
  0 16  0 11  3 15 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 27. 30. 27. 30.  8.  0.  8.  8.  0.  7.  7.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  3. 25.  1.  0.] 
adversary cards in discard: [ 0.  8.  0.  0.  0. 29. 11. 25. 14.  0.  0.  0.  0.  6.  0. 16. 29.  6.
 25.] 
adversary owned cards: [ 0  0  0  0  0  0 25  6  6 25  0  1  8 25  0 14  3 16  0  3  8 29 29  0
 11  0] -> size -> 26 
adversary victory points: 0
player victory points: -3 





Player: 0 
cards in hand: [ 8.  3. 25.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
expected returns: [[  3.440527]
 [-14.496428]
 [  9.586223]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 25.  1.  0.] 
cards in discard: [ 0.  8.  0.  0.  0. 29. 11. 25. 14.  0.  0.  0.  0.  6.  0. 16. 29.  6.
 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 25  6  6 25  0  1  8 25  0 14  3 16  0  3  8 29 29  0
 11  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 27. 30.  8.  0.  8.  8.  0.  7.  7.  8. 10.  7. 10.  9.] 
adversary cards in hand: [14.  6.  3.  0.  0.] 
adversary cards in discard: [16.  6. 11.  0.  8.  0.  6. 29.  8.  0.  1.  8.  0. 10.  8.] 
adversary owned cards: [ 0  0  3  3  0 29 14  0  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8  1
  0 16  0 11  3 15 10] -> size -> 31 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0.1369912177324295
desired expected reward: 24.0305233001709



action possibilites: [-1] 
expected returns: [[85.24045]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 1. 0. 0. 3.] 
cards in discard: [ 0.  8.  0.  0.  0. 29. 11. 25. 14.  0.  0.  0.  0.  6.  0. 16. 29.  6.
 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0 25  6  6 25  0  1  8 25  0 14  3 16  0  3  8 29 29  0
 11  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 27. 30.  8.  0.  8.  8.  0.  7.  7.  8. 10.  7. 10.  9.] 
adversary cards in hand: [14.  6.  3.  0.  0.] 
adversary cards in discard: [16.  6. 11.  0.  8.  0.  6. 29.  8.  0.  1.  8.  0. 10.  8.] 
adversary owned cards: [ 0  0  3  3  0 29 14  0  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8  1
  0 16  0 11  3 15 10] -> size -> 31 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 46 

action type: take_action - action 25.0
Learning step: 3.738598346710205
desired expected reward: 13.324834823608398





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[82.01427 ]
 [85.17374 ]
 [82.310074]
 [83.45482 ]
 [85.64856 ]
 [84.5305  ]
 [77.2673  ]
 [81.98279 ]
 [80.22505 ]
 [84.42737 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 1. 0. 0. 3.] 
cards in discard: [ 0.  8.  0.  0.  0. 29. 11. 25. 14.  0.  0.  0.  0.  6.  0. 16. 29.  6.
 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0 25  6  6 25  0  1  8 25  0 14  3 16  0  3  8 29 29  0
 11  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 27. 30. 27. 30.  8.  0.  8.  8.  0.  7.  7.  8. 10.  7. 10.  9.] 
adversary cards in hand: [14.  6.  3.  0.  0.] 
adversary cards in discard: [16.  6. 11.  0.  8.  0.  6. 29.  8.  0.  1.  8.  0. 10.  8.] 
adversary owned cards: [ 0  0  3  3  0 29 14  0  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8  1
  0 16  0 11  3 15 10] -> size -> 31 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: -0.12410278618335724
desired expected reward: 85.11634826660156



buy possibilites: [-1] 
expected returns: [[50.058838]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 1. 0. 0. 3.] 
cards in discard: [ 0.  8.  0.  0.  0. 29. 11. 25. 14.  0.  0.  0.  0.  6.  0. 16. 29.  6.
 25. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0 25  6  6 25  0  1  8 25  0 14  3 16  0  3  8 29 29  0
 11  0 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 27. 30. 27. 30.  8.  0.  8.  7.  0.  7.  7.  8. 10.  7. 10.  9.] 
adversary cards in hand: [14.  6.  3.  0.  0.] 
adversary cards in discard: [16.  6. 11.  0.  8.  0.  6. 29.  8.  0.  1.  8.  0. 10.  8.] 
adversary owned cards: [ 0  0  3  3  0 29 14  0  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8  1
  0 16  0 11  3 15 10] -> size -> 31 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5.   0.   0.  30.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 49.5 

action type: buy - action 11.0
Learning step: -0.6811050772666931
desired expected reward: 84.96746826171875






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [14.  6.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6.  3.  0.  0.] 
cards in discard: [16.  6. 11.  0.  8.  0.  6. 29.  8.  0.  1.  8.  0. 10.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 29 14  0  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8  1
  0 16  0 11  3 15 10] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 27. 30.  8.  0.  8.  7.  0.  7.  7.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  3.  0. 25. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 25  6  6 25  0  1  8 25  0 14  3 16  0  3  8 29 29  0
 11  0 11] -> size -> 27 
adversary victory points: 0
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 0.] 
cards in discard: [16.  6. 11.  0.  8.  0.  6. 29.  8.  0.  1.  8.  0. 10.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3  0 29 14  0  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8  1
  0 16  0 11  3 15 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 27. 30. 27. 30.  8.  0.  8.  7.  0.  7.  7.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 25. 25.] 
adversary cards in discard: [6. 3.] 
adversary owned cards: [ 0  0  0  0  0  0 25  6  6 25  0  1  8 25  0 14  3 16  0  3  8 29 29  0
 11  0 11] -> size -> 27 
adversary victory points: 0
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0.] 
cards in discard: [16.  6. 11.  0.  8.  0.  6. 29.  8.  0.  1.  8.  0. 10.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3  0 29 14  0  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8  1
  0 16  0 11  3 15 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 27. 30. 27. 30.  8.  0.  8.  7.  0.  7.  7.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 25. 25.] 
adversary cards in discard: [6. 3.] 
adversary owned cards: [ 0  0  0  0  0  0 25  6  6 25  0  1  8 25  0 14  3 16  0  3  8 29 29  0
 11  0 11] -> size -> 27 
adversary victory points: 0
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0.] 
cards in discard: [16.  6. 11.  0.  8.  0.  6. 29.  8.  0.  1.  8.  0. 10.  8. 16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3  0 29 14  0  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8  1
  0 16  0 11  3 15 10 16] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 27. 30.  8.  0.  7.  7.  0.  7.  7.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 25. 25.] 
adversary cards in discard: [6. 3.] 
adversary owned cards: [ 0  0  0  0  0  0 25  6  6 25  0  1  8 25  0 14  3 16  0  3  8 29 29  0
 11  0 11] -> size -> 27 
adversary victory points: 0
player victory points: -3 





Player: 0 
cards in hand: [ 0. 25. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[7.4684916]
 [8.647806 ]
 [8.647806 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 25.] 
cards in discard: [6. 3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 25  6  6 25  0  1  8 25  0 14  3 16  0  3  8 29 29  0
 11  0 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 27. 30.  8.  0.  7.  7.  0.  7.  7.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  6.  1.  0. 15.] 
adversary cards in discard: [16.  6. 11.  0.  8.  0.  6. 29.  8.  0.  1.  8.  0. 10.  8. 16. 14.  6.
  3.  0.  0.] 
adversary owned cards: [ 0  0  3  3  0 29 14  0  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8  1
  0 16  0 11  3 15 10 16] -> size -> 32 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: discard_down_to_3_cards - action 6
Learning step: 2.301661491394043
desired expected reward: -14.944628715515137



action possibilites: [-1] 
expected returns: [[-1.4222219]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 25. 11.] 
cards in discard: [6. 3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0 25  6  6 25  0  1  8 25  0 14  3 16  0  3  8 29 29  0
 11  0 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 27. 30.  8.  0.  7.  7.  0.  7.  7.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  6.  1.  0. 15.] 
adversary cards in discard: [16.  6. 11.  0.  8.  0.  6. 29.  8.  0.  1.  8.  0. 10.  8. 16. 14.  6.
  3.  0.  0.] 
adversary owned cards: [ 0  0  3  3  0 29 14  0  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8  1
  0 16  0 11  3 15 10 16] -> size -> 32 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 1.7856098413467407
desired expected reward: 10.433412551879883





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-6.0227757]
 [-1.5873606]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25. 25. 11.] 
cards in discard: [6. 3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0 25  6  6 25  0  1  8 25  0 14  3 16  0  3  8 29 29  0
 11  0 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 27. 30. 27. 30.  8.  0.  7.  7.  0.  7.  7.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  6.  1.  0. 15.] 
adversary cards in discard: [16.  6. 11.  0.  8.  0.  6. 29.  8.  0.  1.  8.  0. 10.  8. 16. 14.  6.
  3.  0.  0.] 
adversary owned cards: [ 0  0  3  3  0 29 14  0  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8  1
  0 16  0 11  3 15 10 16] -> size -> 32 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 2.2558979988098145
desired expected reward: 0.8336760997772217






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 6.  6.  1.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  1.  0. 15.] 
cards in discard: [16.  6. 11.  0.  8.  0.  6. 29.  8.  0.  1.  8.  0. 10.  8. 16. 14.  6.
  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 29 14  0  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8  1
  0 16  0 11  3 15 10 16] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 27. 30.  8.  0.  7.  7.  0.  7.  7.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  0.  0. 29. 16.] 
adversary cards in discard: [ 6.  3. 25.  0. 25. 25. 11.] 
adversary owned cards: [ 0  0  0  0  0  0 25  6  6 25  0  1  8 25  0 14  3 16  0  3  8 29 29  0
 11  0 11] -> size -> 27 
adversary victory points: 0
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  1.  0. 15.] 
cards in discard: [16.  6. 11.  0.  8.  0.  6. 29.  8.  0.  1.  8.  0. 10.  8. 16. 14.  6.
  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 29 14  0  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8  1
  0 16  0 11  3 15 10 16] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 27. 30. 27. 30.  8.  0.  7.  7.  0.  7.  7.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  0.  0. 29. 16.] 
adversary cards in discard: [ 6.  3. 25.  0. 25. 25. 11.] 
adversary owned cards: [ 0  0  0  0  0  0 25  6  6 25  0  1  8 25  0 14  3 16  0  3  8 29 29  0
 11  0 11] -> size -> 27 
adversary victory points: 0
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  1.  0. 15.] 
cards in discard: [16.  6. 11.  0.  8.  0.  6. 29.  8.  0.  1.  8.  0. 10.  8. 16. 14.  6.
  3.  0.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 29 14  0  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8  1
  0 16  0 11  3 15 10 16 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 27. 30.  8.  0.  7.  6.  0.  7.  7.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  0.  0. 29. 16.] 
adversary cards in discard: [ 6.  3. 25.  0. 25. 25. 11.] 
adversary owned cards: [ 0  0  0  0  0  0 25  6  6 25  0  1  8 25  0 14  3 16  0  3  8 29 29  0
 11  0 11] -> size -> 27 
adversary victory points: 0
player victory points: -3 





Player: 0 
cards in hand: [ 8.  0.  0. 29. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 16.] 
expected returns: [[22.229845]
 [19.855886]
 [19.762232]
 [19.246624]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 29. 16.] 
cards in discard: [ 6.  3. 25.  0. 25. 25. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 25  6  6 25  0  1  8 25  0 14  3 16  0  3  8 29 29  0
 11  0 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 27. 30.  8.  0.  7.  6.  0.  7.  7.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 10.  3.  3.  0.] 
adversary cards in discard: [16.  6. 11.  0.  8.  0.  6. 29.  8.  0.  1.  8.  0. 10.  8. 16. 14.  6.
  3.  0.  0. 11.  6.  6.  1.  0. 15.] 
adversary owned cards: [ 0  0  3  3  0 29 14  0  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8  1
  0 16  0 11  3 15 10 16 11] -> size -> 33 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 1.8035204410552979
desired expected reward: 0.2161571979522705



action possibilites: [-1] 
expected returns: [[-5.346529]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.] 
cards in discard: [ 6.  3. 25.  0. 25. 25. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 25  6  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 27. 30.  8.  0.  7.  6.  0.  7.  7.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 10.  3.  3.  0.] 
adversary cards in discard: [16.  6. 11.  0.  8.  0.  6. 29.  8.  0.  1.  8.  0. 10.  8. 16. 14.  6.
  3.  0.  0. 11.  6.  6.  1.  0. 15.] 
adversary owned cards: [ 0  0  3  3  0 29 14  0  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8  1
  0 16  0 11  3 15 10 16 11] -> size -> 33 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: trash_cards_n_from_hand - action 7
Learning step: 1.3342665433883667
desired expected reward: 17.243000030517578





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-10.064658]
 [ -5.400958]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.] 
cards in discard: [ 6.  3. 25.  0. 25. 25. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 25  6  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 27. 30. 27. 30.  8.  0.  7.  6.  0.  7.  7.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 10.  3.  3.  0.] 
adversary cards in discard: [16.  6. 11.  0.  8.  0.  6. 29.  8.  0.  1.  8.  0. 10.  8. 16. 14.  6.
  3.  0.  0. 11.  6.  6.  1.  0. 15.] 
adversary owned cards: [ 0  0  3  3  0 29 14  0  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8  1
  0 16  0 11  3 15 10 16 11] -> size -> 33 
adversary victory points: -3
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 2.364788770675659
desired expected reward: -2.9817402362823486






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [ 8. 10.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  3.  3.  0.] 
cards in discard: [16.  6. 11.  0.  8.  0.  6. 29.  8.  0.  1.  8.  0. 10.  8. 16. 14.  6.
  3.  0.  0. 11.  6.  6.  1.  0. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0 29 14  0  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8  1
  0 16  0 11  3 15 10 16 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 27. 30.  8.  0.  7.  6.  0.  7.  7.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 1. 3. 0. 0.] 
adversary cards in discard: [ 6.  3. 25.  0. 25. 25. 11.  8. 29.] 
adversary owned cards: [ 0  0  0  0 25  6  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11] -> size -> 24 
adversary victory points: 0
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [16.  6. 11.  0.  8.  0.  6. 29.  8.  0.  1.  8.  0. 10.  8. 16. 14.  6.
  3.  0.  0. 11.  6.  6.  1.  0. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 29 14  0  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8  1  0 16  0
 11  3 15 10 16 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 27. 30.  8.  0.  7.  6.  0.  7.  7.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 1. 3. 0. 0.] 
adversary cards in discard: [ 6.  3. 25.  0. 25. 25. 11.  8. 29.] 
adversary owned cards: [ 0  0  0  0 25  6  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11] -> size -> 24 
adversary victory points: 0
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [16.  6. 11.  0.  8.  0.  6. 29.  8.  0.  1.  8.  0. 10.  8. 16. 14.  6.
  3.  0.  0. 11.  6.  6.  1.  0. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 29 14  0  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8  1  0 16  0
 11  3 15 10 16 11] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 27. 30. 27. 30.  8.  0.  7.  6.  0.  7.  7.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 1. 3. 0. 0.] 
adversary cards in discard: [ 6.  3. 25.  0. 25. 25. 11.  8. 29.] 
adversary owned cards: [ 0  0  0  0 25  6  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11] -> size -> 24 
adversary victory points: 0
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [16.  6. 11.  0.  8.  0.  6. 29.  8.  0.  1.  8.  0. 10.  8. 16. 14.  6.
  3.  0.  0. 11.  6.  6.  1.  0. 15.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 29 14  0  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8  1  0 16  0
 11  3 15 10 16 11  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 27. 30.  8.  0.  7.  6.  0.  7.  7.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 1. 3. 0. 0.] 
adversary cards in discard: [ 6.  3. 25.  0. 25. 25. 11.  8. 29.] 
adversary owned cards: [ 0  0  0  0 25  6  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11] -> size -> 24 
adversary victory points: 0
player victory points: -5 





Player: 0 
cards in hand: [0. 1. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-13.405853]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 0. 0.] 
cards in discard: [ 6.  3. 25.  0. 25. 25. 11.  8. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 25  6  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 27. 30.  8.  0.  7.  6.  0.  7.  7.  8. 10.  7. 10.  9.] 
adversary cards in hand: [15.  1.  0.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 29 14  0  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8  1  0 16  0
 11  3 15 10 16 11  0] -> size -> 31 
adversary victory points: -5
player victory points: 0 

Reward from previous game state: 
[-5  0  0 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: buy - action -1.0
Learning step: 2.2184159755706787
desired expected reward: -3.18254017829895





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-15.47817 ]
 [-11.760239]
 [-13.989644]
 [-17.765501]
 [-13.968563]
 [-11.85172 ]
 [ -8.258403]
 [-13.406477]
 [-17.739367]
 [-16.307495]
 [-15.542325]
 [-18.520344]
 [-16.245298]
 [-13.506257]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0. 0.] 
cards in discard: [ 6.  3. 25.  0. 25. 25. 11.  8. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 25  6  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [18. 27. 30. 27. 30.  8.  0.  7.  6.  0.  7.  7.  8. 10.  7. 10.  9.] 
adversary cards in hand: [15.  1.  0.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 29 14  0  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8  1  0 16  0
 11  3 15 10 16 11  0] -> size -> 31 
adversary victory points: -5
player victory points: 0 

Reward from previous game state: 
[-5  0  0 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 2.65018630027771
desired expected reward: -10.755666732788086



buy possibilites: [-1] 
expected returns: [[-10.036071]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0. 0.] 
cards in discard: [ 6.  3. 25.  0. 25. 25. 11.  8. 29. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 25  6  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 27. 30. 27. 30.  8.  0.  7.  5.  0.  7.  7.  8. 10.  7. 10.  9.] 
adversary cards in hand: [15.  1.  0.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 29 14  0  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8  1  0 16  0
 11  3 15 10 16 11  0] -> size -> 31 
adversary victory points: -5
player victory points: 0 

Reward from previous game state: 
[-5.   0.   0.  50.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 49.5 

action type: buy - action 11.0
Learning step: 2.8417744636535645
desired expected reward: -9.009943008422852






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [15.  1.  0.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1.  0.  3.  6.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 29 14  0  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8  1  0 16  0
 11  3 15 10 16 11  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 27. 30.  8.  0.  7.  5.  0.  7.  7.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  0. 11.] 
adversary cards in discard: [ 6.  3. 25.  0. 25. 25. 11.  8. 29. 11.  0.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0 25  6  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11
 11] -> size -> 25 
adversary victory points: 0
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 6.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0 29 14  0  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8  1  0 16  0 11
  3 15 10 16 11  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [18. 27. 30. 27. 30.  8.  0.  7.  5.  0.  7.  7.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  0. 11.] 
adversary cards in discard: [ 6.  3. 25.  0. 25. 25. 11.  8. 29. 11.  0.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0 25  6  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11
 11] -> size -> 25 
adversary victory points: 0
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 6.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0 29 14  0  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8  1  0 16  0 11
  3 15 10 16 11  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [18. 27. 30. 27. 30.  8.  0.  7.  5.  0.  7.  7.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  0. 11.] 
adversary cards in discard: [ 6.  3. 25.  0. 25. 25. 11.  8. 29. 11.  0.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0 25  6  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11
 11] -> size -> 25 
adversary victory points: 0
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 6.] 
cards in discard: [29.] 
cards in deck: 26 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0 29 14  0  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8  1  0 16  0 11
  3 15 10 16 11  0 29] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 27. 30. 27. 30.  8.  0.  7.  5.  0.  7.  6.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  0. 11.] 
adversary cards in discard: [ 6.  3. 25.  0. 25. 25. 11.  8. 29. 11.  0.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0 25  6  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11
 11] -> size -> 25 
adversary victory points: 0
player victory points: -5 





Player: 0 
cards in hand: [ 0. 29.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[-6.2360477]
 [-9.672033 ]
 [-6.8876886]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0. 11.] 
cards in discard: [ 6.  3. 25.  0. 25. 25. 11.  8. 29. 11.  0.  1.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 25  6  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 27. 30.  8.  0.  7.  5.  0.  7.  6.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 6. 10.  6.  0. 11.] 
adversary cards in discard: [29. 15.  1.  3.  6.] 
adversary owned cards: [ 0 29 14  0  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8  1  0 16  0 11
  3 15 10 16 11  0 29] -> size -> 31 
adversary victory points: -5
player victory points: 0 

Reward from previous game state: 
[-5  0  0 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: buy - action -1
Learning step: 2.593369245529175
desired expected reward: -7.44270133972168



action possibilites: [-1] 
expected returns: [[33.004833]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.] 
cards in discard: [ 6.  3. 25.  0. 25. 25. 11.  8. 29. 11.  0.  1.  3.  0.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0 25  6  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11
 11  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 27. 30.  8.  0.  7.  5.  0.  7.  6.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 6. 10.  6.  0. 11.] 
adversary cards in discard: [29. 15.  1.  3.  6.] 
adversary owned cards: [ 0 29 14  0  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8  1  0 16  0 11
  3 15 10 16 11  0 29] -> size -> 31 
adversary victory points: -5
player victory points: 0 

Reward from previous game state: 
[-5  0  0 50  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 74 

action type: gain_card_n - action 1
Learning step: 4.844677448272705
desired expected reward: -3.1966986656188965





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[25.688473]
 [32.323795]
 [30.994722]
 [34.288395]
 [27.646053]
 [35.74247 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  0.] 
cards in discard: [ 6.  3. 25.  0. 25. 25. 11.  8. 29. 11.  0.  1.  3.  0.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0 25  6  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11
 11  1] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 26. 30. 27. 30.  8.  0.  7.  5.  0.  7.  6.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 6. 10.  6.  0. 11.] 
adversary cards in discard: [29. 15.  1.  3.  6.] 
adversary owned cards: [ 0 29 14  0  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8  1  0 16  0 11
  3 15 10 16 11  0 29] -> size -> 31 
adversary victory points: -5
player victory points: 0 

Reward from previous game state: 
[-5  0  0 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 2.342400550842285
desired expected reward: 35.347232818603516






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [ 6. 10.  6.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  6.  0. 11.] 
cards in discard: [29. 15.  1.  3.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29 14  0  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8  1  0 16  0 11
  3 15 10 16 11  0 29] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 27. 30.  8.  0.  7.  5.  0.  7.  6.  8. 10.  7. 10.  9.] 
adversary cards in hand: [14.  0.  0.  6.  8.] 
adversary cards in discard: [ 6.  3. 25.  0. 25. 25. 11.  8. 29. 11.  0.  1.  3.  0.  0.  1. 11.  0.
 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0 25  6  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11
 11  1] -> size -> 26 
adversary victory points: 0
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  6.  0. 11.] 
cards in discard: [29. 15.  1.  3.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29 14  0  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8  1  0 16  0 11
  3 15 10 16 11  0 29] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 26. 30. 27. 30.  8.  0.  7.  5.  0.  7.  6.  8. 10.  7. 10.  9.] 
adversary cards in hand: [14.  0.  0.  6.  8.] 
adversary cards in discard: [ 6.  3. 25.  0. 25. 25. 11.  8. 29. 11.  0.  1.  3.  0.  0.  1. 11.  0.
 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0 25  6  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11
 11  1] -> size -> 26 
adversary victory points: 0
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  6.  0. 11.] 
cards in discard: [29. 15.  1.  3.  6.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29 14  0  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8  1  0 16  0 11
  3 15 10 16 11  0 29  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 26. 30. 27. 30.  8.  0.  7.  5.  0.  7.  6.  8. 10.  7. 10.  9.] 
adversary cards in hand: [14.  0.  0.  6.  8.] 
adversary cards in discard: [ 6.  3. 25.  0. 25. 25. 11.  8. 29. 11.  0.  1.  3.  0.  0.  1. 11.  0.
 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0 25  6  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11
 11  1] -> size -> 26 
adversary victory points: 0
player victory points: -5 





Player: 0 
cards in hand: [14.  0.  0.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
expected returns: [[24.916935]
 [ 7.885291]
 [14.471269]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  6.  8.] 
cards in discard: [ 6.  3. 25.  0. 25. 25. 11.  8. 29. 11.  0.  1.  3.  0.  0.  1. 11.  0.
 29.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 25  6  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11
 11  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 27. 30.  8.  0.  7.  5.  0.  7.  6.  8. 10.  7. 10.  9.] 
adversary cards in hand: [10.  6.  0.  1.  8.] 
adversary cards in discard: [29. 15.  1.  3.  6.  0.  6. 10.  6.  0. 11.] 
adversary owned cards: [ 0 29 14  0  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8  1  0 16  0 11
  3 15 10 16 11  0 29  0] -> size -> 32 
adversary victory points: -5
player victory points: 0 

Reward from previous game state: 
[-5  0  0 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: buy - action -1.0
Learning step: 0.9016824960708618
desired expected reward: 36.6441535949707



action possibilites: [-1] 
expected returns: [[-13.320359]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.] 
cards in discard: [ 6.  3. 25.  0. 25. 25. 11.  8. 29. 11.  0.  1.  3.  0.  0.  1. 11.  0.
 29.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 27. 30.  8.  0.  7.  5.  0.  7.  6.  8. 10.  7. 10.  9.] 
adversary cards in hand: [10.  6.  0.  1.  8.] 
adversary cards in discard: [29. 15.  1.  3.  6.  0.  6. 10.  6.  0. 11.] 
adversary owned cards: [ 0 29 14  0  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8  1  0 16  0 11
  3 15 10 16 11  0 29  0] -> size -> 32 
adversary victory points: -5
player victory points: 1 

Reward from previous game state: 
[-5  0  1 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 76 

action type: trash_cards_n_from_hand - action 8
Learning step: 2.822523355484009
desired expected reward: 16.377893447875977





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-14.278104]
 [-14.408172]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.] 
cards in discard: [ 6.  3. 25.  0. 25. 25. 11.  8. 29. 11.  0.  1.  3.  0.  0.  1. 11.  0.
 29.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 26. 30. 27. 30.  8.  0.  7.  5.  0.  7.  6.  8. 10.  7. 10.  9.] 
adversary cards in hand: [10.  6.  0.  1.  8.] 
adversary cards in discard: [29. 15.  1.  3.  6.  0.  6. 10.  6.  0. 11.] 
adversary owned cards: [ 0 29 14  0  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8  1  0 16  0 11
  3 15 10 16 11  0 29  0] -> size -> 32 
adversary victory points: -5
player victory points: 1 

Reward from previous game state: 
[-5  0  1 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 76 

action type: take_action - action -1
Learning step: 4.143895626068115
desired expected reward: -9.176464080810547






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [10.  6.  0.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  0.  1.  8.] 
cards in discard: [29. 15.  1.  3.  6.  0.  6. 10.  6.  0. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29 14  0  6  1  6  6  8  0  8  6  8  0 10  6  8  6  8  1  0 16  0 11
  3 15 10 16 11  0 29  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 27. 30.  8.  0.  7.  5.  0.  7.  6.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1] -> size -> 23 
adversary victory points: 1
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [29. 15.  1.  3.  6.  0.  6. 10.  6.  0. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 29 14  0  6  6  8  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10
 16 11  0 29  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 27. 30.  8.  0.  7.  5.  0.  7.  6.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1] -> size -> 23 
adversary victory points: 1
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29. 15.  1.  3.  6.  0.  6. 10.  6.  0. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 29 14  0  6  6  8  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10
 16 11  0 29  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 26. 30. 27. 30.  8.  0.  7.  5.  0.  7.  6.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1] -> size -> 23 
adversary victory points: 1
player victory points: -4 





Player: 0 
cards in hand: [ 0. 11.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[ 0.7373426]
 [-0.5396497]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 27. 30.  8.  0.  7.  5.  0.  7.  6.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  8.  0.  6. 16.] 
adversary cards in discard: [29. 15.  1.  3.  6.  0.  6. 10.  6.  0. 11.  8.  0.] 
adversary owned cards: [ 0 29 14  0  6  6  8  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10
 16 11  0 29  0] -> size -> 29 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[-5  0  1 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 46 

action type: buy - action -1.0
Learning step: 2.986222982406616
desired expected reward: -11.421935081481934





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-13.313436 ]
 [ -8.395426 ]
 [-10.86903  ]
 [ -4.685306 ]
 [-11.401251 ]
 [ -3.4979753]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 26. 30. 27. 30.  8.  0.  7.  5.  0.  7.  6.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  8.  0.  6. 16.] 
adversary cards in discard: [29. 15.  1.  3.  6.  0.  6. 10.  6.  0. 11.  8.  0.] 
adversary owned cards: [ 0 29 14  0  6  6  8  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10
 16 11  0 29  0] -> size -> 29 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[-5  0  1 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 46 

action type: take_action - action -1.0
Learning step: 2.2102854251861572
desired expected reward: 1.0483124256134033



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  0.  6. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0.  6. 16.] 
cards in discard: [29. 15.  1.  3.  6.  0.  6. 10.  6.  0. 11.  8.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29 14  0  6  6  8  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10
 16 11  0 29  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 27. 30.  8.  0.  7.  5.  0.  7.  6.  8. 10.  7. 10.  9.] 
adversary cards in hand: [25. 29. 25.  8.  8.] 
adversary cards in discard: [ 0. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1] -> size -> 23 
adversary victory points: 1
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6.] 
cards in discard: [29. 15.  1.  3.  6.  0.  6. 10.  6.  0. 11.  8.  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0 29 14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16
 11  0 29  0 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 27. 30.  8.  0.  7.  5.  0.  7.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [25. 29. 25.  8.  8.] 
adversary cards in discard: [ 0. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1] -> size -> 23 
adversary victory points: 1
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [29. 15.  1.  3.  6.  0.  6. 10.  6.  0. 11.  8.  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0 29 14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16
 11  0 29  0 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 26. 30. 27. 30.  8.  0.  7.  5.  0.  7.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [25. 29. 25.  8.  8.] 
adversary cards in discard: [ 0. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1] -> size -> 23 
adversary victory points: 1
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [29. 15.  1.  3.  6.  0.  6. 10.  6.  0. 11.  8.  0. 10.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0 29 14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16
 11  0 29  0 10  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 26. 30. 27. 30.  8.  0.  7.  5.  0.  7.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [25. 29. 25.  8.  8.] 
adversary cards in discard: [ 0. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1] -> size -> 23 
adversary victory points: 1
player victory points: -4 





Player: 0 
cards in hand: [25. 29. 25.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25.  8.  8.] 
expected returns: [[27.409027]
 [36.82335 ]
 [23.64246 ]
 [36.82335 ]
 [23.870985]
 [23.870985]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 25.  8.  8.] 
cards in discard: [ 0. 11.  0.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 27. 30.  8.  0.  7.  5.  0.  7.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [14. 29.  0. 11.  0.] 
adversary cards in discard: [29. 15.  1.  3.  6.  0.  6. 10.  6.  0. 11.  8.  0. 10.  0. 16.  0.  0.
  6.] 
adversary owned cards: [ 0 29 14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16
 11  0 29  0 10  0] -> size -> 30 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[-5  0  1 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 46 

action type: buy - action -1.0
Learning step: 2.908867359161377
desired expected reward: 4.621135711669922



action possibilites: [-1] 
expected returns: [[72.00649]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  8.  8. 14. 11.] 
cards in discard: [ 0. 11.  0.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 27. 30.  8.  0.  7.  5.  0.  7.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [14. 29.  0. 11.  0.] 
adversary cards in discard: [29. 15.  1.  3.  6.  0.  6. 10.  6.  0. 11.  8.  0. 10.  0. 16.  0.  0.
  6.] 
adversary owned cards: [ 0 29 14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16
 11  0 29  0 10  0] -> size -> 30 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[-5  0  1 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 66 

action type: take_action - action 25.0
Learning step: 3.140031337738037
desired expected reward: 38.74232864379883





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[58.283955]
 [71.80685 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 25.  8.  8. 14. 11.] 
cards in discard: [ 0. 11.  0.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 26. 30. 27. 30.  8.  0.  7.  5.  0.  7.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [14. 29.  0. 11.  0.] 
adversary cards in discard: [29. 15.  1.  3.  6.  0.  6. 10.  6.  0. 11.  8.  0. 10.  0. 16.  0.  0.
  6.] 
adversary owned cards: [ 0 29 14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16
 11  0 29  0 10  0] -> size -> 30 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[-5  0  1 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 66 

action type: take_action - action -1
Learning step: 1.2253955602645874
desired expected reward: 73.23188781738281






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [14. 29.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 29.  0. 11.  0.] 
cards in discard: [29. 15.  1.  3.  6.  0.  6. 10.  6.  0. 11.  8.  0. 10.  0. 16.  0.  0.
  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29 14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16
 11  0 29  0 10  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 27. 30.  8.  0.  7.  5.  0.  7.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [11.  0.  1.  0.  0.] 
adversary cards in discard: [ 0. 11.  0.  0.  3. 25. 29. 25.  8.  8. 14. 11.] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1] -> size -> 23 
adversary victory points: 1
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 29.  0.  0.] 
cards in discard: [29. 15.  1.  3.  6.  0.  6. 10.  6.  0. 11.  8.  0. 10.  0. 16.  0.  0.
  6.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 29 14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16
 11  0 29  0 10  0  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 27. 30.  8.  0.  7.  5.  0.  7.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [11.  0.  1.  0.  0.] 
adversary cards in discard: [ 0. 11.  0.  0.  3. 25. 29. 25.  8.  8. 14. 11.] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1] -> size -> 23 
adversary victory points: 1
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 29.  0.  0.] 
cards in discard: [29. 15.  1.  3.  6.  0.  6. 10.  6.  0. 11.  8.  0. 10.  0. 16.  0.  0.
  6.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 29 14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16
 11  0 29  0 10  0  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 26. 30. 27. 30.  8.  0.  7.  5.  0.  7.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [11.  0.  1.  0.  0.] 
adversary cards in discard: [ 0. 11.  0.  0.  3. 25. 29. 25.  8.  8. 14. 11.] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1] -> size -> 23 
adversary victory points: 1
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 29.  0.  0.] 
cards in discard: [29. 15.  1.  3.  6.  0.  6. 10.  6.  0. 11.  8.  0. 10.  0. 16.  0.  0.
  6.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 29 14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16
 11  0 29  0 10  0  0  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 26. 30. 27. 30.  8.  0.  7.  5.  0.  7.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [11.  0.  1.  0.  0.] 
adversary cards in discard: [ 0. 11.  0.  0.  3. 25. 29. 25.  8.  8. 14. 11.] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1] -> size -> 23 
adversary victory points: 1
player victory points: -4 





Player: 0 
cards in hand: [11.  0.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[11.891947]
 [11.659726]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  1.  0.  0.] 
cards in discard: [ 0. 11.  0.  0.  3. 25. 29. 25.  8.  8. 14. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 27. 30.  8.  0.  7.  5.  0.  7.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  6. 16.  0.  8.] 
adversary cards in discard: [29. 15.  1.  3.  6.  0.  6. 10.  6.  0. 11.  8.  0. 10.  0. 16.  0.  0.
  6.  0.  0. 11. 14. 29.  0.  0.] 
adversary owned cards: [ 0 29 14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16
 11  0 29  0 10  0  0  0] -> size -> 32 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[-5  0  1 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 46 

action type: buy - action -1.0
Learning step: -1.0243186950683594
desired expected reward: 70.78254699707031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 0.4684584]
 [ 4.3216944]
 [ 4.636468 ]
 [-3.4630692]
 [ 1.8721402]
 [ 6.454177 ]
 [ 8.684074 ]
 [ 2.1161282]
 [-1.8478115]
 [ 1.1913049]
 [ 2.4127991]
 [-2.814807 ]
 [ 1.3429129]
 [ 6.498212 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  1.  0.  0.] 
cards in discard: [ 0. 11.  0.  0.  3. 25. 29. 25.  8.  8. 14. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [14. 26. 30. 27. 30.  8.  0.  7.  5.  0.  7.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  6. 16.  0.  8.] 
adversary cards in discard: [29. 15.  1.  3.  6.  0.  6. 10.  6.  0. 11.  8.  0. 10.  0. 16.  0.  0.
  6.  0.  0. 11. 14. 29.  0.  0.] 
adversary owned cards: [ 0 29 14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16
 11  0 29  0 10  0  0  0] -> size -> 32 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[-5  0  1 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 46 

action type: take_action - action -1.0
Learning step: 1.8155688047409058
desired expected reward: 13.70751667022705



buy possibilites: [-1] 
expected returns: [[13.75779]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  1.  0.  0.] 
cards in discard: [ 0. 11.  0.  0.  3. 25. 29. 25.  8.  8. 14. 11. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 27. 30.  8.  0.  7.  5.  0.  6.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  6. 16.  0.  8.] 
adversary cards in discard: [29. 15.  1.  3.  6.  0.  6. 10.  6.  0. 11.  8.  0. 10.  0. 16.  0.  0.
  6.  0.  0. 11. 14. 29.  0.  0.] 
adversary owned cards: [ 0 29 14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16
 11  0 29  0 10  0  0  0] -> size -> 32 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[-5  0  1 50  0  0  0  0  0  0  0  0  0  0 50  0] 
sum of rewards: 96 

action type: buy - action 25.0
Learning step: 4.675346374511719
desired expected reward: 13.359421730041504






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [ 8.  6. 16.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6. 16.  0.  8.] 
cards in discard: [29. 15.  1.  3.  6.  0.  6. 10.  6.  0. 11.  8.  0. 10.  0. 16.  0.  0.
  6.  0.  0. 11. 14. 29.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29 14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16
 11  0 29  0 10  0  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 27. 30.  8.  0.  7.  5.  0.  6.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [25.  6.  3. 29.  0.] 
adversary cards in discard: [ 0. 11.  0.  0.  3. 25. 29. 25.  8.  8. 14. 11. 25. 11.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25] -> size -> 24 
adversary victory points: 1
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6. 16.  0.  8.] 
cards in discard: [29. 15.  1.  3.  6.  0.  6. 10.  6.  0. 11.  8.  0. 10.  0. 16.  0.  0.
  6.  0.  0. 11. 14. 29.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29 14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16
 11  0 29  0 10  0  0  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 26. 30. 27. 30.  8.  0.  7.  5.  0.  6.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [25.  6.  3. 29.  0.] 
adversary cards in discard: [ 0. 11.  0.  0.  3. 25. 29. 25.  8.  8. 14. 11. 25. 11.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25] -> size -> 24 
adversary victory points: 1
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6. 16.  0.  8.] 
cards in discard: [29. 15.  1.  3.  6.  0.  6. 10.  6.  0. 11.  8.  0. 10.  0. 16.  0.  0.
  6.  0.  0. 11. 14. 29.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29 14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16
 11  0 29  0 10  0  0  0  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 26. 30. 27. 30.  8.  0.  7.  5.  0.  6.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [25.  6.  3. 29.  0.] 
adversary cards in discard: [ 0. 11.  0.  0.  3. 25. 29. 25.  8.  8. 14. 11. 25. 11.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25] -> size -> 24 
adversary victory points: 1
player victory points: -4 





Player: 0 
cards in hand: [25.  6.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[-24.919285]
 [-26.827751]
 [-24.998539]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  6.  3. 29.  0.] 
cards in discard: [ 0. 11.  0.  0.  3. 25. 29. 25.  8.  8. 14. 11. 25. 11.  0.  1.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 27. 30.  8.  0.  7.  5.  0.  6.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [29.  0.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29 14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16
 11  0 29  0 10  0  0  0  0] -> size -> 33 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[-5  0  1 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 46 

action type: buy - action -1
Learning step: 1.0426138639450073
desired expected reward: 14.800403594970703





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-18.352655]
 [-20.12438 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  6.  3. 29.  0.] 
cards in discard: [ 0. 11.  0.  0.  3. 25. 29. 25.  8.  8. 14. 11. 25. 11.  0.  1.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 26. 30. 27. 30.  8.  0.  7.  5.  0.  6.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [29.  0.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29 14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16
 11  0 29  0 10  0  0  0  0] -> size -> 33 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[-5  0  1 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 46 

action type: take_action - action -1.0
Learning step: 3.1212470531463623
desired expected reward: -21.79804229736328



buy possibilites: [-1] 
expected returns: [[14.343182]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  6.  3. 29.  0.] 
cards in discard: [ 0. 11.  0.  0.  3. 25. 29. 25.  8.  8. 14. 11. 25. 11.  0.  1.  0.  0.
  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 26. 30. 27. 30.  8.  0.  7.  5.  0.  6.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [29.  0.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29 14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16
 11  0 29  0 10  0  0  0  0] -> size -> 33 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1.  50.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 16.0 

action type: buy - action 0.0
Learning step: 2.040354013442993
desired expected reward: -16.312294006347656






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [29.  0.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29 14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16
 11  0 29  0 10  0  0  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 27. 30.  8.  0.  7.  5.  0.  6.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [29. 25. 25.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0] -> size -> 25 
adversary victory points: 1
player victory points: -4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6.] 
cards in discard: [0. 8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0 29 14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16
 11  0 29  0 10  0  0  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [12. 26. 30. 27. 30.  8.  0.  7.  5.  0.  6.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [29. 25. 25.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0] -> size -> 25 
adversary victory points: 1
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [0. 8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0 29 14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16
 11  0 29  0 10  0  0  0  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 26. 30. 27. 30.  8.  0.  7.  5.  0.  6.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [29. 25. 25.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0] -> size -> 25 
adversary victory points: 1
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [0. 8. 0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0 29 14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16
 11  0 29  0 10  0  0  0  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [11. 26. 30. 27. 30.  8.  0.  7.  5.  0.  6.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [29. 25. 25.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0] -> size -> 25 
adversary victory points: 1
player victory points: -4 





Player: 0 
cards in hand: [29. 25. 25.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 25.] 
expected returns: [[-4.447728 ]
 [-4.704487 ]
 [-1.3809779]
 [-1.3809779]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 25.  0.  1.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 27. 30.  8.  0.  7.  5.  0.  6.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 29. 10.  8.  6.] 
adversary cards in discard: [ 0.  8.  0. 29.  0.  0.  6.] 
adversary owned cards: [ 0 29 14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16
 11  0 29  0 10  0  0  0  0  0] -> size -> 34 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[-5  0  1 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 46 

action type: buy - action -1
Learning step: 1.530519723892212
desired expected reward: 15.873701095581055



action possibilites: [-1] 
expected returns: [[20.031013]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  0.  1.  1.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 27. 30.  8.  0.  7.  5.  0.  6.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 29. 10.  8.  6.] 
adversary cards in discard: [ 0.  8.  0. 29.  0.  0.  6.] 
adversary owned cards: [ 0 29 14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16
 11  0 29  0 10  0  0  0  0  0] -> size -> 34 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[-5  0  1 50  0  0 20  0  0  0  0  0  0  0  0  3] 
sum of rewards: 69 

action type: take_action - action 25.0
Learning step: 3.9697461128234863
desired expected reward: 2.5887765884399414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 1.5570538 ]
 [10.279018  ]
 [ 0.38816142]
 [ 7.949732  ]
 [-3.6260827 ]
 [ 4.490058  ]
 [15.059357  ]
 [24.593452  ]
 [ 5.6009636 ]
 [-2.658989  ]
 [ 0.92198205]
 [ 3.7986596 ]
 [-3.2858186 ]
 [ 1.5479109 ]
 [14.246929  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 25.  0.  1.  1.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 6 
card supply: [11. 26. 30. 27. 30.  8.  0.  7.  5.  0.  6.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 29. 10.  8.  6.] 
adversary cards in discard: [ 0.  8.  0. 29.  0.  0.  6.] 
adversary owned cards: [ 0 29 14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16
 11  0 29  0 10  0  0  0  0  0] -> size -> 34 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[-5  0  1 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 66 

action type: take_action - action -1
Learning step: 2.596388339996338
desired expected reward: 22.62740135192871



buy possibilites: [-1] 
expected returns: [[-5.9239054]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 25.  0.  1.  1.  0.] 
cards in discard: [25.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 26. 30. 27. 30.  8.  0.  7.  5.  0.  5.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 29. 10.  8.  6.] 
adversary cards in discard: [ 0.  8.  0. 29.  0.  0.  6.] 
adversary owned cards: [ 0 29 14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16
 11  0 29  0 10  0  0  0  0  0] -> size -> 34 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[-5.   0.   1.  50.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
 12.5  0. ] 
sum of rewards: 78.5 

action type: buy - action 25.0
Learning step: 2.5620381832122803
desired expected reward: 27.155519485473633






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [ 0. 29. 10.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10.  8.  6.] 
cards in discard: [ 0.  8.  0. 29.  0.  0.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29 14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16
 11  0 29  0 10  0  0  0  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 27. 30.  8.  0.  7.  5.  0.  5.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [11.  0. 14.  0.  3.] 
adversary cards in discard: [25. 25. 29. 25.  0.  1.  1.  0.] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25] -> size -> 26 
adversary victory points: 1
player victory points: -4 


action possibilites: [-1. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  8.  6.  0.] 
cards in discard: [ 0.  8.  0. 29.  0.  0.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0 29 14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16
 11  0 29  0 10  0  0  0  0  0] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 27. 30.  8.  0.  7.  5.  0.  5.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [11.  0. 14.  0.  3.] 
adversary cards in discard: [25. 25. 29. 25.  0.  1.  1.  0.] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25] -> size -> 26 
adversary victory points: 1
player victory points: -4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0.] 
cards in discard: [ 0.  8.  0. 29.  0.  0.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16 11  0
 29  0 10  0  0  0  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 27. 30.  8.  0.  7.  5.  0.  5.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [11.  0. 14.  0.  3.] 
adversary cards in discard: [25. 25. 29. 25.  0.  1.  1.  0.] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25] -> size -> 26 
adversary victory points: 1
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [ 0.  8.  0. 29.  0.  0.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16 11  0
 29  0 10  0  0  0  0  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 26. 30. 27. 30.  8.  0.  7.  5.  0.  5.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [11.  0. 14.  0.  3.] 
adversary cards in discard: [25. 25. 29. 25.  0.  1.  1.  0.] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25] -> size -> 26 
adversary victory points: 1
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [ 0.  8.  0. 29.  0.  0.  6.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16 11  0
 29  0 10  0  0  0  0  0  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 26. 30. 27. 30.  8.  0.  7.  5.  0.  5.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [11.  0. 14.  0.  3.] 
adversary cards in discard: [25. 25. 29. 25.  0.  1.  1.  0.] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25] -> size -> 26 
adversary victory points: 1
player victory points: -4 





Player: 0 
cards in hand: [11.  0. 14.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
expected returns: [[-9.739481 ]
 [-9.888446 ]
 [-7.4287453]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 14.  0.  3.] 
cards in discard: [25. 25. 29. 25.  0.  1.  1.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 27. 30.  8.  0.  7.  5.  0.  5.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 16. 10.  6. 11.] 
adversary cards in discard: [ 0.  8.  0. 29.  0.  0.  6.  0. 10.  8.  6.  0.] 
adversary owned cards: [14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16 11  0
 29  0 10  0  0  0  0  0  0] -> size -> 33 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[-5  0  1 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 46 

action type: buy - action -1
Learning step: 2.40789794921875
desired expected reward: -3.516007423400879



action possibilites: [-1] 
expected returns: [[12.375278]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  3.] 
cards in discard: [25. 25. 29. 25.  0.  1.  1.  0. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 27. 30.  8.  0.  7.  5.  0.  5.  6.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 16. 10.  6. 11.] 
adversary cards in discard: [ 0.  8.  0. 29.  0.  0.  6.  0. 10.  8.  6.  0.] 
adversary owned cards: [14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16 11  0
 29  0 10  0  0  0  0  0  0] -> size -> 33 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[-5  0  1 50  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 75 

action type: gain_card_n - action 7
Learning step: 4.370498180389404
desired expected reward: -2.47751522064209





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[ 8.5791855]
 [10.301842 ]
 [11.873127 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  3.] 
cards in discard: [25. 25. 29. 25.  0.  1.  1.  0. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 26. 30. 27. 30.  8.  0.  7.  5.  0.  5.  6.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 16. 10.  6. 11.] 
adversary cards in discard: [ 0.  8.  0. 29.  0.  0.  6.  0. 10.  8.  6.  0.] 
adversary owned cards: [14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16 11  0
 29  0 10  0  0  0  0  0  0] -> size -> 33 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[-5  0  1 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 66 

action type: take_action - action -1
Learning step: 2.9268107414245605
desired expected reward: 15.30208969116211






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [ 0. 16. 10.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 10.  6. 11.] 
cards in discard: [ 0.  8.  0. 29.  0.  0.  6.  0. 10.  8.  6.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16 11  0
 29  0 10  0  0  0  0  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 27. 30.  8.  0.  7.  5.  0.  5.  6.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  0.  8.] 
adversary cards in discard: [25. 25. 29. 25.  0.  1.  1.  0. 10. 11.  0. 14.  0.  3.] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10] -> size -> 27 
adversary victory points: 1
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 10.  6.] 
cards in discard: [ 0.  8.  0. 29.  0.  0.  6.  0. 10.  8.  6.  0. 16.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16 11  0
 29  0 10  0  0  0  0  0  0 16] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 27. 30.  8.  0.  6.  5.  0.  5.  6.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  0.  8.] 
adversary cards in discard: [25. 25. 29. 25.  0.  1.  1.  0. 10. 11.  0. 14.  0.  3.] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10] -> size -> 27 
adversary victory points: 1
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16. 10.  6.] 
cards in discard: [ 0.  8.  0. 29.  0.  0.  6.  0. 10.  8.  6.  0. 16.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16 11  0
 29  0 10  0  0  0  0  0  0 16] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 26. 30. 27. 30.  8.  0.  6.  5.  0.  5.  6.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  0.  8.] 
adversary cards in discard: [25. 25. 29. 25.  0.  1.  1.  0. 10. 11.  0. 14.  0.  3.] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10] -> size -> 27 
adversary victory points: 1
player victory points: -4 





Player: 0 
cards in hand: [ 3. 11.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[23.406313]
 [22.730528]
 [18.277283]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.  8.] 
cards in discard: [25. 25. 29. 25.  0.  1.  1.  0. 10. 11.  0. 14.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 27. 30.  8.  0.  6.  5.  0.  5.  6.  8. 10.  5. 10.  9.] 
adversary cards in hand: [0. 6. 0. 1. 3.] 
adversary cards in discard: [ 0.  8.  0. 29.  0.  0.  6.  0. 10.  8.  6.  0. 16. 11.  0. 16. 10.  6.] 
adversary owned cards: [14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16 11  0
 29  0 10  0  0  0  0  0  0 16] -> size -> 34 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[-5  0  1 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 46 

action type: buy - action -1.0
Learning step: 2.207249164581299
desired expected reward: 14.080375671386719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[16.12677 ]
 [19.77837 ]
 [23.873484]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  0.  8.] 
cards in discard: [25. 25. 29. 25.  0.  1.  1.  0. 10. 11.  0. 14.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 26. 30. 27. 30.  8.  0.  6.  5.  0.  5.  6.  8. 10.  5. 10.  9.] 
adversary cards in hand: [0. 6. 0. 1. 3.] 
adversary cards in discard: [ 0.  8.  0. 29.  0.  0.  6.  0. 10.  8.  6.  0. 16. 11.  0. 16. 10.  6.] 
adversary owned cards: [14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16 11  0
 29  0 10  0  0  0  0  0  0 16] -> size -> 34 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[-5  0  1 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 46 

action type: take_action - action -1.0
Learning step: 1.614335060119629
desired expected reward: 25.020648956298828



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [0. 6. 0. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 1. 3.] 
cards in discard: [ 0.  8.  0. 29.  0.  0.  6.  0. 10.  8.  6.  0. 16. 11.  0. 16. 10.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16 11  0
 29  0 10  0  0  0  0  0  0 16] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 27. 30.  8.  0.  6.  5.  0.  5.  6.  8. 10.  5. 10.  9.] 
adversary cards in hand: [25.  6. 29. 25.  0.] 
adversary cards in discard: [25. 25. 29. 25.  0.  1.  1.  0. 10. 11.  0. 14.  0.  3.  3. 11.  0.  0.
  8.] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10] -> size -> 27 
adversary victory points: 1
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 1. 3.] 
cards in discard: [ 0.  8.  0. 29.  0.  0.  6.  0. 10.  8.  6.  0. 16. 11.  0. 16. 10.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16 11  0
 29  0 10  0  0  0  0  0  0 16] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [10. 26. 30. 27. 30.  8.  0.  6.  5.  0.  5.  6.  8. 10.  5. 10.  9.] 
adversary cards in hand: [25.  6. 29. 25.  0.] 
adversary cards in discard: [25. 25. 29. 25.  0.  1.  1.  0. 10. 11.  0. 14.  0.  3.  3. 11.  0.  0.
  8.] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10] -> size -> 27 
adversary victory points: 1
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 1. 3.] 
cards in discard: [ 0.  8.  0. 29.  0.  0.  6.  0. 10.  8.  6.  0. 16. 11.  0. 16. 10.  6.
 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16 11  0
 29  0 10  0  0  0  0  0  0 16 29] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 27. 30.  8.  0.  6.  5.  0.  5.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [25.  6. 29. 25.  0.] 
adversary cards in discard: [25. 25. 29. 25.  0.  1.  1.  0. 10. 11.  0. 14.  0.  3.  3. 11.  0.  0.
  8.] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10] -> size -> 27 
adversary victory points: 1
player victory points: -4 





Player: 0 
cards in hand: [25.  6. 29. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25.] 
expected returns: [[ 8.904764 ]
 [ 9.541959 ]
 [-0.9701543]
 [ 9.541959 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  6. 29. 25.  0.] 
cards in discard: [25. 25. 29. 25.  0.  1.  1.  0. 10. 11.  0. 14.  0.  3.  3. 11.  0.  0.
  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 27. 30.  8.  0.  6.  5.  0.  5.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 16.  0. 15.] 
adversary cards in discard: [ 0.  8.  0. 29.  0.  0.  6.  0. 10.  8.  6.  0. 16. 11.  0. 16. 10.  6.
 29.  0.  6.  0.  1.  3.] 
adversary owned cards: [14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16 11  0
 29  0 10  0  0  0  0  0  0 16 29] -> size -> 35 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[-5  0  1 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 46 

action type: buy - action -1.0
Learning step: 1.283945918083191
desired expected reward: 25.157424926757812





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-2.8002298]
 [10.3408165]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  6. 29. 25.  0.] 
cards in discard: [25. 25. 29. 25.  0.  1.  1.  0. 10. 11.  0. 14.  0.  3.  3. 11.  0.  0.
  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 26. 30. 27. 30.  8.  0.  6.  5.  0.  5.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 16.  0. 15.] 
adversary cards in discard: [ 0.  8.  0. 29.  0.  0.  6.  0. 10.  8.  6.  0. 16. 11.  0. 16. 10.  6.
 29.  0.  6.  0.  1.  3.] 
adversary owned cards: [14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16 11  0
 29  0 10  0  0  0  0  0  0 16 29] -> size -> 35 
adversary victory points: -4
player victory points: 1 

Reward from previous game state: 
[-5  0  1 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 46 

action type: take_action - action -1.0
Learning step: 2.0000369548797607
desired expected reward: 10.90477466583252



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 16.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  0. 15.] 
cards in discard: [ 0.  8.  0. 29.  0.  0.  6.  0. 10.  8.  6.  0. 16. 11.  0. 16. 10.  6.
 29.  0.  6.  0.  1.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16 11  0
 29  0 10  0  0  0  0  0  0 16 29] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 27. 30.  8.  0.  6.  5.  0.  5.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 1.  0.  0. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10] -> size -> 27 
adversary victory points: 1
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.  0. 15.] 
cards in discard: [ 0.  8.  0. 29.  0.  0.  6.  0. 10.  8.  6.  0. 16. 11.  0. 16. 10.  6.
 29.  0.  6.  0.  1.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16 11  0
 29  0 10  0  0  0  0  0  0 16 29] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 26. 30. 27. 30.  8.  0.  6.  5.  0.  5.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 1.  0.  0. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10] -> size -> 27 
adversary victory points: 1
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.  0. 15.] 
cards in discard: [ 0.  8.  0. 29.  0.  0.  6.  0. 10.  8.  6.  0. 16. 11.  0. 16. 10.  6.
 29.  0.  6.  0.  1.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16 11  0
 29  0 10  0  0  0  0  0  0 16 29  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 26. 30. 26. 30.  8.  0.  6.  5.  0.  5.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 1.  0.  0. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10] -> size -> 27 
adversary victory points: 1
player victory points: -3 





Player: 0 
cards in hand: [ 1.  0.  0. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[-11.054275]
 [-12.958017]
 [-13.023227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0. 11.  8.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 26. 30.  8.  0.  6.  5.  0.  5.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  8. 14.  8. 11.] 
adversary cards in discard: [ 0.  8.  0. 29.  0.  0.  6.  0. 10.  8.  6.  0. 16. 11.  0. 16. 10.  6.
 29.  0.  6.  0.  1.  3.  3.  0.  0. 16.  0. 15.] 
adversary owned cards: [14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16 11  0
 29  0 10  0  0  0  0  0  0 16 29  3] -> size -> 36 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[-5  0  1 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 36 

action type: buy - action -1.0
Learning step: 1.017068862915039
desired expected reward: 11.357863426208496





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[ -9.849823]
 [-13.002222]
 [ -8.085814]
 [-11.360685]
 [-13.176597]
 [-12.866046]
 [ -7.36241 ]
 [ -8.969533]
 [ -8.366297]
 [-11.486635]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0. 11.  8.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [10. 26. 30. 26. 30.  8.  0.  6.  5.  0.  5.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  8. 14.  8. 11.] 
adversary cards in discard: [ 0.  8.  0. 29.  0.  0.  6.  0. 10.  8.  6.  0. 16. 11.  0. 16. 10.  6.
 29.  0.  6.  0.  1.  3.  3.  0.  0. 16.  0. 15.] 
adversary owned cards: [14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16 11  0
 29  0 10  0  0  0  0  0  0 16 29  3] -> size -> 36 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[-5  0  1 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 36 

action type: take_action - action -1.0
Learning step: 2.145955801010132
desired expected reward: -8.908297538757324



buy possibilites: [-1] 
expected returns: [[-0.37980962]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0. 11.  8.] 
cards in discard: [1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 25. 30. 26. 30.  8.  0.  6.  5.  0.  5.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  8. 14.  8. 11.] 
adversary cards in discard: [ 0.  8.  0. 29.  0.  0.  6.  0. 10.  8.  6.  0. 16. 11.  0. 16. 10.  6.
 29.  0.  6.  0.  1.  3.  3.  0.  0. 16.  0. 15.] 
adversary owned cards: [14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16 11  0
 29  0 10  0  0  0  0  0  0 16 29  3] -> size -> 36 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[-5.   0.   1.  40.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 40.5 

action type: buy - action 1.0
Learning step: 2.666564702987671
desired expected reward: -10.335639953613281






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [ 0.  8. 14.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 14.  8. 11.] 
cards in discard: [ 0.  8.  0. 29.  0.  0.  6.  0. 10.  8.  6.  0. 16. 11.  0. 16. 10.  6.
 29.  0.  6.  0.  1.  3.  3.  0.  0. 16.  0. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16 11  0
 29  0 10  0  0  0  0  0  0 16 29  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 26. 30.  8.  0.  6.  5.  0.  5.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [11.  0. 10. 25. 29.] 
adversary cards in discard: [ 1.  1.  0.  0. 11.  8.] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10  1] -> size -> 28 
adversary victory points: 1
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 14.  8. 11.] 
cards in discard: [ 0.  8.  0. 29.  0.  0.  6.  0. 10.  8.  6.  0. 16. 11.  0. 16. 10.  6.
 29.  0.  6.  0.  1.  3.  3.  0.  0. 16.  0. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16 11  0
 29  0 10  0  0  0  0  0  0 16 29  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 25. 30. 26. 30.  8.  0.  6.  5.  0.  5.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [11.  0. 10. 25. 29.] 
adversary cards in discard: [ 1.  1.  0.  0. 11.  8.] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10  1] -> size -> 28 
adversary victory points: 1
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 14.  8. 11.] 
cards in discard: [ 0.  8.  0. 29.  0.  0.  6.  0. 10.  8.  6.  0. 16. 11.  0. 16. 10.  6.
 29.  0.  6.  0.  1.  3.  3.  0.  0. 16.  0. 15.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16 11  0
 29  0 10  0  0  0  0  0  0 16 29  3  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 25. 30. 26. 30.  8.  0.  6.  5.  0.  5.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [11.  0. 10. 25. 29.] 
adversary cards in discard: [ 1.  1.  0.  0. 11.  8.] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10  1] -> size -> 28 
adversary victory points: 1
player victory points: -3 





Player: 0 
cards in hand: [11.  0. 10. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 25. 29.] 
expected returns: [[50.124386]
 [47.01923 ]
 [36.04192 ]
 [51.890457]
 [37.08478 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10. 25. 29.] 
cards in discard: [ 1.  1.  0.  0. 11.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 26. 30.  8.  0.  6.  5.  0.  5.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [11.  3.  0.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16 11  0
 29  0 10  0  0  0  0  0  0 16 29  3  0] -> size -> 37 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[-5  0  1 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 36 

action type: buy - action -1
Learning step: 2.8873231410980225
desired expected reward: 2.5075135231018066



action possibilites: [-1] 
expected returns: [[1.8899004]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10. 29. 25.  3.] 
cards in discard: [ 1.  1.  0.  0. 11.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 26. 30.  8.  0.  6.  5.  0.  5.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [11.  3.  0.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16 11  0
 29  0 10  0  0  0  0  0  0 16 29  3  0] -> size -> 37 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[-5  0  1 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 56 

action type: take_action - action 25.0
Learning step: 0.2480003386735916
desired expected reward: 52.138450622558594





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-5.5720863 ]
 [ 0.74494433]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 10. 29. 25.  3.] 
cards in discard: [ 1.  1.  0.  0. 11.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 25. 30. 26. 30.  8.  0.  6.  5.  0.  5.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [11.  3.  0.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16 11  0
 29  0 10  0  0  0  0  0  0 16 29  3  0] -> size -> 37 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[-5  0  1 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 56 

action type: take_action - action -1
Learning step: 2.6802549362182617
desired expected reward: 4.570155143737793






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [11.  3.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0.  6.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16 11  0
 29  0 10  0  0  0  0  0  0 16 29  3  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 26. 30.  8.  0.  6.  5.  0.  5.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [ 1.  1.  0.  0. 11.  8. 25. 11.  0. 10. 29. 25.  3.] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10  1] -> size -> 28 
adversary victory points: 1
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  0.  6.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16 11  0
 29  0 10  0  0  0  0  0  0 16 29  3  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 25. 30. 26. 30.  8.  0.  6.  5.  0.  5.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [ 1.  1.  0.  0. 11.  8. 25. 11.  0. 10. 29. 25.  3.] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10  1] -> size -> 28 
adversary victory points: 1
player victory points: -3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[17.966354]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [ 1.  1.  0.  0. 11.  8. 25. 11.  0. 10. 29. 25.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 26. 30.  8.  0.  6.  5.  0.  5.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [10.  8.  0.  0.  0.] 
adversary cards in discard: [11.  3.  0.  0.  6.] 
adversary owned cards: [14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16 11  0
 29  0 10  0  0  0  0  0  0 16 29  3  0] -> size -> 37 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[-5  0  1 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 36 

action type: buy - action -1.0
Learning step: 2.1669957637786865
desired expected reward: 2.9119367599487305





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[17.355782]
 [18.967216]
 [16.660286]
 [18.438726]
 [15.420108]
 [18.085238]
 [19.787054]
 [20.900827]
 [18.358635]
 [16.025864]
 [16.940659]
 [18.01517 ]
 [14.518195]
 [17.347164]
 [20.768978]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [ 1.  1.  0.  0. 11.  8. 25. 11.  0. 10. 29. 25.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 9. 25. 30. 26. 30.  8.  0.  6.  5.  0.  5.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [10.  8.  0.  0.  0.] 
adversary cards in discard: [11.  3.  0.  0.  6.] 
adversary owned cards: [14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16 11  0
 29  0 10  0  0  0  0  0  0 16 29  3  0] -> size -> 37 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[-5  0  1 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 36 

action type: take_action - action -1.0
Learning step: 1.3312300443649292
desired expected reward: 19.297584533691406



buy possibilites: [-1] 
expected returns: [[32.56075]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [ 1.  1.  0.  0. 11.  8. 25. 11.  0. 10. 29. 25.  3. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10  1 25] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 25. 30. 26. 30.  8.  0.  6.  5.  0.  4.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [10.  8.  0.  0.  0.] 
adversary cards in discard: [11.  3.  0.  0.  6.] 
adversary owned cards: [14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16 11  0
 29  0 10  0  0  0  0  0  0 16 29  3  0] -> size -> 37 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[-5.   0.   1.  40.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
 12.5  0. ] 
sum of rewards: 48.5 

action type: buy - action 25.0
Learning step: 2.1125752925872803
desired expected reward: 23.013404846191406






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [10.  8.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0.  0.  0.] 
cards in discard: [11.  3.  0.  0.  6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [14  0  6  6  0  8  6  8  0  6  8  6  8  1  0 16  0 11  3 15 10 16 11  0
 29  0 10  0  0  0  0  0  0 16 29  3  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 26. 30.  8.  0.  6.  5.  0.  4.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [25.  0.  3.  6. 11.] 
adversary cards in discard: [ 1.  1.  0.  0. 11.  8. 25. 11.  0. 10. 29. 25.  3. 25.  0.  0.  1.  0.
  0.] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10  1 25] -> size -> 29 
adversary victory points: 1
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [11.  3.  0.  0.  6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  6  6  8  6  8  6  8  6  8  1  0 16  0 11  3 15 16 11  0 29  0 10  0
  0  0  0  0  0 16 29  3  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 26. 30.  8.  0.  6.  5.  0.  4.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [25.  0.  3.  6. 11.] 
adversary cards in discard: [ 1.  1.  0.  0. 11.  8. 25. 11.  0. 10. 29. 25.  3. 25.  0.  0.  1.  0.
  0.] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10  1 25] -> size -> 29 
adversary victory points: 1
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [11.  3.  0.  0.  6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  6  6  8  6  8  6  8  6  8  1  0 16  0 11  3 15 16 11  0 29  0 10  0
  0  0  0  0  0 16 29  3  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 25. 30. 26. 30.  8.  0.  6.  5.  0.  4.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [25.  0.  3.  6. 11.] 
adversary cards in discard: [ 1.  1.  0.  0. 11.  8. 25. 11.  0. 10. 29. 25.  3. 25.  0.  0.  1.  0.
  0.] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10  1 25] -> size -> 29 
adversary victory points: 1
player victory points: -3 





Player: 0 
cards in hand: [25.  0.  3.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[62.325916]
 [66.754745]
 [61.87894 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  3.  6. 11.] 
cards in discard: [ 1.  1.  0.  0. 11.  8. 25. 11.  0. 10. 29. 25.  3. 25.  0.  0.  1.  0.
  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10  1 25] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 26. 30.  8.  0.  6.  5.  0.  4.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  1. 15.  6.  0.] 
adversary cards in discard: [11.  3.  0.  0.  6.  8.] 
adversary owned cards: [14  6  6  8  6  8  6  8  6  8  1  0 16  0 11  3 15 16 11  0 29  0 10  0
  0  0  0  0  0 16 29  3  0] -> size -> 33 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[-5  0  1 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 36 

action type: buy - action -1
Learning step: 1.632690668106079
desired expected reward: 34.19343948364258



action possibilites: [-1] 
expected returns: [[23.43759]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  6. 11. 25. 29.] 
cards in discard: [ 1.  1.  0.  0. 11.  8. 25. 11.  0. 10. 29. 25.  3. 25.  0.  0.  1.  0.
  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10  1 25] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 26. 30.  8.  0.  6.  5.  0.  4.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  1. 15.  6.  0.] 
adversary cards in discard: [11.  3.  0.  0.  6.  8.] 
adversary owned cards: [14  6  6  8  6  8  6  8  6  8  1  0 16  0 11  3 15 16 11  0 29  0 10  0
  0  0  0  0  0 16 29  3  0] -> size -> 33 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[-5  0  1 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 56 

action type: take_action - action 25.0
Learning step: -0.029080582782626152
desired expected reward: 66.72566986083984





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[16.166023]
 [24.097218]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  6. 11. 25. 29.] 
cards in discard: [ 1.  1.  0.  0. 11.  8. 25. 11.  0. 10. 29. 25.  3. 25.  0.  0.  1.  0.
  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10  1 25] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 25. 30. 26. 30.  8.  0.  6.  5.  0.  4.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  1. 15.  6.  0.] 
adversary cards in discard: [11.  3.  0.  0.  6.  8.] 
adversary owned cards: [14  6  6  8  6  8  6  8  6  8  1  0 16  0 11  3 15 16 11  0 29  0 10  0
  0  0  0  0  0 16 29  3  0] -> size -> 33 
adversary victory points: -3
player victory points: 1 

Reward from previous game state: 
[-5  0  1 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 56 

action type: take_action - action -1
Learning step: 2.1175613403320312
desired expected reward: 25.555150985717773






         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [ 0.  1. 15.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 15.  6.  0.] 
cards in discard: [11.  3.  0.  0.  6.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [14  6  6  8  6  8  6  8  6  8  1  0 16  0 11  3 15 16 11  0 29  0 10  0
  0  0  0  0  0 16 29  3  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 26. 30.  8.  0.  6.  5.  0.  4.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [10.  0. 25.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10  1 25] -> size -> 29 
adversary victory points: 1
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 0.] 
cards in discard: [11.  3.  0.  0.  6.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [14  6  6  8  6  8  6  8  6  8  1 16  0 11  3 15 16 11  0 29  0 10  0  0
  0  0  0  0 16 29  3  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 9. 25. 30. 26. 30.  8.  0.  6.  5.  0.  4.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [10.  0. 25.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10  1 25] -> size -> 29 
adversary victory points: 1
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 0.] 
cards in discard: [11.  3.  0.  0.  6.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [14  6  6  8  6  8  6  8  6  8  1 16  0 11  3 15 16 11  0 29  0 10  0  0
  0  0  0  0 16 29  3  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 9. 25. 30. 26. 30.  8.  0.  6.  5.  0.  4.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [10.  0. 25.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10  1 25] -> size -> 29 
adversary victory points: 1
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 0.] 
cards in discard: [11.  3.  0.  0.  6.  8.  4.] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [14  6  6  8  6  8  6  8  6  8  1 16  0 11  3 15 16 11  0 29  0 10  0  0
  0  0  0  0 16 29  3  0  4] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 25. 30. 26. 29.  8.  0.  6.  5.  0.  4.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [10.  0. 25.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10  1 25] -> size -> 29 
adversary victory points: 1
player victory points: 0 





Player: 0 
cards in hand: [10.  0. 25.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.  8. 14.] 
expected returns: [[ -8.276097 ]
 [ -9.7975025]
 [ -7.092729 ]
 [ -9.427118 ]
 [-11.931681 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 25.  8. 14.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10  1 25] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 26. 29.  8.  0.  6.  5.  0.  4.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 8. 29.  0.  6.  0.] 
adversary cards in discard: [11.  3.  0.  0.  6.  8.  4. 15.  1.  6.  0.] 
adversary owned cards: [14  6  6  8  6  8  6  8  6  8  1 16  0 11  3 15 16 11  0 29  0 10  0  0
  0  0  0  0 16 29  3  0  4] -> size -> 33 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1.0
Learning step: -1.0938725471496582
desired expected reward: 23.00333595275879



action possibilites: [-1. 25.  8. 14.] 
expected returns: [[-11.309088]
 [-11.504637]
 [-11.874519]
 [-11.89135 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  8. 14.  1.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10  1 25] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 26. 29.  8.  0.  6.  5.  0.  4.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 8. 29.  0.  6.  0.] 
adversary cards in discard: [11.  3.  0.  0.  6.  8.  4. 15.  1.  6.  0.] 
adversary owned cards: [14  6  6  8  6  8  6  8  6  8  1 16  0 11  3 15 16 11  0 29  0 10  0  0
  0  0  0  0 16 29  3  0  4] -> size -> 33 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0 20  0  0  0  0  0  0  0  0  2] 
sum of rewards: 28 

action type: take_action - action 10.0
Learning step: 1.6309541463851929
desired expected reward: -8.166549682617188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-11.707909 ]
 [-11.217176 ]
 [-10.608387 ]
 [-10.979303 ]
 [-11.6353035]
 [-11.774881 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  8. 14.  1.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10  1 25] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 25. 30. 26. 29.  8.  0.  6.  5.  0.  4.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 8. 29.  0.  6.  0.] 
adversary cards in discard: [11.  3.  0.  0.  6.  8.  4. 15.  1.  6.  0.] 
adversary owned cards: [14  6  6  8  6  8  6  8  6  8  1 16  0 11  3 15 16 11  0 29  0 10  0  0
  0  0  0  0 16 29  3  0  4] -> size -> 33 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: take_action - action -1.0
Learning step: 1.6172943115234375
desired expected reward: -9.691798210144043






         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [ 8. 29.  0.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  0.  6.  0.] 
cards in discard: [11.  3.  0.  0.  6.  8.  4. 15.  1.  6.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [14  6  6  8  6  8  6  8  6  8  1 16  0 11  3 15 16 11  0 29  0 10  0  0
  0  0  0  0 16 29  3  0  4] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 26. 29.  8.  0.  6.  5.  0.  4.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [29.  0. 29.  0. 25.] 
adversary cards in discard: [10.  0. 25.  8. 14.  1.] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10  1 25] -> size -> 29 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.] 
cards in discard: [11.  3.  0.  0.  6.  8.  4. 15.  1.  6.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  6  8  6  8  6  8  6  8  1 16  0 11  3 15 16 11  0 29  0 10  0  0  0
  0  0  0 16 29  3  0  4] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 26. 29.  8.  0.  6.  5.  0.  4.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [29.  0. 29.  0. 25.] 
adversary cards in discard: [10.  0. 25.  8. 14.  1.] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10  1 25] -> size -> 29 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.] 
cards in discard: [11.  3.  0.  0.  6.  8.  4. 15.  1.  6.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  6  8  6  8  6  8  6  8  1 16  0 11  3 15 16 11  0 29  0 10  0  0  0
  0  0  0 16 29  3  0  4] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 25. 30. 26. 29.  8.  0.  6.  5.  0.  4.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [29.  0. 29.  0. 25.] 
adversary cards in discard: [10.  0. 25.  8. 14.  1.] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10  1 25] -> size -> 29 
adversary victory points: 1
player victory points: 1 





Player: 0 
cards in hand: [29.  0. 29.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 25.] 
expected returns: [[ 4.321857]
 [-3.108492]
 [-3.108492]
 [ 5.116552]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29.  0. 25.] 
cards in discard: [10.  0. 25.  8. 14.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10  1 25] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 26. 29.  8.  0.  6.  5.  0.  4.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [8. 8. 0. 6. 6.] 
adversary cards in discard: [11.  3.  0.  0.  6.  8.  4. 15.  1.  6.  0.  8. 29.  0.  0.] 
adversary owned cards: [14  6  8  6  8  6  8  6  8  1 16  0 11  3 15 16 11  0 29  0 10  0  0  0
  0  0  0 16 29  3  0  4] -> size -> 32 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1.0
Learning step: 0.44652366638183594
desired expected reward: -11.328363418579102



action possibilites: [-1] 
expected returns: [[-8.355625]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29.  0. 11. 25.] 
cards in discard: [10.  0. 25.  8. 14.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10  1 25] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 26. 29.  8.  0.  6.  5.  0.  4.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [8. 8. 0. 6. 6.] 
adversary cards in discard: [11.  3.  0.  0.  6.  8.  4. 15.  1.  6.  0.  8. 29.  0.  0.] 
adversary owned cards: [14  6  8  6  8  6  8  6  8  1 16  0 11  3 15 16 11  0 29  0 10  0  0  0
  0  0  0 16 29  3  0  4] -> size -> 32 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: take_action - action 25.0
Learning step: 0.3561711013317108
desired expected reward: 5.472718238830566





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-19.007492]
 [-11.888651]
 [ -8.172054]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 29.  0. 11. 25.] 
cards in discard: [10.  0. 25.  8. 14.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10  1 25] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 25. 30. 26. 29.  8.  0.  6.  5.  0.  4.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [8. 8. 0. 6. 6.] 
adversary cards in discard: [11.  3.  0.  0.  6.  8.  4. 15.  1.  6.  0.  8. 29.  0.  0.] 
adversary owned cards: [14  6  8  6  8  6  8  6  8  1 16  0 11  3 15 16 11  0 29  0 10  0  0  0
  0  0  0 16 29  3  0  4] -> size -> 32 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: take_action - action -1
Learning step: 0.9693912863731384
desired expected reward: -7.386233806610107



buy possibilites: [-1] 
expected returns: [[-19.16788]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 29.  0. 11. 25.] 
cards in discard: [10.  0. 25.  8. 14.  1.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10  1 25  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 25. 29.  8.  0.  6.  5.  0.  4.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [8. 8. 0. 6. 6.] 
adversary cards in discard: [11.  3.  0.  0.  6.  8.  4. 15.  1.  6.  0.  8. 29.  0.  0.] 
adversary owned cards: [14  6  8  6  8  6  8  6  8  1 16  0 11  3 15 16 11  0 29  0 10  0  0  0
  0  0  0 16 29  3  0  4] -> size -> 32 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 35 

action type: buy - action 3.0
Learning step: 1.913155436515808
desired expected reward: -9.975497245788574






         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [8. 8. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 6. 6.] 
cards in discard: [11.  3.  0.  0.  6.  8.  4. 15.  1.  6.  0.  8. 29.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [14  6  8  6  8  6  8  6  8  1 16  0 11  3 15 16 11  0 29  0 10  0  0  0
  0  0  0 16 29  3  0  4] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 25. 29.  8.  0.  6.  5.  0.  4.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [25.  0.  8. 25.  0.] 
adversary cards in discard: [10.  0. 25.  8. 14.  1.  3. 25. 29.  0. 29.  0. 11. 25.] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10  1 25  3] -> size -> 30 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0. 6. 6.] 
cards in discard: [11.  3.  0.  0.  6.  8.  4. 15.  1.  6.  0.  8. 29.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [14  6  8  6  8  6  8  6  8  1 16  0 11  3 15 16 11  0 29  0 10  0  0  0
  0  0  0 16 29  3  0  4] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 25. 30. 25. 29.  8.  0.  6.  5.  0.  4.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [25.  0.  8. 25.  0.] 
adversary cards in discard: [10.  0. 25.  8. 14.  1.  3. 25. 29.  0. 29.  0. 11. 25.] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10  1 25  3] -> size -> 30 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0. 6. 6.] 
cards in discard: [11.  3.  0.  0.  6.  8.  4. 15.  1.  6.  0.  8. 29.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [14  6  8  6  8  6  8  6  8  1 16  0 11  3 15 16 11  0 29  0 10  0  0  0
  0  0  0 16 29  3  0  4  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 25. 30. 25. 29.  8.  0.  6.  5.  0.  4.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [25.  0.  8. 25.  0.] 
adversary cards in discard: [10.  0. 25.  8. 14.  1.  3. 25. 29.  0. 29.  0. 11. 25.] 
adversary owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10  1 25  3] -> size -> 30 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [25.  0.  8. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8. 25.] 
expected returns: [[27.286451]
 [27.55443 ]
 [21.80949 ]
 [27.55443 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  8. 25.  0.] 
cards in discard: [10.  0. 25.  8. 14.  1.  3. 25. 29.  0. 29.  0. 11. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25
  0 25 10  1 25  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 25. 29.  8.  0.  6.  5.  0.  4.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  0. 14.] 
adversary cards in discard: [11.  3.  0.  0.  6.  8.  4. 15.  1.  6.  0.  8. 29.  0.  0.  0.  8.  8.
  0.  6.  6.] 
adversary owned cards: [14  6  8  6  8  6  8  6  8  1 16  0 11  3 15 16 11  0 29  0 10  0  0  0
  0  0  0 16 29  3  0  4  0] -> size -> 33 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1
Learning step: 1.9083741903305054
desired expected reward: -17.259504318237305



action possibilites: [-1] 
expected returns: [[45.529114]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.] 
cards in discard: [10.  0. 25.  8. 14.  1.  3. 25. 29.  0. 29.  0. 11. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25  0 25
 10  1 25  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 25. 29.  8.  0.  6.  5.  0.  4.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  0. 14.] 
adversary cards in discard: [11.  3.  0.  0.  6.  8.  4. 15.  1.  6.  0.  8. 29.  0.  0.  0.  8.  8.
  0.  6.  6.] 
adversary owned cards: [14  6  8  6  8  6  8  6  8  1 16  0 11  3 15 16 11  0 29  0 10  0  0  0
  0  0  0 16 29  3  0  4  0] -> size -> 33 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: trash_cards_n_from_hand - action 2
Learning step: 1.3733381032943726
desired expected reward: 21.39467430114746





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[33.93634]
 [45.07566]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.] 
cards in discard: [10.  0. 25.  8. 14.  1.  3. 25. 29.  0. 29.  0. 11. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25  0 25
 10  1 25  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 25. 30. 25. 29.  8.  0.  6.  5.  0.  4.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  0. 14.] 
adversary cards in discard: [11.  3.  0.  0.  6.  8.  4. 15.  1.  6.  0.  8. 29.  0.  0.  0.  8.  8.
  0.  6.  6.] 
adversary owned cards: [14  6  8  6  8  6  8  6  8  1 16  0 11  3 15 16 11  0 29  0 10  0  0  0
  0  0  0 16 29  3  0  4  0] -> size -> 33 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: take_action - action -1
Learning step: 0.013664627447724342
desired expected reward: 45.54277801513672






         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [ 0. 29.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0. 14.] 
cards in discard: [11.  3.  0.  0.  6.  8.  4. 15.  1.  6.  0.  8. 29.  0.  0.  0.  8.  8.
  0.  6.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [14  6  8  6  8  6  8  6  8  1 16  0 11  3 15 16 11  0 29  0 10  0  0  0
  0  0  0 16 29  3  0  4  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 25. 29.  8.  0.  6.  5.  0.  4.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 3. 25.  0.  3. 11.] 
adversary cards in discard: [10.  0. 25.  8. 14.  1.  3. 25. 29.  0. 29.  0. 11. 25.  8. 25.  0.] 
adversary owned cards: [ 0  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25  0 25
 10  1 25  3] -> size -> 28 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  0. 14.] 
cards in discard: [11.  3.  0.  0.  6.  8.  4. 15.  1.  6.  0.  8. 29.  0.  0.  0.  8.  8.
  0.  6.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [14  6  8  6  8  6  8  6  8  1 16  0 11  3 15 16 11  0 29  0 10  0  0  0
  0  0  0 16 29  3  0  4  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 25. 30. 25. 29.  8.  0.  6.  5.  0.  4.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 3. 25.  0.  3. 11.] 
adversary cards in discard: [10.  0. 25.  8. 14.  1.  3. 25. 29.  0. 29.  0. 11. 25.  8. 25.  0.] 
adversary owned cards: [ 0  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25  0 25
 10  1 25  3] -> size -> 28 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  0. 14.] 
cards in discard: [11.  3.  0.  0.  6.  8.  4. 15.  1.  6.  0.  8. 29.  0.  0.  0.  8.  8.
  0.  6.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [14  6  8  6  8  6  8  6  8  1 16  0 11  3 15 16 11  0 29  0 10  0  0  0
  0  0  0 16 29  3  0  4  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 7. 25. 30. 25. 29.  8.  0.  6.  5.  0.  4.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 3. 25.  0.  3. 11.] 
adversary cards in discard: [10.  0. 25.  8. 14.  1.  3. 25. 29.  0. 29.  0. 11. 25.  8. 25.  0.] 
adversary owned cards: [ 0  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25  0 25
 10  1 25  3] -> size -> 28 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [ 3. 25.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[-27.944418]
 [-26.64045 ]
 [-28.316494]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  0.  3. 11.] 
cards in discard: [10.  0. 25.  8. 14.  1.  3. 25. 29.  0. 29.  0. 11. 25.  8. 25.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25  0 25
 10  1 25  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30. 25. 29.  8.  0.  6.  5.  0.  4.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [10. 16. 16.  3.  0.] 
adversary cards in discard: [11.  3.  0.  0.  6.  8.  4. 15.  1.  6.  0.  8. 29.  0.  0.  0.  8.  8.
  0.  6.  6.  0.  0. 29.  0.  0. 14.] 
adversary owned cards: [14  6  8  6  8  6  8  6  8  1 16  0 11  3 15 16 11  0 29  0 10  0  0  0
  0  0  0 16 29  3  0  4  0  0] -> size -> 34 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1.0
Learning step: -2.5164058208465576
desired expected reward: 42.55925750732422



action possibilites: [-1] 
expected returns: [[3.9425244]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 11.  0.  1.] 
cards in discard: [10.  0. 25.  8. 14.  1.  3. 25. 29.  0. 29.  0. 11. 25.  8. 25.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25  0 25
 10  1 25  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30. 25. 29.  8.  0.  6.  5.  0.  4.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [10. 16. 16.  3.  0.] 
adversary cards in discard: [11.  3.  0.  0.  6.  8.  4. 15.  1.  6.  0.  8. 29.  0.  0.  0.  8.  8.
  0.  6.  6.  0.  0. 29.  0.  0. 14.] 
adversary owned cards: [14  6  8  6  8  6  8  6  8  1 16  0 11  3 15 16 11  0 29  0 10  0  0  0
  0  0  0 16 29  3  0  4  0  0] -> size -> 34 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  3] 
sum of rewards: 30 

action type: take_action - action 25.0
Learning step: 2.9207303524017334
desired expected reward: -23.719736099243164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[-10.914719 ]
 [ -0.9801421]
 [ -3.3364992]
 [ -6.8933363]
 [  3.2315369]
 [ -5.6317024]
 [-15.270882 ]
 [ -7.6482472]
 [-10.833815 ]
 [  4.8736672]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 11.  0.  1.] 
cards in discard: [10.  0. 25.  8. 14.  1.  3. 25. 29.  0. 29.  0. 11. 25.  8. 25.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25  0 25
 10  1 25  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 7. 25. 30. 25. 29.  8.  0.  6.  5.  0.  4.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [10. 16. 16.  3.  0.] 
adversary cards in discard: [11.  3.  0.  0.  6.  8.  4. 15.  1.  6.  0.  8. 29.  0.  0.  0.  8.  8.
  0.  6.  6.  0.  0. 29.  0.  0. 14.] 
adversary owned cards: [14  6  8  6  8  6  8  6  8  1 16  0 11  3 15 16 11  0 29  0 10  0  0  0
  0  0  0 16 29  3  0  4  0  0] -> size -> 34 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: take_action - action -1
Learning step: 1.1266740560531616
desired expected reward: 5.0691986083984375






         -------------------- Turn: 55 -------------------- 
Player: 1 
cards in hand: [10. 16. 16.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 16. 16.  3.  0.] 
cards in discard: [11.  3.  0.  0.  6.  8.  4. 15.  1.  6.  0.  8. 29.  0.  0.  0.  8.  8.
  0.  6.  6.  0.  0. 29.  0.  0. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [14  6  8  6  8  6  8  6  8  1 16  0 11  3 15 16 11  0 29  0 10  0  0  0
  0  0  0 16 29  3  0  4  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30. 25. 29.  8.  0.  6.  5.  0.  4.  5.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  1.  0. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25  0 25
 10  1 25  3] -> size -> 28 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  0.] 
cards in discard: [11.  3.  0.  0.  6.  8.  4. 15.  1.  6.  0.  8. 29.  0.  0.  0.  8.  8.
  0.  6.  6.  0.  0. 29.  0.  0. 14. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [14  6  8  6  8  6  8  6  8  1 16  0 11  3 15 16 11  0 29  0  0  0  0  0
  0  0 16 29  3  0  4  0  0 10] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30. 25. 29.  8.  0.  6.  5.  0.  4.  5.  8. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  1.  0. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25  0 25
 10  1 25  3] -> size -> 28 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  0.] 
cards in discard: [11.  3.  0.  0.  6.  8.  4. 15.  1.  6.  0.  8. 29.  0.  0.  0.  8.  8.
  0.  6.  6.  0.  0. 29.  0.  0. 14. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [14  6  8  6  8  6  8  6  8  1 16  0 11  3 15 16 11  0 29  0  0  0  0  0
  0  0 16 29  3  0  4  0  0 10] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 25. 30. 25. 29.  8.  0.  6.  5.  0.  4.  5.  8. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  1.  0. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25  0 25
 10  1 25  3] -> size -> 28 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  0.] 
cards in discard: [11.  3.  0.  0.  6.  8.  4. 15.  1.  6.  0.  8. 29.  0.  0.  0.  8.  8.
  0.  6.  6.  0.  0. 29.  0.  0. 14. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [14  6  8  6  8  6  8  6  8  1 16  0 11  3 15 16 11  0 29  0  0  0  0  0
  0  0 16 29  3  0  4  0  0 10  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 25. 30. 25. 29.  8.  0.  6.  5.  0.  4.  5.  8. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  1.  0. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25  0 25
 10  1 25  3] -> size -> 28 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [ 0.  1.  0. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[6.244806 ]
 [4.0505996]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0. 11.  6.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25  0 25
 10  1 25  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 25. 29.  8.  0.  6.  5.  0.  4.  5.  8. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  3. 15. 16. 11.] 
adversary cards in discard: [] 
adversary owned cards: [14  6  8  6  8  6  8  6  8  1 16  0 11  3 15 16 11  0 29  0  0  0  0  0
  0  0 16 29  3  0  4  0  0 10  0] -> size -> 35 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1.0
Learning step: 0.2322322577238083
desired expected reward: 5.105898380279541



action possibilites: [-1] 
expected returns: [[31.922709]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 6.] 
cards in discard: [11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25  0 25
 10  1 25  3 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 25. 29.  8.  0.  6.  4.  0.  4.  5.  8. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  3. 15. 16. 11.] 
adversary cards in discard: [] 
adversary owned cards: [14  6  8  6  8  6  8  6  8  1 16  0 11  3 15 16 11  0 29  0  0  0  0  0
  0  0 16 29  3  0  4  0  0 10  0] -> size -> 35 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 36 

action type: gain_card_n - action 4
Learning step: 3.2951416969299316
desired expected reward: -12.242471694946289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[24.177393]
 [28.725088]
 [27.73671 ]
 [26.102777]
 [30.710161]
 [26.667547]
 [20.293139]
 [25.873817]
 [24.21138 ]
 [31.552637]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 6.] 
cards in discard: [11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25  0 25
 10  1 25  3 11] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 6. 25. 30. 25. 29.  8.  0.  6.  4.  0.  4.  5.  8. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  3. 15. 16. 11.] 
adversary cards in discard: [] 
adversary owned cards: [14  6  8  6  8  6  8  6  8  1 16  0 11  3 15 16 11  0 29  0  0  0  0  0
  0  0 16 29  3  0  4  0  0 10  0] -> size -> 35 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: take_action - action -1
Learning step: 0.39799126982688904
desired expected reward: 32.320701599121094



buy possibilites: [-1] 
expected returns: [[-17.345528]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 6.] 
cards in discard: [11.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25  0 25
 10  1 25  3 11  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 5. 25. 30. 25. 29.  8.  0.  6.  4.  0.  4.  5.  8. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  3. 15. 16. 11.] 
adversary cards in discard: [] 
adversary owned cards: [14  6  8  6  8  6  8  6  8  1 16  0 11  3 15 16 11  0 29  0  0  0  0  0
  0  0 16 29  3  0  4  0  0 10  0] -> size -> 35 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2.  10.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -3.0 

action type: buy - action 0.0
Learning step: -1.7491438388824463
desired expected reward: 22.428245544433594






         -------------------- Turn: 56 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 15. 16. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16. 11.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15. 16. 11.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [14  6  8  6  8  6  8  6  8  1 16  0 11  3 15 16 11  0 29  0  0  0  0  0
  0  0 16 29  3  0  4  0  0 10  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 25. 30. 25. 29.  8.  0.  6.  4.  0.  4.  5.  8. 10.  4. 10.  9.] 
adversary cards in hand: [29.  3. 29. 25.  1.] 
adversary cards in discard: [11.  0. 11.  0.  1.  0.  6.] 
adversary owned cards: [ 0  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25  0 25
 10  1 25  3 11  0] -> size -> 30 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 11.] 
cards in discard: [16.] 
cards in deck: 30 
card top of deck: [] 
played cards: [16.] 
owned cards: [14  6  8  6  8  6  8  6  8  1 16  0 11 15 16 11  0 29  0  0  0  0  0  0
  0 16 29  3  0  4  0  0 10  0 16] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 25. 30. 25. 29.  8.  0.  5.  4.  0.  4.  5.  8. 10.  4. 10.  9.] 
adversary cards in hand: [29.  3. 29. 25.  1.] 
adversary cards in discard: [11.  0. 11.  0.  1.  0.  6.] 
adversary owned cards: [ 0  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25  0 25
 10  1 25  3 11  0] -> size -> 30 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 11.] 
cards in discard: [16.] 
cards in deck: 30 
card top of deck: [] 
played cards: [16.] 
owned cards: [14  6  8  6  8  6  8  6  8  1 16  0 11 15 16 11  0 29  0  0  0  0  0  0
  0 16 29  3  0  4  0  0 10  0 16] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 25. 30. 25. 29.  8.  0.  5.  4.  0.  4.  5.  8. 10.  4. 10.  9.] 
adversary cards in hand: [29.  3. 29. 25.  1.] 
adversary cards in discard: [11.  0. 11.  0.  1.  0.  6.] 
adversary owned cards: [ 0  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25  0 25
 10  1 25  3 11  0] -> size -> 30 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 11.] 
cards in discard: [16.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [16.] 
owned cards: [14  6  8  6  8  6  8  6  8  1 16  0 11 15 16 11  0 29  0  0  0  0  0  0
  0 16 29  3  0  4  0  0 10  0 16  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 25. 30. 25. 29.  8.  0.  5.  4.  0.  4.  5.  8. 10.  4. 10.  9.] 
adversary cards in hand: [29.  3. 29. 25.  1.] 
adversary cards in discard: [11.  0. 11.  0.  1.  0.  6.] 
adversary owned cards: [ 0  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25  0 25
 10  1 25  3 11  0] -> size -> 30 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [29.  3. 29. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 25.] 
expected returns: [[94.64181]
 [88.15978]
 [88.15978]
 [98.56155]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 29. 25.  1.] 
cards in discard: [11.  0. 11.  0.  1.  0.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25  0 25
 10  1 25  3 11  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 25. 29.  8.  0.  5.  4.  0.  4.  5.  8. 10.  4. 10.  9.] 
adversary cards in hand: [6. 0. 0. 8. 6.] 
adversary cards in discard: [16.  0. 16.  0. 15. 11.] 
adversary owned cards: [14  6  8  6  8  6  8  6  8  1 16  0 11 15 16 11  0 29  0  0  0  0  0  0
  0 16 29  3  0  4  0  0 10  0 16  0] -> size -> 36 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1
Learning step: 3.8526999950408936
desired expected reward: -13.492827415466309



action possibilites: [-1] 
expected returns: [[58.617435]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 29.  1.  0. 25.] 
cards in discard: [11.  0. 11.  0.  1.  0.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25  0 25
 10  1 25  3 11  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 25. 29.  8.  0.  5.  4.  0.  4.  5.  8. 10.  4. 10.  9.] 
adversary cards in hand: [6. 0. 0. 8. 6.] 
adversary cards in discard: [16.  0. 16.  0. 15. 11.] 
adversary owned cards: [14  6  8  6  8  6  8  6  8  1 16  0 11 15 16 11  0 29  0  0  0  0  0  0
  0 16 29  3  0  4  0  0 10  0 16  0] -> size -> 36 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 38 

action type: take_action - action 25.0
Learning step: -1.7091854810714722
desired expected reward: 96.85237121582031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[43.281685]
 [51.09519 ]
 [49.5234  ]
 [54.84971 ]
 [47.241737]
 [57.411114]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3. 29.  1.  0. 25.] 
cards in discard: [11.  0. 11.  0.  1.  0.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25  0 25
 10  1 25  3 11  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 25. 30. 25. 29.  8.  0.  5.  4.  0.  4.  5.  8. 10.  4. 10.  9.] 
adversary cards in hand: [6. 0. 0. 8. 6.] 
adversary cards in discard: [16.  0. 16.  0. 15. 11.] 
adversary owned cards: [14  6  8  6  8  6  8  6  8  1 16  0 11 15 16 11  0 29  0  0  0  0  0  0
  0 16 29  3  0  4  0  0 10  0 16  0] -> size -> 36 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: take_action - action -1
Learning step: 0.11984653770923615
desired expected reward: 58.737281799316406



buy possibilites: [-1] 
expected returns: [[26.080282]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3. 29.  1.  0. 25.] 
cards in discard: [11.  0. 11.  0.  1.  0.  6.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25  0 25
 10  1 25  3 11  0  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 25. 29.  8.  0.  5.  4.  0.  4.  5.  8. 10.  4. 10.  9.] 
adversary cards in hand: [6. 0. 0. 8. 6.] 
adversary cards in discard: [16.  0. 16.  0. 15. 11.] 
adversary owned cards: [14  6  8  6  8  6  8  6  8  1 16  0 11 15 16 11  0 29  0  0  0  0  0  0
  0 16 29  3  0  4  0  0 10  0 16  0] -> size -> 36 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 55 

action type: buy - action 1.0
Learning step: 0.7820455431938171
desired expected reward: 51.87726593017578






         -------------------- Turn: 57 -------------------- 
Player: 1 
cards in hand: [6. 0. 0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 8. 6.] 
cards in discard: [16.  0. 16.  0. 15. 11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [14  6  8  6  8  6  8  6  8  1 16  0 11 15 16 11  0 29  0  0  0  0  0  0
  0 16 29  3  0  4  0  0 10  0 16  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 25. 29.  8.  0.  5.  4.  0.  4.  5.  8. 10.  4. 10.  9.] 
adversary cards in hand: [25. 25.  0.  1.  0.] 
adversary cards in discard: [11.  0. 11.  0.  1.  0.  6.  1. 25. 29.  3. 29.  1.  0. 25.] 
adversary owned cards: [ 0  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25  0 25
 10  1 25  3 11  0  1] -> size -> 31 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6.] 
cards in discard: [16.  0. 16.  0. 15. 11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11  0 29  0  0  0  0  0  0  0 16
 29  3  0  4  0  0 10  0 16  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 25. 29.  8.  0.  5.  4.  0.  4.  5.  8. 10.  4. 10.  9.] 
adversary cards in hand: [25. 25.  0.  1.  0.] 
adversary cards in discard: [11.  0. 11.  0.  1.  0.  6.  1. 25. 29.  3. 29.  1.  0. 25.] 
adversary owned cards: [ 0  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25  0 25
 10  1 25  3 11  0  1] -> size -> 31 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [16.  0. 16.  0. 15. 11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11  0 29  0  0  0  0  0  0  0 16
 29  3  0  4  0  0 10  0 16  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 24. 30. 25. 29.  8.  0.  5.  4.  0.  4.  5.  8. 10.  4. 10.  9.] 
adversary cards in hand: [25. 25.  0.  1.  0.] 
adversary cards in discard: [11.  0. 11.  0.  1.  0.  6.  1. 25. 29.  3. 29.  1.  0. 25.] 
adversary owned cards: [ 0  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25  0 25
 10  1 25  3 11  0  1] -> size -> 31 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [16.  0. 16.  0. 15. 11.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11  0 29  0  0  0  0  0  0  0 16
 29  3  0  4  0  0 10  0 16  0  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 24. 30. 25. 29.  8.  0.  5.  4.  0.  4.  5.  8. 10.  4. 10.  9.] 
adversary cards in hand: [25. 25.  0.  1.  0.] 
adversary cards in discard: [11.  0. 11.  0.  1.  0.  6.  1. 25. 29.  3. 29.  1.  0. 25.] 
adversary owned cards: [ 0  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25  0 25
 10  1 25  3 11  0  1] -> size -> 31 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [25. 25.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[63.691578]
 [67.53972 ]
 [67.53972 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25.  0.  1.  0.] 
cards in discard: [11.  0. 11.  0.  1.  0.  6.  1. 25. 29.  3. 29.  1.  0. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25  0 25
 10  1 25  3 11  0  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 24. 30. 25. 29.  8.  0.  5.  4.  0.  4.  5.  8. 10.  4. 10.  9.] 
adversary cards in hand: [29.  8.  3.  8. 14.] 
adversary cards in discard: [16.  0. 16.  0. 15. 11.  0.  8.  0.  6.] 
adversary owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11  0 29  0  0  0  0  0  0  0 16
 29  3  0  4  0  0 10  0 16  0  0] -> size -> 35 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1
Learning step: 0.5485682487487793
desired expected reward: 26.62885093688965



action possibilites: [-1] 
expected returns: [[9.522413]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  1.  0. 14. 25.] 
cards in discard: [11.  0. 11.  0.  1.  0.  6.  1. 25. 29.  3. 29.  1.  0. 25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25  0 25
 10  1 25  3 11  0  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 24. 30. 25. 29.  8.  0.  5.  4.  0.  4.  5.  8. 10.  4. 10.  9.] 
adversary cards in hand: [29.  8.  3.  8. 14.] 
adversary cards in discard: [16.  0. 16.  0. 15. 11.  0.  8.  0.  6.] 
adversary owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11  0 29  0  0  0  0  0  0  0 16
 29  3  0  4  0  0 10  0 16  0  0] -> size -> 35 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: take_action - action 25.0
Learning step: -1.812731146812439
desired expected reward: 65.72698211669922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[ 6.250011 ]
 [ 7.9187207]
 [ 8.046272 ]
 [ 6.9243903]
 [ 9.161217 ]
 [ 6.992993 ]
 [ 5.4622216]
 [ 7.1991305]
 [ 6.7287354]
 [10.220474 ]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  1.  0. 14. 25.] 
cards in discard: [11.  0. 11.  0.  1.  0.  6.  1. 25. 29.  3. 29.  1.  0. 25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25  0 25
 10  1 25  3 11  0  1] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 3. 24. 30. 25. 29.  8.  0.  5.  4.  0.  4.  5.  8. 10.  4. 10.  9.] 
adversary cards in hand: [29.  8.  3.  8. 14.] 
adversary cards in discard: [16.  0. 16.  0. 15. 11.  0.  8.  0.  6.] 
adversary owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11  0 29  0  0  0  0  0  0  0 16
 29  3  0  4  0  0 10  0 16  0  0] -> size -> 35 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: take_action - action -1
Learning step: 1.0675276517868042
desired expected reward: 10.589941024780273



buy possibilites: [-1] 
expected returns: [[-2.2600296]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  1.  0. 14. 25.] 
cards in discard: [11.  0. 11.  0.  1.  0.  6.  1. 25. 29.  3. 29.  1.  0. 25. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25  0 25
 10  1 25  3 11  0  1 14] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 24. 30. 25. 29.  8.  0.  5.  4.  0.  4.  5.  7. 10.  4. 10.  9.] 
adversary cards in hand: [29.  8.  3.  8. 14.] 
adversary cards in discard: [16.  0. 16.  0. 15. 11.  0.  8.  0.  6.] 
adversary owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11  0 29  0  0  0  0  0  0  0 16
 29  3  0  4  0  0 10  0 16  0  0] -> size -> 35 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0 32  0] 
sum of rewards: 59 

action type: buy - action 14.0
Learning step: 2.6260383129119873
desired expected reward: 8.088258743286133






         -------------------- Turn: 58 -------------------- 
Player: 1 
cards in hand: [29.  8.  3.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  3.  8. 14.] 
cards in discard: [16.  0. 16.  0. 15. 11.  0.  8.  0.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11  0 29  0  0  0  0  0  0  0 16
 29  3  0  4  0  0 10  0 16  0  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 24. 30. 25. 29.  8.  0.  5.  4.  0.  4.  5.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 3. 11. 10.  0.  8.] 
adversary cards in discard: [11.  0. 11.  0.  1.  0.  6.  1. 25. 29.  3. 29.  1.  0. 25. 14. 25. 25.
  0.  1.  0. 14. 25.] 
adversary owned cards: [ 0  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25  0 25
 10  1 25  3 11  0  1 14] -> size -> 32 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8.  3.  8. 14.] 
cards in discard: [16.  0. 16.  0. 15. 11.  0.  8.  0.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11  0 29  0  0  0  0  0  0  0 16
 29  3  0  4  0  0 10  0 16  0  0] -> size -> 35 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 3. 24. 30. 25. 29.  8.  0.  5.  4.  0.  4.  5.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 3. 11. 10.  0.  8.] 
adversary cards in discard: [11.  0. 11.  0.  1.  0.  6.  1. 25. 29.  3. 29.  1.  0. 25. 14. 25. 25.
  0.  1.  0. 14. 25.] 
adversary owned cards: [ 0  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25  0 25
 10  1 25  3 11  0  1 14] -> size -> 32 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8.  3.  8. 14.] 
cards in discard: [16.  0. 16.  0. 15. 11.  0.  8.  0.  6.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11  0 29  0  0  0  0  0  0  0 16
 29  3  0  4  0  0 10  0 16  0  0  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 24. 30. 25. 29.  8.  0.  5.  4.  0.  4.  5.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 3. 11. 10.  0.  8.] 
adversary cards in discard: [11.  0. 11.  0.  1.  0.  6.  1. 25. 29.  3. 29.  1.  0. 25. 14. 25. 25.
  0.  1.  0. 14. 25.] 
adversary owned cards: [ 0  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25  0 25
 10  1 25  3 11  0  1 14] -> size -> 32 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [ 3. 11. 10.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8.] 
expected returns: [[-21.31899 ]
 [-24.22045 ]
 [-34.169197]
 [-34.144432]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10.  0.  8.] 
cards in discard: [11.  0. 11.  0.  1.  0.  6.  1. 25. 29.  3. 29.  1.  0. 25. 14. 25. 25.
  0.  1.  0. 14. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25  0 25
 10  1 25  3 11  0  1 14] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 24. 30. 25. 29.  8.  0.  5.  4.  0.  4.  5.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [16.  0. 16.  0. 15. 11.  0.  8.  0.  6.  0. 29.  8.  3.  8. 14.] 
adversary owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11  0 29  0  0  0  0  0  0  0 16
 29  3  0  4  0  0 10  0 16  0  0  0] -> size -> 36 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1
Learning step: -0.11170168966054916
desired expected reward: -2.3717312812805176





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-39.41132 ]
 [-23.361628]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 10.  0.  8.] 
cards in discard: [11.  0. 11.  0.  1.  0.  6.  1. 25. 29.  3. 29.  1.  0. 25. 14. 25. 25.
  0.  1.  0. 14. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25  0 25
 10  1 25  3 11  0  1 14] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 24. 30. 25. 29.  8.  0.  5.  4.  0.  4.  5.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [16.  0. 16.  0. 15. 11.  0.  8.  0.  6.  0. 29.  8.  3.  8. 14.] 
adversary owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11  0 29  0  0  0  0  0  0  0 16
 29  3  0  4  0  0 10  0 16  0  0  0] -> size -> 36 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: take_action - action -1.0
Learning step: 0.7835747599601746
desired expected reward: -20.535417556762695



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 59 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  0.] 
cards in discard: [16.  0. 16.  0. 15. 11.  0.  8.  0.  6.  0. 29.  8.  3.  8. 14.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11  0 29  0  0  0  0  0  0  0 16
 29  3  0  4  0  0 10  0 16  0  0  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 24. 30. 25. 29.  8.  0.  5.  4.  0.  4.  5.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25  0 25
 10  1 25  3 11  0  1 14] -> size -> 32 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.  0.] 
cards in discard: [16.  0. 16.  0. 15. 11.  0.  8.  0.  6.  0. 29.  8.  3.  8. 14.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11  0 29  0  0  0  0  0  0  0 16
 29  3  0  4  0  0 10  0 16  0  0  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 2. 24. 30. 25. 29.  8.  0.  5.  4.  0.  4.  5.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25  0 25
 10  1 25  3 11  0  1 14] -> size -> 32 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.  0.] 
cards in discard: [16.  0. 16.  0. 15. 11.  0.  8.  0.  6.  0. 29.  8.  3.  8. 14.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11  0 29  0  0  0  0  0  0  0 16
 29  3  0  4  0  0 10  0 16  0  0  0  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 2. 24. 30. 24. 29.  8.  0.  5.  4.  0.  4.  5.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25  0 25
 10  1 25  3 11  0  1 14] -> size -> 32 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [ 0.  0. 11.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[-16.130531]
 [-15.562643]
 [-15.503756]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.  8.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  6 25  0  1  8 25  0 14  3  0  3  8 29 29  0 11  0 11 11  1 25  0 25
 10  1 25  3 11  0  1 14] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 24. 30. 24. 29.  8.  0.  5.  4.  0.  4.  5.  7. 10.  4. 10.  9.] 
adversary cards in hand: [16.  6.  6.  0.  0.] 
adversary cards in discard: [16.  0. 16.  0. 15. 11.  0.  8.  0.  6.  0. 29.  8.  3.  8. 14.  3.  0.
 11.  0.  0.  0.] 
adversary owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11  0 29  0  0  0  0  0  0  0 16
 29  3  0  4  0  0 10  0 16  0  0  0  3] -> size -> 37 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1.0
Learning step: 0.6662070155143738
desired expected reward: -22.695425033569336



action possibilites: [-1] 
expected returns: [[0.50852394]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 6 25  0  1  8 25  0 14  3  0  3  8 29 29  0  0 11 11  1 25  0 25 10  1
 25  3 11  0  1 14] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 24. 30. 24. 29.  8.  0.  5.  4.  0.  4.  5.  7. 10.  4. 10.  9.] 
adversary cards in hand: [16.  6.  6.  0.  0.] 
adversary cards in discard: [16.  0. 16.  0. 15. 11.  0.  8.  0.  6.  0. 29.  8.  3.  8. 14.  3.  0.
 11.  0.  0.  0.] 
adversary owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11  0 29  0  0  0  0  0  0  0 16
 29  3  0  4  0  0 10  0 16  0  0  0  3] -> size -> 37 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: trash_cards_n_from_hand - action 5
Learning step: 1.4463189840316772
desired expected reward: -10.25122356414795





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-5.3405805]
 [ 2.4232674]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 6 25  0  1  8 25  0 14  3  0  3  8 29 29  0  0 11 11  1 25  0 25 10  1
 25  3 11  0  1 14] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 24. 30. 24. 29.  8.  0.  5.  4.  0.  4.  5.  7. 10.  4. 10.  9.] 
adversary cards in hand: [16.  6.  6.  0.  0.] 
adversary cards in discard: [16.  0. 16.  0. 15. 11.  0.  8.  0.  6.  0. 29.  8.  3.  8. 14.  3.  0.
 11.  0.  0.  0.] 
adversary owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11  0 29  0  0  0  0  0  0  0 16
 29  3  0  4  0  0 10  0 16  0  0  0  3] -> size -> 37 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1
Learning step: 0.8274639248847961
desired expected reward: 1.3359878063201904






         -------------------- Turn: 60 -------------------- 
Player: 1 
cards in hand: [16.  6.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6.  6.  0.  0.] 
cards in discard: [16.  0. 16.  0. 15. 11.  0.  8.  0.  6.  0. 29.  8.  3.  8. 14.  3.  0.
 11.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11  0 29  0  0  0  0  0  0  0 16
 29  3  0  4  0  0 10  0 16  0  0  0  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 24. 30. 24. 29.  8.  0.  5.  4.  0.  4.  5.  7. 10.  4. 10.  9.] 
adversary cards in hand: [11. 14. 11. 25.  1.] 
adversary cards in discard: [8. 0. 3.] 
adversary owned cards: [ 6 25  0  1  8 25  0 14  3  0  3  8 29 29  0  0 11 11  1 25  0 25 10  1
 25  3 11  0  1 14] -> size -> 30 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0.] 
cards in discard: [16.  0. 16.  0. 15. 11.  0.  8.  0.  6.  0. 29.  8.  3.  8. 14.  3.  0.
 11.  0.  0.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11 29  0  0  0  0  0  0  0 16 29
  3  0  4  0  0 10  0 16  0  0  0  3  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 24. 30. 23. 29.  8.  0.  5.  4.  0.  4.  5.  7. 10.  4. 10.  9.] 
adversary cards in hand: [11. 14. 11. 25.  1.] 
adversary cards in discard: [8. 0. 3.] 
adversary owned cards: [ 6 25  0  1  8 25  0 14  3  0  3  8 29 29  0  0 11 11  1 25  0 25 10  1
 25  3 11  0  1 14] -> size -> 30 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0.] 
cards in discard: [16.  0. 16.  0. 15. 11.  0.  8.  0.  6.  0. 29.  8.  3.  8. 14.  3.  0.
 11.  0.  0.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11 29  0  0  0  0  0  0  0 16 29
  3  0  4  0  0 10  0 16  0  0  0  3  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 24. 30. 23. 29.  8.  0.  5.  4.  0.  4.  5.  7. 10.  4. 10.  9.] 
adversary cards in hand: [11. 14. 11. 25.  1.] 
adversary cards in discard: [8. 0. 3.] 
adversary owned cards: [ 6 25  0  1  8 25  0 14  3  0  3  8 29 29  0  0 11 11  1 25  0 25 10  1
 25  3 11  0  1 14] -> size -> 30 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0.] 
cards in discard: [16.  0. 16.  0. 15. 11.  0.  8.  0.  6.  0. 29.  8.  3.  8. 14.  3.  0.
 11.  0.  0.  0.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11 29  0  0  0  0  0  0  0 16 29
  3  0  4  0  0 10  0 16  0  0  0  3  3  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 24. 30. 23. 29.  8.  0.  5.  4.  0.  4.  5.  7. 10.  4. 10.  9.] 
adversary cards in hand: [11. 14. 11. 25.  1.] 
adversary cards in discard: [8. 0. 3.] 
adversary owned cards: [ 6 25  0  1  8 25  0 14  3  0  3  8 29 29  0  0 11 11  1 25  0 25 10  1
 25  3 11  0  1 14] -> size -> 30 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [11. 14. 11. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14. 11. 25.] 
expected returns: [[ 3.8631773]
 [ 3.0294542]
 [-0.742661 ]
 [ 3.0294542]
 [ 3.2417998]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 14. 11. 25.  1.] 
cards in discard: [8. 0. 3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 6 25  0  1  8 25  0 14  3  0  3  8 29 29  0  0 11 11  1 25  0 25 10  1
 25  3 11  0  1 14] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 23. 29.  8.  0.  5.  4.  0.  4.  5.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  4. 29.  0.  0.] 
adversary cards in discard: [16.  0. 16.  0. 15. 11.  0.  8.  0.  6.  0. 29.  8.  3.  8. 14.  3.  0.
 11.  0.  0.  0.  3.  0. 16.  6.  6.  0.] 
adversary owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11 29  0  0  0  0  0  0  0 16 29
  3  0  4  0  0 10  0 16  0  0  0  3  3  0] -> size -> 38 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1.0
Learning step: -0.7025834918022156
desired expected reward: 1.7206923961639404



action possibilites: [-1] 
expected returns: [[5.0692058]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 25.  1.] 
cards in discard: [8. 0. 3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 6 25  0  1  8 25  0 14  3  0  3  8 29 29  0  0 11 11  1 25  0 25 10  1
 25  3 11  0  1 14] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 1. 24. 30. 23. 29.  8.  0.  5.  4.  0.  4.  5.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 4. 29.  0.] 
adversary cards in discard: [16.  0. 16.  0. 15. 11.  0.  8.  0.  6.  0. 29.  8.  3.  8. 14.  3.  0.
 11.  0.  0.  0.  3.  0. 16.  6.  6.  0.  0.  0.] 
adversary owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11 29  0  0  0  0  0  0  0 16 29
  3  0  4  0  0 10  0 16  0  0  0  3  3  0] -> size -> 38 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action 14.0
Learning step: 0.5011895298957825
desired expected reward: -0.24145859479904175





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[2.898332 ]
 [5.4196754]
 [5.6815763]
 [3.787054 ]
 [6.532141 ]
 [3.845531 ]
 [1.1940694]
 [3.9447536]
 [3.3436518]
 [6.197722 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 25.  1.] 
cards in discard: [8. 0. 3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 6 25  0  1  8 25  0 14  3  0  3  8 29 29  0  0 11 11  1 25  0 25 10  1
 25  3 11  0  1 14] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 1. 24. 30. 23. 29.  8.  0.  5.  4.  0.  4.  5.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 4. 29.  0.] 
adversary cards in discard: [16.  0. 16.  0. 15. 11.  0.  8.  0.  6.  0. 29.  8.  3.  8. 14.  3.  0.
 11.  0.  0.  0.  3.  0. 16.  6.  6.  0.  0.  0.] 
adversary owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11 29  0  0  0  0  0  0  0 16 29
  3  0  4  0  0 10  0 16  0  0  0  3  3  0] -> size -> 38 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action -1
Learning step: 0.21361640095710754
desired expected reward: 5.282822132110596



buy possibilites: [-1] 
expected returns: [[18.717419]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 25.  1.] 
cards in discard: [8. 0. 3. 1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 6 25  0  1  8 25  0 14  3  0  3  8 29 29  0  0 11 11  1 25  0 25 10  1
 25  3 11  0  1 14  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 23. 30. 23. 29.  8.  0.  5.  4.  0.  4.  5.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 4. 29.  0.] 
adversary cards in discard: [16.  0. 16.  0. 15. 11.  0.  8.  0.  6.  0. 29.  8.  3.  8. 14.  3.  0.
 11.  0.  0.  0.  3.  0. 16.  6.  6.  0.  0.  0.] 
adversary owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11 29  0  0  0  0  0  0  0 16 29
  3  0  4  0  0 10  0 16  0  0  0  3  3  0] -> size -> 38 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5.    0.    2.  -10.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: 11.5 

action type: buy - action 1.0
Learning step: 0.7251582145690918
desired expected reward: 6.144832611083984






         -------------------- Turn: 61 -------------------- 
Player: 1 
cards in hand: [ 4. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4. 29.  0.] 
cards in discard: [16.  0. 16.  0. 15. 11.  0.  8.  0.  6.  0. 29.  8.  3.  8. 14.  3.  0.
 11.  0.  0.  0.  3.  0. 16.  6.  6.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11 29  0  0  0  0  0  0  0 16 29
  3  0  4  0  0 10  0 16  0  0  0  3  3  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 23. 30. 23. 29.  8.  0.  5.  4.  0.  4.  5.  7. 10.  4. 10.  9.] 
adversary cards in hand: [11.  8. 29.  3. 25.] 
adversary cards in discard: [ 8.  0.  3.  1. 14. 11. 11. 25.  1.] 
adversary owned cards: [ 6 25  0  1  8 25  0 14  3  0  3  8 29 29  0  0 11 11  1 25  0 25 10  1
 25  3 11  0  1 14  1] -> size -> 31 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4. 29.  0.] 
cards in discard: [16.  0. 16.  0. 15. 11.  0.  8.  0.  6.  0. 29.  8.  3.  8. 14.  3.  0.
 11.  0.  0.  0.  3.  0. 16.  6.  6.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11 29  0  0  0  0  0  0  0 16 29
  3  0  4  0  0 10  0 16  0  0  0  3  3  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 23. 30. 23. 29.  8.  0.  5.  4.  0.  4.  5.  7. 10.  4. 10.  9.] 
adversary cards in hand: [11.  8. 29.  3. 25.] 
adversary cards in discard: [ 8.  0.  3.  1. 14. 11. 11. 25.  1.] 
adversary owned cards: [ 6 25  0  1  8 25  0 14  3  0  3  8 29 29  0  0 11 11  1 25  0 25 10  1
 25  3 11  0  1 14  1] -> size -> 31 
adversary victory points: 2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11.  8. 29.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 29. 25.] 
expected returns: [[14.695154 ]
 [15.379978 ]
 [13.3376255]
 [13.356722 ]
 [17.12289  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 29.  3. 25.] 
cards in discard: [ 8.  0.  3.  1. 14. 11. 11. 25.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 6 25  0  1  8 25  0 14  3  0  3  8 29 29  0  0 11 11  1 25  0 25 10  1
 25  3 11  0  1 14  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 23. 30. 23. 29.  8.  0.  5.  4.  0.  4.  5.  7. 10.  4. 10.  9.] 
adversary cards in hand: [10.  1.  0.  8. 16.] 
adversary cards in discard: [16.  0. 16.  0. 15. 11.  0.  8.  0.  6.  0. 29.  8.  3.  8. 14.  3.  0.
 11.  0.  0.  0.  3.  0. 16.  6.  6.  0.  0.  0.  4. 29.  0.] 
adversary owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11 29  0  0  0  0  0  0  0 16 29
  3  0  4  0  0 10  0 16  0  0  0  3  3  0] -> size -> 38 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -1.231788992881775
desired expected reward: 17.48563003540039



action possibilites: [-1] 
expected returns: [[5.607517]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 29.  3.  0. 25.] 
cards in discard: [ 8.  0.  3.  1. 14. 11. 11. 25.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 6 25  0  1  8 25  0 14  3  0  3  8 29 29  0  0 11 11  1 25  0 25 10  1
 25  3 11  0  1 14  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 23. 30. 23. 29.  8.  0.  5.  4.  0.  4.  5.  7. 10.  4. 10.  9.] 
adversary cards in hand: [10.  1.  0.  8. 16.] 
adversary cards in discard: [16.  0. 16.  0. 15. 11.  0.  8.  0.  6.  0. 29.  8.  3.  8. 14.  3.  0.
 11.  0.  0.  0.  3.  0. 16.  6.  6.  0.  0.  0.  4. 29.  0.] 
adversary owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11 29  0  0  0  0  0  0  0 16 29
  3  0  4  0  0 10  0 16  0  0  0  3  3  0] -> size -> 38 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: 8 

action type: take_action - action 25.0
Learning step: -0.3299756944179535
desired expected reward: 16.79292106628418





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[2.1158495]
 [5.304545 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8. 29.  3.  0. 25.] 
cards in discard: [ 8.  0.  3.  1. 14. 11. 11. 25.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 6 25  0  1  8 25  0 14  3  0  3  8 29 29  0  0 11 11  1 25  0 25 10  1
 25  3 11  0  1 14  1] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 23. 30. 23. 29.  8.  0.  5.  4.  0.  4.  5.  7. 10.  4. 10.  9.] 
adversary cards in hand: [10.  1.  0.  8. 16.] 
adversary cards in discard: [16.  0. 16.  0. 15. 11.  0.  8.  0.  6.  0. 29.  8.  3.  8. 14.  3.  0.
 11.  0.  0.  0.  3.  0. 16.  6.  6.  0.  0.  0.  4. 29.  0.] 
adversary owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11 29  0  0  0  0  0  0  0 16 29
  3  0  4  0  0 10  0 16  0  0  0  3  3  0] -> size -> 38 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action -1
Learning step: 0.16777002811431885
desired expected reward: 5.775286674499512






         -------------------- Turn: 62 -------------------- 
Player: 1 
cards in hand: [10.  1.  0.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 16.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  0.  8. 16.] 
cards in discard: [16.  0. 16.  0. 15. 11.  0.  8.  0.  6.  0. 29.  8.  3.  8. 14.  3.  0.
 11.  0.  0.  0.  3.  0. 16.  6.  6.  0.  0.  0.  4. 29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11 29  0  0  0  0  0  0  0 16 29
  3  0  4  0  0 10  0 16  0  0  0  3  3  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 23. 30. 23. 29.  8.  0.  5.  4.  0.  4.  5.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0. 10. 25.  1.] 
adversary cards in discard: [ 8.  0.  3.  1. 14. 11. 11. 25.  1. 25. 11.  8. 29.  3.  0. 25.] 
adversary owned cards: [ 6 25  0  1  8 25  0 14  3  0  3  8 29 29  0  0 11 11  1 25  0 25 10  1
 25  3 11  0  1 14  1] -> size -> 31 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1.  8. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  8. 16.  0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [10.] 
owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11 29  0  0  0  0  0  0  0 16 29
  3  0  4  0  0 10  0 16  0  0  0  3  3  0] -> size -> 38 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 1. 23. 30. 23. 29.  8.  0.  5.  4.  0.  4.  5.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0. 10. 25.  1.] 
adversary cards in discard: [ 8.  0.  3.  1. 14. 11. 11. 25.  1. 25. 11.  8. 29.  3.  0. 25.] 
adversary owned cards: [ 6 25  0  1  8 25  0 14  3  0  3  8 29 29  0  0 11 11  1 25  0 25 10  1
 25  3 11  0  1 14  1] -> size -> 31 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  8. 16.  0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [10.] 
owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11 29  0  0  0  0  0  0  0 16 29
  3  0  4  0  0 10  0 16  0  0  0  3  3  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 1. 23. 30. 23. 29.  8.  0.  5.  4.  0.  4.  5.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0. 10. 25.  1.] 
adversary cards in discard: [ 8.  0.  3.  1. 14. 11. 11. 25.  1. 25. 11.  8. 29.  3.  0. 25.] 
adversary owned cards: [ 6 25  0  1  8 25  0 14  3  0  3  8 29 29  0  0 11 11  1 25  0 25 10  1
 25  3 11  0  1 14  1] -> size -> 31 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0. 10. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[50.028168]
 [44.708363]
 [48.873116]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 25.  1.] 
cards in discard: [ 8.  0.  3.  1. 14. 11. 11. 25.  1. 25. 11.  8. 29.  3.  0. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 6 25  0  1  8 25  0 14  3  0  3  8 29 29  0  0 11 11  1 25  0 25 10  1
 25  3 11  0  1 14  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 23. 30. 23. 29.  8.  0.  5.  4.  0.  4.  5.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  0.  0.] 
adversary cards in discard: [10.  1.  0.  8. 16.  0.] 
adversary owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11 29  0  0  0  0  0  0  0 16 29
  3  0  4  0  0 10  0 16  0  0  0  3  3  0] -> size -> 38 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1.0
Learning step: 0.1816992610692978
desired expected reward: 5.486244201660156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[43.832706]
 [47.132797]
 [47.430824]
 [45.16457 ]
 [49.14088 ]
 [45.20196 ]
 [42.02007 ]
 [45.53001 ]
 [44.64809 ]
 [50.849827]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 25.  1.] 
cards in discard: [ 8.  0.  3.  1. 14. 11. 11. 25.  1. 25. 11.  8. 29.  3.  0. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 6 25  0  1  8 25  0 14  3  0  3  8 29 29  0  0 11 11  1 25  0 25 10  1
 25  3 11  0  1 14  1] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 1. 23. 30. 23. 29.  8.  0.  5.  4.  0.  4.  5.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  0.  0.] 
adversary cards in discard: [10.  1.  0.  8. 16.  0.] 
adversary owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11 29  0  0  0  0  0  0  0 16 29
  3  0  4  0  0 10  0 16  0  0  0  3  3  0] -> size -> 38 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -2.070528745651245
desired expected reward: 47.957637786865234



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 63 -------------------- 
Player: 1 
cards in hand: [ 0. 29.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.  0.] 
cards in discard: [10.  1.  0.  8. 16.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11 29  0  0  0  0  0  0  0 16 29
  3  0  4  0  0 10  0 16  0  0  0  3  3  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 23. 30. 23. 29.  8.  0.  5.  4.  0.  4.  5.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  1.  3.] 
adversary cards in discard: [ 8.  0.  3.  1. 14. 11. 11. 25.  1. 25. 11.  8. 29.  3.  0. 25.  0.  0.
 10. 25.  1.] 
adversary owned cards: [ 6 25  0  1  8 25  0 14  3  0  3  8 29 29  0  0 11 11  1 25  0 25 10  1
 25  3 11  0  1 14  1] -> size -> 31 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  0.  0.] 
cards in discard: [10.  1.  0.  8. 16.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11 29  0  0  0  0  0  0  0 16 29
  3  0  4  0  0 10  0 16  0  0  0  3  3  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 1. 23. 30. 23. 29.  8.  0.  5.  4.  0.  4.  5.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  1.  3.] 
adversary cards in discard: [ 8.  0.  3.  1. 14. 11. 11. 25.  1. 25. 11.  8. 29.  3.  0. 25.  0.  0.
 10. 25.  1.] 
adversary owned cards: [ 6 25  0  1  8 25  0 14  3  0  3  8 29 29  0  0 11 11  1 25  0 25 10  1
 25  3 11  0  1 14  1] -> size -> 31 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  0.  0.] 
cards in discard: [10.  1.  0.  8. 16.  0. 11.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11 29  0  0  0  0  0  0  0 16 29
  3  0  4  0  0 10  0 16  0  0  0  3  3  0 11] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 23. 30. 23. 29.  8.  0.  5.  3.  0.  4.  5.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  1.  3.] 
adversary cards in discard: [ 8.  0.  3.  1. 14. 11. 11. 25.  1. 25. 11.  8. 29.  3.  0. 25.  0.  0.
 10. 25.  1.] 
adversary owned cards: [ 6 25  0  1  8 25  0 14  3  0  3  8 29 29  0  0 11 11  1 25  0 25 10  1
 25  3 11  0  1 14  1] -> size -> 31 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0. 29.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-7.540071]
 [-8.579857]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  1.  3.] 
cards in discard: [ 8.  0.  3.  1. 14. 11. 11. 25.  1. 25. 11.  8. 29.  3.  0. 25.  0.  0.
 10. 25.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 6 25  0  1  8 25  0 14  3  0  3  8 29 29  0  0 11 11  1 25  0 25 10  1
 25  3 11  0  1 14  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 23. 30. 23. 29.  8.  0.  5.  3.  0.  4.  5.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 6.  0. 29.  0.  0.] 
adversary cards in discard: [10.  1.  0.  8. 16.  0. 11.  0. 29.  0.  0.  0.] 
adversary owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11 29  0  0  0  0  0  0  0 16 29
  3  0  4  0  0 10  0 16  0  0  0  3  3  0 11] -> size -> 39 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1.0
Learning step: -3.36905837059021
desired expected reward: 47.480777740478516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[-9.504269 ]
 [-9.195036 ]
 [-8.803084 ]
 [-9.435498 ]
 [-8.599407 ]
 [-9.411351 ]
 [-9.28027  ]
 [-8.9805565]
 [-8.986211 ]
 [-8.283421 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  1.  3.] 
cards in discard: [ 8.  0.  3.  1. 14. 11. 11. 25.  1. 25. 11.  8. 29.  3.  0. 25.  0.  0.
 10. 25.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 6 25  0  1  8 25  0 14  3  0  3  8 29 29  0  0 11 11  1 25  0 25 10  1
 25  3 11  0  1 14  1] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 1. 23. 30. 23. 29.  8.  0.  5.  3.  0.  4.  5.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 6.  0. 29.  0.  0.] 
adversary cards in discard: [10.  1.  0.  8. 16.  0. 11.  0. 29.  0.  0.  0.] 
adversary owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11 29  0  0  0  0  0  0  0 16 29
  3  0  4  0  0 10  0 16  0  0  0  3  3  0 11] -> size -> 39 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -0.4695412218570709
desired expected reward: -8.009625434875488



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 64 -------------------- 
Player: 1 
cards in hand: [ 6.  0. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 29.  0.  0.] 
cards in discard: [10.  1.  0.  8. 16.  0. 11.  0. 29.  0.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11 29  0  0  0  0  0  0  0 16 29
  3  0  4  0  0 10  0 16  0  0  0  3  3  0 11] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 23. 30. 23. 29.  8.  0.  5.  3.  0.  4.  5.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 25.  6. 14.  1.] 
adversary cards in discard: [ 8.  0.  3.  1. 14. 11. 11. 25.  1. 25. 11.  8. 29.  3.  0. 25.  0.  0.
 10. 25.  1.  0.  0. 29.  1.  3.] 
adversary owned cards: [ 6 25  0  1  8 25  0 14  3  0  3  8 29 29  0  0 11 11  1 25  0 25 10  1
 25  3 11  0  1 14  1] -> size -> 31 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [10.  1.  0.  8. 16.  0. 11.  0. 29.  0.  0.  0.  6.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11 29  0  0  0  0  0  0  0 16 29
  3  0  4  0  0 10  0 16  0  0  0  3  3  0 11] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 1. 23. 30. 23. 29.  8.  0.  5.  3.  0.  4.  5.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 25.  6. 14.  1.] 
adversary cards in discard: [ 8.  0.  3.  1. 14. 11. 11. 25.  1. 25. 11.  8. 29.  3.  0. 25.  0.  0.
 10. 25.  1.  0.  0. 29.  1.  3.] 
adversary owned cards: [ 6 25  0  1  8 25  0 14  3  0  3  8 29 29  0  0 11 11  1 25  0 25 10  1
 25  3 11  0  1 14  1] -> size -> 31 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [10.  1.  0.  8. 16.  0. 11.  0. 29.  0.  0.  0.  6.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11 29  0  0  0  0  0  0  0 16 29
  3  0  4  0  0 10  0 16  0  0  0  3  3  0 11] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 1. 23. 30. 23. 29.  8.  0.  5.  3.  0.  4.  5.  7. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 25.  6. 14.  1.] 
adversary cards in discard: [ 8.  0.  3.  1. 14. 11. 11. 25.  1. 25. 11.  8. 29.  3.  0. 25.  0.  0.
 10. 25.  1.  0.  0. 29.  1.  3.] 
adversary owned cards: [ 6 25  0  1  8 25  0 14  3  0  3  8 29 29  0  0 11 11  1 25  0 25 10  1
 25  3 11  0  1 14  1] -> size -> 31 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [10.  1.  0.  8. 16.  0. 11.  0. 29.  0.  0.  0.  6.  0. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11 29  0  0  0  0  0  0  0 16 29
  3  0  4  0  0 10  0 16  0  0  0  3  3  0 11 10] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 23. 30. 23. 29.  8.  0.  5.  3.  0.  4.  5.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 25.  6. 14.  1.] 
adversary cards in discard: [ 8.  0.  3.  1. 14. 11. 11. 25.  1. 25. 11.  8. 29.  3.  0. 25.  0.  0.
 10. 25.  1.  0.  0. 29.  1.  3.] 
adversary owned cards: [ 6 25  0  1  8 25  0 14  3  0  3  8 29 29  0  0 11 11  1 25  0 25 10  1
 25  3 11  0  1 14  1] -> size -> 31 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [ 0. 25.  6. 14.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 14.] 
expected returns: [[28.157404]
 [30.323812]
 [22.924875]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  6. 14.  1.] 
cards in discard: [ 8.  0.  3.  1. 14. 11. 11. 25.  1. 25. 11.  8. 29.  3.  0. 25.  0.  0.
 10. 25.  1.  0.  0. 29.  1.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 6 25  0  1  8 25  0 14  3  0  3  8 29 29  0  0 11 11  1 25  0 25 10  1
 25  3 11  0  1 14  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 23. 30. 23. 29.  8.  0.  5.  3.  0.  4.  5.  7. 10.  3. 10.  9.] 
adversary cards in hand: [6. 0. 0. 8. 8.] 
adversary cards in discard: [10.  1.  0.  8. 16.  0. 11.  0. 29.  0.  0.  0.  6.  0. 10. 29.  0.  0.
  3.] 
adversary owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11 29  0  0  0  0  0  0  0 16 29
  3  0  4  0  0 10  0 16  0  0  0  3  3  0 11 10] -> size -> 40 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1.0
Learning step: 0.4040479362010956
desired expected reward: -7.879385948181152





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[22.696447]
 [25.117483]
 [24.071371]
 [25.904013]
 [23.344233]
 [25.97794 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  6. 14.  1.] 
cards in discard: [ 8.  0.  3.  1. 14. 11. 11. 25.  1. 25. 11.  8. 29.  3.  0. 25.  0.  0.
 10. 25.  1.  0.  0. 29.  1.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 6 25  0  1  8 25  0 14  3  0  3  8 29 29  0  0 11 11  1 25  0 25 10  1
 25  3 11  0  1 14  1] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 1. 23. 30. 23. 29.  8.  0.  5.  3.  0.  4.  5.  7. 10.  3. 10.  9.] 
adversary cards in hand: [6. 0. 0. 8. 8.] 
adversary cards in discard: [10.  1.  0.  8. 16.  0. 11.  0. 29.  0.  0.  0.  6.  0. 10. 29.  0.  0.
  3.] 
adversary owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11 29  0  0  0  0  0  0  0 16 29
  3  0  4  0  0 10  0 16  0  0  0  3  3  0 11 10] -> size -> 40 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -1.4927774667739868
desired expected reward: 26.664627075195312



buy possibilites: [-1] 
expected returns: [[24.353676]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  6. 14.  1.] 
cards in discard: [ 8.  0.  3.  1. 14. 11. 11. 25.  1. 25. 11.  8. 29.  3.  0. 25.  0.  0.
 10. 25.  1.  0.  0. 29.  1.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 6 25  0  1  8 25  0 14  3  0  3  8 29 29  0  0 11 11  1 25  0 25 10  1
 25  3 11  0  1 14  1 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 23. 30. 23. 29.  8.  0.  5.  2.  0.  4.  5.  7. 10.  3. 10.  9.] 
adversary cards in hand: [6. 0. 0. 8. 8.] 
adversary cards in discard: [10.  1.  0.  8. 16.  0. 11.  0. 29.  0.  0.  0.  6.  0. 10. 29.  0.  0.
  3.] 
adversary owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11 29  0  0  0  0  0  0  0 16 29
  3  0  4  0  0 10  0 16  0  0  0  3  3  0 11 10] -> size -> 40 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: 5 

action type: buy - action 11.0
Learning step: -0.4409959018230438
desired expected reward: 25.4630126953125






         -------------------- Turn: 65 -------------------- 
Player: 1 
cards in hand: [6. 0. 0. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 8. 8.] 
cards in discard: [10.  1.  0.  8. 16.  0. 11.  0. 29.  0.  0.  0.  6.  0. 10. 29.  0.  0.
  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  6  8  6  8  6  8  1 16 11 15 16 11 29  0  0  0  0  0  0  0 16 29
  3  0  4  0  0 10  0 16  0  0  0  3  3  0 11 10] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 23. 30. 23. 29.  8.  0.  5.  2.  0.  4.  5.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 6.  0.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 6 25  0  1  8 25  0 14  3  0  3  8 29 29  0  0 11 11  1 25  0 25 10  1
 25  3 11  0  1 14  1 11] -> size -> 32 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [10.  1.  0.  8. 16.  0. 11.  0. 29.  0.  0.  0.  6.  0. 10. 29.  0.  0.
  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  6  8  6  8  6  8  1 16 11 15 16 11 29  0  0  0  0  0 16 29  3  0  4
  0  0 10  0 16  0  0  0  3  3  0 11 10] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 23. 30. 23. 29.  8.  0.  5.  2.  0.  4.  5.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 6.  0.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 6 25  0  1  8 25  0 14  3  0  3  8 29 29  0  0 11 11  1 25  0 25 10  1
 25  3 11  0  1 14  1 11] -> size -> 32 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [10.  1.  0.  8. 16.  0. 11.  0. 29.  0.  0.  0.  6.  0. 10. 29.  0.  0.
  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  6  8  6  8  6  8  1 16 11 15 16 11 29  0  0  0  0  0 16 29  3  0  4
  0  0 10  0 16  0  0  0  3  3  0 11 10] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 1. 23. 30. 23. 29.  8.  0.  5.  2.  0.  4.  5.  7. 10.  3. 10.  9.] 
adversary cards in hand: [ 6.  0.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 6 25  0  1  8 25  0 14  3  0  3  8 29 29  0  0 11 11  1 25  0 25 10  1
 25  3 11  0  1 14  1 11] -> size -> 32 
adversary victory points: 2
player victory points: 3 


Player 1 won the game! 



Player 0 bought cards:
Copper: 6 
Silver: 4 
Gold: 0 
Estate: 3 
Duchy: 0 
Province: 0 
Curse: 2 

Remodel: 1 
Workshop: 4 
Chapel: 2 
Witch: 6 
Poacher: 2 
Militia: 2 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 6.  0.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 6 25  0  1  8 25  0 14  3  0  3  8 29 29  0  0 11 11  1 25  0 25 10  1
 25  3 11  0  1 14  1 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 23. 29.  8.  0.  5.  2.  0.  4.  5.  7. 10.  3. 10.  9.] 
adversary cards in hand: [6.] 
adversary cards in discard: [10.  1.  0.  8. 16.  0. 11.  0. 29.  0.  0.  0.  6.  0. 10. 29.  0.  0.
  3.  0.] 
adversary owned cards: [14  6  8  6  8  6  8  1 16 11 15 16 11 29  0  0  0  0  0 16 29  3  0  4
  0  0 10  0 16  0  0  0  3  3  0 11 10  0] -> size -> 38 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5 -500    2  -10    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -513 

action type: buy - action -1
Learning step: -26.867685317993164
desired expected reward: -2.514009475708008



