 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[300.76315]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    0  -40    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -545 

action type: buy - action -1
Learning step: -27.254369735717773
desired expected reward: -27.166994094848633





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[276.41486]
 [289.18906]
 [285.26215]
 [259.58246]
 [250.7847 ]
 [283.0489 ]
 [298.6607 ]
 [285.78638]
 [308.6829 ]
 [288.4828 ]
 [264.35226]
 [273.44855]
 [284.09195]
 [258.95996]
 [278.55902]
 [303.83987]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.953592300415039
desired expected reward: 295.26702880859375



buy possibilites: [-1] 
expected returns: [[214.71573]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  8.  0.] 
sum of rewards: 6.0 

action type: buy - action 29.0
Learning step: -9.293036460876465
desired expected reward: 279.18975830078125






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[274.81656]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [11.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -4.611348628997803
desired expected reward: 210.10438537597656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[259.48352]
 [266.16553]
 [238.9368 ]
 [267.8988 ]
 [280.96585]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [11.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -7.992576599121094
desired expected reward: 268.64910888671875



buy possibilites: [-1] 
expected returns: [[278.1981]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [11.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -32.0 

action type: buy - action 0.0
Learning step: -8.314719200134277
desired expected reward: 251.1687774658203






Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [11.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [11.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [11.  3.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0] -> size -> 12 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[246.57092]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -9.009231567382812
desired expected reward: 269.1888427734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[227.49261]
 [232.36528]
 [207.62357]
 [235.02315]
 [243.96126]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -7.641362190246582
desired expected reward: 236.83299255371094



buy possibilites: [-1] 
expected returns: [[289.63666]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -10.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -42.0 

action type: buy - action 0.0
Learning step: -6.957808017730713
desired expected reward: 220.5348358154297






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0] -> size -> 13 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0] -> size -> 13 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[331.54495]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 3. 3. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  3.  3.] 
adversary cards in discard: [14.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -7.607159614562988
desired expected reward: 282.0295104980469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[304.83594]
 [318.50955]
 [314.00204]
 [287.093  ]
 [278.40295]
 [311.92963]
 [327.96832]
 [314.89594]
 [338.8574 ]
 [317.4835 ]
 [291.35004]
 [301.20468]
 [312.52142]
 [285.91245]
 [306.47592]
 [332.62973]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 0. 3. 3. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  3.  3.] 
adversary cards in discard: [14.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -10.21044635772705
desired expected reward: 321.9972839355469



buy possibilites: [-1] 
expected returns: [[232.85432]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0.  0.  3.  3.  3.  0. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  9. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  3.  3.] 
adversary cards in discard: [14.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0  50   0] 
sum of rewards: 38 

action type: buy - action 25.0
Learning step: -9.803648948669434
desired expected reward: 329.05377197265625






Player: 1 
cards in hand: [ 3. 11.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  3.  3.] 
cards in discard: [14.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  9. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25] -> size -> 14 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  3.  3.] 
cards in discard: [14.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  9. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25] -> size -> 14 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[254.27458]
 [245.73026]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 29.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  9. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -6.733498573303223
desired expected reward: 226.12081909179688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[235.62213]
 [246.25743]
 [241.66086]
 [214.07031]
 [252.095  ]
 [243.76231]
 [240.29875]
 [254.48213]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 29.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  9. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -7.599000453948975
desired expected reward: 241.27159118652344



buy possibilites: [-1] 
expected returns: [[280.7158]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 29.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  9. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 1.0 

action type: buy - action 3.0
Learning step: -5.71693754196167
desired expected reward: 235.9439239501953






Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  9. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 3.  0.  0.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3] -> size -> 15 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  9. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 3.  0.  0.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3] -> size -> 15 
adversary victory points: 4
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[292.66452]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 3.  0.  0.  3.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  9. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  3.] 
adversary cards in discard: [0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -7.570200443267822
desired expected reward: 273.1455993652344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[275.2501 ]
 [285.71588]
 [281.95212]
 [254.43694]
 [280.70956]
 [292.38687]
 [282.94687]
 [284.8399 ]
 [264.73267]
 [280.67816]
 [276.03265]
 [295.59088]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 3.  0.  0.  3.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  9. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  3.] 
adversary cards in discard: [0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -8.212604522705078
desired expected reward: 281.369140625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 11.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0.  3.] 
cards in discard: [0. 3. 0. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  9. 10.  9.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3] -> size -> 15 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [ 0.  3.  0.  3.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  9. 10.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3] -> size -> 15 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [ 0.  3.  0.  3.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  9. 10.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3] -> size -> 15 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[303.61728]
 [311.24753]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  9. 10.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14 10] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1.0
Learning step: -7.145423412322998
desired expected reward: 272.8112487792969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[281.60312]
 [291.15182]
 [285.92807]
 [262.02502]
 [295.57452]
 [289.33215]
 [285.15723]
 [296.39417]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 25.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  9. 10.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14 10] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -8.72451114654541
desired expected reward: 293.7517395019531



buy possibilites: [-1] 
expected returns: [[222.38995]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 25.  0.  0.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  9.  9.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14 10] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 1.0 

action type: buy - action 8.0
Learning step: -9.412834167480469
desired expected reward: 279.9193115234375






Player: 1 
cards in hand: [ 0. 11. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 14.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8. 10. 10.  9.  9.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [ 8.  0.  3. 25.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8] -> size -> 16 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  0.] 
cards in discard: [1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14 10  1] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  9.  9.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [ 8.  0.  3. 25.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8] -> size -> 16 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  0.] 
cards in discard: [1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14 10  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  9.  9.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [ 8.  0.  3. 25.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8] -> size -> 16 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  0.] 
cards in discard: [1. 8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14 10  1  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  9.  8.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [ 8.  0.  3. 25.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8] -> size -> 16 
adversary victory points: 4
player victory points: 4 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[321.133 ]
 [315.1445]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  3.  0.] 
cards in discard: [ 8.  0.  3. 25.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  9.  8.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [ 1.  8. 11.  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14 10  1  8] -> size -> 16 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -4.039805889129639
desired expected reward: 218.3501434326172



action possibilites: [-1.] 
expected returns: [[306.6859]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 8.  0.  3. 25.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  9.  8.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [ 1.  8. 11.  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14 10  1  8] -> size -> 16 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 20 

action type: take_action - action 29.0
Learning step: -7.778378963470459
desired expected reward: 305.7978515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[294.25455]
 [303.38995]
 [298.82968]
 [280.90652]
 [272.7458 ]
 [299.0473 ]
 [307.64362]
 [301.59647]
 [315.66632]
 [302.9262 ]
 [282.8977 ]
 [289.64148]
 [298.14548]
 [278.55258]
 [293.87155]
 [308.17993]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 8.  0.  3. 25.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 29. 30. 28. 30.  8. 10. 10.  9.  8.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [ 1.  8. 11.  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14 10  1  8] -> size -> 16 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1.0
Learning step: -7.703181743621826
desired expected reward: 298.98272705078125



buy possibilites: [-1] 
expected returns: [[267.11816]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 8.  0.  3. 25.  0.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  9.  8.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [ 1.  8. 11.  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14 10  1  8] -> size -> 16 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5.   0.   4.   0.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 23.5 

action type: buy - action 1.0
Learning step: -7.984339237213135
desired expected reward: 295.4056091308594






Player: 1 
cards in hand: [0. 3. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [ 1.  8. 11.  0. 14.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14 10  1  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  9.  8.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1] -> size -> 17 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [ 1.  8. 11.  0. 14.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14 10  1  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  9.  8.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1] -> size -> 17 
adversary victory points: 4
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[242.02646]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  9.  8.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 10.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14 10  1  8] -> size -> 16 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: buy - action -1
Learning step: -7.998927593231201
desired expected reward: 259.1192321777344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[220.44525]
 [231.81581]
 [226.7594 ]
 [197.61594]
 [237.95546]
 [229.265  ]
 [225.15956]
 [240.71938]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  9.  8.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 10.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14 10  1  8] -> size -> 16 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -6.952635288238525
desired expected reward: 233.35765075683594



buy possibilites: [-1] 
expected returns: [[205.21138]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 27. 30.  8. 10. 10.  9.  8.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 10.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14 10  1  8] -> size -> 16 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5.  0.  5. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 12.0 

action type: buy - action 3.0
Learning step: -6.120713710784912
desired expected reward: 220.638671875






Player: 1 
cards in hand: [ 3. 10.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14 10  1  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8. 10. 10.  9.  8.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [25.  0.  0.  0.  8.] 
adversary cards in discard: [3. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3] -> size -> 18 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14 10  1  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 27. 30.  8. 10. 10.  9.  8.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [25.  0.  0.  0.  8.] 
adversary cards in discard: [3. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3] -> size -> 18 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  0.  0.] 
cards in discard: [8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14 10  1  8  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8. 10. 10.  9.  7.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [25.  0.  0.  0.  8.] 
adversary cards in discard: [3. 0. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3] -> size -> 18 
adversary victory points: 5
player victory points: 4 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [25.  0.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[265.0988 ]
 [270.3583 ]
 [257.94504]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.  0.  8.] 
cards in discard: [3. 0. 3. 0. 0. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8. 10. 10.  9.  7.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [ 8.  3. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14 10  1  8  8] -> size -> 17 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 10 

action type: buy - action -1
Learning step: -3.878436326980591
desired expected reward: 201.33294677734375



action possibilites: [-1] 
expected returns: [[195.69829]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  8.  3. 29.] 
cards in discard: [3. 0. 3. 0. 0. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  9. 10.  9.  7.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [ 8.  3. 10.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14 10  1  8  8  6] -> size -> 18 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 30 

action type: take_action - action 25.0
Learning step: -7.440831661224365
desired expected reward: 259.4400329589844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[187.36942]
 [198.50702]
 [195.60585]
 [163.75784]
 [208.03052]
 [195.34785]
 [194.63445]
 [214.02878]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  8.  3. 29.] 
cards in discard: [3. 0. 3. 0. 0. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 27. 30.  8.  9. 10.  9.  7.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [ 8.  3. 10.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14 10  1  8  8  6] -> size -> 18 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  5 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 30 

action type: take_action - action -1
Learning step: -3.8743462562561035
desired expected reward: 191.82394409179688



buy possibilites: [-1] 
expected returns: [[186.18434]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  8.  3. 29.] 
cards in discard: [3. 0. 3. 0. 0. 3. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 26. 30.  8.  9. 10.  9.  7.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [ 8.  3. 10.  3.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14 10  1  8  8  6] -> size -> 18 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5.  0.  6. 20.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 43.0 

action type: buy - action 3.0
Learning step: -3.441145658493042
desired expected reward: 192.1647186279297






Player: 1 
cards in hand: [ 0.  0. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.  0.] 
cards in discard: [ 8.  3. 10.  3.  0.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14 10  1  8  8  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 26. 30.  8.  9. 10.  9.  7.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  3.  3. 25.  0.  0.  0.  8.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3] -> size -> 19 
adversary victory points: 6
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 8.  3. 10.  3.  0.  0.  6.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14 10  1  8  8  6  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 26. 30.  8.  8. 10.  9.  7.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  3.  3. 25.  0.  0.  0.  8.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3] -> size -> 19 
adversary victory points: 6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 8.  3. 10.  3.  0.  0.  6.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14 10  1  8  8  6  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 26. 30.  8.  8. 10.  9.  7.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  3.  3. 25.  0.  0.  0.  8.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3] -> size -> 19 
adversary victory points: 6
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 8.  3. 10.  3.  0.  0.  6.  6. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14 10  1  8  8  6  6 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 26. 30.  8.  8. 10.  9.  7.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  3.  3. 25.  0.  0.  0.  8.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3] -> size -> 19 
adversary victory points: 6
player victory points: 2 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[162.79836]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [ 3.  0.  3.  0.  0.  3.  3. 25.  0.  0.  0.  8.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 26. 30.  8.  8. 10.  9.  7.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  3.  8. 14.  0.] 
adversary cards in discard: [ 8.  3. 10.  3.  0.  0.  6.  6. 10. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14 10  1  8  8  6  6 10] -> size -> 20 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 41 

action type: buy - action -1
Learning step: -3.691767930984497
desired expected reward: 182.49256896972656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[150.02429]
 [158.22968]
 [154.83333]
 [139.42279]
 [133.78473]
 [154.1148 ]
 [163.24731]
 [156.00319]
 [171.01196]
 [157.28311]
 [141.54541]
 [147.23567]
 [153.70657]
 [138.50755]
 [150.08456]
 [165.1974 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [ 3.  0.  3.  0.  0.  3.  3. 25.  0.  0.  0.  8.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 28. 30. 26. 30.  8.  8. 10.  9.  7.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  3.  8. 14.  0.] 
adversary cards in discard: [ 8.  3. 10.  3.  0.  0.  6.  6. 10. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14 10  1  8  8  6  6 10] -> size -> 20 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 41 

action type: take_action - action -1.0
Learning step: -2.42460036277771
desired expected reward: 156.1287078857422



buy possibilites: [-1] 
expected returns: [[199.95845]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [ 3.  0.  3.  0.  0.  3.  3. 25.  0.  0.  0.  8.  3. 29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 5 
card supply: [27. 28. 30. 26. 30.  8.  8. 10.  9.  7.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  3.  8. 14.  0.] 
adversary cards in discard: [ 8.  3. 10.  3.  0.  0.  6.  6. 10. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14 10  1  8  8  6  6 10] -> size -> 20 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[ -5.   0.   6.  40.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 11.0 

action type: buy - action 0.0
Learning step: -2.1722514629364014
desired expected reward: 142.2540740966797






Player: 1 
cards in hand: [ 1.  3.  8. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  8. 14.  0.] 
cards in discard: [ 8.  3. 10.  3.  0.  0.  6.  6. 10. 11.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14 10  1  8  8  6  6 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8.  8. 10.  9.  7.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  1.  8. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0] -> size -> 20 
adversary victory points: 6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  8. 14.  0.] 
cards in discard: [ 8.  3. 10.  3.  0.  0.  6.  6. 10. 11.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14 10  1  8  8  6  6 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 26. 30.  8.  8. 10.  9.  7.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  1.  8. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0] -> size -> 20 
adversary victory points: 6
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  8. 14.  0.] 
cards in discard: [ 8.  3. 10.  3.  0.  0.  6.  6. 10. 11.  0.  0.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14 10  1  8  8  6  6 10  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 25. 30.  8.  8. 10.  9.  7.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  1.  8. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0] -> size -> 20 
adversary victory points: 6
player victory points: 3 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [29.  1.  8. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 25.] 
expected returns: [[185.84344]
 [175.37143]
 [173.5429 ]
 [190.16536]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  8. 25.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  8. 10.  9.  7.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [8. 3. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14 10  1  8  8  6  6 10  3] -> size -> 21 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 31 

action type: buy - action -1
Learning step: -4.452096462249756
desired expected reward: 195.50634765625



action possibilites: [-1] 
expected returns: [[172.45244]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  8.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  7. 10.  9.  7.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [8. 3. 3. 1. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14 10  1  8  8  6  6 10  3  6] -> size -> 22 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 30  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 52 

action type: take_action - action 25.0
Learning step: -2.811776876449585
desired expected reward: 183.02734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[155.93073]
 [166.19478]
 [161.98862]
 [134.6736 ]
 [172.37482]
 [163.71521]
 [160.88916]
 [174.65347]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  8.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 25. 30.  8.  7. 10.  9.  7.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [8. 3. 3. 1. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14 10  1  8  8  6  6 10  3  6] -> size -> 22 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: take_action - action -1
Learning step: -2.4221436977386475
desired expected reward: 170.03028869628906



buy possibilites: [-1] 
expected returns: [[153.80093]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  8.  3.  0.  3.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  7. 10.  9.  7.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [8. 3. 3. 1. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14 10  1  8  8  6  6 10  3  6] -> size -> 22 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 30  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 69 

action type: buy - action 10.0
Learning step: -1.1339362859725952
desired expected reward: 159.7552032470703






Player: 1 
cards in hand: [8. 3. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 1. 0.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14 10  1  8  8  6  6 10  3  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  7. 10.  9.  7.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [10. 25. 29.  1.  8.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10] -> size -> 21 
adversary victory points: 6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 1. 0.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14 10  1  8  8  6  6 10  3  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 25. 30.  8.  7. 10.  9.  7.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [10. 25. 29.  1.  8.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10] -> size -> 21 
adversary victory points: 6
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 1. 0.] 
cards in discard: [ 6. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14 10  1  8  8  6  6 10  3  6 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  7. 10.  8.  7.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [10. 25. 29.  1.  8.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10] -> size -> 21 
adversary victory points: 6
player victory points: 2 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[185.47327]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10. 25. 29.  1.  8.  3.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  7. 10.  8.  7.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 8. 14.  3.  0.  0.] 
adversary cards in discard: [ 6. 11.  8.  3.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14 10  1  8  8  6  6 10  3  6 11] -> size -> 23 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 41 

action type: buy - action -1
Learning step: -1.5762748718261719
desired expected reward: 152.2246551513672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[158.2026 ]
 [167.35864]
 [164.70816]
 [141.4478 ]
 [162.74866]
 [174.54262]
 [164.17375]
 [165.77846]
 [149.96498]
 [163.3832 ]
 [159.34471]
 [177.78032]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10. 25. 29.  1.  8.  3.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 28. 30. 25. 30.  8.  7. 10.  8.  7.  9.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 8. 14.  3.  0.  0.] 
adversary cards in discard: [ 6. 11.  8.  3.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14 10  1  8  8  6  6 10  3  6 11] -> size -> 23 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 41 

action type: take_action - action -1.0
Learning step: -3.3011109828948975
desired expected reward: 177.31097412109375



buy possibilites: [-1] 
expected returns: [[127.7763]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10. 25. 29.  1.  8.  3.  0.  3. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  7. 10.  8.  7.  9.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8. 14.  3.  0.  0.] 
adversary cards in discard: [ 6. 11.  8.  3.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14 10  1  8  8  6  6 10  3  6 11] -> size -> 23 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  6 40  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 73 

action type: buy - action 14.0
Learning step: -0.9732818603515625
desired expected reward: 148.99168395996094






Player: 1 
cards in hand: [ 8. 14.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  3.  0.  0.] 
cards in discard: [ 6. 11.  8.  3.  3.  1.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3 14 10  1  8  8  6  6 10  3  6 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  7. 10.  8.  7.  9.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [10. 25. 29.  1.  8.  3.  0.  3. 14.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14] -> size -> 22 
adversary victory points: 6
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 6. 11.  8.  3.  3.  1.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3 10  1  8  8  6  6 10  3  6 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  7. 10.  8.  7.  9.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [10. 25. 29.  1.  8.  3.  0.  3. 14.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14] -> size -> 22 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 6. 11.  8.  3.  3.  1.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3 10  1  8  8  6  6 10  3  6 11] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 25. 30.  8.  7. 10.  8.  7.  9.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [10. 25. 29.  1.  8.  3.  0.  3. 14.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14] -> size -> 22 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[147.63841]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [10. 25. 29.  1.  8.  3.  0.  3. 14.  0.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  7. 10.  8.  7.  9.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [10.  6.  0. 11.  3.] 
adversary cards in discard: [ 6. 11.  8.  3.  3.  1.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3 10  1  8  8  6  6 10  3  6 11] -> size -> 20 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: buy - action -1
Learning step: -0.5799121856689453
desired expected reward: 127.1963882446289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[128.39148]
 [136.8166 ]
 [134.01613]
 [109.1993 ]
 [141.96094]
 [134.5125 ]
 [132.75945]
 [144.20593]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [10. 25. 29.  1.  8.  3.  0.  3. 14.  0.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 25. 30.  8.  7. 10.  8.  7.  9.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [10.  6.  0. 11.  3.] 
adversary cards in discard: [ 6. 11.  8.  3.  3.  1.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3 10  1  8  8  6  6 10  3  6 11] -> size -> 20 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: take_action - action -1.0
Learning step: -1.6873257160186768
desired expected reward: 143.15280151367188



buy possibilites: [-1] 
expected returns: [[139.69435]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [10. 25. 29.  1.  8.  3.  0.  3. 14.  0.  0.  0.  3.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  7. 10.  8.  7.  9.  9.  8. 10.  6. 10. 10.] 
adversary cards in hand: [10.  6.  0. 11.  3.] 
adversary cards in discard: [ 6. 11.  8.  3.  3.  1.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3 10  1  8  8  6  6 10  3  6 11] -> size -> 20 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 69 

action type: buy - action 10.0
Learning step: -0.04484863206744194
desired expected reward: 132.71458435058594






Player: 1 
cards in hand: [10.  6.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  0. 11.  3.] 
cards in discard: [ 6. 11.  8.  3.  3.  1.  0.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3 10  1  8  8  6  6 10  3  6 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8.  7. 10.  8.  7.  9.  9.  8. 10.  6. 10. 10.] 
adversary cards in hand: [25.  0.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14 10] -> size -> 23 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  0. 11.  3.] 
cards in discard: [ 6. 11.  8.  3.  3.  1.  0.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3 10  1  8  8  6  6 10  3  6 11] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 25. 30.  8.  7. 10.  8.  7.  9.  9.  8. 10.  6. 10. 10.] 
adversary cards in hand: [25.  0.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14 10] -> size -> 23 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  0. 11.  3.] 
cards in discard: [ 6. 11.  8.  3.  3.  1.  0.  8.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3 10  1  8  8  6  6 10  3  6 11  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 25. 30.  8.  7. 10.  8.  7.  9.  9.  8. 10.  6. 10. 10.] 
adversary cards in hand: [25.  0.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14 10] -> size -> 23 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [25.  0.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[131.94382]
 [137.95834]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 30.  8.  7. 10.  8.  7.  9.  9.  8. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0.  0.  3.  0.] 
adversary cards in discard: [ 6. 11.  8.  3.  3.  1.  0.  8.  0.  0. 10.  6.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3 10  1  8  8  6  6 10  3  6 11  0] -> size -> 21 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: buy - action -1
Learning step: -1.4436836242675781
desired expected reward: 138.25067138671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[114.8904 ]
 [124.14875]
 [120.17373]
 [ 96.43631]
 [129.77864]
 [122.05032]
 [119.41367]
 [132.0596 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 25. 30.  8.  7. 10.  8.  7.  9.  9.  8. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0.  0.  3.  0.] 
adversary cards in discard: [ 6. 11.  8.  3.  3.  1.  0.  8.  0.  0. 10.  6.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3 10  1  8  8  6  6 10  3  6 11  0] -> size -> 21 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: take_action - action -1.0
Learning step: -1.2194000482559204
desired expected reward: 128.49623107910156



buy possibilites: [-1] 
expected returns: [[105.702934]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0.  3.  0.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14 10 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 30.  8.  7. 10.  8.  7.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [10.  0.  0.  3.  0.] 
adversary cards in discard: [ 6. 11.  8.  3.  3.  1.  0.  8.  0.  0. 10.  6.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3 10  1  8  8  6  6 10  3  6 11  0] -> size -> 21 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 69 

action type: buy - action 10.0
Learning step: -0.14236831665039062
desired expected reward: 119.27131652832031






Player: 1 
cards in hand: [10.  0.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3.  0.] 
cards in discard: [ 6. 11.  8.  3.  3.  1.  0.  8.  0.  0. 10.  6.  0. 11.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3 10  1  8  8  6  6 10  3  6 11  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 30.  8.  7. 10.  8.  7.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [3. 8. 3. 0. 3.] 
adversary cards in discard: [10. 25.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14 10 10] -> size -> 24 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.  0.] 
cards in discard: [ 6. 11.  8.  3.  3.  1.  0.  8.  0.  0. 10.  6.  0. 11.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3 10  1  8  8  6  6 10  3  6 11  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 25. 30.  8.  7. 10.  8.  7.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [3. 8. 3. 0. 3.] 
adversary cards in discard: [10. 25.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14 10 10] -> size -> 24 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.  0.] 
cards in discard: [ 6. 11.  8.  3.  3.  1.  0.  8.  0.  0. 10.  6.  0. 11.  3.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3 10  1  8  8  6  6 10  3  6 11  0  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 25. 30.  8.  7. 10.  8.  6.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [3. 8. 3. 0. 3.] 
adversary cards in discard: [10. 25.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14 10 10] -> size -> 24 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [3. 8. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[132.21786 ]
 [120.011986]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3. 0. 3.] 
cards in discard: [10. 25.  0.  0.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14 10 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 30.  8.  7. 10.  8.  6.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [6. 6. 3. 1. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3 10  1  8  8  6  6 10  3  6 11  0  8] -> size -> 22 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: buy - action -1
Learning step: 0.017271805554628372
desired expected reward: 105.72020721435547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[113.853355]
 [ 98.15885 ]
 [131.85289 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3. 0. 3.] 
cards in discard: [10. 25.  0.  0.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14 10 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 25. 30.  8.  7. 10.  8.  6.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [6. 6. 3. 1. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3 10  1  8  8  6  6 10  3  6 11  0  8] -> size -> 22 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: take_action - action -1.0
Learning step: -1.2438156604766846
desired expected reward: 126.75875091552734



buy possibilites: [-1] 
expected returns: [[95.93231]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3. 0. 3.] 
cards in discard: [10. 25.  0.  0.  3.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14 10 10
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 25. 30.  8.  6. 10.  8.  6.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [6. 6. 3. 1. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3 10  1  8  8  6  6 10  3  6 11  0  8] -> size -> 22 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[  -5.    0.    5.   40.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -260.0 

action type: buy - action 6.0
Learning step: -15.749612808227539
desired expected reward: 82.41217041015625






Player: 1 
cards in hand: [6. 6. 3. 1. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 3. 1. 6.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3 10  1  8  8  6  6 10  3  6 11  0  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 30.  8.  6. 10.  8.  6.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 1.  0. 29. 14.  0.] 
adversary cards in discard: [10. 25.  0.  0.  3.  0.  6.  3.  8.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14 10 10
  6] -> size -> 25 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3. 1. 6.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3 10  1  8  8  6  6 10  3  6 11  0  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 25. 30.  8.  6. 10.  8.  6.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 1.  0. 29. 14.  0.] 
adversary cards in discard: [10. 25.  0.  0.  3.  0.  6.  3.  8.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14 10 10
  6] -> size -> 25 
adversary victory points: 5
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 1.  0. 29. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14.] 
expected returns: [[134.9472 ]
 [129.32513]
 [112.6906 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 29. 14.  0.] 
cards in discard: [10. 25.  0.  0.  3.  0.  6.  3.  8.  3.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14 10 10
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 30.  8.  6. 10.  8.  6.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [6. 6. 3. 1. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3 10  1  8  8  6  6 10  3  6 11  0  8] -> size -> 22 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: buy - action -1
Learning step: 0.045342255383729935
desired expected reward: 95.97765350341797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[129.13412]
 [138.12773]
 [133.36267]
 [110.3289 ]
 [133.65092]
 [141.29913]
 [136.13007]
 [136.67244]
 [118.25208]
 [131.8754 ]
 [127.54224]
 [140.82222]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 29. 14.  0.] 
cards in discard: [10. 25.  0.  0.  3.  0.  6.  3.  8.  3.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14 10 10
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 28. 30. 25. 30.  8.  6. 10.  8.  6.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [6. 6. 3. 1. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3 10  1  8  8  6  6 10  3  6 11  0  8] -> size -> 22 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: take_action - action -1.0
Learning step: -1.7744697332382202
desired expected reward: 133.17274475097656



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [6. 6. 3. 1. 6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3 10  1  8  8  6  6 10  3  6 11  0  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 30.  8.  6. 10.  8.  6.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [10. 10.  3.  0.  0.] 
adversary cards in discard: [10. 25.  0.  0.  3.  0.  6.  3.  8.  3.  0.  3.  1.  0. 29. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14 10 10
  6] -> size -> 25 
adversary victory points: 5
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [6. 6. 3. 1. 6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 11  3 10  1  8  8  6  6 10  3  6 11  0  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 30.  8.  6. 10.  8.  6.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [10. 10.  3.  0.  0.] 
adversary cards in discard: [10. 25.  0.  0.  3.  0.  6.  3.  8.  3.  0.  3.  1.  0. 29. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14 10 10
  6] -> size -> 25 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [6. 6. 3. 1. 6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 11  3 10  1  8  8  6  6 10  3  6 11  0  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 25. 30.  8.  6. 10.  8.  6.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [10. 10.  3.  0.  0.] 
adversary cards in discard: [10. 25.  0.  0.  3.  0.  6.  3.  8.  3.  0.  3.  1.  0. 29. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14 10 10
  6] -> size -> 25 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [6. 6. 3. 1. 6. 8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 11  3 10  1  8  8  6  6 10  3  6 11  0  8  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 30.  8.  6. 10.  8.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [10. 10.  3.  0.  0.] 
adversary cards in discard: [10. 25.  0.  0.  3.  0.  6.  3.  8.  3.  0.  3.  1.  0. 29. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14 10 10
  6] -> size -> 25 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [10. 10.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[21.999987]
 [14.912191]
 [14.912191]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3.  0.  0.] 
cards in discard: [10. 25.  0.  0.  3.  0.  6.  3.  8.  3.  0.  3.  1.  0. 29. 14.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14 10 10
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 30.  8.  6. 10.  8.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 3.] 
adversary cards in discard: [6. 6. 3. 1. 6. 8. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3 11  3 10  1  8  8  6  6 10  3  6 11  0  8  8] -> size -> 21 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: buy - action -1.0
Learning step: -4.144935607910156
desired expected reward: 136.67727661132812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[15.881081]
 [19.39664 ]
 [11.784328]
 [20.36435 ]
 [25.208838]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  3.  0.  0.] 
cards in discard: [10. 25.  0.  0.  3.  0.  6.  3.  8.  3.  0.  3.  1.  0. 29. 14.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14 10 10
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 25. 30.  8.  6. 10.  8.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 3.] 
adversary cards in discard: [6. 6. 3. 1. 6. 8. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3 11  3 10  1  8  8  6  6 10  3  6 11  0  8  8] -> size -> 21 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: take_action - action -1.0
Learning step: 1.8274548053741455
desired expected reward: 23.827438354492188



buy possibilites: [-1] 
expected returns: [[92.44507]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  3.  0.  0.] 
cards in discard: [10. 25.  0.  0.  3.  0.  6.  3.  8.  3.  0.  3.  1.  0. 29. 14.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14 10 10
  6  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 28. 30. 25. 30.  8.  6. 10.  8.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 3.] 
adversary cards in discard: [6. 6. 3. 1. 6. 8. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3 11  3 10  1  8  8  6  6 10  3  6 11  0  8  8] -> size -> 21 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5.   0.   5.  50.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 20.0 

action type: buy - action 0.0
Learning step: 2.2859606742858887
desired expected reward: 18.167030334472656






Player: 1 
cards in hand: [0. 8. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 3. 3.] 
cards in discard: [6. 6. 3. 1. 6. 8. 8. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11  3 10  1  8  8  6  6 10  3  6 11  0  8  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  6. 10.  8.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14 10 10
  6  0] -> size -> 26 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 3. 3.] 
cards in discard: [6. 6. 3. 1. 6. 8. 8. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11  3 10  1  8  8  6  6 10  3  6 11  0  8  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 25. 30.  8.  6. 10.  8.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14 10 10
  6  0] -> size -> 26 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 3. 3.] 
cards in discard: [6. 6. 3. 1. 6. 8. 8. 0. 0. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11  3 10  1  8  8  6  6 10  3  6 11  0  8  8  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8.  6. 10.  8.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14 10 10
  6  0] -> size -> 26 
adversary victory points: 5
player victory points: 1 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[85.148506]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14 10 10
  6  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8.  6. 10.  8.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 8. 11. 10.  0. 10.] 
adversary cards in discard: [6. 6. 3. 1. 6. 8. 8. 0. 0. 3. 0. 8. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3 11  3 10  1  8  8  6  6 10  3  6 11  0  8  8  3] -> size -> 22 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: buy - action -1
Learning step: -0.8422653079032898
desired expected reward: 91.6028060913086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[66.18143]
 [74.91906]
 [72.35254]
 [49.19581]
 [81.48858]
 [72.49866]
 [71.47492]
 [85.1285 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14 10 10
  6  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 24. 30.  8.  6. 10.  8.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 8. 11. 10.  0. 10.] 
adversary cards in discard: [6. 6. 3. 1. 6. 8. 8. 0. 0. 3. 0. 8. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3 11  3 10  1  8  8  6  6 10  3  6 11  0  8  8  3] -> size -> 22 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: take_action - action -1.0
Learning step: -0.3219284117221832
desired expected reward: 78.78866577148438



buy possibilites: [-1] 
expected returns: [[98.52229]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14 10 10
  6  0 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8.  6. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 8. 11. 10.  0. 10.] 
adversary cards in discard: [6. 6. 3. 1. 6. 8. 8. 0. 0. 3. 0. 8. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3 11  3 10  1  8  8  6  6 10  3  6 11  0  8  8  3] -> size -> 22 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 58 

action type: buy - action 11.0
Learning step: 1.0423225164413452
desired expected reward: 82.53089141845703






Player: 1 
cards in hand: [ 8. 11. 10.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 10.  0. 10.] 
cards in discard: [6. 6. 3. 1. 6. 8. 8. 0. 0. 3. 0. 8. 0. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 11  3 10  1  8  8  6  6 10  3  6 11  0  8  8  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8.  6. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 25.  0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14 10 10
  6  0 11] -> size -> 27 
adversary victory points: 5
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.] 
cards in discard: [6. 6. 3. 1. 6. 8. 8. 0. 0. 3. 0. 8. 0. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 10  1  8  8  6  6 10  3  6 11  0  8  8  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8.  6. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 25.  0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14 10 10
  6  0 11] -> size -> 27 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.] 
cards in discard: [6. 6. 3. 1. 6. 8. 8. 0. 0. 3. 0. 8. 0. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 10  1  8  8  6  6 10  3  6 11  0  8  8  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 24. 30.  8.  6. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 25.  0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14 10 10
  6  0 11] -> size -> 27 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.] 
cards in discard: [6. 6. 3. 1. 6. 8. 8. 0. 0. 3. 0. 8. 0. 3. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 10  1  8  8  6  6 10  3  6 11  0  8  8  3  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 24. 30.  8.  6. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 25.  0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14 10 10
  6  0 11] -> size -> 27 
adversary victory points: 5
player victory points: 1 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[111.076904]
 [112.33294 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 25.  0.] 
cards in discard: [11.  0.  3.  0.  0.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14 10 10
  6  0 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 24. 30.  8.  6. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 6.  0.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  1  8  8  6  6 10  3  6 11  0  8  8  3  0] -> size -> 22 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: buy - action -1
Learning step: -0.46556398272514343
desired expected reward: 98.05673217773438



action possibilites: [-1] 
expected returns: [[70.57716]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0.  6. 29.] 
cards in discard: [11.  0.  3.  0.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14 10 10
  6  0 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 24. 30.  8.  5. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 6.  0.  3.  0. 11.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  1  8  8  6  6 10  3  6 11  0  8  8  3  0  6] -> size -> 23 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 60 

action type: take_action - action 25.0
Learning step: -0.8941013216972351
desired expected reward: 108.74764251708984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[58.136078]
 [64.7484  ]
 [63.3248  ]
 [48.15084 ]
 [70.535355]
 [62.698135]
 [62.58999 ]
 [74.08263 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0.  6. 29.] 
cards in discard: [11.  0.  3.  0.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14 10 10
  6  0 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 28. 30. 24. 30.  8.  5. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 6.  0.  3.  0. 11.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  1  8  8  6  6 10  3  6 11  0  8  8  3  0  6] -> size -> 23 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 60 

action type: take_action - action -1
Learning step: 0.9069118499755859
desired expected reward: 71.48407745361328



buy possibilites: [-1] 
expected returns: [[104.247604]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0.  6. 29.] 
cards in discard: [11.  0.  3.  0.  0.  3.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14 10 10
  6  0 11  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 24. 30.  8.  5. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 6.  0.  3.  0. 11.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  1  8  8  6  6 10  3  6 11  0  8  8  3  0  6] -> size -> 23 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 78 

action type: buy - action 1.0
Learning step: 3.008150815963745
desired expected reward: 67.75655364990234






Player: 1 
cards in hand: [ 6.  0.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3.  0. 11.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  1  8  8  6  6 10  3  6 11  0  8  8  3  0  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 24. 30.  8.  5. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [8. 0. 1. 3. 0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.  1. 25.  0.  0.  3.  0.  6. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14 10 10
  6  0 11  1] -> size -> 28 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  3.  0. 11.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  1  8  8  6  6 10  3  6 11  0  8  8  3  0  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 27. 30. 24. 30.  8.  5. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [8. 0. 1. 3. 0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.  1. 25.  0.  0.  3.  0.  6. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14 10 10
  6  0 11  1] -> size -> 28 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  3.  0. 11.] 
cards in discard: [6. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  1  8  8  6  6 10  3  6 11  0  8  8  3  0  6  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 27. 30. 24. 30.  8.  5. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [8. 0. 1. 3. 0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.  1. 25.  0.  0.  3.  0.  6. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14 10 10
  6  0 11  1] -> size -> 28 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [8. 0. 1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[115.31741]
 [103.1156 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 1. 3. 0.] 
cards in discard: [11.  0.  3.  0.  0.  3.  1. 25.  0.  0.  3.  0.  6. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  0  0 25  3  8  1  3  3  0 10 14 10 10
  6  0 11  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 24. 30.  8.  5. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [6. 3. 0. 1. 8.] 
adversary cards in discard: [ 6.  0.  6.  0.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  1  8  8  6  6 10  3  6 11  0  8  8  3  0  6  0] -> size -> 24 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: buy - action -1
Learning step: -0.24533462524414062
desired expected reward: 104.00227355957031



action possibilites: [-1] 
expected returns: [[101.87938]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [11.  0.  3.  0.  0.  3.  1. 25.  0.  0.  3.  0.  6. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 29  0  0 25  3  8  3  3  0 10 14 10 10  6  0 11
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 24. 30.  8.  5. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [6. 3. 0. 1. 8.] 
adversary cards in discard: [ 6.  0.  6.  0.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  1  8  8  6  6 10  3  6 11  0  8  8  3  0  6  0] -> size -> 24 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 59 

action type: trash_cards_n_from_hand - action 9
Learning step: -0.19246406853199005
desired expected reward: 109.22481536865234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 81.19218 ]
 [ 62.192604]
 [105.45125 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [11.  0.  3.  0.  0.  3.  1. 25.  0.  0.  3.  0.  6. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 29  0  0 25  3  8  3  3  0 10 14 10 10  6  0 11
  1] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 27. 30. 24. 30.  8.  5. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [6. 3. 0. 1. 8.] 
adversary cards in discard: [ 6.  0.  6.  0.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  1  8  8  6  6 10  3  6 11  0  8  8  3  0  6  0] -> size -> 24 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 59 

action type: take_action - action -1
Learning step: -0.24201050400733948
desired expected reward: 101.63736724853516






Player: 1 
cards in hand: [6. 3. 0. 1. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 1. 8.] 
cards in discard: [ 6.  0.  6.  0.  3.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  1  8  8  6  6 10  3  6 11  0  8  8  3  0  6  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 24. 30.  8.  5. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [14. 10.  0.  3. 10.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.  1. 25.  0.  0.  3.  0.  6. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29  0  0 25  3  8  3  3  0 10 14 10 10  6  0 11
  1] -> size -> 25 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 1. 8.] 
cards in discard: [ 6.  0.  6.  0.  3.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  1  8  8  6  6 10  3  6 11  0  8  8  3  0  6  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 27. 30. 24. 30.  8.  5. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [14. 10.  0.  3. 10.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.  1. 25.  0.  0.  3.  0.  6. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29  0  0 25  3  8  3  3  0 10 14 10 10  6  0 11
  1] -> size -> 25 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 1. 8.] 
cards in discard: [ 6.  0.  6.  0.  3.  0. 11.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  1  8  8  6  6 10  3  6 11  0  8  8  3  0  6  0
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 23. 30.  8.  5. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [14. 10.  0.  3. 10.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.  1. 25.  0.  0.  3.  0.  6. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29  0  0 25  3  8  3  3  0 10 14 10 10  6  0 11
  1] -> size -> 25 
adversary victory points: 4
player victory points: 1 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [14. 10.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10. 10.] 
expected returns: [[47.216465]
 [21.206007]
 [34.551697]
 [34.551697]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 10.  0.  3. 10.] 
cards in discard: [11.  0.  3.  0.  0.  3.  1. 25.  0.  0.  3.  0.  6. 29.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 29  0  0 25  3  8  3  3  0 10 14 10 10  6  0 11
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 23. 30.  8.  5. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 8.  0. 10.  3.  0.] 
adversary cards in discard: [ 6.  0.  6.  0.  3.  0. 11.  3.  6.  3.  0.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  1  8  8  6  6 10  3  6 11  0  8  8  3  0  6  0
  3] -> size -> 25 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: buy - action -1.0
Learning step: -3.02862811088562
desired expected reward: 102.42265319824219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[30.600004]
 [15.997259]
 [46.261562]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 10.  0.  3. 10.] 
cards in discard: [11.  0.  3.  0.  0.  3.  1. 25.  0.  0.  3.  0.  6. 29.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 29  0  0 25  3  8  3  3  0 10 14 10 10  6  0 11
  1] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 27. 30. 23. 30.  8.  5. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 8.  0. 10.  3.  0.] 
adversary cards in discard: [ 6.  0.  6.  0.  3.  0. 11.  3.  6.  3.  0.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  1  8  8  6  6 10  3  6 11  0  8  8  3  0  6  0
  3] -> size -> 25 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: take_action - action -1.0
Learning step: -0.19010639190673828
desired expected reward: 47.02635192871094



buy possibilites: [-1] 
expected returns: [[71.549644]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 10.  0.  3. 10.] 
cards in discard: [11.  0.  3.  0.  0.  3.  1. 25.  0.  0.  3.  0.  6. 29.  8.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 29  0  0 25  3  8  3  3  0 10 14 10 10  6  0 11
  1  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 23. 30.  8.  5. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 8.  0. 10.  3.  0.] 
adversary cards in discard: [ 6.  0.  6.  0.  3.  0. 11.  3.  6.  3.  0.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10  1  8  8  6  6 10  3  6 11  0  8  8  3  0  6  0
  3] -> size -> 25 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4.  30.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -1.0 

action type: buy - action 0.0
Learning step: 0.029866887256503105
desired expected reward: 30.629867553710938






Player: 1 
cards in hand: [ 8.  0. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  3.  0.] 
cards in discard: [ 6.  0.  6.  0.  3.  0. 11.  3.  6.  3.  0.  1.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10  1  8  8  6  6 10  3  6 11  0  8  8  3  0  6  0
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 23. 30.  8.  5. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [29.  0.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29  0  0 25  3  8  3  3  0 10 14 10 10  6  0 11
  1  0] -> size -> 26 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 6.  0.  6.  0.  3.  0. 11.  3.  6.  3.  0.  1.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  1  8  8  6  6 10  3  6 11  0  8  8  3  0  6  0  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 23. 30.  8.  5. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [29.  0.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29  0  0 25  3  8  3  3  0 10 14 10 10  6  0 11
  1  0] -> size -> 26 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 6.  0.  6.  0.  3.  0. 11.  3.  6.  3.  0.  1.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  1  8  8  6  6 10  3  6 11  0  8  8  3  0  6  0  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 27. 30. 23. 30.  8.  5. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [29.  0.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29  0  0 25  3  8  3  3  0 10 14 10 10  6  0 11
  1  0] -> size -> 26 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 6.  0.  6.  0.  3.  0. 11.  3.  6.  3.  0.  1.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  1  8  8  6  6 10  3  6 11  0  8  8  3  0  6  0  3  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 27. 30. 23. 30.  8.  5. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [29.  0.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29  0  0 25  3  8  3  3  0 10 14 10 10  6  0 11
  1  0] -> size -> 26 
adversary victory points: 4
player victory points: 0 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [29.  0.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[128.79257 ]
 [121.05634 ]
 [117.398155]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 10.  3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 29  0  0 25  3  8  3  3  0 10 14 10 10  6  0 11
  1  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 23. 30.  8.  5. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [6. 0. 3. 8. 0.] 
adversary cards in discard: [ 6.  0.  6.  0.  3.  0. 11.  3.  6.  3.  0.  1.  8.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  1  8  8  6  6 10  3  6 11  0  8  8  3  0  6  0  3  0] -> size -> 23 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: buy - action -1
Learning step: 1.0180240869522095
desired expected reward: 72.56766510009766



action possibilites: [-1. 29.] 
expected returns: [[119.733246]
 [110.19416 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 29  0  0 25  3  8  3  3  0 10 14 10 10  6  0 11
  1  0] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 23. 30.  8.  5. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [6. 0. 3. 8. 0.] 
adversary cards in discard: [ 6.  0.  6.  0.  3.  0. 11.  3.  6.  3.  0.  1.  8.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  1  8  8  6  6 10  3  6 11  0  8  8  3  0  6  0  3  0] -> size -> 23 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 60 

action type: take_action - action 10.0
Learning step: -0.025519181042909622
desired expected reward: 112.36979675292969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[110.66193 ]
 [118.84147 ]
 [116.12234 ]
 [ 94.36451 ]
 [124.433205]
 [116.79909 ]
 [115.366104]
 [127.23118 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 29  0  0 25  3  8  3  3  0 10 14 10 10  6  0 11
  1  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 27. 30. 23. 30.  8.  5. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [6. 0. 3. 8. 0.] 
adversary cards in discard: [ 6.  0.  6.  0.  3.  0. 11.  3.  6.  3.  0.  1.  8.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  1  8  8  6  6 10  3  6 11  0  8  8  3  0  6  0  3  0] -> size -> 23 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 59 

action type: take_action - action -1.0
Learning step: -0.4197807312011719
desired expected reward: 119.31346130371094



buy possibilites: [-1] 
expected returns: [[156.02783]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  3.  0.] 
cards in discard: [3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 29  0  0 25  3  8  3  3  0 10 14 10 10  6  0 11
  1  0  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 27. 30. 22. 30.  8.  5. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [6. 0. 3. 8. 0.] 
adversary cards in discard: [ 6.  0.  6.  0.  3.  0. 11.  3.  6.  3.  0.  1.  8.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  1  8  8  6  6 10  3  6 11  0  8  8  3  0  6  0  3  0] -> size -> 23 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5.  0.  5. 50.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 72.0 

action type: buy - action 3.0
Learning step: 1.3045090436935425
desired expected reward: 117.4268569946289






Player: 1 
cards in hand: [6. 0. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 8. 0.] 
cards in discard: [ 6.  0.  6.  0.  3.  0. 11.  3.  6.  3.  0.  1.  8.  0.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1  8  8  6  6 10  3  6 11  0  8  8  3  0  6  0  3  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 22. 30.  8.  5. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  8.  0. 14. 11.] 
adversary cards in discard: [ 3. 10. 29.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29  0  0 25  3  8  3  3  0 10 14 10 10  6  0 11
  1  0  3] -> size -> 27 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 8. 0.] 
cards in discard: [ 6.  0.  6.  0.  3.  0. 11.  3.  6.  3.  0.  1.  8.  0.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1  8  8  6  6 10  3  6 11  0  8  8  3  0  6  0  3  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 27. 30. 22. 30.  8.  5. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  8.  0. 14. 11.] 
adversary cards in discard: [ 3. 10. 29.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29  0  0 25  3  8  3  3  0 10 14 10 10  6  0 11
  1  0  3] -> size -> 27 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 8. 0.] 
cards in discard: [ 6.  0.  6.  0.  3.  0. 11.  3.  6.  3.  0.  1.  8.  0.  8.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1  8  8  6  6 10  3  6 11  0  8  8  3  0  6  0  3  0  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 21. 30.  8.  5. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  8.  0. 14. 11.] 
adversary cards in discard: [ 3. 10. 29.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29  0  0 25  3  8  3  3  0 10 14 10 10  6  0 11
  1  0  3] -> size -> 27 
adversary victory points: 5
player victory points: 1 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 3.  8.  0. 14. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 11.] 
expected returns: [[51.949493]
 [43.612328]
 [32.06369 ]
 [49.370975]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0. 14. 11.] 
cards in discard: [ 3. 10. 29.  0.  0.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 29  0  0 25  3  8  3  3  0 10 14 10 10  6  0 11
  1  0  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 21. 30.  8.  5. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  1  8  8  6  6 10  3  6 11  0  8  8  3  0  6  0  3  0  3] -> size -> 24 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: buy - action -1
Learning step: -4.822577953338623
desired expected reward: 151.20526123046875



action possibilites: [-1] 
expected returns: [[65.394844]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.] 
cards in discard: [ 3. 10. 29.  0.  0.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 29  0  0 25  3  8  3  3  0 10 14 10 10  6  0  1  0  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 21. 30.  8.  5. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  1  8  8  6  6 10  3  6 11  0  8  8  3  0  6  0  3  0  3] -> size -> 24 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 49 

action type: trash_cards_n_from_hand - action 10
Learning step: 1.8392301797866821
desired expected reward: 43.48230743408203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[59.23681 ]
 [45.1118  ]
 [71.187325]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.] 
cards in discard: [ 3. 10. 29.  0.  0.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 29  0  0 25  3  8  3  3  0 10 14 10 10  6  0  1  0  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 27. 30. 21. 30.  8.  5. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  1  8  8  6  6 10  3  6 11  0  8  8  3  0  6  0  3  0  3] -> size -> 24 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 49 

action type: take_action - action -1
Learning step: 0.5168769955635071
desired expected reward: 65.9117202758789



buy possibilites: [-1] 
expected returns: [[21.201107]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.] 
cards in discard: [ 3. 10. 29.  0.  0.  3.  0.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 29  0  0 25  3  8  3  3  0 10 14 10 10  6  0  1  0  3
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 21. 30.  8.  4. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  1  8  8  6  6 10  3  6 11  0  8  8  3  0  6  0  3  0  3] -> size -> 24 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[  -5    0    3   20    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -262 

action type: buy - action 6.0
Learning step: -14.878564834594727
desired expected reward: 30.233213424682617






Player: 1 
cards in hand: [ 3.  3.  0.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  8. 10.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1  8  8  6  6 10  3  6 11  0  8  8  3  0  6  0  3  0  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 21. 30.  8.  4. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  3. 10.  0.  0.] 
adversary cards in discard: [ 3. 10. 29.  0.  0.  3.  0.  6.  8. 14.] 
adversary owned cards: [ 0  0  0  0  0  3 29  0  0 25  3  8  3  3  0 10 14 10 10  6  0  1  0  3
  6] -> size -> 25 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  1  8  8  6  6 10  6 11  0  8  8  3  0  6  0  3  0  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 21. 30.  8.  4. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  3. 10.  0.  0.] 
adversary cards in discard: [ 3. 10. 29.  0.  0.  3.  0.  6.  8. 14.] 
adversary owned cards: [ 0  0  0  0  0  3 29  0  0 25  3  8  3  3  0 10 14 10 10  6  0  1  0  3
  6] -> size -> 25 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  1  8  8  6  6 10  6 11  0  8  8  3  0  6  0  3  0  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 27. 30. 21. 30.  8.  4. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  3. 10.  0.  0.] 
adversary cards in discard: [ 3. 10. 29.  0.  0.  3.  0.  6.  8. 14.] 
adversary owned cards: [ 0  0  0  0  0  3 29  0  0 25  3  8  3  3  0 10 14 10 10  6  0  1  0  3
  6] -> size -> 25 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 3.  3. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[39.168488]
 [29.25466 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.  0.  0.] 
cards in discard: [ 3. 10. 29.  0.  0.  3.  0.  6.  8. 14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29  0  0 25  3  8  3  3  0 10 14 10 10  6  0  1  0  3
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 21. 30.  8.  4. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [8. 0. 6. 0. 6.] 
adversary cards in discard: [ 8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  1  8  8  6  6 10  6 11  0  8  8  3  0  6  0  3  0  3] -> size -> 22 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: buy - action -1
Learning step: 1.6109068393707275
desired expected reward: 22.812013626098633





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[25.44389 ]
 [29.548212]
 [15.371407]
 [29.962576]
 [37.99718 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.  0.  0.] 
cards in discard: [ 3. 10. 29.  0.  0.  3.  0.  6.  8. 14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29  0  0 25  3  8  3  3  0 10 14 10 10  6  0  1  0  3
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 27. 30. 21. 30.  8.  4. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [8. 0. 6. 0. 6.] 
adversary cards in discard: [ 8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  1  8  8  6  6 10  6 11  0  8  8  3  0  6  0  3  0  3] -> size -> 22 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: take_action - action -1.0
Learning step: 0.5960235595703125
desired expected reward: 39.45233917236328



buy possibilites: [-1] 
expected returns: [[34.54553]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.  0.  0.] 
cards in discard: [ 3. 10. 29.  0.  0.  3.  0.  6.  8. 14.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29  0  0 25  3  8  3  3  0 10 14 10 10  6  0  1  0  3
  6  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 27. 30. 21. 30.  8.  3. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [8. 0. 6. 0. 6.] 
adversary cards in discard: [ 8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  1  8  8  6  6 10  6 11  0  8  8  3  0  6  0  3  0  3] -> size -> 22 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.   30.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -273.0 

action type: buy - action 6.0
Learning step: -13.645835876464844
desired expected reward: 1.7255859375






Player: 1 
cards in hand: [8. 0. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 0. 6.] 
cards in discard: [ 8.  0. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  1  8  8  6  6 10  6 11  0  8  8  3  0  6  0  3  0  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 21. 30.  8.  3. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [25.  0.  0.  0.  0.] 
adversary cards in discard: [ 3. 10. 29.  0.  0.  3.  0.  6.  8. 14.  6.  3.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29  0  0 25  3  8  3  3  0 10 14 10 10  6  0  1  0  3
  6  6] -> size -> 26 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 8.  0. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  1  8  8  6 10  6 11  0  8  8  3  0  6  0  3  0  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 21. 30.  8.  3. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [25.  0.  0.  0.  0.] 
adversary cards in discard: [ 3. 10. 29.  0.  0.  3.  0.  6.  8. 14.  6.  3.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29  0  0 25  3  8  3  3  0 10 14 10 10  6  0  1  0  3
  6  6] -> size -> 26 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 8.  0. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  1  8  8  6 10  6 11  0  8  8  3  0  6  0  3  0  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 27. 30. 21. 30.  8.  3. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [25.  0.  0.  0.  0.] 
adversary cards in discard: [ 3. 10. 29.  0.  0.  3.  0.  6.  8. 14.  6.  3.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29  0  0 25  3  8  3  3  0 10 14 10 10  6  0  1  0  3
  6  6] -> size -> 26 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 8.  0. 10.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  1  8  8  6 10  6 11  0  8  8  3  0  6  0  3  0  3  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 21. 30.  8.  3. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [25.  0.  0.  0.  0.] 
adversary cards in discard: [ 3. 10. 29.  0.  0.  3.  0.  6.  8. 14.  6.  3.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29  0  0 25  3  8  3  3  0 10 14 10 10  6  0  1  0  3
  6  6] -> size -> 26 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [25.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[45.102604]
 [47.85973 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.  0.  0.] 
cards in discard: [ 3. 10. 29.  0.  0.  3.  0.  6.  8. 14.  6.  3.  3. 10.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29  0  0 25  3  8  3  3  0 10 14 10 10  6  0  1  0  3
  6  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 21. 30.  8.  3. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [11.  0.  6.  6.  8.] 
adversary cards in discard: [ 8.  0. 10.  0.  8.  6.] 
adversary owned cards: [ 0  0  1  8  8  6 10  6 11  0  8  8  3  0  6  0  3  0  3  0] -> size -> 20 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1
Learning step: 0.17073574662208557
desired expected reward: 34.71626281738281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[29.197865]
 [35.333057]
 [33.71382 ]
 [17.313364]
 [32.41355 ]
 [39.78204 ]
 [33.509613]
 [34.534374]
 [23.450546]
 [32.851593]
 [29.98562 ]
 [41.89858 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0.  0.  0.] 
cards in discard: [ 3. 10. 29.  0.  0.  3.  0.  6.  8. 14.  6.  3.  3. 10.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29  0  0 25  3  8  3  3  0 10 14 10 10  6  0  1  0  3
  6  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 27. 30. 21. 30.  8.  3. 10.  7.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [11.  0.  6.  6.  8.] 
adversary cards in discard: [ 8.  0. 10.  0.  8.  6.] 
adversary owned cards: [ 0  0  1  8  8  6 10  6 11  0  8  8  3  0  6  0  3  0  3  0] -> size -> 20 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -0.6694620251655579
desired expected reward: 44.43315124511719



buy possibilites: [-1] 
expected returns: [[30.901342]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0.  0.  0.] 
cards in discard: [ 3. 10. 29.  0.  0.  3.  0.  6.  8. 14.  6.  3.  3. 10.  0.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29  0  0 25  3  8  3  3  0 10 14 10 10  6  0  1  0  3
  6  6  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 27. 30. 21. 30.  8.  3. 10.  7.  4.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [11.  0.  6.  6.  8.] 
adversary cards in discard: [ 8.  0. 10.  0.  8.  6.] 
adversary owned cards: [ 0  0  1  8  8  6 10  6 11  0  8  8  3  0  6  0  3  0  3  0] -> size -> 20 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5.  0.  2. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 19.0 

action type: buy - action 8.0
Learning step: -0.030200768262147903
desired expected reward: 33.47941589355469






Player: 1 
cards in hand: [11.  0.  6.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6.  6.  8.] 
cards in discard: [ 8.  0. 10.  0.  8.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1  8  8  6 10  6 11  0  8  8  3  0  6  0  3  0  3  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 21. 30.  8.  3. 10.  7.  4.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  6.  1.] 
adversary cards in discard: [ 3. 10. 29.  0.  0.  3.  0.  6.  8. 14.  6.  3.  3. 10.  0.  0.  8. 25.
  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29  0  0 25  3  8  3  3  0 10 14 10 10  6  0  1  0  3
  6  6  8] -> size -> 27 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  6.  6.  8.] 
cards in discard: [ 8.  0. 10.  0.  8.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1  8  8  6 10  6 11  0  8  8  3  0  6  0  3  0  3  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 27. 30. 21. 30.  8.  3. 10.  7.  4.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  6.  1.] 
adversary cards in discard: [ 3. 10. 29.  0.  0.  3.  0.  6.  8. 14.  6.  3.  3. 10.  0.  0.  8. 25.
  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29  0  0 25  3  8  3  3  0 10 14 10 10  6  0  1  0  3
  6  6  8] -> size -> 27 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  6.  6.  8.] 
cards in discard: [ 8.  0. 10.  0.  8.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1  8  8  6 10  6 11  0  8  8  3  0  6  0  3  0  3  0  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 27. 30. 21. 30.  8.  3. 10.  7.  4.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  6.  1.] 
adversary cards in discard: [ 3. 10. 29.  0.  0.  3.  0.  6.  8. 14.  6.  3.  3. 10.  0.  0.  8. 25.
  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29  0  0 25  3  8  3  3  0 10 14 10 10  6  0  1  0  3
  6  6  8] -> size -> 27 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 10.  6.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[62.00697 ]
 [47.845535]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  6.  1.] 
cards in discard: [ 3. 10. 29.  0.  0.  3.  0.  6.  8. 14.  6.  3.  3. 10.  0.  0.  8. 25.
  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29  0  0 25  3  8  3  3  0 10 14 10 10  6  0  1  0  3
  6  6  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 21. 30.  8.  3. 10.  7.  4.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 8. 3. 3.] 
adversary cards in discard: [ 8.  0. 10.  0.  8.  6.  0. 11.  0.  6.  6.  8.] 
adversary owned cards: [ 0  0  1  8  8  6 10  6 11  0  8  8  3  0  6  0  3  0  3  0  0] -> size -> 21 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1
Learning step: 0.5520016551017761
desired expected reward: 31.453344345092773





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[43.2994  ]
 [50.10726 ]
 [48.44202 ]
 [29.254452]
 [55.453083]
 [47.934204]
 [47.192883]
 [58.685654]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  6.  1.] 
cards in discard: [ 3. 10. 29.  0.  0.  3.  0.  6.  8. 14.  6.  3.  3. 10.  0.  0.  8. 25.
  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29  0  0 25  3  8  3  3  0 10 14 10 10  6  0  1  0  3
  6  6  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 27. 30. 21. 30.  8.  3. 10.  7.  4.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 8. 3. 3.] 
adversary cards in discard: [ 8.  0. 10.  0.  8.  6.  0. 11.  0.  6.  6.  8.] 
adversary owned cards: [ 0  0  1  8  8  6 10  6 11  0  8  8  3  0  6  0  3  0  3  0  0] -> size -> 21 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -1.1628965139389038
desired expected reward: 60.84407424926758



buy possibilites: [-1] 
expected returns: [[109.80832]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  6.  1.] 
cards in discard: [ 3. 10. 29.  0.  0.  3.  0.  6.  8. 14.  6.  3.  3. 10.  0.  0.  8. 25.
  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29  0  0 25  3  8  3  3  0 10 14 10 10  6  0  1  0  3
  6  6  8  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 3 
card supply: [18. 27. 30. 21. 30.  8.  3. 10.  7.  4.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 8. 3. 3.] 
adversary cards in discard: [ 8.  0. 10.  0.  8.  6.  0. 11.  0.  6.  6.  8.] 
adversary owned cards: [ 0  0  1  8  8  6 10  6 11  0  8  8  3  0  6  0  3  0  3  0  0] -> size -> 21 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2.  20.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -13.0 

action type: buy - action 0.0
Learning step: -0.34428292512893677
desired expected reward: 42.955116271972656






Player: 1 
cards in hand: [0. 3. 8. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 3. 3.] 
cards in discard: [ 8.  0. 10.  0.  8.  6.  0. 11.  0.  6.  6.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1  8  8  6 10  6 11  0  8  8  3  0  6  0  3  0  3  0  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 21. 30.  8.  3. 10.  7.  4.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [10. 14.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 29  0  0 25  3  8  3  3  0 10 14 10 10  6  0  1  0  3
  6  6  8  0] -> size -> 28 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 8.  0. 10.  0.  8.  6.  0. 11.  0.  6.  6.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  1  8  8  6 10  6 11  0  8  8  0  6  0  0  3  0  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 21. 30.  8.  3. 10.  7.  4.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [10. 14.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 29  0  0 25  3  8  3  3  0 10 14 10 10  6  0  1  0  3
  6  6  8  0] -> size -> 28 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 8.  0. 10.  0.  8.  6.  0. 11.  0.  6.  6.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  1  8  8  6 10  6 11  0  8  8  0  6  0  0  3  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 27. 30. 21. 30.  8.  3. 10.  7.  4.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [10. 14.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 29  0  0 25  3  8  3  3  0 10 14 10 10  6  0  1  0  3
  6  6  8  0] -> size -> 28 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 8.  0. 10.  0.  8.  6.  0. 11.  0.  6.  6.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  1  8  8  6 10  6 11  0  8  8  0  6  0  0  3  0  0  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 21. 30.  8.  3. 10.  7.  4.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [10. 14.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 29  0  0 25  3  8  3  3  0 10 14 10 10  6  0  1  0  3
  6  6  8  0] -> size -> 28 
adversary victory points: 2
player victory points: -2 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [10. 14.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.  8.] 
expected returns: [[70.39928 ]
 [59.60318 ]
 [47.797714]
 [60.681576]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 14.  0.  3.  8.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29  0  0 25  3  8  3  3  0 10 14 10 10  6  0  1  0  3
  6  6  8  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 21. 30.  8.  3. 10.  7.  4.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1  8  8  6 10  6 11  0  8  8  0  6  0  0  3  0  0  0] -> size -> 19 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  2 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: buy - action -1
Learning step: -2.40368390083313
desired expected reward: 107.40463256835938



action possibilites: [-1] 
expected returns: [[60.89997]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 21. 30.  8.  3. 10.  7.  4.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1  8  8  6 10  6 11  0  8  8  0  6  0  0  3  0  0  0] -> size -> 19 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  1 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 46 

action type: trash_cards_n_from_hand - action 11
Learning step: 0.7718704342842102
desired expected reward: 58.739444732666016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[50.21988 ]
 [37.585426]
 [60.585484]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 27. 30. 21. 30.  8.  3. 10.  7.  4.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1  8  8  6 10  6 11  0  8  8  0  6  0  0  3  0  0  0] -> size -> 19 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  1 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 46 

action type: take_action - action -1
Learning step: 0.38556861877441406
desired expected reward: 61.28553771972656






Player: 1 
cards in hand: [8. 0. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1  8  8  6 10  6 11  0  8  8  0  6  0  0  3  0  0  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 21. 30.  8.  3. 10.  7.  4.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [8. 6. 0. 0. 0.] 
adversary cards in discard: [ 8. 10.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0] -> size -> 25 
adversary victory points: 1
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1  8  8  6 10  6 11  0  8  8  0  6  0  0  3  0  0  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [17. 27. 30. 21. 30.  8.  3. 10.  7.  4.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [8. 6. 0. 0. 0.] 
adversary cards in discard: [ 8. 10.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0] -> size -> 25 
adversary victory points: 1
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 1.] 
cards in discard: [29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1  8  8  6 10  6 11  0  8  8  0  6  0  0  3  0  0  0 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 27. 30. 21. 30.  8.  3. 10.  7.  4.  9.  8.  8. 10.  5. 10. 10.] 
adversary cards in hand: [8. 6. 0. 0. 0.] 
adversary cards in discard: [ 8. 10.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0] -> size -> 25 
adversary victory points: 1
player victory points: -2 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [8. 6. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[30.950865]
 [23.706604]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0. 0. 0.] 
cards in discard: [ 8. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 21. 30.  8.  3. 10.  7.  4.  9.  8.  8. 10.  5. 10. 10.] 
adversary cards in hand: [11.  8.  0.  0.  8.] 
adversary cards in discard: [29.  8.  0.  0.  0.  1.] 
adversary owned cards: [ 0  1  8  8  6 10  6 11  0  8  8  0  6  0  0  3  0  0  0 29] -> size -> 20 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  1 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: buy - action -1.0
Learning step: -1.2364253997802734
desired expected reward: 59.34906768798828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[23.114412]
 [28.860548]
 [25.733212]
 [15.794665]
 [32.755226]
 [27.678473]
 [24.964203]
 [33.763405]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0. 0. 0.] 
cards in discard: [ 8. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 27. 30. 21. 30.  8.  3. 10.  7.  4.  9.  8.  8. 10.  5. 10. 10.] 
adversary cards in hand: [11.  8.  0.  0.  8.] 
adversary cards in discard: [29.  8.  0.  0.  0.  1.] 
adversary owned cards: [ 0  1  8  8  6 10  6 11  0  8  8  0  6  0  0  3  0  0  0 29] -> size -> 20 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  1 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: take_action - action -1.0
Learning step: 0.6686070561408997
desired expected reward: 25.486549377441406



buy possibilites: [-1] 
expected returns: [[17.138872]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0. 0. 0.] 
cards in discard: [ 8. 10. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 21. 30.  8.  3. 10.  7.  4.  9.  8.  8. 10.  4. 10. 10.] 
adversary cards in hand: [11.  8.  0.  0.  8.] 
adversary cards in discard: [29.  8.  0.  0.  0.  1.] 
adversary owned cards: [ 0  1  8  8  6 10  6 11  0  8  8  0  6  0  0  3  0  0  0 29] -> size -> 20 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  1 30  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 44 

action type: buy - action 10.0
Learning step: 1.3374154567718506
desired expected reward: 26.30160140991211






Player: 1 
cards in hand: [11.  8.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0.  0.  8.] 
cards in discard: [29.  8.  0.  0.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1  8  8  6 10  6 11  0  8  8  0  6  0  0  3  0  0  0 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 21. 30.  8.  3. 10.  7.  4.  9.  8.  8. 10.  4. 10. 10.] 
adversary cards in hand: [3. 6. 0. 1. 0.] 
adversary cards in discard: [ 8. 10. 10.  8.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10] -> size -> 26 
adversary victory points: 1
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [29.  8.  0.  0.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  8  6 10  6  8  8  0  6  0  0  3  0  0  0 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 21. 30.  8.  3. 10.  7.  4.  9.  8.  8. 10.  4. 10. 10.] 
adversary cards in hand: [3. 6. 0. 1. 0.] 
adversary cards in discard: [ 8. 10. 10.  8.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10] -> size -> 26 
adversary victory points: 1
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.  8.  0.  0.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  8  6 10  6  8  8  0  6  0  0  3  0  0  0 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 27. 30. 21. 30.  8.  3. 10.  7.  4.  9.  8.  8. 10.  4. 10. 10.] 
adversary cards in hand: [3. 6. 0. 1. 0.] 
adversary cards in discard: [ 8. 10. 10.  8.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10] -> size -> 26 
adversary victory points: 1
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.  8.  0.  0.  0.  1.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  8  6 10  6  8  8  0  6  0  0  3  0  0  0 29  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  3. 10.  7.  4.  9.  8.  8. 10.  4. 10. 10.] 
adversary cards in hand: [3. 6. 0. 1. 0.] 
adversary cards in discard: [ 8. 10. 10.  8.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10] -> size -> 26 
adversary victory points: 1
player victory points: -2 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [3. 6. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[28.800604]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 1. 0.] 
cards in discard: [ 8. 10. 10.  8.  6.  0.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  3. 10.  7.  4.  9.  8.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  6.  0.] 
adversary cards in discard: [29.  8.  0.  0.  0.  1.  0.  8.] 
adversary owned cards: [ 1  8  6 10  6  8  8  0  6  0  0  3  0  0  0 29  0] -> size -> 17 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  1 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: buy - action -1
Learning step: 1.0513020753860474
desired expected reward: 18.190174102783203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[21.02723 ]
 [23.889292]
 [23.119656]
 [14.03987 ]
 [22.36271 ]
 [27.491707]
 [22.938173]
 [23.50749 ]
 [18.822788]
 [22.957188]
 [21.780836]
 [29.434717]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 1. 0.] 
cards in discard: [ 8. 10. 10.  8.  6.  0.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 27. 30. 21. 30.  8.  3. 10.  7.  4.  9.  8.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  6.  0.] 
adversary cards in discard: [29.  8.  0.  0.  0.  1.  0.  8.] 
adversary owned cards: [ 1  8  6 10  6  8  8  0  6  0  0  3  0  0  0 29  0] -> size -> 17 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  1 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: take_action - action -1.0
Learning step: 0.46797990798950195
desired expected reward: 27.501123428344727



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  0. 10.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  6.  0.] 
cards in discard: [29.  8.  0.  0.  0.  1.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  6 10  6  8  8  0  6  0  0  3  0  0  0 29  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  3. 10.  7.  4.  9.  8.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 10.  3. 29.  3.] 
adversary cards in discard: [ 8. 10. 10.  8.  6.  0.  0.  0.  3.  6.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10] -> size -> 26 
adversary victory points: 1
player victory points: -2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 0. 0.] 
cards in discard: [29.  8.  0.  0.  0.  1.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 1  8  6 10  6  8  8  0  6  0  0  3  0  0  0 29  0] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  3. 10.  7.  4.  9.  8.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 10.  3. 29.  3.] 
adversary cards in discard: [ 8. 10. 10.  8.  6.  0.  0.  0.  3.  6.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10] -> size -> 26 
adversary victory points: 1
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 0.] 
cards in discard: [29.  8.  0.  0.  0.  1.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 1  8  6 10  6  8  8  0  6  0  0  3  0  0  0 29  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 27. 30. 21. 30.  8.  3. 10.  7.  4.  9.  8.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 10.  3. 29.  3.] 
adversary cards in discard: [ 8. 10. 10.  8.  6.  0.  0.  0.  3.  6.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10] -> size -> 26 
adversary victory points: 1
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 0.] 
cards in discard: [29.  8.  0.  0.  0.  1.  0.  8. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 1  8  6 10  6  8  8  0  6  0  0  3  0  0  0 29  0 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  3. 10.  7.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 10.  3. 29.  3.] 
adversary cards in discard: [ 8. 10. 10.  8.  6.  0.  0.  0.  3.  6.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10] -> size -> 26 
adversary victory points: 1
player victory points: -2 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  3. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[116.09749]
 [102.59525]
 [106.89634]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 29.  3.] 
cards in discard: [ 8. 10. 10.  8.  6.  0.  0.  0.  3.  6.  0.  1.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  3. 10.  7.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [29.  0.  6.  8.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8  6 10  6  8  8  0  6  0  0  3  0  0  0 29  0 10] -> size -> 18 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  1 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: buy - action -1.0
Learning step: 2.2013862133026123
desired expected reward: 31.636110305786133





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 91.14345]
 [ 70.28394]
 [109.51948]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3. 29.  3.] 
cards in discard: [ 8. 10. 10.  8.  6.  0.  0.  0.  3.  6.  0.  1.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 27. 30. 21. 30.  8.  3. 10.  7.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [29.  0.  6.  8.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8  6 10  6  8  8  0  6  0  0  3  0  0  0 29  0 10] -> size -> 18 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  1 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: take_action - action -1.0
Learning step: -2.2089157104492188
desired expected reward: 109.22046661376953



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [29.  0.  6.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  6.  8.  6.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8  6 10  6  8  8  0  6  0  0  3  0  0  0 29  0 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  3. 10.  7.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 25.] 
adversary cards in discard: [ 8. 10. 10.  8.  6.  0.  0.  0.  3.  6.  0.  1.  0.  0. 10.  3. 29.  3.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10] -> size -> 26 
adversary victory points: 1
player victory points: -2 


action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  8.  6. 10.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 1  8  6 10  6  8  8  0  6  0  0  3  0  0  0 29  0 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 27. 30. 21. 30.  8.  3. 10.  7.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 25.] 
adversary cards in discard: [ 8. 10. 10.  8.  6.  0.  0.  0.  3.  6.  0.  1.  0.  0. 10.  3. 29.  3.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10] -> size -> 26 
adversary victory points: 1
player victory points: -2 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8. 6. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 1  8  6 10  6  8  8  0  6  0  0  3  0  0  0 29  0 10] -> size -> 18 
action values: 2 
buys: 0 
player value: 1 
card supply: [16. 27. 30. 21. 30.  8.  3. 10.  7.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 25.] 
adversary cards in discard: [ 8. 10. 10.  8.  6.  0.  0.  0.  3.  6.  0.  1.  0.  0. 10.  3. 29.  3.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10] -> size -> 26 
adversary victory points: 1
player victory points: -2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 10.  8.] 
owned cards: [ 1  8 10  6  8  8  6  0  3  0  0  0 29  0 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 27. 30. 21. 30.  8.  3. 10.  7.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 25.] 
adversary cards in discard: [ 8. 10. 10.  8.  6.  0.  0.  0.  3.  6.  0.  1.  0.  0. 10.  3. 29.  3.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10] -> size -> 26 
adversary victory points: 1
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 10.  8.] 
owned cards: [ 1  8 10  6  8  8  6  0  3  0  0  0 29  0 10] -> size -> 15 
action values: 1 
buys: 1 
player value: 1 
card supply: [16. 27. 30. 21. 30.  8.  3. 10.  7.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 25.] 
adversary cards in discard: [ 8. 10. 10.  8.  6.  0.  0.  0.  3.  6.  0.  1.  0.  0. 10.  3. 29.  3.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10] -> size -> 26 
adversary victory points: 1
player victory points: -1 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[-2.6005871]
 [-4.9602976]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 25.] 
cards in discard: [ 8. 10. 10.  8.  6.  0.  0.  0.  3.  6.  0.  1.  0.  0. 10.  3. 29.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  3. 10.  7.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 6. 10.  0.  0.  0.] 
adversary cards in discard: [29. 10.  8.  6.] 
adversary owned cards: [ 1  8 10  6  8  8  6  0  3  0  0  0 29  0 10] -> size -> 15 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  1 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: buy - action -1.0
Learning step: -4.7591633796691895
desired expected reward: 104.76032257080078



action possibilites: [-1] 
expected returns: [[43.011753]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 10.  0.] 
cards in discard: [ 8. 10. 10.  8.  6.  0.  0.  0.  3.  6.  0.  1.  0.  0. 10.  3. 29.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 21. 30.  8.  2. 10.  7.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 6. 10.  0.  0.  0.] 
adversary cards in discard: [29. 10.  8.  6.  6.] 
adversary owned cards: [ 1  8 10  6  8  8  6  0  3  0  0  0 29  0 10  6] -> size -> 16 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  1 20  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 37 

action type: take_action - action 25.0
Learning step: 3.065778970718384
desired expected reward: -1.8945138454437256





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[25.890278]
 [32.14866 ]
 [31.665062]
 [16.97054 ]
 [29.220741]
 [38.079834]
 [29.666317]
 [31.152687]
 [22.10999 ]
 [30.659626]
 [27.853485]
 [41.34879 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 10.  0.] 
cards in discard: [ 8. 10. 10.  8.  6.  0.  0.  0.  3.  6.  0.  1.  0.  0. 10.  3. 29.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 27. 30. 21. 30.  8.  2. 10.  7.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 6. 10.  0.  0.  0.] 
adversary cards in discard: [29. 10.  8.  6.  6.] 
adversary owned cards: [ 1  8 10  6  8  8  6  0  3  0  0  0 29  0 10  6] -> size -> 16 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  1 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 36 

action type: take_action - action -1
Learning step: 0.33677196502685547
desired expected reward: 43.34852600097656



buy possibilites: [-1] 
expected returns: [[21.82869]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 10.  0.] 
cards in discard: [ 8. 10. 10.  8.  6.  0.  0.  0.  3.  6.  0.  1.  0.  0. 10.  3. 29.  3.
  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 26. 30. 21. 30.  8.  2. 10.  7.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 6. 10.  0.  0.  0.] 
adversary cards in discard: [29. 10.  8.  6.  6.] 
adversary owned cards: [ 1  8 10  6  8  8  6  0  3  0  0  0 29  0 10  6] -> size -> 16 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5.   0.   1.  20.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 40.5 

action type: buy - action 1.0
Learning step: 0.9087129831314087
desired expected reward: 33.05736541748047






Player: 1 
cards in hand: [ 6. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.  0.  0.] 
cards in discard: [29. 10.  8.  6.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8 10  6  8  8  6  0  3  0  0  0 29  0 10  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 21. 30.  8.  2. 10.  7.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [1. 0. 3. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10  1] -> size -> 27 
adversary victory points: 1
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0.  0.  0.] 
cards in discard: [29. 10.  8.  6.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8 10  6  8  8  6  0  3  0  0  0 29  0 10  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 26. 30. 21. 30.  8.  2. 10.  7.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [1. 0. 3. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10  1] -> size -> 27 
adversary victory points: 1
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0.  0.  0.] 
cards in discard: [29. 10.  8.  6.  6. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8 10  6  8  8  6  0  3  0  0  0 29  0 10  6 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 21. 30.  8.  2. 10.  6.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [1. 0. 3. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10  1] -> size -> 27 
adversary victory points: 1
player victory points: -2 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [1. 0. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[17.270706]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 0. 6.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 21. 30.  8.  2. 10.  6.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [1. 0. 3. 0. 8.] 
adversary cards in discard: [29. 10.  8.  6.  6. 11.  6. 10.  0.  0.  0.] 
adversary owned cards: [ 1  8 10  6  8  8  6  0  3  0  0  0 29  0 10  6 11] -> size -> 17 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  1 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: buy - action -1
Learning step: 0.5468292236328125
desired expected reward: 22.375518798828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 8.084073 ]
 [11.705256 ]
 [10.737536 ]
 [ 2.532796 ]
 [ 9.959537 ]
 [14.529313 ]
 [10.624719 ]
 [11.330793 ]
 [ 4.7840133]
 [10.304946 ]
 [ 8.677435 ]
 [16.226246 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 6.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10  1] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 26. 30. 21. 30.  8.  2. 10.  6.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [1. 0. 3. 0. 8.] 
adversary cards in discard: [29. 10.  8.  6.  6. 11.  6. 10.  0.  0.  0.] 
adversary owned cards: [ 1  8 10  6  8  8  6  0  3  0  0  0 29  0 10  6 11] -> size -> 17 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  1 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: take_action - action -1.0
Learning step: 0.7822988033294678
desired expected reward: 15.816241264343262



buy possibilites: [-1] 
expected returns: [[-7.4723005]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 6.] 
cards in discard: [11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10  1 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 26. 30. 21. 30.  8.  2. 10.  5.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [1. 0. 3. 0. 8.] 
adversary cards in discard: [29. 10.  8.  6.  6. 11.  6. 10.  0.  0.  0.] 
adversary owned cards: [ 1  8 10  6  8  8  6  0  3  0  0  0 29  0 10  6 11] -> size -> 17 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5.   0.   1.  30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 30.5 

action type: buy - action 11.0
Learning step: 0.6304075121879578
desired expected reward: 15.159722328186035






Player: 1 
cards in hand: [1. 0. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 0. 8.] 
cards in discard: [29. 10.  8.  6.  6. 11.  6. 10.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8 10  6  8  8  6  0  3  0  0  0 29  0 10  6 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 21. 30.  8.  2. 10.  5.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 6.  0. 10.  3.  0.] 
adversary cards in discard: [11.  1.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10  1 11] -> size -> 28 
adversary victory points: 1
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 8.] 
cards in discard: [29. 10.  8.  6.  6. 11.  6. 10.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8 10  6  8  8  6  0  3  0  0  0 29  0 10  6 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 26. 30. 21. 30.  8.  2. 10.  5.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 6.  0. 10.  3.  0.] 
adversary cards in discard: [11.  1.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10  1 11] -> size -> 28 
adversary victory points: 1
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 8.] 
cards in discard: [29. 10.  8.  6.  6. 11.  6. 10.  0.  0.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8 10  6  8  8  6  0  3  0  0  0 29  0 10  6 11 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 26. 30. 21. 30.  8.  2. 10.  4.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 6.  0. 10.  3.  0.] 
adversary cards in discard: [11.  1.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10  1 11] -> size -> 28 
adversary victory points: 1
player victory points: -2 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [ 6.  0. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[34.127434]
 [26.272976]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10.  3.  0.] 
cards in discard: [11.  1.  0.  3.  0.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10  1 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 21. 30.  8.  2. 10.  4.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [11. 10.  0.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8 10  6  8  8  6  0  3  0  0  0 29  0 10  6 11 11] -> size -> 18 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  1 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: buy - action -1
Learning step: 2.344473123550415
desired expected reward: -5.1278276443481445





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[23.07531 ]
 [27.02246 ]
 [10.88579 ]
 [27.261723]
 [33.164845]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 10.  3.  0.] 
cards in discard: [11.  1.  0.  3.  0.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10  1 11] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 26. 30. 21. 30.  8.  2. 10.  4.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [11. 10.  0.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8 10  6  8  8  6  0  3  0  0  0 29  0 10  6 11 11] -> size -> 18 
adversary victory points: -2
player victory points: 1 

Reward from previous game state: 
[-5  0  1 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: take_action - action -1.0
Learning step: 0.18072834610939026
desired expected reward: 33.77478790283203



buy possibilites: [-1] 
expected returns: [[2.6381826]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 10.  3.  0.] 
cards in discard: [11.  1.  0.  3.  0.  6.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10  1 11  6] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 26. 30. 21. 30.  8.  1. 10.  4.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [11. 10.  0.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8 10  6  8  8  6  0  3  0  0  0 29  0 10  6 11 11] -> size -> 18 
adversary victory points: -2
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.   20.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -285.0 

action type: buy - action 6.0
Learning step: -14.734929084777832
desired expected reward: -3.849142074584961






Player: 1 
cards in hand: [11. 10.  0.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.  6.  8.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8 10  6  8  8  6  0  3  0  0  0 29  0 10  6 11 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 21. 30.  8.  1. 10.  4.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 10.] 
adversary cards in discard: [11.  1.  0.  3.  0.  6.  6.  6.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10  1 11  6] -> size -> 29 
adversary victory points: 0
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  8 10  8  8  6  0  3  0  0  0 29  0 10  6 11 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 21. 30.  8.  1. 10.  4.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 10.] 
adversary cards in discard: [11.  1.  0.  3.  0.  6.  6.  6.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10  1 11  6] -> size -> 29 
adversary victory points: 0
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  8 10  8  8  6  0  3  0  0  0 29  0 10  6 11 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 26. 30. 21. 30.  8.  1. 10.  4.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 10.] 
adversary cards in discard: [11.  1.  0.  3.  0.  6.  6.  6.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10  1 11  6] -> size -> 29 
adversary victory points: 0
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  0.] 
cards in discard: [0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  8 10  8  8  6  0  3  0  0  0 29  0 10  6 11 11  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 26. 30. 21. 30.  8.  1. 10.  4.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 10.] 
adversary cards in discard: [11.  1.  0.  3.  0.  6.  6.  6.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10  1 11  6] -> size -> 29 
adversary victory points: 0
player victory points: -1 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[23.819756]
 [16.837326]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 10.] 
cards in discard: [11.  1.  0.  3.  0.  6.  6.  6.  0. 10.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10  1 11  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 21. 30.  8.  1. 10.  4.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 6. 29.  0.  8. 10.] 
adversary cards in discard: [ 0.  8. 11. 10.  0.] 
adversary owned cards: [ 1  8 10  8  8  6  0  3  0  0  0 29  0 10  6 11 11  0] -> size -> 18 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 5 

action type: buy - action -1
Learning step: 0.5810191631317139
desired expected reward: 3.2192018032073975





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[12.303241 ]
 [17.079708 ]
 [15.435264 ]
 [ 4.3774724]
 [20.235565 ]
 [15.656974 ]
 [14.761653 ]
 [21.352089 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 10.] 
cards in discard: [11.  1.  0.  3.  0.  6.  6.  6.  0. 10.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10  1 11  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 26. 30. 21. 30.  8.  1. 10.  4.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 6. 29.  0.  8. 10.] 
adversary cards in discard: [ 0.  8. 11. 10.  0.] 
adversary owned cards: [ 1  8 10  8  8  6  0  3  0  0  0 29  0 10  6 11 11  0] -> size -> 18 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 5 

action type: take_action - action -1.0
Learning step: -0.5902732014656067
desired expected reward: 23.229490280151367



buy possibilites: [-1] 
expected returns: [[33.417538]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 10.] 
cards in discard: [11.  1.  0.  3.  0.  6.  6.  6.  0. 10.  3.  0.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10  1 11  6  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [15. 26. 30. 21. 30.  8.  0. 10.  4.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 6. 29.  0.  8. 10.] 
adversary cards in discard: [ 0.  8. 11. 10.  0.] 
adversary owned cards: [ 1  8 10  8  8  6  0  3  0  0  0 29  0 10  6 11 11  0] -> size -> 18 
adversary victory points: -1
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -306.0 

action type: buy - action 6.0
Learning step: -14.76697826385498
desired expected reward: -10.38950252532959






Player: 1 
cards in hand: [ 6. 29.  0.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 10.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29.  0.  8. 10.] 
cards in discard: [ 0.  8. 11. 10.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8 10  8  8  6  0  3  0  0  0 29  0 10  6 11 11  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 26. 30. 21. 30.  8.  0. 10.  4.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [29.  0. 25.  8.  0.] 
adversary cards in discard: [11.  1.  0.  3.  0.  6.  6.  6.  0. 10.  3.  0.  6.  0.  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10  1 11  6  6] -> size -> 30 
adversary victory points: -1
player victory points: -1 


action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.  0.] 
cards in discard: [ 0.  8. 11. 10.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 1  8 10  8  8  6  0  3  0  0  0 29  0 10  6 11 11  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [15. 26. 30. 21. 30.  8.  0. 10.  4.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [29.  0. 25.  8.  0.] 
adversary cards in discard: [11.  1.  0.  3.  0.  6.  6.  6.  0. 10.  3.  0.  6.  0.  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10  1 11  6  6] -> size -> 30 
adversary victory points: -1
player victory points: -1 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 1.] 
cards in discard: [ 0.  8. 11. 10.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 1  8 10  8  8  6  0  3  0  0  0 29  0 10  6 11 11  0] -> size -> 18 
action values: 2 
buys: 0 
player value: 1 
card supply: [15. 26. 30. 21. 30.  8.  0. 10.  4.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [29.  0. 25.  8.  0.] 
adversary cards in discard: [11.  1.  0.  3.  0.  6.  6.  6.  0. 10.  3.  0.  6.  0.  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10  1 11  6  6] -> size -> 30 
adversary victory points: -1
player victory points: -1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [ 0.  8. 11. 10.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 10.  8.] 
owned cards: [ 1  8 10  8  8  6  3  0  0 29  0 10  6 11 11  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [15. 26. 30. 21. 30.  8.  0. 10.  4.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [29.  0. 25.  8.  0.] 
adversary cards in discard: [11.  1.  0.  3.  0.  6.  6.  6.  0. 10.  3.  0.  6.  0.  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10  1 11  6  6] -> size -> 30 
adversary victory points: -1
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 0.  8. 11. 10.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 10.  8.] 
owned cards: [ 1  8 10  8  8  6  3  0  0 29  0 10  6 11 11  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 26. 30. 21. 30.  8.  0. 10.  4.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [29.  0. 25.  8.  0.] 
adversary cards in discard: [11.  1.  0.  3.  0.  6.  6.  6.  0. 10.  3.  0.  6.  0.  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10  1 11  6  6] -> size -> 30 
adversary victory points: -1
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 0.  8. 11. 10.  0.  6.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 10.  8.] 
owned cards: [ 1  8 10  8  8  6  3  0  0 29  0 10  6 11 11  0  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 21. 30.  8.  0. 10.  4.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [29.  0. 25.  8.  0.] 
adversary cards in discard: [11.  1.  0.  3.  0.  6.  6.  6.  0. 10.  3.  0.  6.  0.  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10  1 11  6  6] -> size -> 30 
adversary victory points: -1
player victory points: -1 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [29.  0. 25.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.  8.] 
expected returns: [[-10.643895]
 [-15.626324]
 [-12.046567]
 [-16.259087]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 25.  8.  0.] 
cards in discard: [11.  1.  0.  3.  0.  6.  6.  6.  0. 10.  3.  0.  6.  0.  0.  0.  3. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10  1 11  6  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 21. 30.  8.  0. 10.  4.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [0. 8. 6. 0. 3.] 
adversary cards in discard: [ 0.  8. 11. 10.  0.  6.  1. 29. 10.  8.  1.] 
adversary owned cards: [ 1  8 10  8  8  6  3  0  0 29  0 10  6 11 11  0  1] -> size -> 17 
adversary victory points: -1
player victory points: -1 

Reward from previous game state: 
[-5  0 -1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -6 

action type: buy - action -1
Learning step: -2.273108959197998
desired expected reward: 31.144428253173828



action possibilites: [-1] 
expected returns: [[10.390008]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  8.  0.  1.  6.] 
cards in discard: [11.  1.  0.  3.  0.  6.  6.  6.  0. 10.  3.  0.  6.  0.  0.  0.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10  1 11  6  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 21. 30.  8.  0. 10.  4.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [0. 8. 6. 0. 3.] 
adversary cards in discard: [ 0.  8. 11. 10.  0.  6.  1. 29. 10.  8.  1.] 
adversary owned cards: [ 1  8 10  8  8  6  3  0  0 29  0 10  6 11 11  0  1] -> size -> 17 
adversary victory points: -1
player victory points: -1 

Reward from previous game state: 
[-5  0 -1  0  0  0 20  0  0  0  0  0  0  0  0  2] 
sum of rewards: 16 

action type: take_action - action 25.0
Learning step: 1.6512597799301147
desired expected reward: -10.395310401916504





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 8.912423]
 [ 9.740919]
 [ 9.293646]
 [ 9.198004]
 [10.863758]
 [ 9.50565 ]
 [ 9.870072]
 [ 8.435134]
 [ 9.350642]
 [ 9.154352]
 [12.105091]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  8.  0.  1.  6.] 
cards in discard: [11.  1.  0.  3.  0.  6.  6.  6.  0. 10.  3.  0.  6.  0.  0.  0.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10  1 11  6  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 25. 30. 21. 30.  8.  0. 10.  4.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [0. 8. 6. 0. 3.] 
adversary cards in discard: [ 0.  8. 11. 10.  0.  6.  1. 29. 10.  8.  1.] 
adversary owned cards: [ 1  8 10  8  8  6  3  0  0 29  0 10  6 11 11  0  1] -> size -> 17 
adversary victory points: -1
player victory points: -1 

Reward from previous game state: 
[-5  0 -1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 14 

action type: take_action - action -1
Learning step: 0.4020495116710663
desired expected reward: 10.792057037353516



buy possibilites: [-1] 
expected returns: [[59.482414]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  8.  0.  1.  6.] 
cards in discard: [11.  1.  0.  3.  0.  6.  6.  6.  0. 10.  3.  0.  6.  0.  0.  0.  3. 10.
  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10  1 11  6  6  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 25. 30. 20. 30.  8.  0. 10.  4.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [0. 8. 6. 0. 3.] 
adversary cards in discard: [ 0.  8. 11. 10.  0.  6.  1. 29. 10.  8.  1.] 
adversary owned cards: [ 1  8 10  8  8  6  3  0  0 29  0 10  6 11 11  0  1] -> size -> 17 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5.  0.  0. 10.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 27.0 

action type: buy - action 3.0
Learning step: 2.2236716747283936
desired expected reward: 11.517328262329102






Player: 1 
cards in hand: [0. 8. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 0. 3.] 
cards in discard: [ 0.  8. 11. 10.  0.  6.  1. 29. 10.  8.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8 10  8  8  6  3  0  0 29  0 10  6 11 11  0  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 20. 30.  8.  0. 10.  4.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 8.  0. 10.  3. 10.] 
adversary cards in discard: [11.  1.  0.  3.  0.  6.  6.  6.  0. 10.  3.  0.  6.  0.  0.  0.  3. 10.
  3. 25. 29.  0.  8.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10  1 11  6  6  3] -> size -> 31 
adversary victory points: 0
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3.] 
cards in discard: [ 0.  8. 11. 10.  0.  6.  1. 29. 10.  8.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  8 10  8  8  6  3  0 29  0 10  6 11 11  0  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 20. 30.  8.  0. 10.  4.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 8.  0. 10.  3. 10.] 
adversary cards in discard: [11.  1.  0.  3.  0.  6.  6.  6.  0. 10.  3.  0.  6.  0.  0.  0.  3. 10.
  3. 25. 29.  0.  8.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10  1 11  6  6  3] -> size -> 31 
adversary victory points: 0
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3.] 
cards in discard: [ 0.  8. 11. 10.  0.  6.  1. 29. 10.  8.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  8 10  8  8  6  3  0 29  0 10  6 11 11  0  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 25. 30. 20. 30.  8.  0. 10.  4.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 8.  0. 10.  3. 10.] 
adversary cards in discard: [11.  1.  0.  3.  0.  6.  6.  6.  0. 10.  3.  0.  6.  0.  0.  0.  3. 10.
  3. 25. 29.  0.  8.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10  1 11  6  6  3] -> size -> 31 
adversary victory points: 0
player victory points: -1 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 10.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10.] 
expected returns: [[55.3138  ]
 [47.24334 ]
 [45.795036]
 [45.795036]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  3. 10.] 
cards in discard: [11.  1.  0.  3.  0.  6.  6.  6.  0. 10.  3.  0.  6.  0.  0.  0.  3. 10.
  3. 25. 29.  0.  8.  0.  1.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10  1 11  6  6  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 20. 30.  8.  0. 10.  4.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 8.  3.  8. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8 10  8  8  6  3  0 29  0 10  6 11 11  0  1] -> size -> 16 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 5 

action type: buy - action -1
Learning step: -1.6212962865829468
desired expected reward: 57.86111831665039



action possibilites: [-1.  8. 10.] 
expected returns: [[33.965252]
 [26.76726 ]
 [26.126776]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3. 10.  3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10  1 11  6  6  3] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 20. 30.  8.  0. 10.  4.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 8.  3.  8. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8 10  8  8  6  3  0 29  0 10  6 11 11  0  1] -> size -> 16 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action 10.0
Learning step: -0.3803586959838867
desired expected reward: 45.41466522216797





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[26.25044 ]
 [37.152584]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3. 10.  3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10  1 11  6  6  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 25. 30. 20. 30.  8.  0. 10.  4.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 8.  3.  8. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  8 10  8  8  6  3  0 29  0 10  6 11 11  0  1] -> size -> 16 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0.27366581559181213
desired expected reward: 34.23891067504883






Player: 1 
cards in hand: [ 8.  3.  8. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  8. 10. 11.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  8 10  8  8  6  3  0 29  0 10  6 11 11  0  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 20. 30.  8.  0. 10.  4.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 1.  8. 11.  6.  6.] 
adversary cards in discard: [10.  8.  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10  1 11  6  6  3] -> size -> 31 
adversary victory points: 0
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1 10  8  8  6  3  0 29  0 10  6 11 11  0  1] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 20. 30.  8.  0. 10.  4.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 1.  8. 11.  6.  6.] 
adversary cards in discard: [10.  8.  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10  1 11  6  6  3] -> size -> 31 
adversary victory points: 0
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 11.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1 10  8  8  6  3  0 29  0 10  6 11 11  0  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 25. 30. 20. 30.  8.  0. 10.  4.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 1.  8. 11.  6.  6.] 
adversary cards in discard: [10.  8.  0.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10  1 11  6  6  3] -> size -> 31 
adversary victory points: 0
player victory points: -1 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 1.  8. 11.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[29.246717]
 [26.022173]
 [29.07721 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8. 11.  6.  6.] 
cards in discard: [10.  8.  0.  3. 10.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  6  0  1  0  3  6  6  8
  0 10  1 11  6  6  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 20. 30.  8.  0. 10.  4.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 1.  6. 10.  1.  8.] 
adversary cards in discard: [ 8.  3. 10. 11.] 
adversary owned cards: [ 1 10  8  8  6  3  0 29  0 10  6 11 11  0  1] -> size -> 15 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 5 

action type: buy - action -1.0
Learning step: -1.0153875350952148
desired expected reward: 36.13719177246094



action possibilites: [-1] 
expected returns: [[-12.442341]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [10.  8.  0.  3. 10.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  0  1  0  3  6  8  0 10
  1  6  6  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 20. 30.  8.  0. 10.  4.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 1.  6. 10.  1.  8.] 
adversary cards in discard: [ 8.  3. 10. 11.] 
adversary owned cards: [ 1 10  8  8  6  3  0 29  0 10  6 11 11  0  1] -> size -> 15 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 47 

action type: trash_cards_n_from_hand - action 9
Learning step: 0.6126416325569153
desired expected reward: 29.760757446289062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-15.333511]
 [-14.142195]
 [-15.469337]
 [-14.503375]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [10.  8.  0.  3. 10.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  0  1  0  3  6  8  0 10
  1  6  6  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 25. 30. 20. 30.  8.  0. 10.  4.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 1.  6. 10.  1.  8.] 
adversary cards in discard: [ 8.  3. 10. 11.] 
adversary owned cards: [ 1 10  8  8  6  3  0 29  0 10  6 11 11  0  1] -> size -> 15 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 47 

action type: take_action - action -1
Learning step: 2.6388614177703857
desired expected reward: -9.803479194641113



buy possibilites: [-1] 
expected returns: [[73.2204]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [10.  8.  0.  3. 10.  3.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  0  1  0  3  6  8  0 10
  1  6  6  3  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 25. 30. 20. 30.  8.  0. 10.  4.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 1.  6. 10.  1.  8.] 
adversary cards in discard: [ 8.  3. 10. 11.] 
adversary owned cards: [ 1 10  8  8  6  3  0 29  0 10  6 11 11  0  1] -> size -> 15 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2.  30.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 17.0 

action type: buy - action 0.0
Learning step: 3.264134168624878
desired expected reward: -12.069379806518555






Player: 1 
cards in hand: [ 1.  6. 10.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6. 10.  1.  8.] 
cards in discard: [ 8.  3. 10. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 10  8  8  6  3  0 29  0 10  6 11 11  0  1] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 20. 30.  8.  0. 10.  4.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [10.  8.  0.  3. 10.  3.  0.  8.  1.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  0  1  0  3  6  8  0 10
  1  6  6  3  0] -> size -> 29 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.] 
cards in discard: [ 8.  3. 10. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  8  6  3  0 29  0 10  6 11 11  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 20. 30.  8.  0. 10.  4.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [10.  8.  0.  3. 10.  3.  0.  8.  1.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  0  1  0  3  6  8  0 10
  1  6  6  3  0] -> size -> 29 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.] 
cards in discard: [ 8.  3. 10. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  8  6  3  0 29  0 10  6 11 11  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 25. 30. 20. 30.  8.  0. 10.  4.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [10.  8.  0.  3. 10.  3.  0.  8.  1.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  0  1  0  3  6  8  0 10
  1  6  6  3  0] -> size -> 29 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.] 
cards in discard: [ 8.  3. 10. 11.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  8  6  3  0 29  0 10  6 11 11  0  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 20. 30.  8.  0. 10.  4.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [10.  8.  0.  3. 10.  3.  0.  8.  1.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  0  1  0  3  6  8  0 10
  1  6  6  3  0] -> size -> 29 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[6.445137]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [10.  8.  0.  3. 10.  3.  0.  8.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  0  1  0  3  6  8  0 10
  1  6  6  3  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 20. 30.  8.  0. 10.  4.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  6.] 
adversary cards in discard: [ 8.  3. 10. 11.  0.  8.  6. 10.] 
adversary owned cards: [10  8  8  6  3  0 29  0 10  6 11 11  0  0] -> size -> 14 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: buy - action -1
Learning step: -2.138359308242798
desired expected reward: 71.08203887939453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-7.2400227 ]
 [ 0.64012575]
 [-1.6615645 ]
 [ 5.4948187 ]
 [-2.778026  ]
 [-2.3259141 ]
 [ 7.3623943 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [10.  8.  0.  3. 10.  3.  0.  8.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  0  1  0  3  6  8  0 10
  1  6  6  3  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 25. 30. 20. 30.  8.  0. 10.  4.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  6.] 
adversary cards in discard: [ 8.  3. 10. 11.  0.  8.  6. 10.] 
adversary owned cards: [10  8  8  6  3  0 29  0 10  6 11 11  0  0] -> size -> 14 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: take_action - action -1.0
Learning step: 0.976466178894043
desired expected reward: 8.65027141571045



buy possibilites: [-1] 
expected returns: [[-14.01435]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [10.  8.  0.  3. 10.  3.  0.  8.  1.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  0  1  0  3  6  8  0 10
  1  6  6  3  0  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 25. 30. 19. 30.  8.  0. 10.  4.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  6.] 
adversary cards in discard: [ 8.  3. 10. 11.  0.  8.  6. 10.] 
adversary owned cards: [10  8  8  6  3  0 29  0 10  6 11 11  0  0] -> size -> 14 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3. 40.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 40.0 

action type: buy - action 3.0
Learning step: 1.7677555084228516
desired expected reward: 0.10618722438812256






Player: 1 
cards in hand: [29.  0.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0.  6.] 
cards in discard: [ 8.  3. 10. 11.  0.  8.  6. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  6  3  0 29  0 10  6 11 11  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 19. 30.  8.  0. 10.  4.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 6.  0.  0. 10.  0.] 
adversary cards in discard: [10.  8.  0.  3. 10.  3.  0.  8.  1.  3.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  0  1  0  3  6  8  0 10
  1  6  6  3  0  3] -> size -> 30 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  0.  6.] 
cards in discard: [ 8.  3. 10. 11.  0.  8.  6. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  6  3  0 29  0 10  6 11 11  0  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 25. 30. 19. 30.  8.  0. 10.  4.  4.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 6.  0.  0. 10.  0.] 
adversary cards in discard: [10.  8.  0.  3. 10.  3.  0.  8.  1.  3.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  0  1  0  3  6  8  0 10
  1  6  6  3  0  3] -> size -> 30 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  0.  6.] 
cards in discard: [ 8.  3. 10. 11.  0.  8.  6. 10.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  6  3  0 29  0 10  6 11 11  0  0  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 25. 30. 19. 30.  8.  0. 10.  4.  3.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 6.  0.  0. 10.  0.] 
adversary cards in discard: [10.  8.  0.  3. 10.  3.  0.  8.  1.  3.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  0  1  0  3  6  8  0 10
  1  6  6  3  0  3] -> size -> 30 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[51.341457]
 [42.82863 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 10.  0.] 
cards in discard: [10.  8.  0.  3. 10.  3.  0.  8.  1.  3.  3.  0.  3.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  0  1  0  3  6  8  0 10
  1  6  6  3  0  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 19. 30.  8.  0. 10.  4.  3.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  6  3  0 29  0 10  6 11 11  0  0  8] -> size -> 15 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: buy - action -1
Learning step: 3.6668803691864014
desired expected reward: -10.347469329833984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[42.691547]
 [48.791042]
 [46.49982 ]
 [52.72615 ]
 [46.847713]
 [45.344383]
 [54.04517 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0. 10.  0.] 
cards in discard: [10.  8.  0.  3. 10.  3.  0.  8.  1.  3.  3.  0.  3.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  0  1  0  3  6  8  0 10
  1  6  6  3  0  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 25. 30. 19. 30.  8.  0. 10.  4.  3.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  6  3  0 29  0 10  6 11 11  0  0  8] -> size -> 15 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: take_action - action -1.0
Learning step: 0.42533931136131287
desired expected reward: 51.766788482666016



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0.  3.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  6. 11.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  6  3  0 29  0 10  6 11 11  0  0  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 19. 30.  8.  0. 10.  4.  3.  9.  8.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 29.  3. 10.  1.] 
adversary cards in discard: [10.  8.  0.  3. 10.  3.  0.  8.  1.  3.  3.  0.  3.  0.  0.  6.  0.  0.
 10.  0.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  0  1  0  3  6  8  0 10
  1  6  6  3  0  3] -> size -> 30 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 6.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  8  8  6  3  0 29  0 10  6 11 11  0  0  8 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 19. 30.  8.  0. 10.  4.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 29.  3. 10.  1.] 
adversary cards in discard: [10.  8.  0.  3. 10.  3.  0.  8.  1.  3.  3.  0.  3.  0.  0.  6.  0.  0.
 10.  0.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  0  1  0  3  6  8  0 10
  1  6  6  3  0  3] -> size -> 30 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  8  8  6  3  0 29  0 10  6 11 11  0  0  8 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 25. 30. 19. 30.  8.  0. 10.  4.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 29.  3. 10.  1.] 
adversary cards in discard: [10.  8.  0.  3. 10.  3.  0.  8.  1.  3.  3.  0.  3.  0.  0.  6.  0.  0.
 10.  0.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  0  1  0  3  6  8  0 10
  1  6  6  3  0  3] -> size -> 30 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  3. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[21.185785]
 [17.593454]
 [14.853066]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3. 10.  1.] 
cards in discard: [10.  8.  0.  3. 10.  3.  0.  8.  1.  3.  3.  0.  3.  0.  0.  6.  0.  0.
 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  0  1  0  3  6  8  0 10
  1  6  6  3  0  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 19. 30.  8.  0. 10.  4.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 10.  8.  8. 11.] 
adversary cards in discard: [10. 11.  0.  0.  3.  6.] 
adversary owned cards: [10  8  8  6  3  0 29  0 10  6 11 11  0  0  8 10] -> size -> 16 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: buy - action -1.0
Learning step: -0.3947698771953583
desired expected reward: 53.650394439697266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[13.837197]
 [20.212051]
 [16.97484 ]
 [22.808933]
 [18.6716  ]
 [16.196346]
 [22.02657 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3. 10.  1.] 
cards in discard: [10.  8.  0.  3. 10.  3.  0.  8.  1.  3.  3.  0.  3.  0.  0.  6.  0.  0.
 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  0  1  0  3  6  8  0 10
  1  6  6  3  0  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 25. 30. 19. 30.  8.  0. 10.  4.  3.  9.  8.  8. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 10.  8.  8. 11.] 
adversary cards in discard: [10. 11.  0.  0.  3.  6.] 
adversary owned cards: [10  8  8  6  3  0 29  0 10  6 11 11  0  0  8 10] -> size -> 16 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: take_action - action -1.0
Learning step: 1.3017011880874634
desired expected reward: 21.802684783935547



buy possibilites: [-1] 
expected returns: [[29.006197]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3. 10.  1.] 
cards in discard: [10.  8.  0.  3. 10.  3.  0.  8.  1.  3.  3.  0.  3.  0.  0.  6.  0.  0.
 10.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  0  1  0  3  6  8  0 10
  1  6  6  3  0  3 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 19. 30.  8.  0. 10.  4.  3.  9.  8.  8. 10.  1. 10. 10.] 
adversary cards in hand: [ 0. 10.  8.  8. 11.] 
adversary cards in discard: [10. 11.  0.  0.  3.  6.] 
adversary owned cards: [10  8  8  6  3  0 29  0 10  6 11 11  0  0  8 10] -> size -> 16 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 56 

action type: buy - action 10.0
Learning step: 2.642822265625
desired expected reward: 18.83916664123535






Player: 1 
cards in hand: [ 0. 10.  8.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8.  8. 11.] 
cards in discard: [10. 11.  0.  0.  3.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  6  3  0 29  0 10  6 11 11  0  0  8 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 19. 30.  8.  0. 10.  4.  3.  9.  8.  8. 10.  1. 10. 10.] 
adversary cards in hand: [ 6. 25.  6.  0.  0.] 
adversary cards in discard: [10.  8.  0.  3. 10.  3.  0.  8.  1.  3.  3.  0.  3.  0.  0.  6.  0.  0.
 10.  0. 10.  0. 29.  3. 10.  1.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  0  1  0  3  6  8  0 10
  1  6  6  3  0  3 10] -> size -> 31 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1.  8.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  8. 11.  0.] 
cards in discard: [10. 11.  0.  0.  3.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  8  6  3  0 29  0 10  6 11 11  0  0  8 10] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 19. 30.  8.  0. 10.  4.  3.  9.  8.  8. 10.  1. 10. 10.] 
adversary cards in hand: [ 6. 25.  6.  0.  0.] 
adversary cards in discard: [10.  8.  0.  3. 10.  3.  0.  8.  1.  3.  3.  0.  3.  0.  0.  6.  0.  0.
 10.  0. 10.  0. 29.  3. 10.  1.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  0  1  0  3  6  8  0 10
  1  6  6  3  0  3 10] -> size -> 31 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [10. 11.  0.  0.  3.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [10  8  8  6  3 29 10  6 11  0  0  8 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 19. 30.  8.  0. 10.  4.  3.  9.  8.  8. 10.  1. 10. 10.] 
adversary cards in hand: [ 6. 25.  6.  0.  0.] 
adversary cards in discard: [10.  8.  0.  3. 10.  3.  0.  8.  1.  3.  3.  0.  3.  0.  0.  6.  0.  0.
 10.  0. 10.  0. 29.  3. 10.  1.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  0  1  0  3  6  8  0 10
  1  6  6  3  0  3 10] -> size -> 31 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [10. 11.  0.  0.  3.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.  8.  8.] 
owned cards: [10  8  8  6  3 29 10  6 11  0  0  8 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 19. 30.  8.  0. 10.  4.  3.  9.  8.  8. 10.  1. 10. 10.] 
adversary cards in hand: [ 6. 25.  6.  0.  0.] 
adversary cards in discard: [10.  8.  0.  3. 10.  3.  0.  8.  1.  3.  3.  0.  3.  0.  0.  6.  0.  0.
 10.  0. 10.  0. 29.  3. 10.  1.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  0  1  0  3  6  8  0 10
  1  6  6  3  0  3 10] -> size -> 31 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [10. 11.  0.  0.  3.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.  8.  8.] 
owned cards: [10  8  8  6  3 29 10  6 11  0  0  8 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 25. 30. 19. 30.  8.  0. 10.  4.  3.  9.  8.  8. 10.  1. 10. 10.] 
adversary cards in hand: [ 6. 25.  6.  0.  0.] 
adversary cards in discard: [10.  8.  0.  3. 10.  3.  0.  8.  1.  3.  3.  0.  3.  0.  0.  6.  0.  0.
 10.  0. 10.  0. 29.  3. 10.  1.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  0  1  0  3  6  8  0 10
  1  6  6  3  0  3 10] -> size -> 31 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [10. 11.  0.  0.  3.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.  8.  8.] 
owned cards: [10  8  8  6  3 29 10  6 11  0  0  8 10  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 25. 30. 19. 30.  8.  0. 10.  4.  3.  9.  8.  8. 10.  1. 10. 10.] 
adversary cards in hand: [ 6. 25.  6.  0.  0.] 
adversary cards in discard: [10.  8.  0.  3. 10.  3.  0.  8.  1.  3.  3.  0.  3.  0.  0.  6.  0.  0.
 10.  0. 10.  0. 29.  3. 10.  1.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  0  1  0  3  6  8  0 10
  1  6  6  3  0  3 10] -> size -> 31 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [ 6. 25.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[42.793438]
 [46.54809 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 25.  6.  0.  0.] 
cards in discard: [10.  8.  0.  3. 10.  3.  0.  8.  1.  3.  3.  0.  3.  0.  0.  6.  0.  0.
 10.  0. 10.  0. 29.  3. 10.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  0  1  0  3  6  8  0 10
  1  6  6  3  0  3 10] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 25. 30. 19. 30.  8.  0. 10.  4.  3.  9.  8.  8. 10.  1. 10. 10.] 
adversary cards in hand: [11. 10.  8.  6. 29.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  6  3 29 10  6 11  0  0  8 10  0] -> size -> 14 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: buy - action -1
Learning step: 1.4577592611312866
desired expected reward: 30.463956832885742



action possibilites: [-1] 
expected returns: [[-6.900503]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0.  0.  3. 10.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  0  1  0  3  6  8  0 10
  1  6  6  3  0  3 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 25. 30. 19. 30.  8.  0. 10.  4.  3.  9.  8.  8. 10.  1. 10. 10.] 
adversary cards in hand: [11. 10.  8.  6. 29.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  6  3 29 10  6 11  0  0  8 10  0] -> size -> 14 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 58 

action type: take_action - action 25.0
Learning step: 0.4173343777656555
desired expected reward: 46.965423583984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-4.496601 ]
 [-4.073604 ]
 [-4.66695  ]
 [-1.4619888]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0.  0.  3. 10.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  0  1  0  3  6  8  0 10
  1  6  6  3  0  3 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 25. 30. 19. 30.  8.  0. 10.  4.  3.  9.  8.  8. 10.  1. 10. 10.] 
adversary cards in hand: [11. 10.  8.  6. 29.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  6  3 29 10  6 11  0  0  8 10  0] -> size -> 14 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 58 

action type: take_action - action -1
Learning step: 3.165851354598999
desired expected reward: -3.734651803970337



buy possibilites: [-1] 
expected returns: [[14.405749]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0.  0.  3. 10.] 
cards in discard: [8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  0  1  0  3  6  8  0 10
  1  6  6  3  0  3 10  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 25. 30. 19. 30.  8.  0. 10.  4.  2.  9.  8.  8. 10.  1. 10. 10.] 
adversary cards in hand: [11. 10.  8.  6. 29.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  6  3 29 10  6 11  0  0  8 10  0] -> size -> 14 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 66 

action type: buy - action 8.0
Learning step: 3.8574771881103516
desired expected reward: -0.8094797134399414






Player: 1 
cards in hand: [11. 10.  8.  6. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  8.  6. 29.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  6  3 29 10  6 11  0  0  8 10  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 25. 30. 19. 30.  8.  0. 10.  4.  2.  9.  8.  8. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  1.  0.  0. 10.] 
adversary cards in discard: [ 8. 25.  6.  6.  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  0  1  0  3  6  8  0 10
  1  6  6  3  0  3 10  8] -> size -> 32 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  8  6  3 10  6  0  0  8 10  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 25. 30. 19. 30.  8.  0. 10.  4.  2.  9.  8.  8. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  1.  0.  0. 10.] 
adversary cards in discard: [ 8. 25.  6.  6.  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  0  1  0  3  6  8  0 10
  1  6  6  3  0  3 10  8] -> size -> 32 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  8  6  3 10  6  0  0  8 10  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 25. 30. 19. 30.  8.  0. 10.  4.  2.  9.  8.  8. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  1.  0.  0. 10.] 
adversary cards in discard: [ 8. 25.  6.  6.  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  0  1  0  3  6  8  0 10
  1  6  6  3  0  3 10  8] -> size -> 32 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  8  6  3 10  6  0  0  8 10  0  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 25. 30. 19. 30.  8.  0. 10.  4.  2.  9.  8.  8. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  1.  0.  0. 10.] 
adversary cards in discard: [ 8. 25.  6.  6.  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  0  1  0  3  6  8  0 10
  1  6  6  3  0  3 10  8] -> size -> 32 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [ 0.  1.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[-5.927031 ]
 [-7.7861147]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0.  0. 10.] 
cards in discard: [ 8. 25.  6.  6.  0.  0.  3. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  0  1  0  3  6  8  0 10
  1  6  6  3  0  3 10  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 25. 30. 19. 30.  8.  0. 10.  4.  2.  9.  8.  8. 10.  1. 10. 10.] 
adversary cards in hand: [3. 6. 8. 0. 0.] 
adversary cards in discard: [ 0.  8. 10.  6.] 
adversary owned cards: [10  8  8  6  3 10  6  0  0  8 10  0  0] -> size -> 13 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: buy - action -1
Learning step: 1.0182815790176392
desired expected reward: 15.424031257629395





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ -9.333622 ]
 [ -9.104911 ]
 [ -8.866148 ]
 [-11.482753 ]
 [ -9.243167 ]
 [ -8.234498 ]
 [ -9.281552 ]
 [ -7.0304546]
 [ -9.191772 ]
 [-10.100731 ]
 [ -9.102705 ]
 [ -8.868023 ]
 [-10.684448 ]
 [ -8.983122 ]
 [ -7.555209 ]]
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0.  0. 10.] 
cards in discard: [ 8. 25.  6.  6.  0.  0.  3. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  0  1  0  3  6  8  0 10
  1  6  6  3  0  3 10  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 5 
card supply: [11. 25. 30. 19. 30.  8.  0. 10.  4.  2.  9.  8.  8. 10.  1. 10. 10.] 
adversary cards in hand: [3. 6. 8. 0. 0.] 
adversary cards in discard: [ 0.  8. 10.  6.] 
adversary owned cards: [10  8  8  6  3 10  6  0  0  8 10  0  0] -> size -> 13 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: take_action - action -1.0
Learning step: 2.0095467567443848
desired expected reward: -4.2264533042907715



buy possibilites: [-1] 
expected returns: [[2.7593563]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0.  0. 10.] 
cards in discard: [ 8. 25.  6.  6.  0.  0.  3. 10. 22.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  0  1  0  3  6  8  0 10
  1  6  6  3  0  3 10  8 22] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 25. 30. 19. 30.  8.  0. 10.  4.  2.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [3. 6. 8. 0. 0.] 
adversary cards in discard: [ 0.  8. 10.  6.] 
adversary owned cards: [10  8  8  6  3 10  6  0  0  8 10  0  0] -> size -> 13 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0  0  0  0  0  0  0  0  0 50  0] 
sum of rewards: 88 

action type: buy - action 22.0
Learning step: 4.996307849884033
desired expected reward: -5.688140392303467






Player: 1 
cards in hand: [3. 6. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 8. 0. 0.] 
cards in discard: [ 0.  8. 10.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  6  3 10  6  0  0  8 10  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 25. 30. 19. 30.  8.  0. 10.  4.  2.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [10.  3.  3.  0.  8.] 
adversary cards in discard: [ 8. 25.  6.  6.  0.  0.  3. 10. 22.  0.  1.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  0  1  0  3  6  8  0 10
  1  6  6  3  0  3 10  8 22] -> size -> 33 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 8. 0. 0.] 
cards in discard: [ 0.  8. 10.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  6  3 10  6  0  0  8 10  0  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 25. 30. 19. 30.  8.  0. 10.  4.  2.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [10.  3.  3.  0.  8.] 
adversary cards in discard: [ 8. 25.  6.  6.  0.  0.  3. 10. 22.  0.  1.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  0  1  0  3  6  8  0 10
  1  6  6  3  0  3 10  8 22] -> size -> 33 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 8. 0. 0.] 
cards in discard: [ 0.  8. 10.  6.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  6  3 10  6  0  0  8 10  0  0  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 25. 30. 19. 30.  8.  0. 10.  4.  1.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [10.  3.  3.  0.  8.] 
adversary cards in discard: [ 8. 25.  6.  6.  0.  0.  3. 10. 22.  0.  1.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  0  1  0  3  6  8  0 10
  1  6  6  3  0  3 10  8 22] -> size -> 33 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [10.  3.  3.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[ 2.8022592]
 [-1.4070637]
 [-1.636168 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3.  0.  8.] 
cards in discard: [ 8. 25.  6.  6.  0.  0.  3. 10. 22.  0.  1.  0.  0. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10 10  0  1  0  3  6  8  0 10
  1  6  6  3  0  3 10  8 22] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 25. 30. 19. 30.  8.  0. 10.  4.  1.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [ 0.  8.  0. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  6  3 10  6  0  0  8 10  0  0  8] -> size -> 14 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: buy - action -1
Learning step: 1.7647958993911743
desired expected reward: 4.5241522789001465



action possibilites: [-1] 
expected returns: [[-13.798628]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [ 8. 25.  6.  6.  0.  0.  3. 10. 22.  0.  1.  0.  0. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10  0  1  0  3  6  8  0 10  1
  6  6  3  0  3 10  8 22] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 25. 30. 19. 30.  8.  0. 10.  4.  1.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [ 0.  8.  0. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  6  3 10  6  0  0  8 10  0  0  8] -> size -> 14 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 58 

action type: trash_cards_n_from_hand - action 2
Learning step: 2.801643133163452
desired expected reward: -1.4406025409698486





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-19.675064]
 [ -8.257648]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 8. 25.  6.  6.  0.  0.  3. 10. 22.  0.  1.  0.  0. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10  0  1  0  3  6  8  0 10  1
  6  6  3  0  3 10  8 22] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 25. 30. 19. 30.  8.  0. 10.  4.  1.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [ 0.  8.  0. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  6  3 10  6  0  0  8 10  0  0  8] -> size -> 14 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 58 

action type: take_action - action -1
Learning step: 3.284740924835205
desired expected reward: -10.513887405395508






Player: 1 
cards in hand: [ 0.  8.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 10. 10.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  6  3 10  6  0  0  8 10  0  0  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 25. 30. 19. 30.  8.  0. 10.  4.  1.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [ 6.  3.  3.  0. 10.] 
adversary cards in discard: [ 8. 25.  6.  6.  0.  0.  3. 10. 22.  0.  1.  0.  0. 10.  8.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10  0  1  0  3  6  8  0 10  1
  6  6  3  0  3 10  8 22] -> size -> 32 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 10. 10.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  6  3 10  6  0  0  8 10  0  0  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 25. 30. 19. 30.  8.  0. 10.  4.  1.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [ 6.  3.  3.  0. 10.] 
adversary cards in discard: [ 8. 25.  6.  6.  0.  0.  3. 10. 22.  0.  1.  0.  0. 10.  8.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10  0  1  0  3  6  8  0 10  1
  6  6  3  0  3 10  8 22] -> size -> 32 
adversary victory points: 3
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [ 6.  3.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[14.1909685]
 [ 8.66708  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  3.  0. 10.] 
cards in discard: [ 8. 25.  6.  6.  0.  0.  3. 10. 22.  0.  1.  0.  0. 10.  8.  3.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10  0  1  0  3  6  8  0 10  1
  6  6  3  0  3 10  8 22] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 25. 30. 19. 30.  8.  0. 10.  4.  1.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [6. 6. 3. 8. 8.] 
adversary cards in discard: [ 0.  8.  0. 10. 10.] 
adversary owned cards: [10  8  8  6  3 10  6  0  0  8 10  0  0  8] -> size -> 14 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: buy - action -1.0
Learning step: 2.5744149684906006
desired expected reward: -5.683226585388184





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 6.9358625]
 [14.263419 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  3.  0. 10.] 
cards in discard: [ 8. 25.  6.  6.  0.  0.  3. 10. 22.  0.  1.  0.  0. 10.  8.  3.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10  0  1  0  3  6  8  0 10  1
  6  6  3  0  3 10  8 22] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 25. 30. 19. 30.  8.  0. 10.  4.  1.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [6. 6. 3. 8. 8.] 
adversary cards in discard: [ 0.  8.  0. 10. 10.] 
adversary owned cards: [10  8  8  6  3 10  6  0  0  8 10  0  0  8] -> size -> 14 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: take_action - action -1.0
Learning step: 1.4347532987594604
desired expected reward: 15.62572193145752



buy possibilites: [-1] 
expected returns: [[-3.9716363]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  3.  0. 10.] 
cards in discard: [ 8. 25.  6.  6.  0.  0.  3. 10. 22.  0.  1.  0.  0. 10.  8.  3.  3.  0.
  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10  0  1  0  3  6  8  0 10  1
  6  6  3  0  3 10  8 22  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 25. 30. 19. 30.  8.  0. 10.  4.  1.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [6. 6. 3. 8. 8.] 
adversary cards in discard: [ 0.  8.  0. 10. 10.] 
adversary owned cards: [10  8  8  6  3 10  6  0  0  8 10  0  0  8] -> size -> 14 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.  40.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 8.0 

action type: buy - action 0.0
Learning step: -0.03662700578570366
desired expected reward: 6.899237632751465






Player: 1 
cards in hand: [6. 6. 3. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 3. 8. 8.] 
cards in discard: [ 0.  8.  0. 10. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  6  3 10  6  0  0  8 10  0  0  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 19. 30.  8.  0. 10.  4.  1.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [ 8. 25.  6.  6.  0.  0.  3. 10. 22.  0.  1.  0.  0. 10.  8.  3.  3.  0.
  0.  6.  3.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10  0  1  0  3  6  8  0 10  1
  6  6  3  0  3 10  8 22  0] -> size -> 33 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3. 8. 8.] 
cards in discard: [ 0.  8.  0. 10. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  6  3 10  6  0  0  8 10  0  0  8] -> size -> 14 
action values: 1 
buys: 1 
player value: 0 
card supply: [10. 25. 30. 19. 30.  8.  0. 10.  4.  1.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [ 8. 25.  6.  6.  0.  0.  3. 10. 22.  0.  1.  0.  0. 10.  8.  3.  3.  0.
  0.  6.  3.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10  0  1  0  3  6  8  0 10  1
  6  6  3  0  3 10  8 22  0] -> size -> 33 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3. 8. 8.] 
cards in discard: [ 0.  8.  0. 10. 10.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  6  3 10  6  0  0  8 10  0  0  8  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 19. 30.  8.  0. 10.  4.  1.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [ 8. 25.  6.  6.  0.  0.  3. 10. 22.  0.  1.  0.  0. 10.  8.  3.  3.  0.
  0.  6.  3.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10  0  1  0  3  6  8  0 10  1
  6  6  3  0  3 10  8 22  0] -> size -> 33 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [0. 0. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[ 0.37721086]
 [-1.6976738 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [ 8. 25.  6.  6.  0.  0.  3. 10. 22.  0.  1.  0.  0. 10.  8.  3.  3.  0.
  0.  6.  3.  3.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10  0  1  0  3  6  8  0 10  1
  6  6  3  0  3 10  8 22  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 19. 30.  8.  0. 10.  4.  1.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [ 8.  0.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  6  3 10  6  0  0  8 10  0  0  8  0] -> size -> 15 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: buy - action -1
Learning step: 2.085371732711792
desired expected reward: -1.8862645626068115





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-3.2196288]
 [-2.7168427]
 [-2.3335388]
 [-1.3339841]
 [-3.0659456]
 [-2.3131113]
 [-0.6031823]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [ 8. 25.  6.  6.  0.  0.  3. 10. 22.  0.  1.  0.  0. 10.  8.  3.  3.  0.
  0.  6.  3.  3.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10  0  1  0  3  6  8  0 10  1
  6  6  3  0  3 10  8 22  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 25. 30. 19. 30.  8.  0. 10.  4.  1.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [ 8.  0.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  6  3 10  6  0  0  8 10  0  0  8  0] -> size -> 15 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: take_action - action -1.0
Learning step: 1.8336151838302612
desired expected reward: 2.2108278274536133



buy possibilites: [-1] 
expected returns: [[2.877826]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [ 8. 25.  6.  6.  0.  0.  3. 10. 22.  0.  1.  0.  0. 10.  8.  3.  3.  0.
  0.  6.  3.  3.  0. 10.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10  0  1  0  3  6  8  0 10  1
  6  6  3  0  3 10  8 22  0  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 25. 30. 18. 30.  8.  0. 10.  4.  1.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [ 8.  0.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  6  3 10  6  0  0  8 10  0  0  8  0] -> size -> 15 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4. 50.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 51.0 

action type: buy - action 3.0
Learning step: 2.7314279079437256
desired expected reward: 0.3978912830352783






Player: 1 
cards in hand: [ 8.  0.  8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  8.  0. 10.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  6  3 10  6  0  0  8 10  0  0  8  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 18. 30.  8.  0. 10.  4.  1.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [25.  0. 10.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10  0  1  0  3  6  8  0 10  1
  6  6  3  0  3 10  8 22  0  3] -> size -> 34 
adversary victory points: 4
player victory points: -1 


action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 0. 6.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  8  6  3 10  6  0  0  8 10  0  0  8  0] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 18. 30.  8.  0. 10.  4.  1.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [25.  0. 10.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10  0  1  0  3  6  8  0 10  1
  6  6  3  0  3 10  8 22  0  3] -> size -> 34 
adversary victory points: 4
player victory points: -1 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [10  8  8  6  3 10  6  0  8 10  0  0  8  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 18. 30.  8.  0. 10.  4.  1.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [25.  0. 10.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10  0  1  0  3  6  8  0 10  1
  6  6  3  0  3 10  8 22  0  3] -> size -> 34 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [10  8  8  6  3 10  6  0  8 10  0  0  8  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 25. 30. 18. 30.  8.  0. 10.  4.  1.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [25.  0. 10.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10  0  1  0  3  6  8  0 10  1
  6  6  3  0  3 10  8 22  0  3] -> size -> 34 
adversary victory points: 4
player victory points: -1 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [25.  0. 10.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 29.] 
expected returns: [[12.343549 ]
 [13.8096075]
 [ 5.8915462]
 [ 6.959283 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 10.  1. 29.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10  0  1  0  3  6  8  0 10  1
  6  6  3  0  3 10  8 22  0  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 18. 30.  8.  0. 10.  4.  1.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [10.  0. 10.  8.  0.] 
adversary cards in discard: [10.  8.  8.  0.  6.] 
adversary owned cards: [10  8  8  6  3 10  6  0  8 10  0  0  8  0] -> size -> 14 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 49 

action type: buy - action -1
Learning step: 2.414979934692383
desired expected reward: 5.2928056716918945





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[ 5.591133]
 [ 9.585052]
 [ 8.537087]
 [12.836795]
 [ 8.378664]
 [ 8.134961]
 [13.964784]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0. 10.  1. 29.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10  0  1  0  3  6  8  0 10  1
  6  6  3  0  3 10  8 22  0  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 25. 30. 18. 30.  8.  0. 10.  4.  1.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [10.  0. 10.  8.  0.] 
adversary cards in discard: [10.  8.  8.  0.  6.] 
adversary owned cards: [10  8  8  6  3 10  6  0  8 10  0  0  8  0] -> size -> 14 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 49 

action type: take_action - action -1.0
Learning step: 2.313502073287964
desired expected reward: 9.4916353225708



buy possibilites: [-1] 
expected returns: [[24.948038]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0. 10.  1. 29.] 
cards in discard: [8.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10  0  1  0  3  6  8  0 10  1
  6  6  3  0  3 10  8 22  0  3  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 25. 30. 18. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [10.  0. 10.  8.  0.] 
adversary cards in discard: [10.  8.  8.  0.  6.] 
adversary owned cards: [10  8  8  6  3 10  6  0  8 10  0  0  8  0] -> size -> 14 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5.  0.  4. 50.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 51.0 

action type: buy - action 8.0
Learning step: 2.6923980712890625
desired expected reward: 11.071050643920898






Player: 1 
cards in hand: [10.  0. 10.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  8.  0.] 
cards in discard: [10.  8.  8.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  6  3 10  6  0  8 10  0  0  8  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 18. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [10.  3.  3.  0.  8.] 
adversary cards in discard: [ 8. 25.  0. 10.  1. 29.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10  0  1  0  3  6  8  0 10  1
  6  6  3  0  3 10  8 22  0  3  8] -> size -> 35 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  8.  0.] 
cards in discard: [10.  8.  8.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  6  3 10  6  0  8 10  0  0  8  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 25. 30. 18. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [10.  3.  3.  0.  8.] 
adversary cards in discard: [ 8. 25.  0. 10.  1. 29.] 
adversary owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10  0  1  0  3  6  8  0 10  1
  6  6  3  0  3 10  8 22  0  3  8] -> size -> 35 
adversary victory points: 4
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [10.  3.  3.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[-1.1239035]
 [-2.4550755]
 [-2.0160193]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3.  0.  8.] 
cards in discard: [ 8. 25.  0. 10.  1. 29.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10  0  1  0  3  6  8  0 10  1
  6  6  3  0  3 10  8 22  0  3  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 18. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [8. 0. 8. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  6  3 10  6  0  8 10  0  0  8  0] -> size -> 14 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 49 

action type: buy - action -1
Learning step: 1.163332462310791
desired expected reward: 26.111370086669922



action possibilites: [-1.  8.  8.] 
expected returns: [[-7.2551165]
 [-5.785589 ]
 [-5.785589 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 8. 8.] 
cards in discard: [ 8. 25.  0. 10.  1. 29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0 29  0  0 25  3  8  3  3  0 10 10  0  1  0  3  6  8  0 10  1
  6  6  3  0  3 10  8 22  0  3  8] -> size -> 35 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 18. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [8. 0. 8. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  6  3 10  6  0  8 10  0  0  8  0] -> size -> 14 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 69 

action type: take_action - action 10.0
Learning step: 3.4316349029541016
desired expected reward: 0.9905261993408203



action possibilites: [-1.] 
expected returns: [[-7.620366]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [ 8. 25.  0. 10.  1. 29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0 29  0  0 25  3  3  3  0 10 10  0  1  0  3  6  8  0 10  1  6  6
  3  0  3 10  8 22  0  3  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 18. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [8. 0. 8. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  6  3 10  6  0  8 10  0  0  8  0] -> size -> 14 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 89 

action type: trash_cards_n_from_hand - action 5
Learning step: 4.502184867858887
desired expected reward: 0.02933025360107422





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-5.7943344]
 [-8.123435 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [ 8. 25.  0. 10.  1. 29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0 29  0  0 25  3  3  3  0 10 10  0  1  0  3  6  8  0 10  1  6  6
  3  0  3 10  8 22  0  3  8] -> size -> 33 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 9. 25. 30. 18. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [8. 0. 8. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  6  3 10  6  0  8 10  0  0  8  0] -> size -> 14 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 89 

action type: take_action - action -1.0
Learning step: 4.676290035247803
desired expected reward: -2.9440760612487793






Player: 1 
cards in hand: [8. 0. 8. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 6. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  6  3 10  6  0  8 10  0  0  8  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 18. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [ 8. 25.  0. 10.  1. 29. 10.  8.  3.  3.] 
adversary owned cards: [ 0  0  0 29  0  0 25  3  3  3  0 10 10  0  1  0  3  6  8  0 10  1  6  6
  3  0  3 10  8 22  0  3  8] -> size -> 33 
adversary victory points: 4
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  8 10  6  0  8 10  0  0  8  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 18. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [ 8. 25.  0. 10.  1. 29. 10.  8.  3.  3.] 
adversary owned cards: [ 0  0  0 29  0  0 25  3  3  3  0 10 10  0  1  0  3  6  8  0 10  1  6  6
  3  0  3 10  8 22  0  3  8] -> size -> 33 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  8 10  6  0  8 10  0  0  8  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 25. 30. 18. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [ 8. 25.  0. 10.  1. 29. 10.  8.  3.  3.] 
adversary owned cards: [ 0  0  0 29  0  0 25  3  3  3  0 10 10  0  1  0  3  6  8  0 10  1  6  6
  3  0  3 10  8 22  0  3  8] -> size -> 33 
adversary victory points: 4
player victory points: -1 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[-0.31784034]
 [-3.2759442 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0.  0.] 
cards in discard: [ 8. 25.  0. 10.  1. 29. 10.  8.  3.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 29  0  0 25  3  3  3  0 10 10  0  1  0  3  6  8  0 10  1  6  6
  3  0  3 10  8 22  0  3  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 18. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [ 0.  8. 10.  6.  0.] 
adversary cards in discard: [8. 0. 8.] 
adversary owned cards: [10  8  8 10  6  0  8 10  0  0  8  0] -> size -> 12 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 49 

action type: buy - action -1.0
Learning step: 2.8269002437591553
desired expected reward: -5.296531677246094



action possibilites: [-1.] 
expected returns: [[-11.774233]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 6.] 
cards in discard: [ 8. 25.  0. 10.  1. 29. 10.  8.  3.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0 29  0  0 25  3  3  3  0 10 10  0  1  0  3  6  8  0 10  1  6  6
  3  0  3 10  8 22  0  3  8] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 18. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [ 0.  8. 10.  6.  0.] 
adversary cards in discard: [8. 0. 8.] 
adversary owned cards: [10  8  8 10  6  0  8 10  0  0  8  0] -> size -> 12 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 69 

action type: take_action - action 10.0
Learning step: 3.3551461696624756
desired expected reward: -0.04617905616760254





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-10.362263 ]
 [-10.8490925]
 [-10.899007 ]
 [-11.405873 ]
 [-10.974055 ]
 [-11.747706 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 6.] 
cards in discard: [ 8. 25.  0. 10.  1. 29. 10.  8.  3.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0 29  0  0 25  3  3  3  0 10 10  0  1  0  3  6  8  0 10  1  6  6
  3  0  3 10  8 22  0  3  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 25. 30. 18. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [ 0.  8. 10.  6.  0.] 
adversary cards in discard: [8. 0. 8.] 
adversary owned cards: [10  8  8 10  6  0  8 10  0  0  8  0] -> size -> 12 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 69 

action type: take_action - action -1.0
Learning step: 3.791393280029297
desired expected reward: -7.982839584350586






Player: 1 
cards in hand: [ 0.  8. 10.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.  6.  0.] 
cards in discard: [8. 0. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8 10  6  0  8 10  0  0  8  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 18. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 8. 25.  0. 10.  1. 29. 10.  8.  3.  3. 10.  3.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0 29  0  0 25  3  3  3  0 10 10  0  1  0  3  6  8  0 10  1  6  6
  3  0  3 10  8 22  0  3  8] -> size -> 33 
adversary victory points: 4
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [8. 0. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8 10  8 10  0  0  8  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 18. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 8. 25.  0. 10.  1. 29. 10.  8.  3.  3. 10.  3.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0 29  0  0 25  3  3  3  0 10 10  0  1  0  3  6  8  0 10  1  6  6
  3  0  3 10  8 22  0  3  8] -> size -> 33 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [8. 0. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8 10  8 10  0  0  8  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 25. 30. 18. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 8. 25.  0. 10.  1. 29. 10.  8.  3.  3. 10.  3.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0 29  0  0 25  3  3  3  0 10 10  0  1  0  3  6  8  0 10  1  6  6
  3  0  3 10  8 22  0  3  8] -> size -> 33 
adversary victory points: 4
player victory points: 0 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[18.702003]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 8. 25.  0. 10.  1. 29. 10.  8.  3.  3. 10.  3.  0.  0.  0.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 29  0  0 25  3  3  3  0 10 10  0  1  0  3  6  8  0 10  1  6  6
  3  0  3 10  8 22  0  3  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 18. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [ 8.  0.  8. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 10  8 10  0  0  8  0] -> size -> 9 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: buy - action -1.0
Learning step: 2.955186367034912
desired expected reward: -8.792518615722656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[16.910942]
 [20.18841 ]
 [18.20574 ]
 [18.444233]
 [21.698084]
 [19.830408]
 [12.787465]
 [17.846386]
 [16.431738]
 [21.599178]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 8. 25.  0. 10.  1. 29. 10.  8.  3.  3. 10.  3.  0.  0.  0.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 29  0  0 25  3  3  3  0 10 10  0  1  0  3  6  8  0 10  1  6  6
  3  0  3 10  8 22  0  3  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 9. 25. 30. 18. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [ 8.  0.  8. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 10  8 10  0  0  8  0] -> size -> 9 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action -1.0
Learning step: 1.4406628608703613
desired expected reward: 20.009599685668945



buy possibilites: [-1] 
expected returns: [[-3.4603405]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 8. 25.  0. 10.  1. 29. 10.  8.  3.  3. 10.  3.  0.  0.  0.  6.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 29  0  0 25  3  3  3  0 10 10  0  1  0  3  6  8  0 10  1  6  6
  3  0  3 10  8 22  0  3  8  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 25. 30. 17. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [ 8.  0.  8. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 10  8 10  0  0  8  0] -> size -> 9 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5.  0.  5. 50.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 52.0 

action type: buy - action 3.0
Learning step: 1.4962341785430908
desired expected reward: 22.014400482177734






Player: 1 
cards in hand: [ 8.  0.  8. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  8. 10. 10.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 10  8 10  0  0  8  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 17. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [ 8.  1.  6. 22.  0.] 
adversary cards in discard: [ 8. 25.  0. 10.  1. 29. 10.  8.  3.  3. 10.  3.  0.  0.  0.  6.  3.  0.
  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0 29  0  0 25  3  3  3  0 10 10  0  1  0  3  6  8  0 10  1  6  6
  3  0  3 10  8 22  0  3  8  3] -> size -> 34 
adversary victory points: 5
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8 10  0  8  0] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 17. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [ 8.  1.  6. 22.  0.] 
adversary cards in discard: [ 8. 25.  0. 10.  1. 29. 10.  8.  3.  3. 10.  3.  0.  0.  0.  6.  3.  0.
  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0 29  0  0 25  3  3  3  0 10 10  0  1  0  3  6  8  0 10  1  6  6
  3  0  3 10  8 22  0  3  8  3] -> size -> 34 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8 10  0  8  0] -> size -> 6 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 25. 30. 17. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [ 8.  1.  6. 22.  0.] 
adversary cards in discard: [ 8. 25.  0. 10.  1. 29. 10.  8.  3.  3. 10.  3.  0.  0.  0.  6.  3.  0.
  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0 29  0  0 25  3  3  3  0 10 10  0  1  0  3  6  8  0 10  1  6  6
  3  0  3 10  8 22  0  3  8  3] -> size -> 34 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [ 8.  1.  6. 22.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22.] 
expected returns: [[37.462715]
 [31.932016]
 [25.00872 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1.  6. 22.  0.] 
cards in discard: [ 8. 25.  0. 10.  1. 29. 10.  8.  3.  3. 10.  3.  0.  0.  0.  6.  3.  0.
  0.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 29  0  0 25  3  3  3  0 10 10  0  1  0  3  6  8  0 10  1  6  6
  3  0  3 10  8 22  0  3  8  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 17. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [8. 0. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 10  0  8  0] -> size -> 6 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: buy - action -1
Learning step: 3.390549421310425
desired expected reward: -0.06979107856750488



action possibilites: [-1] 
expected returns: [[21.914274]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6.] 
cards in discard: [ 8. 25.  0. 10.  1. 29. 10.  8.  3.  3. 10.  3.  0.  0.  0.  6.  3.  0.
  0.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 29  0  0 25  3  3  3  0 10 10  0  1  0  3  6  8  0 10  1  6  6  3
  0  3 10  8  0  3  8  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 17. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [8. 0. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 10  0  8  0] -> size -> 6 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 70 

action type: trash_cards_n_from_hand - action 4
Learning step: 2.8736207485198975
desired expected reward: 25.262624740600586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[13.940148]
 [16.29411 ]
 [21.105541]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6.] 
cards in discard: [ 8. 25.  0. 10.  1. 29. 10.  8.  3.  3. 10.  3.  0.  0.  0.  6.  3.  0.
  0.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 29  0  0 25  3  3  3  0 10 10  0  1  0  3  6  8  0 10  1  6  6  3
  0  3 10  8  0  3  8  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 25. 30. 17. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [8. 0. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 10  0  8  0] -> size -> 6 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 70 

action type: take_action - action -1
Learning step: 2.7956655025482178
desired expected reward: 24.70993995666504



buy possibilites: [-1] 
expected returns: [[6.0065174]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6.] 
cards in discard: [ 8. 25.  0. 10.  1. 29. 10.  8.  3.  3. 10.  3.  0.  0.  0.  6.  3.  0.
  0.  3.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 29  0  0 25  3  3  3  0 10 10  0  1  0  3  6  8  0 10  1  6  6  3
  0  3 10  8  0  3  8  3  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 8. 25. 30. 17. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [8. 0. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 10  0  8  0] -> size -> 6 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5.   0.   5.  50.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 40.0 

action type: buy - action 0.0
Learning step: 1.4381392002105713
desired expected reward: 15.378289222717285






Player: 1 
cards in hand: [8. 0. 8. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 0. 8.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 10  0  8  0] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 17. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [ 6.  3.  0. 10.  3.] 
adversary cards in discard: [ 8. 25.  0. 10.  1. 29. 10.  8.  3.  3. 10.  3.  0.  0.  0.  6.  3.  0.
  0.  3.  0.  0.  0.  8.  1.  6.] 
adversary owned cards: [ 0  0 29  0  0 25  3  3  3  0 10 10  0  1  0  3  6  8  0 10  1  6  6  3
  0  3 10  8  0  3  8  3  0] -> size -> 33 
adversary victory points: 5
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8 10  8  0] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 17. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [ 6.  3.  0. 10.  3.] 
adversary cards in discard: [ 8. 25.  0. 10.  1. 29. 10.  8.  3.  3. 10.  3.  0.  0.  0.  6.  3.  0.
  0.  3.  0.  0.  0.  8.  1.  6.] 
adversary owned cards: [ 0  0 29  0  0 25  3  3  3  0 10 10  0  1  0  3  6  8  0 10  1  6  6  3
  0  3 10  8  0  3  8  3  0] -> size -> 33 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8 10  8  0] -> size -> 5 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 25. 30. 17. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [ 6.  3.  0. 10.  3.] 
adversary cards in discard: [ 8. 25.  0. 10.  1. 29. 10.  8.  3.  3. 10.  3.  0.  0.  0.  6.  3.  0.
  0.  3.  0.  0.  0.  8.  1.  6.] 
adversary owned cards: [ 0  0 29  0  0 25  3  3  3  0 10 10  0  1  0  3  6  8  0 10  1  6  6  3
  0  3 10  8  0  3  8  3  0] -> size -> 33 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [ 6.  3.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[9.547942 ]
 [6.4551935]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  0. 10.  3.] 
cards in discard: [ 8. 25.  0. 10.  1. 29. 10.  8.  3.  3. 10.  3.  0.  0.  0.  6.  3.  0.
  0.  3.  0.  0.  0.  8.  1.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 29  0  0 25  3  3  3  0 10 10  0  1  0  3  6  8  0 10  1  6  6  3
  0  3 10  8  0  3  8  3  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 17. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [ 0.  8.  8.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 10  8  0] -> size -> 5 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: buy - action -1
Learning step: 2.382161855697632
desired expected reward: 8.388679504394531



action possibilites: [-1.] 
expected returns: [[2.4281123]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 3. 0.] 
cards in discard: [ 8. 25.  0. 10.  1. 29. 10.  8.  3.  3. 10.  3.  0.  0.  0.  6.  3.  0.
  0.  3.  0.  0.  0.  8.  1.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0 29  0  0 25  3  3  3  0 10 10  0  1  0  3  6  8  0 10  1  6  6  3
  0  3 10  8  0  3  8  3  0] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 17. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [ 0.  8.  8.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 10  8  0] -> size -> 5 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 71 

action type: take_action - action 10.0
Learning step: 3.2818729877471924
desired expected reward: 9.737062454223633





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-4.59039  ]
 [ 0.8781462]
 [ 3.523651 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 3. 0.] 
cards in discard: [ 8. 25.  0. 10.  1. 29. 10.  8.  3.  3. 10.  3.  0.  0.  0.  6.  3.  0.
  0.  3.  0.  0.  0.  8.  1.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0 29  0  0 25  3  3  3  0 10 10  0  1  0  3  6  8  0 10  1  6  6  3
  0  3 10  8  0  3  8  3  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 25. 30. 17. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [ 0.  8.  8.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 10  8  0] -> size -> 5 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 70 

action type: take_action - action -1.0
Learning step: 3.3828670978546143
desired expected reward: 5.81097936630249



buy possibilites: [-1] 
expected returns: [[14.657203]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 3. 0.] 
cards in discard: [ 8. 25.  0. 10.  1. 29. 10.  8.  3.  3. 10.  3.  0.  0.  0.  6.  3.  0.
  0.  3.  0.  0.  0.  8.  1.  6.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0 29  0  0 25  3  3  3  0 10 10  0  1  0  3  6  8  0 10  1  6  6  3
  0  3 10  8  0  3  8  3  0  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 16. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [ 0.  8.  8.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 10  8  0] -> size -> 5 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 89 

action type: buy - action 3.0
Learning step: 4.735879421234131
desired expected reward: 5.6140289306640625






Player: 1 
cards in hand: [ 0.  8.  8.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  8.  8. 10.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 10  8  0] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 16. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [ 6.  0. 10.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 29  0  0 25  3  3  3  0 10 10  0  1  0  3  6  8  0 10  1  6  6  3
  0  3 10  8  0  3  8  3  0  3] -> size -> 34 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  8 10  8  0] -> size -> 5 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 16. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [ 6.  0. 10.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 29  0  0 25  3  3  3  0 10 10  0  1  0  3  6  8  0 10  1  6  6  3
  0  3 10  8  0  3  8  3  0  3] -> size -> 34 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 8  8 10  8] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 16. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [ 6.  0. 10.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 29  0  0 25  3  3  3  0 10 10  0  1  0  3  6  8  0 10  1  6  6  3
  0  3 10  8  0  3  8  3  0  3] -> size -> 34 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8.  8.] 
owned cards: [ 8 10  8] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 16. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [ 6.  0. 10.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 29  0  0 25  3  3  3  0 10 10  0  1  0  3  6  8  0 10  1  6  6  3
  0  3 10  8  0  3  8  3  0  3] -> size -> 34 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8.  8.] 
owned cards: [ 8 10  8] -> size -> 3 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 25. 30. 16. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [ 6.  0. 10.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 29  0  0 25  3  3  3  0 10 10  0  1  0  3  6  8  0 10  1  6  6  3
  0  3 10  8  0  3  8  3  0  3] -> size -> 34 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.  8.  8.] 
owned cards: [ 8 10  8  0] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30. 16. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [ 6.  0. 10.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 29  0  0 25  3  3  3  0 10 10  0  1  0  3  6  8  0 10  1  6  6  3
  0  3 10  8  0  3  8  3  0  3] -> size -> 34 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [ 6.  0. 10.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[-12.241627]
 [-11.134267]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10.  3.  3.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 29  0  0 25  3  3  3  0 10 10  0  1  0  3  6  8  0 10  1  6  6  3
  0  3 10  8  0  3  8  3  0  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30. 16. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [ 8.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 61 

action type: buy - action -1
Learning step: 2.0765628814697266
desired expected reward: 16.7337646484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-12.04292 ]
 [-12.860698]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 10.  3.  3.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 29  0  0 25  3  3  3  0 10 10  0  1  0  3  6  8  0 10  1  6  6  3
  0  3 10  8  0  3  8  3  0  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 25. 30. 16. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [ 8.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 61 

action type: take_action - action -1.0
Learning step: 3.333155870437622
desired expected reward: -7.920309066772461



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8.  8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  0. 10.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  8  0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30. 16. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 6.  0. 10.  3.  3.] 
adversary owned cards: [ 0  0 29  0  0 25  3  3  3  0 10 10  0  1  0  3  6  8  0 10  1  6  6  3
  0  3 10  8  0  3  8  3  0  3] -> size -> 34 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30. 16. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 6.  0. 10.  3.  3.] 
adversary owned cards: [ 0  0 29  0  0 25  3  3  3  0 10 10  0  1  0  3  6  8  0 10  1  6  6  3
  0  3 10  8  0  3  8  3  0  3] -> size -> 34 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8] -> size -> 2 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 7. 25. 30. 16. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 6.  0. 10.  3.  3.] 
adversary owned cards: [ 0  0 29  0  0 25  3  3  3  0 10 10  0  1  0  3  6  8  0 10  1  6  6  3
  0  3 10  8  0  3  8  3  0  3] -> size -> 34 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 16. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 6.  0. 10.  3.  3.] 
adversary owned cards: [ 0  0 29  0  0 25  3  3  3  0 10 10  0  1  0  3  6  8  0 10  1  6  6  3
  0  3 10  8  0  3  8  3  0  3] -> size -> 34 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[28.013985]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 6.  0. 10.  3.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 29  0  0 25  3  3  3  0 10 10  0  1  0  3  6  8  0 10  1  6  6  3
  0  3 10  8  0  3  8  3  0  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 16. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [ 8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0] -> size -> 3 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 61 

action type: buy - action -1.0
Learning step: 4.291595458984375
desired expected reward: -8.569123268127441





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[20.502605]
 [23.201262]
 [22.318718]
 [25.179998]
 [22.090038]
 [26.158861]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 6.  0. 10.  3.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 29  0  0 25  3  3  3  0 10 10  0  1  0  3  6  8  0 10  1  6  6  3
  0  3 10  8  0  3  8  3  0  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 25. 30. 16. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  1.  9. 10.] 
adversary cards in hand: [ 8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0] -> size -> 3 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 61 

action type: take_action - action -1.0
Learning step: 2.2474353313446045
desired expected reward: 28.850093841552734



Player 0 won the game! 



Player 0 bought cards:
Copper: 9 
Silver: 3 
Gold: 0 
Estate: 9 
Duchy: 0 
Province: 0 
Curse: 5 

Remodel: 0 
Workshop: 2 
Chapel: 4 
Witch: 1 
Poacher: 1 
Militia: 1 
Market: 0 
Village: 6 
Library: 1 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 6.  0. 10.  3.  3. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 29  0  0 25  3  3  3  0 10 10  0  1  0  3  6  8  0 10  1  6  6  3
  0  3 10  8  0  3  8  3  0  3 10] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 16. 30.  8.  0. 10.  4.  0.  9.  8.  8. 10.  0.  9. 10.] 
adversary cards in hand: [ 8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0] -> size -> 3 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5 500   6  60   0   0   0   0   0   0   0   0   0   0   9   0] 
sum of rewards: 570 

action type: buy - action 10.0
Learning step: 27.395498275756836
desired expected reward: 49.48554611206055



