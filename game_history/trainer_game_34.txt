 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[321.28088]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500   -2  -50    0    0   20  -30    0    0    0    0    0    0
    0    0] 
sum of rewards: -567 

action type: buy - action 0.0
Learning step: -28.2437801361084
desired expected reward: -30.36814308166504





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[300.92865]
 [309.2501 ]
 [308.17117]
 [291.9561 ]
 [306.9064 ]
 [318.3616 ]
 [310.596  ]
 [318.52225]
 [302.10376]
 [309.5151 ]
 [310.95023]
 [327.08298]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.215018272399902
desired expected reward: 316.4862060546875



buy possibilites: [-1] 
expected returns: [[280.3133]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 30 

action type: buy - action 15.0
Learning step: -7.740462779998779
desired expected reward: 303.20977783203125






Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [15.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [15.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [15.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[317.25916]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [15.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [8. 0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -6.943939208984375
desired expected reward: 273.3693542480469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[300.4225 ]
 [307.43967]
 [306.5819 ]
 [292.86838]
 [315.3819 ]
 [308.59842]
 [307.73886]
 [323.62775]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [15.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [8. 0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.925895690917969
desired expected reward: 309.81744384765625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [8. 0. 0. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [8. 0. 0. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 8.  0.  0.  3.  0.  3. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[296.06036]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -9.56831169128418
desired expected reward: 314.0594177246094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[279.92847]
 [287.32547]
 [286.37906]
 [272.2804 ]
 [285.24823]
 [295.44513]
 [288.53036]
 [295.57272]
 [280.98633]
 [287.58218]
 [288.84927]
 [303.3685 ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.361952781677246
desired expected reward: 289.9969787597656



buy possibilites: [-1] 
expected returns: [[279.6874]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 16] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  9. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 30 

action type: buy - action 16.0
Learning step: -6.469442844390869
desired expected reward: 278.7787170410156






Player: 1 
cards in hand: [0. 3. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 14] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  9. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [16.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 14] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  9. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [16.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 16] -> size -> 12 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 14] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  9. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [16.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 16] -> size -> 12 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 14  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  8. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [16.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 16] -> size -> 12 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[356.23853]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [16.  3.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 16] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  8. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [8. 8. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 14  8] -> size -> 12 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1
Learning step: -5.563459873199463
desired expected reward: 274.12396240234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[332.6236 ]
 [340.7656 ]
 [339.81607]
 [323.89023]
 [349.8261 ]
 [342.0763 ]
 [341.1246 ]
 [358.73538]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [16.  3.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 16] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  8. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [8. 8. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 14  8] -> size -> 12 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -9.542821884155273
desired expected reward: 346.942138671875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [8. 8. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 14  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  8. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 16.  3.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 16] -> size -> 12 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [8. 8. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 14  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  8. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 16.  3.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 16] -> size -> 12 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 8.  8.  0.  0.  3. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 14  8 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 16.  3.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 16] -> size -> 12 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 0. 16.  3.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 15.] 
expected returns: [[371.9577 ]
 [349.48682]
 [354.21198]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  3.  0. 15.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 16] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  8. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 14  8 29] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1.0
Learning step: -9.285651206970215
desired expected reward: 349.44976806640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[342.8387 ]
 [350.3368 ]
 [333.8664 ]
 [352.75073]
 [371.55014]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  3.  0. 15.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 16] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  8. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 14  8 29] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -10.13688850402832
desired expected reward: 363.2079772949219



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0.  8. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 14.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 14  8 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 0. 16.  3.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 16] -> size -> 12 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 14  8 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [ 0. 16.  3.  0. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 16] -> size -> 12 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 14  8 29] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [ 0. 16.  3.  0. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 16] -> size -> 12 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0.] 
cards in discard: [1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 14  8 29  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [ 0. 16.  3.  0. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 16] -> size -> 12 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[278.24576]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [ 0. 16.  3.  0. 15.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 16] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  3. 29.] 
adversary cards in discard: [ 1. 14.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 14  8 29  1] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: discard_down_to_3_cards - action 1
Learning step: -8.8849515914917
desired expected reward: 301.5345458984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[253.27278]
 [260.2044 ]
 [245.2126 ]
 [262.13763]
 [278.6091 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 0. 16.  3.  0. 15.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 16] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8. 10.  9. 10.  8. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  3. 29.] 
adversary cards in discard: [ 1. 14.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 14  8 29  1] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -7.3910417556762695
desired expected reward: 269.76556396484375



buy possibilites: [-1] 
expected returns: [[308.57373]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 0. 16.  3.  0. 15.  0.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 16  6] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8.  9.  9. 10.  8. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  3. 29.] 
adversary cards in discard: [ 1. 14.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 14  8 29  1] -> size -> 14 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -303.0 

action type: buy - action 6.0
Learning step: -20.467721939086914
desired expected reward: 224.74488830566406






Player: 1 
cards in hand: [ 0.  3.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  3. 29.] 
cards in discard: [ 1. 14.  0.  0.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 14  8 29  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9.  9. 10.  8. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 16  6] -> size -> 13 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 1. 14.  0.  0.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 14  8 29  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8.  9.  9. 10.  8. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 16  6] -> size -> 13 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 1. 14.  0.  0.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 14  8 29  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8.  9.  9. 10.  8. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 16  6] -> size -> 13 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 1. 14.  0.  0.  8.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 14  8 29  1  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8.  9.  9. 10.  7. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 16  6] -> size -> 13 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[361.7019]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 16  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9.  9. 10.  7. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [8. 8. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 14  8 29  1  8] -> size -> 15 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: -7.391293525695801
desired expected reward: 301.18243408203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[344.87628]
 [353.17285]
 [352.19693]
 [335.75208]
 [350.8537 ]
 [362.3939 ]
 [354.50317]
 [362.5057 ]
 [346.121  ]
 [353.52417]
 [354.99078]
 [371.74677]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 16  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8.  9.  9. 10.  7. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [8. 8. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 14  8 29  1  8] -> size -> 15 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -10.322820663452148
desired expected reward: 356.4952392578125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8. 8. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 3. 8. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 14  8 29  1  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9.  9. 10.  7. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 15.  6.  0.  3.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 16  6] -> size -> 13 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9.  9. 10.  7. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 15.  6.  0.  3.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 16  6] -> size -> 13 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9.  9. 10.  7. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 15.  6.  0.  3.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 16  6] -> size -> 13 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 0. 15.  6.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[353.9004 ]
 [336.86908]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  6.  0.  3.] 
cards in discard: [0. 3. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 16  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9.  9. 10.  7. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [8. 8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8] -> size -> 12 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1.0
Learning step: -10.337803840637207
desired expected reward: 361.40899658203125



action possibilites: [-1] 
expected returns: [[395.64386]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3.] 
cards in discard: [0. 3. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 16  6] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8.  9.  9. 10.  7. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [8. 8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8] -> size -> 12 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: take_action - action 15.0
Learning step: -6.632920742034912
desired expected reward: 331.0652160644531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[367.24893]
 [375.66367]
 [374.8638 ]
 [359.26508]
 [373.32825]
 [385.16357]
 [377.00687]
 [385.2415 ]
 [368.62296]
 [376.20325]
 [377.7737 ]
 [393.98178]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3.] 
cards in discard: [0. 3. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 16  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8.  9.  9. 10.  7. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [8. 8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8] -> size -> 12 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: take_action - action -1
Learning step: -9.759413719177246
desired expected reward: 385.88446044921875






Player: 1 
cards in hand: [3. 0. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [8. 8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9.  9. 10.  7. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  6. 16.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 16  6] -> size -> 12 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [8. 8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 30. 30.  8.  9.  9. 10.  7. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  6. 16.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 16  6] -> size -> 12 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [8. 8. 1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 30. 30.  8.  9.  9. 10.  7. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  6. 16.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 16  6] -> size -> 12 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 0.  6. 16.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[305.0895 ]
 [288.53864]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 16.  3.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 16  6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8.  9.  9. 10.  7. 10.  9.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 14.  0. 29.] 
adversary cards in discard: [8. 8. 1. 3. 0. 0. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8  1] -> size -> 13 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1.0
Learning step: -12.519157409667969
desired expected reward: 381.46258544921875



action possibilites: [-1] 
expected returns: [[341.03256]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3 15 16  6 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8.  9.  9. 10.  7. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 14.  0. 29.] 
adversary cards in discard: [8. 8. 1. 3. 0. 0. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8  1] -> size -> 13 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 25 

action type: gain_card_n - action 9
Learning step: -3.338179111480713
desired expected reward: 241.89002990722656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[302.09943]
 [310.08313]
 [292.6855 ]
 [312.332  ]
 [330.87476]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3 15 16  6 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 30. 30.  8.  9.  9. 10.  7. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 14.  0. 29.] 
adversary cards in discard: [8. 8. 1. 3. 0. 0. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8  1] -> size -> 13 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: take_action - action -1
Learning step: -9.036233901977539
desired expected reward: 331.996337890625



buy possibilites: [-1] 
expected returns: [[271.94727]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0.] 
cards in discard: [10.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3 15 16  6 10  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8.  9.  9. 10.  6. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 14.  0. 29.] 
adversary cards in discard: [8. 8. 1. 3. 0. 0. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8  1] -> size -> 13 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 24 

action type: buy - action 8.0
Learning step: -8.297785758972168
desired expected reward: 304.0341796875






Player: 1 
cards in hand: [ 0.  0. 14.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  0. 29.] 
cards in discard: [8. 8. 1. 3. 0. 0. 1. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8.  9.  9. 10.  6. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 15.  0.] 
adversary cards in discard: [10.  8. 16.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 15 16  6 10  8] -> size -> 13 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 30. 30.  8.  9.  9. 10.  6. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 15.  0.] 
adversary cards in discard: [10.  8. 16.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 15 16  6 10  8] -> size -> 13 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 28. 30. 30. 30.  8.  9.  9. 10.  6. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.] 
adversary cards in discard: [10.  8. 16.  0.  6.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 15 16  6 10  8] -> size -> 13 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 7 
card supply: [30. 28. 30. 30. 30.  8.  9.  9. 10.  6. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 15.  0.] 
adversary cards in discard: [10.  8. 16.  0.  6.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 15 16  6 10  8] -> size -> 13 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[315.00656]
 [297.48407]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.] 
cards in discard: [10.  8. 16.  0.  6.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 15 16  6 10  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8.  9.  9. 10.  6. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [8. 3. 1. 0. 0.] 
adversary cards in discard: [29. 14.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8  1] -> size -> 13 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: discard_down_to_3_cards - action 2
Learning step: -7.0492472648620605
desired expected reward: 269.40997314453125



action possibilites: [-1] 
expected returns: [[291.283]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [10.  8. 16.  0.  6.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3 15 16  6 10  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 28. 30. 30. 30.  8.  9.  9. 10.  6. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [8. 3. 1. 0. 0.] 
adversary cards in discard: [29. 14.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8  1] -> size -> 13 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: take_action - action 15.0
Learning step: -7.47713041305542
desired expected reward: 289.1427917480469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[275.9053 ]
 [281.47208]
 [280.65234]
 [270.2697 ]
 [279.83295]
 [287.69757]
 [282.4094 ]
 [287.86874]
 [276.57086]
 [281.5877 ]
 [282.60104]
 [293.88492]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [10.  8. 16.  0.  6.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3 15 16  6 10  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 30. 30.  8.  9.  9. 10.  6. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [8. 3. 1. 0. 0.] 
adversary cards in discard: [29. 14.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8  1] -> size -> 13 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: take_action - action -1
Learning step: -7.2828369140625
desired expected reward: 284.0001525878906






Player: 1 
cards in hand: [8. 3. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 1. 0. 0.] 
cards in discard: [29. 14.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8.  9.  9. 10.  6. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 15 16  6 10  8] -> size -> 12 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 1. 0. 0.] 
cards in discard: [29. 14.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 30. 30.  8.  9.  9. 10.  6. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 15 16  6 10  8] -> size -> 12 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 1. 0. 0.] 
cards in discard: [29. 14.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8  1  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 28. 30. 30. 30.  8.  9.  9. 10.  6. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 15 16  6 10  8] -> size -> 12 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [0. 8. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[293.4477]
 [277.0227]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 15 16  6 10  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9.  9. 10.  6. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 1. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8  1  0] -> size -> 14 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1.0
Learning step: -8.314005851745605
desired expected reward: 285.5709533691406



action possibilites: [-1] 
expected returns: [[240.37933]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 15 16  6 10  8] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9.  9. 10.  6. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 1. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8  1  0] -> size -> 14 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: trash_cards_n_from_hand - action 1
Learning step: -8.102428436279297
desired expected reward: 267.1168518066406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[212.78221]
 [219.07675]
 [218.30357]
 [206.83624]
 [226.10031]
 [220.09132]
 [219.31563]
 [233.07378]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 15 16  6 10  8] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 30. 30.  8.  9.  9. 10.  6. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 1. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8  1  0] -> size -> 14 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: -6.671766757965088
desired expected reward: 233.7075653076172






Player: 1 
cards in hand: [0. 0. 0. 1. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 8.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8  1  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9.  9. 10.  6. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3. 16.  0. 10.] 
adversary cards in discard: [8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3 15 16  6 10  8] -> size -> 11 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 8.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8  1  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 28. 30. 30. 30.  8.  9.  9. 10.  6. 10.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3. 16.  0. 10.] 
adversary cards in discard: [8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3 15 16  6 10  8] -> size -> 11 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 8.] 
cards in discard: [29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8  1  0 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 30. 30.  8.  9.  9. 10.  6. 10.  8.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3. 16.  0. 10.] 
adversary cards in discard: [8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3 15 16  6 10  8] -> size -> 11 
adversary victory points: 0
player victory points: 1 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 16.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
expected returns: [[323.83432]
 [308.62112]
 [310.47275]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 16.  0. 10.] 
cards in discard: [8. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 15 16  6 10  8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9.  9. 10.  6. 10.  8.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 1. 0. 0. 0.] 
adversary cards in discard: [29.  0.  0.  0.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8  1  0 29] -> size -> 15 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1.0
Learning step: -5.277212619781494
desired expected reward: 227.79656982421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[302.88303]
 [308.1968 ]
 [296.82773]
 [310.10898]
 [322.42297]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 16.  0. 10.] 
cards in discard: [8. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 15 16  6 10  8] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 30. 30.  8.  9.  9. 10.  6. 10.  8.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 1. 0. 0. 0.] 
adversary cards in discard: [29.  0.  0.  0.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8  1  0 29] -> size -> 15 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: -9.713821411132812
desired expected reward: 311.56085205078125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 1. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [29.  0.  0.  0.  1.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8  1  0 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9.  9. 10.  6. 10.  8.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  0.  3.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 15 16  6 10  8] -> size -> 11 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [29.  0.  0.  0.  1.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8  1  0 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 6 
card supply: [29. 28. 30. 30. 30.  8.  9.  9. 10.  6. 10.  8.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  0.  3.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 15 16  6 10  8] -> size -> 11 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [29.  0.  0.  0.  1.  8. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8  1  0 29 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 30. 30.  8.  9.  9. 10.  6. 10.  7.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  0.  3.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 15 16  6 10  8] -> size -> 11 
adversary victory points: 0
player victory points: 1 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 8.  0.  3.  6. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
expected returns: [[285.17148]
 [270.13712]
 [270.59494]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3.  6. 15.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 15 16  6 10  8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9.  9. 10.  6. 10.  7.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 29.  8. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8  1  0 29 29] -> size -> 16 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1.0
Learning step: -10.566441535949707
desired expected reward: 311.8565673828125



action possibilites: [-1] 
expected returns: [[200.96576]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 6.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3 15 16  6 10  8] -> size -> 10 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 28. 30. 30. 30.  8.  9.  9. 10.  6. 10.  7.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 29.  8. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8  1  0 29 29] -> size -> 16 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 15.0
Learning step: -8.728074073791504
desired expected reward: 261.2679748535156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[173.08978]
 [180.89594]
 [180.3659 ]
 [165.38437]
 [190.11476]
 [182.10136]
 [181.5669 ]
 [199.26385]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 6.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3 15 16  6 10  8] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 30. 30.  8.  9.  9. 10.  6. 10.  7.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 29.  8. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8  1  0 29 29] -> size -> 16 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: -5.505379676818848
desired expected reward: 195.4603729248047






Player: 1 
cards in hand: [ 0. 29.  8. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 14.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  8. 14.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8  1  0 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9.  9. 10.  6. 10.  7.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 16.  0.  0.  0.] 
adversary cards in discard: [15.  8.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3 15 16  6 10  8] -> size -> 10 
adversary victory points: 0
player victory points: 1 


action possibilites: [-1.  8. 14. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 14.  3. 29.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8  1  0 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 30. 30.  8.  9.  9. 10.  6. 10.  7.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 16.  0.  0.  0.] 
adversary cards in discard: [15.  8.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3 15 16  6 10  8] -> size -> 10 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 14.  3. 29.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8  1  0 29 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 30. 30.  8.  9.  9. 10.  6. 10.  7.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 16.  0.  0.  0.] 
adversary cards in discard: [15.  8.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3 15 16  6 10  8] -> size -> 10 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 14.  3. 29.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8  1  0 29 29  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9.  9. 10.  5. 10.  7.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 16.  0.  0.  0.] 
adversary cards in discard: [15.  8.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3 15 16  6 10  8] -> size -> 10 
adversary victory points: 0
player victory points: 1 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 0. 16.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[229.5834]
 [209.9422]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  0.  0.] 
cards in discard: [15.  8.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16  6 10  8] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9.  9. 10.  5. 10.  7.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  0.  1.] 
adversary cards in discard: [ 8. 29.  0.  8. 14.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8  1  0 29 29  8] -> size -> 17 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1.0
Learning step: -5.639597415924072
desired expected reward: 193.6242218017578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[204.51468]
 [212.2144 ]
 [211.50711]
 [196.33682]
 [210.10223]
 [221.04932]
 [213.42148]
 [221.09567]
 [205.83545]
 [212.71036]
 [214.1744 ]
 [229.74345]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  0.  0.] 
cards in discard: [15.  8.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16  6 10  8] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 30. 30.  8.  9.  9. 10.  5. 10.  7.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  0.  1.] 
adversary cards in discard: [ 8. 29.  0.  8. 14.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8  1  0 29 29  8] -> size -> 17 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: -7.274332523345947
desired expected reward: 222.9260711669922



buy possibilites: [-1] 
expected returns: [[285.64825]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  0.  0.] 
cards in discard: [15.  8.  3.  6. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16  6 10  8 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 30. 30.  8.  9.  9. 10.  5. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  0.  1.] 
adversary cards in discard: [ 8. 29.  0.  8. 14.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8  1  0 29 29  8] -> size -> 17 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5.    0.    0.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -10.5 

action type: buy - action 10.0
Learning step: -4.7334303855896
desired expected reward: 207.97689819335938






Player: 1 
cards in hand: [ 0.  0. 29.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  1.] 
cards in discard: [ 8. 29.  0.  8. 14.  3. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8  1  0 29 29  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9.  9. 10.  5. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 15 16  6 10  8 10] -> size -> 11 
adversary victory points: 0
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [ 8. 29.  0.  8. 14.  3. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8  1  0 29 29  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 30. 30.  8.  9.  9. 10.  5. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 15 16  6 10  8 10] -> size -> 11 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [ 8. 29.  0.  8. 14.  3. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8  1  0 29 29  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 7 
card supply: [29. 28. 30. 30. 30.  8.  9.  9. 10.  5. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 15 16  6 10  8 10] -> size -> 11 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [ 8. 29.  0.  8. 14.  3. 29. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8  1  0 29 29  8 16] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 28. 30. 30. 30.  8.  9.  8. 10.  5. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 15 16  6 10  8 10] -> size -> 11 
adversary victory points: 0
player victory points: 1 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 0.  8.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10.] 
expected returns: [[269.03427]
 [251.32257]
 [250.82062]
 [250.82062]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 10. 10.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16  6 10  8 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9.  8. 10.  5. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 8. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8  1  0 29 29  8 16] -> size -> 18 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1
Learning step: -9.114160537719727
desired expected reward: 276.5340881347656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[242.62233]
 [249.7861 ]
 [234.76488]
 [251.65488]
 [268.3372 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 10. 10.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16  6 10  8 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 30. 30.  8.  9.  8. 10.  5. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 8. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8  1  0 29 29  8 16] -> size -> 18 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: -8.392571449279785
desired expected reward: 261.1329650878906



buy possibilites: [-1] 
expected returns: [[235.66098]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 10. 10.] 
cards in discard: [6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16  6 10  8 10  6] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 30. 30.  8.  8.  8. 10.  5. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 8. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8  1  0 29 29  8 16] -> size -> 18 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -326.0 

action type: buy - action 6.0
Learning step: -22.735870361328125
desired expected reward: 212.0289764404297






Player: 1 
cards in hand: [8. 8. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14  8 29  1  8  1  0 29 29  8 16] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  8.  8. 10.  5. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  6. 15.] 
adversary cards in discard: [ 6.  0.  8.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  3 15 16  6 10  8 10  6] -> size -> 12 
adversary victory points: -1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 14  8 29  8  1  0 29 29  8 16] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  8.  8. 10.  5. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  6. 15.] 
adversary cards in discard: [ 6.  0.  8.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  3 15 16  6 10  8 10  6] -> size -> 12 
adversary victory points: -1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 14  8 29  8  1  0 29 29  8 16] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  8.  8. 10.  5. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  6. 15.] 
adversary cards in discard: [ 6.  0.  8.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  3 15 16  6 10  8 10  6] -> size -> 12 
adversary victory points: -1
player victory points: 1 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0.  6. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[221.45505]
 [210.45882]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  6. 15.] 
cards in discard: [ 6.  0.  8.  0. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16  6 10  8 10  6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  8.  8. 10.  5. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [16. 29.  8.  0.  0.] 
adversary cards in discard: [8. 8.] 
adversary owned cards: [ 0  0  0  0  3 14  8 29  8  1  0 29 29  8 16] -> size -> 15 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: buy - action -1
Learning step: -8.192641258239746
desired expected reward: 227.4683380126953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[202.5842 ]
 [206.9553 ]
 [197.17436]
 [208.4191 ]
 [219.70131]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  6. 15.] 
cards in discard: [ 6.  0.  8.  0. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16  6 10  8 10  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 30. 30.  8.  8.  8. 10.  5. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [16. 29.  8.  0.  0.] 
adversary cards in discard: [8. 8.] 
adversary owned cards: [ 0  0  0  0  3 14  8 29  8  1  0 29 29  8 16] -> size -> 15 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1.0
Learning step: -7.499497413635254
desired expected reward: 212.6092071533203



buy possibilites: [-1] 
expected returns: [[316.21313]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  6. 15.] 
cards in discard: [ 6.  0.  8.  0. 10. 10.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16  6 10  8 10  6  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  8.  8. 10.  4. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [16. 29.  8.  0.  0.] 
adversary cards in discard: [8. 8.] 
adversary owned cards: [ 0  0  0  0  3 14  8 29  8  1  0 29 29  8 16] -> size -> 15 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -18 

action type: buy - action 8.0
Learning step: -4.022399425506592
desired expected reward: 204.39669799804688






Player: 1 
cards in hand: [16. 29.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 29.  8.  0.  0.] 
cards in discard: [8. 8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  8 29  8  1  0 29 29  8 16] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  8.  8. 10.  4. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  0.  8.  6. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 15 16  6 10  8 10  6  8] -> size -> 13 
adversary victory points: -1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [8. 8. 4.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3 14  8  8  1  0 29 29  8 16  4] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 29.  8.  8.  8. 10.  4. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  0.  8.  6. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 15 16  6 10  8 10  6  8] -> size -> 13 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0.] 
cards in discard: [8. 8. 4.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3 14  8  8  1  0 29 29  8 16  4] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 30. 29.  8.  8.  8. 10.  4. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  0.  8.  6. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 15 16  6 10  8 10  6  8] -> size -> 13 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  8.  6. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
expected returns: [[242.24493]
 [230.13101]
 [227.69133]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  8.  6. 16.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16  6 10  8 10  6  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 29.  8.  8.  8. 10.  4. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3. 14. 29. 29.] 
adversary cards in discard: [ 8.  8.  4. 16.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 14  8  8  1  0 29 29  8 16  4] -> size -> 15 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -13.247200012207031
desired expected reward: 302.9659423828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[222.0464 ]
 [216.06125]
 [240.40952]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  8.  6. 16.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16  6 10  8 10  6  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 28. 30. 30. 29.  8.  8.  8. 10.  4. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3. 14. 29. 29.] 
adversary cards in discard: [ 8.  8.  4. 16.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 14  8  8  1  0 29 29  8 16  4] -> size -> 15 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -9.676945686340332
desired expected reward: 232.9752960205078



buy possibilites: [-1] 
expected returns: [[254.72888]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  8.  6. 16.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16  6 10  8 10  6  8  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 30. 29.  8.  7.  8. 10.  4. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3. 14. 29. 29.] 
adversary cards in discard: [ 8.  8.  4. 16.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 14  8  8  1  0 29 29  8 16  4] -> size -> 15 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2.  -60.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -367.0 

action type: buy - action 6.0
Learning step: -23.421663284301758
desired expected reward: 192.63958740234375






Player: 1 
cards in hand: [ 0.  3. 14. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 14. 29. 29.] 
cards in discard: [ 8.  8.  4. 16.  8.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  8  8  1  0 29 29  8 16  4] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 29.  8.  7.  8. 10.  4. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 15. 10.  8.  3.] 
adversary cards in discard: [ 6.  6.  0.  8.  6. 16.] 
adversary owned cards: [ 0  0  0  0  3 15 16  6 10  8 10  6  8  6] -> size -> 14 
adversary victory points: -2
player victory points: 4 


action possibilites: [-1. 14. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 14. 29.  0.] 
cards in discard: [ 8.  8.  4. 16.  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 14  8  8  1  0 29 29  8 16  4] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 30. 29.  8.  7.  8. 10.  4. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 15. 10.  8.  3.] 
adversary cards in discard: [ 6.  6.  0.  8.  6. 16.] 
adversary owned cards: [ 0  0  0  0  3 15 16  6 10  8 10  6  8  6] -> size -> 14 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 14. 29.  0.] 
cards in discard: [ 8.  8.  4. 16.  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 14  8  8  1  0 29 29  8 16  4] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 30. 29.  8.  7.  8. 10.  4. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 15. 10.  8.  3.] 
adversary cards in discard: [ 6.  6.  0.  8.  6. 16.] 
adversary owned cards: [ 0  0  0  0  3 15 16  6 10  8 10  6  8  6] -> size -> 14 
adversary victory points: -2
player victory points: 4 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 0. 15. 10.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.  8.] 
expected returns: [[276.0233 ]
 [260.71216]
 [259.29742]
 [260.19504]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 10.  8.  3.] 
cards in discard: [ 6.  6.  0.  8.  6. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16  6 10  8 10  6  8  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 29.  8.  7.  8. 10.  4. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  0. 14.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 14  8  8  1  0 29 29  8 16  4] -> size -> 15 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1
Learning step: -10.072260856628418
desired expected reward: 244.6566162109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[249.37112]
 [241.21422]
 [274.14798]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 10.  8.  3.] 
cards in discard: [ 6.  6.  0.  8.  6. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16  6 10  8 10  6  8  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 28. 30. 30. 29.  8.  7.  8. 10.  4. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  0. 14.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 14  8  8  1  0 29 29  8 16  4] -> size -> 15 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1.0
Learning step: -11.040785789489746
desired expected reward: 261.99212646484375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8.  0. 14.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 14.  0.  1.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  8  8  1  0 29 29  8 16  4] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 29.  8.  7.  8. 10.  4. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 15 16  6 10  8 10  6  8  6] -> size -> 14 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 14.  0.  1.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  8  8  1  0 29 29  8 16  4] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 30. 29.  8.  7.  8. 10.  4. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 15 16  6 10  8 10  6  8  6] -> size -> 14 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 14.  0.  1.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  8  8  1  0 29 29  8 16  4  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 28. 30. 30. 29.  8.  7.  8. 10.  4. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 15 16  6 10  8 10  6  8  6] -> size -> 14 
adversary victory points: -2
player victory points: 4 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[257.0199 ]
 [244.92502]
 [244.0555 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16  6 10  8 10  6  8  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 29.  8.  7.  8. 10.  4. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8. 29.  0.  8.  0.] 
adversary cards in discard: [ 0.  8.  0. 14.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3 14  8  8  1  0 29 29  8 16  4  0] -> size -> 16 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1.0
Learning step: -11.412820816040039
desired expected reward: 262.7351989746094



action possibilites: [-1.  8.] 
expected returns: [[231.65472]
 [218.60257]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3 15 16  6 10  8 10  6  8  6] -> size -> 14 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 29.  8.  7.  8. 10.  4. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8. 29.  0.  8.  0.] 
adversary cards in discard: [ 0.  8.  0. 14.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3 14  8  8  1  0 29 29  8 16  4  0] -> size -> 16 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action 10.0
Learning step: -9.302456855773926
desired expected reward: 232.5836181640625



action possibilites: [-1.] 
expected returns: [[211.05133]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 29.  8.  7.  8. 10.  4. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8. 29.  0.  8.  0.] 
adversary cards in discard: [ 0.  8.  0. 14.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3 14  8  8  1  0 29 29  8 16  4  0] -> size -> 16 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: trash_cards_n_from_hand - action 1
Learning step: -6.409414768218994
desired expected reward: 200.75198364257812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[176.34428]
 [182.70688]
 [182.12471]
 [169.5987 ]
 [190.00758]
 [183.70535]
 [183.11859]
 [197.1746 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 30. 29.  8.  7.  8. 10.  4. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8. 29.  0.  8.  0.] 
adversary cards in discard: [ 0.  8.  0. 14.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3 14  8  8  1  0 29 29  8 16  4  0] -> size -> 16 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -7.067958831787109
desired expected reward: 203.98336791992188






Player: 1 
cards in hand: [ 8. 29.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  0.  8.  0.] 
cards in discard: [ 0.  8.  0. 14.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 14  8  8  1  0 29 29  8 16  4  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 29.  8.  7.  8. 10.  4. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [15. 16.  0.  6.  3.] 
adversary cards in discard: [10.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6] -> size -> 13 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1.  8.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  8.  0. 16.] 
cards in discard: [ 0.  8.  0. 14.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 14  8  8  1  0 29 29  8 16  4  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 30. 29.  8.  7.  8. 10.  4. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [15. 16.  0.  6.  3.] 
adversary cards in discard: [10.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6] -> size -> 13 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0.] 
cards in discard: [ 0.  8.  0. 14.  0.  1.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0  0  0  3 14  8  8  1  0 29 29  8 16  4  0  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 30. 29.  8.  7.  8. 10.  3. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [15. 16.  0.  6.  3.] 
adversary cards in discard: [10.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6] -> size -> 13 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0.] 
cards in discard: [ 0.  8.  0. 14.  0.  1.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0  0  0  3 14  8  8  1  0 29 29  8 16  4  0  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 30. 29.  8.  7.  8. 10.  3. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [15. 16.  0.  6.  3.] 
adversary cards in discard: [10.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6] -> size -> 13 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0.] 
cards in discard: [ 0.  8.  0. 14.  0.  1.  8.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0  0  0  3 14  8  8  1  0 29 29  8 16  4  0  8  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 29.  8.  7.  8. 10.  2. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [15. 16.  0.  6.  3.] 
adversary cards in discard: [10.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6] -> size -> 13 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [15. 16.  0.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16.] 
expected returns: [[211.51071]
 [199.64107]
 [196.84161]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 16.  0.  6.  3.] 
cards in discard: [10.  8.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 29.  8.  7.  8. 10.  2. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  0.  4. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 14  8  8  1  0 29 29  8 16  4  0  8  8] -> size -> 17 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1.0
Learning step: -8.029861450195312
desired expected reward: 189.14476013183594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[191.3183 ]
 [184.95334]
 [210.26556]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 16.  0.  6.  3.] 
cards in discard: [10.  8.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 28. 30. 30. 29.  8.  7.  8. 10.  2. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  0.  4. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 14  8  8  1  0 29 29  8 16  4  0  8  8] -> size -> 17 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -8.730206489562988
desired expected reward: 201.3111572265625



buy possibilites: [-1] 
expected returns: [[235.85384]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 16.  0.  6.  3.] 
cards in discard: [10.  8.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 30. 29.  8.  7.  8. 10.  2. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  0.  4. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 14  8  8  1  0 29 29  8 16  4  0  8  8] -> size -> 17 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -50.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -86.0 

action type: buy - action 0.0
Learning step: -8.559206008911133
desired expected reward: 182.75912475585938






Player: 1 
cards in hand: [ 8.  0.  4. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  4. 29.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 14  8  8  1  0 29 29  8 16  4  0  8  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 29.  8.  7.  8. 10.  2. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  8.  6.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0] -> size -> 14 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 14  8  8  1  0 29  8 16  4  0  8  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 29.  8.  7.  8. 10.  2. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  8.  6.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0] -> size -> 14 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 14  8  8  1  0 29  8 16  4  0  8  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 28. 30. 30. 29.  8.  7.  8. 10.  2. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  8.  6.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0] -> size -> 14 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 3.  8.  6.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.] 
expected returns: [[197.14261]
 [187.28787]
 [187.28787]
 [186.59128]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  6.  8. 10.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 29.  8.  7.  8. 10.  2. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  8.  1.  0. 29.] 
adversary cards in discard: [8. 4.] 
adversary owned cards: [ 0  0 14  8  8  1  0 29  8 16  4  0  8  8] -> size -> 14 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1
Learning step: -9.76024055480957
desired expected reward: 226.09359741210938



action possibilites: [-1.  8.  8. 10.] 
expected returns: [[159.3891 ]
 [151.30609]
 [151.30609]
 [150.73105]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  6.  8. 10.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0] -> size -> 14 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 29.  8.  7.  8. 10.  2. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  8.  1.  0. 29.] 
adversary cards in discard: [8. 4.] 
adversary owned cards: [ 0  0 14  8  8  1  0 29  8 16  4  0  8  8] -> size -> 14 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action 10.0
Learning step: -7.062094211578369
desired expected reward: 178.5662384033203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[146.10097]
 [141.40028]
 [159.88629]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  6.  8. 10.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0] -> size -> 14 
action values: 2 
buys: 1 
player value: 0 
card supply: [27. 28. 30. 30. 29.  8.  7.  8. 10.  2. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  8.  1.  0. 29.] 
adversary cards in discard: [8. 4.] 
adversary owned cards: [ 0  0 14  8  8  1  0 29  8 16  4  0  8  8] -> size -> 14 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1.0
Learning step: -5.788029670715332
desired expected reward: 153.60107421875






Player: 1 
cards in hand: [ 8.  8.  1.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  1.  0. 29.] 
cards in discard: [8. 4.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14  8  8  1  0 29  8 16  4  0  8  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 29.  8.  7.  8. 10.  2. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 16.  0.] 
adversary cards in discard: [10.  3.  8.  6.  8. 10.] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0] -> size -> 14 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [8. 4.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 14  8  8  0  8 16  4  0  8  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 29.  8.  7.  8. 10.  2. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 16.  0.] 
adversary cards in discard: [10.  3.  8.  6.  8. 10.] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0] -> size -> 14 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [8. 4.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 14  8  8  0  8 16  4  0  8  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 30. 29.  8.  7.  8. 10.  2. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 16.  0.] 
adversary cards in discard: [10.  3.  8.  6.  8. 10.] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0] -> size -> 14 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[208.11217]
 [192.54637]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 16.  0.] 
cards in discard: [10.  3.  8.  6.  8. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 29.  8.  7.  8. 10.  2. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  8. 16. 14.  0.] 
adversary cards in discard: [8. 4. 8. 8. 0.] 
adversary owned cards: [ 0  0 14  8  8  0  8 16  4  0  8  8] -> size -> 12 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1.0
Learning step: -5.198905944824219
desired expected reward: 143.35748291015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[183.87921]
 [189.60548]
 [189.14629]
 [177.82869]
 [188.05562]
 [196.26787]
 [190.49838]
 [196.27042]
 [184.9056 ]
 [190.03403]
 [191.13937]
 [202.83034]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 16.  0.] 
cards in discard: [10.  3.  8.  6.  8. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 28. 30. 30. 29.  8.  7.  8. 10.  2. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  8. 16. 14.  0.] 
adversary cards in discard: [8. 4. 8. 8. 0.] 
adversary owned cards: [ 0  0 14  8  8  0  8 16  4  0  8  8] -> size -> 12 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1.0
Learning step: -8.126778602600098
desired expected reward: 196.9232177734375



buy possibilites: [-1] 
expected returns: [[195.51164]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 16.  0.] 
cards in discard: [10.  3.  8.  6.  8. 10.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 29. 29.  8.  7.  8. 10.  2. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  8. 16. 14.  0.] 
adversary cards in discard: [8. 4. 8. 8. 0.] 
adversary owned cards: [ 0  0 14  8  8  0  8 16  4  0  8  8] -> size -> 12 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -33.0 

action type: buy - action 3.0
Learning step: -6.708301067352295
desired expected reward: 182.43795776367188






Player: 1 
cards in hand: [ 0.  8. 16. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 14.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 16. 14.  0.] 
cards in discard: [8. 4. 8. 8. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14  8  8  0  8 16  4  0  8  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 29.  8.  7.  8. 10.  2. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3] -> size -> 15 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  0.] 
cards in discard: [8. 4. 8. 8. 0. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0 14  8  8  0  8 16  4  0  8  8  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 29.  8.  7.  8. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3] -> size -> 15 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 14.  0.] 
cards in discard: [8. 4. 8. 8. 0. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0 14  8  8  0  8 16  4  0  8  8  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 29. 29.  8.  7.  8. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3] -> size -> 15 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 14.  0.] 
cards in discard: [8. 4. 8. 8. 0. 8. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0 14  8  8  0  8 16  4  0  8  8  8  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 29. 29.  8.  7.  8. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  6. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3] -> size -> 15 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0.  6. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[167.62202]
 [155.87126]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  6. 15.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 29.  8.  7.  8. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8. 16.  8.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 14  8  8  0  8 16  4  0  8  8  8  0] -> size -> 13 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: -7.820839881896973
desired expected reward: 187.6907958984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[148.01105]
 [153.15872]
 [141.92892]
 [154.63098]
 [166.90016]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  6. 15.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 29. 29.  8.  7.  8. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8. 16.  8.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 14  8  8  0  8 16  4  0  8  8  8  0] -> size -> 13 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -6.516462802886963
desired expected reward: 160.90362548828125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8. 16.  8.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  8.  0.  8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  8  8  0  8 16  4  0  8  8  8  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 29.  8.  7.  8. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 16.  0.  8.] 
adversary cards in discard: [ 3.  0.  0.  6. 15.] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3] -> size -> 15 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  0  8 16  4  0  8  8  8  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 29.  8.  7.  8. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 16.  0.  8.] 
adversary cards in discard: [ 3.  0.  0.  6. 15.] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3] -> size -> 15 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  0  8 16  4  0  8  8  8  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 28. 30. 29. 29.  8.  7.  8. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 16.  0.  8.] 
adversary cards in discard: [ 3.  0.  0.  6. 15.] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3] -> size -> 15 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  8.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [14  8  0  8 16  4  0  8  8  8  0  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8.  7.  8. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 16.  0.  8.] 
adversary cards in discard: [ 3.  0.  0.  6. 15.] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3] -> size -> 15 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 16.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
expected returns: [[197.17845]
 [186.39171]
 [188.36171]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  0.  8.] 
cards in discard: [ 3.  0.  0.  6. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8.  7.  8. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  8.  0.  0. 14.] 
adversary cards in discard: [ 0.  8. 16.  8.] 
adversary owned cards: [14  8  0  8 16  4  0  8  8  8  0  0] -> size -> 12 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: -5.712943077087402
desired expected reward: 161.18722534179688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[184.53188]
 [188.94402]
 [188.26785]
 [179.5262 ]
 [193.71603]
 [189.66718]
 [188.98865]
 [198.76181]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.  0.  8.] 
cards in discard: [ 3.  0.  0.  6. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 29. 29.  8.  7.  8. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  8.  0.  0. 14.] 
adversary cards in discard: [ 0.  8. 16.  8.] 
adversary owned cards: [14  8  0  8 16  4  0  8  8  8  0  0] -> size -> 12 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -7.285190105438232
desired expected reward: 190.7666778564453



buy possibilites: [-1] 
expected returns: [[191.4691]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.  0.  8.] 
cards in discard: [ 3.  0.  0.  6. 15.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 28. 30. 29. 29.  8.  6.  8. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  8.  0.  0. 14.] 
adversary cards in discard: [ 0.  8. 16.  8.] 
adversary owned cards: [14  8  0  8 16  4  0  8  8  8  0  0] -> size -> 12 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -40.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -346.0 

action type: buy - action 6.0
Learning step: -21.9682559967041
desired expected reward: 157.5579376220703






Player: 1 
cards in hand: [ 0.  8.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0.  0. 14.] 
cards in discard: [ 0.  8. 16.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [14  8  0  8 16  4  0  8  8  8  0  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8.  6.  8. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [10.  3.  6. 10.  8.] 
adversary cards in discard: [ 3.  0.  0.  6. 15.  6.  0.  0. 16.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6] -> size -> 16 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0.  8. 16.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  8 16  4  0  8  8  8  0  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 29.  8.  6.  8. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [10.  3.  6. 10.  8.] 
adversary cards in discard: [ 3.  0.  0.  6. 15.  6.  0.  0. 16.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6] -> size -> 16 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0.  8. 16.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  8 16  4  0  8  8  8  0  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 29. 29.  8.  6.  8. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [10.  3.  6. 10.  8.] 
adversary cards in discard: [ 3.  0.  0.  6. 15.  6.  0.  0. 16.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6] -> size -> 16 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0.  8. 16.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  8 16  4  0  8  8  8  0  0  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 28. 30. 29. 29.  8.  6.  8. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [10.  3.  6. 10.  8.] 
adversary cards in discard: [ 3.  0.  0.  6. 15.  6.  0.  0. 16.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6] -> size -> 16 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [10.  3.  6. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.  8.] 
expected returns: [[227.87372]
 [215.99013]
 [215.99013]
 [216.5928 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  6. 10.  8.] 
cards in discard: [ 3.  0.  0.  6. 15.  6.  0.  0. 16.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 29.  8.  6.  8. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8. 16.  8.  8.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8 16  4  0  8  8  8  0  0  0] -> size -> 12 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1
Learning step: -6.884274959564209
desired expected reward: 184.58482360839844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[208.56592]
 [202.45583]
 [227.08702]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  6. 10.  8.] 
cards in discard: [ 3.  0.  0.  6. 15.  6.  0.  0. 16.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6] -> size -> 16 
action values: 1 
buys: 1 
player value: 0 
card supply: [24. 28. 30. 29. 29.  8.  6.  8. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8. 16.  8.  8.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8 16  4  0  8  8  8  0  0  0] -> size -> 12 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1.0
Learning step: -8.653403282165527
desired expected reward: 217.50115966796875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8. 16.  8.  8.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  8.  8.  4.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8 16  4  0  8  8  8  0  0  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 29.  8.  6.  8. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 10.  6.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6] -> size -> 16 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 4 0 8 8 8 0 0 0] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 29.  8.  6.  8. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 10.  6.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6] -> size -> 16 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 4 0 8 8 8 0 0 0] -> size -> 9 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 28. 30. 29. 29.  8.  6.  8. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 10.  6.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6] -> size -> 16 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 4 0 8 8 8 0 0 0 0] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 29. 29.  8.  6.  8. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 10.  6.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6] -> size -> 16 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 3. 10.  6.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 15.] 
expected returns: [[133.0689  ]
 [125.40807 ]
 [126.117714]
 [126.00222 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  6.  8. 15.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 29. 29.  8.  6.  8. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 8. 0. 0.] 
adversary cards in discard: [0. 8. 4.] 
adversary owned cards: [0 4 0 8 8 8 0 0 0 0] -> size -> 10 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1.0
Learning step: -10.674361228942871
desired expected reward: 216.41265869140625



action possibilites: [-1] 
expected returns: [[127.676]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  6.  8.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 29. 29.  8.  6.  8. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 8. 0. 0.] 
adversary cards in discard: [0. 8. 4.] 
adversary owned cards: [0 4 0 8 8 8 0 0 0 0] -> size -> 10 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action 15.0
Learning step: -4.817774295806885
desired expected reward: 122.99191284179688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[115.31492 ]
 [111.163765]
 [125.67691 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  6.  8.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 28. 30. 29. 29.  8.  6.  8. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 8. 0. 0.] 
adversary cards in discard: [0. 8. 4.] 
adversary owned cards: [0 4 0 8 8 8 0 0 0 0] -> size -> 10 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1
Learning step: -4.945496082305908
desired expected reward: 122.73050689697266






Player: 1 
cards in hand: [8. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 0. 0.] 
cards in discard: [0. 8. 4.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 4 0 8 8 8 0 0 0 0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 29. 29.  8.  6.  8. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [16.  0. 10.  0.  8.] 
adversary cards in discard: [15.  3. 10.  6.  8.] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6] -> size -> 16 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8. 0. 0.] 
cards in discard: [0. 8. 4.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 4 0 8 8 8 0 0 0 0] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 28. 30. 29. 29.  8.  6.  8. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [16.  0. 10.  0.  8.] 
adversary cards in discard: [15.  3. 10.  6.  8.] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6] -> size -> 16 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8. 0. 0.] 
cards in discard: [0. 8. 4. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 4 0 8 8 8 0 0 0 0 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 28. 30. 29. 29.  8.  6.  8. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [16.  0. 10.  0.  8.] 
adversary cards in discard: [15.  3. 10.  6.  8.] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6] -> size -> 16 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [16.  0. 10.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.  8.] 
expected returns: [[139.53053]
 [128.623  ]
 [129.83391]
 [130.5067 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 10.  0.  8.] 
cards in discard: [15.  3. 10.  6.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 29. 29.  8.  6.  8. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 4. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 4 0 8 8 8 0 0 0 0 0] -> size -> 11 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1.0
Learning step: -5.535417079925537
desired expected reward: 120.14148712158203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[122.346886]
 [125.716194]
 [118.19439 ]
 [127.07809 ]
 [135.90489 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0. 10.  0.  8.] 
cards in discard: [15.  3. 10.  6.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 29. 29.  8.  6.  8. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 4. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 4 0 8 8 8 0 0 0 0 0] -> size -> 11 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1.0
Learning step: -6.304041385650635
desired expected reward: 132.7647247314453



buy possibilites: [-1] 
expected returns: [[139.91763]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0. 10.  0.  8.] 
cards in discard: [15.  3. 10.  6.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 28. 30. 29. 29.  8.  6.  8. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 4. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 4 0 8 8 8 0 0 0 0 0] -> size -> 11 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -40.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -76.0 

action type: buy - action 0.0
Learning step: -6.561418056488037
desired expected reward: 115.78545379638672






Player: 1 
cards in hand: [0. 4. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 4. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 4 0 8 8 8 0 0 0 0 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 29. 29.  8.  6.  8. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 6. 0. 6.] 
adversary cards in discard: [15.  3. 10.  6.  8.  0. 16.  0. 10.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0] -> size -> 17 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 4. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 4 0 8 8 8 0 0 0 0 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 28. 30. 29. 29.  8.  6.  8. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 6. 0. 6.] 
adversary cards in discard: [15.  3. 10.  6.  8.  0. 16.  0. 10.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0] -> size -> 17 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 4. 0. 0. 0.] 
cards in discard: [16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  4  0  8  8  8  0  0  0  0  0 16] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 29. 29.  8.  6.  7. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 6. 0. 6.] 
adversary cards in discard: [15.  3. 10.  6.  8.  0. 16.  0. 10.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0] -> size -> 17 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [0. 3. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[162.24458]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 0. 6.] 
cards in discard: [15.  3. 10.  6.  8.  0. 16.  0. 10.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 29. 29.  8.  6.  7. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 8. 8. 0. 0.] 
adversary cards in discard: [16.  0.  4.  0.  0.  0.] 
adversary owned cards: [ 0  4  0  8  8  8  0  0  0  0  0 16] -> size -> 12 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1
Learning step: -5.662606716156006
desired expected reward: 134.25502014160156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[144.09499]
 [148.20609]
 [139.14862]
 [149.67838]
 [159.23685]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 6.] 
cards in discard: [15.  3. 10.  6.  8.  0. 16.  0. 10.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 28. 30. 29. 29.  8.  6.  7. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 8. 8. 0. 0.] 
adversary cards in discard: [16.  0.  4.  0.  0.  0.] 
adversary owned cards: [ 0  4  0  8  8  8  0  0  0  0  0 16] -> size -> 12 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1.0
Learning step: -6.911518096923828
desired expected reward: 154.5673828125



buy possibilites: [-1] 
expected returns: [[158.76125]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 6.] 
cards in discard: [15.  3. 10.  6.  8.  0. 16.  0. 10.  0.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 28. 30. 29. 29.  8.  6.  7. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 8. 8. 0. 0.] 
adversary cards in discard: [16.  0.  4.  0.  0.  0.] 
adversary owned cards: [ 0  4  0  8  8  8  0  0  0  0  0 16] -> size -> 12 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -40.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -76.0 

action type: buy - action 0.0
Learning step: -7.432620525360107
desired expected reward: 136.662353515625






Player: 1 
cards in hand: [8. 8. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 8. 0. 0.] 
cards in discard: [16.  0.  4.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  4  0  8  8  8  0  0  0  0  0 16] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 29. 29.  8.  6.  7. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  0. 10.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0] -> size -> 18 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [16.  0.  4.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 4  0  8  0  0  0  0  0 16] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 29. 29.  8.  6.  7. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  0. 10.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0] -> size -> 18 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [16.  0.  4.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 4  0  8  0  0  0  0  0 16] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 30. 29. 29.  8.  6.  7. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  0. 10.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0] -> size -> 18 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 6.  0. 10.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[142.17491]
 [136.33585]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10.  6.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 29. 29.  8.  6.  7. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 4  0  8  0  0  0  0  0 16] -> size -> 9 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1
Learning step: -7.053791046142578
desired expected reward: 151.70745849609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[137.24277]
 [139.04597]
 [134.25224]
 [140.30702]
 [144.74109]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 10.  6.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 28. 30. 29. 29.  8.  6.  7. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 4  0  8  0  0  0  0  0 16] -> size -> 9 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1.0
Learning step: -6.252593994140625
desired expected reward: 136.71983337402344



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 4  0  8  0  0  0  0  0 16] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 29. 29.  8.  6.  7. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  8. 15.  8.  0.] 
adversary cards in discard: [ 6.  0. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0] -> size -> 18 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 4  0  8  0  0  0  0  0 16] -> size -> 9 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 28. 30. 29. 29.  8.  6.  7. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  8. 15.  8.  0.] 
adversary cards in discard: [ 6.  0. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0] -> size -> 18 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 4  0  8  0  0  0  0  0 16  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 5 
card supply: [19. 28. 30. 29. 29.  8.  6.  7. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  8. 15.  8.  0.] 
adversary cards in discard: [ 6.  0. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0] -> size -> 18 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 6.  8. 15.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.  8.] 
expected returns: [[170.59908]
 [157.95683]
 [158.1449 ]
 [157.95683]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8. 15.  8.  0.] 
cards in discard: [ 6.  0. 10.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 29. 29.  8.  6.  7. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 16.  8.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 4  0  8  0  0  0  0  0 16  0] -> size -> 10 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1.0
Learning step: -5.8121795654296875
desired expected reward: 138.92889404296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[154.26317]
 [148.83727]
 [172.88213]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8. 15.  8.  0.] 
cards in discard: [ 6.  0. 10.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 28. 30. 29. 29.  8.  6.  7. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 16.  8.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 4  0  8  0  0  0  0  0 16  0] -> size -> 10 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1.0
Learning step: -7.0747528076171875
desired expected reward: 163.14971923828125



buy possibilites: [-1] 
expected returns: [[151.18208]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8. 15.  8.  0.] 
cards in discard: [ 6.  0. 10.  6.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 29. 29.  8.  5.  7. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 16.  8.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 4  0  8  0  0  0  0  0 16  0] -> size -> 10 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2.  -50.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -357.0 

action type: buy - action 6.0
Learning step: -21.890268325805664
desired expected reward: 126.94701385498047






Player: 1 
cards in hand: [ 0.  0. 16.  8.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  8.  4.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 4  0  8  0  0  0  0  0 16  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 29. 29.  8.  5.  7. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 10.  0.] 
adversary cards in discard: [ 6.  0. 10.  6.  0.  6.  6.  8. 15.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6] -> size -> 19 
adversary victory points: -2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  0  0  0  0  0 16  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 29. 29.  8.  5.  7. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 10.  0.] 
adversary cards in discard: [ 6.  0. 10.  6.  0.  6.  6.  8. 15.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6] -> size -> 19 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  0  0  0  0  0 16  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 28. 30. 29. 29.  8.  5.  7. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 10.  0.] 
adversary cards in discard: [ 6.  0. 10.  6.  0.  6.  6.  8. 15.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6] -> size -> 19 
adversary victory points: -2
player victory points: 0 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[189.26256]
 [178.17397]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10.  0.] 
cards in discard: [ 6.  0. 10.  6.  0.  6.  6.  8. 15.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 29. 29.  8.  5.  7. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  0. 16.] 
adversary owned cards: [ 0  8  0  0  0  0  0 16  0] -> size -> 9 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: buy - action -1
Learning step: -4.746557235717773
desired expected reward: 146.43553161621094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[173.969  ]
 [178.90817]
 [178.34879]
 [168.6933 ]
 [184.42047]
 [179.70692]
 [179.14337]
 [189.86931]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.  0.] 
cards in discard: [ 6.  0. 10.  6.  0.  6.  6.  8. 15.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 28. 30. 29. 29.  8.  5.  7. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  0. 16.] 
adversary owned cards: [ 0  8  0  0  0  0  0 16  0] -> size -> 9 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: take_action - action -1.0
Learning step: -6.576531410217285
desired expected reward: 181.07933044433594



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 8.  0.  0. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0  0  0  0  0 16  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 29. 29.  8.  5.  7. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  0.  0.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6] -> size -> 19 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 8.  0.  0. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0  0  0  0  0 16  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 5 
card supply: [19. 28. 30. 29. 29.  8.  5.  7. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  0.  0.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6] -> size -> 19 
adversary victory points: -2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 8.  0.  0. 16. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0  0  0  0  0 16  0 16] -> size -> 10 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 29. 29.  8.  5.  6. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  0.  0.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6] -> size -> 19 
adversary victory points: -2
player victory points: 0 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 8.  0.  0.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
expected returns: [[131.44267 ]
 [126.44801 ]
 [124.999565]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0.  3. 16.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 29. 29.  8.  5.  6. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  0  0  0  0  0 16  0 16] -> size -> 10 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: buy - action -1.0
Learning step: -7.920239448547363
desired expected reward: 181.94908142089844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[126.746  ]
 [128.95335]
 [123.4086 ]
 [130.23058]
 [134.95567]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0.  3. 16.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 28. 30. 29. 29.  8.  5.  6. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  0  0  0  0  0 16  0 16] -> size -> 10 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: take_action - action -1.0
Learning step: -4.967041015625
desired expected reward: 126.78874206542969



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 16.  0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0  0  0  0  0 16  0 16] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 29. 29.  8.  5.  6. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  6. 15.  6.  3.] 
adversary cards in discard: [ 8.  0.  0.  3. 16.] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6] -> size -> 19 
adversary victory points: -2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8  0  0  0  0  0 16  0 16  6] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 29. 29.  8.  4.  6. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  6. 15.  6.  3.] 
adversary cards in discard: [ 8.  0.  0.  3. 16.] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6] -> size -> 19 
adversary victory points: -2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8  0  0  0  0  0 16  0 16  6] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 28. 30. 29. 29.  8.  4.  6. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  6. 15.  6.  3.] 
adversary cards in discard: [ 8.  0.  0.  3. 16.] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6] -> size -> 19 
adversary victory points: -2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [6. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8  0  0  0  0  0 16  0 16  6  3] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 28. 29.  8.  4.  6. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  6. 15.  6.  3.] 
adversary cards in discard: [ 8.  0.  0.  3. 16.] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6] -> size -> 19 
adversary victory points: -2
player victory points: 0 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 0.  6. 15.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[151.35652]
 [142.30537]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 15.  6.  3.] 
cards in discard: [ 8.  0.  0.  3. 16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 28. 29.  8.  4.  6. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [16.  0.  8.  0.  0.] 
adversary cards in discard: [ 6.  3. 16.  0.  0.  0.] 
adversary owned cards: [ 8  0  0  0  0  0 16  0 16  6  3] -> size -> 11 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: buy - action -1.0
Learning step: -4.796567440032959
desired expected reward: 130.15911865234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[137.94023]
 [132.41502]
 [152.56276]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 15.  6.  3.] 
cards in discard: [ 8.  0.  0.  3. 16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 28. 30. 28. 29.  8.  4.  6. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [16.  0.  8.  0.  0.] 
adversary cards in discard: [ 6.  3. 16.  0.  0.  0.] 
adversary owned cards: [ 8  0  0  0  0  0 16  0 16  6  3] -> size -> 11 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -27 

action type: take_action - action -1.0
Learning step: -5.486840724945068
desired expected reward: 143.40321350097656



buy possibilites: [-1] 
expected returns: [[169.40816]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 15.  6.  3.] 
cards in discard: [ 8.  0.  0.  3. 16.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 28. 29.  8.  3.  6. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [16.  0.  8.  0.  0.] 
adversary cards in discard: [ 6.  3. 16.  0.  0.  0.] 
adversary owned cards: [ 8  0  0  0  0  0 16  0 16  6  3] -> size -> 11 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3.  -30.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -338.0 

action type: buy - action 6.0
Learning step: -19.70906639099121
desired expected reward: 112.7059555053711






Player: 1 
cards in hand: [16.  0.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  8.  0.  0.] 
cards in discard: [ 6.  3. 16.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  0  0 16  0 16  6  3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 28. 29.  8.  3.  6. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  0.  0.  6. 10.] 
adversary cards in discard: [ 8.  0.  0.  3. 16.  6.  0.  6. 15.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6] -> size -> 20 
adversary victory points: -3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  8.  0.  0.] 
cards in discard: [ 6.  3. 16.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  0  0 16  0 16  6  3] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 28. 30. 28. 29.  8.  3.  6. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  0.  0.  6. 10.] 
adversary cards in discard: [ 8.  0.  0.  3. 16.  6.  0.  6. 15.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6] -> size -> 20 
adversary victory points: -3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  8.  0.  0.] 
cards in discard: [ 6.  3. 16.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  0  0 16  0 16  6  3  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 27. 29.  8.  3.  6. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  0.  0.  6. 10.] 
adversary cards in discard: [ 8.  0.  0.  3. 16.  6.  0.  6. 15.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6] -> size -> 20 
adversary victory points: -3
player victory points: 1 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [ 8.  0.  0.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[112.225746]
 [100.236176]
 [ 99.76236 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0.  6. 10.] 
cards in discard: [ 8.  0.  0.  3. 16.  6.  0.  6. 15.  6.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 27. 29.  8.  3.  6. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  0  0 16  0 16  6  3  3] -> size -> 12 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: buy - action -1
Learning step: -8.480388641357422
desired expected reward: 160.92776489257812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 84.07073 ]
 [ 88.18647 ]
 [ 79.22048 ]
 [ 89.36945 ]
 [100.032684]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0.  6. 10.] 
cards in discard: [ 8.  0.  0.  3. 16.  6.  0.  6. 15.  6.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 28. 30. 27. 29.  8.  3.  6. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  0  0 16  0 16  6  3  3] -> size -> 12 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: take_action - action -1.0
Learning step: -5.184556484222412
desired expected reward: 92.96378326416016



buy possibilites: [-1] 
expected returns: [[82.793785]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0.  6. 10.] 
cards in discard: [ 8.  0.  0.  3. 16.  6.  0.  6. 15.  6.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 26. 29.  8.  3.  6. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0  0  0 16  0 16  6  3  3] -> size -> 12 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -29 

action type: buy - action 3.0
Learning step: -3.9964637756347656
desired expected reward: 84.19000244140625






Player: 1 
cards in hand: [ 0.  3.  0. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 16.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  0  0 16  0 16  6  3  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 26. 29.  8.  3.  6. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  6.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6  3] -> size -> 21 
adversary victory points: -2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8  0  0  0  0 16  0 16  6  3  3  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 26. 29.  8.  3.  6. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  6.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6  3] -> size -> 21 
adversary victory points: -2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8  0  0  0  0 16  0 16  6  3  3  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 28. 30. 26. 29.  8.  3.  6. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  6.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6  3] -> size -> 21 
adversary victory points: -2
player victory points: 1 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 0.  6.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[109.94395]
 [103.00181]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 26. 29.  8.  3.  6. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  0.  8.  0. 16.] 
adversary cards in discard: [ 0. 16.  3.  0.  3.] 
adversary owned cards: [ 8  0  0  0  0 16  0 16  6  3  3  0] -> size -> 12 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: buy - action -1
Learning step: -3.5600202083587646
desired expected reward: 79.2337646484375



action possibilites: [-1.] 
expected returns: [[90.16894]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6  3] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 26. 29.  8.  3.  6. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  0.  8.  0. 16.] 
adversary cards in discard: [ 0. 16.  3.  0.  3.] 
adversary owned cards: [ 8  0  0  0  0 16  0 16  6  3  3  0] -> size -> 12 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: take_action - action 10.0
Learning step: -3.963639497756958
desired expected reward: 98.88516998291016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[78.91466 ]
 [81.90946 ]
 [81.42811 ]
 [75.805145]
 [85.35782 ]
 [82.44418 ]
 [81.960335]
 [88.62482 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 28. 30. 26. 29.  8.  3.  6. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  0.  8.  0. 16.] 
adversary cards in discard: [ 0. 16.  3.  0.  3.] 
adversary owned cards: [ 8  0  0  0  0 16  0 16  6  3  3  0] -> size -> 12 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: take_action - action -1.0
Learning step: -3.4352378845214844
desired expected reward: 86.73370361328125






Player: 1 
cards in hand: [ 6.  0.  8.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  8.  0. 16.] 
cards in discard: [ 0. 16.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0  0 16  0 16  6  3  3  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 26. 29.  8.  3.  6. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6. 16.  0.  8.  3.] 
adversary cards in discard: [10.  0.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6  3] -> size -> 21 
adversary victory points: -2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 16.] 
cards in discard: [ 0. 16.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  0 16  0 16  6  3  3  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 26. 29.  8.  3.  6. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6. 16.  0.  8.  3.] 
adversary cards in discard: [10.  0.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6  3] -> size -> 21 
adversary victory points: -2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 16.] 
cards in discard: [ 0. 16.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  0 16  0 16  6  3  3  0] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 28. 30. 26. 29.  8.  3.  6. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6. 16.  0.  8.  3.] 
adversary cards in discard: [10.  0.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6  3] -> size -> 21 
adversary victory points: -2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 16.] 
cards in discard: [ 0. 16.  3.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  0 16  0 16  6  3  3  0  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 26. 29.  8.  3.  6. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6. 16.  0.  8.  3.] 
adversary cards in discard: [10.  0.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6  3] -> size -> 21 
adversary victory points: -2
player victory points: 1 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 6. 16.  0.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
expected returns: [[188.27196]
 [175.04167]
 [177.37306]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 16.  0.  8.  3.] 
cards in discard: [10.  0.  6.  0.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 26. 29.  8.  3.  6. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 6. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0 16  0 16  6  3  3  0  0] -> size -> 11 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: buy - action -1.0
Learning step: -2.199965238571167
desired expected reward: 86.42485046386719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[171.02396]
 [164.97862]
 [189.05057]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 16.  0.  8.  3.] 
cards in discard: [10.  0.  6.  0.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 28. 30. 26. 29.  8.  3.  6. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 6. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0 16  0 16  6  3  3  0  0] -> size -> 11 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action -1.0
Learning step: -7.0131354331970215
desired expected reward: 178.29542541503906



buy possibilites: [-1] 
expected returns: [[153.24425]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 16.  0.  8.  3.] 
cards in discard: [10.  0.  6.  0.  0.  6.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6  3  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 28. 30. 26. 29.  8.  2.  6. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 6. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0 16  0 16  6  3  3  0  0] -> size -> 11 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3.  -40.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -348.0 

action type: buy - action 6.0
Learning step: -22.200937271118164
desired expected reward: 142.77769470214844






Player: 1 
cards in hand: [3. 6. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0 16  0 16  6  3  3  0  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 26. 29.  8.  2.  6. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.  3. 15.] 
adversary cards in discard: [10.  0.  6.  0.  0.  6.  6.  6. 16.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6  3  6] -> size -> 22 
adversary victory points: -3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0 16  0 16  6  3  3  0  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 28. 30. 26. 29.  8.  2.  6. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.  3. 15.] 
adversary cards in discard: [10.  0.  6.  0.  0.  6.  6.  6. 16.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6  3  6] -> size -> 22 
adversary victory points: -3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0 16  0 16  6  3  3  0  0  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 28. 30. 26. 29.  8.  2.  6. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.  3. 15.] 
adversary cards in discard: [10.  0.  6.  0.  0.  6.  6.  6. 16.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6  3  6] -> size -> 22 
adversary victory points: -3
player victory points: 1 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  3.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
expected returns: [[125.14661 ]
 [109.518456]
 [110.79674 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  3. 15.] 
cards in discard: [10.  0.  6.  0.  0.  6.  6.  6. 16.  0.  8.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6  3  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 26. 29.  8.  2.  6. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 16. 16.] 
adversary cards in discard: [0. 3. 6. 0. 0. 0.] 
adversary owned cards: [ 8  0  0 16  0 16  6  3  3  0  0  0] -> size -> 12 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: buy - action -1
Learning step: -7.41656494140625
desired expected reward: 145.8276824951172



action possibilites: [-1] 
expected returns: [[98.10887]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3.] 
cards in discard: [10.  0.  6.  0.  0.  6.  6.  6. 16.  0.  8.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6  3  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 28. 30. 26. 29.  8.  2.  6. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 16. 16.] 
adversary cards in discard: [0. 3. 6. 0. 0. 0.] 
adversary owned cards: [ 8  0  0 16  0 16  6  3  3  0  0  0] -> size -> 12 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -28 

action type: take_action - action 15.0
Learning step: -4.606647491455078
desired expected reward: 103.67529296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[80.86198 ]
 [86.19192 ]
 [85.647644]
 [75.182465]
 [92.41298 ]
 [87.06021 ]
 [86.509445]
 [98.50975 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3.] 
cards in discard: [10.  0.  6.  0.  0.  6.  6.  6. 16.  0.  8.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6  3  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 28. 30. 26. 29.  8.  2.  6. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 16. 16.] 
adversary cards in discard: [0. 3. 6. 0. 0. 0.] 
adversary owned cards: [ 8  0  0 16  0 16  6  3  3  0  0  0] -> size -> 12 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -28 

action type: take_action - action -1
Learning step: -4.217992305755615
desired expected reward: 93.89087677001953






Player: 1 
cards in hand: [ 3.  0.  0. 16. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 16. 16.] 
cards in discard: [0. 3. 6. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0 16  0 16  6  3  3  0  0  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 26. 29.  8.  2.  6. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 6. 6. 0.] 
adversary cards in discard: [10.  0.  6.  0.  0.  6.  6.  6. 16.  0.  8.  3. 15. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6  3  6] -> size -> 21 
adversary victory points: -3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [ 0.  3.  6.  0.  0.  0. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8  0  0  0 16  6  3  3  0  0  0 16] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 26. 29.  8.  2.  5. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 6. 6. 0.] 
adversary cards in discard: [10.  0.  6.  0.  0.  6.  6.  6. 16.  0.  8.  3. 15. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6  3  6] -> size -> 21 
adversary victory points: -3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 0.  3.  6.  0.  0.  0. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8  0  0  0 16  6  3  3  0  0  0 16] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 28. 30. 26. 29.  8.  2.  5. 10.  1. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 6. 6. 0.] 
adversary cards in discard: [10.  0.  6.  0.  0.  6.  6.  6. 16.  0.  8.  3. 15. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6  3  6] -> size -> 21 
adversary victory points: -3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 0.  3.  6.  0.  0.  0. 16.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8  0  0  0 16  6  3  3  0  0  0 16  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 26. 29.  8.  2.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [8. 0. 6. 6. 0.] 
adversary cards in discard: [10.  0.  6.  0.  0.  6.  6.  6. 16.  0.  8.  3. 15. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6  3  6] -> size -> 21 
adversary victory points: -3
player victory points: 1 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [8. 0. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[189.46854]
 [178.85535]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 6. 0.] 
cards in discard: [10.  0.  6.  0.  0.  6.  6.  6. 16.  0.  8.  3. 15. 10.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6  3  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 26. 29.  8.  2.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  3. 16.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0 16  6  3  3  0  0  0 16  8] -> size -> 13 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: buy - action -1.0
Learning step: -3.154409408569336
desired expected reward: 95.3553695678711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[178.51505]
 [182.79416]
 [173.55713]
 [194.09332]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6. 6. 0.] 
cards in discard: [10.  0.  6.  0.  0.  6.  6.  6. 16.  0.  8.  3. 15. 10.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6  3  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 28. 30. 26. 29.  8.  2.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  3. 16.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  0 16  6  3  3  0  0  0 16  8] -> size -> 13 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: take_action - action -1.0
Learning step: -7.546139717102051
desired expected reward: 180.161865234375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 6.  3. 16.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 16.  0.  8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  0 16  6  3  3  0  0  0 16  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 26. 29.  8.  2.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 15. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6  3  6] -> size -> 21 
adversary victory points: -3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 8.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8  0  0 16  6  3  3  0  0  0 16  8  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 26. 29.  8.  2.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 15. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6  3  6] -> size -> 21 
adversary victory points: -3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 8.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8  0  0 16  6  3  3  0  0  0 16  8  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 28. 30. 26. 29.  8.  2.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 15. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6  3  6] -> size -> 21 
adversary victory points: -3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 8.] 
cards in discard: [0. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8  0  0 16  6  3  3  0  0  0 16  8  0  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 26. 29.  8.  2.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 15. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6  3  6] -> size -> 21 
adversary victory points: -3
player victory points: 1 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 15. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
expected returns: [[114.167725]
 [104.81547 ]
 [104.01264 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15. 10.  6.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6  3  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 26. 29.  8.  2.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [ 0.  0. 16.  6.  3.  8.] 
adversary owned cards: [ 8  0  0 16  6  3  3  0  0  0 16  8  0  0] -> size -> 14 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: buy - action -1.0
Learning step: -9.650717735290527
desired expected reward: 184.44261169433594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[ 96.74587]
 [100.3101 ]
 [ 92.37136]
 [110.96473]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15. 10.  6.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6  3  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 28. 30. 26. 29.  8.  2.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [ 0.  0. 16.  6.  3.  8.] 
adversary owned cards: [ 8  0  0 16  6  3  3  0  0  0 16  8  0  0] -> size -> 14 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: take_action - action -1.0
Learning step: -5.629941463470459
desired expected reward: 106.5590591430664



buy possibilites: [-1] 
expected returns: [[99.353035]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15. 10.  6.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6  3  6  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 28. 30. 26. 29.  8.  1.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [ 0.  0. 16.  6.  3.  8.] 
adversary owned cards: [ 8  0  0 16  6  3  3  0  0  0 16  8  0  0] -> size -> 14 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[  -5.    0.   -4.  -50.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -359.0 

action type: buy - action 6.0
Learning step: -20.115591049194336
desired expected reward: 72.25576782226562






Player: 1 
cards in hand: [0. 8. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 3. 0.] 
cards in discard: [ 0.  0. 16.  6.  3.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0 16  6  3  3  0  0  0 16  8  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 26. 29.  8.  1.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [6. 0. 6. 0. 6.] 
adversary cards in discard: [ 6.  0.  0. 15. 10.  6.] 
adversary owned cards: [ 0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6  3  6  6] -> size -> 22 
adversary victory points: -4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [ 0.  0. 16.  6.  3.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0 16  6  3  3  0  0  0 16  8  0  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 26. 29.  8.  1.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [6. 0. 6. 0. 6.] 
adversary cards in discard: [ 6.  0.  0. 15. 10.  6.] 
adversary owned cards: [ 0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6  3  6  6] -> size -> 22 
adversary victory points: -4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 0.  0. 16.  6.  3.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0 16  6  3  3  0  0  0 16  8  0  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 28. 30. 26. 29.  8.  1.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [6. 0. 6. 0. 6.] 
adversary cards in discard: [ 6.  0.  0. 15. 10.  6.] 
adversary owned cards: [ 0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6  3  6  6] -> size -> 22 
adversary victory points: -4
player victory points: 1 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [6. 0. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[104.30668]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 0. 6.] 
cards in discard: [ 6.  0.  0. 15. 10.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6  3  6  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 26. 29.  8.  1.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0 16  6  3  3  0  0  0 16  8  0  0] -> size -> 13 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: buy - action -1
Learning step: -5.580670356750488
desired expected reward: 93.7723617553711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[ 91.67573]
 [ 94.39136]
 [ 88.22135]
 [101.84794]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0. 6.] 
cards in discard: [ 6.  0.  0. 15. 10.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6  3  6  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 28. 30. 26. 29.  8.  1.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0 16  6  3  3  0  0  0 16  8  0  0] -> size -> 13 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: take_action - action -1.0
Learning step: -5.9359869956970215
desired expected reward: 97.92987823486328



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 16.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 16  6  3  3  0  0  0 16  8  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 26. 29.  8.  1.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  3. 10.  8.  8.] 
adversary cards in discard: [ 6.  0.  0. 15. 10.  6.  6.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6  3  6  6] -> size -> 22 
adversary victory points: -4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8 16  6  3  3  0  0  0 16  8  0  0  6] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 26. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  3. 10.  8.  8.] 
adversary cards in discard: [ 6.  0.  0. 15. 10.  6.  6.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6  3  6  6] -> size -> 22 
adversary victory points: -4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8 16  6  3  3  0  0  0 16  8  0  0  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 28. 30. 26. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  3. 10.  8.  8.] 
adversary cards in discard: [ 6.  0.  0. 15. 10.  6.  6.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6  3  6  6] -> size -> 22 
adversary victory points: -4
player victory points: 0 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [ 3.  3. 10.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8.] 
expected returns: [[109.064766]
 [100.137115]
 [100.64303 ]
 [100.64303 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.  8.  8.] 
cards in discard: [ 6.  0.  0. 15. 10.  6.  6.  0.  6.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 15 16 10  8 10  6  8  6  0  3  6  0  0  6  6  3  6  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 26. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8. 16.  0.  0.  0.] 
adversary cards in discard: [ 6. 16.  3.  0.  0.] 
adversary owned cards: [ 8 16  6  3  3  0  0  0 16  8  0  0  6] -> size -> 13 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -49 

action type: buy - action -1.0
Learning step: -5.207125186920166
desired expected reward: 96.64083099365234



action possibilites: [-1] 
expected returns: [[129.22641]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [ 6.  0.  0. 15. 10.  6.  6.  0.  6.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 15 16  8 10  6  8  6  0  6  0  0  6  6  3  6  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 26. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8. 16.  0.  0.  0.] 
adversary cards in discard: [ 6. 16.  3.  0.  0.] 
adversary owned cards: [ 8 16  6  3  3  0  0  0 16  8  0  0  6] -> size -> 13 
adversary victory points: 0
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -51 

action type: trash_cards_n_from_hand - action 9
Learning step: -5.413854122161865
desired expected reward: 110.01510620117188





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[121.612175]
 [130.57315 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [ 6.  0.  0. 15. 10.  6.  6.  0.  6.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 15 16  8 10  6  8  6  0  6  0  0  6  6  3  6  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 28. 30. 26. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8. 16.  0.  0.  0.] 
adversary cards in discard: [ 6. 16.  3.  0.  0.] 
adversary owned cards: [ 8 16  6  3  3  0  0  0 16  8  0  0  6] -> size -> 13 
adversary victory points: 0
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -51 

action type: take_action - action -1
Learning step: -6.121747016906738
desired expected reward: 123.10466003417969






Player: 1 
cards in hand: [ 8. 16.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  0.  0.  0.] 
cards in discard: [ 6. 16.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 16  6  3  3  0  0  0 16  8  0  0  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 26. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 6. 0. 6. 3.] 
adversary cards in discard: [ 6.  0.  0. 15. 10.  6.  6.  0.  6.  0.  6.  8.  8.] 
adversary owned cards: [ 0  0  0 15 16  8 10  6  8  6  0  6  0  0  6  6  3  6  6] -> size -> 19 
adversary victory points: -6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.] 
cards in discard: [ 6. 16.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 16  6  3  3  0  0 16  8  0  0  6] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 26. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 6. 0. 6. 3.] 
adversary cards in discard: [ 6.  0.  0. 15. 10.  6.  6.  0.  6.  0.  6.  8.  8.] 
adversary owned cards: [ 0  0  0 15 16  8 10  6  8  6  0  6  0  0  6  6  3  6  6] -> size -> 19 
adversary victory points: -6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.] 
cards in discard: [ 6. 16.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 16  6  3  3  0  0 16  8  0  0  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 28. 30. 26. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 6. 0. 6. 3.] 
adversary cards in discard: [ 6.  0.  0. 15. 10.  6.  6.  0.  6.  0.  6.  8.  8.] 
adversary owned cards: [ 0  0  0 15 16  8 10  6  8  6  0  6  0  0  6  6  3  6  6] -> size -> 19 
adversary victory points: -6
player victory points: 0 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [0. 6. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[106.54696]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 6. 3.] 
cards in discard: [ 6.  0.  0. 15. 10.  6.  6.  0.  6.  0.  6.  8.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15 16  8 10  6  8  6  0  6  0  0  6  6  3  6  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 26. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8. 6. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 16  6  3  3  0  0 16  8  0  0  6] -> size -> 12 
adversary victory points: 0
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -71 

action type: buy - action -1.0
Learning step: -7.732459545135498
desired expected reward: 122.8407211303711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[ 92.74822 ]
 [ 96.22059 ]
 [105.754555]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6. 3.] 
cards in discard: [ 6.  0.  0. 15. 10.  6.  6.  0.  6.  0.  6.  8.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15 16  8 10  6  8  6  0  6  0  0  6  6  3  6  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 28. 30. 26. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8. 6. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 16  6  3  3  0  0 16  8  0  0  6] -> size -> 12 
adversary victory points: 0
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -71 

action type: take_action - action -1.0
Learning step: -6.465333461761475
desired expected reward: 97.81023406982422



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 8. 6. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 8. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 16  6  3  3  0  0 16  8  0  0  6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 26. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  8.  0.  6. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 15 16  8 10  6  8  6  0  6  0  0  6  6  3  6  6] -> size -> 19 
adversary victory points: -6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  6  3  3  0 16  8  0  0  6] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 26. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  8.  0.  6. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 15 16  8 10  6  8  6  0  6  0  0  6  6  3  6  6] -> size -> 19 
adversary victory points: -6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  6  3  3  0 16  8  0  0  6] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 28. 30. 26. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  8.  0.  6. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 15 16  8 10  6  8  6  0  6  0  0  6  6  3  6  6] -> size -> 19 
adversary victory points: -6
player victory points: 0 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [ 8.  8.  0.  6. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 16.] 
expected returns: [[46.13041]
 [39.90694]
 [39.90694]
 [38.63283]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  0.  6. 16.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15 16  8 10  6  8  6  0  6  0  0  6  6  3  6  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 26. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [16.  0.  6.  3. 16.] 
adversary cards in discard: [8. 6. 3.] 
adversary owned cards: [16  6  3  3  0 16  8  0  0  6] -> size -> 10 
adversary victory points: 0
player victory points: -6 

Reward from previous game state: 
[ -5   0  -6 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -71 

action type: buy - action -1.0
Learning step: -7.857414245605469
desired expected reward: 97.89714813232422



action possibilites: [-1] 
expected returns: [[98.71766]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 15  8 10  8  6  0  6  0  0  6  6  3  6  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 26. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [16.  0.  6.  3. 16.] 
adversary cards in discard: [8. 6. 3.] 
adversary owned cards: [16  6  3  3  0 16  8  0  0  6] -> size -> 10 
adversary victory points: 0
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -40 

action type: trash_cards_n_from_hand - action 9
Learning step: -1.7884172201156616
desired expected reward: 38.402870178222656





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[86.27036 ]
 [94.750275]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 15  8 10  8  6  0  6  0  0  6  6  3  6  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 28. 30. 26. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [16.  0.  6.  3. 16.] 
adversary cards in discard: [8. 6. 3.] 
adversary owned cards: [16  6  3  3  0 16  8  0  0  6] -> size -> 10 
adversary victory points: 0
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -40 

action type: take_action - action -1
Learning step: -4.849730014801025
desired expected reward: 93.86792755126953






Player: 1 
cards in hand: [16.  0.  6.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  6.  3. 16.] 
cards in discard: [8. 6. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [16  6  3  3  0 16  8  0  0  6] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 26. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [6. 6. 0. 3. 6.] 
adversary cards in discard: [8. 8. 0.] 
adversary owned cards: [ 0  0  0 15  8 10  8  6  0  6  0  0  6  6  3  6  6] -> size -> 17 
adversary victory points: -5
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 16.] 
cards in discard: [8. 6. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  3  3  0 16  8  0  0  6  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 26. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [6. 6. 0. 3. 6.] 
adversary cards in discard: [8. 8. 0.] 
adversary owned cards: [ 0  0  0 15  8 10  8  6  0  6  0  0  6  6  3  6  6] -> size -> 17 
adversary victory points: -5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 16.] 
cards in discard: [8. 6. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  3  3  0 16  8  0  0  6  0] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 28. 30. 26. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [6. 6. 0. 3. 6.] 
adversary cards in discard: [8. 8. 0.] 
adversary owned cards: [ 0  0  0 15  8 10  8  6  0  6  0  0  6  6  3  6  6] -> size -> 17 
adversary victory points: -5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 16.] 
cards in discard: [8. 6. 3. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  3  3  0 16  8  0  0  6  0  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 28. 30. 26. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [6. 6. 0. 3. 6.] 
adversary cards in discard: [8. 8. 0.] 
adversary owned cards: [ 0  0  0 15  8 10  8  6  0  6  0  0  6  6  3  6  6] -> size -> 17 
adversary victory points: -5
player victory points: 1 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [6. 6. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[114.72714]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 3. 6.] 
cards in discard: [8. 8. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  8 10  8  6  0  6  0  0  6  6  3  6  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 26. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  6. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  3  3  0 16  8  0  0  6  0  0] -> size -> 11 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -70 

action type: buy - action -1.0
Learning step: -5.6566901206970215
desired expected reward: 89.09358978271484





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[100.38114]
 [111.86343]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 3. 6.] 
cards in discard: [8. 8. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  8 10  8  6  0  6  0  0  6  6  3  6  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 28. 30. 26. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  6. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  3  3  0 16  8  0  0  6  0  0] -> size -> 11 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -70 

action type: take_action - action -1.0
Learning step: -6.780157566070557
desired expected reward: 107.92315673828125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  6. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 16.  0.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [16  3  3  0 16  8  0  0  6  0  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 26. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  6.  6.] 
adversary cards in discard: [8. 8. 0. 6. 6. 0. 3. 6.] 
adversary owned cards: [ 0  0  0 15  8 10  8  6  0  6  0  0  6  6  3  6  6] -> size -> 17 
adversary victory points: -5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 16.  0.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [16  3  3  0 16  8  0  0  6  0  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 28. 30. 26. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  6.  6.] 
adversary cards in discard: [8. 8. 0. 6. 6. 0. 3. 6.] 
adversary owned cards: [ 0  0  0 15  8 10  8  6  0  6  0  0  6  6  3  6  6] -> size -> 17 
adversary victory points: -5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 16.  0.  0.] 
cards in discard: [0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [16  3  3  0 16  8  0  0  6  0  0  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [11. 28. 30. 26. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  6.  6.] 
adversary cards in discard: [8. 8. 0. 6. 6. 0. 3. 6.] 
adversary owned cards: [ 0  0  0 15  8 10  8  6  0  6  0  0  6  6  3  6  6] -> size -> 17 
adversary victory points: -5
player victory points: 1 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  0.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[123.58863 ]
 [113.255486]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  6.  6.] 
cards in discard: [8. 8. 0. 6. 6. 0. 3. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  8 10  8  6  0  6  0  0  6  6  3  6  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 26. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  0.  3.  3. 16.] 
adversary cards in discard: [ 0.  0.  6. 16.  0.  0.] 
adversary owned cards: [16  3  3  0 16  8  0  0  6  0  0  0] -> size -> 12 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -70 

action type: buy - action -1.0
Learning step: -6.39442777633667
desired expected reward: 105.46898651123047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[103.9924  ]
 [107.485405]
 [120.01303 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  6.  6.] 
cards in discard: [8. 8. 0. 6. 6. 0. 3. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  8 10  8  6  0  6  0  0  6  6  3  6  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 28. 30. 26. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  0.  3.  3. 16.] 
adversary cards in discard: [ 0.  0.  6. 16.  0.  0.] 
adversary owned cards: [16  3  3  0 16  8  0  0  6  0  0  0] -> size -> 12 
adversary victory points: 1
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -70 

action type: take_action - action -1.0
Learning step: -7.029054164886475
desired expected reward: 115.50526428222656



buy possibilites: [-1] 
expected returns: [[163.11223]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  6.  6.] 
cards in discard: [8. 8. 0. 6. 6. 0. 3. 6. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  8 10  8  6  0  6  0  0  6  6  3  6  6  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 25. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8.  0.  3.  3. 16.] 
adversary cards in discard: [ 0.  0.  6. 16.  0.  0.] 
adversary owned cards: [16  3  3  0 16  8  0  0  6  0  0  0] -> size -> 12 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -50   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -51 

action type: buy - action 3.0
Learning step: -3.834921360015869
desired expected reward: 95.26399993896484






Player: 1 
cards in hand: [ 8.  0.  3.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3.  3. 16.] 
cards in discard: [ 0.  0.  6. 16.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [16  3  3  0 16  8  0  0  6  0  0  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 25. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  6.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 15  8 10  8  6  0  6  0  0  6  6  3  6  6  3] -> size -> 18 
adversary victory points: -4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 16.] 
cards in discard: [ 0.  0.  6. 16.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  3  0 16  8  0  0  6  0  0  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 25. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  6.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 15  8 10  8  6  0  6  0  0  6  6  3  6  6  3] -> size -> 18 
adversary victory points: -4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 16.] 
cards in discard: [ 0.  0.  6. 16.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  3  0 16  8  0  0  6  0  0  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 28. 30. 25. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  6.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 15  8 10  8  6  0  6  0  0  6  6  3  6  6  3] -> size -> 18 
adversary victory points: -4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 16.] 
cards in discard: [ 0.  0.  6. 16.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  3  0 16  8  0  0  6  0  0  0  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 28. 30. 25. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  6.  0.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 15  8 10  8  6  0  6  0  0  6  6  3  6  6  3] -> size -> 18 
adversary victory points: -4
player victory points: 0 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [ 6.  6.  0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[78.46433]
 [72.23327]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0.  0. 15.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  8 10  8  6  0  6  0  0  6  6  3  6  6  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 25. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  3  0 16  8  0  0  6  0  0  0  0] -> size -> 12 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -49 

action type: buy - action -1
Learning step: -8.887852668762207
desired expected reward: 154.22438049316406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[71.32708 ]
 [73.61024 ]
 [80.801094]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0.  0. 15.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  8 10  8  6  0  6  0  0  6  6  3  6  6  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 28. 30. 25. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  3  0 16  8  0  0  6  0  0  0  0] -> size -> 12 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -49 

action type: take_action - action -1.0
Learning step: -4.5844035148620605
desired expected reward: 73.26594543457031



buy possibilites: [-1] 
expected returns: [[122.92811]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0.  0. 15.] 
cards in discard: [0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  8 10  8  6  0  6  0  0  6  6  3  6  6  3  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 28. 30. 25. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  3  0 16  8  0  0  6  0  0  0  0] -> size -> 12 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[ -5.   0.  -4. -40.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -79.0 

action type: buy - action 0.0
Learning step: -4.750472068786621
desired expected reward: 66.57660675048828






Player: 1 
cards in hand: [ 0.  0.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 16.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [16  3  0 16  8  0  0  6  0  0  0  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 25. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8. 6. 6. 6.] 
adversary cards in discard: [ 0.  6.  6.  0.  0. 15.] 
adversary owned cards: [ 0  0  0 15  8 10  8  6  0  6  0  0  6  6  3  6  6  3  0] -> size -> 19 
adversary victory points: -4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  3 16  8  0  0  6  0  0  0  0  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 24. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8. 6. 6. 6.] 
adversary cards in discard: [ 0.  6.  6.  0.  0. 15.] 
adversary owned cards: [ 0  0  0 15  8 10  8  6  0  6  0  0  6  6  3  6  6  3  0] -> size -> 19 
adversary victory points: -4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  3 16  8  0  0  6  0  0  0  0  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 28. 30. 24. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8. 6. 6. 6.] 
adversary cards in discard: [ 0.  6.  6.  0.  0. 15.] 
adversary owned cards: [ 0  0  0 15  8 10  8  6  0  6  0  0  6  6  3  6  6  3  0] -> size -> 19 
adversary victory points: -4
player victory points: 1 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [0. 8. 6. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[112.30223]
 [106.68359]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 6. 6.] 
cards in discard: [ 0.  6.  6.  0.  0. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  8 10  8  6  0  6  0  0  6  6  3  6  6  3  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 24. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [16.  0.  0.  6.  3.] 
adversary cards in discard: [ 3. 16.  0.  0.  0.] 
adversary owned cards: [16  3 16  8  0  0  6  0  0  0  0  3] -> size -> 12 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: buy - action -1
Learning step: -6.5819244384765625
desired expected reward: 116.34618377685547





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[102.429695]
 [110.972664]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 6. 6.] 
cards in discard: [ 0.  6.  6.  0.  0. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  8 10  8  6  0  6  0  0  6  6  3  6  6  3  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 28. 30. 24. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [16.  0.  0.  6.  3.] 
adversary cards in discard: [ 3. 16.  0.  0.  0.] 
adversary owned cards: [16  3 16  8  0  0  6  0  0  0  0  3] -> size -> 12 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: take_action - action -1.0
Learning step: -6.159079551696777
desired expected reward: 107.0388412475586



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [16.  0.  0.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.  6.  3.] 
cards in discard: [ 3. 16.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 16  8  0  0  6  0  0  0  0  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 24. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  8. 10.  0.  6.] 
adversary cards in discard: [ 0.  6.  6.  0.  0. 15.  0.  8.  6.  6.  6.] 
adversary owned cards: [ 0  0  0 15  8 10  8  6  0  6  0  0  6  6  3  6  6  3  0] -> size -> 19 
adversary victory points: -4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [ 3. 16.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  3 16  8  0  0  0  0  0  0  3  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 24. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  8. 10.  0.  6.] 
adversary cards in discard: [ 0.  6.  6.  0.  0. 15.  0.  8.  6.  6.  6.] 
adversary owned cards: [ 0  0  0 15  8 10  8  6  0  6  0  0  6  6  3  6  6  3  0] -> size -> 19 
adversary victory points: -4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 3. 16.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  3 16  8  0  0  0  0  0  0  3  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 28. 30. 24. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  8. 10.  0.  6.] 
adversary cards in discard: [ 0.  6.  6.  0.  0. 15.  0.  8.  6.  6.  6.] 
adversary owned cards: [ 0  0  0 15  8 10  8  6  0  6  0  0  6  6  3  6  6  3  0] -> size -> 19 
adversary victory points: -4
player victory points: 2 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [ 3.  8. 10.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[89.408806]
 [82.32693 ]
 [81.70369 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 10.  0.  6.] 
cards in discard: [ 0.  6.  6.  0.  0. 15.  0.  8.  6.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 15  8 10  8  6  0  6  0  0  6  6  3  6  6  3  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 24. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 16.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16  3 16  8  0  0  0  0  0  0  3  0] -> size -> 12 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: buy - action -1.0
Learning step: -7.063292026519775
desired expected reward: 103.90934753417969



action possibilites: [-1] 
expected returns: [[70.52154]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 0.  6.  6.  0.  0. 15.  0.  8.  6.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 24. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 16.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16  3 16  8  0  0  0  0  0  0  3  0] -> size -> 12 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -49 

action type: trash_cards_n_from_hand - action 14
Learning step: -5.297253608703613
desired expected reward: 83.38249969482422





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[54.876022]
 [67.98436 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0.  6.  6.  0.  0. 15.  0.  8.  6.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 28. 30. 24. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 16.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16  3 16  8  0  0  0  0  0  0  3  0] -> size -> 12 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -49 

action type: take_action - action -1
Learning step: -4.517116069793701
desired expected reward: 66.00442504882812



buy possibilites: [-1] 
expected returns: [[93.746346]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0.  6.  6.  0.  0. 15.  0.  8.  6.  6.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 24. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 16.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16  3 16  8  0  0  0  0  0  0  3  0] -> size -> 12 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -79 

action type: buy - action 0.0
Learning step: -4.584507942199707
desired expected reward: 50.291500091552734






Player: 1 
cards in hand: [ 3. 16.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 16  8  0  0  0  0  0  0  3  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 24. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0] -> size -> 16 
adversary victory points: -4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 16  8  0  0  0  0  0  0  3  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 28. 30. 24. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0] -> size -> 16 
adversary victory points: -4
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [0. 6. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[132.04715]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 28. 30. 24. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  0. 16.] 
adversary cards in discard: [ 3. 16.  0.  0.  8.] 
adversary owned cards: [16  3 16  8  0  0  0  0  0  0  3  0] -> size -> 12 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: buy - action -1
Learning step: -5.161133766174316
desired expected reward: 88.58521270751953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[118.76146 ]
 [121.88134 ]
 [121.17241 ]
 [125.63418 ]
 [121.721245]
 [130.02713 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 28. 30. 24. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  0. 16.] 
adversary cards in discard: [ 3. 16.  0.  0.  8.] 
adversary owned cards: [16  3 16  8  0  0  0  0  0  0  3  0] -> size -> 12 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: take_action - action -1.0
Learning step: -7.211767673492432
desired expected reward: 125.0630874633789



buy possibilites: [-1] 
expected returns: [[165.29507]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 6. 28. 30. 24. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  0. 16.] 
adversary cards in discard: [ 3. 16.  0.  0.  8.] 
adversary owned cards: [16  3 16  8  0  0  0  0  0  0  3  0] -> size -> 12 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5.   0.  -4. -60.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -99.0 

action type: buy - action 0.0
Learning step: -7.1689348220825195
desired expected reward: 111.59253692626953






Player: 1 
cards in hand: [ 3.  0.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 16.] 
cards in discard: [ 3. 16.  0.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 16  8  0  0  0  0  0  0  3  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 24. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  6.  0.  0. 15.] 
adversary cards in discard: [0. 0. 6. 0. 0. 3.] 
adversary owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0] -> size -> 17 
adversary victory points: -4
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [ 3. 16.  0.  0.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  3 16  8  0  0  0  0  0  3  0  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 24. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  6.  0.  0. 15.] 
adversary cards in discard: [0. 0. 6. 0. 0. 3.] 
adversary owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0] -> size -> 17 
adversary victory points: -4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 3. 16.  0.  0.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  3 16  8  0  0  0  0  0  3  0  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 28. 30. 24. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  6.  0.  0. 15.] 
adversary cards in discard: [0. 0. 6. 0. 0. 3.] 
adversary owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0] -> size -> 17 
adversary victory points: -4
player victory points: 2 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [ 0.  6.  0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[140.64882]
 [134.69077]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0.  0. 15.] 
cards in discard: [0. 0. 6. 0. 0. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 24. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [16.  0.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  3 16  8  0  0  0  0  0  3  0  0] -> size -> 12 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: buy - action -1
Learning step: -8.553999900817871
desired expected reward: 156.74107360839844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[127.79882]
 [130.85576]
 [130.1171 ]
 [134.70291]
 [130.67241]
 [138.8097 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0.  0. 15.] 
cards in discard: [0. 0. 6. 0. 0. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 28. 30. 24. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [16.  0.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  3 16  8  0  0  0  0  0  3  0  0] -> size -> 12 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: take_action - action -1.0
Learning step: -7.503381252288818
desired expected reward: 134.59413146972656



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [16.  0.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [16  3 16  8  0  0  0  0  0  3  0  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 24. 29.  8.  0.  5. 10.  0. 10.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [6. 6. 8. 6. 0.] 
adversary cards in discard: [ 0.  0.  6.  0.  0.  3.  0.  6.  0.  0. 15.] 
adversary owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0] -> size -> 17 
adversary victory points: -4
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [16 16  8  0  0  0  0  0  3  0  0 14] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 28. 30. 24. 29.  8.  0.  5. 10.  0. 10.  7.  8. 10.  8. 10.  9.] 
adversary cards in hand: [6. 6. 8. 6. 0.] 
adversary cards in discard: [ 0.  0.  6.  0.  0.  3.  0.  6.  0.  0. 15.] 
adversary owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0] -> size -> 17 
adversary victory points: -4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [16 16  8  0  0  0  0  0  3  0  0 14] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 28. 30. 24. 29.  8.  0.  5. 10.  0. 10.  7.  8. 10.  8. 10.  9.] 
adversary cards in hand: [6. 6. 8. 6. 0.] 
adversary cards in discard: [ 0.  0.  6.  0.  0.  3.  0.  6.  0.  0. 15.] 
adversary owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0] -> size -> 17 
adversary victory points: -4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [14.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [16 16  8  0  0  0  0  0  3  0  0 14  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 4. 28. 30. 24. 29.  8.  0.  5. 10.  0. 10.  7.  8. 10.  8. 10.  9.] 
adversary cards in hand: [6. 6. 8. 6. 0.] 
adversary cards in discard: [ 0.  0.  6.  0.  0.  3.  0.  6.  0.  0. 15.] 
adversary owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0] -> size -> 17 
adversary victory points: -4
player victory points: 1 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [6. 6. 8. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[141.21046]
 [134.29178]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 8. 6. 0.] 
cards in discard: [ 0.  0.  6.  0.  0.  3.  0.  6.  0.  0. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 24. 29.  8.  0.  5. 10.  0. 10.  7.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  8. 16.  3.  0.] 
adversary cards in discard: [14.  0. 16.  0.  0.  0.] 
adversary owned cards: [16 16  8  0  0  0  0  0  3  0  0 14  0] -> size -> 13 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: buy - action -1.0
Learning step: -6.132533073425293
desired expected reward: 121.6285171508789





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[131.05869]
 [143.41347]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 8. 6. 0.] 
cards in discard: [ 0.  0.  6.  0.  0.  3.  0.  6.  0.  0. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 28. 30. 24. 29.  8.  0.  5. 10.  0. 10.  7.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  8. 16.  3.  0.] 
adversary cards in discard: [14.  0. 16.  0.  0.  0.] 
adversary owned cards: [16 16  8  0  0  0  0  0  3  0  0 14  0] -> size -> 13 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: take_action - action -1.0
Learning step: -6.9972357749938965
desired expected reward: 137.1510772705078



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  8. 16.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 16.  3.  0.] 
cards in discard: [14.  0. 16.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [16 16  8  0  0  0  0  0  3  0  0 14  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 24. 29.  8.  0.  5. 10.  0. 10.  7.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  6. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0] -> size -> 17 
adversary victory points: -4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  0.] 
cards in discard: [14.  0. 16.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 16  8  0  0  0  0  3  0  0 14  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 24. 29.  8.  0.  5. 10.  0. 10.  7.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  6. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0] -> size -> 17 
adversary victory points: -4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  0.] 
cards in discard: [14.  0. 16.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 16  8  0  0  0  0  3  0  0 14  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 28. 30. 24. 29.  8.  0.  5. 10.  0. 10.  7.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  6. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0] -> size -> 17 
adversary victory points: -4
player victory points: 1 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  6. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[90.629776]
 [84.56846 ]
 [84.67445 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6. 15.  8.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 24. 29.  8.  0.  5. 10.  0. 10.  7.  8. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [16 16  8  0  0  0  0  3  0  0 14  0] -> size -> 12 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: buy - action -1.0
Learning step: -8.117372512817383
desired expected reward: 135.29611206054688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[83.84729]
 [86.55313]
 [93.33941]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6. 15.  8.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 28. 30. 24. 29.  8.  0.  5. 10.  0. 10.  7.  8. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [16 16  8  0  0  0  0  3  0  0 14  0] -> size -> 12 
adversary victory points: 1
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -59 

action type: take_action - action -1.0
Learning step: -5.454219341278076
desired expected reward: 85.46247100830078



buy possibilites: [-1] 
expected returns: [[128.82013]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6. 15.  8.] 
cards in discard: [3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 23. 29.  8.  0.  5. 10.  0. 10.  7.  8. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [16 16  8  0  0  0  0  3  0  0 14  0] -> size -> 12 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -40 

action type: buy - action 3.0
Learning step: -3.4292047023773193
desired expected reward: 83.12393951416016






Player: 1 
cards in hand: [0. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [16 16  8  0  0  0  0  3  0  0 14  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 23. 29.  8.  0.  5. 10.  0. 10.  7.  8. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 6. 0. 3.] 
adversary cards in discard: [ 3.  0.  0.  6. 15.  8.] 
adversary owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0  3] -> size -> 18 
adversary victory points: -3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 16  8  0  0  0  3  0  0 14  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 23. 29.  8.  0.  5. 10.  0. 10.  7.  8. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 6. 0. 3.] 
adversary cards in discard: [ 3.  0.  0.  6. 15.  8.] 
adversary owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0  3] -> size -> 18 
adversary victory points: -3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 16  8  0  0  0  3  0  0 14  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 28. 30. 23. 29.  8.  0.  5. 10.  0. 10.  7.  8. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 6. 0. 3.] 
adversary cards in discard: [ 3.  0.  0.  6. 15.  8.] 
adversary owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0  3] -> size -> 18 
adversary victory points: -3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 16  8  0  0  0  3  0  0 14  0  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 28. 30. 22. 29.  8.  0.  5. 10.  0. 10.  7.  8. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 6. 0. 3.] 
adversary cards in discard: [ 3.  0.  0.  6. 15.  8.] 
adversary owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0  3] -> size -> 18 
adversary victory points: -3
player victory points: 2 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [0. 0. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[93.58835]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 3.] 
cards in discard: [ 3.  0.  0.  6. 15.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 22. 29.  8.  0.  5. 10.  0. 10.  7.  8. 10.  8. 10.  9.] 
adversary cards in hand: [16.  0. 16.  3.  0.] 
adversary cards in discard: [3. 8. 0. 0. 0.] 
adversary owned cards: [16 16  8  0  0  0  3  0  0 14  0  3] -> size -> 12 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -58 

action type: buy - action -1
Learning step: -7.231460094451904
desired expected reward: 121.58866882324219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[82.52409 ]
 [85.74693 ]
 [85.10897 ]
 [88.980064]
 [85.66874 ]
 [91.768005]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 3.] 
cards in discard: [ 3.  0.  0.  6. 15.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 28. 30. 22. 29.  8.  0.  5. 10.  0. 10.  7.  8. 10.  8. 10.  9.] 
adversary cards in hand: [16.  0. 16.  3.  0.] 
adversary cards in discard: [3. 8. 0. 0. 0.] 
adversary owned cards: [16 16  8  0  0  0  3  0  0 14  0  3] -> size -> 12 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -58 

action type: take_action - action -1.0
Learning step: -5.578484535217285
desired expected reward: 88.17913818359375



buy possibilites: [-1] 
expected returns: [[99.85976]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 3.] 
cards in discard: [ 3.  0.  0.  6. 15.  8.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0  3  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 28. 30. 21. 29.  8.  0.  5. 10.  0. 10.  7.  8. 10.  8. 10.  9.] 
adversary cards in hand: [16.  0. 16.  3.  0.] 
adversary cards in discard: [3. 8. 0. 0. 0.] 
adversary owned cards: [16 16  8  0  0  0  3  0  0 14  0  3] -> size -> 12 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -40.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -45.0 

action type: buy - action 3.0
Learning step: -4.258603572845459
desired expected reward: 80.85035705566406






Player: 1 
cards in hand: [16.  0. 16.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 16.  3.  0.] 
cards in discard: [3. 8. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [16 16  8  0  0  0  3  0  0 14  0  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 21. 29.  8.  0.  5. 10.  0. 10.  7.  8. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 6. 6. 8.] 
adversary cards in discard: [ 3.  0.  0.  6. 15.  8.  3.  0.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0  3  3] -> size -> 19 
adversary victory points: -2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.] 
cards in discard: [ 3.  8.  0.  0.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [16 16  8  0  0  0  0  0 14  0  3 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 21. 29.  8.  0.  5. 10.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 6. 6. 8.] 
adversary cards in discard: [ 3.  0.  0.  6. 15.  8.  3.  0.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0  3  3] -> size -> 19 
adversary victory points: -2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.] 
cards in discard: [ 3.  8.  0.  0.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [16 16  8  0  0  0  0  0 14  0  3 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 28. 30. 21. 29.  8.  0.  5. 10.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 6. 6. 8.] 
adversary cards in discard: [ 3.  0.  0.  6. 15.  8.  3.  0.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0  3  3] -> size -> 19 
adversary victory points: -2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.] 
cards in discard: [ 3.  8.  0.  0.  0. 29.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [16 16  8  0  0  0  0  0 14  0  3 29  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 20. 29.  8.  0.  5. 10.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 6. 6. 8.] 
adversary cards in discard: [ 3.  0.  0.  6. 15.  8.  3.  0.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0  3  3] -> size -> 19 
adversary victory points: -2
player victory points: 2 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [0. 0. 6. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[100.20685]
 [ 94.77299]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 6. 8.] 
cards in discard: [ 3.  0.  0.  6. 15.  8.  3.  0.  0.  6.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0  3  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 20. 29.  8.  0.  5. 10.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 16. 16.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [16 16  8  0  0  0  0  0 14  0  3 29  3] -> size -> 13 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: buy - action -1
Learning step: -5.104063510894775
desired expected reward: 94.75569152832031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[90.384186]
 [92.87043 ]
 [99.432175]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6. 8.] 
cards in discard: [ 3.  0.  0.  6. 15.  8.  3.  0.  0.  6.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0  3  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 28. 30. 20. 29.  8.  0.  5. 10.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 16. 16.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [16 16  8  0  0  0  0  0 14  0  3 29  3] -> size -> 13 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action -1.0
Learning step: -5.209393501281738
desired expected reward: 95.6006088256836



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 16. 16.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 16.  0. 14.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [16 16  8  0  0  0  0  0 14  0  3 29  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 20. 29.  8.  0.  5. 10.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [8. 6. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0  3  3] -> size -> 19 
adversary victory points: -2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 16.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [16 16  8  0  0  0  0  0 14  0  3 29  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 28. 30. 20. 29.  8.  0.  5. 10.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [8. 6. 6.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0  3  3] -> size -> 19 
adversary victory points: -2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16. 16.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [16 16  8  0  0  0  0  0 14  0  3 29  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 4. 28. 30. 20. 29.  8.  0.  5. 10.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [8. 6. 6.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0  3  3] -> size -> 19 
adversary victory points: -2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16. 16.  0.] 
cards in discard: [3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [16 16  8  0  0  0  0  0 14  0  3 29  3  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 28. 30. 19. 29.  8.  0.  5. 10.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [8. 6. 6.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0  3  3] -> size -> 19 
adversary victory points: -2
player victory points: 3 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [8. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[77.640884]
 [69.93867 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 6.] 
cards in discard: [0. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0  3  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 19. 29.  8.  0.  5. 10.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0. 29.  8.  0.] 
adversary cards in discard: [ 3. 14.  0. 16. 16.  0.] 
adversary owned cards: [16 16  8  0  0  0  0  0 14  0  3 29  3  3] -> size -> 14 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[   -5     0    -2   -50     0     0     0   -60     0     0     0     0
     0 -1500    24     0] 
sum of rewards: -1593 

action type: discard_down_to_3_cards - action 0
Learning step: -82.27196502685547
desired expected reward: 5.225608825683594





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[65.2929 ]
 [78.06683]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 6.] 
cards in discard: [0. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0  3  3] -> size -> 19 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 4. 28. 30. 19. 29.  8.  0.  5. 10.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0. 29.  8.  0.] 
adversary cards in discard: [ 3. 14.  0. 16. 16.  0.] 
adversary owned cards: [16 16  8  0  0  0  0  0 14  0  3 29  3  3] -> size -> 14 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action -1.0
Learning step: -5.150083065032959
desired expected reward: 74.60397338867188



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  0. 29.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  8.  0.] 
cards in discard: [ 3. 14.  0. 16. 16.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [16 16  8  0  0  0  0  0 14  0  3 29  3  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 19. 29.  8.  0.  5. 10.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  6.  0. 15.] 
adversary cards in discard: [0. 0. 8. 6. 6.] 
adversary owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0  3  3] -> size -> 19 
adversary victory points: -2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [ 3. 14.  0. 16. 16.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 16  8  0  0  0  0  0 14  0  3  3  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 19. 29.  8.  0.  5. 10.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  6.  0. 15.] 
adversary cards in discard: [0. 0. 8. 6. 6.] 
adversary owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0  3  3] -> size -> 19 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 3. 14.  0. 16. 16.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 16  8  0  0  0  0  0 14  0  3  3  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 28. 30. 19. 29.  8.  0.  5. 10.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  6.  0. 15.] 
adversary cards in discard: [0. 0. 8. 6. 6.] 
adversary owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0  3  3] -> size -> 19 
adversary victory points: -2
player victory points: 3 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  6.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[79.16176]
 [73.23519]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  6.  0. 15.] 
cards in discard: [0. 0. 8. 6. 6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0  3  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 19. 29.  8.  0.  5. 10.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [3. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [16 16  8  0  0  0  0  0 14  0  3  3  3] -> size -> 13 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1.0
Learning step: -5.006139278411865
desired expected reward: 73.0606918334961





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[69.805534]
 [71.64676 ]
 [78.26968 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  6.  0. 15.] 
cards in discard: [0. 0. 8. 6. 6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0  3  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 28. 30. 19. 29.  8.  0.  5. 10.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [3. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [16 16  8  0  0  0  0  0 14  0  3  3  3] -> size -> 13 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action -1.0
Learning step: -5.0964884757995605
desired expected reward: 73.96986389160156



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [16 16  8  0  0  0  0  0 14  0  3  3  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 19. 29.  8.  0.  5. 10.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [6. 8. 0. 6. 3.] 
adversary cards in discard: [ 0.  0.  8.  6.  6.  3.  0.  6.  0. 15.] 
adversary owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0  3  3] -> size -> 19 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [16 16  8  0  0  0  0  0 14  0  3  3  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 28. 30. 19. 29.  8.  0.  5. 10.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [6. 8. 0. 6. 3.] 
adversary cards in discard: [ 0.  0.  8.  6.  6.  3.  0.  6.  0. 15.] 
adversary owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0  3  3] -> size -> 19 
adversary victory points: -2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [6. 8. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[86.18947]
 [80.67153]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0. 6. 3.] 
cards in discard: [ 0.  0.  8.  6.  6.  3.  0.  6.  0. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0  3  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 19. 29.  8.  0.  5. 10.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [14.  0.  0.  0. 16.] 
adversary cards in discard: [3. 8. 3. 0. 0.] 
adversary owned cards: [16 16  8  0  0  0  0  0 14  0  3  3  3] -> size -> 13 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1.0
Learning step: -4.861615180969238
desired expected reward: 73.40806579589844





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[72.925865]
 [81.68072 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0. 6. 3.] 
cards in discard: [ 0.  0.  8.  6.  6.  3.  0.  6.  0. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0  3  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 28. 30. 19. 29.  8.  0.  5. 10.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [14.  0.  0.  0. 16.] 
adversary cards in discard: [3. 8. 3. 0. 0.] 
adversary owned cards: [16 16  8  0  0  0  0  0 14  0  3  3  3] -> size -> 13 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action -1.0
Learning step: -5.072270393371582
desired expected reward: 75.18524169921875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [14.  0.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  0. 16.] 
cards in discard: [3. 8. 3. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [16 16  8  0  0  0  0  0 14  0  3  3  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 19. 29.  8.  0.  5. 10.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0  3  3] -> size -> 19 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  0. 16.] 
cards in discard: [3. 8. 3. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [16 16  8  0  0  0  0  0 14  0  3  3  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 28. 30. 19. 29.  8.  0.  5. 10.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0  3  3] -> size -> 19 
adversary victory points: -2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  0. 16.] 
cards in discard: [3. 8. 3. 0. 0. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [16 16  8  0  0  0  0  0 14  0  3  3  3  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 28. 30. 18. 29.  8.  0.  5. 10.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0  3  3] -> size -> 19 
adversary victory points: -2
player victory points: 4 





         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [8. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[87.418335]
 [81.66885 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 15  8  8  0  6  0  0  6  6  6  6  3  0  0  0  3  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 18. 29.  8.  0.  5. 10.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 14.  3.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16 16  8  0  0  0  0  0 14  0  3  3  3  3] -> size -> 14 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1.0
Learning step: -5.46148157119751
desired expected reward: 76.21923828125



action possibilites: [-1] 
expected returns: [[104.92626]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  8  8  0  6  0  0  6  6  6  6  0  0  0  3  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 28. 30. 18. 29.  8.  0.  5. 10.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 14.  3.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16 16  8  0  0  0  0  0 14  0  3  3  3  3] -> size -> 14 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -58 

action type: trash_cards_n_from_hand - action 4
Learning step: -4.35136604309082
desired expected reward: 71.89276885986328





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 99.94301]
 [106.26835]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  8  8  0  6  0  0  6  6  6  6  0  0  0  3  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 28. 30. 18. 29.  8.  0.  5. 10.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 14.  3.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16 16  8  0  0  0  0  0 14  0  3  3  3  3] -> size -> 14 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -58 

action type: take_action - action -1
Learning step: -5.789384841918945
desired expected reward: 99.13687896728516



buy possibilites: [-1] 
expected returns: [[161.25815]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  8  8  0  6  0  0  6  6  6  6  0  0  0  3  3  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 28. 30. 18. 29.  8.  0.  5. 10.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 14.  3.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16 16  8  0  0  0  0  0 14  0  3  3  3  3] -> size -> 14 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5.   0.  -3. -70.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -88.0 

action type: buy - action 0.0
Learning step: -5.768843173980713
desired expected reward: 94.17417907714844






Player: 1 
cards in hand: [ 3. 14.  3.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  3.  0. 16.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [16 16  8  0  0  0  0  0 14  0  3  3  3  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 18. 29.  8.  0.  5. 10.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  0.  3. 15.  8.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [15  8  8  0  6  0  0  6  6  6  6  0  0  0  3  3  0] -> size -> 17 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  3.  0. 16.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [16 16  8  0  0  0  0  0 14  0  3  3  3  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 28. 30. 18. 29.  8.  0.  5. 10.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 6.  0.  3. 15.  8.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [15  8  8  0  6  0  0  6  6  6  6  0  0  0  3  3  0] -> size -> 17 
adversary victory points: -3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  3. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[91.02941 ]
 [85.48974 ]
 [85.671425]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3. 15.  8.] 
cards in discard: [0. 8. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  8  0  6  0  0  6  6  6  6  0  0  0  3  3  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 18. 29.  8.  0.  5. 10.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 16.  0.] 
adversary cards in discard: [ 3. 14.  3.  0. 16.] 
adversary owned cards: [16 16  8  0  0  0  0  0 14  0  3  3  3  3] -> size -> 14 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: buy - action -1
Learning step: -9.9412841796875
desired expected reward: 151.31686401367188





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[83.16346]
 [92.35503]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  3. 15.  8.] 
cards in discard: [0. 8. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  8  0  6  0  0  6  6  6  6  0  0  0  3  3  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 28. 30. 18. 29.  8.  0.  5. 10.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 16.  0.] 
adversary cards in discard: [ 3. 14.  3.  0. 16.] 
adversary owned cards: [16 16  8  0  0  0  0  0 14  0  3  3  3  3] -> size -> 14 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: take_action - action -1.0
Learning step: -6.468592166900635
desired expected reward: 85.4717025756836



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  0.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 16.  0.] 
cards in discard: [ 3. 14.  3.  0. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [16 16  8  0  0  0  0  0 14  0  3  3  3  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 18. 29.  8.  0.  5. 10.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [6. 0. 3. 0. 6.] 
adversary cards in discard: [ 0.  8.  0.  6.  0.  3. 15.  8.] 
adversary owned cards: [15  8  8  0  6  0  0  6  6  6  6  0  0  0  3  3  0] -> size -> 17 
adversary victory points: -3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3. 14.  3.  0. 16. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [16 16  8  0  0  0  0  0 14  0  3  3  3 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 18. 29.  8.  0.  5.  9.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [6. 0. 3. 0. 6.] 
adversary cards in discard: [ 0.  8.  0.  6.  0.  3. 15.  8.] 
adversary owned cards: [15  8  8  0  6  0  0  6  6  6  6  0  0  0  3  3  0] -> size -> 17 
adversary victory points: -3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3. 14.  3.  0. 16. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [16 16  8  0  0  0  0  0 14  0  3  3  3 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 28. 30. 18. 29.  8.  0.  5.  9.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [6. 0. 3. 0. 6.] 
adversary cards in discard: [ 0.  8.  0.  6.  0.  3. 15.  8.] 
adversary owned cards: [15  8  8  0  6  0  0  6  6  6  6  0  0  0  3  3  0] -> size -> 17 
adversary victory points: -3
player victory points: 3 





         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [6. 0. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[82.84319]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0. 6.] 
cards in discard: [ 0.  8.  0.  6.  0.  3. 15.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  8  0  6  0  0  6  6  6  6  0  0  0  3  3  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 18. 29.  8.  0.  5.  9.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [16.  3.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16 16  8  0  0  0  0  0 14  0  3  3  3 11] -> size -> 14 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -68 

action type: buy - action -1.0
Learning step: -6.085504055023193
desired expected reward: 86.26953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[79.90458]
 [81.39841]
 [84.96007]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 6.] 
cards in discard: [ 0.  8.  0.  6.  0.  3. 15.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  8  0  6  0  0  6  6  6  6  0  0  0  3  3  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 28. 30. 18. 29.  8.  0.  5.  9.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [16.  3.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16 16  8  0  0  0  0  0 14  0  3  3  3 11] -> size -> 14 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -68 

action type: take_action - action -1.0
Learning step: -5.813261032104492
desired expected reward: 80.06441497802734



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [16.  3.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [16 16  8  0  0  0  0  0 14  0  3  3  3 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 18. 29.  8.  0.  5.  9.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [15.  0.  0.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [15  8  8  0  6  0  0  6  6  6  6  0  0  0  3  3  0] -> size -> 17 
adversary victory points: -3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [16 16  8  0  0  0  0 14  0  3  3  3 11  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 17. 29.  8.  0.  5.  9.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [15.  0.  0.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [15  8  8  0  6  0  0  6  6  6  6  0  0  0  3  3  0] -> size -> 17 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [16 16  8  0  0  0  0 14  0  3  3  3 11  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 28. 30. 17. 29.  8.  0.  5.  9.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [15.  0.  0.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [15  8  8  0  6  0  0  6  6  6  6  0  0  0  3  3  0] -> size -> 17 
adversary victory points: -3
player victory points: 4 





         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [15.  0.  0.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[62.86415 ]
 [59.030884]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  6.  6.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  8  0  6  0  0  6  6  6  6  0  0  0  3  3  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 17. 29.  8.  0.  5.  9.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [14.  3. 16.  3.  0.] 
adversary cards in discard: [ 3. 16.  3.  0.  8.] 
adversary owned cards: [16 16  8  0  0  0  0 14  0  3  3  3 11  3] -> size -> 14 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: buy - action -1.0
Learning step: -6.735421180725098
desired expected reward: 78.22465515136719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[58.7646  ]
 [60.694874]
 [64.65141 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.  6.  6.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  8  0  6  0  0  6  6  6  6  0  0  0  3  3  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 28. 30. 17. 29.  8.  0.  5.  9.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [14.  3. 16.  3.  0.] 
adversary cards in discard: [ 3. 16.  3.  0.  8.] 
adversary owned cards: [16 16  8  0  0  0  0 14  0  3  3  3 11  3] -> size -> 14 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: take_action - action -1.0
Learning step: -5.667043209075928
desired expected reward: 58.0592155456543



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [14.  3. 16.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3. 16.  3.  0.] 
cards in discard: [ 3. 16.  3.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [16 16  8  0  0  0  0 14  0  3  3  3 11  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 17. 29.  8.  0.  5.  9.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [3. 6. 0. 6. 0.] 
adversary cards in discard: [15.  0.  0.  6.  6.] 
adversary owned cards: [15  8  8  0  6  0  0  6  6  6  6  0  0  0  3  3  0] -> size -> 17 
adversary victory points: -3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  3.  0.] 
cards in discard: [ 3. 16.  3.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [16 16  8  0  0  0  0 14  0  3  3  3 11  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 28. 30. 17. 29.  8.  0.  5.  9.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [3. 6. 0.] 
adversary cards in discard: [15.  0.  0.  6.  6.  0.  6.] 
adversary owned cards: [15  8  8  0  6  0  0  6  6  6  6  0  0  0  3  3  0] -> size -> 17 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  3.  0.] 
cards in discard: [ 3. 16.  3.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [16 16  8  0  0  0  0 14  0  3  3  3 11  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 28. 30. 17. 29.  8.  0.  5.  9.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [3. 6. 0.] 
adversary cards in discard: [15.  0.  0.  6.  6.  0.  6.] 
adversary owned cards: [15  8  8  0  6  0  0  6  6  6  6  0  0  0  3  3  0] -> size -> 17 
adversary victory points: -3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  3.  0.] 
cards in discard: [ 3. 16.  3.  0.  8. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [16 16  8  0  0  0  0 14  0  3  3  3 11  3 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 17. 29.  8.  0.  5.  8.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [3. 6. 0.] 
adversary cards in discard: [15.  0.  0.  6.  6.  0.  6.] 
adversary owned cards: [15  8  8  0  6  0  0  6  6  6  6  0  0  0  3  3  0] -> size -> 17 
adversary victory points: -3
player victory points: 4 





         -------------------- Turn: 62 -------------------- 
Player: 0 
cards in hand: [3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[91.46441]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0.] 
cards in discard: [15.  0.  0.  6.  6.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  8  0  6  0  0  6  6  6  6  0  0  0  3  3  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 17. 29.  8.  0.  5.  8.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 8. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16 16  8  0  0  0  0 14  0  3  3  3 11  3 11] -> size -> 15 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[   -5     0    -3   -70     0     0     0   -60     0     0     0     0
     0 -1500    20     0] 
sum of rewards: -1618 

action type: discard_down_to_3_cards - action 1
Learning step: -79.38885498046875
desired expected reward: -69.04313659667969





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[83.15196]
 [92.41048]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0.] 
cards in discard: [15.  0.  0.  6.  6.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  8  0  6  0  0  6  6  6  6  0  0  0  3  3  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 28. 30. 17. 29.  8.  0.  5.  8.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 8. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16 16  8  0  0  0  0 14  0  3  3  3 11  3 11] -> size -> 15 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: take_action - action -1.0
Learning step: -6.378310680389404
desired expected reward: 83.77408599853516



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [16 16  8  0  0  0  0 14  0  3  3  3 11  3 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 17. 29.  8.  0.  5.  8.  0. 10.  6.  8. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 3. 8. 8.] 
adversary cards in discard: [15.  0.  0.  6.  6.  0.  6.  3.  6.  0.] 
adversary owned cards: [15  8  8  0  6  0  0  6  6  6  6  0  0  0  3  3  0] -> size -> 17 
adversary victory points: -3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [16 16  8  0  0  0  0 14  0  3  3  3 11  3 11 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 17. 29.  8.  0.  5.  8.  0. 10.  6.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 8. 8.] 
adversary cards in discard: [15.  0.  0.  6.  6.  0.  6.  3.  6.  0.] 
adversary owned cards: [15  8  8  0  6  0  0  6  6  6  6  0  0  0  3  3  0] -> size -> 17 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [16 16  8  0  0  0  0 14  0  3  3  3 11  3 11 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 28. 30. 17. 29.  8.  0.  5.  8.  0. 10.  6.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 8. 8.] 
adversary cards in discard: [15.  0.  0.  6.  6.  0.  6.  3.  6.  0.] 
adversary owned cards: [15  8  8  0  6  0  0  6  6  6  6  0  0  0  3  3  0] -> size -> 17 
adversary victory points: -3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0.] 
cards in discard: [10. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [16 16  8  0  0  0  0 14  0  3  3  3 11  3 11 10 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 17. 29.  8.  0.  5.  8.  0. 10.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 3. 8. 8.] 
adversary cards in discard: [15.  0.  0.  6.  6.  0.  6.  3.  6.  0.] 
adversary owned cards: [15  8  8  0  6  0  0  6  6  6  6  0  0  0  3  3  0] -> size -> 17 
adversary victory points: -3
player victory points: 4 





         -------------------- Turn: 63 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[98.054855]
 [90.66169 ]
 [90.66169 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 8.] 
cards in discard: [15.  0.  0.  6.  6.  0.  6.  3.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  8  0  6  0  0  6  6  6  6  0  0  0  3  3  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 17. 29.  8.  0.  5.  8.  0. 10.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [16.  3. 16. 14. 11.] 
adversary cards in discard: [10. 10. 11.  8.  0.  0.  0.] 
adversary owned cards: [16 16  8  0  0  0  0 14  0  3  3  3 11  3 11 10 10] -> size -> 17 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: buy - action -1.0
Learning step: -6.377537250518799
desired expected reward: 86.03294372558594



action possibilites: [-1] 
expected returns: [[73.243195]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [15.  0.  0.  6.  6.  0.  6.  3.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  8  8  6  0  6  6  6  6  0  0  0  3  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 17. 29.  8.  0.  5.  8.  0. 10.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [16.  3. 16. 14. 11.] 
adversary cards in discard: [10. 10. 11.  8.  0.  0.  0.] 
adversary owned cards: [16 16  8  0  0  0  0 14  0  3  3  3 11  3 11 10 10] -> size -> 17 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: trash_cards_n_from_hand - action 9
Learning step: -5.976102352142334
desired expected reward: 77.50538635253906





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[64.80036]
 [68.9177 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [15.  0.  0.  6.  6.  0.  6.  3.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  8  8  6  0  6  6  6  6  0  0  0  3  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 3. 28. 30. 17. 29.  8.  0.  5.  8.  0. 10.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [16.  3. 16. 14. 11.] 
adversary cards in discard: [10. 10. 11.  8.  0.  0.  0.] 
adversary owned cards: [16 16  8  0  0  0  0 14  0  3  3  3 11  3 11 10 10] -> size -> 17 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: take_action - action -1
Learning step: -5.583714485168457
desired expected reward: 67.65947723388672






Player: 1 
cards in hand: [16.  3. 16. 14. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16. 14. 11.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3. 16. 14. 11.] 
cards in discard: [10. 10. 11.  8.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [16 16  8  0  0  0  0 14  0  3  3  3 11  3 11 10 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 17. 29.  8.  0.  5.  8.  0. 10.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [15  8  8  6  0  6  6  6  6  0  0  0  3  0] -> size -> 14 
adversary victory points: -4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3. 16. 11.] 
cards in discard: [10. 10. 11.  8.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [16 16  8  0  0  0  0 14  0  3  3  3 11  3 11 10 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 28. 30. 17. 29.  8.  0.  5.  8.  0. 10.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [8. 0. 6.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [15  8  8  6  0  6  6  6  6  0  0  0  3  0] -> size -> 14 
adversary victory points: -4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3. 16. 11.] 
cards in discard: [10. 10. 11.  8.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [16 16  8  0  0  0  0 14  0  3  3  3 11  3 11 10 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 28. 30. 17. 29.  8.  0.  5.  8.  0. 10.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [8. 0. 6.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [15  8  8  6  0  6  6  6  6  0  0  0  3  0] -> size -> 14 
adversary victory points: -4
player victory points: 4 





         -------------------- Turn: 64 -------------------- 
Player: 0 
cards in hand: [8. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[82.79306]
 [77.68698]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6.] 
cards in discard: [0. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  8  6  0  6  6  6  6  0  0  0  3  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 17. 29.  8.  0.  5.  8.  0. 10.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [10. 10. 11.  8.  0.  0.  0. 14. 16.  3. 16. 11.] 
adversary owned cards: [16 16  8  0  0  0  0 14  0  3  3  3 11  3 11 10 10] -> size -> 17 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -89 

action type: discard_down_to_3_cards - action 0
Learning step: -3.822315216064453
desired expected reward: 20.699777603149414





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[76.643364]
 [84.33854 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6.] 
cards in discard: [0. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  8  6  0  6  6  6  6  0  0  0  3  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 28. 30. 17. 29.  8.  0.  5.  8.  0. 10.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [10. 10. 11.  8.  0.  0.  0. 14. 16.  3. 16. 11.] 
adversary owned cards: [16 16  8  0  0  0  0 14  0  3  3  3 11  3 11 10 10] -> size -> 17 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -89 

action type: take_action - action -1.0
Learning step: -6.771065711975098
desired expected reward: 76.77265930175781



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [10. 10. 11.  8.  0.  0.  0. 14. 16.  3. 16. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [16 16  8  0  0  0  0 14  0  3  3  3 11  3 11 10 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 17. 29.  8.  0.  5.  8.  0. 10.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 6. 15.  8.  6.  0.] 
adversary cards in discard: [0. 0. 8. 0. 6.] 
adversary owned cards: [15  8  8  6  0  6  6  6  6  0  0  0  3  0] -> size -> 14 
adversary victory points: -4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [10. 10. 11.  8.  0.  0.  0. 14. 16.  3. 16. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [16 16  8  0  0  0  0 14  0  3  3  3 11  3 11 10 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 28. 30. 17. 29.  8.  0.  5.  8.  0. 10.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 6. 15.  8.  6.  0.] 
adversary cards in discard: [0. 0. 8. 0. 6.] 
adversary owned cards: [15  8  8  6  0  6  6  6  6  0  0  0  3  0] -> size -> 14 
adversary victory points: -4
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 65 -------------------- 
Player: 0 
cards in hand: [ 6. 15.  8.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[67.33887]
 [65.20495]
 [65.85977]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  8.  6.  0.] 
cards in discard: [0. 0. 8. 0. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  8  6  0  6  6  6  6  0  0  0  3  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 28. 30. 17. 29.  8.  0.  5.  8.  0. 10.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [16 16  8  0  0  0  0 14  0  3  3  3 11  3 11 10 10] -> size -> 17 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -89 

action type: buy - action -1.0
Learning step: -7.170870304107666
desired expected reward: 77.16766357421875



action possibilites: [-1] 
expected returns: [[26.940853]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 6.] 
cards in discard: [0. 0. 8. 0. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  8  8  6  6  6  6  6  0  0  0  3  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 3. 28. 30. 17. 29.  8.  0.  5.  8.  0. 10.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [16 16  8  0  0  0  0 14  0  3  3  3 11  3 11 10 10] -> size -> 17 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: take_action - action 15.0
Learning step: -6.08289098739624
desired expected reward: 58.698307037353516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[21.795605]
 [23.18995 ]
 [22.826189]
 [24.624327]
 [23.077171]
 [26.615925]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 6.] 
cards in discard: [0. 0. 8. 0. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  8  8  6  6  6  6  6  0  0  0  3  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 28. 30. 17. 29.  8.  0.  5.  8.  0. 10.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [16 16  8  0  0  0  0 14  0  3  3  3 11  3 11 10 10] -> size -> 17 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: take_action - action -1
Learning step: -4.22976016998291
desired expected reward: 22.71109390258789



buy possibilites: [-1] 
expected returns: [[64.23163]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 6.] 
cards in discard: [0. 0. 8. 0. 6. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  8  8  6  6  6  6  6  0  0  0  3  0  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 2. 28. 30. 17. 29.  8.  0.  5.  8.  0. 10.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  3.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [16 16  8  0  0  0  0 14  0  3  3  3 11  3 11 10 10] -> size -> 17 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5.   0.  -4. -80.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -99.0 

action type: buy - action 0.0
Learning step: -4.594568252563477
desired expected reward: 17.201032638549805






Player: 1 
cards in hand: [ 0.  0.  3.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  8. 10.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [16 16  8  0  0  0  0 14  0  3  3  3 11  3 11 10 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 28. 30. 17. 29.  8.  0.  5.  8.  0. 10.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 3. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [15  8  8  6  6  6  6  6  0  0  0  3  0  0] -> size -> 14 
adversary victory points: -4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 16  8  0  0  0  0 14  0  3  3 11  3 11 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 28. 30. 17. 29.  8.  0.  5.  8.  0. 10.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 3. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [15  8  8  6  6  6  6  6  0  0  0  3  0  0] -> size -> 14 
adversary victory points: -4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [16 16  8  0  0  0  0 14  0  3  3 11  3 11 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 28. 30. 17. 29.  8.  0.  5.  8.  0. 10.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 3. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [15  8  8  6  6  6  6  6  0  0  0  3  0  0] -> size -> 14 
adversary victory points: -4
player victory points: 3 





         -------------------- Turn: 66 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[100.61771]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 6. 6.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  8  6  6  6  6  6  0  0  0  3  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 28. 30. 17. 29.  8.  0.  5.  8.  0. 10.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 16. 16. 11. 11.] 
adversary cards in discard: [8. 0. 0.] 
adversary owned cards: [16 16  8  0  0  0  0 14  0  3  3 11  3 11 10] -> size -> 15 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -79 

action type: buy - action -1
Learning step: -4.9150071144104
desired expected reward: 59.316619873046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[88.01651 ]
 [90.42662 ]
 [97.995026]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 6.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  8  6  6  6  6  6  0  0  0  3  0  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 28. 30. 17. 29.  8.  0.  5.  8.  0. 10.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 16. 16. 11. 11.] 
adversary cards in discard: [8. 0. 0.] 
adversary owned cards: [16 16  8  0  0  0  0 14  0  3  3 11  3 11 10] -> size -> 15 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -79 

action type: take_action - action -1.0
Learning step: -6.800581455230713
desired expected reward: 93.04716491699219



buy possibilites: [-1] 
expected returns: [[102.83603]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 6.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  8  6  6  6  6  6  0  0  0  3  0  0  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 1. 28. 30. 17. 29.  8.  0.  5.  8.  0. 10.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 16. 16. 11. 11.] 
adversary cards in discard: [8. 0. 0.] 
adversary owned cards: [16 16  8  0  0  0  0 14  0  3  3 11  3 11 10] -> size -> 15 
adversary victory points: 3
player victory points: -4 

Reward from previous game state: 
[ -5.   0.  -4. -70.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -109.0 

action type: buy - action 0.0
Learning step: -7.537014961242676
desired expected reward: 80.4794921875






Player: 1 
cards in hand: [ 3. 16. 16. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16. 11. 11.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16. 16. 11. 11.] 
cards in discard: [8. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [16 16  8  0  0  0  0 14  0  3  3 11  3 11 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 28. 30. 17. 29.  8.  0.  5.  8.  0. 10.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [8. 0. 6. 8. 0.] 
adversary cards in discard: [0. 0. 0. 3. 6. 6.] 
adversary owned cards: [15  8  8  6  6  6  6  6  0  0  0  3  0  0  0] -> size -> 15 
adversary victory points: -4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 11. 11.] 
cards in discard: [ 8.  0.  0. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [16 16  8  0  0  0  0 14  0  3 11  3 11 10 15] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 28. 30. 17. 29.  8.  0.  5.  8.  0. 10.  6.  8. 10.  6. 10.  8.] 
adversary cards in hand: [8. 0. 6. 8. 0.] 
adversary cards in discard: [0. 0. 0. 3. 6. 6.] 
adversary owned cards: [15  8  8  6  6  6  6  6  0  0  0  3  0  0  0] -> size -> 15 
adversary victory points: -4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 11. 11.] 
cards in discard: [ 8.  0.  0. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [16 16  8  0  0  0  0 14  0  3 11  3 11 10 15] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 1. 28. 30. 17. 29.  8.  0.  5.  8.  0. 10.  6.  8. 10.  6. 10.  8.] 
adversary cards in hand: [8. 0. 6. 8. 0.] 
adversary cards in discard: [0. 0. 0. 3. 6. 6.] 
adversary owned cards: [15  8  8  6  6  6  6  6  0  0  0  3  0  0  0] -> size -> 15 
adversary victory points: -4
player victory points: 2 


Player 1 won the game! 



Player 0 bought cards:
Copper: 9 
Silver: 0 
Gold: 0 
Estate: 5 
Duchy: 0 
Province: 0 
Curse: 8 

Remodel: 1 
Workshop: 0 
Chapel: 2 
Witch: 0 
Poacher: 0 
Militia: 0 
Market: 0 
Village: 1 
Library: 0 
Moneylender: 1 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [8. 0. 6. 8. 0.] 
cards in discard: [0. 0. 0. 3. 6. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  8  6  6  6  6  6  0  0  0  3  0  0  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 28. 30. 17. 29.  8.  0.  5.  8.  0. 10.  6.  8. 10.  6. 10.  8.] 
adversary cards in hand: [16. 11. 11.] 
adversary cards in discard: [ 8.  0.  0. 15.  0.] 
adversary owned cards: [16 16  8  0  0  0  0 14  0  3 11  3 11 10 15  0] -> size -> 16 
adversary victory points: 2
player victory points: -4 

Reward from previous game state: 
[  -5 -500   -4  -60    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -569 

action type: buy - action -1
Learning step: -33.59180450439453
desired expected reward: 69.24422454833984



