 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[20.833868]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    0    0    0    0   20    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -469 

action type: gain_card_n - action 8
Learning step: -15.118935585021973
desired expected reward: 19.845592498779297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[19.058867]
 [21.406788]
 [19.938686]
 [15.802021]
 [19.788334]
 [22.939682]
 [22.047462]
 [23.276031]
 [18.71755 ]
 [20.571867]
 [21.06068 ]
 [21.115152]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5662510991096497
desired expected reward: 20.671646118164062



buy possibilites: [-1] 
expected returns: [[21.314547]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 1.0
Learning step: -0.433400958776474
desired expected reward: 20.973388671875






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [0. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [1. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [0. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [1. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [0. 0. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [1. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[21.043116]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [1. 0. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5659292340278625
desired expected reward: 20.74861717224121





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[19.655733]
 [21.99069 ]
 [20.535551]
 [16.347717]
 [23.517488]
 [22.625267]
 [21.167292]
 [21.703075]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [1. 0. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.563285231590271
desired expected reward: 20.723112106323242



buy possibilites: [-1] 
expected returns: [[22.651999]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [ 1.  0.  0.  0.  3.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: -0.07767865806818008
desired expected reward: 23.439809799194336






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 3] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 3. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[21.713648]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [3. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5982905030250549
desired expected reward: 22.053707122802734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[19.955765]
 [20.835585]
 [16.671303]
 [22.922462]
 [22.003107]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [3. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5906203985214233
desired expected reward: 21.435039520263672



buy possibilites: [-1] 
expected returns: [[22.479101]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [3. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 3] -> size -> 12 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 3.0
Learning step: -0.29903697967529297
desired expected reward: 20.536548614501953






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [3. 3. 0. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  1.] 
adversary cards in discard: [3. 0. 3. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3] -> size -> 13 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [3. 3. 0. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 3] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  1.] 
adversary cards in discard: [3. 0. 3. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3] -> size -> 13 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [3. 3. 0. 0. 0. 0. 8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 3 8] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  1.] 
adversary cards in discard: [3. 0. 3. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3] -> size -> 13 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0. 11.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[23.466513]
 [25.265688]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  1.] 
cards in discard: [3. 0. 3. 0. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 3 8] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5657399296760559
desired expected reward: 21.913360595703125



action possibilites: [-1] 
expected returns: [[22.529211]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1.] 
cards in discard: [3. 0. 3. 0. 3. 3. 1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 3 8] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 1
Learning step: 0.2562273144721985
desired expected reward: 23.600540161132812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[21.317898]
 [23.672022]
 [22.197718]
 [19.465023]
 [18.009882]
 [22.047365]
 [25.204918]
 [24.312693]
 [27.420267]
 [25.541265]
 [20.97658 ]
 [21.074306]
 [22.8371  ]
 [18.739347]
 [23.325916]
 [23.380384]]
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1.] 
cards in discard: [3. 0. 3. 0. 3. 3. 1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 28. 30. 28. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 3 8] -> size -> 13 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.020455684512853622
desired expected reward: 22.549667358398438



buy possibilites: [-1] 
expected returns: [[24.287199]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1.] 
cards in discard: [3. 0. 3. 0. 3. 3. 1. 4.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 29.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 3 8] -> size -> 13 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 50  0] 
sum of rewards: 65 

action type: buy - action 4.0
Learning step: 1.6210649013519287
desired expected reward: 21.08608627319336






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 3 8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 29.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4] -> size -> 15 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 3 8] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 28. 29.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4] -> size -> 15 
adversary victory points: 7
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 3 8 1] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 27. 30. 28. 29.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4] -> size -> 15 
adversary victory points: 7
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[23.420464]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 29.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 3 8 1] -> size -> 14 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6301803588867188
desired expected reward: 23.657018661499023





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[21.58256 ]
 [23.917698]
 [22.46238 ]
 [18.274544]
 [22.312027]
 [25.45059 ]
 [24.558365]
 [25.786938]
 [21.241243]
 [23.094118]
 [23.5762  ]
 [23.629902]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 27. 30. 28. 29.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 3 8 1] -> size -> 14 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6125427484512329
desired expected reward: 23.047988891601562



buy possibilites: [-1] 
expected returns: [[25.856785]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 29.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 3 8 1] -> size -> 14 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 29.0
Learning step: 0.31257620453834534
desired expected reward: 26.099515914916992






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [1. 0. 3. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 3 8 1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 29.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 1. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29] -> size -> 16 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [1. 0. 3. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 3 8 1] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 27. 30. 28. 29.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 1. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29] -> size -> 16 
adversary victory points: 7
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [1. 0. 3. 0. 0. 0. 1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 3 8 1 1] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 28. 29.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 1. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29] -> size -> 16 
adversary victory points: 7
player victory points: 4 





Player: 0 
cards in hand: [3. 1. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[26.644999]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 3. 0. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 28. 29.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 3 8 1 1] -> size -> 15 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6453967094421387
desired expected reward: 25.211387634277344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[25.307896]
 [27.718376]
 [26.205282]
 [21.875647]
 [26.057316]
 [29.270855]
 [28.373472]
 [29.616953]
 [24.941223]
 [26.860374]
 [27.351704]
 [27.376368]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 0. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 26. 30. 28. 29.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 3 8 1 1] -> size -> 15 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6640123128890991
desired expected reward: 26.031877517700195



buy possibilites: [-1] 
expected returns: [[28.837137]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 0. 0.] 
cards in discard: [29.  0.  0.  3.  0.  0. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 28. 29.  8. 10.  9.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 3 8 1 1] -> size -> 15 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 16.0
Learning step: 0.3310704827308655
desired expected reward: 26.388385772705078






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [3. 0. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 3 8 1 1] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 28. 29.  8. 10.  9.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 4.  3.  0.  1. 11.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0. 16.  3.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16] -> size -> 17 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 3. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 3 8 1 1] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 26. 30. 28. 29.  8. 10.  9.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 4.  3.  0.  1. 11.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0. 16.  3.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16] -> size -> 17 
adversary victory points: 7
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 3. 0.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 3 8 1 1 0] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 26. 30. 28. 29.  8. 10.  9.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 4.  3.  0.  1. 11.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0. 16.  3.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16] -> size -> 17 
adversary victory points: 7
player victory points: 4 





Player: 0 
cards in hand: [ 4.  3.  0.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[26.889107]
 [28.716846]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4.  3.  0.  1. 11.] 
cards in discard: [29.  0.  0.  3.  0.  0. 16.  3.  1.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 29.  8. 10.  9.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 1. 1.] 
adversary cards in discard: [0. 3. 0. 8. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 3 8 1 1 0] -> size -> 16 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7203314900398254
desired expected reward: 28.116806030273438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[25.481176]
 [27.74371 ]
 [26.314064]
 [22.310595]
 [29.24018 ]
 [28.36671 ]
 [26.927809]
 [27.41844 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4.  3.  0.  1. 11.] 
cards in discard: [29.  0.  0.  3.  0.  0. 16.  3.  1.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 26. 30. 28. 29.  8. 10.  9.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 1. 1.] 
adversary cards in discard: [0. 3. 0. 8. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 3 8 1 1 0] -> size -> 16 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6736664175987244
desired expected reward: 26.31178855895996



buy possibilites: [-1] 
expected returns: [[27.48804]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4.  3.  0.  1. 11.] 
cards in discard: [29.  0.  0.  3.  0.  0. 16.  3.  1.  3.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 29.  8. 10.  9.  8.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 1. 1.] 
adversary cards in discard: [0. 3. 0. 8. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 3 8 1 1 0] -> size -> 16 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: -0.19858090579509735
desired expected reward: 29.041597366333008






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 1. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 1.] 
cards in discard: [0. 3. 0. 8. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 3 8 1 1 0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 29.  8. 10.  9.  8.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0. 29. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11] -> size -> 18 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 1.] 
cards in discard: [0. 3. 0. 8. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 3 8 1 1 0] -> size -> 16 
action values: 0 
buys: 1 
player value: 7 
card supply: [28. 26. 30. 28. 29.  8. 10.  9.  8.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0. 29. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11] -> size -> 18 
adversary victory points: 7
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 1.] 
cards in discard: [ 0.  3.  0.  8.  3.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  8  1  1  0 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 26. 30. 28. 29.  8. 10.  9.  8.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [16.  0. 29. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11] -> size -> 18 
adversary victory points: 7
player victory points: 4 





Player: 0 
cards in hand: [16.  0. 29. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29. 11.] 
expected returns: [[22.890171]
 [21.557922]
 [25.174334]
 [24.823895]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 29. 11.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 29.  8. 10.  9.  8.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 0.  3.  0.  8.  3.  0. 10.  0.  0.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  8  1  1  0 10] -> size -> 17 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7224292159080505
desired expected reward: 26.76561164855957



action possibilites: [-1. 16. 11.] 
expected returns: [[30.071995]
 [28.671064]
 [32.084156]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 26. 30. 28. 29.  8. 10.  9.  8.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 0.  3.  0.  8.  3.  0. 10.  0.  0.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  8  1  1  0 10] -> size -> 17 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0.013606681488454342
desired expected reward: 25.28314781188965



action possibilites: [-1] 
expected returns: [[32.861977]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  3.  0.] 
cards in discard: [14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 26. 30. 28. 29.  8. 10.  9.  8.  9. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 0.  3.  0.  8.  3.  0. 10.  0.  0.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  8  1  1  0 10] -> size -> 17 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 51 

action type: gain_card_n - action 8
Learning step: 0.9413383603096008
desired expected reward: 32.065086364746094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[31.1685  ]
 [33.728607]
 [32.1216  ]
 [27.523256]
 [35.377464]
 [34.42436 ]
 [32.817356]
 [33.365303]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  3.  0.] 
cards in discard: [14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 26. 30. 28. 29.  8. 10.  9.  8.  9. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 0.  3.  0.  8.  3.  0. 10.  0.  0.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  8  1  1  0 10] -> size -> 17 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.4119861423969269
desired expected reward: 33.273963928222656



buy possibilites: [-1] 
expected returns: [[27.77523]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  3.  0.] 
cards in discard: [14.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 26. 30. 28. 29.  8.  9.  9.  8.  9. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 0.  3.  0.  8.  3.  0. 10.  0.  0.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  8  1  1  0 10] -> size -> 17 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   40.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -265.0 

action type: buy - action 6.0
Learning step: -8.484058380126953
desired expected reward: 19.03919792175293






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 0.  3.  0.  8.  3.  0. 10.  0.  0.  0.  1.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  8  1  1  0 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 29.  8.  9.  9.  8.  9. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [1. 4. 3. 0. 0.] 
adversary cards in discard: [14.  6. 29. 11. 16.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6] -> size -> 20 
adversary victory points: 6
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 0.  3.  0.  8.  3.  0. 10.  0.  0.  0.  1.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  8  1  1  0 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 26. 30. 28. 29.  8.  9.  9.  8.  9. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [1. 4. 3. 0. 0.] 
adversary cards in discard: [14.  6. 29. 11. 16.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6] -> size -> 20 
adversary victory points: 6
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 0.  3.  0.  8.  3.  0. 10.  0.  0.  0.  1.  1.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  8  1  1  0 10  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 28. 29.  8.  9.  9.  8.  9. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [1. 4. 3. 0. 0.] 
adversary cards in discard: [14.  6. 29. 11. 16.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6] -> size -> 20 
adversary victory points: 6
player victory points: 4 





Player: 0 
cards in hand: [1. 4. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[27.155142]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 4. 3. 0. 0.] 
cards in discard: [14.  6. 29. 11. 16.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 28. 29.  8.  9.  9.  8.  9. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  8  1  1  0 10  1] -> size -> 18 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6977686285972595
desired expected reward: 27.07746124267578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[25.625513]
 [27.874706]
 [26.462925]
 [22.423405]
 [26.324837]
 [29.324167]
 [28.486023]
 [29.65011 ]
 [25.283329]
 [27.07424 ]
 [27.532524]
 [27.555555]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 4. 3. 0. 0.] 
cards in discard: [14.  6. 29. 11. 16.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 25. 30. 28. 29.  8.  9.  9.  8.  9. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  8  1  1  0 10  1] -> size -> 18 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.676883339881897
desired expected reward: 26.512474060058594



buy possibilites: [-1] 
expected returns: [[22.7051]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 4. 3. 0. 0.] 
cards in discard: [14.  6. 29. 11. 16.  0.  3.  0. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 28. 29.  8.  9.  9.  8.  9. 10.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  8  1  1  0 10  1] -> size -> 18 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 29.0
Learning step: 0.158900186419487
desired expected reward: 29.809011459350586






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  3  8  1  1  0 10  1] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 28. 29.  8.  9.  9.  8.  9. 10.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [11.  1.  3.  3.  0.] 
adversary cards in discard: [14.  6. 29. 11. 16.  0.  3.  0. 29.  1.  4.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29] -> size -> 21 
adversary victory points: 6
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  0  3  8  1  1  0 10  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 28. 29.  8.  9.  9.  8.  9. 10.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [11.  1.  3.  3.  0.] 
adversary cards in discard: [14.  6. 29. 11. 16.  0.  3.  0. 29.  1.  4.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29] -> size -> 21 
adversary victory points: 6
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  0  3  8  1  1  0 10  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 25. 30. 28. 29.  8.  9.  9.  8.  9. 10.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [11.  1.  3.  3.  0.] 
adversary cards in discard: [14.  6. 29. 11. 16.  0.  3.  0. 29.  1.  4.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29] -> size -> 21 
adversary victory points: 6
player victory points: 4 





Player: 0 
cards in hand: [11.  1.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[21.764614]
 [23.294668]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  3.  3.  0.] 
cards in discard: [14.  6. 29. 11. 16.  0.  3.  0. 29.  1.  4.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 28. 29.  8.  9.  9.  8.  9. 10.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 0  0  0  3  3  3  0  3  8  1  1  0 10  1] -> size -> 14 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5924002528190613
desired expected reward: 22.112699508666992





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[20.144909]
 [22.05858 ]
 [20.845243]
 [17.500841]
 [23.300362]
 [22.585283]
 [21.368477]
 [21.7328  ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  3.  3.  0.] 
cards in discard: [14.  6. 29. 11. 16.  0.  3.  0. 29.  1.  4.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 25. 30. 28. 29.  8.  9.  9.  8.  9. 10.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 0  0  0  3  3  3  0  3  8  1  1  0 10  1] -> size -> 14 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.57271808385849
desired expected reward: 21.082687377929688



buy possibilites: [-1] 
expected returns: [[22.526094]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  3.  3.  0.] 
cards in discard: [14.  6. 29. 11. 16.  0.  3.  0. 29.  1.  4.  3.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 25. 30. 27. 29.  8.  9.  9.  8.  9. 10.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 0  0  0  3  3  3  0  3  8  1  1  0 10  1] -> size -> 14 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: -3.0 

action type: buy - action 3.0
Learning step: -0.4788333773612976
desired expected reward: 20.366411209106445






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  3  8  1  1  0 10  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 27. 29.  8.  9.  9.  8.  9. 10.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3] -> size -> 22 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  3  8  1  1  0 10  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 25. 30. 27. 29.  8.  9.  9.  8.  9. 10.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3] -> size -> 22 
adversary victory points: 7
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [ 8. 23.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  3  8  1  1  0 10  1 23] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 27. 29.  8.  9.  9.  8.  9. 10.  8.  9.  9.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3] -> size -> 22 
adversary victory points: 7
player victory points: 4 





Player: 0 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[30.618912]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 27. 29.  8.  9.  9.  8.  9. 10.  8.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 1. 10.  0.  3.  3.] 
adversary cards in discard: [ 8. 23.  0.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  0  3  8  1  1  0 10  1 23] -> size -> 15 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5031999945640564
desired expected reward: 22.02289390563965





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[29.2699  ]
 [31.767023]
 [30.183722]
 [25.722013]
 [33.363506]
 [32.449684]
 [30.866383]
 [31.341711]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 25. 30. 27. 29.  8.  9.  9.  8.  9. 10.  8.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 1. 10.  0.  3.  3.] 
adversary cards in discard: [ 8. 23.  0.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  0  3  8  1  1  0 10  1 23] -> size -> 15 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7443898320198059
desired expected reward: 29.977787017822266



buy possibilites: [-1] 
expected returns: [[29.31469]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 25. 30. 27. 29.  8.  9.  9.  8.  9. 10.  8.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 1. 10.  0.  3.  3.] 
adversary cards in discard: [ 8. 23.  0.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  0  3  8  1  1  0 10  1 23] -> size -> 15 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.720292866230011
desired expected reward: 28.549610137939453






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 1. 10.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  0.  3.  3.] 
cards in discard: [ 8. 23.  0.  0.  3.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  3  8  1  1  0 10  1 23] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 27. 29.  8.  9.  9.  8.  9. 10.  8.  9.  9.  9. 10. 10.] 
adversary cards in hand: [29.  6. 29. 11.  1.] 
adversary cards in discard: [0. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0] -> size -> 23 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  0.  3.  3.] 
cards in discard: [ 8. 23.  0.  0.  3.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  3  8  1  1  0 10  1 23] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 25. 30. 27. 29.  8.  9.  9.  8.  9. 10.  8.  9.  9.  9. 10. 10.] 
adversary cards in hand: [29.  6. 29. 11.  1.] 
adversary cards in discard: [0. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0] -> size -> 23 
adversary victory points: 7
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  0.  3.  3.] 
cards in discard: [ 8. 23.  0.  0.  3.  1.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  3  8  1  1  0 10  1 23  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 25. 30. 27. 29.  8.  9.  9.  8.  9. 10.  8.  9.  9.  9. 10. 10.] 
adversary cards in hand: [29.  6. 29. 11.  1.] 
adversary cards in discard: [0. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0] -> size -> 23 
adversary victory points: 7
player victory points: 4 





Player: 0 
cards in hand: [29.  6. 29. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 11.] 
expected returns: [[24.060055]
 [26.332874]
 [26.332874]
 [25.991896]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6. 29. 11.  1.] 
cards in discard: [0. 0. 3. 3. 0. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 27. 29.  8.  9.  9.  8.  9. 10.  8.  9.  9.  9. 10. 10.] 
adversary cards in hand: [10.  3.  0.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0  3  8  1  1  0 10  1 23  0] -> size -> 16 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7574915289878845
desired expected reward: 28.55719757080078



action possibilites: [-1. 29. 11.] 
expected returns: [[28.838224]
 [31.164911]
 [30.815868]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29. 11.  1.  3.] 
cards in discard: [0. 0. 3. 3. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 27. 29.  8.  9.  9.  8.  9. 10.  8.  9.  9.  9. 10. 10.] 
adversary cards in hand: [10.  3.  0.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0  3  8  1  1  0 10  1 23  0] -> size -> 16 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: -0.022940825670957565
desired expected reward: 26.399736404418945



action possibilites: [-1] 
expected returns: [[35.131546]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29.  1.  3.] 
cards in discard: [0. 0. 3. 3. 0. 0. 1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 24. 30. 27. 29.  8.  9.  9.  8.  9. 10.  8.  9.  9.  9. 10. 10.] 
adversary cards in hand: [10.  3.  0.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0  3  8  1  1  0 10  1 23  0] -> size -> 16 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  9  0] 
sum of rewards: 44 

action type: gain_card_n - action 1
Learning step: 0.8112407922744751
desired expected reward: 30.065919876098633





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[33.265938]
 [35.77936 ]
 [34.18097 ]
 [29.69179 ]
 [37.41243 ]
 [36.47557 ]
 [34.86977 ]
 [35.349903]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 29.  1.  3.] 
cards in discard: [0. 0. 3. 3. 0. 0. 1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 24. 30. 27. 29.  8.  9.  9.  8.  9. 10.  8.  9.  9.  9. 10. 10.] 
adversary cards in hand: [10.  3.  0.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0  3  8  1  1  0 10  1 23  0] -> size -> 16 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.3654966950416565
desired expected reward: 35.49704360961914



buy possibilites: [-1] 
expected returns: [[33.50216]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 29.  1.  3.] 
cards in discard: [0. 0. 3. 3. 0. 0. 1. 3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 24. 30. 26. 29.  8.  9.  9.  8.  9. 10.  8.  9.  9.  9. 10. 10.] 
adversary cards in hand: [10.  3.  0.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  0  3  8  1  1  0 10  1 23  0] -> size -> 16 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 40.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 37.0 

action type: buy - action 3.0
Learning step: 0.4363435208797455
desired expected reward: 34.617313385009766






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [10.  3.  0.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  1.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  3  8  1  1  0 10  1 23  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 26. 29.  8.  9.  9.  8.  9. 10.  8.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 0. 16. 14.  1.  3.] 
adversary cards in discard: [ 0.  0.  3.  3.  0.  0.  1.  3. 29. 11.  6. 29.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3] -> size -> 25 
adversary victory points: 8
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  1.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  3  8  1  1  0 10  1 23  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 24. 30. 26. 29.  8.  9.  9.  8.  9. 10.  8.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 0. 16. 14.  1.  3.] 
adversary cards in discard: [ 0.  0.  3.  3.  0.  0.  1.  3. 29. 11.  6. 29.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3] -> size -> 25 
adversary victory points: 8
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  1.  3.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  3  8  1  1  0 10  1 23  0 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 26. 29.  8.  9.  9.  8.  9. 10.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 0. 16. 14.  1.  3.] 
adversary cards in discard: [ 0.  0.  3.  3.  0.  0.  1.  3. 29. 11.  6. 29.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3] -> size -> 25 
adversary victory points: 8
player victory points: 4 





Player: 0 
cards in hand: [ 0. 16. 14.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14.] 
expected returns: [[27.009333]
 [25.866398]
 [24.834076]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 14.  1.  3.] 
cards in discard: [ 0.  0.  3.  3.  0.  0.  1.  3. 29. 11.  6. 29.  1.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 26. 29.  8.  9.  9.  8.  9. 10.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 1.] 
adversary cards in discard: [10. 10.  3.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  0  3  8  1  1  0 10  1 23  0 10] -> size -> 17 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.8807772397994995
desired expected reward: 32.62138366699219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[25.36837 ]
 [27.563932]
 [26.171864]
 [22.230934]
 [28.96873 ]
 [28.16424 ]
 [26.772173]
 [27.1902  ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16. 14.  1.  3.] 
cards in discard: [ 0.  0.  3.  3.  0.  0.  1.  3. 29. 11.  6. 29.  1.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 24. 30. 26. 29.  8.  9.  9.  8.  9. 10.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 1.] 
adversary cards in discard: [10. 10.  3.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  0  3  8  1  1  0 10  1 23  0 10] -> size -> 17 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6763378977775574
desired expected reward: 26.33113670349121



buy possibilites: [-1] 
expected returns: [[27.541746]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16. 14.  1.  3.] 
cards in discard: [ 0.  0.  3.  3.  0.  0.  1.  3. 29. 11.  6. 29.  1.  3.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 24. 30. 26. 29.  8.  8.  9.  8.  9. 10.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 1.] 
adversary cards in discard: [10. 10.  3.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  0  3  8  1  1  0 10  1 23  0 10] -> size -> 17 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.527738571166992
desired expected reward: 12.703193664550781






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 1.] 
cards in discard: [10. 10.  3.  0.  1.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  3  8  1  1  0 10  1 23  0 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 26. 29.  8.  8.  9.  8.  9. 10.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 4.] 
adversary cards in discard: [ 0.  0.  3.  3.  0.  0.  1.  3. 29. 11.  6. 29.  1.  3.  6.  0. 16. 14.
  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6] -> size -> 26 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 1.] 
cards in discard: [10. 10.  3.  0.  1.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  3  8  1  1  0 10  1 23  0 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 24. 30. 26. 29.  8.  8.  9.  8.  9. 10.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 4.] 
adversary cards in discard: [ 0.  0.  3.  3.  0.  0.  1.  3. 29. 11.  6. 29.  1.  3.  6.  0. 16. 14.
  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6] -> size -> 26 
adversary victory points: 7
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 1.] 
cards in discard: [10. 10.  3.  0.  1.  3.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  3  8  1  1  0 10  1 23  0 10  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 24. 30. 26. 29.  8.  8.  9.  8.  8. 10.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 4.] 
adversary cards in discard: [ 0.  0.  3.  3.  0.  0.  1.  3. 29. 11.  6. 29.  1.  3.  6.  0. 16. 14.
  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6] -> size -> 26 
adversary victory points: 7
player victory points: 4 





Player: 0 
cards in hand: [0. 3. 0. 0. 4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[25.549843]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 4.] 
cards in discard: [ 0.  0.  3.  3.  0.  0.  1.  3. 29. 11.  6. 29.  1.  3.  6.  0. 16. 14.
  1.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 26. 29.  8.  8.  9.  8.  8. 10.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 1.  0. 23.  8.  0.] 
adversary cards in discard: [10. 10.  3.  0.  1.  3.  8.  0.  3.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  3  3  3  0  3  8  1  1  0 10  1 23  0 10  8] -> size -> 18 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7079790234565735
desired expected reward: 26.83376693725586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[23.950779]
 [26.190895]
 [24.7532  ]
 [20.859753]
 [27.70555 ]
 [26.838564]
 [25.356783]
 [25.793694]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 4.] 
cards in discard: [ 0.  0.  3.  3.  0.  0.  1.  3. 29. 11.  6. 29.  1.  3.  6.  0. 16. 14.
  1.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 24. 30. 26. 29.  8.  8.  9.  8.  8. 10.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 1.  0. 23.  8.  0.] 
adversary cards in discard: [10. 10.  3.  0.  1.  3.  8.  0.  3.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  3  3  3  0  3  8  1  1  0 10  1 23  0 10  8] -> size -> 18 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.646791934967041
desired expected reward: 24.903051376342773



buy possibilites: [-1] 
expected returns: [[22.194342]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 4.] 
cards in discard: [ 0.  0.  3.  3.  0.  0.  1.  3. 29. 11.  6. 29.  1.  3.  6.  0. 16. 14.
  1.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 24. 30. 26. 29.  8.  8.  9.  8.  8. 10.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 1.  0. 23.  8.  0.] 
adversary cards in discard: [10. 10.  3.  0.  1.  3.  8.  0.  3.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  3  3  3  0  3  8  1  1  0 10  1 23  0 10  8] -> size -> 18 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.6171499490737915
desired expected reward: 22.722536087036133






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 1.  0. 23.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 23.  8.  0.] 
cards in discard: [10. 10.  3.  0.  1.  3.  8.  0.  3.  0.  3.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  0  3  8  1  1  0 10  1 23  0 10  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 26. 29.  8.  8.  9.  8.  8. 10.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 6.  1.  0.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6  0] -> size -> 27 
adversary victory points: 7
player victory points: 4 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 8. 0. 0.] 
cards in discard: [10. 10.  3.  0.  1.  3.  8.  0.  3.  0.  3.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  3  3  3  0  3  8  1  1  0 10  1 23  0 10  8] -> size -> 18 
action values: 1 
buys: 1 
player value: 1 
card supply: [25. 24. 30. 26. 29.  8.  8.  9.  8.  8. 10.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 6.  1.  0.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6  0] -> size -> 27 
adversary victory points: 7
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [10. 10.  3.  0.  1.  3.  8.  0.  3.  0.  3.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [ 3  3  3  0  3  8  1  1  0 10  1 23  0 10  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 24. 30. 26. 29.  8.  8.  9.  8.  8. 10.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 6.  1.  0.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6  0] -> size -> 27 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [10. 10.  3.  0.  1.  3.  8.  0.  3.  0.  3.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [ 3  3  3  0  3  8  1  1  0 10  1 23  0 10  8] -> size -> 15 
action values: 0 
buys: 2 
player value: 3 
card supply: [25. 24. 30. 26. 29.  8.  8.  9.  8.  8. 10.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 6.  1.  0.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6  0] -> size -> 27 
adversary victory points: 7
player victory points: 4 


buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [10. 10.  3.  0.  1.  3.  8.  0.  3.  0.  3.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [ 3  3  3  0  3  8  1  1  0 10  1 23  0 10  8  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 24. 30. 26. 29.  8.  8.  9.  8.  8. 10.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 6.  1.  0.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6  0] -> size -> 27 
adversary victory points: 7
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [10. 10.  3.  0.  1.  3.  8.  0.  3.  0.  3.  1.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [ 3  3  3  0  3  8  1  1  0 10  1 23  0 10  8  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 24. 30. 26. 29.  8.  8.  9.  8.  8. 10.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 6.  1.  0.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6  0] -> size -> 27 
adversary victory points: 7
player victory points: 4 





Player: 0 
cards in hand: [ 6.  1.  0.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[25.409384]
 [27.36936 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  1.  0.  1. 11.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 26. 29.  8.  8.  9.  8.  8. 10.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  0  3  8  1  1  0 10  1 23  0 10  8  0  0] -> size -> 17 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5359295010566711
desired expected reward: 21.65841293334961



action possibilites: [-1] 
expected returns: [[26.971972]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 0. 1.] 
cards in discard: [15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6  0 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 26. 29.  8.  8.  9.  8.  8. 10.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  0  3  8  1  1  0 10  1 23  0 10  8  0  0] -> size -> 17 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 10
Learning step: 0.46049851179122925
desired expected reward: 25.550737380981445





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[25.98073 ]
 [28.409678]
 [26.848074]
 [24.089584]
 [22.6263  ]
 [26.71826 ]
 [29.990465]
 [29.087215]
 [32.358322]
 [30.34543 ]
 [25.579046]
 [25.657572]
 [27.516417]
 [23.310593]
 [27.99476 ]
 [27.919085]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 0. 1.] 
cards in discard: [15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6  0 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 24. 30. 26. 29.  8.  8.  9.  8.  8. 10.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  0  3  8  1  1  0 10  1 23  0 10  8  0  0] -> size -> 17 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.06313013285398483
desired expected reward: 26.908842086791992



buy possibilites: [-1] 
expected returns: [[23.573542]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 0. 1.] 
cards in discard: [15.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6  0 15  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 5 
card supply: [22. 24. 30. 26. 29.  8.  8.  9.  8.  8. 10.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  0  3  8  1  1  0 10  1 23  0 10  8  0  0] -> size -> 17 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: -0.08189964294433594
desired expected reward: 25.898828506469727






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [0. 8. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  0  3  8  1  1  0 10  1 23  0 10  8  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 26. 29.  8.  8.  9.  8.  8. 10.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [29.  3.  4.  0.  3.] 
adversary cards in discard: [15.  0. 11.  6.  1.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6  0 15  0] -> size -> 29 
adversary victory points: 7
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3  8  1  1  0 10  1 23  0 10  8  0  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 26. 29.  8.  8.  9.  8.  8. 10.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [29.  3.  4.  0.  3.] 
adversary cards in discard: [15.  0. 11.  6.  1.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6  0 15  0] -> size -> 29 
adversary victory points: 7
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3  8  1  1  0 10  1 23  0 10  8  0  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 24. 30. 26. 29.  8.  8.  9.  8.  8. 10.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [29.  3.  4.  0.  3.] 
adversary cards in discard: [15.  0. 11.  6.  1.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6  0 15  0] -> size -> 29 
adversary victory points: 7
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3  8  1  1  0 10  1 23  0 10  8  0  0  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 25. 29.  8.  8.  9.  8.  8. 10.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [29.  3.  4.  0.  3.] 
adversary cards in discard: [15.  0. 11.  6.  1.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6  0 15  0] -> size -> 29 
adversary victory points: 7
player victory points: 4 





Player: 0 
cards in hand: [29.  3.  4.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[26.139393]
 [28.430496]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  4.  0.  3.] 
cards in discard: [15.  0. 11.  6.  1.  0.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6  0 15  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 25. 29.  8.  8.  9.  8.  8. 10.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [10.  3. 10.  1.  0.] 
adversary cards in discard: [3. 8. 0. 0.] 
adversary owned cards: [ 3  3  3  8  1  1  0 10  1 23  0 10  8  0  0  3] -> size -> 16 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.568082869052887
desired expected reward: 23.00545883178711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[24.383255]
 [21.207388]
 [26.233194]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  4.  0.  3.] 
cards in discard: [15.  0. 11.  6.  1.  0.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6  0 15  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 24. 30. 25. 29.  8.  8.  9.  8.  8. 10.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [10.  3. 10.  1.  0.] 
adversary cards in discard: [3. 8. 0. 0.] 
adversary owned cards: [ 3  3  3  8  1  1  0 10  1 23  0 10  8  0  0  3] -> size -> 16 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.678630530834198
desired expected reward: 25.482267379760742



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [10.  3. 10.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10.  1.  0.] 
cards in discard: [3. 8. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  1  1  0 10  1 23  0 10  8  0  0  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 25. 29.  8.  8.  9.  8.  8. 10.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [29.  1.  0.  0. 14.] 
adversary cards in discard: [15.  0. 11.  6.  1.  0.  1. 29.  3.  4.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6  0 15  0] -> size -> 29 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 10.  1.  0.] 
cards in discard: [3. 8. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  1  1  0 10  1 23  0 10  8  0  0  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 24. 30. 25. 29.  8.  8.  9.  8.  8. 10.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [29.  1.  0.  0. 14.] 
adversary cards in discard: [15.  0. 11.  6.  1.  0.  1. 29.  3.  4.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6  0 15  0] -> size -> 29 
adversary victory points: 7
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 10.  1.  0.] 
cards in discard: [ 3.  8.  0.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  1  1  0 10  1 23  0 10  8  0  0  3 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 25. 29.  8.  8.  9.  7.  8. 10.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [29.  1.  0.  0. 14.] 
adversary cards in discard: [15.  0. 11.  6.  1.  0.  1. 29.  3.  4.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6  0 15  0] -> size -> 29 
adversary victory points: 7
player victory points: 4 





Player: 0 
cards in hand: [29.  1.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14.] 
expected returns: [[23.844557]
 [26.008802]
 [21.787306]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  0.  0. 14.] 
cards in discard: [15.  0. 11.  6.  1.  0.  1. 29.  3.  4.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6  0 15  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 25. 29.  8.  8.  9.  7.  8. 10.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 0.  1. 23.  8.  1.] 
adversary cards in discard: [ 3.  8.  0.  0. 11. 10.  3. 10.  1.  0.] 
adversary owned cards: [ 3  3  3  8  1  1  0 10  1 23  0 10  8  0  0  3 11] -> size -> 17 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6816359758377075
desired expected reward: 25.551557540893555



action possibilites: [-1. 14. 16.] 
expected returns: [[24.96824 ]
 [22.826117]
 [23.878721]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0. 14. 16.] 
cards in discard: [15.  0. 11.  6.  1.  0.  1. 29.  3.  4.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6  0 15  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 24. 30. 25. 29.  8.  8.  9.  7.  8. 10.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 0.  1. 23.  8.  1.] 
adversary cards in discard: [ 3.  8.  0.  0. 11. 10.  3. 10.  1.  0.] 
adversary owned cards: [ 3  3  3  8  1  1  0 10  1 23  0 10  8  0  0  3 11] -> size -> 17 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: -0.07752994447946548
desired expected reward: 25.94406509399414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[23.485874]
 [25.699125]
 [24.284613]
 [21.727255]
 [20.406637]
 [24.165201]
 [27.107882]
 [26.30452 ]
 [29.25722 ]
 [27.43001 ]
 [23.109968]
 [23.183897]
 [24.890009]
 [21.027897]
 [25.323215]
 [25.254726]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0. 14. 16.] 
cards in discard: [15.  0. 11.  6.  1.  0.  1. 29.  3.  4.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6  0 15  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 24. 30. 25. 29.  8.  8.  9.  7.  8. 10.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 0.  1. 23.  8.  1.] 
adversary cards in discard: [ 3.  8.  0.  0. 11. 10.  3. 10.  1.  0.] 
adversary owned cards: [ 3  3  3  8  1  1  0 10  1 23  0 10  8  0  0  3 11] -> size -> 17 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.031461697071790695
desired expected reward: 24.936782836914062



buy possibilites: [-1] 
expected returns: [[25.713709]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0. 14. 16.] 
cards in discard: [15.  0. 11.  6.  1.  0.  1. 29.  3.  4.  0.  3. 16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6  0 15  0 16] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 24. 30. 25. 29.  8.  8.  8.  7.  8. 10.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 0.  1. 23.  8.  1.] 
adversary cards in discard: [ 3.  8.  0.  0. 11. 10.  3. 10.  1.  0.] 
adversary owned cards: [ 3  3  3  8  1  1  0 10  1 23  0 10  8  0  0  3 11] -> size -> 17 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  8.  0.] 
sum of rewards: 23.0 

action type: buy - action 16.0
Learning step: 0.2350378930568695
desired expected reward: 24.400239944458008






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 0.  1. 23.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 23.  8.  1.] 
cards in discard: [ 3.  8.  0.  0. 11. 10.  3. 10.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  1  1  0 10  1 23  0 10  8  0  0  3 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 25. 29.  8.  8.  8.  7.  8. 10.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 3.  3. 11.  3.  0.] 
adversary cards in discard: [15.  0. 11.  6.  1.  0.  1. 29.  3.  4.  0.  3. 16. 29.  1.  0.  0. 14.
 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6  0 15  0 16] -> size -> 30 
adversary victory points: 7
player victory points: 4 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 8. 1. 3.] 
cards in discard: [ 3.  8.  0.  0. 11. 10.  3. 10.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 3  3  3  8  1  1  0 10  1 23  0 10  8  0  0  3 11] -> size -> 17 
action values: 1 
buys: 1 
player value: 1 
card supply: [22. 24. 30. 25. 29.  8.  8.  8.  7.  8. 10.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 3.  3. 11.  3.  0.] 
adversary cards in discard: [15.  0. 11.  6.  1.  0.  1. 29.  3.  4.  0.  3. 16. 29.  1.  0.  0. 14.
 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6  0 15  0 16] -> size -> 30 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 8. 1. 3.] 
cards in discard: [ 3.  8.  0.  0. 11. 10.  3. 10.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 3  3  3  8  1  1  0 10  1 23  0 10  8  0  0  3 11] -> size -> 17 
action values: 0 
buys: 2 
player value: 6 
card supply: [22. 24. 30. 25. 29.  8.  8.  8.  7.  8. 10.  8.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 3.  3. 11.  3.  0.] 
adversary cards in discard: [15.  0. 11.  6.  1.  0.  1. 29.  3.  4.  0.  3. 16. 29.  1.  0.  0. 14.
 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6  0 15  0 16] -> size -> 30 
adversary victory points: 7
player victory points: 4 


buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 8. 1. 3.] 
cards in discard: [ 3.  8.  0.  0. 11. 10.  3. 10.  1.  0. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 3  3  3  8  1  1  0 10  1 23  0 10  8  0  0  3 11 15] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 24. 30. 25. 29.  8.  8.  8.  7.  8. 10.  8.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 3.  3. 11.  3.  0.] 
adversary cards in discard: [15.  0. 11.  6.  1.  0.  1. 29.  3.  4.  0.  3. 16. 29.  1.  0.  0. 14.
 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6  0 15  0 16] -> size -> 30 
adversary victory points: 7
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 8. 1. 3.] 
cards in discard: [ 3.  8.  0.  0. 11. 10.  3. 10.  1.  0. 15.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 3  3  3  8  1  1  0 10  1 23  0 10  8  0  0  3 11 15  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 25. 29.  8.  8.  8.  7.  7. 10.  8.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 3.  3. 11.  3.  0.] 
adversary cards in discard: [15.  0. 11.  6.  1.  0.  1. 29.  3.  4.  0.  3. 16. 29.  1.  0.  0. 14.
 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6  0 15  0 16] -> size -> 30 
adversary victory points: 7
player victory points: 4 





Player: 0 
cards in hand: [ 3.  3. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[29.843796]
 [31.802656]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11.  3.  0.] 
cards in discard: [15.  0. 11.  6.  1.  0.  1. 29.  3.  4.  0.  3. 16. 29.  1.  0.  0. 14.
 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6  0 15  0 16] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 25. 29.  8.  8.  8.  7.  7. 10.  8.  9.  9.  8. 10.  8.] 
adversary cards in hand: [0. 3. 8. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  8  1  1  0 10  1 23  0 10  8  0  0  3 11 15  8] -> size -> 19 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5957106351852417
desired expected reward: 25.117998123168945





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[27.954256]
 [24.74526 ]
 [29.79922 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 11.  3.  0.] 
cards in discard: [15.  0. 11.  6.  1.  0.  1. 29.  3.  4.  0.  3. 16. 29.  1.  0.  0. 14.
 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6  0 15  0 16] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 24. 30. 25. 29.  8.  8.  8.  7.  7. 10.  8.  9.  9.  8. 10.  8.] 
adversary cards in hand: [0. 3. 8. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  8  1  1  0 10  1 23  0 10  8  0  0  3 11 15  8] -> size -> 19 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7517390847206116
desired expected reward: 29.092058181762695



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [0. 3. 8. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 3. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  1  1  0 10  1 23  0 10  8  0  0  3 11 15  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 25. 29.  8.  8.  8.  7.  7. 10.  8.  9.  9.  8. 10.  8.] 
adversary cards in hand: [0. 3. 0. 6. 0.] 
adversary cards in discard: [15.  0. 11.  6.  1.  0.  1. 29.  3.  4.  0.  3. 16. 29.  1.  0.  0. 14.
 16.  3.  3. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6  0 15  0 16] -> size -> 30 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 3. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  1  1  0 10  1 23  0 10  8  0  0  3 11 15  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 24. 30. 25. 29.  8.  8.  8.  7.  7. 10.  8.  9.  9.  8. 10.  8.] 
adversary cards in hand: [0. 3. 0. 6. 0.] 
adversary cards in discard: [15.  0. 11.  6.  1.  0.  1. 29.  3.  4.  0.  3. 16. 29.  1.  0.  0. 14.
 16.  3.  3. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6  0 15  0 16] -> size -> 30 
adversary victory points: 7
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 3. 3.] 
cards in discard: [0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  1  1  0 10  1 23  0 10  8  0  0  3 11 15  8  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 24. 30. 25. 29.  8.  8.  8.  7.  7. 10.  8.  9.  9.  8. 10.  8.] 
adversary cards in hand: [0. 3. 0. 6. 0.] 
adversary cards in discard: [15.  0. 11.  6.  1.  0.  1. 29.  3.  4.  0.  3. 16. 29.  1.  0.  0. 14.
 16.  3.  3. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6  0 15  0 16] -> size -> 30 
adversary victory points: 7
player victory points: 4 





Player: 0 
cards in hand: [0. 3. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[24.897297]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 6. 0.] 
cards in discard: [15.  0. 11.  6.  1.  0.  1. 29.  3.  4.  0.  3. 16. 29.  1.  0.  0. 14.
 16.  3.  3. 11.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6  0 15  0 16] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 24. 30. 25. 29.  8.  8.  8.  7.  7. 10.  8.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 3. 10. 23.  8.  8.] 
adversary cards in discard: [0. 0. 3. 8. 3. 3.] 
adversary owned cards: [ 3  3  3  8  1  1  0 10  1 23  0 10  8  0  0  3 11 15  8  0] -> size -> 20 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.7825549244880676
desired expected reward: 29.016664505004883





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[23.066113]
 [25.239147]
 [23.83194 ]
 [20.056314]
 [26.644844]
 [25.843624]
 [24.432825]
 [24.796215]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 0.] 
cards in discard: [15.  0. 11.  6.  1.  0.  1. 29.  3.  4.  0.  3. 16. 29.  1.  0.  0. 14.
 16.  3.  3. 11.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6  0 15  0 16] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 24. 30. 25. 29.  8.  8.  8.  7.  7. 10.  8.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 3. 10. 23.  8.  8.] 
adversary cards in discard: [0. 0. 3. 8. 3. 3.] 
adversary owned cards: [ 3  3  3  8  1  1  0 10  1 23  0 10  8  0  0  3 11 15  8  0] -> size -> 20 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6373581290245056
desired expected reward: 24.259939193725586



buy possibilites: [-1] 
expected returns: [[26.858076]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 0.] 
cards in discard: [15.  0. 11.  6.  1.  0.  1. 29.  3.  4.  0.  3. 16. 29.  1.  0.  0. 14.
 16.  3.  3. 11.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6  0 15  0 16  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 24. 30. 24. 29.  8.  8.  8.  7.  7. 10.  8.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 3. 10. 23.  8.  8.] 
adversary cards in discard: [0. 0. 3. 8. 3. 3.] 
adversary owned cards: [ 3  3  3  8  1  1  0 10  1 23  0 10  8  0  0  3 11 15  8  0] -> size -> 20 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: -3.0 

action type: buy - action 3.0
Learning step: -0.5121463537216187
desired expected reward: 22.959726333618164






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 3. 10. 23.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 23.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 23.  8.  8.] 
cards in discard: [0. 0. 3. 8. 3. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  1  1  0 10  1 23  0 10  8  0  0  3 11 15  8  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 24. 30. 24. 29.  8.  8.  8.  7.  7. 10.  8.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 6.  0. 15.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6  0 15  0 16  3] -> size -> 31 
adversary victory points: 8
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.] 
cards in discard: [0. 0. 3. 8. 3. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  1  1  0  1 23  0 10  8  0  0  3 11 15  8  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 24. 30. 24. 29.  8.  8.  8.  7.  7. 10.  8.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 6.  0. 15.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6  0 15  0 16  3] -> size -> 31 
adversary victory points: 8
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.] 
cards in discard: [0. 0. 3. 8. 3. 3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  1  1  0  1 23  0 10  8  0  0  3 11 15  8  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 24. 30. 24. 29.  8.  8.  8.  7.  7. 10.  8.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 6.  0. 15.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6  0 15  0 16  3] -> size -> 31 
adversary victory points: 8
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.] 
cards in discard: [0. 0. 3. 8. 3. 3. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  1  1  0  1 23  0 10  8  0  0  3 11 15  8  0  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 24. 29.  8.  8.  8.  7.  7. 10.  8.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 6.  0. 15.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6  0 15  0 16  3] -> size -> 31 
adversary victory points: 8
player victory points: 3 





Player: 0 
cards in hand: [ 6.  0. 15.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[26.355091]
 [26.474638]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 15.  3.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1
  3  6  0 15  0 16  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 24. 29.  8.  8.  8.  7.  7. 10.  8.  9.  9.  8. 10.  8.] 
adversary cards in hand: [10.  1. 15.  0.  1.] 
adversary cards in discard: [ 0.  0.  3.  8.  3.  3.  0.  8. 23.] 
adversary owned cards: [ 3  3  1  1  0  1 23  0 10  8  0  0  3 11 15  8  0  0] -> size -> 18 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6776101589202881
desired expected reward: 26.180465698242188



action possibilites: [-1] 
expected returns: [[21.093004]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 24. 30. 24. 29.  8.  8.  8.  7.  7. 10.  8.  9.  9.  8. 10.  8.] 
adversary cards in hand: [10.  1. 15.  0.  1.] 
adversary cards in discard: [ 0.  0.  3.  8.  3.  3.  0.  8. 23.] 
adversary owned cards: [ 3  3  1  1  0  1 23  0 10  8  0  0  3 11 15  8  0  0] -> size -> 18 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: -0.12462123483419418
desired expected reward: 26.411972045898438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[19.60443 ]
 [21.816795]
 [20.38901 ]
 [16.58981 ]
 [20.274324]
 [23.244442]
 [22.434881]
 [23.572033]
 [19.223188]
 [20.993204]
 [21.417057]
 [21.303753]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 24. 30. 24. 29.  8.  8.  8.  7.  7. 10.  8.  9.  9.  8. 10.  8.] 
adversary cards in hand: [10.  1. 15.  0.  1.] 
adversary cards in discard: [ 0.  0.  3.  8.  3.  3.  0.  8. 23.] 
adversary owned cards: [ 3  3  1  1  0  1 23  0 10  8  0  0  3 11 15  8  0  0] -> size -> 18 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.04231515899300575
desired expected reward: 21.135318756103516



buy possibilites: [-1] 
expected returns: [[28.86369]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0.] 
cards in discard: [1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 23. 30. 24. 29.  8.  8.  8.  7.  7. 10.  8.  9.  9.  8. 10.  8.] 
adversary cards in hand: [10.  1. 15.  0.  1.] 
adversary cards in discard: [ 0.  0.  3.  8.  3.  3.  0.  8. 23.] 
adversary owned cards: [ 3  3  1  1  0  1 23  0 10  8  0  0  3 11 15  8  0  0] -> size -> 18 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 19.5 

action type: buy - action 1.0
Learning step: 0.2335648089647293
desired expected reward: 22.05036163330078






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [10.  1. 15.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1. 15.  0.  1.] 
cards in discard: [ 0.  0.  3.  8.  3.  3.  0.  8. 23.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  1  1  0  1 23  0 10  8  0  0  3 11 15  8  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 24. 29.  8.  8.  8.  7.  7. 10.  8.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 6.  0.  0. 16. 29.] 
adversary cards in discard: [ 1. 15.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1] -> size -> 31 
adversary victory points: 8
player victory points: 3 


action possibilites: [-1. 15. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15.  0.  1. 11.] 
cards in discard: [ 0.  0.  3.  8.  3.  3.  0.  8. 23.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  1  1  0  1 23  0 10  8  0  0  3 11 15  8  0  0] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 24. 29.  8.  8.  8.  7.  7. 10.  8.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 6.  0.  0. 16. 29.] 
adversary cards in discard: [ 1. 15.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1] -> size -> 31 
adversary victory points: 8
player victory points: 3 


action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15.  0.  1.] 
cards in discard: [ 0.  0.  3.  8.  3.  3.  0.  8. 23.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 3  3  1  1  0  1 23  0 10  8  0  0  3 11 15  8  0  0  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 24. 29.  8.  8.  8.  7.  6. 10.  8.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 6.  0.  0. 16. 29.] 
adversary cards in discard: [ 1. 15.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1] -> size -> 31 
adversary victory points: 8
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1.] 
cards in discard: [ 0.  0.  3.  8.  3.  3.  0.  8. 23.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 11. 15.] 
owned cards: [ 3  3  1  1  1 23  0 10  8  0  0  3 11 15  8  0  0  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 23. 30. 24. 29.  8.  8.  8.  7.  6. 10.  8.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 6.  0.  0. 16. 29.] 
adversary cards in discard: [ 1. 15.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1] -> size -> 31 
adversary victory points: 8
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1.] 
cards in discard: [ 0.  0.  3.  8.  3.  3.  0.  8. 23.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 11. 15.] 
owned cards: [ 3  3  1  1  1 23  0 10  8  0  0  3 11 15  8  0  0  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 7 
card supply: [20. 23. 30. 24. 29.  8.  8.  8.  7.  6. 10.  8.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 6.  0.  0. 16. 29.] 
adversary cards in discard: [ 1. 15.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1] -> size -> 31 
adversary victory points: 8
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1.] 
cards in discard: [ 0.  0.  3.  8.  3.  3.  0.  8. 23.  8. 23.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 11. 15.] 
owned cards: [ 3  3  1  1  1 23  0 10  8  0  0  3 11 15  8  0  0  8 23] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 23. 30. 24. 29.  8.  8.  8.  7.  6. 10.  8.  9.  8.  8. 10.  8.] 
adversary cards in hand: [ 6.  0.  0. 16. 29.] 
adversary cards in discard: [ 1. 15.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1] -> size -> 31 
adversary victory points: 8
player victory points: 3 





Player: 0 
cards in hand: [ 6.  0.  0. 16. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29.] 
expected returns: [[22.67821 ]
 [21.608364]
 [25.003351]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 16. 29.] 
cards in discard: [ 1. 15.  6.  3.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 24. 29.  8.  8.  8.  7.  6. 10.  8.  9.  8.  8. 10.  8.] 
adversary cards in hand: [ 0. 11.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  1  1  1 23  0 10  8  0  0  3 11 15  8  0  0  8 23] -> size -> 19 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7694335579872131
desired expected reward: 28.094255447387695



action possibilites: [-1. 16.] 
expected returns: [[26.524305]
 [25.409882]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 16.  4.] 
cards in discard: [ 1. 15.  6.  3.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 23. 30. 24. 29.  8.  8.  8.  7.  6. 10.  8.  9.  8.  8. 10.  8.] 
adversary cards in hand: [ 0. 11.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  1  1  1 23  0 10  8  0  0  3 11 15  8  0  0  8 23] -> size -> 19 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: -0.026214923709630966
desired expected reward: 24.9751033782959





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[24.885683]
 [27.277843]
 [25.739151]
 [21.455692]
 [28.785585]
 [27.932116]
 [26.393425]
 [26.729582]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0. 16.  4.] 
cards in discard: [ 1. 15.  6.  3.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 23. 30. 24. 29.  8.  8.  8.  7.  6. 10.  8.  9.  8.  8. 10.  8.] 
adversary cards in hand: [ 0. 11.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  1  1  1 23  0 10  8  0  0  3 11 15  8  0  0  8 23] -> size -> 19 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.0656203031539917
desired expected reward: 26.458683013916016



buy possibilites: [-1] 
expected returns: [[26.214489]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0. 16.  4.] 
cards in discard: [ 1. 15.  6.  3.  0. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 24. 29.  8.  8.  8.  6.  6. 10.  8.  9.  8.  8. 10.  8.] 
adversary cards in hand: [ 0. 11.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  1  1  1 23  0 10  8  0  0  3 11 15  8  0  0  8 23] -> size -> 19 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 11.0
Learning step: 0.40168458223342896
desired expected reward: 29.18726921081543






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  1.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  1  1  1 23  0 10  8  0  0  3 11 15  8  0  0  8 23] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 24. 29.  8.  8.  8.  6.  6. 10.  8.  9.  8.  8. 10.  8.] 
adversary cards in hand: [16. 11.  0.  3.  3.] 
adversary cards in discard: [ 1. 15.  6.  3.  0. 11. 29.  6.  0.  0. 16.  4.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11] -> size -> 32 
adversary victory points: 8
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.  1.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  1  1  1 23  0 10  8  0  0  3 11 15  8  0  0  8 23] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 23. 30. 24. 29.  8.  8.  8.  6.  6. 10.  8.  9.  8.  8. 10.  8.] 
adversary cards in hand: [16. 11.  0.  3.  3.] 
adversary cards in discard: [ 1. 15.  6.  3.  0. 11. 29.  6.  0.  0. 16.  4.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11] -> size -> 32 
adversary victory points: 8
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.  1.] 
cards in discard: [3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  1  1  1 23  0 10  8  0  0  3 11 15  8  0  0  8 23  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 23. 30. 23. 29.  8.  8.  8.  6.  6. 10.  8.  9.  8.  8. 10.  8.] 
adversary cards in hand: [16. 11.  0.  3.  3.] 
adversary cards in discard: [ 1. 15.  6.  3.  0. 11. 29.  6.  0.  0. 16.  4.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11] -> size -> 32 
adversary victory points: 8
player victory points: 4 





Player: 0 
cards in hand: [16. 11.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
expected returns: [[23.696852]
 [22.718687]
 [25.523489]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 11.  0.  3.  3.] 
cards in discard: [ 1. 15.  6.  3.  0. 11. 29.  6.  0.  0. 16.  4.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 23. 29.  8.  8.  8.  6.  6. 10.  8.  9.  8.  8. 10.  8.] 
adversary cards in hand: [ 1.  3.  0. 10. 23.] 
adversary cards in discard: [ 3.  0. 11.  0.  0.  1.] 
adversary owned cards: [ 3  3  1  1  1 23  0 10  8  0  0  3 11 15  8  0  0  8 23  3] -> size -> 20 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6814060211181641
desired expected reward: 25.533082962036133



action possibilites: [-1] 
expected returns: [[27.676208]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  3.  3.] 
cards in discard: [ 1. 15.  6.  3.  0. 11. 29.  6.  0.  0. 16.  4.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 23. 29.  8.  8.  8.  6.  6. 10.  8.  9.  8.  8. 10.  8.] 
adversary cards in hand: [ 1.  3.  0. 10. 23.] 
adversary cards in discard: [ 3.  0. 11.  0.  0.  1.] 
adversary owned cards: [ 3  3  1  1  1 23  0 10  8  0  0  3 11 15  8  0  0  8 23  3] -> size -> 20 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: gain_card_n - action 0
Learning step: 0.07798948138952255
desired expected reward: 22.16501235961914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[26.126383]
 [23.168558]
 [27.788237]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  3.  3.] 
cards in discard: [ 1. 15.  6.  3.  0. 11. 29.  6.  0.  0. 16.  4.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 23. 30. 23. 29.  8.  8.  8.  6.  6. 10.  8.  9.  8.  8. 10.  8.] 
adversary cards in hand: [ 1.  3.  0. 10. 23.] 
adversary cards in discard: [ 3.  0. 11.  0.  0.  1.] 
adversary owned cards: [ 3  3  1  1  1 23  0 10  8  0  0  3 11 15  8  0  0  8 23  3] -> size -> 20 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.10609805583953857
desired expected reward: 27.570110321044922






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 1.  3.  0. 10. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 23.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0. 10. 23.] 
cards in discard: [ 3.  0. 11.  0.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  1  1  1 23  0 10  8  0  0  3 11 15  8  0  0  8 23  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 23. 29.  8.  8.  8.  6.  6. 10.  8.  9.  8.  8. 10.  8.] 
adversary cards in hand: [ 0.  0. 11.  1.  0.] 
adversary cards in discard: [ 1. 15.  6.  3.  0. 11. 29.  6.  0.  0. 16.  4.  0. 11. 16.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0] -> size -> 33 
adversary victory points: 8
player victory points: 4 


action possibilites: [-1. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0. 23.  3.] 
cards in discard: [ 3.  0. 11.  0.  0.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  1  1  1 23  0 10  8  0  0  3 11 15  8  0  0  8 23  3] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 23. 29.  8.  8.  8.  6.  6. 10.  8.  9.  8.  8. 10.  8.] 
adversary cards in hand: [ 0.  0. 11.  1.  0.] 
adversary cards in discard: [ 1. 15.  6.  3.  0. 11. 29.  6.  0.  0. 16.  4.  0. 11. 16.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0] -> size -> 33 
adversary victory points: 8
player victory points: 4 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 3. 8.] 
cards in discard: [ 3.  0. 11.  0.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 23.] 
owned cards: [ 3  3  1  1  1 23  0 10  8  0  0  3 11 15  8  0  0  8 23  3] -> size -> 20 
action values: 2 
buys: 1 
player value: 1 
card supply: [19. 23. 30. 23. 29.  8.  8.  8.  6.  6. 10.  8.  9.  8.  8. 10.  8.] 
adversary cards in hand: [ 0.  0. 11.  1.  0.] 
adversary cards in discard: [ 1. 15.  6.  3.  0. 11. 29.  6.  0.  0. 16.  4.  0. 11. 16.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0] -> size -> 33 
adversary victory points: 8
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 3. 8.] 
cards in discard: [ 3.  0. 11.  0.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 23.] 
owned cards: [ 3  3  1  1  1 23  0 10  8  0  0  3 11 15  8  0  0  8 23  3] -> size -> 20 
action values: 0 
buys: 2 
player value: 4 
card supply: [19. 23. 30. 23. 29.  8.  8.  8.  6.  6. 10.  8.  9.  8.  8. 10.  8.] 
adversary cards in hand: [ 0.  0. 11.  1.  0.] 
adversary cards in discard: [ 1. 15.  6.  3.  0. 11. 29.  6.  0.  0. 16.  4.  0. 11. 16.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0] -> size -> 33 
adversary victory points: 8
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0. 11.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[22.731638]
 [24.669752]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  1.  0.] 
cards in discard: [ 1. 15.  6.  3.  0. 11. 29.  6.  0.  0. 16.  4.  0. 11. 16.  0.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 23. 29.  8.  8.  8.  6.  6. 10.  8.  9.  8.  8. 10.  8.] 
adversary cards in hand: [15. 23.  0.  1.  8.] 
adversary cards in discard: [ 3.  0. 11.  0.  0.  1. 10. 23.  1.  3.  0.  3.  8.] 
adversary owned cards: [ 3  3  1  1  1 23  0 10  8  0  0  3 11 15  8  0  0  8 23  3] -> size -> 20 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.7327547669410706
desired expected reward: 27.05548095703125



action possibilites: [-1] 
expected returns: [[24.355152]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0.] 
cards in discard: [ 1. 15.  6.  3.  0. 11. 29.  6.  0.  0. 16.  4.  0. 11. 16.  0.  3.  3.
  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 23. 29.  8.  8.  8.  6.  5. 10.  8.  9.  8.  8. 10.  8.] 
adversary cards in hand: [15. 23.  0.  1.  8.] 
adversary cards in discard: [ 3.  0. 11.  0.  0.  1. 10. 23.  1.  3.  0.  3.  8.] 
adversary owned cards: [ 3  3  1  1  1 23  0 10  8  0  0  3 11 15  8  0  0  8 23  3] -> size -> 20 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 19 

action type: gain_card_n - action 6
Learning step: 0.2872233986854553
desired expected reward: 18.394338607788086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[22.868279]
 [25.088837]
 [23.63251 ]
 [21.233267]
 [20.011032]
 [23.527042]
 [26.57076 ]
 [25.735868]
 [28.831314]
 [26.899273]
 [22.472754]
 [22.531267]
 [24.23642 ]
 [20.55087 ]
 [24.652262]
 [24.49383 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0.] 
cards in discard: [ 1. 15.  6.  3.  0. 11. 29.  6.  0.  0. 16.  4.  0. 11. 16.  0.  3.  3.
  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 5 
card supply: [19. 23. 30. 23. 29.  8.  8.  8.  6.  5. 10.  8.  9.  8.  8. 10.  8.] 
adversary cards in hand: [15. 23.  0.  1.  8.] 
adversary cards in discard: [ 3.  0. 11.  0.  0.  1. 10. 23.  1.  3.  0.  3.  8.] 
adversary owned cards: [ 3  3  1  1  1 23  0 10  8  0  0  3 11 15  8  0  0  8 23  3] -> size -> 20 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.01885763183236122
desired expected reward: 24.336294174194336



buy possibilites: [-1] 
expected returns: [[24.931541]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0.] 
cards in discard: [ 1. 15.  6.  3.  0. 11. 29.  6.  0.  0. 16.  4.  0. 11. 16.  0.  3.  3.
  8.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 23. 30. 22. 29.  8.  8.  8.  6.  5. 10.  8.  9.  8.  8. 10.  8.] 
adversary cards in hand: [15. 23.  0.  1.  8.] 
adversary cards in discard: [ 3.  0. 11.  0.  0.  1. 10. 23.  1.  3.  0.  3.  8.] 
adversary owned cards: [ 3  3  1  1  1 23  0 10  8  0  0  3 11 15  8  0  0  8 23  3] -> size -> 20 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 17.0 

action type: buy - action 3.0
Learning step: 0.06280597299337387
desired expected reward: 23.6953125






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [15. 23.  0.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 23.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 23.  0.  1.  8.] 
cards in discard: [ 3.  0. 11.  0.  0.  1. 10. 23.  1.  3.  0.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  1  1  1 23  0 10  8  0  0  3 11 15  8  0  0  8 23  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 22. 29.  8.  8.  8.  6.  5. 10.  8.  9.  8.  8. 10.  8.] 
adversary cards in hand: [ 0.  0.  3.  1. 14.] 
adversary cards in discard: [ 1. 15.  6.  3.  0. 11. 29.  6.  0.  0. 16.  4.  0. 11. 16.  0.  3.  3.
  8.  3. 11.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3] -> size -> 35 
adversary victory points: 9
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  1.  8.] 
cards in discard: [ 3.  0. 11.  0.  0.  1. 10. 23.  1.  3.  0.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  1  1  1 23 10  8  0  0  3 11 15  8  0  0  8 23  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 23. 30. 22. 29.  8.  8.  8.  6.  5. 10.  8.  9.  8.  8. 10.  8.] 
adversary cards in hand: [ 0.  0.  3.  1. 14.] 
adversary cards in discard: [ 1. 15.  6.  3.  0. 11. 29.  6.  0.  0. 16.  4.  0. 11. 16.  0.  3.  3.
  8.  3. 11.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3] -> size -> 35 
adversary victory points: 9
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  1.  8.] 
cards in discard: [ 3.  0. 11.  0.  0.  1. 10. 23.  1.  3.  0.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  1  1  1 23 10  8  0  0  3 11 15  8  0  0  8 23  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [19. 23. 30. 22. 29.  8.  8.  8.  6.  5. 10.  8.  9.  8.  8. 10.  8.] 
adversary cards in hand: [ 0.  0.  3.  1. 14.] 
adversary cards in discard: [ 1. 15.  6.  3.  0. 11. 29.  6.  0.  0. 16.  4.  0. 11. 16.  0.  3.  3.
  8.  3. 11.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3] -> size -> 35 
adversary victory points: 9
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  1.  8.] 
cards in discard: [ 3.  0. 11.  0.  0.  1. 10. 23.  1.  3.  0.  3.  8.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  1  1  1 23 10  8  0  0  3 11 15  8  0  0  8 23  3  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 23. 30. 22. 29.  8.  8.  8.  6.  4. 10.  8.  9.  8.  8. 10.  8.] 
adversary cards in hand: [ 0.  0.  3.  1. 14.] 
adversary cards in discard: [ 1. 15.  6.  3.  0. 11. 29.  6.  0.  0. 16.  4.  0. 11. 16.  0.  3.  3.
  8.  3. 11.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3] -> size -> 35 
adversary victory points: 9
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0.  3.  1. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[20.052967]
 [18.217152]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  1. 14.] 
cards in discard: [ 1. 15.  6.  3.  0. 11. 29.  6.  0.  0. 16.  4.  0. 11. 16.  0.  3.  3.
  8.  3. 11.  0.  0.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 22. 29.  8.  8.  8.  6.  4. 10.  8.  9.  8.  8. 10.  8.] 
adversary cards in hand: [11. 23.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  1  1  1 23 10  8  0  0  3 11 15  8  0  0  8 23  3  8] -> size -> 20 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6951004862785339
desired expected reward: 24.236440658569336



action possibilites: [-1] 
expected returns: [[24.166992]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 1.] 
cards in discard: [ 1. 15.  6.  3.  0. 11. 29.  6.  0.  0. 16.  4.  0. 11. 16.  0.  3.  3.
  8.  3. 11.  0.  0.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 23. 30. 22. 29.  8.  8.  8.  6.  4. 10.  8.  9.  8.  8. 10.  8.] 
adversary cards in hand: [11.  0.  8.] 
adversary cards in discard: [23.  3.] 
adversary owned cards: [ 3  3  1  1  1 23 10  8  0  0  3 11 15  8  0  0  8 23  3  8] -> size -> 20 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: 0.15723884105682373
desired expected reward: 18.3743896484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[22.980957]
 [25.069086]
 [21.709492]
 [23.712616]
 [21.398338]
 [20.219967]
 [23.611467]
 [26.399717]
 [25.646105]
 [28.4482  ]
 [26.696196]
 [22.605068]
 [22.662533]
 [24.285381]
 [20.745533]
 [24.675564]
 [24.526848]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1.] 
cards in discard: [ 1. 15.  6.  3.  0. 11. 29.  6.  0.  0. 16.  4.  0. 11. 16.  0.  3.  3.
  8.  3. 11.  0.  0.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 6 
card supply: [19. 23. 30. 22. 29.  8.  8.  8.  6.  4. 10.  8.  9.  8.  8. 10.  8.] 
adversary cards in hand: [11.  0.  8.] 
adversary cards in discard: [23.  3.] 
adversary owned cards: [ 3  3  1  1  1 23 10  8  0  0  3 11 15  8  0  0  8 23  3  8] -> size -> 20 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.014956626109778881
desired expected reward: 24.152034759521484



buy possibilites: [-1] 
expected returns: [[23.028282]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1.] 
cards in discard: [ 1. 15.  6.  3.  0. 11. 29.  6.  0.  0. 16.  4.  0. 11. 16.  0.  3.  3.
  8.  3. 11.  0.  0.  1.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 22. 30. 22. 29.  8.  8.  8.  6.  4. 10.  8.  9.  8.  8. 10.  8.] 
adversary cards in hand: [11.  0.  8.] 
adversary cards in discard: [23.  3.] 
adversary owned cards: [ 3  3  1  1  1 23 10  8  0  0  3 11 15  8  0  0  8 23  3  8] -> size -> 20 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0.  -1.   0.   0.
  4.5  0. ] 
sum of rewards: 18.5 

action type: buy - action 1.0
Learning step: 0.04472442343831062
desired expected reward: 25.113807678222656






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [11.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8.] 
cards in discard: [23.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  1  1  1 23 10  8  0  0  3 11 15  8  0  0  8 23  3  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 22. 29.  8.  8.  8.  6.  4. 10.  8.  9.  8.  8. 10.  8.] 
adversary cards in hand: [ 3. 29.  3.  3.  1.] 
adversary cards in discard: [ 1. 15.  6.  3.  0. 11. 29.  6.  0.  0. 16.  4.  0. 11. 16.  0.  3.  3.
  8.  3. 11.  0.  0.  1.  0.  1. 14.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3  1] -> size -> 36 
adversary victory points: 9
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  8.] 
cards in discard: [23.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  1  1  1 23 10  8  0  0  3 11 15  8  0  0  8 23  3  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 22. 30. 22. 29.  8.  8.  8.  6.  4. 10.  8.  9.  8.  8. 10.  8.] 
adversary cards in hand: [ 3. 29.  3.  3.  1.] 
adversary cards in discard: [ 1. 15.  6.  3.  0. 11. 29.  6.  0.  0. 16.  4.  0. 11. 16.  0.  3.  3.
  8.  3. 11.  0.  0.  1.  0.  1. 14.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3  1] -> size -> 36 
adversary victory points: 9
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  8.] 
cards in discard: [23.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  1  1  1 23 10  8  0  0  3 11 15  8  0  0  8 23  3  8  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 22. 30. 22. 29.  8.  8.  8.  6.  4. 10.  8.  9.  8.  8. 10.  8.] 
adversary cards in hand: [ 3. 29.  3.  3.  1.] 
adversary cards in discard: [ 1. 15.  6.  3.  0. 11. 29.  6.  0.  0. 16.  4.  0. 11. 16.  0.  3.  3.
  8.  3. 11.  0.  0.  1.  0.  1. 14.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3  1] -> size -> 36 
adversary victory points: 9
player victory points: 4 





Player: 0 
cards in hand: [ 3. 29.  3.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[17.450851]
 [19.41027 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3.  3.  1.] 
cards in discard: [ 1. 15.  6.  3.  0. 11. 29.  6.  0.  0. 16.  4.  0. 11. 16.  0.  3.  3.
  8.  3. 11.  0.  0.  1.  0.  1. 14.  0.  0.  3.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 22. 29.  8.  8.  8.  6.  4. 10.  8.  9.  8.  8. 10.  8.] 
adversary cards in hand: [ 8. 23. 15.  3. 10.] 
adversary cards in discard: [23.  3.  0. 11.  0.  8.] 
adversary owned cards: [ 3  3  1  1  1 23 10  8  0  0  3 11 15  8  0  0  8 23  3  8  0] -> size -> 21 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6452701687812805
desired expected reward: 22.383012771606445



action possibilites: [-1.] 
expected returns: [[26.649506]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 1. 0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 22. 30. 22. 29.  8.  8.  8.  6.  4. 10.  8.  9.  8.  8. 10.  8.] 
adversary cards in hand: [ 8. 23. 15.  3. 10.] 
adversary cards in discard: [23.  3.  0. 11.  0.  8.] 
adversary owned cards: [ 3  3  1  1  1 23 10  8  0  0  3 11 15  8  0  0  8 23  3  8  0] -> size -> 21 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0.14751170575618744
desired expected reward: 19.557783126831055





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[25.228954]
 [27.525936]
 [26.02719 ]
 [22.03081 ]
 [25.917328]
 [29.007044]
 [28.175034]
 [29.334566]
 [24.80286 ]
 [26.649952]
 [27.083664]
 [26.918156]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 1. 0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3  1] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 22. 30. 22. 29.  8.  8.  8.  6.  4. 10.  8.  9.  8.  8. 10.  8.] 
adversary cards in hand: [ 8. 23. 15.  3. 10.] 
adversary cards in discard: [23.  3.  0. 11.  0.  8.] 
adversary owned cards: [ 3  3  1  1  1 23 10  8  0  0  3 11 15  8  0  0  8 23  3  8  0] -> size -> 21 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.06479152292013168
desired expected reward: 26.584714889526367



buy possibilites: [-1] 
expected returns: [[25.303902]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 1. 0.] 
cards in discard: [6.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3  1  6] -> size -> 37 
action values: 0 
buys: 0 
player value: 4 
card supply: [18. 22. 30. 22. 29.  8.  7.  8.  6.  4. 10.  8.  9.  8.  8. 10.  8.] 
adversary cards in hand: [ 8. 23. 15.  3. 10.] 
adversary cards in discard: [23.  3.  0. 11.  0.  8.] 
adversary owned cards: [ 3  3  1  1  1 23 10  8  0  0  3 11 15  8  0  0  8 23  3  8  0] -> size -> 21 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.   -2.
    0. -300.    0.    0.] 
sum of rewards: -287.0 

action type: buy - action 6.0
Learning step: -9.005233764648438
desired expected reward: 13.025577545166016






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 8. 23. 15.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23. 15. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 23. 15.  3. 10.] 
cards in discard: [23.  3.  0. 11.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  1  1  1 23 10  8  0  0  3 11 15  8  0  0  8 23  3  8  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 22. 29.  8.  7.  8.  6.  4. 10.  8.  9.  8.  8. 10.  8.] 
adversary cards in hand: [ 3.  6.  0. 14.  0.] 
adversary cards in discard: [ 6. 29.  3.  3.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3  1  6] -> size -> 37 
adversary victory points: 8
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.] 
cards in discard: [23.  3.  0. 11.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  1  1  1 23  8  0  0  3 11  8  0  0  8 23  3  8  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 22. 29.  8.  7.  8.  6.  4. 10.  8.  9.  8.  8. 10.  8.] 
adversary cards in hand: [ 3.  6.  0. 14.  0.] 
adversary cards in discard: [ 6. 29.  3.  3.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3  1  6] -> size -> 37 
adversary victory points: 8
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.] 
cards in discard: [23.  3.  0. 11.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  1  1  1 23  8  0  0  3 11  8  0  0  8 23  3  8  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 22. 30. 22. 29.  8.  7.  8.  6.  4. 10.  8.  9.  8.  8. 10.  8.] 
adversary cards in hand: [ 3.  6.  0. 14.  0.] 
adversary cards in discard: [ 6. 29.  3.  3.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3  1  6] -> size -> 37 
adversary victory points: 8
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.] 
cards in discard: [23.  3.  0. 11.  0.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  1  1  1 23  8  0  0  3 11  8  0  0  8 23  3  8  0  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 22. 30. 22. 29.  8.  7.  8.  6.  4. 10.  8.  9.  8.  8. 10.  8.] 
adversary cards in hand: [ 3.  6.  0. 14.  0.] 
adversary cards in discard: [ 6. 29.  3.  3.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3  1  6] -> size -> 37 
adversary victory points: 8
player victory points: 3 





Player: 0 
cards in hand: [ 3.  6.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[17.46376 ]
 [15.439233]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  0. 14.  0.] 
cards in discard: [ 6. 29.  3.  3.  3.  1.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3  1  6] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 22. 30. 22. 29.  8.  7.  8.  6.  4. 10.  8.  9.  8.  8. 10.  8.] 
adversary cards in hand: [1. 1. 3. 3. 0.] 
adversary cards in discard: [23.  3.  0. 11.  0.  8.  0.  8. 23.] 
adversary owned cards: [ 3  1  1  1 23  8  0  0  3 11  8  0  0  8 23  3  8  0  0] -> size -> 19 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.734250545501709
desired expected reward: 24.569650650024414



action possibilites: [-1] 
expected returns: [[21.666409]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 0.] 
cards in discard: [ 6. 29.  3.  3.  3.  1.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3  1  6] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 22. 30. 22. 29.  8.  7.  8.  6.  4. 10.  8.  9.  8.  8. 10.  8.] 
adversary cards in hand: [1. 1. 0.] 
adversary cards in discard: [23.  3.  0. 11.  0.  8.  0.  8. 23.  3.  3.] 
adversary owned cards: [ 3  1  1  1 23  8  0  0  3 11  8  0  0  8 23  3  8  0  0] -> size -> 19 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: 0.2143203467130661
desired expected reward: 15.653553009033203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[20.094753]
 [22.439537]
 [20.913744]
 [16.797686]
 [20.799963]
 [23.91153 ]
 [23.08463 ]
 [24.236937]
 [19.661215]
 [21.558836]
 [21.998026]
 [21.830805]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0.] 
cards in discard: [ 6. 29.  3.  3.  3.  1.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3  1  6] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 22. 30. 22. 29.  8.  7.  8.  6.  4. 10.  8.  9.  8.  8. 10.  8.] 
adversary cards in hand: [1. 1. 0.] 
adversary cards in discard: [23.  3.  0. 11.  0.  8.  0.  8. 23.  3.  3.] 
adversary owned cards: [ 3  1  1  1 23  8  0  0  3 11  8  0  0  8 23  3  8  0  0] -> size -> 19 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.03103465959429741
desired expected reward: 21.69744300842285



buy possibilites: [-1] 
expected returns: [[23.751999]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0.] 
cards in discard: [ 6. 29.  3.  3.  3.  1.  0.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3  1  6  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 4 
card supply: [16. 22. 30. 22. 29.  8.  7.  8.  6.  4. 10.  8.  9.  8.  8. 10.  8.] 
adversary cards in hand: [1. 1. 0.] 
adversary cards in discard: [23.  3.  0. 11.  0.  8.  0.  8. 23.  3.  3.] 
adversary owned cards: [ 3  1  1  1 23  8  0  0  3 11  8  0  0  8 23  3  8  0  0] -> size -> 19 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0. -3.  0.  0.  0.  0.] 
sum of rewards: 12.0 

action type: buy - action 0.0
Learning step: 0.006553458981215954
desired expected reward: 20.10130500793457






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [1. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 0.] 
cards in discard: [23.  3.  0. 11.  0.  8.  0.  8. 23.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1  1  1 23  8  0  0  3 11  8  0  0  8 23  3  8  0  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 22. 30. 22. 29.  8.  7.  8.  6.  4. 10.  8.  9.  8.  8. 10.  8.] 
adversary cards in hand: [ 1. 11.  3.  8.  1.] 
adversary cards in discard: [ 6. 29.  3.  3.  3.  1.  0.  0. 14.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3  1  6  0] -> size -> 38 
adversary victory points: 8
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0.] 
cards in discard: [23.  3.  0. 11.  0.  8.  0.  8. 23.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1  1  1 23  8  0  0  3 11  8  0  0  8 23  3  8  0  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [16. 22. 30. 22. 29.  8.  7.  8.  6.  4. 10.  8.  9.  8.  8. 10.  8.] 
adversary cards in hand: [ 1. 11.  3.  8.  1.] 
adversary cards in discard: [ 6. 29.  3.  3.  3.  1.  0.  0. 14.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3  1  6  0] -> size -> 38 
adversary victory points: 8
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0.] 
cards in discard: [23.  3.  0. 11.  0.  8.  0.  8. 23.  3.  3.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1  1  1 23  8  0  0  3 11  8  0  0  8 23  3  8  0  0  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 21. 30. 22. 29.  8.  7.  8.  6.  4. 10.  8.  9.  8.  8. 10.  8.] 
adversary cards in hand: [ 1. 11.  3.  8.  1.] 
adversary cards in discard: [ 6. 29.  3.  3.  3.  1.  0.  0. 14.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3  1  6  0] -> size -> 38 
adversary victory points: 8
player victory points: 3 





Player: 0 
cards in hand: [ 1. 11.  3.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[16.232155]
 [18.007664]
 [17.301033]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  3.  8.  1.] 
cards in discard: [ 6. 29.  3.  3.  3.  1.  0.  0. 14.  3.  6.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3  1  6  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 21. 30. 22. 29.  8.  7.  8.  6.  4. 10.  8.  9.  8.  8. 10.  8.] 
adversary cards in hand: [8. 8. 0. 1. 0.] 
adversary cards in discard: [23.  3.  0. 11.  0.  8.  0.  8. 23.  3.  3.  1.  1.  1.  0.] 
adversary owned cards: [ 3  1  1  1 23  8  0  0  3 11  8  0  0  8 23  3  8  0  0  1] -> size -> 20 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6804294586181641
desired expected reward: 23.071569442749023



action possibilites: [-1] 
expected returns: [[20.983664]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 8. 1.] 
cards in discard: [ 6. 29.  3.  3.  3.  1.  0.  0. 14.  3.  6.  0.  0. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3  1  6  0 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 21. 30. 22. 29.  8.  7.  8.  6.  4. 10.  8.  9.  8.  8. 10.  7.] 
adversary cards in hand: [8. 8. 0. 1. 0.] 
adversary cards in discard: [23.  3.  0. 11.  0.  8.  0.  8. 23.  3.  3.  1.  1.  1.  0.] 
adversary owned cards: [ 3  1  1  1 23  8  0  0  3 11  8  0  0  8 23  3  8  0  0  1] -> size -> 20 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -4  0  0 16  0] 
sum of rewards: 27 

action type: gain_card_n - action 10
Learning step: 0.5538355112075806
desired expected reward: 16.436935424804688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[19.669287]
 [21.70931 ]
 [20.375422]
 [16.771017]
 [20.280888]
 [22.980692]
 [22.270582]
 [23.260006]
 [19.273785]
 [20.936697]
 [21.310545]
 [21.128185]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 8. 1.] 
cards in discard: [ 6. 29.  3.  3.  3.  1.  0.  0. 14.  3.  6.  0.  0. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3  1  6  0 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 21. 30. 22. 29.  8.  7.  8.  6.  4. 10.  8.  9.  8.  8. 10.  7.] 
adversary cards in hand: [8. 8. 0. 1. 0.] 
adversary cards in discard: [23.  3.  0. 11.  0.  8.  0.  8. 23.  3.  3.  1.  1.  1.  0.] 
adversary owned cards: [ 3  1  1  1 23  8  0  0  3 11  8  0  0  8 23  3  8  0  0  1] -> size -> 20 
adversary victory points: 3
player victory points: 8 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.04431261122226715
desired expected reward: 21.027976989746094



buy possibilites: [-1] 
expected returns: [[24.025644]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 8. 1.] 
cards in discard: [ 6. 29.  3.  3.  3.  1.  0.  0. 14.  3.  6.  0.  0. 15.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3  1  6  0 15  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 21. 30. 21. 29.  8.  7.  8.  6.  4. 10.  8.  9.  8.  8. 10.  7.] 
adversary cards in hand: [8. 8. 0. 1. 0.] 
adversary cards in discard: [23.  3.  0. 11.  0.  8.  0.  8. 23.  3.  3.  1.  1.  1.  0.] 
adversary owned cards: [ 3  1  1  1 23  8  0  0  3 11  8  0  0  8 23  3  8  0  0  1] -> size -> 20 
adversary victory points: 3
player victory points: 9 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0. -5.  0.  0.  2.  0.] 
sum of rewards: 12.0 

action type: buy - action 3.0
Learning step: 0.0010067367693409324
desired expected reward: 20.37642478942871






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [8. 8. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 1. 0.] 
cards in discard: [23.  3.  0. 11.  0.  8.  0.  8. 23.  3.  3.  1.  1.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1  1  1 23  8  0  0  3 11  8  0  0  8 23  3  8  0  0  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 21. 30. 21. 29.  8.  7.  8.  6.  4. 10.  8.  9.  8.  8. 10.  7.] 
adversary cards in hand: [11.  4. 11.  0.  0.] 
adversary cards in discard: [ 6. 29.  3.  3.  3.  1.  0.  0. 14.  3.  6.  0.  0. 15.  3. 11.  1.  3.
  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3  1  6  0 15  3] -> size -> 40 
adversary victory points: 9
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0. 1. 0.] 
cards in discard: [23.  3.  0. 11.  0.  8.  0.  8. 23.  3.  3.  1.  1.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1  1  1 23  8  0  0  3 11  8  0  0  8 23  3  8  0  0  1] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 21. 30. 21. 29.  8.  7.  8.  6.  4. 10.  8.  9.  8.  8. 10.  7.] 
adversary cards in hand: [11.  4. 11.  0.  0.] 
adversary cards in discard: [ 6. 29.  3.  3.  3.  1.  0.  0. 14.  3.  6.  0.  0. 15.  3. 11.  1.  3.
  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3  1  6  0 15  3] -> size -> 40 
adversary victory points: 9
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0. 1. 0.] 
cards in discard: [23.  3.  0. 11.  0.  8.  0.  8. 23.  3.  3.  1.  1.  1.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1  1  1 23  8  0  0  3 11  8  0  0  8 23  3  8  0  0  1 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 21. 30. 21. 29.  8.  7.  8.  6.  4. 10.  8.  9.  8.  7. 10.  7.] 
adversary cards in hand: [11.  4. 11.  0.  0.] 
adversary cards in discard: [ 6. 29.  3.  3.  3.  1.  0.  0. 14.  3.  6.  0.  0. 15.  3. 11.  1.  3.
  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3  1  6  0 15  3] -> size -> 40 
adversary victory points: 9
player victory points: 3 





Player: 0 
cards in hand: [11.  4. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[16.110163]
 [17.99007 ]
 [17.99007 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  4. 11.  0.  0.] 
cards in discard: [ 6. 29.  3.  3.  3.  1.  0.  0. 14.  3.  6.  0.  0. 15.  3. 11.  1.  3.
  8.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3  1  6  0 15  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 21. 30. 21. 29.  8.  7.  8.  6.  4. 10.  8.  9.  8.  7. 10.  7.] 
adversary cards in hand: [ 0.  3. 23.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  1  1  1 23  8  0  0  3 11  8  0  0  8 23  3  8  0  0  1 10] -> size -> 21 
adversary victory points: 3
player victory points: 9 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6871373057365417
desired expected reward: 23.3385066986084





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[14.877396]
 [15.567556]
 [12.150573]
 [17.461771]
 [16.312946]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  4. 11.  0.  0.] 
cards in discard: [ 6. 29.  3.  3.  3.  1.  0.  0. 14.  3.  6.  0.  0. 15.  3. 11.  1.  3.
  8.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3  1  6  0 15  3] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 21. 30. 21. 29.  8.  7.  8.  6.  4. 10.  8.  9.  8.  7. 10.  7.] 
adversary cards in hand: [ 0.  3. 23.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  1  1  1 23  8  0  0  3 11  8  0  0  8 23  3  8  0  0  1 10] -> size -> 21 
adversary victory points: 3
player victory points: 9 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.46833309531211853
desired expected reward: 15.641827583312988



buy possibilites: [-1] 
expected returns: [[17.251122]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  4. 11.  0.  0.] 
cards in discard: [ 6. 29.  3.  3.  3.  1.  0.  0. 14.  3.  6.  0.  0. 15.  3. 11.  1.  3.
  8.  1.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 21. 30. 21. 29.  8.  7.  8.  6.  3. 10.  8.  9.  8.  7. 10.  7.] 
adversary cards in hand: [ 0.  3. 23.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  1  1  1 23  8  0  0  3 11  8  0  0  8 23  3  8  0  0  1 10] -> size -> 21 
adversary victory points: 3
player victory points: 9 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0 -6  0  0  8  0] 
sum of rewards: -3 

action type: buy - action 8.0
Learning step: -0.4327162802219391
desired expected reward: 17.029052734375






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 23.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 23.  0.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1  1  1 23  8  0  0  3 11  8  0  0  8 23  3  8  0  0  1 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 21. 30. 21. 29.  8.  7.  8.  6.  3. 10.  8.  9.  8.  7. 10.  7.] 
adversary cards in hand: [1. 1. 3. 3. 0.] 
adversary cards in discard: [ 6. 29.  3.  3.  3.  1.  0.  0. 14.  3.  6.  0.  0. 15.  3. 11.  1.  3.
  8.  1.  8. 11.  4. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8] -> size -> 41 
adversary victory points: 9
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 23.  0.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1  1  1 23  8  0  0  3 11  8  0  0  8 23  3  8  0  0  1 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 21. 30. 21. 29.  8.  7.  8.  6.  3. 10.  8.  9.  8.  7. 10.  7.] 
adversary cards in hand: [1. 1. 3. 3. 0.] 
adversary cards in discard: [ 6. 29.  3.  3.  3.  1.  0.  0. 14.  3.  6.  0.  0. 15.  3. 11.  1.  3.
  8.  1.  8. 11.  4. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8] -> size -> 41 
adversary victory points: 9
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 23.  0.  0.] 
cards in discard: [3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1  1  1 23  8  0  0  3 11  8  0  0  8 23  3  8  0  0  1 10  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 21. 30. 20. 29.  8.  7.  8.  6.  3. 10.  8.  9.  8.  7. 10.  7.] 
adversary cards in hand: [1. 1. 3. 3. 0.] 
adversary cards in discard: [ 6. 29.  3.  3.  3.  1.  0.  0. 14.  3.  6.  0.  0. 15.  3. 11.  1.  3.
  8.  1.  8. 11.  4. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8] -> size -> 41 
adversary victory points: 9
player victory points: 4 





Player: 0 
cards in hand: [1. 1. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[16.48922]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 3. 3. 0.] 
cards in discard: [ 6. 29.  3.  3.  3.  1.  0.  0. 14.  3.  6.  0.  0. 15.  3. 11.  1.  3.
  8.  1.  8. 11.  4. 11.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 21. 30. 20. 29.  8.  7.  8.  6.  3. 10.  8.  9.  8.  7. 10.  7.] 
adversary cards in hand: [0. 1. 8. 8. 8.] 
adversary cards in discard: [ 3.  0.  3. 23.  0.  0.] 
adversary owned cards: [ 3  1  1  1 23  8  0  0  3 11  8  0  0  8 23  3  8  0  0  1 10  3] -> size -> 22 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.494396835565567
desired expected reward: 16.756725311279297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[15.134178]
 [17.028845]
 [15.784088]
 [13.605699]
 [12.441584]
 [15.697355]
 [18.222605]
 [17.554255]
 [20.148853]
 [18.49226 ]
 [14.769251]
 [14.818783]
 [16.305462]
 [12.947853]
 [16.65558 ]
 [16.484713]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 3. 3. 0.] 
cards in discard: [ 6. 29.  3.  3.  3.  1.  0.  0. 14.  3.  6.  0.  0. 15.  3. 11.  1.  3.
  8.  1.  8. 11.  4. 11.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8] -> size -> 41 
action values: 0 
buys: 1 
player value: 5 
card supply: [16. 21. 30. 20. 29.  8.  7.  8.  6.  3. 10.  8.  9.  8.  7. 10.  7.] 
adversary cards in hand: [0. 1. 8. 8. 8.] 
adversary cards in discard: [ 3.  0.  3. 23.  0.  0.] 
adversary owned cards: [ 3  1  1  1 23  8  0  0  3 11  8  0  0  8 23  3  8  0  0  1 10  3] -> size -> 22 
adversary victory points: 4
player victory points: 9 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.46791601181030273
desired expected reward: 16.021303176879883



buy possibilites: [-1] 
expected returns: [[13.805806]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 3. 3. 0.] 
cards in discard: [ 6. 29.  3.  3.  3.  1.  0.  0. 14.  3.  6.  0.  0. 15.  3. 11.  1.  3.
  8.  1.  8. 11.  4. 11.  0.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6] -> size -> 42 
action values: 0 
buys: 0 
player value: 5 
card supply: [16. 21. 30. 20. 29.  8.  6.  8.  6.  3. 10.  8.  9.  8.  7. 10.  7.] 
adversary cards in hand: [0. 1. 8. 8. 8.] 
adversary cards in discard: [ 3.  0.  3. 23.  0.  0.] 
adversary owned cards: [ 3  1  1  1 23  8  0  0  3 11  8  0  0  8 23  3  8  0  0  1 10  3] -> size -> 22 
adversary victory points: 4
player victory points: 8 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   -7.
    0. -300.    0.    0.] 
sum of rewards: -312.0 

action type: buy - action 6.0
Learning step: -9.588286399841309
desired expected reward: 2.853297233581543






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [0. 1. 8. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 8. 8. 8.] 
cards in discard: [ 3.  0.  3. 23.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1  1  1 23  8  0  0  3 11  8  0  0  8 23  3  8  0  0  1 10  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 21. 30. 20. 29.  8.  6.  8.  6.  3. 10.  8.  9.  8.  7. 10.  7.] 
adversary cards in hand: [29.  0. 16. 16.  0.] 
adversary cards in discard: [ 6. 29.  3.  3.  3.  1.  0.  0. 14.  3.  6.  0.  0. 15.  3. 11.  1.  3.
  8.  1.  8. 11.  4. 11.  0.  0.  6.  1.  1.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6] -> size -> 42 
adversary victory points: 8
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [ 3.  0.  3. 23.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  1  1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 21. 30. 20. 29.  8.  6.  8.  6.  3. 10.  8.  9.  8.  7. 10.  7.] 
adversary cards in hand: [29.  0. 16. 16.  0.] 
adversary cards in discard: [ 6. 29.  3.  3.  3.  1.  0.  0. 14.  3.  6.  0.  0. 15.  3. 11.  1.  3.
  8.  1.  8. 11.  4. 11.  0.  0.  6.  1.  1.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6] -> size -> 42 
adversary victory points: 8
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 3.  0.  3. 23.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  1  1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 21. 30. 20. 29.  8.  6.  8.  6.  3. 10.  8.  9.  8.  7. 10.  7.] 
adversary cards in hand: [29.  0. 16. 16.  0.] 
adversary cards in discard: [ 6. 29.  3.  3.  3.  1.  0.  0. 14.  3.  6.  0.  0. 15.  3. 11.  1.  3.
  8.  1.  8. 11.  4. 11.  0.  0.  6.  1.  1.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6] -> size -> 42 
adversary victory points: 8
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 3.  0.  3. 23.  0.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  1  1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 21. 30. 19. 29.  8.  6.  8.  6.  3. 10.  8.  9.  8.  7. 10.  7.] 
adversary cards in hand: [29.  0. 16. 16.  0.] 
adversary cards in discard: [ 6. 29.  3.  3.  3.  1.  0.  0. 14.  3.  6.  0.  0. 15.  3. 11.  1.  3.
  8.  1.  8. 11.  4. 11.  0.  0.  6.  1.  1.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6] -> size -> 42 
adversary victory points: 8
player victory points: 5 





Player: 0 
cards in hand: [29.  0. 16. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 16. 16.] 
expected returns: [[10.766342]
 [12.530589]
 [10.129462]
 [10.129462]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 16. 16.  0.] 
cards in discard: [ 6. 29.  3.  3.  3.  1.  0.  0. 14.  3.  6.  0.  0. 15.  3. 11.  1.  3.
  8.  1.  8. 11.  4. 11.  0.  0.  6.  1.  1.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 21. 30. 19. 29.  8.  6.  8.  6.  3. 10.  8.  9.  8.  7. 10.  7.] 
adversary cards in hand: [1. 0. 0. 8. 3.] 
adversary cards in discard: [ 3.  0.  3. 23.  0.  0.  3.  8.  1.] 
adversary owned cards: [ 3  1  1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3] -> size -> 20 
adversary victory points: 5
player victory points: 8 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.44639265537261963
desired expected reward: 13.359413146972656



action possibilites: [-1. 16. 16.] 
expected returns: [[12.25887 ]
 [11.548449]
 [11.548449]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 16.  0.  6.] 
cards in discard: [ 6. 29.  3.  3.  3.  1.  0.  0. 14.  3.  6.  0.  0. 15.  3. 11.  1.  3.
  8.  1.  8. 11.  4. 11.  0.  0.  6.  1.  1.  3.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14  6 29  3  0  1  3
  6  0 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6] -> size -> 42 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 21. 30. 19. 29.  8.  6.  8.  6.  3. 10.  8.  9.  8.  7. 10.  7.] 
adversary cards in hand: [1. 0. 0. 8. 3.] 
adversary cards in discard: [ 3.  0.  3. 23.  0.  0.  3.  8.  1.] 
adversary owned cards: [ 3  1  1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3] -> size -> 20 
adversary victory points: 5
player victory points: 8 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0.19882212579250336
desired expected reward: 12.729411125183105



action possibilites: [-1] 
expected returns: [[12.1143]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.] 
cards in discard: [ 6. 29.  3.  3.  3.  1.  0.  0. 14.  3.  6.  0.  0. 15.  3. 11.  1.  3.
  8.  1.  8. 11.  4. 11.  0.  0.  6.  1.  1.  3.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6
  0 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 21. 30. 19. 29.  8.  6.  8.  6.  3. 10.  8.  9.  8.  7. 10.  7.] 
adversary cards in hand: [1. 0. 0. 8. 3.] 
adversary cards in discard: [ 3.  0.  3. 23.  0.  0.  3.  8.  1.] 
adversary owned cards: [ 3  1  1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3] -> size -> 20 
adversary victory points: 5
player victory points: 9 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0 -7  0  0  0  0] 
sum of rewards: 28 

action type: gain_card_n - action 0
Learning step: 0.5097357630729675
desired expected reward: 15.758549690246582





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[10.845444]
 [12.622334]
 [11.458163]
 [ 8.399138]
 [13.734705]
 [13.113403]
 [11.946963]
 [12.114302]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.] 
cards in discard: [ 6. 29.  3.  3.  3.  1.  0.  0. 14.  3.  6.  0.  0. 15.  3. 11.  1.  3.
  8.  1.  8. 11.  4. 11.  0.  0.  6.  1.  1.  3.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6
  0 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 21. 30. 19. 29.  8.  6.  8.  6.  3. 10.  8.  9.  8.  7. 10.  7.] 
adversary cards in hand: [1. 0. 0. 8. 3.] 
adversary cards in discard: [ 3.  0.  3. 23.  0.  0.  3.  8.  1.] 
adversary owned cards: [ 3  1  1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3] -> size -> 20 
adversary victory points: 5
player victory points: 9 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.8143600821495056
desired expected reward: 12.928659439086914



buy possibilites: [-1] 
expected returns: [[11.576337]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.] 
cards in discard: [ 6. 29.  3.  3.  3.  1.  0.  0. 14.  3.  6.  0.  0. 15.  3. 11.  1.  3.
  8.  1.  8. 11.  4. 11.  0.  0.  6.  1.  1.  3.  3.  0.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6
  0 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 19. 29.  8.  6.  8.  5.  3. 10.  8.  9.  8.  7. 10.  7.] 
adversary cards in hand: [1. 0. 0. 8. 3.] 
adversary cards in discard: [ 3.  0.  3. 23.  0.  0.  3.  8.  1.] 
adversary owned cards: [ 3  1  1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3] -> size -> 20 
adversary victory points: 5
player victory points: 9 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0 -8  0  0 18  0] 
sum of rewards: 45 

action type: buy - action 11.0
Learning step: 1.0582016706466675
desired expected reward: 14.792906761169434






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [1. 0. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 8. 3.] 
cards in discard: [ 3.  0.  3. 23.  0.  0.  3.  8.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1  1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 19. 29.  8.  6.  8.  5.  3. 10.  8.  9.  8.  7. 10.  7.] 
adversary cards in hand: [ 0.  0.  3. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6
  0 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11] -> size -> 43 
adversary victory points: 9
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 8. 3.] 
cards in discard: [ 3.  0.  3. 23.  0.  0.  3.  8.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1  1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 21. 30. 19. 29.  8.  6.  8.  5.  3. 10.  8.  9.  8.  7. 10.  7.] 
adversary cards in hand: [ 0.  0.  3. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6
  0 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11] -> size -> 43 
adversary victory points: 9
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 8. 3.] 
cards in discard: [ 3.  0.  3. 23.  0.  0.  3.  8.  1.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1  1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 21. 30. 18. 29.  8.  6.  8.  5.  3. 10.  8.  9.  8.  7. 10.  7.] 
adversary cards in hand: [ 0.  0.  3. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6
  0 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11] -> size -> 43 
adversary victory points: 9
player victory points: 6 





Player: 0 
cards in hand: [ 0.  0.  3. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[20.444132]
 [20.649942]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 15.  0.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6
  0 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 18. 29.  8.  6.  8.  5.  3. 10.  8.  9.  8.  7. 10.  7.] 
adversary cards in hand: [11.  1.  1.  3. 23.] 
adversary cards in discard: [ 3.  0.  3. 23.  0.  0.  3.  8.  1.  3.  1.  0.  0.  8.  3.] 
adversary owned cards: [ 3  1  1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3] -> size -> 21 
adversary victory points: 6
player victory points: 9 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.2813301086425781
desired expected reward: 11.29500675201416



action possibilites: [-1] 
expected returns: [[17.502346]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11] -> size -> 42 
action values: 0 
buys: 0 
player value: 3 
card supply: [15. 21. 30. 18. 29.  8.  6.  8.  5.  3. 10.  8.  9.  8.  7. 10.  7.] 
adversary cards in hand: [11.  1.  1.  3. 23.] 
adversary cards in discard: [ 3.  0.  3. 23.  0.  0.  3.  8.  1.  3.  1.  0.  0.  8.  3.] 
adversary owned cards: [ 3  1  1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3] -> size -> 21 
adversary victory points: 6
player victory points: 9 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: 0.014276332221925259
desired expected reward: 20.66421890258789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[16.355213]
 [18.345654]
 [17.037928]
 [14.755325]
 [13.566462]
 [16.946054]
 [19.600714]
 [18.893751]
 [21.56633 ]
 [19.876175]
 [15.958504]
 [16.00676 ]
 [17.585333]
 [14.068161]
 [17.944958]
 [17.731083]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11] -> size -> 42 
action values: 0 
buys: 1 
player value: 5 
card supply: [15. 21. 30. 18. 29.  8.  6.  8.  5.  3. 10.  8.  9.  8.  7. 10.  7.] 
adversary cards in hand: [11.  1.  1.  3. 23.] 
adversary cards in discard: [ 3.  0.  3. 23.  0.  0.  3.  8.  1.  3.  1.  0.  0.  8.  3.] 
adversary owned cards: [ 3  1  1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3] -> size -> 21 
adversary victory points: 6
player victory points: 9 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.115244060754776
desired expected reward: 17.617589950561523



buy possibilites: [-1] 
expected returns: [[18.26444]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [29.] 
cards in deck: 38 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 21. 30. 18. 29.  8.  6.  8.  5.  3. 10.  7.  9.  8.  7. 10.  7.] 
adversary cards in hand: [11.  1.  1.  3. 23.] 
adversary cards in discard: [ 3.  0.  3. 23.  0.  0.  3.  8.  1.  3.  1.  0.  0.  8.  3.] 
adversary owned cards: [ 3  1  1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3] -> size -> 21 
adversary victory points: 6
player victory points: 9 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0. -8.  0.  0.  8.  0.] 
sum of rewards: 15.0 

action type: buy - action 29.0
Learning step: 0.04549146443605423
desired expected reward: 19.92166519165039






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [11.  1.  1.  3. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  1.  3. 23.] 
cards in discard: [ 3.  0.  3. 23.  0.  0.  3.  8.  1.  3.  1.  0.  0.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1  1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 18. 29.  8.  6.  8.  5.  3. 10.  7.  9.  8.  7. 10.  7.] 
adversary cards in hand: [ 6. 11.  8. 11.  0.] 
adversary cards in discard: [29. 15.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29] -> size -> 43 
adversary victory points: 9
player victory points: 6 


action possibilites: [-1. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  1.  3. 10.] 
cards in discard: [ 3.  0.  3. 23.  0.  0.  3.  8.  1.  3.  1.  0.  0.  8.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 3  1  1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3] -> size -> 21 
action values: 1 
buys: 1 
player value: 1 
card supply: [15. 21. 30. 18. 29.  8.  6.  8.  5.  3. 10.  7.  9.  8.  7. 10.  7.] 
adversary cards in hand: [ 6. 11.  8. 11.  0.] 
adversary cards in discard: [29. 15.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29] -> size -> 43 
adversary victory points: 9
player victory points: 6 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  1.  3.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [23. 10.] 
owned cards: [ 3  1  1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3] -> size -> 21 
action values: 2 
buys: 1 
player value: 1 
card supply: [15. 21. 30. 18. 29.  8.  6.  8.  5.  3. 10.  7.  9.  8.  7. 10.  7.] 
adversary cards in hand: [ 6. 11.  8. 11.  0.] 
adversary cards in discard: [29. 15.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29] -> size -> 43 
adversary victory points: 9
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  1.  3.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [23. 10.] 
owned cards: [ 3  1  1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3] -> size -> 21 
action values: 0 
buys: 2 
player value: 5 
card supply: [15. 21. 30. 18. 29.  8.  6.  8.  5.  3. 10.  7.  9.  8.  7. 10.  7.] 
adversary cards in hand: [ 6. 11.  8. 11.  0.] 
adversary cards in discard: [29. 15.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29] -> size -> 43 
adversary victory points: 9
player victory points: 6 


buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  1.  3.  3.] 
cards in discard: [10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [23. 10.] 
owned cards: [ 3  1  1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 21. 30. 18. 29.  8.  6.  8.  5.  3. 10.  7.  9.  8.  6. 10.  7.] 
adversary cards in hand: [ 6. 11.  8. 11.  0.] 
adversary cards in discard: [29. 15.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29] -> size -> 43 
adversary victory points: 9
player victory points: 6 





Player: 0 
cards in hand: [ 6. 11.  8. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 11.] 
expected returns: [[20.88236 ]
 [22.762547]
 [22.040977]
 [22.762547]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  8. 11.  0.] 
cards in discard: [29. 15.  0.  3.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 18. 29.  8.  6.  8.  5.  3. 10.  7.  9.  8.  6. 10.  7.] 
adversary cards in hand: [ 1.  3.  8. 23.  3.] 
adversary cards in discard: [10. 23. 10. 11.  1.  1.  3.  3.] 
adversary owned cards: [ 3  1  1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10] -> size -> 22 
adversary victory points: 6
player victory points: 9 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4643901586532593
desired expected reward: 17.800050735473633





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[19.380886]
 [16.796953]
 [20.70345 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  8. 11.  0.] 
cards in discard: [29. 15.  0.  3.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 21. 30. 18. 29.  8.  6.  8.  5.  3. 10.  7.  9.  8.  6. 10.  7.] 
adversary cards in hand: [ 1.  3.  8. 23.  3.] 
adversary cards in discard: [10. 23. 10. 11.  1.  1.  3.  3.] 
adversary owned cards: [ 3  1  1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10] -> size -> 22 
adversary victory points: 6
player victory points: 9 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5737259387969971
desired expected reward: 20.30863380432129



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 1.  3.  8. 23.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  8. 23.  3.] 
cards in discard: [10. 23. 10. 11.  1.  1.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  1  1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 18. 29.  8.  6.  8.  5.  3. 10.  7.  9.  8.  6. 10.  7.] 
adversary cards in hand: [16.  0.  0.  3.  3.] 
adversary cards in discard: [29. 15.  0.  3.  0.  6. 11.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29] -> size -> 43 
adversary victory points: 9
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  3.] 
cards in discard: [10. 23. 10. 11.  1.  1.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 18. 29.  8.  6.  8.  5.  3. 10.  7.  9.  8.  6. 10.  7.] 
adversary cards in hand: [16.  0.  0.  3.  3.] 
adversary cards in discard: [29. 15.  0.  3.  0.  6. 11.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29] -> size -> 43 
adversary victory points: 9
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  3.] 
cards in discard: [10. 23. 10. 11.  1.  1.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 21. 30. 18. 29.  8.  6.  8.  5.  3. 10.  7.  9.  8.  6. 10.  7.] 
adversary cards in hand: [16.  0.  0.  3.  3.] 
adversary cards in discard: [29. 15.  0.  3.  0.  6. 11.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29] -> size -> 43 
adversary victory points: 9
player victory points: 5 





Player: 0 
cards in hand: [16.  0.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[21.74372]
 [20.96478]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.  3.  3.] 
cards in discard: [29. 15.  0.  3.  0.  6. 11.  8. 11.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 18. 29.  8.  6.  8.  5.  3. 10.  7.  9.  8.  6. 10.  7.] 
adversary cards in hand: [3. 0. 1. 0. 0.] 
adversary cards in discard: [10. 23. 10. 11.  1.  1.  3.  3.  8. 23.  3.] 
adversary owned cards: [ 1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10] -> size -> 20 
adversary victory points: 5
player victory points: 9 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5460659265518188
desired expected reward: 20.15738296508789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[20.511404]
 [21.194304]
 [17.700554]
 [23.065052]
 [21.88138 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.  3.  3.] 
cards in discard: [29. 15.  0.  3.  0.  6. 11.  8. 11.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 21. 30. 18. 29.  8.  6.  8.  5.  3. 10.  7.  9.  8.  6. 10.  7.] 
adversary cards in hand: [3. 0. 1. 0. 0.] 
adversary cards in discard: [10. 23. 10. 11.  1.  1.  3.  3.  8. 23.  3.] 
adversary owned cards: [ 1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10] -> size -> 20 
adversary victory points: 5
player victory points: 9 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5785624384880066
desired expected reward: 21.165157318115234



buy possibilites: [-1] 
expected returns: [[17.611269]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.  3.  3.] 
cards in discard: [29. 15.  0.  3.  0.  6. 11.  8. 11.  0.  6.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6] -> size -> 44 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 21. 30. 18. 29.  8.  5.  8.  5.  3. 10.  7.  9.  8.  6. 10.  7.] 
adversary cards in hand: [3. 0. 1. 0. 0.] 
adversary cards in discard: [10. 23. 10. 11.  1.  1.  3.  3.  8. 23.  3.] 
adversary owned cards: [ 1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10] -> size -> 20 
adversary victory points: 5
player victory points: 8 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   -9.
    0. -300.    0.    0.] 
sum of rewards: -314.0 

action type: buy - action 6.0
Learning step: -9.766098022460938
desired expected reward: 7.934453964233398






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [3. 0. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 0. 0.] 
cards in discard: [10. 23. 10. 11.  1.  1.  3.  3.  8. 23.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 18. 29.  8.  5.  8.  5.  3. 10.  7.  9.  8.  6. 10.  7.] 
adversary cards in hand: [ 0.  4.  3.  0. 29.] 
adversary cards in discard: [29. 15.  0.  3.  0.  6. 11.  8. 11.  0.  6. 16.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6] -> size -> 44 
adversary victory points: 8
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 0.] 
cards in discard: [10. 23. 10. 11.  1.  1.  3.  3.  8. 23.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [15. 21. 30. 18. 29.  8.  5.  8.  5.  3. 10.  7.  9.  8.  6. 10.  7.] 
adversary cards in hand: [ 0.  4.  3.  0. 29.] 
adversary cards in discard: [29. 15.  0.  3.  0.  6. 11.  8. 11.  0.  6. 16.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6] -> size -> 44 
adversary victory points: 8
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 0.] 
cards in discard: [10. 23. 10. 11.  1.  1.  3.  3.  8. 23.  3. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 21. 30. 18. 29.  8.  5.  8.  5.  3. 10.  7.  8.  8.  6. 10.  7.] 
adversary cards in hand: [ 0.  4.  3.  0. 29.] 
adversary cards in discard: [29. 15.  0.  3.  0.  6. 11.  8. 11.  0.  6. 16.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6] -> size -> 44 
adversary victory points: 8
player victory points: 5 





Player: 0 
cards in hand: [ 0.  4.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[15.189124]
 [16.82926 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  4.  3.  0. 29.] 
cards in discard: [29. 15.  0.  3.  0.  6. 11.  8. 11.  0.  6. 16.  0.  0.  3.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 18. 29.  8.  5.  8.  5.  3. 10.  7.  8.  8.  6. 10.  7.] 
adversary cards in hand: [10.  3.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14] -> size -> 21 
adversary victory points: 5
player victory points: 8 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5085194110870361
desired expected reward: 17.10274887084961





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[14.302113]
 [14.806063]
 [12.215344]
 [16.235367]
 [15.338269]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  4.  3.  0. 29.] 
cards in discard: [29. 15.  0.  3.  0.  6. 11.  8. 11.  0.  6. 16.  0.  0.  3.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 21. 30. 18. 29.  8.  5.  8.  5.  3. 10.  7.  8.  8.  6. 10.  7.] 
adversary cards in hand: [10.  3.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14] -> size -> 21 
adversary victory points: 5
player victory points: 8 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.44911226630210876
desired expected reward: 14.74001407623291



buy possibilites: [-1] 
expected returns: [[14.418744]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  4.  3.  0. 29.] 
cards in discard: [29. 15.  0.  3.  0.  6. 11.  8. 11.  0.  6. 16.  0.  0.  3.  3.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 21. 30. 18. 29.  8.  5.  8.  5.  3. 10.  7.  8.  8.  6. 10.  7.] 
adversary cards in hand: [10.  3.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14] -> size -> 21 
adversary victory points: 5
player victory points: 8 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. -10.   0.   0.
   0.   0.] 
sum of rewards: -15.0 

action type: buy - action 0.0
Learning step: -0.7276664972305298
desired expected reward: 13.574444770812988






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [10.  3.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 21. 30. 18. 29.  8.  5.  8.  5.  3. 10.  7.  8.  8.  6. 10.  7.] 
adversary cards in hand: [11.  1.  3.  0.  6.] 
adversary cards in discard: [29. 15.  0.  3.  0.  6. 11.  8. 11.  0.  6. 16.  0.  0.  3.  3.  0.  0.
  4.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0] -> size -> 45 
adversary victory points: 8
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 21. 30. 18. 29.  8.  5.  8.  5.  3. 10.  7.  8.  8.  6. 10.  7.] 
adversary cards in hand: [11.  1.  3.  0.  6.] 
adversary cards in discard: [29. 15.  0.  3.  0.  6. 11.  8. 11.  0.  6. 16.  0.  0.  3.  3.  0.  0.
  4.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0] -> size -> 45 
adversary victory points: 8
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.  8.] 
cards in discard: [0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 21. 30. 18. 29.  8.  5.  8.  5.  3. 10.  7.  8.  8.  6. 10.  7.] 
adversary cards in hand: [11.  1.  3.  0.  6.] 
adversary cards in discard: [29. 15.  0.  3.  0.  6. 11.  8. 11.  0.  6. 16.  0.  0.  3.  3.  0.  0.
  4.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0] -> size -> 45 
adversary victory points: 8
player victory points: 5 





Player: 0 
cards in hand: [11.  1.  3.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[14.381007]
 [16.042212]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  3.  0.  6.] 
cards in discard: [29. 15.  0.  3.  0.  6. 11.  8. 11.  0.  6. 16.  0.  0.  3.  3.  0.  0.
  4.  3.  0. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 21. 30. 18. 29.  8.  5.  8.  5.  3. 10.  7.  8.  8.  6. 10.  7.] 
adversary cards in hand: [ 1. 23.  3. 11.  1.] 
adversary cards in discard: [ 0. 10.  3.  0.  0.  8.] 
adversary owned cards: [ 1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0] -> size -> 22 
adversary victory points: 5
player victory points: 8 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.42109617590904236
desired expected reward: 13.997648239135742



action possibilites: [-1] 
expected returns: [[12.943045]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 6.] 
cards in discard: [29. 15.  0.  3.  0.  6. 11.  8. 11.  0.  6. 16.  0.  0.  3.  3.  0.  0.
  4.  3.  0. 29. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 21. 30. 18. 29.  8.  5.  8.  5.  3. 10.  7.  8.  8.  5. 10.  7.] 
adversary cards in hand: [ 1. 23.  3. 11.  1.] 
adversary cards in discard: [ 0. 10.  3.  0.  0.  8.] 
adversary owned cards: [ 1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0] -> size -> 22 
adversary victory points: 5
player victory points: 8 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -11   0   0   9   0] 
sum of rewards: 13 

action type: gain_card_n - action 9
Learning step: 0.008481788448989391
desired expected reward: 17.255821228027344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[11.788105]
 [13.493318]
 [12.347535]
 [ 9.515796]
 [14.643947]
 [13.999764]
 [12.813213]
 [12.943045]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 6.] 
cards in discard: [29. 15.  0.  3.  0.  6. 11.  8. 11.  0.  6. 16.  0.  0.  3.  3.  0.  0.
  4.  3.  0. 29. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10] -> size -> 46 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 21. 30. 18. 29.  8.  5.  8.  5.  3. 10.  7.  8.  8.  5. 10.  7.] 
adversary cards in hand: [ 1. 23.  3. 11.  1.] 
adversary cards in discard: [ 0. 10.  3.  0.  0.  8.] 
adversary owned cards: [ 1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0] -> size -> 22 
adversary victory points: 5
player victory points: 8 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.19908291101455688
desired expected reward: 13.142127990722656



buy possibilites: [-1] 
expected returns: [[11.589257]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 6.] 
cards in discard: [29. 15.  0.  3.  0.  6. 11.  8. 11.  0.  6. 16.  0.  0.  3.  3.  0.  0.
  4.  3.  0. 29. 10.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6] -> size -> 47 
action values: 0 
buys: 0 
player value: 3 
card supply: [13. 21. 30. 18. 29.  8.  4.  8.  5.  3. 10.  7.  8.  8.  5. 10.  7.] 
adversary cards in hand: [ 1. 23.  3. 11.  1.] 
adversary cards in discard: [ 0. 10.  3.  0.  0.  8.] 
adversary owned cards: [ 1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0] -> size -> 22 
adversary victory points: 5
player victory points: 7 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.  -12.
    0. -300.    0.    0.] 
sum of rewards: -297.0 

action type: buy - action 6.0
Learning step: -9.072519302368164
desired expected reward: 0.4010591506958008






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [ 1. 23.  3. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 11.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 23.  3. 11.  1.] 
cards in discard: [ 0. 10.  3.  0.  0.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 21. 30. 18. 29.  8.  4.  8.  5.  3. 10.  7.  8.  8.  5. 10.  7.] 
adversary cards in hand: [ 0. 15.  3.  6.  8.] 
adversary cards in discard: [29. 15.  0.  3.  0.  6. 11.  8. 11.  0.  6. 16.  0.  0.  3.  3.  0.  0.
  4.  3.  0. 29. 10.  6. 11.  1.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6] -> size -> 47 
adversary victory points: 7
player victory points: 5 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 11.  1.  0.] 
cards in discard: [ 0. 10.  3.  0.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0] -> size -> 22 
action values: 1 
buys: 1 
player value: 1 
card supply: [13. 21. 30. 18. 29.  8.  4.  8.  5.  3. 10.  7.  8.  8.  5. 10.  7.] 
adversary cards in hand: [ 0. 15.  3.  6.  8.] 
adversary cards in discard: [29. 15.  0.  3.  0.  6. 11.  8. 11.  0.  6. 16.  0.  0.  3.  3.  0.  0.
  4.  3.  0. 29. 10.  6. 11.  1.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6] -> size -> 47 
adversary victory points: 7
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 1. 0.] 
cards in discard: [ 0. 10.  3.  0.  0.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [23. 11.] 
owned cards: [ 1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 21. 30. 18. 29.  8.  4.  8.  5.  3. 10.  7.  8.  8.  5. 10.  7.] 
adversary cards in hand: [ 0. 15.  3.  6.  8.] 
adversary cards in discard: [29. 15.  0.  3.  0.  6. 11.  8. 11.  0.  6. 16.  0.  0.  3.  3.  0.  0.
  4.  3.  0. 29. 10.  6. 11.  1.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6] -> size -> 47 
adversary victory points: 7
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1. 0.] 
cards in discard: [ 0. 10.  3.  0.  0.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [23. 11.] 
owned cards: [ 1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0] -> size -> 23 
action values: 0 
buys: 2 
player value: 6 
card supply: [12. 21. 30. 18. 29.  8.  4.  8.  5.  3. 10.  7.  8.  8.  5. 10.  7.] 
adversary cards in hand: [ 0. 15.  3.  6.  8.] 
adversary cards in discard: [29. 15.  0.  3.  0.  6. 11.  8. 11.  0.  6. 16.  0.  0.  3.  3.  0.  0.
  4.  3.  0. 29. 10.  6. 11.  1.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6] -> size -> 47 
adversary victory points: 7
player victory points: 5 


buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1. 0.] 
cards in discard: [ 0. 10.  3.  0.  0.  8.  0. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [23. 11.] 
owned cards: [ 1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 21. 30. 18. 29.  8.  4.  8.  5.  3.  9.  7.  8.  8.  5. 10.  7.] 
adversary cards in hand: [ 0. 15.  3.  6.  8.] 
adversary cards in discard: [29. 15.  0.  3.  0.  6. 11.  8. 11.  0.  6. 16.  0.  0.  3.  3.  0.  0.
  4.  3.  0. 29. 10.  6. 11.  1.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6] -> size -> 47 
adversary victory points: 7
player victory points: 5 





Player: 0 
cards in hand: [ 0. 15.  3.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[10.749907]
 [10.928048]
 [11.651198]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3.  6.  8.] 
cards in discard: [29. 15.  0.  3.  0.  6. 11.  8. 11.  0.  6. 16.  0.  0.  3.  3.  0.  0.
  4.  3.  0. 29. 10.  6. 11.  1.  3.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 18. 29.  8.  4.  8.  5.  3.  9.  7.  8.  8.  5. 10.  7.] 
adversary cards in hand: [14.  0.  0. 23. 10.] 
adversary cards in discard: [ 0. 10.  3.  0.  0.  8.  0. 25. 23. 11.  1.  3.  1.  0.] 
adversary owned cards: [ 1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25] -> size -> 24 
adversary victory points: 5
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3798885643482208
desired expected reward: 11.209368705749512





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 9.749578]
 [ 7.706961]
 [10.749907]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  3.  6.  8.] 
cards in discard: [29. 15.  0.  3.  0.  6. 11.  8. 11.  0.  6. 16.  0.  0.  3.  3.  0.  0.
  4.  3.  0. 29. 10.  6. 11.  1.  3.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6] -> size -> 47 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 21. 30. 18. 29.  8.  4.  8.  5.  3.  9.  7.  8.  8.  5. 10.  7.] 
adversary cards in hand: [14.  0.  0. 23. 10.] 
adversary cards in discard: [ 0. 10.  3.  0.  0.  8.  0. 25. 23. 11.  1.  3.  1.  0.] 
adversary owned cards: [ 1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25] -> size -> 24 
adversary victory points: 5
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.37094438076019287
desired expected reward: 10.378963470458984



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [14.  0.  0. 23. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 23. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0. 23. 10.] 
cards in discard: [ 0. 10.  3.  0.  0.  8.  0. 25. 23. 11.  1.  3.  1.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 18. 29.  8.  4.  8.  5.  3.  9.  7.  8.  8.  5. 10.  7.] 
adversary cards in hand: [ 1.  1.  0. 11. 14.] 
adversary cards in discard: [29. 15.  0.  3.  0.  6. 11.  8. 11.  0.  6. 16.  0.  0.  3.  3.  0.  0.
  4.  3.  0. 29. 10.  6. 11.  1.  3.  0.  6.  0. 15.  3.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6] -> size -> 47 
adversary victory points: 7
player victory points: 5 


action possibilites: [-1. 14. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0. 23.  3.] 
cards in discard: [ 0. 10.  3.  0.  0.  8.  0. 25. 23. 11.  1.  3.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 18. 29.  8.  4.  8.  5.  3.  9.  7.  8.  8.  5. 10.  7.] 
adversary cards in hand: [ 1.  1.  0. 11. 14.] 
adversary cards in discard: [29. 15.  0.  3.  0.  6. 11.  8. 11.  0.  6. 16.  0.  0.  3.  3.  0.  0.
  4.  3.  0. 29. 10.  6. 11.  1.  3.  0.  6.  0. 15.  3.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6] -> size -> 47 
adversary victory points: 7
player victory points: 5 


action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  3.  1.] 
cards in discard: [ 0. 10.  3.  0.  0.  8.  0. 25. 23. 11.  1.  3.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 23.] 
owned cards: [ 1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25] -> size -> 24 
action values: 2 
buys: 1 
player value: 1 
card supply: [12. 21. 30. 18. 29.  8.  4.  8.  5.  3.  9.  7.  8.  8.  5. 10.  7.] 
adversary cards in hand: [ 1.  1.  0. 11. 14.] 
adversary cards in discard: [29. 15.  0.  3.  0.  6. 11.  8. 11.  0.  6. 16.  0.  0.  3.  3.  0.  0.
  4.  3.  0. 29. 10.  6. 11.  1.  3.  0.  6.  0. 15.  3.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6] -> size -> 47 
adversary victory points: 7
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 1.] 
cards in discard: [ 0. 10.  3.  0.  0.  8.  0. 25. 23. 11.  1.  3.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 23. 14.] 
owned cards: [ 1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25] -> size -> 24 
action values: 1 
buys: 1 
player value: 3 
card supply: [12. 21. 30. 18. 29.  8.  4.  8.  5.  3.  9.  7.  8.  8.  5. 10.  7.] 
adversary cards in hand: [ 1.  1. 11.] 
adversary cards in discard: [29. 15.  0.  3.  0.  6. 11.  8. 11.  0.  6. 16.  0.  0.  3.  3.  0.  0.
  4.  3.  0. 29. 10.  6. 11.  1.  3.  0.  6.  0. 15.  3.  6.  8.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6] -> size -> 47 
adversary victory points: 7
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1.] 
cards in discard: [ 0. 10.  3.  0.  0.  8.  0. 25. 23. 11.  1.  3.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 23. 14.] 
owned cards: [ 1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25] -> size -> 24 
action values: 0 
buys: 2 
player value: 7 
card supply: [12. 21. 30. 18. 29.  8.  4.  8.  5.  3.  9.  7.  8.  8.  5. 10.  7.] 
adversary cards in hand: [ 1.  1. 11.] 
adversary cards in discard: [29. 15.  0.  3.  0.  6. 11.  8. 11.  0.  6. 16.  0.  0.  3.  3.  0.  0.
  4.  3.  0. 29. 10.  6. 11.  1.  3.  0.  6.  0. 15.  3.  6.  8.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6] -> size -> 47 
adversary victory points: 7
player victory points: 5 


buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1.] 
cards in discard: [ 0. 10.  3.  0.  0.  8.  0. 25. 23. 11.  1.  3.  1.  0. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 23. 14.] 
owned cards: [ 1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25
 15] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 21. 30. 18. 29.  8.  4.  8.  5.  3.  9.  7.  8.  8.  5. 10.  6.] 
adversary cards in hand: [ 1.  1. 11.] 
adversary cards in discard: [29. 15.  0.  3.  0.  6. 11.  8. 11.  0.  6. 16.  0.  0.  3.  3.  0.  0.
  4.  3.  0. 29. 10.  6. 11.  1.  3.  0.  6.  0. 15.  3.  6.  8.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6] -> size -> 47 
adversary victory points: 7
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1.] 
cards in discard: [ 0. 10.  3.  0.  0.  8.  0. 25. 23. 11.  1.  3.  1.  0. 15. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 23. 14.] 
owned cards: [ 1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25
 15 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 18. 29.  8.  4.  8.  5.  3.  9.  7.  8.  8.  4. 10.  6.] 
adversary cards in hand: [ 1.  1. 11.] 
adversary cards in discard: [29. 15.  0.  3.  0.  6. 11.  8. 11.  0.  6. 16.  0.  0.  3.  3.  0.  0.
  4.  3.  0. 29. 10.  6. 11.  1.  3.  0.  6.  0. 15.  3.  6.  8.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6] -> size -> 47 
adversary victory points: 7
player victory points: 5 





Player: 0 
cards in hand: [ 1.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[ 9.953278]
 [11.282278]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1. 11.] 
cards in discard: [29. 15.  0.  3.  0.  6. 11.  8. 11.  0.  6. 16.  0.  0.  3.  3.  0.  0.
  4.  3.  0. 29. 10.  6. 11.  1.  3.  0.  6.  0. 15.  3.  6.  8.  0. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 18. 29.  8.  4.  8.  5.  3.  9.  7.  8.  8.  4. 10.  6.] 
adversary cards in hand: [3. 0. 3. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25
 15 10] -> size -> 26 
adversary victory points: 5
player victory points: 7 

Reward from previous game state: 
[   -5     0     0     0     0     0     0     0     0     0     0   -12
     0 -1500   198     0] 
sum of rewards: -1319 

action type: discard_down_to_3_cards - action 5
Learning step: -39.836673736572266
desired expected reward: -27.184852600097656



action possibilites: [-1] 
expected returns: [[10.380319]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1.] 
cards in discard: [29. 15.  0.  3.  0.  6. 11.  8. 11.  0.  6. 16.  0.  0.  3.  3.  0.  0.
  4.  3.  0. 29. 10.  6. 11.  1.  3.  0.  6.  0. 15.  3.  6.  8.  0. 14.
 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 18. 29.  8.  4.  8.  5.  3.  9.  7.  8.  8.  3. 10.  6.] 
adversary cards in hand: [3. 0. 3. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25
 15 10] -> size -> 26 
adversary victory points: 5
player victory points: 7 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -13   0   0   9   0] 
sum of rewards: 11 

action type: gain_card_n - action 9
Learning step: 0.07058260589838028
desired expected reward: 12.350940704345703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 9.444145]
 [10.835419]
 [ 9.917546]
 [ 7.584693]
 [ 9.851201]
 [11.715616]
 [11.222974]
 [11.905805]
 [ 9.169577]
 [10.298116]
 [10.549089]
 [10.380319]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1.] 
cards in discard: [29. 15.  0.  3.  0.  6. 11.  8. 11.  0.  6. 16.  0.  0.  3.  3.  0.  0.
  4.  3.  0. 29. 10.  6. 11.  1.  3.  0.  6.  0. 15.  3.  6.  8.  0. 14.
 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10] -> size -> 48 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 21. 30. 18. 29.  8.  4.  8.  5.  3.  9.  7.  8.  8.  3. 10.  6.] 
adversary cards in hand: [3. 0. 3. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25
 15 10] -> size -> 26 
adversary victory points: 5
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.24960476160049438
desired expected reward: 10.629923820495605






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 8.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25
 15 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 18. 29.  8.  4.  8.  5.  3.  9.  7.  8.  8.  3. 10.  6.] 
adversary cards in hand: [ 0. 16.  3. 29.  1.] 
adversary cards in discard: [29. 15.  0.  3.  0.  6. 11.  8. 11.  0.  6. 16.  0.  0.  3.  3.  0.  0.
  4.  3.  0. 29. 10.  6. 11.  1.  3.  0.  6.  0. 15.  3.  6.  8.  0. 14.
 10. 11.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10] -> size -> 48 
adversary victory points: 7
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 8.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25
 15 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 21. 30. 18. 29.  8.  4.  8.  5.  3.  9.  7.  8.  8.  3. 10.  6.] 
adversary cards in hand: [ 0. 16.  3. 29.  1.] 
adversary cards in discard: [29. 15.  0.  3.  0.  6. 11.  8. 11.  0.  6. 16.  0.  0.  3.  3.  0.  0.
  4.  3.  0. 29. 10.  6. 11.  1.  3.  0.  6.  0. 15.  3.  6.  8.  0. 14.
 10. 11.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10] -> size -> 48 
adversary victory points: 7
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 16.  3. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29.] 
expected returns: [[8.433505]
 [7.952069]
 [9.852958]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  3. 29.  1.] 
cards in discard: [29. 15.  0.  3.  0.  6. 11.  8. 11.  0.  6. 16.  0.  0.  3.  3.  0.  0.
  4.  3.  0. 29. 10.  6. 11.  1.  3.  0.  6.  0. 15.  3.  6.  8.  0. 14.
 10. 11.  1.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0
 15  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 18. 29.  8.  4.  8.  5.  3.  9.  7.  8.  8.  3. 10.  6.] 
adversary cards in hand: [23.  0.  3.  1.  8.] 
adversary cards in discard: [3. 0. 3. 3. 8.] 
adversary owned cards: [ 1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25
 15 10] -> size -> 26 
adversary victory points: 5
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.3672504425048828
desired expected reward: 10.013068199157715



action possibilites: [-1] 
expected returns: [[10.648847]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  1.] 
cards in discard: [29. 15.  0.  3.  0.  6. 11.  8. 11.  0.  6. 16.  0.  0.  3.  3.  0.  0.
  4.  3.  0. 29. 10.  6. 11.  1.  3.  0.  6.  0. 15.  3.  6.  8.  0. 14.
 10. 11.  1.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 21. 30. 18. 29.  8.  4.  8.  5.  3.  9.  7.  8.  8.  3. 10.  6.] 
adversary cards in hand: [23.  0.  3.  1.  8.] 
adversary cards in discard: [3. 0. 3. 3. 8.] 
adversary owned cards: [ 1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25
 15 10] -> size -> 26 
adversary victory points: 5
player victory points: 7 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -13   0   0   0   0] 
sum of rewards: 2 

action type: gain_card_n - action 0
Learning step: -0.07680696249008179
desired expected reward: 8.210521697998047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 9.746435]
 [10.204253]
 [ 7.868718]
 [11.461186]
 [10.648848]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  1.] 
cards in discard: [29. 15.  0.  3.  0.  6. 11.  8. 11.  0.  6. 16.  0.  0.  3.  3.  0.  0.
  4.  3.  0. 29. 10.  6. 11.  1.  3.  0.  6.  0. 15.  3.  6.  8.  0. 14.
 10. 11.  1.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0] -> size -> 48 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 21. 30. 18. 29.  8.  4.  8.  5.  3.  9.  7.  8.  8.  3. 10.  6.] 
adversary cards in hand: [23.  0.  3.  1.  8.] 
adversary cards in discard: [3. 0. 3. 3. 8.] 
adversary owned cards: [ 1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25
 15 10] -> size -> 26 
adversary victory points: 5
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.23848454654216766
desired expected reward: 10.887331008911133






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [23.  0.  3.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0.  3.  1.  8.] 
cards in discard: [3. 0. 3. 3. 8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1 23  0  3 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25
 15 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 21. 30. 18. 29.  8.  4.  8.  5.  3.  9.  7.  8.  8.  3. 10.  6.] 
adversary cards in hand: [ 0. 11.  3.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0] -> size -> 48 
adversary victory points: 7
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1.] 
cards in discard: [3. 0. 3. 3. 8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 21. 30. 18. 29.  8.  4.  8.  5.  3.  9.  7.  8.  8.  3. 10.  6.] 
adversary cards in hand: [ 0. 11.  3.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0] -> size -> 48 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1.] 
cards in discard: [3. 0. 3. 3. 8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 21. 30. 18. 29.  8.  4.  8.  5.  3.  9.  7.  8.  8.  3. 10.  6.] 
adversary cards in hand: [ 0. 11.  3.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0] -> size -> 48 
adversary victory points: 7
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1.] 
cards in discard: [ 3.  0.  3.  3.  8. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 21. 30. 18. 29.  8.  4.  8.  4.  3.  9.  7.  8.  8.  3. 10.  6.] 
adversary cards in hand: [ 0. 11.  3.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0] -> size -> 48 
adversary victory points: 7
player victory points: 4 





Player: 0 
cards in hand: [ 0. 11.  3.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[11.482474]
 [12.978801]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  1.  3.] 
cards in discard: [] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 21. 30. 18. 29.  8.  4.  8.  4.  3.  9.  7.  8.  8.  3. 10.  6.] 
adversary cards in hand: [ 0.  0. 11.  0.  1.] 
adversary cards in discard: [ 3.  0.  3.  3.  8. 11.  8.  0.  1.] 
adversary owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11] -> size -> 25 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.33947256207466125
desired expected reward: 10.30937385559082



action possibilites: [-1] 
expected returns: [[10.980587]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 3.] 
cards in discard: [10.] 
cards in deck: 43 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 21. 30. 18. 29.  8.  4.  8.  4.  3.  9.  7.  8.  8.  2. 10.  6.] 
adversary cards in hand: [ 0.  0. 11.  0.  1.] 
adversary cards in discard: [ 3.  0.  3.  3.  8. 11.  8.  0.  1.] 
adversary owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11] -> size -> 25 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -14   0   0   9   0] 
sum of rewards: 10 

action type: gain_card_n - action 9
Learning step: -0.004608192481100559
desired expected reward: 14.104606628417969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[10.069207 ]
 [11.679373 ]
 [10.618816 ]
 [ 7.8714776]
 [12.692397 ]
 [12.126892 ]
 [11.058041 ]
 [11.152398 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 3.] 
cards in discard: [10.] 
cards in deck: 43 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10] -> size -> 49 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 21. 30. 18. 29.  8.  4.  8.  4.  3.  9.  7.  8.  8.  2. 10.  6.] 
adversary cards in hand: [ 0.  0. 11.  0.  1.] 
adversary cards in discard: [ 3.  0.  3.  3.  8. 11.  8.  0.  1.] 
adversary owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11] -> size -> 25 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.23886846005916595
desired expected reward: 11.21945571899414






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 11.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  1.] 
cards in discard: [ 3.  0.  3.  3.  8. 11.  8.  0.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 21. 30. 18. 29.  8.  4.  8.  4.  3.  9.  7.  8.  8.  2. 10.  6.] 
adversary cards in hand: [ 3. 10. 15. 11.  3.] 
adversary cards in discard: [10. 11.  0.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10] -> size -> 49 
adversary victory points: 7
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1.] 
cards in discard: [ 3.  0.  3.  3.  8. 11.  8.  0.  1. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 21. 30. 18. 29.  8.  4.  8.  4.  3.  9.  6.  8.  8.  2. 10.  6.] 
adversary cards in hand: [ 3. 10. 15. 11.  3.] 
adversary cards in discard: [10. 11.  0.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10] -> size -> 49 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1.] 
cards in discard: [ 3.  0.  3.  3.  8. 11.  8.  0.  1. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29] -> size -> 26 
action values: 0 
buys: 1 
player value: 5 
card supply: [11. 21. 30. 18. 29.  8.  4.  8.  4.  3.  9.  6.  8.  8.  2. 10.  6.] 
adversary cards in hand: [ 3. 10. 15. 11.  3.] 
adversary cards in discard: [10. 11.  0.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10] -> size -> 49 
adversary victory points: 7
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1.] 
cards in discard: [ 3.  0.  3.  3.  8. 11.  8.  0.  1. 29. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 21. 30. 18. 29.  8.  4.  8.  4.  3.  9.  6.  8.  8.  1. 10.  6.] 
adversary cards in hand: [ 3. 10. 15. 11.  3.] 
adversary cards in discard: [10. 11.  0.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10] -> size -> 49 
adversary victory points: 7
player victory points: 4 





Player: 0 
cards in hand: [ 3. 10. 15. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 11.] 
expected returns: [[13.783316]
 [13.681971]
 [13.996085]
 [15.458699]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 15. 11.  3.] 
cards in discard: [10. 11.  0.  3.  1.  3.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 21. 30. 18. 29.  8.  4.  8.  4.  3.  9.  6.  8.  8.  1. 10.  6.] 
adversary cards in hand: [14.  1.  0.  0. 10.] 
adversary cards in discard: [ 3.  0.  3.  3.  8. 11.  8.  0.  1. 29. 10. 11.  0.  0.  0.  1.] 
adversary owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10] -> size -> 27 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.33257657289505005
desired expected reward: 10.819822311401367





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[12.5852165]
 [10.314296 ]
 [13.762529 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 15. 11.  3.] 
cards in discard: [10. 11.  0.  3.  1.  3.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10] -> size -> 49 
action values: 1 
buys: 1 
player value: 0 
card supply: [11. 21. 30. 18. 29.  8.  4.  8.  4.  3.  9.  6.  8.  8.  1. 10.  6.] 
adversary cards in hand: [14.  1.  0.  0. 10.] 
adversary cards in discard: [ 3.  0.  3.  3.  8. 11.  8.  0.  1. 29. 10. 11.  0.  0.  0.  1.] 
adversary owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10] -> size -> 27 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.43194442987442017
desired expected reward: 13.351370811462402



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [14.  1.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  1.  0.  0. 10.] 
cards in discard: [ 3.  0.  3.  3.  8. 11.  8.  0.  1. 29. 10. 11.  0.  0.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 21. 30. 18. 29.  8.  4.  8.  4.  3.  9.  6.  8.  8.  1. 10.  6.] 
adversary cards in hand: [ 3.  8.  0.  0. 29.] 
adversary cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10] -> size -> 49 
adversary victory points: 7
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0. 10.] 
cards in discard: [ 3.  0.  3.  3.  8. 11.  8.  0.  1. 29. 10. 11.  0.  0.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 21. 30. 18. 29.  8.  4.  8.  4.  3.  9.  6.  8.  8.  1. 10.  6.] 
adversary cards in hand: [ 0.  0. 29.] 
adversary cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10] -> size -> 49 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0. 10.] 
cards in discard: [ 3.  0.  3.  3.  8. 11.  8.  0.  1. 29. 10. 11.  0.  0.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 6 
card supply: [11. 21. 30. 18. 29.  8.  4.  8.  4.  3.  9.  6.  8.  8.  1. 10.  6.] 
adversary cards in hand: [ 0.  0. 29.] 
adversary cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10] -> size -> 49 
adversary victory points: 7
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[13.347513]
 [15.115767]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.] 
cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 21. 30. 18. 29.  8.  4.  8.  4.  3.  9.  6.  8.  8.  1. 10.  6.] 
adversary cards in hand: [25. 10. 15. 10.  3.] 
adversary cards in discard: [ 3.  0.  3.  3.  8. 11.  8.  0.  1. 29. 10. 11.  0.  0.  0.  1. 14.  1.
  0.  0. 10.] 
adversary owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10] -> size -> 27 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[   -5     0     0     0     0     0     0     0     0     0     0   -14
     0 -1500   161     0] 
sum of rewards: -1358 

action type: discard_down_to_3_cards - action 0
Learning step: -40.897151947021484
desired expected reward: -30.61574935913086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[12.36783 ]
 [12.90712 ]
 [10.180699]
 [14.379441]
 [13.426395]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.] 
cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10] -> size -> 49 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 21. 30. 18. 29.  8.  4.  8.  4.  3.  9.  6.  8.  8.  1. 10.  6.] 
adversary cards in hand: [25. 10. 15. 10.  3.] 
adversary cards in discard: [ 3.  0.  3.  3.  8. 11.  8.  0.  1. 29. 10. 11.  0.  0.  0.  1. 14.  1.
  0.  0. 10.] 
adversary owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10] -> size -> 27 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.41394928097724915
desired expected reward: 12.933564186096191



buy possibilites: [-1] 
expected returns: [[9.645673]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.] 
cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.  8.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 21. 30. 18. 29.  8.  4.  8.  4.  2.  9.  6.  8.  8.  1. 10.  6.] 
adversary cards in hand: [25. 10. 15. 10.  3.] 
adversary cards in discard: [ 3.  0.  3.  3.  8. 11.  8.  0.  1. 29. 10. 11.  0.  0.  0.  1. 14.  1.
  0.  0. 10.] 
adversary owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10] -> size -> 27 
adversary victory points: 4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0 -15   0   0   8   0] 
sum of rewards: -12 

action type: buy - action 8.0
Learning step: -0.6901036500930786
desired expected reward: 13.689336776733398






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [25. 10. 15. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 15. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10. 15. 10.  3.] 
cards in discard: [ 3.  0.  3.  3.  8. 11.  8.  0.  1. 29. 10. 11.  0.  0.  0.  1. 14.  1.
  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 21. 30. 18. 29.  8.  4.  8.  4.  2.  9.  6.  8.  8.  1. 10.  6.] 
adversary cards in hand: [11.  8. 15.  6.  0.] 
adversary cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.  8.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8] -> size -> 50 
adversary victory points: 7
player victory points: 4 


action possibilites: [-1. 25. 15. 10. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 15. 10.  3. 23.] 
cards in discard: [ 3.  0.  3.  3.  8. 11.  8.  0.  1. 29. 10. 11.  0.  0.  0.  1. 14.  1.
  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [11. 21. 30. 18. 29.  8.  4.  8.  4.  2.  9.  6.  8.  8.  1. 10.  6.] 
adversary cards in hand: [11.  8. 15.  6.  0.] 
adversary cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.  8.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8] -> size -> 50 
adversary victory points: 7
player victory points: 4 


action possibilites: [-1. 25. 15. 10. 10.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 15. 10.  3. 10.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [10. 23.] 
owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10] -> size -> 27 
action values: 2 
buys: 1 
player value: 1 
card supply: [11. 21. 30. 18. 29.  8.  4.  8.  4.  2.  9.  6.  8.  8.  1. 10.  6.] 
adversary cards in hand: [11.  8. 15.  6.  0.] 
adversary cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.  8.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8] -> size -> 50 
adversary victory points: 7
player victory points: 4 


action possibilites: [-1. 15. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  3. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [10. 23. 25.] 
owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10] -> size -> 27 
action values: 1 
buys: 1 
player value: 1 
card supply: [11. 21. 30. 18. 29.  8.  3.  8.  4.  2.  9.  6.  8.  8.  1. 10.  6.] 
adversary cards in hand: [11.  8. 15.  6.  0.] 
adversary cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.  8.  0.  0. 29.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6] -> size -> 51 
adversary victory points: 7
player victory points: 4 


action possibilites: [-1. 15. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 10.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [10. 23. 25. 10.] 
owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10] -> size -> 27 
action values: 2 
buys: 1 
player value: 1 
card supply: [11. 21. 30. 18. 29.  8.  3.  8.  4.  2.  9.  6.  8.  8.  1. 10.  6.] 
adversary cards in hand: [11.  8. 15.  6.  0.] 
adversary cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.  8.  0.  0. 29.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6] -> size -> 51 
adversary victory points: 7
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3. 10.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [10. 23. 25. 10.] 
owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10] -> size -> 27 
action values: 0 
buys: 2 
player value: 4 
card supply: [11. 21. 30. 18. 29.  8.  3.  8.  4.  2.  9.  6.  8.  8.  1. 10.  6.] 
adversary cards in hand: [11.  8. 15.  6.  0.] 
adversary cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.  8.  0.  0. 29.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6] -> size -> 51 
adversary victory points: 7
player victory points: 4 


buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3. 10.  0.  0.  0.] 
cards in discard: [3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10. 23. 25. 10.] 
owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 21. 30. 17. 29.  8.  3.  8.  4.  2.  9.  6.  8.  8.  1. 10.  6.] 
adversary cards in hand: [11.  8. 15.  6.  0.] 
adversary cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.  8.  0.  0. 29.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6] -> size -> 51 
adversary victory points: 7
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3. 10.  0.  0.  0.] 
cards in discard: [3. 8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10. 23. 25. 10.] 
owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10  3  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 21. 30. 17. 29.  8.  3.  8.  4.  1.  9.  6.  8.  8.  1. 10.  6.] 
adversary cards in hand: [11.  8. 15.  6.  0.] 
adversary cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.  8.  0.  0. 29.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6] -> size -> 51 
adversary victory points: 7
player victory points: 5 





Player: 0 
cards in hand: [11.  8. 15.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 15.] 
expected returns: [[10.178216]
 [11.4531  ]
 [10.976662]
 [10.341257]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 15.  6.  0.] 
cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.  8.  0.  0. 29.  6.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 21. 30. 17. 29.  8.  3.  8.  4.  1.  9.  6.  8.  8.  1. 10.  6.] 
adversary cards in hand: [ 1. 14.  0.  3.  8.] 
adversary cards in discard: [ 3.  8. 10. 23. 25. 10. 15.  3. 10.  0.  0.  0.] 
adversary owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10  3  8] -> size -> 29 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0  -16    0 -300
    0    0] 
sum of rewards: -321 

action type: buy - action -1
Learning step: -9.805124282836914
desired expected reward: -0.15945148468017578



action possibilites: [-1] 
expected returns: [[13.162701]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  6.  0.] 
cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.  8.  0.  0. 29.  6.
 29.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 21. 30. 17. 29.  8.  3.  8.  4.  1.  9.  5.  8.  8.  1. 10.  6.] 
adversary cards in hand: [ 1. 14.  0.  3.  8.] 
adversary cards in discard: [ 3.  8. 10. 23. 25. 10. 15.  3. 10.  0.  0.  0.] 
adversary owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10  3  8] -> size -> 29 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -17   0   0  16   0] 
sum of rewards: 14 

action type: gain_card_n - action 7
Learning step: 0.2971121370792389
desired expected reward: 9.000319480895996





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[12.166421]
 [10.170939]
 [13.162702]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15.  6.  0.] 
cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.  8.  0.  0. 29.  6.
 29.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29] -> size -> 52 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 21. 30. 17. 29.  8.  3.  8.  4.  1.  9.  5.  8.  8.  1. 10.  6.] 
adversary cards in hand: [ 1. 14.  0.  3.  8.] 
adversary cards in discard: [ 3.  8. 10. 23. 25. 10. 15.  3. 10.  0.  0.  0.] 
adversary owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10  3  8] -> size -> 29 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.18216080963611603
desired expected reward: 13.344861030578613



buy possibilites: [-1] 
expected returns: [[10.590233]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15.  6.  0.] 
cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.  8.  0.  0. 29.  6.
 29.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29  0] -> size -> 53 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 21. 30. 17. 29.  8.  3.  8.  4.  1.  9.  5.  8.  8.  1. 10.  6.] 
adversary cards in hand: [ 1. 14.  0.  3.  8.] 
adversary cards in discard: [ 3.  8. 10. 23. 25. 10. 15.  3. 10.  0.  0.  0.] 
adversary owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10  3  8] -> size -> 29 
adversary victory points: 5
player victory points: 6 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0. -18.   0.   0.
   0.   0.] 
sum of rewards: -3.0 

action type: buy - action 0.0
Learning step: -0.34379521012306213
desired expected reward: 11.822627067565918






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [ 1. 14.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 14.  0.  3.  8.] 
cards in discard: [ 3.  8. 10. 23. 25. 10. 15.  3. 10.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10  3  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 21. 30. 17. 29.  8.  3.  8.  4.  1.  9.  5.  8.  8.  1. 10.  6.] 
adversary cards in hand: [ 1. 29.  3.  0.  1.] 
adversary cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.  8.  0.  0. 29.  6.
 29.  0. 11.  8. 15.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29  0] -> size -> 53 
adversary victory points: 6
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 14.  0.  3.  8.] 
cards in discard: [ 3.  8. 10. 23. 25. 10. 15.  3. 10.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10  3  8] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 21. 30. 17. 29.  8.  3.  8.  4.  1.  9.  5.  8.  8.  1. 10.  6.] 
adversary cards in hand: [ 1. 29.  3.  0.  1.] 
adversary cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.  8.  0.  0. 29.  6.
 29.  0. 11.  8. 15.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29  0] -> size -> 53 
adversary victory points: 6
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 14.  0.  3.  8.] 
cards in discard: [ 3.  8. 10. 23. 25. 10. 15.  3. 10.  0.  0.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10  3  8  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 21. 30. 16. 29.  8.  3.  8.  4.  1.  9.  5.  8.  8.  1. 10.  6.] 
adversary cards in hand: [ 1. 29.  3.  0.  1.] 
adversary cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.  8.  0.  0. 29.  6.
 29.  0. 11.  8. 15.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29  0] -> size -> 53 
adversary victory points: 6
player victory points: 6 





Player: 0 
cards in hand: [ 1. 29.  3.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[10.964924]
 [12.426893]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  3.  0.  1.] 
cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.  8.  0.  0. 29.  6.
 29.  0. 11.  8. 15.  6.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29  0] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 21. 30. 16. 29.  8.  3.  8.  4.  1.  9.  5.  8.  8.  1. 10.  6.] 
adversary cards in hand: [ 1.  1.  0.  3. 29.] 
adversary cards in discard: [ 3.  8. 10. 23. 25. 10. 15.  3. 10.  0.  0.  0.  3.  1. 14.  0.  3.  8.] 
adversary owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10  3  8  3] -> size -> 30 
adversary victory points: 6
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3433648645877838
desired expected reward: 10.246868133544922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[10.103127 ]
 [11.400269 ]
 [10.538437 ]
 [ 9.081955 ]
 [ 8.315289 ]
 [10.476567 ]
 [12.242553 ]
 [11.77168  ]
 [13.616891 ]
 [12.426893 ]
 [ 9.851454 ]
 [ 9.8806925]
 [10.886902 ]
 [ 8.642154 ]
 [11.129922 ]
 [10.964925 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.  3.  0.  1.] 
cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.  8.  0.  0. 29.  6.
 29.  0. 11.  8. 15.  6.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29  0] -> size -> 53 
action values: 0 
buys: 1 
player value: 5 
card supply: [10. 21. 30. 16. 29.  8.  3.  8.  4.  1.  9.  5.  8.  8.  1. 10.  6.] 
adversary cards in hand: [ 1.  1.  0.  3. 29.] 
adversary cards in discard: [ 3.  8. 10. 23. 25. 10. 15.  3. 10.  0.  0.  0.  3.  1. 14.  0.  3.  8.] 
adversary owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10  3  8  3] -> size -> 30 
adversary victory points: 6
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.3604041337966919
desired expected reward: 10.604519844055176



buy possibilites: [-1] 
expected returns: [[10.338964]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.  3.  0.  1.] 
cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.  8.  0.  0. 29.  6.
 29.  0. 11.  8. 15.  6.  0. 25.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29  0 25] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 21. 30. 16. 29.  8.  3.  8.  4.  1.  8.  5.  8.  8.  1. 10.  6.] 
adversary cards in hand: [ 1.  1.  0.  3. 29.] 
adversary cards in discard: [ 3.  8. 10. 23. 25. 10. 15.  3. 10.  0.  0.  0.  3.  1. 14.  0.  3.  8.] 
adversary owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10  3  8  3] -> size -> 30 
adversary victory points: 6
player victory points: 6 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0 -19   0   0  50   0] 
sum of rewards: 26 

action type: buy - action 25.0
Learning step: 0.4800524115562439
desired expected reward: 14.096941947937012






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [ 1.  1.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1.  0.  3. 29.] 
cards in discard: [ 3.  8. 10. 23. 25. 10. 15.  3. 10.  0.  0.  0.  3.  1. 14.  0.  3.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10  3  8  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 21. 30. 16. 29.  8.  3.  8.  4.  1.  8.  5.  8.  8.  1. 10.  6.] 
adversary cards in hand: [ 0.  0.  0.  3. 10.] 
adversary cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.  8.  0.  0. 29.  6.
 29.  0. 11.  8. 15.  6.  0. 25.  1. 29.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29  0 25] -> size -> 54 
adversary victory points: 6
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1.  0.  3. 29.] 
cards in discard: [ 3.  8. 10. 23. 25. 10. 15.  3. 10.  0.  0.  0.  3.  1. 14.  0.  3.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10  3  8  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [10. 21. 30. 16. 29.  8.  3.  8.  4.  1.  8.  5.  8.  8.  1. 10.  6.] 
adversary cards in hand: [ 0.  0.  0.  3. 10.] 
adversary cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.  8.  0.  0. 29.  6.
 29.  0. 11.  8. 15.  6.  0. 25.  1. 29.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29  0 25] -> size -> 54 
adversary victory points: 6
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  0.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[13.295969]
 [13.195494]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 10.] 
cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.  8.  0.  0. 29.  6.
 29.  0. 11.  8. 15.  6.  0. 25.  1. 29.  3.  0.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29  0 25] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 21. 30. 16. 29.  8.  3.  8.  4.  1.  8.  5.  8.  8.  1. 10.  6.] 
adversary cards in hand: [ 0.  3. 11. 10.  8.] 
adversary cards in discard: [ 3.  8. 10. 23. 25. 10. 15.  3. 10.  0.  0.  0.  3.  1. 14.  0.  3.  8.
  1.  1.  0.  3. 29.] 
adversary owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10  3  8  3] -> size -> 30 
adversary victory points: 6
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.32098326086997986
desired expected reward: 10.01798152923584





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[11.4239645]
 [13.1164465]
 [12.009098 ]
 [ 9.127204 ]
 [14.220994 ]
 [13.598539 ]
 [12.47128  ]
 [12.568438 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 10.] 
cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.  8.  0.  0. 29.  6.
 29.  0. 11.  8. 15.  6.  0. 25.  1. 29.  3.  0.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29  0 25] -> size -> 54 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 21. 30. 16. 29.  8.  3.  8.  4.  1.  8.  5.  8.  8.  1. 10.  6.] 
adversary cards in hand: [ 0.  3. 11. 10.  8.] 
adversary cards in discard: [ 3.  8. 10. 23. 25. 10. 15.  3. 10.  0.  0.  0.  3.  1. 14.  0.  3.  8.
  1.  1.  0.  3. 29.] 
adversary owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10  3  8  3] -> size -> 30 
adversary victory points: 6
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.39372628927230835
desired expected reward: 12.174712181091309



buy possibilites: [-1] 
expected returns: [[13.880688]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 10.] 
cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.  8.  0.  0. 29.  6.
 29.  0. 11.  8. 15.  6.  0. 25.  1. 29.  3.  0.  1.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29  0 25  3] -> size -> 55 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 21. 30. 15. 29.  8.  3.  8.  4.  1.  8.  5.  8.  8.  1. 10.  6.] 
adversary cards in hand: [ 0.  3. 11. 10.  8.] 
adversary cards in discard: [ 3.  8. 10. 23. 25. 10. 15.  3. 10.  0.  0.  0.  3.  1. 14.  0.  3.  8.
  1.  1.  0.  3. 29.] 
adversary owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10  3  8  3] -> size -> 30 
adversary victory points: 6
player victory points: 7 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. -20.   0.   0.
   2.   0.] 
sum of rewards: -23.0 

action type: buy - action 3.0
Learning step: -0.904525637626648
desired expected reward: 11.104571342468262






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 11. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11. 10.  8.] 
cards in discard: [ 3.  8. 10. 23. 25. 10. 15.  3. 10.  0.  0.  0.  3.  1. 14.  0.  3.  8.
  1.  1.  0.  3. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10  3  8  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 21. 30. 15. 29.  8.  3.  8.  4.  1.  8.  5.  8.  8.  1. 10.  6.] 
adversary cards in hand: [ 0.  6. 29.  4. 11.] 
adversary cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.  8.  0.  0. 29.  6.
 29.  0. 11.  8. 15.  6.  0. 25.  1. 29.  3.  0.  1.  3.  0.  0.  0.  3.
 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29  0 25  3] -> size -> 55 
adversary victory points: 7
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  8.] 
cards in discard: [ 3.  8. 10. 23. 25. 10. 15.  3. 10.  0.  0.  0.  3.  1. 14.  0.  3.  8.
  1.  1.  0.  3. 29. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10  3  8  3 29] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 21. 30. 15. 29.  8.  3.  8.  4.  1.  8.  4.  8.  8.  1. 10.  6.] 
adversary cards in hand: [ 0.  6. 29.  4. 11.] 
adversary cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.  8.  0.  0. 29.  6.
 29.  0. 11.  8. 15.  6.  0. 25.  1. 29.  3.  0.  1.  3.  0.  0.  0.  3.
 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29  0 25  3] -> size -> 55 
adversary victory points: 7
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  8.] 
cards in discard: [ 3.  8. 10. 23. 25. 10. 15.  3. 10.  0.  0.  0.  3.  1. 14.  0.  3.  8.
  1.  1.  0.  3. 29. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10  3  8  3 29] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 21. 30. 15. 29.  8.  3.  8.  4.  1.  8.  4.  8.  8.  1. 10.  6.] 
adversary cards in hand: [ 0.  6. 29.  4. 11.] 
adversary cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.  8.  0.  0. 29.  6.
 29.  0. 11.  8. 15.  6.  0. 25.  1. 29.  3.  0.  1.  3.  0.  0.  0.  3.
 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29  0 25  3] -> size -> 55 
adversary victory points: 7
player victory points: 6 





Player: 0 
cards in hand: [ 0.  6. 29.  4. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[8.026244]
 [9.445134]
 [9.264822]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 29.  4. 11.] 
cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.  8.  0.  0. 29.  6.
 29.  0. 11.  8. 15.  6.  0. 25.  1. 29.  3.  0.  1.  3.  0.  0.  0.  3.
 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29  0 25  3] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 21. 30. 15. 29.  8.  3.  8.  4.  1.  8.  4.  8.  8.  1. 10.  6.] 
adversary cards in hand: [ 8.  3. 23. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10  3  8  3 29] -> size -> 31 
adversary victory points: 6
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4717244803905487
desired expected reward: 13.408963203430176



action possibilites: [-1. 11.] 
expected returns: [[7.2327576]
 [8.481106 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  4. 11.  0.] 
cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.  8.  0.  0. 29.  6.
 29.  0. 11.  8. 15.  6.  0. 25.  1. 29.  3.  0.  1.  3.  0.  0.  0.  3.
 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29  0 25  3] -> size -> 55 
action values: 1 
buys: 0 
player value: 1 
card supply: [10. 21. 30. 15. 29.  8.  3.  8.  4.  1.  8.  4.  8.  8.  1. 10.  6.] 
adversary cards in hand: [ 8.  3. 23. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10  3  8  3 29] -> size -> 31 
adversary victory points: 6
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0.25045448541641235
desired expected reward: 9.695589065551758



action possibilites: [-1] 
expected returns: [[7.1262674]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 4. 0.] 
cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.  8.  0.  0. 29.  6.
 29.  0. 11.  8. 15.  6.  0. 25.  1. 29.  3.  0.  1.  3.  0.  0.  0.  3.
 10. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29  0 25  3 10] -> size -> 56 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 21. 30. 15. 29.  8.  3.  8.  4.  1.  8.  4.  8.  8.  0. 10.  6.] 
adversary cards in hand: [ 8.  3. 23. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10  3  8  3 29] -> size -> 31 
adversary victory points: 6
player victory points: 7 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0 -21   0   0   9   0] 
sum of rewards: 23 

action type: gain_card_n - action 9
Learning step: 0.48244667053222656
desired expected reward: 9.895084381103516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[6.182338 ]
 [7.59638  ]
 [6.6566467]
 [4.3765683]
 [8.50982  ]
 [7.998395 ]
 [7.126268 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 4. 0.] 
cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.  8.  0.  0. 29.  6.
 29.  0. 11.  8. 15.  6.  0. 25.  1. 29.  3.  0.  1.  3.  0.  0.  0.  3.
 10. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29  0 25  3 10] -> size -> 56 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 21. 30. 15. 29.  8.  3.  8.  4.  1.  8.  4.  8.  8.  0. 10.  6.] 
adversary cards in hand: [ 8.  3. 23. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10  3  8  3 29] -> size -> 31 
adversary victory points: 6
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.9122182726860046
desired expected reward: 8.038485527038574



buy possibilites: [-1] 
expected returns: [[9.003549]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 4. 0.] 
cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.  8.  0.  0. 29.  6.
 29.  0. 11.  8. 15.  6.  0. 25.  1. 29.  3.  0.  1.  3.  0.  0.  0.  3.
 10. 10. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29  0 25  3 10 11] -> size -> 57 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 21. 30. 15. 29.  8.  3.  8.  3.  1.  8.  4.  8.  8.  0. 10.  6.] 
adversary cards in hand: [ 8.  3. 23. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10  3  8  3 29] -> size -> 31 
adversary victory points: 6
player victory points: 7 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0 -22   0   0  18   0] 
sum of rewards: 31 

action type: buy - action 11.0
Learning step: 0.7692426443099976
desired expected reward: 9.279061317443848






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [ 8.  3. 23. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 23. 11.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10  3  8  3 29] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 21. 30. 15. 29.  8.  3.  8.  3.  1.  8.  4.  8.  8.  0. 10.  6.] 
adversary cards in hand: [14.  1.  1.  3.  0.] 
adversary cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.  8.  0.  0. 29.  6.
 29.  0. 11.  8. 15.  6.  0. 25.  1. 29.  3.  0.  1.  3.  0.  0.  0.  3.
 10. 10. 11. 29. 11.  0.  6.  4.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29  0 25  3 10 11] -> size -> 57 
adversary victory points: 7
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 23.  0.] 
cards in discard: [15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10  3  8  3 29 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 21. 30. 15. 29.  8.  3.  8.  3.  1.  8.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [14.  1.  1.  3.  0.] 
adversary cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.  8.  0.  0. 29.  6.
 29.  0. 11.  8. 15.  6.  0. 25.  1. 29.  3.  0.  1.  3.  0.  0.  0.  3.
 10. 10. 11. 29. 11.  0.  6.  4.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29  0 25  3 10 11] -> size -> 57 
adversary victory points: 7
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 23.  0.] 
cards in discard: [15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10  3  8  3 29 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 21. 30. 15. 29.  8.  3.  8.  3.  1.  8.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [14.  1.  1.  3.  0.] 
adversary cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.  8.  0.  0. 29.  6.
 29.  0. 11.  8. 15.  6.  0. 25.  1. 29.  3.  0.  1.  3.  0.  0.  0.  3.
 10. 10. 11. 29. 11.  0.  6.  4.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29  0 25  3 10 11] -> size -> 57 
adversary victory points: 7
player victory points: 6 





Player: 0 
cards in hand: [14.  1.  1.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[10.357913 ]
 [ 9.0794935]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  1.  1.  3.  0.] 
cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.  8.  0.  0. 29.  6.
 29.  0. 11.  8. 15.  6.  0. 25.  1. 29.  3.  0.  1.  3.  0.  0.  0.  3.
 10. 10. 11. 29. 11.  0.  6.  4.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29  0 25  3 10 11] -> size -> 57 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 21. 30. 15. 29.  8.  3.  8.  3.  1.  8.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [ 0. 10.  1.  1.  0.] 
adversary cards in discard: [15. 11.  8.  3. 23.  0.] 
adversary owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10  3  8  3 29 15] -> size -> 32 
adversary victory points: 6
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3167177140712738
desired expected reward: 8.686830520629883





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[ 9.368754 ]
 [10.83492  ]
 [ 9.871851 ]
 [ 8.228402 ]
 [ 7.4331446]
 [ 9.800549 ]
 [11.757401 ]
 [11.238794 ]
 [13.290923 ]
 [11.969959 ]
 [ 9.079494 ]
 [ 9.113887 ]
 [ 7.7709746]
 [10.540938 ]
 [10.357913 ]]
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  1.  1.  3.  0.] 
cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.  8.  0.  0. 29.  6.
 29.  0. 11.  8. 15.  6.  0. 25.  1. 29.  3.  0.  1.  3.  0.  0.  0.  3.
 10. 10. 11. 29. 11.  0.  6.  4.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29  0 25  3 10 11] -> size -> 57 
action values: 0 
buys: 1 
player value: 5 
card supply: [10. 21. 30. 15. 29.  8.  3.  8.  3.  1.  8.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [ 0. 10.  1.  1.  0.] 
adversary cards in discard: [15. 11.  8.  3. 23.  0.] 
adversary owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10  3  8  3 29 15] -> size -> 32 
adversary victory points: 6
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.34845802187919617
desired expected reward: 10.009454727172852



buy possibilites: [-1] 
expected returns: [[12.83047]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  1.  1.  3.  0.] 
cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.  8.  0.  0. 29.  6.
 29.  0. 11.  8. 15.  6.  0. 25.  1. 29.  3.  0.  1.  3.  0.  0.  0.  3.
 10. 10. 11. 29. 11.  0.  6.  4.  0.  4.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29  0 25  3 10 11  4] -> size -> 58 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 21. 30. 15. 28.  8.  3.  8.  3.  1.  8.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [ 0. 10.  1.  1.  0.] 
adversary cards in discard: [15. 11.  8.  3. 23.  0.] 
adversary owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10  3  8  3 29 15] -> size -> 32 
adversary victory points: 6
player victory points: 10 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0 -23   0   0  50   0] 
sum of rewards: 22 

action type: buy - action 4.0
Learning step: 0.5478678345680237
desired expected reward: 8.776270866394043






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  1.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  1.  1.  0.] 
cards in discard: [15. 11.  8.  3. 23.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10  3  8  3 29 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 21. 30. 15. 28.  8.  3.  8.  3.  1.  8.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [ 0. 16. 16.  6.  3.] 
adversary cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.  8.  0.  0. 29.  6.
 29.  0. 11.  8. 15.  6.  0. 25.  1. 29.  3.  0.  1.  3.  0.  0.  0.  3.
 10. 10. 11. 29. 11.  0.  6.  4.  0.  4. 14.  1.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29  0 25  3 10 11  4] -> size -> 58 
adversary victory points: 10
player victory points: 6 


action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  1.  0. 15.] 
cards in discard: [15. 11.  8.  3. 23.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10  3  8  3 29 15] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [10. 21. 30. 15. 28.  8.  3.  8.  3.  1.  8.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [ 0. 16. 16.  6.  3.] 
adversary cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.  8.  0.  0. 29.  6.
 29.  0. 11.  8. 15.  6.  0. 25.  1. 29.  3.  0.  1.  3.  0.  0.  0.  3.
 10. 10. 11. 29. 11.  0.  6.  4.  0.  4. 14.  1.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29  0 25  3 10 11  4] -> size -> 58 
adversary victory points: 10
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  1.  0. 15.] 
cards in discard: [15. 11.  8.  3. 23.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10  3  8  3 29 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 6 
card supply: [10. 21. 30. 15. 28.  8.  3.  8.  3.  1.  8.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [ 0. 16. 16.  6.  3.] 
adversary cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.  8.  0.  0. 29.  6.
 29.  0. 11.  8. 15.  6.  0. 25.  1. 29.  3.  0.  1.  3.  0.  0.  0.  3.
 10. 10. 11. 29. 11.  0.  6.  4.  0.  4. 14.  1.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29  0 25  3 10 11  4] -> size -> 58 
adversary victory points: 10
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  1.  0. 15.] 
cards in discard: [15. 11.  8.  3. 23.  0.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10  3  8  3 29 15  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 4 
card supply: [10. 21. 30. 15. 28.  8.  3.  8.  3.  0.  8.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [ 0. 16. 16.  6.  3.] 
adversary cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.  8.  0.  0. 29.  6.
 29.  0. 11.  8. 15.  6.  0. 25.  1. 29.  3.  0.  1.  3.  0.  0.  0.  3.
 10. 10. 11. 29. 11.  0.  6.  4.  0.  4. 14.  1.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29  0 25  3 10 11  4] -> size -> 58 
adversary victory points: 10
player victory points: 6 





Player: 0 
cards in hand: [ 0. 16. 16.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.] 
expected returns: [[9.890011]
 [9.380133]
 [9.380133]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 16.  6.  3.] 
cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.  8.  0.  0. 29.  6.
 29.  0. 11.  8. 15.  6.  0. 25.  1. 29.  3.  0.  1.  3.  0.  0.  0.  3.
 10. 10. 11. 29. 11.  0.  6.  4.  0.  4. 14.  1.  1.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29  0 25  3 10 11  4] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 21. 30. 15. 28.  8.  3.  8.  3.  0.  8.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [11.  3. 14. 10.  8.] 
adversary cards in discard: [15. 11.  8.  3. 23.  0.  8. 10.  0.  1.  1.  0. 15.] 
adversary owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10  3  8  3 29 15  8] -> size -> 33 
adversary victory points: 6
player victory points: 10 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4339243173599243
desired expected reward: 12.39654541015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[8.981831 ]
 [7.0933022]
 [9.890011 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16. 16.  6.  3.] 
cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.  8.  0.  0. 29.  6.
 29.  0. 11.  8. 15.  6.  0. 25.  1. 29.  3.  0.  1.  3.  0.  0.  0.  3.
 10. 10. 11. 29. 11.  0.  6.  4.  0.  4. 14.  1.  1.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29  0 25  3 10 11  4] -> size -> 58 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 21. 30. 15. 28.  8.  3.  8.  3.  0.  8.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [11.  3. 14. 10.  8.] 
adversary cards in discard: [15. 11.  8.  3. 23.  0.  8. 10.  0.  1.  1.  0. 15.] 
adversary owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10  3  8  3 29 15  8] -> size -> 33 
adversary victory points: 6
player victory points: 10 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.353228896856308
desired expected reward: 9.536782264709473



buy possibilites: [-1] 
expected returns: [[8.461201]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16. 16.  6.  3.] 
cards in discard: [10. 11.  0.  3.  1.  3.  3. 10. 15. 11.  3.  3.  8.  8.  0.  0. 29.  6.
 29.  0. 11.  8. 15.  6.  0. 25.  1. 29.  3.  0.  1.  3.  0.  0.  0.  3.
 10. 10. 11. 29. 11.  0.  6.  4.  0.  4. 14.  1.  1.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29  0 25  3 10 11  4  0] -> size -> 59 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 21. 30. 15. 28.  8.  3.  8.  3.  0.  8.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [11.  3. 14. 10.  8.] 
adversary cards in discard: [15. 11.  8.  3. 23.  0.  8. 10.  0.  1.  1.  0. 15.] 
adversary owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10  3  8  3 29 15  8] -> size -> 33 
adversary victory points: 6
player victory points: 10 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. -24.   0.   0.
   0.   0.] 
sum of rewards: -29.0 

action type: buy - action 0.0
Learning step: -1.050612211227417
desired expected reward: 7.931218147277832






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [11.  3. 14. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 14. 10.  8.] 
cards in discard: [15. 11.  8.  3. 23.  0.  8. 10.  0.  1.  1.  0. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  0 11  0  0  8 23  3  8  0  0  1 10  3  3  3 10 14  0  0 25 15 10
 11 29 10  3  8  3 29 15  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 21. 30. 15. 28.  8.  3.  8.  3.  0.  8.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [ 3. 11. 16.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29  0 25  3 10 11  4  0] -> size -> 59 
adversary victory points: 10
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.] 
cards in discard: [15. 11.  8.  3. 23.  0.  8. 10.  0.  1.  1.  0. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  1  0 11  0  0  8 23  8  0  0  1 10  3  3  3 10  0  0 25 15 10 11 29
 10  3  8  3 29 15  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 21. 30. 15. 28.  8.  3.  8.  3.  0.  8.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [ 3. 11. 16.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29  0 25  3 10 11  4  0] -> size -> 59 
adversary victory points: 10
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.] 
cards in discard: [15. 11.  8.  3. 23.  0.  8. 10.  0.  1.  1.  0. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  1  0 11  0  0  8 23  8  0  0  1 10  3  3  3 10  0  0 25 15 10 11 29
 10  3  8  3 29 15  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 21. 30. 15. 28.  8.  3.  8.  3.  0.  8.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [ 3. 11. 16.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29  0 25  3 10 11  4  0] -> size -> 59 
adversary victory points: 10
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.] 
cards in discard: [15. 11.  8.  3. 23.  0.  8. 10.  0.  1.  1.  0. 15.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  1  0 11  0  0  8 23  8  0  0  1 10  3  3  3 10  0  0 25 15 10 11 29
 10  3  8  3 29 15  8  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 21. 30. 15. 28.  8.  3.  8.  3.  0.  8.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [ 3. 11. 16.  6.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29  0 25  3 10 11  4  0] -> size -> 59 
adversary victory points: 10
player victory points: 5 





Player: 0 
cards in hand: [ 3. 11. 16.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
expected returns: [[8.395725 ]
 [9.487294 ]
 [7.9713793]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 16.  6.  6.] 
cards in discard: [] 
cards in deck: 54 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29  0 25  3 10 11  4  0] -> size -> 59 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 21. 30. 15. 28.  8.  3.  8.  3.  0.  8.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [29.  3.  0.  3.  3.] 
adversary cards in discard: [15. 11.  8.  3. 23.  0.  8. 10.  0.  1.  1.  0. 15.  0.  8. 11. 10.] 
adversary owned cards: [ 1  1  0 11  0  0  8 23  8  0  0  1 10  3  3  3 10  0  0 25 15 10 11 29
 10  3  8  3 29 15  8  0] -> size -> 32 
adversary victory points: 5
player victory points: 10 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.31152039766311646
desired expected reward: 8.149680137634277



action possibilites: [-1] 
expected returns: [[7.8196545]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  6.  6.] 
cards in discard: [11.] 
cards in deck: 54 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29  0 25  3 10 11  4  0 11] -> size -> 60 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 21. 30. 15. 28.  8.  3.  8.  2.  0.  8.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [29.  3.  0.  3.  3.] 
adversary cards in discard: [15. 11.  8.  3. 23.  0.  8. 10.  0.  1.  1.  0. 15.  0.  8. 11. 10.] 
adversary owned cards: [ 1  1  0 11  0  0  8 23  8  0  0  1 10  3  3  3 10  0  0 25 15 10 11 29
 10  3  8  3 29 15  8  0] -> size -> 32 
adversary victory points: 5
player victory points: 10 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -25   0   0   9   0] 
sum of rewards: -1 

action type: gain_card_n - action 5
Learning step: -0.1836853325366974
desired expected reward: 7.6760382652282715





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[7.083445]
 [5.444877]
 [7.873222]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  6.  6.] 
cards in discard: [11.] 
cards in deck: 54 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29  0 25  3 10 11  4  0 11] -> size -> 60 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 21. 30. 15. 28.  8.  3.  8.  2.  0.  8.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [29.  3.  0.  3.  3.] 
adversary cards in discard: [15. 11.  8.  3. 23.  0.  8. 10.  0.  1.  1.  0. 15.  0.  8. 11. 10.] 
adversary owned cards: [ 1  1  0 11  0  0  8 23  8  0  0  1 10  3  3  3 10  0  0 25 15 10 11 29
 10  3  8  3 29 15  8  0] -> size -> 32 
adversary victory points: 5
player victory points: 10 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.28906843066215515
desired expected reward: 8.108722686767578



buy possibilites: [-1] 
expected returns: [[11.675309]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  6.  6.] 
cards in discard: [11.  0.] 
cards in deck: 54 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29  0 25  3 10 11  4  0 11  0] -> size -> 61 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 21. 30. 15. 28.  8.  3.  8.  2.  0.  8.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [29.  3.  0.  3.  3.] 
adversary cards in discard: [15. 11.  8.  3. 23.  0.  8. 10.  0.  1.  1.  0. 15.  0.  8. 11. 10.] 
adversary owned cards: [ 1  1  0 11  0  0  8 23  8  0  0  1 10  3  3  3 10  0  0 25 15 10 11 29
 10  3  8  3 29 15  8  0] -> size -> 32 
adversary victory points: 5
player victory points: 10 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -26   0   0   0   0] 
sum of rewards: -11 

action type: buy - action 0.0
Learning step: -0.4199126064777374
desired expected reward: 6.663532257080078






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [29.  3.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  3.  3.] 
cards in discard: [15. 11.  8.  3. 23.  0.  8. 10.  0.  1.  1.  0. 15.  0.  8. 11. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  0 11  0  0  8 23  8  0  0  1 10  3  3  3 10  0  0 25 15 10 11 29
 10  3  8  3 29 15  8  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 21. 30. 15. 28.  8.  3.  8.  2.  0.  8.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [10.  1.  0. 29.  8.] 
adversary cards in discard: [11.  0. 11.  3. 16.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29  0 25  3 10 11  4  0 11  0] -> size -> 61 
adversary victory points: 10
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 1.] 
cards in discard: [15. 11.  8.  3. 23.  0.  8. 10.  0.  1.  1.  0. 15.  0.  8. 11. 10.  3.
  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 1  1  0 11  0  0  8 23  8  0  0  1 10  3  3  3 10  0  0 25 15 10 11 29
 10  3  8  3 29 15  8  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 7. 21. 30. 15. 28.  8.  3.  8.  2.  0.  8.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [10.  1.  0. 29.  8.] 
adversary cards in discard: [11.  0. 11.  3. 16.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29  0 25  3 10 11  4  0 11  0] -> size -> 61 
adversary victory points: 10
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1.] 
cards in discard: [15. 11.  8.  3. 23.  0.  8. 10.  0.  1.  1.  0. 15.  0.  8. 11. 10.  3.
  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 1  1  0 11  0  0  8 23  8  0  0  1 10  3  3  3 10  0  0 25 15 10 11 29
 10  3  8  3 29 15  8  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 21. 30. 15. 28.  8.  3.  8.  2.  0.  8.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [10.  1.  0. 29.  8.] 
adversary cards in discard: [11.  0. 11.  3. 16.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29  0 25  3 10 11  4  0 11  0] -> size -> 61 
adversary victory points: 10
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1.] 
cards in discard: [15. 11.  8.  3. 23.  0.  8. 10.  0.  1.  1.  0. 15.  0.  8. 11. 10.  3.
  0. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 1  1  0 11  0  0  8 23  8  0  0  1 10  3  3  3 10  0  0 25 15 10 11 29
 10  3  8  3 29 15  8  0 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 21. 30. 15. 28.  8.  3.  8.  1.  0.  8.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [10.  1.  0. 29.  8.] 
adversary cards in discard: [11.  0. 11.  3. 16.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29  0 25  3 10 11  4  0 11  0] -> size -> 61 
adversary victory points: 10
player victory points: 5 





Player: 0 
cards in hand: [10.  1.  0. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.  8.] 
expected returns: [[ 9.991178]
 [ 9.911336]
 [11.512825]
 [10.802663]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  0. 29.  8.] 
cards in discard: [11.  0. 11.  3. 16.  6.  6.] 
cards in deck: 49 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29  0 25  3 10 11  4  0 11  0] -> size -> 61 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 21. 30. 15. 28.  8.  3.  8.  1.  0.  8.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [ 0.  8.  0. 10. 10.] 
adversary cards in discard: [15. 11.  8.  3. 23.  0.  8. 10.  0.  1.  1.  0. 15.  0.  8. 11. 10.  3.
  0. 11. 29.  3.  3.  1.] 
adversary owned cards: [ 1  1  0 11  0  0  8 23  8  0  0  1 10  3  3  3 10  0  0 25 15 10 11 29
 10  3  8  3 29 15  8  0 11] -> size -> 33 
adversary victory points: 5
player victory points: 10 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3874245285987854
desired expected reward: 11.287884712219238



action possibilites: [-1. 29.  8.] 
expected returns: [[12.283725]
 [13.944533]
 [13.177318]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 29.  8.  0.] 
cards in discard: [11.  0. 11.  3. 16.  6.  6.] 
cards in deck: 48 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  1 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15
  0 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0
 10  8  6 29  0 25  3 10 11  4  0 11  0] -> size -> 61 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 7. 21. 30. 15. 28.  8.  3.  8.  1.  0.  8.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [ 0.  8.  0. 10. 10.] 
adversary cards in discard: [15. 11.  8.  3. 23.  0.  8. 10.  0.  1.  1.  0. 15.  0.  8. 11. 10.  3.
  0. 11. 29.  3.  3.  1.] 
adversary owned cards: [ 1  1  0 11  0  0  8 23  8  0  0  1 10  3  3  3 10  0  0 25 15 10 11 29
 10  3  8  3 29 15  8  0 11] -> size -> 33 
adversary victory points: 5
player victory points: 10 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.29227903485298157
desired expected reward: 10.203615188598633



action possibilites: [-1. 29.] 
expected returns: [[8.358843]
 [9.615722]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.] 
cards in discard: [11.  0. 11.  3. 16.  6.  6.] 
cards in deck: 48 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  3  3  3 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15  0
 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0 10
  8  6 29  0 25  3 10 11  4  0 11  0] -> size -> 60 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 21. 30. 15. 28.  8.  3.  8.  1.  0.  8.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [ 0.  8.  0. 10. 10.] 
adversary cards in discard: [15. 11.  8.  3. 23.  0.  8. 10.  0.  1.  1.  0. 15.  0.  8. 11. 10.  3.
  0. 11. 29.  3.  3.  1.] 
adversary owned cards: [ 1  1  0 11  0  0  8 23  8  0  0  1 10  3  3  3 10  0  0 25 15 10 11 29
 10  3  8  3 29 15  8  0 11] -> size -> 33 
adversary victory points: 5
player victory points: 10 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: trash_cards_n_from_hand - action 1
Learning step: 0.7629844546318054
desired expected reward: 13.519709587097168





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[7.600716 ]
 [7.9707847]
 [6.1404057]
 [8.328749 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.] 
cards in discard: [11.  0. 11.  3. 16.  6.  6.] 
cards in deck: 48 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  3  3  3 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15  0
 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0 10
  8  6 29  0 25  3 10 11  4  0 11  0] -> size -> 60 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 21. 30. 15. 28.  8.  3.  8.  1.  0.  8.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [ 0.  8.  0. 10. 10.] 
adversary cards in discard: [15. 11.  8.  3. 23.  0.  8. 10.  0.  1.  1.  0. 15.  0.  8. 11. 10.  3.
  0. 11. 29.  3.  3.  1.] 
adversary owned cards: [ 1  1  0 11  0  0  8 23  8  0  0  1 10  3  3  3 10  0  0 25 15 10 11 29
 10  3  8  3 29 15  8  0 11] -> size -> 33 
adversary victory points: 5
player victory points: 10 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.8798105120658875
desired expected reward: 9.238653182983398






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 10. 10.] 
cards in discard: [15. 11.  8.  3. 23.  0.  8. 10.  0.  1.  1.  0. 15.  0.  8. 11. 10.  3.
  0. 11. 29.  3.  3.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  0 11  0  0  8 23  8  0  0  1 10  3  3  3 10  0  0 25 15 10 11 29
 10  3  8  3 29 15  8  0 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 21. 30. 15. 28.  8.  3.  8.  1.  0.  8.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [15.  0.  3.  3.  1.] 
adversary cards in discard: [11.  0. 11.  3. 16.  6.  6. 10.  8.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15  0
 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0 10
  8  6 29  0 25  3 10 11  4  0 11  0] -> size -> 60 
adversary victory points: 10
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 10. 10.] 
cards in discard: [15. 11.  8.  3. 23.  0.  8. 10.  0.  1.  1.  0. 15.  0.  8. 11. 10.  3.
  0. 11. 29.  3.  3.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  0 11  0  0  8 23  8  0  0  1 10  3  3  3 10  0  0 25 15 10 11 29
 10  3  8  3 29 15  8  0 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 21. 30. 15. 28.  8.  3.  8.  1.  0.  8.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [15.  0.  3.  3.  1.] 
adversary cards in discard: [11.  0. 11.  3. 16.  6.  6. 10.  8.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15  0
 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0 10
  8  6 29  0 25  3 10 11  4  0 11  0] -> size -> 60 
adversary victory points: 10
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [15.  0.  3.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[8.969506]
 [9.135101]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  3.  3.  1.] 
cards in discard: [11.  0. 11.  3. 16.  6.  6. 10.  8.  0. 29.  0.] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15  0
 16  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0 10
  8  6 29  0 25  3 10 11  4  0 11  0] -> size -> 60 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 21. 30. 15. 28.  8.  3.  8.  1.  0.  8.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [10.  0. 29.  3. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  1  0 11  0  0  8 23  8  0  0  1 10  3  3  3 10  0  0 25 15 10 11 29
 10  3  8  3 29 15  8  0 11] -> size -> 33 
adversary victory points: 5
player victory points: 10 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.30463936924934387
desired expected reward: 8.02410888671875



action possibilites: [-1] 
expected returns: [[7.138844]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 1.] 
cards in discard: [11.  0. 11.  3. 16.  6.  6. 10.  8.  0. 29.  0.] 
cards in deck: 43 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15  0 16
  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0 10  8
  6 29  0 25  3 10 11  4  0 11  0] -> size -> 59 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 7. 21. 30. 15. 28.  8.  3.  8.  1.  0.  8.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [10.  0. 29.  3. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  1  0 11  0  0  8 23  8  0  0  1 10  3  3  3 10  0  0 25 15 10 11 29
 10  3  8  3 29 15  8  0 11] -> size -> 33 
adversary victory points: 5
player victory points: 10 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: 0.2509048283100128
desired expected reward: 9.386006355285645





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[6.375595 ]
 [7.5331655]
 [6.748733 ]
 [5.5263925]
 [4.91213  ]
 [6.6927285]
 [8.312892 ]
 [9.561864 ]
 [8.482412 ]
 [6.1705856]
 [6.1959724]
 [5.1667237]
 [7.2893496]
 [7.138844 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1.] 
cards in discard: [11.  0. 11.  3. 16.  6.  6. 10.  8.  0. 29.  0.] 
cards in deck: 43 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15  0 16
  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0 10  8
  6 29  0 25  3 10 11  4  0 11  0] -> size -> 59 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 7. 21. 30. 15. 28.  8.  3.  8.  1.  0.  8.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [10.  0. 29.  3. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  1  0 11  0  0  8 23  8  0  0  1 10  3  3  3 10  0  0 25 15 10 11 29
 10  3  8  3 29 15  8  0 11] -> size -> 33 
adversary victory points: 5
player victory points: 10 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.3135790228843689
desired expected reward: 7.452423095703125



buy possibilites: [-1] 
expected returns: [[5.0741305]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1.] 
cards in discard: [11.  0. 11.  3. 16.  6.  6. 10.  8.  0. 29.  0. 25.] 
cards in deck: 43 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15  0 16
  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0 10  8
  6 29  0 25  3 10 11  4  0 11  0 25] -> size -> 60 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 21. 30. 15. 28.  8.  3.  8.  1.  0.  7.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [10.  0. 29.  3. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 1  1  0 11  0  0  8 23  8  0  0  1 10  3  3  3 10  0  0 25 15 10 11 29
 10  3  8  3 29 15  8  0 11] -> size -> 33 
adversary victory points: 5
player victory points: 10 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -25   0   0  50   0] 
sum of rewards: 40 

action type: buy - action 25.0
Learning step: 0.9664224982261658
desired expected reward: 10.52828598022461






         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [10.  0. 29.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 25.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29.  3. 25.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  0 11  0  0  8 23  8  0  0  1 10  3  3  3 10  0  0 25 15 10 11 29
 10  3  8  3 29 15  8  0 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 21. 30. 15. 28.  8.  3.  8.  1.  0.  7.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [11.  0. 11.  3. 16.  6.  6. 10.  8.  0. 29.  0. 25. 15.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  3  3  3 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15  0 16
  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0 10  8
  6 29  0 25  3 10 11  4  0 11  0 25] -> size -> 60 
adversary victory points: 10
player victory points: 5 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8.] 
cards in discard: [10. 25.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 1  1  0 11  0  0  8 23  8  0  0  1 10  3  3  3 10  0  0 25 15 10 11 29
 10  3  8  3 29 15  8  0 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 7. 21. 30. 15. 28.  8.  3.  8.  1.  0.  7.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [11.  0. 11.  3. 16.  6.  6. 10.  8.  0. 29.  0. 25. 15.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  3  3  3 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15  0 16
  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0 10  8
  6 29  0 25  3 10 11  4  0 11  0 25] -> size -> 60 
adversary victory points: 10
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8.] 
cards in discard: [10. 25.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 1  1  0 11  0  0  8 23  8  0  0  1 10  3  3  3 10  0  0 25 15 10 11 29
 10  3  8  3 29 15  8  0 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 21. 30. 15. 28.  8.  3.  8.  1.  0.  7.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [11.  0. 11.  3. 16.  6.  6. 10.  8.  0. 29.  0. 25. 15.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  3  3  3 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15  0 16
  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0 10  8
  6 29  0 25  3 10 11  4  0 11  0 25] -> size -> 60 
adversary victory points: 10
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8.] 
cards in discard: [10. 25.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 1  1  0 11  0  0  8 23  8  0  0  1 10  3  3  3 10  0  0 25 15 10 11 29
 10  3  8  3 29 15  8  0 11  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 21. 30. 14. 28.  8.  3.  8.  1.  0.  7.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [11.  0. 11.  3. 16.  6.  6. 10.  8.  0. 29.  0. 25. 15.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  3  3  3 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15  0 16
  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0 10  8
  6 29  0 25  3 10 11  4  0 11  0 25] -> size -> 60 
adversary victory points: 10
player victory points: 6 





Player: 0 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[12.026883]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [11.  0. 11.  3. 16.  6.  6. 10.  8.  0. 29.  0. 25. 15.  3.  3.  1.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15  0 16
  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0 10  8
  6 29  0 25  3 10 11  4  0 11  0 25] -> size -> 60 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 21. 30. 14. 28.  8.  3.  8.  1.  0.  7.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [ 8.  1. 10.  0. 11.] 
adversary cards in discard: [10. 25.  3. 29.  0.  3.  8.] 
adversary owned cards: [ 1  1  0 11  0  0  8 23  8  0  0  1 10  3  3  3 10  0  0 25 15 10 11 29
 10  3  8  3 29 15  8  0 11  3] -> size -> 34 
adversary victory points: 6
player victory points: 10 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.17594163119792938
desired expected reward: 4.898189067840576





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. -1.] 
expected returns: [[11.149024]
 [12.445033]
 [11.591645]
 [ 9.399898]
 [13.2585  ]
 [12.026885]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [11.  0. 11.  3. 16.  6.  6. 10.  8.  0. 29.  0. 25. 15.  3.  3.  1.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15  0 16
  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0 10  8
  6 29  0 25  3 10 11  4  0 11  0 25] -> size -> 60 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 21. 30. 14. 28.  8.  3.  8.  1.  0.  7.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [ 8.  1. 10.  0. 11.] 
adversary cards in discard: [10. 25.  3. 29.  0.  3.  8.] 
adversary owned cards: [ 1  1  0 11  0  0  8 23  8  0  0  1 10  3  3  3 10  0  0 25 15 10 11 29
 10  3  8  3 29 15  8  0 11  3] -> size -> 34 
adversary victory points: 6
player victory points: 10 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.38514426350593567
desired expected reward: 11.641738891601562



buy possibilites: [-1] 
expected returns: [[9.620963]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [11.  0. 11.  3. 16.  6.  6. 10.  8.  0. 29.  0. 25. 15.  3.  3.  1.  6.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15  0 16
  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0 10  8
  6 29  0 25  3 10 11  4  0 11  0 25  6] -> size -> 61 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 7. 21. 30. 14. 28.  8.  2.  8.  1.  0.  7.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [ 8.  1. 10.  0. 11.] 
adversary cards in discard: [10. 25.  3. 29.  0.  3.  8.] 
adversary owned cards: [ 1  1  0 11  0  0  8 23  8  0  0  1 10  3  3  3 10  0  0 25 15 10 11 29
 10  3  8  3 29 15  8  0 11  3] -> size -> 34 
adversary victory points: 6
player victory points: 9 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  -26.
    0. -300.    0.    0.] 
sum of rewards: -331.0 

action type: buy - action 6.0
Learning step: -10.110976219177246
desired expected reward: -0.7110795974731445






         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [ 8.  1. 10.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1. 10.  0. 11.] 
cards in discard: [10. 25.  3. 29.  0.  3.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 1  1  0 11  0  0  8 23  8  0  0  1 10  3  3  3 10  0  0 25 15 10 11 29
 10  3  8  3 29 15  8  0 11  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 21. 30. 14. 28.  8.  2.  8.  1.  0.  7.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [10.  3.  0. 11.  4.] 
adversary cards in discard: [11.  0. 11.  3. 16.  6.  6. 10.  8.  0. 29.  0. 25. 15.  3.  3.  1.  6.
  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15  0 16
  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0 10  8
  6 29  0 25  3 10 11  4  0 11  0 25  6] -> size -> 61 
adversary victory points: 9
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.] 
cards in discard: [10. 25.  3. 29.  0.  3.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  1  0  0  8 23  8  0  0  1 10  3  3  3 10  0  0 25 15 10 11 29 10  3
  8  3 29 15  8  0 11  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 21. 30. 14. 28.  8.  2.  8.  1.  0.  7.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [10.  3.  0. 11.  4.] 
adversary cards in discard: [11.  0. 11.  3. 16.  6.  6. 10.  8.  0. 29.  0. 25. 15.  3.  3.  1.  6.
  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15  0 16
  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0 10  8
  6 29  0 25  3 10 11  4  0 11  0 25  6] -> size -> 61 
adversary victory points: 9
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.] 
cards in discard: [10. 25.  3. 29.  0.  3.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  1  0  0  8 23  8  0  0  1 10  3  3  3 10  0  0 25 15 10 11 29 10  3
  8  3 29 15  8  0 11  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 21. 30. 14. 28.  8.  2.  8.  1.  0.  7.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [10.  3.  0. 11.  4.] 
adversary cards in discard: [11.  0. 11.  3. 16.  6.  6. 10.  8.  0. 29.  0. 25. 15.  3.  3.  1.  6.
  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15  0 16
  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0 10  8
  6 29  0 25  3 10 11  4  0 11  0 25  6] -> size -> 61 
adversary victory points: 9
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.] 
cards in discard: [10. 25.  3. 29.  0.  3.  8.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1  1  0  0  8 23  8  0  0  1 10  3  3  3 10  0  0 25 15 10 11 29 10  3
  8  3 29 15  8  0 11  3  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 21. 30. 14. 28.  8.  2.  8.  1.  0.  7.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [10.  3.  0. 11.  4.] 
adversary cards in discard: [11.  0. 11.  3. 16.  6.  6. 10.  8.  0. 29.  0. 25. 15.  3.  3.  1.  6.
  0.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15  0 16
  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0 10  8
  6 29  0 25  3 10 11  4  0 11  0 25  6] -> size -> 61 
adversary victory points: 9
player victory points: 6 





Player: 0 
cards in hand: [10.  3.  0. 11.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[6.423681]
 [6.365704]
 [7.346053]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0. 11.  4.] 
cards in discard: [11.  0. 11.  3. 16.  6.  6. 10.  8.  0. 29.  0. 25. 15.  3.  3.  1.  6.
  0.  3.  0.  3.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15  0 16
  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0 10  8
  6 29  0 25  3 10 11  4  0 11  0 25  6] -> size -> 61 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 21. 30. 14. 28.  8.  2.  8.  1.  0.  7.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [ 0. 10.  3. 29.  3.] 
adversary cards in discard: [10. 25.  3. 29.  0.  3.  8.  0.  8.  1. 10.] 
adversary owned cards: [ 1  1  0  0  8 23  8  0  0  1 10  3  3  3 10  0  0 25 15 10 11 29 10  3
  8  3 29 15  8  0 11  3  0] -> size -> 33 
adversary victory points: 6
player victory points: 9 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3668229579925537
desired expected reward: 9.25413990020752



Player 0 won the game! 



Player 0 bought cards:
Copper: 8 
Silver: 3 
Gold: 0 
Estate: 7 
Duchy: 2 
Province: 0 
Curse: 7 

Remodel: 2 
Workshop: 5 
Chapel: 2 
Witch: 2 
Poacher: 3 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [10.  3.  0.  4.] 
cards in discard: [11.  0. 11.  3. 16.  6.  6. 10.  8.  0. 29.  0. 25. 15.  3.  3.  1.  6.
  0.  3.  0.  3.  0. 11.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3 11  3  1  4 29 16 11 14 29  3  0  1  3  6  0 15  0 16
  3  1 11  0  8  3  1  6  0 15  3  8  6  0 11 29  6  0 10  6 10  0 10  8
  6 29  0 25  3 10 11  4  0 11  0 25  6 11] -> size -> 62 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 21. 30. 14. 28.  8.  2.  8.  0.  0.  7.  4.  8.  8.  0. 10.  5.] 
adversary cards in hand: [ 0. 10.  3. 29.  3.] 
adversary cards in discard: [10. 25.  3. 29.  0.  3.  8.  0.  8.  1. 10.] 
adversary owned cards: [ 1  1  0  0  8 23  8  0  0  1 10  3  3  3 10  0  0 25 15 10 11 29 10  3
  8  3 29 15  8  0 11  3  0] -> size -> 33 
adversary victory points: 6
player victory points: 9 

Reward from previous game state: 
[ -5 500   0   0   0   0  20   0   0   0   0 -27   0   0   9   0] 
sum of rewards: 497 

action type: gain_card_n - action 5
Learning step: 14.733755111694336
desired expected reward: 20.608579635620117



