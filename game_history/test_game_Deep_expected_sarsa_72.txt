 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[67.77351]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -120        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000125 

action type: discard_down_to_3_cards - action 1
Learning step: -119999.9296875
desired expected reward: -120126.6953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[48.628643]
 [60.225517]
 [11.590317]
 [70.24768 ]
 [67.10045 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 70.79408264160156



buy possibilites: [-1] 
expected returns: [[72.469246]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 16  0] 
sum of rewards: 11 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 70.24769592285156






Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [8. 0. 3. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [8. 0. 3. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [8. 0. 3. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[72.68277]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [8. 0. 3. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [1. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 72.46924591064453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 55.666595]
 [ 83.9847  ]
 [ 66.52243 ]
 [ 32.91258 ]
 [ 18.086727]
 [ 73.85914 ]
 [ 88.91886 ]
 [ 76.62544 ]
 [128.21237 ]
 [101.20735 ]
 [ 37.217834]
 [ 61.24939 ]
 [ 60.02726 ]
 [ 34.732395]
 [ 63.76554 ]
 [ 73.316895]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [8. 0. 3. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [1. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 73.22535705566406



buy possibilites: [-1] 
expected returns: [[52.332657]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 8.  0.  3.  3.  0.  3. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [1. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 250   0] 
sum of rewards: 245 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 128.21237182617188






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [1. 3. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [1. 3. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [1. 3. 0. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 0] -> size -> 12 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[68.45903]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 52.33265686035156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[51.368084]
 [80.20805 ]
 [62.89601 ]
 [13.333982]
 [70.37068 ]
 [84.97786 ]
 [73.128876]
 [96.5465  ]
 [32.574177]
 [55.839314]
 [59.91085 ]
 [69.951416]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 70.45272827148438



buy possibilites: [-1] 
expected returns: [[71.28869]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 96.54651641845703






Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 8. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 0] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 8. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 0 0] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 8. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[85.2872 ]
 [88.15974]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 8. 0.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 25 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 71.28868865966797



action possibilites: [-1] 
expected returns: [[71.64184]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0 0] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 86.51451110839844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[57.06695 ]
 [81.25522 ]
 [66.89124 ]
 [22.69832 ]
 [85.23386 ]
 [75.375046]
 [61.02491 ]
 [72.78593 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0 0] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 71.64183807373047



buy possibilites: [-1] 
expected returns: [[63.579582]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [29.  0.  0.  0.  0.  3. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  9.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0 0] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 85.23387145996094






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 3. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 0 0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  9.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11] -> size -> 13 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 3. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 0 0] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  9.  9.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11] -> size -> 13 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 0. 0. 3. 3. 0. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 0 0 8] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  9.  8.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11] -> size -> 13 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[ 65.549545]
 [112.00401 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 25.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  9.  8.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0 0 8] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 63.57958221435547



action possibilites: [-1] 
expected returns: [[52.60202]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3. 8.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  9.  8.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0 0 8 6] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 112.06301879882812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[39.072952 ]
 [62.180824 ]
 [48.453945 ]
 [ 6.3437324]
 [66.263565 ]
 [56.534603 ]
 [42.859524 ]
 [54.155117 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3. 8.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  9.  8.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0 0 8 6] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 52.602020263671875



buy possibilites: [-1] 
expected returns: [[34.66162]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3. 8.] 
cards in discard: [11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  8.  8.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0 0 8 6] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 66.26355743408203






Player: 1 
cards in hand: [0. 0. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 0 0 8 6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  8.  8.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0.  0.] 
adversary cards in discard: [11. 25.  0.  0.  0.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11] -> size -> 14 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 0 0 8 6] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  8.  8.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0.  0.] 
adversary cards in discard: [11. 25.  0.  0.  0.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11] -> size -> 14 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [ 6. 22.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  8.  8.  9.  9. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0. 29.  0.  0.  0.] 
adversary cards in discard: [11. 25.  0.  0.  0.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11] -> size -> 14 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[69.0118 ]
 [92.73195]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.  0.] 
cards in discard: [11. 25.  0.  0.  0.  3.  3.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  8.  8.  9.  9. 10. 10. 10.  9. 10.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [ 6. 22.  0.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22] -> size -> 16 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 34.66162109375



action possibilites: [-1. 11.] 
expected returns: [[67.86282]
 [80.26913]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [11. 25.  0.  0.  0.  3.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  8.  8.  9.  9. 10. 10. 10.  9. 10.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [ 6. 22.  0.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22] -> size -> 16 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 91.21217346191406



action possibilites: [-1] 
expected returns: [[84.857544]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [11. 25.  0.  0.  0.  3.  3.  8. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  8.  8.  9.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [ 6. 22.  0.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22] -> size -> 16 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 94.83409118652344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 73.50959 ]
 [ 98.42453 ]
 [ 83.07112 ]
 [ 53.24722 ]
 [ 39.28759 ]
 [ 89.66489 ]
 [102.67084 ]
 [ 92.11429 ]
 [136.37173 ]
 [112.99064 ]
 [ 57.090202]
 [ 78.43055 ]
 [ 77.352585]
 [ 54.875317]
 [ 80.64546 ]
 [ 89.21257 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [11. 25.  0.  0.  0.  3.  3.  8. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  8.  8.  9.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [ 6. 22.  0.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22] -> size -> 16 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 84.8575439453125



buy possibilites: [-1] 
expected returns: [[116.00567]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [11. 25.  0.  0.  0.  3.  3.  8. 10. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  8.  8.  8.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [ 6. 22.  0.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22] -> size -> 16 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 285 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 136.37168884277344






Player: 1 
cards in hand: [3. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [ 6. 22.  0.  0.  3.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  8.  8.  8.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [11. 29.  0. 10. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25] -> size -> 16 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [ 6. 22.  0.  0.  3.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  8.  8.  8.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [11. 29.  0. 10. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25] -> size -> 16 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [ 6. 22.  0.  0.  3.  0.  1. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  7.  8.  8.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [11. 29.  0. 10. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25] -> size -> 16 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [11. 29.  0. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10. 25.] 
expected returns: [[25.655546]
 [38.913292]
 [49.43453 ]
 [13.585073]
 [71.96287 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  0. 10. 25.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  7.  8.  8.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11] -> size -> 17 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 116.00566864013672



action possibilites: [-1] 
expected returns: [[31.40338]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  0. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  8. 10.  7.  8.  8.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6] -> size -> 18 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 70.26411437988281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[20.873007 ]
 [42.610054 ]
 [29.724443 ]
 [-7.9451427]
 [46.18653  ]
 [37.3351   ]
 [24.449493 ]
 [35.16204  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29.  0. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8.  8. 10.  7.  8.  8.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6] -> size -> 18 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 31.403379440307617



buy possibilites: [-1] 
expected returns: [[40.326363]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29.  0. 10.  0.  0.] 
cards in discard: [11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  8. 10.  6.  8.  8.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6] -> size -> 18 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 46.18653106689453






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  8. 10.  6.  8.  8.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [11. 25. 11. 29.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11] -> size -> 17 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 30. 30.  8.  8. 10.  6.  8.  8.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [11. 25. 11. 29.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11] -> size -> 17 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 6. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8.  8. 10.  5.  8.  8.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [11. 25. 11. 29.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11] -> size -> 17 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[44.353905]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [11. 25. 11. 29.  0. 10.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  8. 10.  5.  8.  8.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 0.  1.  3.  0. 11.] 
adversary cards in discard: [ 6. 11.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11] -> size -> 19 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 40.32636260986328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[34.351757]
 [52.907703]
 [41.89632 ]
 [ 9.147242]
 [56.0682  ]
 [48.4061  ]
 [37.394726]
 [46.433197]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [11. 25. 11. 29.  0. 10.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8.  8. 10.  5.  8.  8.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 0.  1.  3.  0. 11.] 
adversary cards in discard: [ 6. 11.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11] -> size -> 19 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 40.91969299316406



buy possibilites: [-1] 
expected returns: [[59.61946]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [11. 25. 11. 29.  0. 10.  0.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  8. 10.  4.  8.  8.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 0.  1.  3.  0. 11.] 
adversary cards in discard: [ 6. 11.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11] -> size -> 19 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 79 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 56.06819152832031






Player: 1 
cards in hand: [ 0.  1.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3.  0. 11.] 
cards in discard: [ 6. 11.  0.  0.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  8. 10.  4.  8.  8.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 3. 11. 25.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11] -> size -> 18 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 0.] 
cards in discard: [ 6. 11.  0.  0.  0.  3.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  7. 10.  4.  8.  8.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 3. 11. 25.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11] -> size -> 18 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0.] 
cards in discard: [ 6. 11.  0.  0.  0.  3.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 30. 30.  8.  7. 10.  4.  8.  8.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 3. 11. 25.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11] -> size -> 18 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0.] 
cards in discard: [ 6. 11.  0.  0.  0.  3.  0.  6.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 30. 30.  8.  7. 10.  4.  8.  8.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 3. 11. 25.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11] -> size -> 18 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 3. 11. 25.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.  8.] 
expected returns: [[38.927795]
 [50.363697]
 [80.4106  ]
 [41.151634]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 25.  8.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8.  7. 10.  4.  8.  8.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 0.  0.  6.  3. 22.] 
adversary cards in discard: [ 6. 11.  0.  0.  0.  3.  0.  6.  1. 11.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1] -> size -> 21 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 59.61946105957031



action possibilites: [-1] 
expected returns: [[13.67967]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  8.  0. 11. 11.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8.  6. 10.  4.  8.  8.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 0.  0.  6.  3. 22.] 
adversary cards in discard: [ 6. 11.  0.  0.  0.  3.  0.  6.  1. 11.  0.  1.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6] -> size -> 22 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 78.94585418701172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[  8.73649 ]
 [-15.561316]
 [ 19.81824 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  8.  0. 11. 11.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 28. 30. 30. 30.  8.  6. 10.  4.  8.  8.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 0.  0.  6.  3. 22.] 
adversary cards in discard: [ 6. 11.  0.  0.  0.  3.  0.  6.  1. 11.  0.  1.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6] -> size -> 22 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 13.679670333862305






Player: 1 
cards in hand: [ 0.  0.  6.  3. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6.  3. 22.] 
cards in discard: [ 6. 11.  0.  0.  0.  3.  0.  6.  1. 11.  0.  1.  3.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8.  6. 10.  4.  8.  8.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 3. 10. 25.  0. 11.] 
adversary cards in discard: [25.  3. 11.  8.  0. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11] -> size -> 18 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6.  3. 22.] 
cards in discard: [ 6. 11.  0.  0.  0.  3.  0.  6.  1. 11.  0.  1.  3.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 30. 30.  8.  6. 10.  4.  8.  8.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 3. 10. 25.  0. 11.] 
adversary cards in discard: [25.  3. 11.  8.  0. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11] -> size -> 18 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6.  3. 22.] 
cards in discard: [ 6. 11.  0.  0.  0.  3.  0.  6.  1. 11.  0.  1.  3.  0.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 30. 30.  8.  6. 10.  4.  8.  8.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 3. 10. 25.  0. 11.] 
adversary cards in discard: [25.  3. 11.  8.  0. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11] -> size -> 18 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 25.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 11.] 
expected returns: [[ 6.4885144]
 [-2.368451 ]
 [40.02339  ]
 [16.146872 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 25.  0. 11.] 
cards in discard: [25.  3. 11.  8.  0. 11. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8.  6. 10.  4.  8.  8.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [6. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0] -> size -> 23 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 19.8182430267334



action possibilites: [-1] 
expected returns: [[23.92908]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0. 11.  0.  0.] 
cards in discard: [25.  3. 11.  8.  0. 11. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8.  5. 10.  4.  8.  8.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [6. 0. 0. 0. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6] -> size -> 24 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 35.4666862487793





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[17.108406]
 [33.934513]
 [23.95609 ]
 [-7.319401]
 [36.701725]
 [29.85404 ]
 [19.875624]
 [28.122976]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0. 11.  0.  0.] 
cards in discard: [25.  3. 11.  8.  0. 11. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 30. 30.  8.  5. 10.  4.  8.  8.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [6. 0. 0. 0. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6] -> size -> 24 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 23.929079055786133



buy possibilites: [-1] 
expected returns: [[36.8565]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0. 11.  0.  0.] 
cards in discard: [25.  3. 11.  8.  0. 11. 11. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8.  5. 10.  3.  8.  8.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [6. 0. 0. 0. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6] -> size -> 24 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 159 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 36.70173645019531






Player: 1 
cards in hand: [6. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0. 8.] 
cards in discard: [6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8.  5. 10.  3.  8.  8.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 3. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11] -> size -> 19 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 8.] 
cards in discard: [6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 30. 30.  8.  5. 10.  3.  8.  8.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 3. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11] -> size -> 19 
adversary victory points: 2
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 3. 29.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-18.334541 ]
 [  0.5754051]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8.  5. 10.  3.  8.  8.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [1. 0. 6. 0. 3.] 
adversary cards in discard: [6. 6. 0. 0. 0. 8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6] -> size -> 24 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 36.85649871826172



action possibilites: [-1.] 
expected returns: [[10.977587]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 30. 30.  8.  5. 10.  3.  8.  8.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [1. 0. 6. 0. 3.] 
adversary cards in discard: [6. 6. 0. 0. 0. 8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6] -> size -> 24 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: -1.9605379104614258





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[  3.0577836]
 [ 18.840105 ]
 [  9.4846325]
 [-10.490484 ]
 [-19.845953 ]
 [ 13.498686 ]
 [ 21.967606 ]
 [ 15.010214 ]
 [ 46.748985 ]
 [ 29.770075 ]
 [ -7.8935146]
 [  6.3772874]
 [  5.6547446]
 [ -9.405045 ]
 [  7.888819 ]
 [ 13.436352 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 28. 30. 30. 30.  8.  5. 10.  3.  8.  8.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [1. 0. 6. 0. 3.] 
adversary cards in discard: [6. 6. 0. 0. 0. 8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6] -> size -> 24 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 10.97758674621582



buy possibilites: [-1] 
expected returns: [[54.403305]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8.  5. 10.  3.  8.  7.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [1. 0. 6. 0. 3.] 
adversary cards in discard: [6. 6. 0. 0. 0. 8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6] -> size -> 24 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 385 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 46.749000549316406






Player: 1 
cards in hand: [1. 0. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 6. 0. 3.] 
cards in discard: [6. 6. 0. 0. 0. 8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8.  5. 10.  3.  8.  7.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 3.  8. 11. 11. 25.] 
adversary cards in discard: [25. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25] -> size -> 20 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6. 0. 3.] 
cards in discard: [6. 6. 0. 0. 0. 8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 28. 30. 30. 30.  8.  5. 10.  3.  8.  7.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 3.  8. 11. 11. 25.] 
adversary cards in discard: [25. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25] -> size -> 20 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6. 0. 3.] 
cards in discard: [6. 6. 0. 0. 0. 8. 1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 30. 30.  8.  5. 10.  3.  8.  7.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 3.  8. 11. 11. 25.] 
adversary cards in discard: [25. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25] -> size -> 20 
adversary victory points: 2
player victory points: -2 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 3.  8. 11. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 11. 25.] 
expected returns: [[50.266144]
 [52.18661 ]
 [59.97351 ]
 [59.97351 ]
 [84.163246]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 11. 11. 25.] 
cards in discard: [25. 29.  3.  0.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 30. 30.  8.  5. 10.  3.  8.  7.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [0. 3. 3. 0. 6.] 
adversary cards in discard: [6. 6. 0. 0. 0. 8. 1. 1. 0. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1] -> size -> 25 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 54.40330505371094



action possibilites: [-1] 
expected returns: [[60.337708]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 11. 11.  0. 11.] 
cards in discard: [25. 29.  3.  0.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 30. 30.  8.  4. 10.  3.  8.  7.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [0. 3. 3. 0. 6.] 
adversary cards in discard: [6. 6. 0. 0. 0. 8. 1. 1. 0. 6. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6] -> size -> 26 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 81.23658752441406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[46.028988]
 [21.142124]
 [57.316902]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 11. 11.  0. 11.] 
cards in discard: [25. 29.  3.  0.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 27. 30. 30. 30.  8.  4. 10.  3.  8.  7.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [0. 3. 3. 0. 6.] 
adversary cards in discard: [6. 6. 0. 0. 0. 8. 1. 1. 0. 6. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6] -> size -> 26 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 60.33770751953125






Player: 1 
cards in hand: [0. 3. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 6.] 
cards in discard: [6. 6. 0. 0. 0. 8. 1. 1. 0. 6. 0. 3. 6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 30. 30.  8.  4. 10.  3.  8.  7.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 0. 10. 11. 11. 25.] 
adversary cards in discard: [25. 29.  3.  0.  0.  0.  0. 25.  3.  8. 11. 11.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25] -> size -> 20 
adversary victory points: 2
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 6.] 
cards in discard: [6. 6. 0. 0. 0. 8. 1. 1. 0. 6. 0. 3. 6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 30. 30.  8.  4. 10.  3.  8.  7.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 0. 10. 11. 11. 25.] 
adversary cards in discard: [25. 29.  3.  0.  0.  0.  0. 25.  3.  8. 11. 11.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25] -> size -> 20 
adversary victory points: 2
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 6.] 
cards in discard: [6. 6. 0. 0. 0. 8. 1. 1. 0. 6. 0. 3. 6. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 27. 30. 30. 30.  8.  4. 10.  3.  8.  7.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 0. 10. 11. 11. 25.] 
adversary cards in discard: [25. 29.  3.  0.  0.  0.  0. 25.  3.  8. 11. 11.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25] -> size -> 20 
adversary victory points: 2
player victory points: -3 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 11. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11. 25.] 
expected returns: [[-13.534437]
 [-24.355814]
 [ -2.25138 ]
 [ -2.25138 ]
 [ 25.486511]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 11. 25.] 
cards in discard: [25. 29.  3.  0.  0.  0.  0. 25.  3.  8. 11. 11.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 30. 30.  8.  4. 10.  3.  8.  7.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 0. 11. 22.  6.  0.] 
adversary cards in discard: [6. 6. 0. 0. 0. 8. 1. 1. 0. 6. 0. 3. 6. 0. 0. 3. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0] -> size -> 27 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 57.31690979003906



action possibilites: [-1] 
expected returns: [[22.942999]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 11.  8.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 30. 30.  8.  3. 10.  3.  8.  7.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 0. 11. 22.  6.  0.] 
adversary cards in discard: [6. 6. 0. 0. 0. 8. 1. 1. 0. 6. 0. 3. 6. 0. 0. 3. 3. 0. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6] -> size -> 28 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 25.486528396606445





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[  5.198836]
 [ 12.709002]
 [-20.01463 ]
 [ 19.154238]
 [ 17.393953]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11. 11.  8.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 30. 30.  8.  3. 10.  3.  8.  7.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 0. 11. 22.  6.  0.] 
adversary cards in discard: [6. 6. 0. 0. 0. 8. 1. 1. 0. 6. 0. 3. 6. 0. 0. 3. 3. 0. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6] -> size -> 28 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 22.9429988861084



buy possibilites: [-1] 
expected returns: [[22.65964]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11. 11.  8.  0.] 
cards in discard: [8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 30. 30.  8.  3. 10.  3.  7.  7.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 0. 11. 22.  6.  0.] 
adversary cards in discard: [6. 6. 0. 0. 0. 8. 1. 1. 0. 6. 0. 3. 6. 0. 0. 3. 3. 0. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6] -> size -> 28 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 181 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 19.15424156188965






Player: 1 
cards in hand: [ 0. 11. 22.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 22.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 22.  6.  0.] 
cards in discard: [6. 6. 0. 0. 0. 8. 1. 1. 0. 6. 0. 3. 6. 0. 0. 3. 3. 0. 6. 6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 30. 30.  8.  3. 10.  3.  7.  7.  9. 10. 10.  9.  9. 10.] 
adversary cards in hand: [11. 25. 25.  0.  0.] 
adversary cards in discard: [ 8. 25.  0. 10. 11. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8] -> size -> 21 
adversary victory points: 2
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22.  6.  0.] 
cards in discard: [ 6.  6.  0.  0.  0.  8.  1.  1.  0.  6.  0.  3.  6.  0.  0.  3.  3.  0.
  6.  6. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6 29] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 30. 30.  8.  3. 10.  3.  7.  7.  8. 10. 10.  9.  9. 10.] 
adversary cards in hand: [11. 25. 25.  0.  0.] 
adversary cards in discard: [ 8. 25.  0. 10. 11. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8] -> size -> 21 
adversary victory points: 2
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 22.  6.  0.] 
cards in discard: [ 6.  6.  0.  0.  0.  8.  1.  1.  0.  6.  0.  3.  6.  0.  0.  3.  3.  0.
  6.  6. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6 29] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 30. 30.  8.  3. 10.  3.  7.  7.  8. 10. 10.  9.  9. 10.] 
adversary cards in hand: [11. 25. 25.  0.  0.] 
adversary cards in discard: [ 8. 25.  0. 10. 11. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8] -> size -> 21 
adversary victory points: 2
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 22.  6.  0.] 
cards in discard: [ 6.  6.  0.  0.  0.  8.  1.  1.  0.  6.  0.  3.  6.  0.  0.  3.  3.  0.
  6.  6. 29.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6 29  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 27. 30. 30. 30.  8.  3. 10.  3.  7.  7.  8. 10. 10.  9.  9. 10.] 
adversary cards in hand: [11. 25. 25.  0.  0.] 
adversary cards in discard: [ 8. 25.  0. 10. 11. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8] -> size -> 21 
adversary victory points: 2
player victory points: -4 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [11. 25. 25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 25.] 
expected returns: [[-21.157751 ]
 [-14.082205 ]
 [  3.9782834]
 [  3.9782834]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25. 25.  0.  0.] 
cards in discard: [ 8. 25.  0. 10. 11. 11.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 30. 30.  8.  3. 10.  3.  7.  7.  8. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 0.  0.  0.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6 29  0] -> size -> 30 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 22.659639358520508



action possibilites: [-1] 
expected returns: [[-28.008383]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25.  0.  0.  0.  3.] 
cards in discard: [ 8. 25.  0. 10. 11. 11.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 30. 30.  8.  2. 10.  3.  7.  7.  8. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 0.  0.  0.  1. 11.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6 29  0  6] -> size -> 31 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 3.978283405303955





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-40.554955]
 [-18.584045]
 [-32.15347 ]
 [-68.25651 ]
 [-14.293111]
 [-24.889196]
 [-37.15303 ]
 [-26.899904]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 25.  0.  0.  0.  3.] 
cards in discard: [ 8. 25.  0. 10. 11. 11.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 27. 30. 30. 30.  8.  2. 10.  3.  7.  7.  8. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 0.  0.  0.  1. 11.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6 29  0  6] -> size -> 31 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: -28.00838279724121



buy possibilites: [-1] 
expected returns: [[-8.99523]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 25.  0.  0.  0.  3.] 
cards in discard: [ 8. 25.  0. 10. 11. 11.  8.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 30. 30.  8.  2. 10.  2.  7.  7.  8. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 0.  0.  0.  1. 11.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6 29  0  6] -> size -> 31 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 249 

action type: buy - action 11.0
Learning step: 0
desired expected reward: -14.293100357055664






Player: 1 
cards in hand: [ 0.  0.  0.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  1. 11.] 
cards in discard: [6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6 29  0  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 30. 30.  8.  2. 10.  2.  7.  7.  8. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 3.  0. 11.  0. 29.] 
adversary cards in discard: [ 8. 25.  0. 10. 11. 11.  8.  0. 11. 25. 11. 25.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11] -> size -> 22 
adversary victory points: 2
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1.] 
cards in discard: [6. 1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6 29  0  6  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 30. 30.  8.  2. 10.  2.  7.  7.  8. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 3.  0. 11.  0. 29.] 
adversary cards in discard: [ 8. 25.  0. 10. 11. 11.  8.  0. 11. 25. 11. 25.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11] -> size -> 22 
adversary victory points: 2
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1.] 
cards in discard: [6. 1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6 29  0  6  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 26. 30. 30. 30.  8.  2. 10.  2.  7.  7.  8. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 3.  0. 11.  0. 29.] 
adversary cards in discard: [ 8. 25.  0. 10. 11. 11.  8.  0. 11. 25. 11. 25.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11] -> size -> 22 
adversary victory points: 2
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1.] 
cards in discard: [ 6.  1. 25.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6 29  0  6  1 25] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 30. 30.  8.  2. 10.  2.  7.  6.  8. 10. 10.  9.  9. 10.] 
adversary cards in hand: [ 3.  0. 11.  0. 29.] 
adversary cards in discard: [ 8. 25.  0. 10. 11. 11.  8.  0. 11. 25. 11. 25.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11] -> size -> 22 
adversary victory points: 2
player victory points: -5 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 11.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[11.600992]
 [18.999073]
 [24.999643]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0. 29.] 
cards in discard: [ 8. 25.  0. 10. 11. 11.  8.  0. 11. 25. 11. 25.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 30. 30.  8.  2. 10.  2.  7.  6.  8. 10. 10.  9.  9. 10.] 
adversary cards in hand: [1. 0. 6. 1. 0.] 
adversary cards in discard: [ 6.  1. 25. 11.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6 29  0  6  1 25] -> size -> 33 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: -8.995229721069336



action possibilites: [-1. 11. 11.] 
expected returns: [[18.890156]
 [26.021025]
 [26.021025]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0. 11.] 
cards in discard: [ 8. 25.  0. 10. 11. 11.  8.  0. 11. 25. 11. 25.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 30. 30.  8.  2. 10.  2.  7.  6.  8. 10. 10.  9.  9. 10.] 
adversary cards in hand: [1. 0. 6. 1. 0.] 
adversary cards in discard: [ 6.  1. 25. 11.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6 29  0  6  1 25] -> size -> 33 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 24.9996337890625



action possibilites: [-1] 
expected returns: [[-8.175676]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11.] 
cards in discard: [ 8. 25.  0. 10. 11. 11.  8.  0. 11. 25. 11. 25.  0.  0.  0.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 30. 30.  8.  2. 10.  2.  7.  6.  8. 10. 10.  8.  9. 10.] 
adversary cards in hand: [1. 0. 6. 1. 0.] 
adversary cards in discard: [ 6.  1. 25. 11.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6 29  0  6  1 25] -> size -> 33 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 272 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 34.339515686035156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-16.892662 ]
 [ -3.1918817]
 [-11.663601 ]
 [-32.516266 ]
 [ -0.8338795]
 [ -6.6565013]
 [-14.852373 ]
 [ -8.079747 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11.] 
cards in discard: [ 8. 25.  0. 10. 11. 11.  8.  0. 11. 25. 11. 25.  0.  0.  0.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 26. 30. 30. 30.  8.  2. 10.  2.  7.  6.  8. 10. 10.  8.  9. 10.] 
adversary cards in hand: [1. 0. 6. 1. 0.] 
adversary cards in discard: [ 6.  1. 25. 11.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6 29  0  6  1 25] -> size -> 33 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action -1
Learning step: 0
desired expected reward: -8.175676345825195



buy possibilites: [-1] 
expected returns: [[7.3147845]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11.] 
cards in discard: [ 8. 25.  0. 10. 11. 11.  8.  0. 11. 25. 11. 25.  0.  0.  0.  3. 10. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 30. 30.  8.  2. 10.  1.  7.  6.  8. 10. 10.  8.  9. 10.] 
adversary cards in hand: [1. 0. 6. 1. 0.] 
adversary cards in discard: [ 6.  1. 25. 11.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6 29  0  6  1 25] -> size -> 33 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 299 

action type: buy - action 11.0
Learning step: 0
desired expected reward: -0.8338665962219238






Player: 1 
cards in hand: [1. 0. 6. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 6. 1. 0.] 
cards in discard: [ 6.  1. 25. 11.  0.  0.  0.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6 29  0  6  1 25] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 30. 30.  8.  2. 10.  1.  7.  6.  8. 10. 10.  8.  9. 10.] 
adversary cards in hand: [10.  0. 11. 25. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10 11] -> size -> 24 
adversary victory points: 2
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6. 1. 0.] 
cards in discard: [ 6.  1. 25. 11.  0.  0.  0.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6 29  0  6  1 25] -> size -> 33 
action values: 0 
buys: 1 
player value: 6 
card supply: [25. 26. 30. 30. 30.  8.  2. 10.  1.  7.  6.  8. 10. 10.  8.  9. 10.] 
adversary cards in hand: [10.  0. 11. 25. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10 11] -> size -> 24 
adversary victory points: 2
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6. 1. 0.] 
cards in discard: [ 6.  1. 25. 11.  0.  0.  0.  1. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6 29  0  6  1 25 29] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 26. 30. 30. 30.  8.  2. 10.  1.  7.  6.  7. 10. 10.  8.  9. 10.] 
adversary cards in hand: [10.  0. 11. 25. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10 11] -> size -> 24 
adversary victory points: 2
player victory points: -5 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [10.  0. 11. 25. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 25. 11.] 
expected returns: [[-58.347675]
 [-66.73665 ]
 [-49.877995]
 [-30.996044]
 [-49.877995]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11. 25. 11.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 30. 30.  8.  2. 10.  1.  7.  6.  7. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 0. 29.  6.  0.  0.] 
adversary cards in discard: [ 6.  1. 25. 11.  0.  0.  0.  1. 29.  1.  0.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6 29  0  6  1 25 29] -> size -> 34 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 7.314784526824951



action possibilites: [-1] 
expected returns: [[-17.70068]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11. 11. 29. 10.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 30. 30.  8.  1. 10.  1.  7.  6.  7. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 0. 29.  6.  0.  0.] 
adversary cards in discard: [ 6.  1. 25. 11.  0.  0.  0.  1. 29.  1.  0.  6.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6 29  0  6  1 25 29  6] -> size -> 35 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -31.151704788208008





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-24.624907]
 [-43.185966]
 [-16.078196]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11. 11. 29. 10.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 26. 30. 30. 30.  8.  1. 10.  1.  7.  6.  7. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 0. 29.  6.  0.  0.] 
adversary cards in discard: [ 6.  1. 25. 11.  0.  0.  0.  1. 29.  1.  0.  6.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6 29  0  6  1 25 29  6] -> size -> 35 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: -17.700679779052734






Player: 1 
cards in hand: [ 0. 29.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  6.  0.  0.] 
cards in discard: [ 6.  1. 25. 11.  0.  0.  0.  1. 29.  1.  0.  6.  1.  0.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6 29  0  6  1 25 29  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 30. 30.  8.  1. 10.  1.  7.  6.  7. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 8.  0. 11.  3.  0.] 
adversary cards in discard: [25. 10.  0. 11. 11. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10 11] -> size -> 24 
adversary victory points: 2
player victory points: -6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 6.] 
cards in discard: [ 6.  1. 25. 11.  0.  0.  0.  1. 29.  1.  0.  6.  1.  0.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6 29  0  6  1 25 29  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 30. 30.  8.  1. 10.  1.  7.  6.  7. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 8.  0. 11.  3.  0.] 
adversary cards in discard: [25. 10.  0. 11. 11. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10 11] -> size -> 24 
adversary victory points: 2
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 6.] 
cards in discard: [ 6.  1. 25. 11.  0.  0.  0.  1. 29.  1.  0.  6.  1.  0.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6 29  0  6  1 25 29  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 26. 30. 30. 30.  8.  1. 10.  1.  7.  6.  7. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 8.  0. 11.  3.  0.] 
adversary cards in discard: [25. 10.  0. 11. 11. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10 11] -> size -> 24 
adversary victory points: 2
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 6.] 
cards in discard: [ 6.  1. 25. 11.  0.  0.  0.  1. 29.  1.  0.  6.  1.  0.  6.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6 29  0  6  1 25 29  6  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 26. 30. 29. 30.  8.  1. 10.  1.  7.  6.  7. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 8.  0. 11.  3.  0.] 
adversary cards in discard: [25. 10.  0. 11. 11. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10 11] -> size -> 24 
adversary victory points: 2
player victory points: -5 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[-46.15352 ]
 [-44.7557  ]
 [-39.064342]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.  3.  0.] 
cards in discard: [25. 10.  0. 11. 11. 29. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 29. 30.  8.  1. 10.  1.  7.  6.  7. 10. 10.  8.  9. 10.] 
adversary cards in hand: [11.  6.  6.  6.  3.] 
adversary cards in discard: [ 6.  1. 25. 11.  0.  0.  0.  1. 29.  1.  0.  6.  1.  0.  6.  3. 29.  0.
  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6 29  0  6  1 25 29  6  3] -> size -> 36 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -16.07819366455078



action possibilites: [-1] 
expected returns: [[-21.603153]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0.] 
cards in discard: [25. 10.  0. 11. 11. 29. 10. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10 11
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 29. 30.  8.  1. 10.  1.  7.  6.  7. 10. 10.  7.  9. 10.] 
adversary cards in hand: [11.  6.  6.  6.  3.] 
adversary cards in discard: [ 6.  1. 25. 11.  0.  0.  0.  1. 29.  1.  0.  6.  1.  0.  6.  3. 29.  0.
  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6 29  0  6  1 25 29  6  3] -> size -> 36 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 252 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -30.781204223632812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-30.168512]
 [-24.159424]
 [-49.028645]
 [-18.70734 ]
 [-20.274435]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 0.] 
cards in discard: [25. 10.  0. 11. 11. 29. 10. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10 11
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 26. 30. 29. 30.  8.  1. 10.  1.  7.  6.  7. 10. 10.  7.  9. 10.] 
adversary cards in hand: [11.  6.  6.  6.  3.] 
adversary cards in discard: [ 6.  1. 25. 11.  0.  0.  0.  1. 29.  1.  0.  6.  1.  0.  6.  3. 29.  0.
  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6 29  0  6  1 25 29  6  3] -> size -> 36 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: -21.603153228759766



buy possibilites: [-1] 
expected returns: [[-36.53739]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 0.] 
cards in discard: [25. 10.  0. 11. 11. 29. 10. 10.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10 11
 10  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 29. 30.  8.  1. 10.  1.  6.  6.  7. 10. 10.  7.  9. 10.] 
adversary cards in hand: [11.  6.  6.  6.  3.] 
adversary cards in discard: [ 6.  1. 25. 11.  0.  0.  0.  1. 29.  1.  0.  6.  1.  0.  6.  3. 29.  0.
  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6 29  0  6  1 25 29  6  3] -> size -> 36 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 241 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -18.707351684570312






Player: 1 
cards in hand: [11.  6.  6.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  6.  6.  3.] 
cards in discard: [ 6.  1. 25. 11.  0.  0.  0.  1. 29.  1.  0.  6.  1.  0.  6.  3. 29.  0.
  6.  0.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6 29  0  6  1 25 29  6  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 29. 30.  8.  1. 10.  1.  6.  6.  7. 10. 10.  7.  9. 10.] 
adversary cards in hand: [11. 11.  0.  3.  8.] 
adversary cards in discard: [25. 10.  0. 11. 11. 29. 10. 10.  8. 11.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10 11
 10  8] -> size -> 26 
adversary victory points: 2
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6. 3.] 
cards in discard: [ 6.  1. 25. 11.  0.  0.  0.  1. 29.  1.  0.  6.  1.  0.  6.  3. 29.  0.
  6.  0.  0.  6. 16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6 29  0  6  1 25 29  6  3 16] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 29. 30.  8.  1.  9.  1.  6.  6.  7. 10. 10.  7.  9. 10.] 
adversary cards in hand: [11. 11.  0.  3.  8.] 
adversary cards in discard: [25. 10.  0. 11. 11. 29. 10. 10.  8. 11.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10 11
 10  8] -> size -> 26 
adversary victory points: 2
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6. 3.] 
cards in discard: [ 6.  1. 25. 11.  0.  0.  0.  1. 29.  1.  0.  6.  1.  0.  6.  3. 29.  0.
  6.  0.  0.  6. 16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6 29  0  6  1 25 29  6  3 16] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 26. 30. 29. 30.  8.  1.  9.  1.  6.  6.  7. 10. 10.  7.  9. 10.] 
adversary cards in hand: [11. 11.  0.  3.  8.] 
adversary cards in discard: [25. 10.  0. 11. 11. 29. 10. 10.  8. 11.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10 11
 10  8] -> size -> 26 
adversary victory points: 2
player victory points: -5 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [11. 11.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8.] 
expected returns: [[-23.332514 ]
 [-15.6827965]
 [-15.6827965]
 [-21.885622 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0.  3.  8.] 
cards in discard: [25. 10.  0. 11. 11. 29. 10. 10.  8. 11.  8.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10 11
 10  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 29. 30.  8.  1.  9.  1.  6.  6.  7. 10. 10.  7.  9. 10.] 
adversary cards in hand: [ 0. 22.  0.  6.  3.] 
adversary cards in discard: [ 6.  1. 25. 11.  0.  0.  0.  1. 29.  1.  0.  6.  1.  0.  6.  3. 29.  0.
  6.  0.  0.  6. 16. 11.  6.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6 29  0  6  1 25 29  6  3 16] -> size -> 37 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: -36.537391662597656



action possibilites: [-1] 
expected returns: [[-29.387522]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  8.] 
cards in discard: [25. 10.  0. 11. 11. 29. 10. 10.  8. 11.  8.  0.  3.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10 11
 10  8 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 29. 30.  8.  1.  9.  1.  6.  6.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [ 0. 22.  0.  6.  3.] 
adversary cards in discard: [ 6.  1. 25. 11.  0.  0.  0.  1. 29.  1.  0.  6.  1.  0.  6.  3. 29.  0.
  6.  0.  0.  6. 16. 11.  6.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6 29  0  6  1 25 29  6  3 16] -> size -> 37 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 252 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -6.65022087097168





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-41.15265 ]
 [-59.90523 ]
 [-28.410421]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  8.] 
cards in discard: [25. 10.  0. 11. 11. 29. 10. 10.  8. 11.  8.  0.  3.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10 11
 10  8 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 26. 30. 29. 30.  8.  1.  9.  1.  6.  6.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [ 0. 22.  0.  6.  3.] 
adversary cards in discard: [ 6.  1. 25. 11.  0.  0.  0.  1. 29.  1.  0.  6.  1.  0.  6.  3. 29.  0.
  6.  0.  0.  6. 16. 11.  6.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6 29  0  6  1 25 29  6  3 16] -> size -> 37 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: -29.387521743774414






Player: 1 
cards in hand: [ 0. 22.  0.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22.  0.  6.  3.] 
cards in discard: [ 6.  1. 25. 11.  0.  0.  0.  1. 29.  1.  0.  6.  1.  0.  6.  3. 29.  0.
  6.  0.  0.  6. 16. 11.  6.  6.  6.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6 29  0  6  1 25 29  6  3 16] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 29. 30.  8.  1.  9.  1.  6.  6.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [25.  0.  0. 11. 25.] 
adversary cards in discard: [25. 10.  0. 11. 11. 29. 10. 10.  8. 11.  8.  0.  3.  0. 10. 11. 11.  0.
  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10 11
 10  8 10] -> size -> 27 
adversary victory points: 2
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 22.  0.  6.  3.] 
cards in discard: [ 6.  1. 25. 11.  0.  0.  0.  1. 29.  1.  0.  6.  1.  0.  6.  3. 29.  0.
  6.  0.  0.  6. 16. 11.  6.  6.  6.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6 29  0  6  1 25 29  6  3 16] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 26. 30. 29. 30.  8.  1.  9.  1.  6.  6.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [25.  0.  0. 11. 25.] 
adversary cards in discard: [25. 10.  0. 11. 11. 29. 10. 10.  8. 11.  8.  0.  3.  0. 10. 11. 11.  0.
  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10 11
 10  8 10] -> size -> 27 
adversary victory points: 2
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 22.  0.  6.  3.] 
cards in discard: [ 6.  1. 25. 11.  0.  0.  0.  1. 29.  1.  0.  6.  1.  0.  6.  3. 29.  0.
  6.  0.  0.  6. 16. 11.  6.  6.  6.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6 29  0  6  1 25 29  6  3 16  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  1.  9.  1.  6.  6.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [25.  0.  0. 11. 25.] 
adversary cards in discard: [25. 10.  0. 11. 11. 29. 10. 10.  8. 11.  8.  0.  3.  0. 10. 11. 11.  0.
  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10 11
 10  8 10] -> size -> 27 
adversary victory points: 2
player victory points: -4 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [25.  0.  0. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 25.] 
expected returns: [[ 8.869854]
 [33.799927]
 [15.612894]
 [33.799927]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0. 11. 25.] 
cards in discard: [25. 10.  0. 11. 11. 29. 10. 10.  8. 11.  8.  0.  3.  0. 10. 11. 11.  0.
  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10 11
 10  8 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  1.  9.  1.  6.  6.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [0. 3. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6 29  0  6  1 25 29  6  3 16  3] -> size -> 38 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -28.41041374206543



action possibilites: [-1] 
expected returns: [[-26.95049]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 25. 11.  0.] 
cards in discard: [25. 10.  0. 11. 11. 29. 10. 10.  8. 11.  8.  0.  3.  0. 10. 11. 11.  0.
  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10 11
 10  8 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  0.  9.  1.  6.  6.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [0. 3. 0. 0. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6 29  0  6  1 25 29  6  3 16  3  6] -> size -> 39 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 33.79991912841797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-34.680794]
 [-23.023335]
 [-29.832933]
 [-21.20547 ]
 [-25.695023]
 [-32.719177]
 [-26.88775 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 25. 11.  0.] 
cards in discard: [25. 10.  0. 11. 11. 29. 10. 10.  8. 11.  8.  0.  3.  0. 10. 11. 11.  0.
  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10 11
 10  8 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 26. 30. 28. 30.  8.  0.  9.  1.  6.  6.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [0. 3. 0. 0. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6 29  0  6  1 25 29  6  3 16  3  6] -> size -> 39 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: -26.950490951538086



buy possibilites: [-1] 
expected returns: [[-21.516796]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 25. 11.  0.] 
cards in discard: [25. 10.  0. 11. 11. 29. 10. 10.  8. 11.  8.  0.  3.  0. 10. 11. 11.  0.
  3.  8. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10 11
 10  8 10 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  0.  9.  0.  6.  6.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [0. 3. 0. 0. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6 29  0  6  1 25 29  6  3 16  3  6] -> size -> 39 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 249 

action type: buy - action 11.0
Learning step: 0
desired expected reward: -21.2054500579834






Player: 1 
cards in hand: [0. 3. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 8.] 
cards in discard: [6.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6
  1  6  0  6 29  0  6  1 25 29  6  3 16  3  6] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  0.  9.  0.  6.  6.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [11. 11. 11.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10 11
 10  8 10 11] -> size -> 28 
adversary victory points: 2
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 33 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  0.  9.  0.  6.  6.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [11. 11. 11.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10 11
 10  8 10 11] -> size -> 28 
adversary victory points: 2
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 33 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 26. 30. 28. 30.  8.  0.  9.  0.  6.  6.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [11. 11. 11.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10 11
 10  8 10 11] -> size -> 28 
adversary victory points: 2
player victory points: -6 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [11. 11. 11.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11.  8. 11.] 
expected returns: [[-49.81521 ]
 [-44.951015]
 [-44.951015]
 [-44.951015]
 [-48.873707]
 [-44.951015]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 11.  8. 11.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10 11
 10  8 10 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 28. 30.  8.  0.  9.  0.  6.  6.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [22. 25. 11.  6.  0.] 
adversary cards in discard: [6. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6] -> size -> 38 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: -21.516796112060547



action possibilites: [-1] 
expected returns: [[-37.502243]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  8. 11.] 
cards in discard: [1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10 11
 10  8 10 11  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  0.  9.  0.  6.  6.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [22. 25. 11.  6.  0.] 
adversary cards in discard: [6. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6] -> size -> 38 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 282 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -46.50528335571289





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-46.03851]
 [-36.95974]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  8. 11.] 
cards in discard: [1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10 11
 10  8 10 11  1] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  0.  9.  0.  6.  6.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [22. 25. 11.  6.  0.] 
adversary cards in discard: [6. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6] -> size -> 38 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: -37.50224304199219






Player: 1 
cards in hand: [22. 25. 11.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 25. 11.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22. 25. 11.  6.  0.] 
cards in discard: [6. 8. 0. 0. 0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  0.  9.  0.  6.  6.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [ 0. 11. 25. 25.  0.] 
adversary cards in discard: [ 1. 11. 11. 11.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10 11
 10  8 10 11  1] -> size -> 29 
adversary victory points: 2
player victory points: -6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22. 11.  6.  0.  0.  6.] 
cards in discard: [6. 8. 0. 0. 0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  0.  9.  0.  6.  6.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [ 0. 11. 25. 25.  0.] 
adversary cards in discard: [ 1. 11. 11. 11.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10 11
 10  8 10 11  1] -> size -> 29 
adversary victory points: 2
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22. 11.  6.  0.  0.  6.] 
cards in discard: [6. 8. 0. 0. 0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 25. 30. 28. 30.  8.  0.  9.  0.  6.  6.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [ 0. 11. 25. 25.  0.] 
adversary cards in discard: [ 1. 11. 11. 11.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10 11
 10  8 10 11  1] -> size -> 29 
adversary victory points: 2
player victory points: -6 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 25. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 25.] 
expected returns: [[-53.453056]
 [-45.958603]
 [-27.437916]
 [-27.437916]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 25. 25.  0.] 
cards in discard: [ 1. 11. 11. 11.  8. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10 11
 10  8 10 11  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  0.  9.  0.  6.  6.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [ 6. 29.  3.  6.  0.] 
adversary cards in discard: [ 6.  8.  0.  0.  0. 25. 22. 11.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6] -> size -> 38 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -36.9597282409668



action possibilites: [-1] 
expected returns: [[-37.00221]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 25.  0. 25.  0.] 
cards in discard: [ 1. 11. 11. 11.  8. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10 11
 10  8 10 11  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  0.  9.  0.  6.  6.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [ 6. 29.  3.  6.  0.] 
adversary cards in discard: [ 6.  8.  0.  0.  0. 25. 22. 11.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6] -> size -> 38 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -27.437911987304688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[-44.56914 ]
 [-32.753944]
 [-39.928528]
 [-35.84191 ]
 [-42.728565]
 [-36.96254 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 25.  0. 25.  0.] 
cards in discard: [ 1. 11. 11. 11.  8. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10 11
 10  8 10 11  1] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 25. 30. 28. 30.  8.  0.  9.  0.  6.  6.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [ 6. 29.  3.  6.  0.] 
adversary cards in discard: [ 6.  8.  0.  0.  0. 25. 22. 11.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6] -> size -> 38 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: -37.0022087097168



buy possibilites: [-1] 
expected returns: [[-42.653236]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 25.  0. 25.  0.] 
cards in discard: [ 1. 11. 11. 11.  8. 11.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10 11
 10  8 10 11  1  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 28. 30.  8.  0.  9.  0.  6.  6.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [ 6. 29.  3.  6.  0.] 
adversary cards in discard: [ 6.  8.  0.  0.  0. 25. 22. 11.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6] -> size -> 38 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 309 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -32.75393295288086






Player: 1 
cards in hand: [ 6. 29.  3.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29.  3.  6.  0.] 
cards in discard: [ 6.  8.  0.  0.  0. 25. 22. 11.  6.  0.  0.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 28. 30.  8.  0.  9.  0.  6.  6.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  8. 29. 10. 10.] 
adversary cards in discard: [ 1. 11. 11. 11.  8. 11.  1. 25.  0. 11. 25.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10 11
 10  8 10 11  1  1] -> size -> 30 
adversary victory points: 2
player victory points: -6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 1.] 
cards in discard: [ 6.  8.  0.  0.  0. 25. 22. 11.  6.  0.  0.  6.  3.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 24. 30. 28. 30.  8.  0.  9.  0.  6.  6.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  8. 29. 10. 10.] 
adversary cards in discard: [ 1. 11. 11. 11.  8. 11.  1. 25.  0. 11. 25.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10 11
 10  8 10 11  1  1] -> size -> 30 
adversary victory points: 2
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1.] 
cards in discard: [ 6.  8.  0.  0.  0. 25. 22. 11.  6.  0.  0.  6.  3.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6] -> size -> 38 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 24. 30. 28. 30.  8.  0.  9.  0.  6.  6.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  8. 29. 10. 10.] 
adversary cards in discard: [ 1. 11. 11. 11.  8. 11.  1. 25.  0. 11. 25.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10 11
 10  8 10 11  1  1] -> size -> 30 
adversary victory points: 2
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1.] 
cards in discard: [ 6.  8.  0.  0.  0. 25. 22. 11.  6.  0.  0.  6.  3.  6.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 24. 30. 28. 30.  8.  0.  9.  0.  5.  6.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  8. 29. 10. 10.] 
adversary cards in discard: [ 1. 11. 11. 11.  8. 11.  1. 25.  0. 11. 25.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10 11
 10  8 10 11  1  1] -> size -> 30 
adversary victory points: 2
player victory points: -6 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 0.  8. 29. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 10. 10.] 
expected returns: [[-49.241486]
 [-47.745903]
 [-35.721134]
 [-55.81277 ]
 [-55.81277 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 29. 10. 10.] 
cards in discard: [ 1. 11. 11. 11.  8. 11.  1. 25.  0. 11. 25.  0. 25.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10 11
 10  8 10 11  1  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 28. 30.  8.  0.  9.  0.  5.  6.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [0. 6. 3. 3. 1.] 
adversary cards in discard: [ 6.  8.  0.  0.  0. 25. 22. 11.  6.  0.  0.  6.  3.  6.  8. 29.  6.  0.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8] -> size -> 39 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: -42.653236389160156



action possibilites: [-1.  8. 10. 10.] 
expected returns: [[-29.991318]
 [-28.550875]
 [-37.11793 ]
 [-37.11793 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 10.] 
cards in discard: [ 1. 11. 11. 11.  8. 11.  1. 25.  0. 11. 25.  0. 25.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 10 25 11 11 11 25  8 11 10 11
 10  8 10 11  1  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 24. 30. 28. 30.  8.  0.  9.  0.  5.  6.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [0. 6. 3. 3. 1.] 
adversary cards in discard: [ 6.  8.  0.  0.  0. 25. 22. 11.  6.  0.  0.  6.  3.  6.  8. 29.  6.  0.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8] -> size -> 39 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -44.11631393432617



action possibilites: [-1] 
expected returns: [[-57.376793]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 1. 11. 11. 11.  8. 11.  1. 25.  0. 11. 25.  0. 25.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 24. 30. 28. 30.  8.  0.  9.  0.  5.  6.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [0. 6. 3. 3. 1.] 
adversary cards in discard: [ 6.  8.  0.  0.  0. 25. 22. 11.  6.  0.  0.  6.  3.  6.  8. 29.  6.  0.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8] -> size -> 39 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: -25.216461181640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-61.85875 ]
 [-53.606834]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 1. 11. 11. 11.  8. 11.  1. 25.  0. 11. 25.  0. 25.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 24. 30. 28. 30.  8.  0.  9.  0.  5.  6.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [0. 6. 3. 3. 1.] 
adversary cards in discard: [ 6.  8.  0.  0.  0. 25. 22. 11.  6.  0.  0.  6.  3.  6.  8. 29.  6.  0.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8] -> size -> 39 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1
Learning step: 0
desired expected reward: -57.376792907714844






Player: 1 
cards in hand: [0. 6. 3. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 3. 1.] 
cards in discard: [ 6.  8.  0.  0.  0. 25. 22. 11.  6.  0.  0.  6.  3.  6.  8. 29.  6.  0.
  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 28. 30.  8.  0.  9.  0.  5.  6.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [11.  0.  3. 10.  0.] 
adversary cards in discard: [ 1. 11. 11. 11.  8. 11.  1. 25.  0. 11. 25.  0. 25.  0.  0.  0. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1] -> size -> 28 
adversary victory points: 2
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 3. 1.] 
cards in discard: [ 6.  8.  0.  0.  0. 25. 22. 11.  6.  0.  0.  6.  3.  6.  8. 29.  6.  0.
  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 24. 30. 28. 30.  8.  0.  9.  0.  5.  6.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [11.  0.  3. 10.  0.] 
adversary cards in discard: [ 1. 11. 11. 11.  8. 11.  1. 25.  0. 11. 25.  0. 25.  0.  0.  0. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1] -> size -> 28 
adversary victory points: 2
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 3. 1.] 
cards in discard: [ 6.  8.  0.  0.  0. 25. 22. 11.  6.  0.  0.  6.  3.  6.  8. 29.  6.  0.
  1.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 28. 30.  8.  0.  9.  0.  5.  6.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [11.  0.  3. 10.  0.] 
adversary cards in discard: [ 1. 11. 11. 11.  8. 11.  1. 25.  0. 11. 25.  0. 25.  0.  0.  0. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1] -> size -> 28 
adversary victory points: 2
player victory points: -6 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [11.  0.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[-23.546892]
 [-16.491085]
 [-29.806974]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3. 10.  0.] 
cards in discard: [ 1. 11. 11. 11.  8. 11.  1. 25.  0. 11. 25.  0. 25.  0.  0.  0. 29.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 28. 30.  8.  0.  9.  0.  5.  6.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [6. 1. 3. 6. 0.] 
adversary cards in discard: [ 6.  8.  0.  0.  0. 25. 22. 11.  6.  0.  0.  6.  3.  6.  8. 29.  6.  0.
  1.  1.  0.  6.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1] -> size -> 40 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -53.606849670410156



action possibilites: [-1] 
expected returns: [[-9.056982]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  0.] 
cards in discard: [ 1. 11. 11. 11.  8. 11.  1. 25.  0. 11. 25.  0. 25.  0.  0.  0. 29.  8.
  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 22. 30. 28. 30.  8.  0.  9.  0.  5.  6.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [6. 1. 3. 6. 0.] 
adversary cards in discard: [ 6.  8.  0.  0.  0. 25. 22. 11.  6.  0.  0.  6.  3.  6.  8. 29.  6.  0.
  1.  1.  0.  6.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1] -> size -> 40 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 282 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -18.794185638427734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-18.537237]
 [-13.55591 ]
 [ -8.537143]
 [-10.019447]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0.] 
cards in discard: [ 1. 11. 11. 11.  8. 11.  1. 25.  0. 11. 25.  0. 25.  0.  0.  0. 29.  8.
  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 22. 30. 28. 30.  8.  0.  9.  0.  5.  6.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [6. 1. 3. 6. 0.] 
adversary cards in discard: [ 6.  8.  0.  0.  0. 25. 22. 11.  6.  0.  0.  6.  3.  6.  8. 29.  6.  0.
  1.  1.  0.  6.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1] -> size -> 40 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: -9.056982040405273



buy possibilites: [-1] 
expected returns: [[-8.958874]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0.] 
cards in discard: [ 1. 11. 11. 11.  8. 11.  1. 25.  0. 11. 25.  0. 25.  0.  0.  0. 29.  8.
  1.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 22. 30. 28. 30.  8.  0.  9.  0.  4.  6.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [6. 1. 3. 6. 0.] 
adversary cards in discard: [ 6.  8.  0.  0.  0. 25. 22. 11.  6.  0.  0.  6.  3.  6.  8. 29.  6.  0.
  1.  1.  0.  6.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1] -> size -> 40 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 271 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -8.537135124206543






Player: 1 
cards in hand: [6. 1. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 3. 6. 0.] 
cards in discard: [ 6.  8.  0.  0.  0. 25. 22. 11.  6.  0.  0.  6.  3.  6.  8. 29.  6.  0.
  1.  1.  0.  6.  3.  3.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 22. 30. 28. 30.  8.  0.  9.  0.  4.  6.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [ 3. 11.  8. 11. 10.] 
adversary cards in discard: [ 1. 11. 11. 11.  8. 11.  1. 25.  0. 11. 25.  0. 25.  0.  0.  0. 29.  8.
  1.  8. 11.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8] -> size -> 30 
adversary victory points: 2
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 3. 6. 0.] 
cards in discard: [ 6.  8.  0.  0.  0. 25. 22. 11.  6.  0.  0.  6.  3.  6.  8. 29.  6.  0.
  1.  1.  0.  6.  3.  3.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 22. 30. 28. 30.  8.  0.  9.  0.  4.  6.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [ 3. 11.  8. 11. 10.] 
adversary cards in discard: [ 1. 11. 11. 11.  8. 11.  1. 25.  0. 11. 25.  0. 25.  0.  0.  0. 29.  8.
  1.  8. 11.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8] -> size -> 30 
adversary victory points: 2
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 3. 6. 0.] 
cards in discard: [ 6.  8.  0.  0.  0. 25. 22. 11.  6.  0.  0.  6.  3.  6.  8. 29.  6.  0.
  1.  1.  0.  6.  3.  3.  1.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 21. 30. 28. 30.  8.  0.  9.  0.  4.  6.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [ 3. 11.  8. 11. 10.] 
adversary cards in discard: [ 1. 11. 11. 11.  8. 11.  1. 25.  0. 11. 25.  0. 25.  0.  0.  0. 29.  8.
  1.  8. 11.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8] -> size -> 30 
adversary victory points: 2
player victory points: -6 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  8. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 11. 10.] 
expected returns: [[-22.327156]
 [-16.607178]
 [-21.2909  ]
 [-16.607178]
 [-28.079432]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  8. 11. 10.] 
cards in discard: [ 1. 11. 11. 11.  8. 11.  1. 25.  0. 11. 25.  0. 25.  0.  0.  0. 29.  8.
  1.  8. 11.  0.  3. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 21. 30. 28. 30.  8.  0.  9.  0.  4.  6.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [ 1.  0. 16.  0.  0.] 
adversary cards in discard: [ 6.  8.  0.  0.  0. 25. 22. 11.  6.  0.  0.  6.  3.  6.  8. 29.  6.  0.
  1.  1.  0.  6.  3.  3.  1.  1.  6.  1.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1] -> size -> 41 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: -8.958873748779297



action possibilites: [-1] 
expected returns: [[-52.354088]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 11. 10.] 
cards in discard: [ 1. 11. 11. 11.  8. 11.  1. 25.  0. 11. 25.  0. 25.  0.  0.  0. 29.  8.
  1.  8. 11.  0.  3. 10.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 20. 30. 28. 30.  8.  0.  9.  0.  4.  6.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [ 1.  0. 16.  0.  0.] 
adversary cards in discard: [ 6.  8.  0.  0.  0. 25. 22. 11.  6.  0.  0.  6.  3.  6.  8. 29.  6.  0.
  1.  1.  0.  6.  3.  3.  1.  1.  6.  1.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1] -> size -> 41 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 282 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -18.51198387145996





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-59.43647 ]
 [-52.473816]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 11. 10.] 
cards in discard: [ 1. 11. 11. 11.  8. 11.  1. 25.  0. 11. 25.  0. 25.  0.  0.  0. 29.  8.
  1.  8. 11.  0.  3. 10.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 20. 30. 28. 30.  8.  0.  9.  0.  4.  6.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [ 1.  0. 16.  0.  0.] 
adversary cards in discard: [ 6.  8.  0.  0.  0. 25. 22. 11.  6.  0.  0.  6.  3.  6.  8. 29.  6.  0.
  1.  1.  0.  6.  3.  3.  1.  1.  6.  1.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1] -> size -> 41 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: -52.354087829589844






Player: 1 
cards in hand: [ 1.  0. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 16.  0.  0.] 
cards in discard: [ 6.  8.  0.  0.  0. 25. 22. 11.  6.  0.  0.  6.  3.  6.  8. 29.  6.  0.
  1.  1.  0.  6.  3.  3.  1.  1.  6.  1.  3.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 20. 30. 28. 30.  8.  0.  9.  0.  4.  6.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [ 0. 11.  1.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1] -> size -> 31 
adversary victory points: 2
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 16.  0.  0.] 
cards in discard: [ 6.  8.  0.  0.  0. 25. 22. 11.  6.  0.  0.  6.  3.  6.  8. 29.  6.  0.
  1.  1.  0.  6.  3.  3.  1.  1.  6.  1.  3.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 20. 30. 28. 30.  8.  0.  9.  0.  4.  6.  7. 10. 10.  6.  9. 10.] 
adversary cards in hand: [ 0. 11.  1.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1] -> size -> 31 
adversary victory points: 2
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 16.  0.  0.] 
cards in discard: [ 6.  8.  0.  0.  0. 25. 22. 11.  6.  0.  0.  6.  3.  6.  8. 29.  6.  0.
  1.  1.  0.  6.  3.  3.  1.  1.  6.  1.  3.  6.  0. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 20. 30. 28. 30.  8.  0.  9.  0.  4.  6.  7.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0. 11.  1.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1] -> size -> 31 
adversary victory points: 2
player victory points: -6 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  1.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[-61.141243]
 [-55.016937]
 [-60.012123]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  1.  0.  8.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 20. 30. 28. 30.  8.  0.  9.  0.  4.  6.  7.  9. 10.  6.  9. 10.] 
adversary cards in hand: [29.  0.  6.  6. 11.] 
adversary cards in discard: [ 6.  8.  0.  0.  0. 25. 22. 11.  6.  0.  0.  6.  3.  6.  8. 29.  6.  0.
  1.  1.  0.  6.  3.  3.  1.  1.  6.  1.  3.  6.  0. 14.  1.  0. 16.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14] -> size -> 42 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -52.47381591796875



action possibilites: [-1] 
expected returns: [[-49.594162]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 8.] 
cards in discard: [1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 19. 30. 28. 30.  8.  0.  9.  0.  4.  6.  7.  9. 10.  6.  9. 10.] 
adversary cards in hand: [29.  0.  6.  6. 11.] 
adversary cards in discard: [ 6.  8.  0.  0.  0. 25. 22. 11.  6.  0.  0.  6.  3.  6.  8. 29.  6.  0.
  1.  1.  0.  6.  3.  3.  1.  1.  6.  1.  3.  6.  0. 14.  1.  0. 16.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14] -> size -> 42 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 282 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -57.04869079589844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-56.98899 ]
 [-42.30053 ]
 [-50.916992]
 [-47.23158 ]
 [-45.827625]
 [-34.13042 ]
 [-66.49039 ]
 [-54.501366]
 [-52.368847]
 [-47.17752 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 8.] 
cards in discard: [1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 19. 30. 28. 30.  8.  0.  9.  0.  4.  6.  7.  9. 10.  6.  9. 10.] 
adversary cards in hand: [29.  0.  6.  6. 11.] 
adversary cards in discard: [ 6.  8.  0.  0.  0. 25. 22. 11.  6.  0.  0.  6.  3.  6.  8. 29.  6.  0.
  1.  1.  0.  6.  3.  3.  1.  1.  6.  1.  3.  6.  0. 14.  1.  0. 16.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14] -> size -> 42 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: -49.59416198730469



buy possibilites: [-1] 
expected returns: [[-28.113861]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 8.] 
cards in discard: [ 1. 29.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 19. 30. 28. 30.  8.  0.  9.  0.  4.  6.  6.  9. 10.  6.  9. 10.] 
adversary cards in hand: [29.  0.  6.  6. 11.] 
adversary cards in discard: [ 6.  8.  0.  0.  0. 25. 22. 11.  6.  0.  0.  6.  3.  6.  8. 29.  6.  0.
  1.  1.  0.  6.  3.  3.  1.  1.  6.  1.  3.  6.  0. 14.  1.  0. 16.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14] -> size -> 42 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 383 

action type: buy - action 29.0
Learning step: 0
desired expected reward: -34.13041305541992






Player: 1 
cards in hand: [29.  0.  6.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  6.  6. 11.] 
cards in discard: [ 6.  8.  0.  0.  0. 25. 22. 11.  6.  0.  0.  6.  3.  6.  8. 29.  6.  0.
  1.  1.  0.  6.  3.  3.  1.  1.  6.  1.  3.  6.  0. 14.  1.  0. 16.  0.
  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 19. 30. 28. 30.  8.  0.  9.  0.  4.  6.  6.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  0. 11.  1.  8.] 
adversary cards in discard: [ 1. 29. 11.  0.  1.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29] -> size -> 33 
adversary victory points: 2
player victory points: -6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  6.  6.] 
cards in discard: [ 6.  8.  0.  0.  0. 25. 22. 11.  6.  0.  0.  6.  3.  6.  8. 29.  6.  0.
  1.  1.  0.  6.  3.  3.  1.  1.  6.  1.  3.  6.  0. 14.  1.  0. 16.  0.
  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 19. 30. 28. 30.  8.  0.  9.  0.  4.  6.  5.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  0. 11.  1.  8.] 
adversary cards in discard: [ 1. 29. 11.  0.  1.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29] -> size -> 33 
adversary victory points: 2
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  6.  6.] 
cards in discard: [ 6.  8.  0.  0.  0. 25. 22. 11.  6.  0.  0.  6.  3.  6.  8. 29.  6.  0.
  1.  1.  0.  6.  3.  3.  1.  1.  6.  1.  3.  6.  0. 14.  1.  0. 16.  0.
  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 19. 30. 28. 30.  8.  0.  9.  0.  4.  6.  5.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  0. 11.  1.  8.] 
adversary cards in discard: [ 1. 29. 11.  0.  1.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29] -> size -> 33 
adversary victory points: 2
player victory points: -6 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[-61.153877]
 [-54.095642]
 [-59.74063 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  1.  8.] 
cards in discard: [ 1. 29. 11.  0.  1.  0.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 19. 30. 28. 30.  8.  0.  9.  0.  4.  6.  5.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  0. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29] -> size -> 43 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: -28.113861083984375



action possibilites: [-1] 
expected returns: [[-44.88023]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 8.] 
cards in discard: [ 1. 29. 11.  0.  1.  0.  8.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 18. 30. 28. 30.  8.  0.  9.  0.  4.  6.  5.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  0. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29] -> size -> 43 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 282 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -56.37883758544922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-51.975075]
 [-39.308823]
 [-46.81746 ]
 [-43.58728 ]
 [-42.37873 ]
 [-32.19766 ]
 [-60.562702]
 [-49.887367]
 [-48.094345]
 [-43.654896]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 8.] 
cards in discard: [ 1. 29. 11.  0.  1.  0.  8.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 18. 30. 28. 30.  8.  0.  9.  0.  4.  6.  5.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  0. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29] -> size -> 43 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: -44.88022994995117



buy possibilites: [-1] 
expected returns: [[-20.545254]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 8.] 
cards in discard: [ 1. 29. 11.  0.  1.  0.  8.  1. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 18. 30. 28. 30.  8.  0.  9.  0.  4.  6.  4.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  0. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29] -> size -> 43 
adversary victory points: -6
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 383 

action type: buy - action 29.0
Learning step: 0
desired expected reward: -32.197654724121094






Player: 1 
cards in hand: [ 0.  0. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 18. 30. 28. 30.  8.  0.  9.  0.  4.  6.  4.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 1. 10.  3. 29. 11.] 
adversary cards in discard: [ 1. 29. 11.  0.  1.  0.  8.  1. 29. 11.  0.  0.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29] -> size -> 35 
adversary victory points: 2
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29] -> size -> 43 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 18. 30. 28. 30.  8.  0.  9.  0.  4.  6.  4.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 1. 10.  3. 29. 11.] 
adversary cards in discard: [ 1. 29. 11.  0.  1.  0.  8.  1. 29. 11.  0.  0.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29] -> size -> 35 
adversary victory points: 2
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  3.  0.] 
cards in discard: [3.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 18. 30. 27. 30.  8.  0.  9.  0.  4.  6.  4.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 1. 10.  3. 29. 11.] 
adversary cards in discard: [ 1. 29. 11.  0.  1.  0.  8.  1. 29. 11.  0.  0.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29] -> size -> 35 
adversary victory points: 2
player victory points: -5 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 1. 10.  3. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11.] 
expected returns: [[-45.031246]
 [-50.502113]
 [-33.540245]
 [-38.738754]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  3. 29. 11.] 
cards in discard: [ 1. 29. 11.  0.  1.  0.  8.  1. 29. 11.  0.  0.  1.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 18. 30. 27. 30.  8.  0.  9.  0.  4.  6.  4.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0. 14.  1.  3. 11.] 
adversary cards in discard: [ 3.  0.  0. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3] -> size -> 44 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: -20.54525375366211



action possibilites: [-1. 10.] 
expected returns: [[-48.818855]
 [-53.523182]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  1.] 
cards in discard: [ 1. 29. 11.  0.  1.  0.  8.  1. 29. 11.  0.  0.  1.  8.  3. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 18. 30. 27. 30.  8.  0.  9.  0.  4.  6.  4.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0. 14.  1.  3. 11.] 
adversary cards in discard: [ 3.  0.  0. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3] -> size -> 44 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: -30.970529556274414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-55.462658]
 [-45.812176]
 [-51.53655 ]
 [-64.32722 ]
 [-49.06308 ]
 [-48.150295]
 [-30.070517]
 [-39.773388]
 [-62.440327]
 [-53.42684 ]
 [-53.87466 ]
 [-63.525745]
 [-52.51406 ]
 [-49.17033 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  1.] 
cards in discard: [ 1. 29. 11.  0.  1.  0.  8.  1. 29. 11.  0.  0.  1.  8.  3. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29] -> size -> 35 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 18. 30. 27. 30.  8.  0.  9.  0.  4.  6.  4.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0. 14.  1.  3. 11.] 
adversary cards in discard: [ 3.  0.  0. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3] -> size -> 44 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -48.8188591003418



buy possibilites: [-1] 
expected returns: [[-37.81225]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  1.] 
cards in discard: [ 1. 29. 11.  0.  1.  0.  8.  1. 29. 11.  0.  0.  1.  8.  3. 11. 25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 18. 30. 27. 30.  8.  0.  9.  0.  4.  5.  4.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0. 14.  1.  3. 11.] 
adversary cards in discard: [ 3.  0.  0. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3] -> size -> 44 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0 -10   0   0 250   0] 
sum of rewards: 465 

action type: buy - action 25.0
Learning step: 0
desired expected reward: -30.070533752441406






Player: 1 
cards in hand: [ 0. 14.  1.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  1.  3. 11.] 
cards in discard: [ 3.  0.  0. 29.  3.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 18. 30. 27. 30.  8.  0.  9.  0.  4.  5.  4.  9. 10.  6.  9. 10.] 
adversary cards in hand: [11.  0. 11. 11. 25.] 
adversary cards in discard: [ 1. 29. 11.  0.  1.  0.  8.  1. 29. 11.  0.  0.  1.  8.  3. 11. 25. 29.
  1. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25] -> size -> 36 
adversary victory points: 2
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3. 11.] 
cards in discard: [ 3.  0.  0. 29.  3.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3] -> size -> 44 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 18. 30. 27. 30.  8.  0.  9.  0.  4.  5.  4.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0. 11. 25.] 
adversary cards in discard: [ 1. 29. 11.  0.  1.  0.  8.  1. 29. 11.  0.  0.  1.  8.  3. 11. 25. 29.
  1. 10.  1. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25] -> size -> 36 
adversary victory points: 2
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3. 11.] 
cards in discard: [ 3.  0.  0. 29.  3.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3] -> size -> 44 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 18. 30. 27. 30.  8.  0.  9.  0.  4.  5.  4.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0. 11. 25.] 
adversary cards in discard: [ 1. 29. 11.  0.  1.  0.  8.  1. 29. 11.  0.  0.  1.  8.  3. 11. 25. 29.
  1. 10.  1. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25] -> size -> 36 
adversary victory points: 2
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3. 11.] 
cards in discard: [ 3.  0.  0. 29.  3.  0. 29.] 
cards in deck: 33 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29] -> size -> 45 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 18. 30. 27. 30.  8.  0.  9.  0.  4.  5.  3.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0. 11. 25.] 
adversary cards in discard: [ 1. 29. 11.  0.  1.  0.  8.  1. 29. 11.  0.  0.  1.  8.  3. 11. 25. 29.
  1. 10.  1. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25] -> size -> 36 
adversary victory points: 2
player victory points: -5 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[-35.34387 ]
 [-29.927212]
 [-16.593472]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 25.] 
cards in discard: [ 1. 29. 11.  0.  1.  0.  8.  1. 29. 11.  0.  0.  1.  8.  3. 11. 25. 29.
  1. 10.  1. 11. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 18. 30. 27. 30.  8.  0.  9.  0.  4.  5.  3.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 1.  0. 11.  0.  6.] 
adversary cards in discard: [ 3.  0.  0. 29.  3.  0. 29. 14.  0.  1.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29] -> size -> 45 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -89.44041442871094



action possibilites: [-1] 
expected returns: [[-42.458393]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  3.] 
cards in discard: [ 1. 29. 11.  0.  1.  0.  8.  1. 29. 11.  0.  0.  1.  8.  3. 11. 25. 29.
  1. 10.  1. 11. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 18. 30. 27. 30.  8.  0.  9.  0.  4.  5.  3.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 1.  0. 11.  0.  6.] 
adversary cards in discard: [ 3.  0.  0. 29.  3.  0. 29. 14.  0.  1.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29] -> size -> 45 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -16.593463897705078





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-50.41044 ]
 [-42.135303]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 11.  3.] 
cards in discard: [ 1. 29. 11.  0.  1.  0.  8.  1. 29. 11.  0.  0.  1.  8.  3. 11. 25. 29.
  1. 10.  1. 11. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 18. 30. 27. 30.  8.  0.  9.  0.  4.  5.  3.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 1.  0. 11.  0.  6.] 
adversary cards in discard: [ 3.  0.  0. 29.  3.  0. 29. 14.  0.  1.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29] -> size -> 45 
adversary victory points: -5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: -42.45839309692383






Player: 1 
cards in hand: [ 1.  0. 11.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 11.  0.  6.] 
cards in discard: [ 3.  0.  0. 29.  3.  0. 29. 14.  0.  1.  3. 11.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 18. 30. 27. 30.  8.  0.  9.  0.  4.  5.  3.  9. 10.  6.  9. 10.] 
adversary cards in hand: [25.  8. 25.  0.  8.] 
adversary cards in discard: [ 1. 29. 11.  0.  1.  0.  8.  1. 29. 11.  0.  0.  1.  8.  3. 11. 25. 29.
  1. 10.  1. 11. 11. 25.  0. 11. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25] -> size -> 36 
adversary victory points: 2
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 6.] 
cards in discard: [ 3.  0.  0. 29.  3.  0. 29. 14.  0.  1.  3. 11.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 18. 30. 26. 30.  8.  0.  9.  0.  4.  5.  3.  9. 10.  6.  9. 10.] 
adversary cards in hand: [25.  8. 25.  0.  8.] 
adversary cards in discard: [ 1. 29. 11.  0.  1.  0.  8.  1. 29. 11.  0.  0.  1.  8.  3. 11. 25. 29.
  1. 10.  1. 11. 11. 25.  0. 11. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25] -> size -> 36 
adversary victory points: 2
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 6.] 
cards in discard: [ 3.  0.  0. 29.  3.  0. 29. 14.  0.  1.  3. 11.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3] -> size -> 46 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 18. 30. 26. 30.  8.  0.  9.  0.  4.  5.  3.  9. 10.  6.  9. 10.] 
adversary cards in hand: [25.  8. 25.  0.  8.] 
adversary cards in discard: [ 1. 29. 11.  0.  1.  0.  8.  1. 29. 11.  0.  0.  1.  8.  3. 11. 25. 29.
  1. 10.  1. 11. 11. 25.  0. 11. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25] -> size -> 36 
adversary victory points: 2
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 6.] 
cards in discard: [ 3.  0.  0. 29.  3.  0. 29. 14.  0.  1.  3. 11.  3.  1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 17. 30. 26. 30.  8.  0.  9.  0.  4.  5.  3.  9. 10.  6.  9. 10.] 
adversary cards in hand: [25.  8. 25.  0.  8.] 
adversary cards in discard: [ 1. 29. 11.  0.  1.  0.  8.  1. 29. 11.  0.  0.  1.  8.  3. 11. 25. 29.
  1. 10.  1. 11. 11. 25.  0. 11. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25] -> size -> 36 
adversary victory points: 2
player victory points: -4 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [25.  8. 25.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8. 25.  8.] 
expected returns: [[-40.456764]
 [-21.359905]
 [-39.46585 ]
 [-21.359905]
 [-39.46585 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8. 25.  0.  8.] 
cards in discard: [ 1. 29. 11.  0.  1.  0.  8.  1. 29. 11.  0.  0.  1.  8.  3. 11. 25. 29.
  1. 10.  1. 11. 11. 25.  0. 11. 11.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 17. 30. 26. 30.  8.  0.  9.  0.  4.  5.  3.  9. 10.  6.  9. 10.] 
adversary cards in hand: [1. 3. 6. 6. 6.] 
adversary cards in discard: [ 3.  0.  0. 29.  3.  0. 29. 14.  0.  1.  3. 11.  3.  1. 11.  1.  0.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1] -> size -> 47 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -42.13529586791992



action possibilites: [-1] 
expected returns: [[-51.773678]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25.  0.  8.  0. 11.] 
cards in discard: [ 1. 29. 11.  0.  1.  0.  8.  1. 29. 11.  0.  0.  1.  8.  3. 11. 25. 29.
  1. 10.  1. 11. 11. 25.  0. 11. 11.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 17. 30. 26. 30.  8.  0.  9.  0.  4.  5.  3.  9. 10.  6.  9. 10.] 
adversary cards in hand: [1. 3. 6. 6. 6.] 
adversary cards in discard: [ 3.  0.  0. 29.  3.  0. 29. 14.  0.  1.  3. 11.  3.  1. 11.  1.  0.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1] -> size -> 47 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -21.359926223754883





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-57.730156]
 [-54.33944 ]
 [-51.434933]
 [-52.193256]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 25.  0.  8.  0. 11.] 
cards in discard: [ 1. 29. 11.  0.  1.  0.  8.  1. 29. 11.  0.  0.  1.  8.  3. 11. 25. 29.
  1. 10.  1. 11. 11. 25.  0. 11. 11.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 17. 30. 26. 30.  8.  0.  9.  0.  4.  5.  3.  9. 10.  6.  9. 10.] 
adversary cards in hand: [1. 3. 6. 6. 6.] 
adversary cards in discard: [ 3.  0.  0. 29.  3.  0. 29. 14.  0.  1.  3. 11.  3.  1. 11.  1.  0.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1] -> size -> 47 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: -51.773677825927734



buy possibilites: [-1] 
expected returns: [[-38.06158]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 25.  0.  8.  0. 11.] 
cards in discard: [ 1. 29. 11.  0.  1.  0.  8.  1. 29. 11.  0.  0.  1.  8.  3. 11. 25. 29.
  1. 10.  1. 11. 11. 25.  0. 11. 11.  3.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 17. 30. 26. 30.  8.  0.  9.  0.  3.  5.  3.  9. 10.  6.  9. 10.] 
adversary cards in hand: [1. 3. 6. 6. 6.] 
adversary cards in discard: [ 3.  0.  0. 29.  3.  0. 29. 14.  0.  1.  3. 11.  3.  1. 11.  1.  0.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1] -> size -> 47 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0 -20   0   0  16   0] 
sum of rewards: 191 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -51.4349365234375






Player: 1 
cards in hand: [1. 3. 6. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 6. 6. 6.] 
cards in discard: [ 3.  0.  0. 29.  3.  0. 29. 14.  0.  1.  3. 11.  3.  1. 11.  1.  0.  0.
  6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 17. 30. 26. 30.  8.  0.  9.  0.  3.  5.  3.  9. 10.  6.  9. 10.] 
adversary cards in hand: [11.  8.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8] -> size -> 37 
adversary victory points: 2
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 6. 6. 6.] 
cards in discard: [ 3.  0.  0. 29.  3.  0. 29. 14.  0.  1.  3. 11.  3.  1. 11.  1.  0.  0.
  6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 17. 30. 26. 30.  8.  0.  9.  0.  3.  5.  3.  9. 10.  6.  9. 10.] 
adversary cards in hand: [11.  8.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8] -> size -> 37 
adversary victory points: 2
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 6. 6. 6.] 
cards in discard: [ 3.  0.  0. 29.  3.  0. 29. 14.  0.  1.  3. 11.  3.  1. 11.  1.  0.  0.
  6.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0] -> size -> 48 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 17. 30. 26. 30.  8.  0.  9.  0.  3.  5.  3.  9. 10.  6.  9. 10.] 
adversary cards in hand: [11.  8.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8] -> size -> 37 
adversary victory points: 2
player victory points: -4 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [11.  8.  8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8. 10.] 
expected returns: [[-36.98329 ]
 [-31.399363]
 [-35.943096]
 [-35.943096]
 [-42.53917 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  8.  0. 10.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 17. 30. 26. 30.  8.  0.  9.  0.  3.  5.  3.  9. 10.  6.  9. 10.] 
adversary cards in hand: [8. 6. 6. 0. 0.] 
adversary cards in discard: [ 3.  0.  0. 29.  3.  0. 29. 14.  0.  1.  3. 11.  3.  1. 11.  1.  0.  0.
  6.  0.  1.  3.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0] -> size -> 48 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: -38.061580657958984



action possibilites: [-1] 
expected returns: [[-25.604895]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  0. 10.] 
cards in discard: [1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 16. 30. 26. 30.  8.  0.  9.  0.  3.  5.  3.  9. 10.  6.  9. 10.] 
adversary cards in hand: [8. 6. 6. 0. 0.] 
adversary cards in discard: [ 3.  0.  0. 29.  3.  0. 29. 14.  0.  1.  3. 11.  3.  1. 11.  1.  0.  0.
  6.  0.  1.  3.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0] -> size -> 48 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0 -30   0   0  27   0] 
sum of rewards: 192 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -33.242431640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-32.61525 ]
 [-25.339382]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8.  0. 10.] 
cards in discard: [1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 16. 30. 26. 30.  8.  0.  9.  0.  3.  5.  3.  9. 10.  6.  9. 10.] 
adversary cards in hand: [8. 6. 6. 0. 0.] 
adversary cards in discard: [ 3.  0.  0. 29.  3.  0. 29. 14.  0.  1.  3. 11.  3.  1. 11.  1.  0.  0.
  6.  0.  1.  3.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0] -> size -> 48 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: -25.604894638061523






Player: 1 
cards in hand: [8. 6. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 6. 0. 0.] 
cards in discard: [ 3.  0.  0. 29.  3.  0. 29. 14.  0.  1.  3. 11.  3.  1. 11.  1.  0.  0.
  6.  0.  1.  3.  6.  6.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1
  6  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 16. 30. 26. 30.  8.  0.  9.  0.  3.  5.  3.  9. 10.  6.  9. 10.] 
adversary cards in hand: [25. 25.  1.  1.  1.] 
adversary cards in discard: [ 1. 11.  8.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1] -> size -> 38 
adversary victory points: 2
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0.] 
cards in discard: [ 3.  0.  0. 29.  3.  0. 29. 14.  0.  1.  3. 11.  3.  1. 11.  1.  0.  0.
  6.  0.  1.  3.  6.  6.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 16. 30. 26. 30.  8.  0.  9.  0.  3.  5.  3.  9. 10.  6.  9. 10.] 
adversary cards in hand: [25. 25.  1.  1.  1.] 
adversary cards in discard: [ 1. 11.  8.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1] -> size -> 38 
adversary victory points: 2
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0.] 
cards in discard: [ 3.  0.  0. 29.  3.  0. 29. 14.  0.  1.  3. 11.  3.  1. 11.  1.  0.  0.
  6.  0.  1.  3.  6.  6.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0] -> size -> 47 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 16. 30. 26. 30.  8.  0.  9.  0.  3.  5.  3.  9. 10.  6.  9. 10.] 
adversary cards in hand: [25. 25.  1.  1.  1.] 
adversary cards in discard: [ 1. 11.  8.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1] -> size -> 38 
adversary victory points: 2
player victory points: -4 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [25. 25.  1.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[-26.34028  ]
 [  2.7146049]
 [  2.7146049]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25.  1.  1.  1.] 
cards in discard: [ 1. 11.  8.  8.  0. 10.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 16. 30. 26. 30.  8.  0.  9.  0.  3.  5.  3.  9. 10.  6.  9. 10.] 
adversary cards in hand: [25. 22.  0.  8.  6.] 
adversary cards in discard: [ 3.  0.  0. 29.  3.  0. 29. 14.  0.  1.  3. 11.  3.  1. 11.  1.  0.  0.
  6.  0.  1.  3.  6.  6.  6.  8.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0] -> size -> 47 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -25.339380264282227



action possibilites: [-1] 
expected returns: [[-49.831993]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  1.  1. 11.  0.] 
cards in discard: [ 1. 11.  8.  8.  0. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 16. 30. 26. 30.  8.  0.  9.  0.  3.  5.  3.  9. 10.  6.  9. 10.] 
adversary cards in hand: [25. 22.  0.  8.  6.] 
adversary cards in discard: [ 3.  0.  0. 29.  3.  0. 29. 14.  0.  1.  3. 11.  3.  1. 11.  1.  0.  0.
  6.  0.  1.  3.  6.  6.  6.  8.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0] -> size -> 47 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 2.714592456817627





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-58.863586]
 [-42.28336 ]
 [-67.26996 ]
 [-52.807953]
 [-71.03694 ]
 [-48.244583]
 [-46.193092]
 [-19.406366]
 [-33.5684  ]
 [-68.70848 ]
 [-55.842426]
 [-56.535126]
 [-70.061066]
 [-54.36797 ]
 [-48.353058]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1.  1.  1. 11.  0.] 
cards in discard: [ 1. 11.  8.  8.  0. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 7 
card supply: [24. 16. 30. 26. 30.  8.  0.  9.  0.  3.  5.  3.  9. 10.  6.  9. 10.] 
adversary cards in hand: [25. 22.  0.  8.  6.] 
adversary cards in discard: [ 3.  0.  0. 29.  3.  0. 29. 14.  0.  1.  3. 11.  3.  1. 11.  1.  0.  0.
  6.  0.  1.  3.  6.  6.  6.  8.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0] -> size -> 47 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: -49.831993103027344



buy possibilites: [-1] 
expected returns: [[12.508064]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1.  1.  1. 11.  0.] 
cards in discard: [ 1. 11.  8.  8.  0. 10. 25.] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 16. 30. 26. 30.  8.  0.  9.  0.  3.  4.  3.  9. 10.  6.  9. 10.] 
adversary cards in hand: [25. 22.  0.  8.  6.] 
adversary cards in discard: [ 3.  0.  0. 29.  3.  0. 29. 14.  0.  1.  3. 11.  3.  1. 11.  1.  0.  0.
  6.  0.  1.  3.  6.  6.  6.  8.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0] -> size -> 47 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5.    0.    0.  180.    0.    0.   20.    0.    0.    0.    0.  -40.
   0.    0.   62.5   0. ] 
sum of rewards: 217.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: -19.4063777923584






Player: 1 
cards in hand: [25. 22.  0.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 22.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 22.  0.  8.  6.] 
cards in discard: [ 3.  0.  0. 29.  3.  0. 29. 14.  0.  1.  3. 11.  3.  1. 11.  1.  0.  0.
  6.  0.  1.  3.  6.  6.  6.  8.  6.  6.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 16. 30. 26. 30.  8.  0.  9.  0.  3.  4.  3.  9. 10.  6.  9. 10.] 
adversary cards in hand: [29.  3. 25. 11.  0.] 
adversary cards in discard: [ 1. 11.  8.  8.  0. 10. 25. 25. 25.  1.  1.  1. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25] -> size -> 39 
adversary victory points: 2
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 22.  0.  8.  6.] 
cards in discard: [ 3.  0.  0. 29.  3.  0. 29. 14.  0.  1.  3. 11.  3.  1. 11.  1.  0.  0.
  6.  0.  1.  3.  6.  6.  6.  8.  6.  6.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0] -> size -> 47 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 16. 30. 26. 30.  8.  0.  9.  0.  3.  4.  3.  9. 10.  6.  9. 10.] 
adversary cards in hand: [29.  3. 25. 11.  0.] 
adversary cards in discard: [ 1. 11.  8.  8.  0. 10. 25. 25. 25.  1.  1.  1. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25] -> size -> 39 
adversary victory points: 2
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 22.  0.  8.  6.] 
cards in discard: [ 3.  0.  0. 29.  3.  0. 29. 14.  0.  1.  3. 11.  3.  1. 11.  1.  0.  0.
  6.  0.  1.  3.  6.  6.  6.  8.  6.  6.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0] -> size -> 48 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 16. 30. 26. 30.  8.  0.  9.  0.  3.  4.  3.  9. 10.  6.  9. 10.] 
adversary cards in hand: [29.  3. 25. 11.  0.] 
adversary cards in discard: [ 1. 11.  8.  8.  0. 10. 25. 25. 25.  1.  1.  1. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25] -> size -> 39 
adversary victory points: 2
player victory points: -4 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [29.  3. 25. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 11.] 
expected returns: [[-49.662804]
 [-39.6034  ]
 [-29.544836]
 [-43.990425]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 25. 11.  0.] 
cards in discard: [ 1. 11.  8.  8.  0. 10. 25. 25. 25.  1.  1.  1. 11.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 16. 30. 26. 30.  8.  0.  9.  0.  3.  4.  3.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 1.  1.  1. 16.  3.] 
adversary cards in discard: [ 3.  0.  0. 29.  3.  0. 29. 14.  0.  1.  3. 11.  3.  1. 11.  1.  0.  0.
  6.  0.  1.  3.  6.  6.  6.  8.  6.  6.  0.  0. 25. 22.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0] -> size -> 48 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 12.508064270019531



action possibilites: [-1] 
expected returns: [[9.399288]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 11.  0.  3.  1.] 
cards in discard: [ 1. 11.  8.  8.  0. 10. 25. 25. 25.  1.  1.  1. 11.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 16. 30. 26. 30.  8.  0.  9.  0.  3.  4.  3.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 1.  1.  1. 16.  3.] 
adversary cards in discard: [ 3.  0.  0. 29.  3.  0. 29. 14.  0.  1.  3. 11.  3.  1. 11.  1.  0.  0.
  6.  0.  1.  3.  6.  6.  6.  8.  6.  6.  0.  0. 25. 22.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0] -> size -> 48 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -29.544845581054688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[ 3.0763564]
 [12.948639 ]
 [ 7.0998254]
 [10.558876 ]
 [ 4.710052 ]
 [ 9.5857315]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3. 11.  0.  3.  1.] 
cards in discard: [ 1. 11.  8.  8.  0. 10. 25. 25. 25.  1.  1.  1. 11.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 16. 30. 26. 30.  8.  0.  9.  0.  3.  4.  3.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 1.  1.  1. 16.  3.] 
adversary cards in discard: [ 3.  0.  0. 29.  3.  0. 29. 14.  0.  1.  3. 11.  3.  1. 11.  1.  0.  0.
  6.  0.  1.  3.  6.  6.  6.  8.  6.  6.  0.  0. 25. 22.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0] -> size -> 48 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 9.399288177490234



buy possibilites: [-1] 
expected returns: [[20.1508]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3. 11.  0.  3.  1.] 
cards in discard: [ 1. 11.  8.  8.  0. 10. 25. 25. 25.  1.  1.  1. 11.  0.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 15. 30. 26. 30.  8.  0.  9.  0.  3.  4.  3.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 1.  1.  1. 16.  3.] 
adversary cards in discard: [ 3.  0.  0. 29.  3.  0. 29. 14.  0.  1.  3. 11.  3.  1. 11.  1.  0.  0.
  6.  0.  1.  3.  6.  6.  6.  8.  6.  6.  0.  0. 25. 22.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0] -> size -> 48 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0 -50   0   0  54   0] 
sum of rewards: 199 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 12.948614120483398






Player: 1 
cards in hand: [ 1.  1.  1. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1.  1. 16.  3.] 
cards in discard: [ 3.  0.  0. 29.  3.  0. 29. 14.  0.  1.  3. 11.  3.  1. 11.  1.  0.  0.
  6.  0.  1.  3.  6.  6.  6.  8.  6.  6.  0.  0. 25. 22.  0.  8.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 15. 30. 26. 30.  8.  0.  9.  0.  3.  4.  3.  9. 10.  6.  9. 10.] 
adversary cards in hand: [25. 11. 11.  8.  0.] 
adversary cards in discard: [ 1. 11.  8.  8.  0. 10. 25. 25. 25.  1.  1.  1. 11.  0.  1. 25. 29.  3.
 11.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1] -> size -> 40 
adversary victory points: 2
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1.  1. 16.  3.] 
cards in discard: [ 3.  0.  0. 29.  3.  0. 29. 14.  0.  1.  3. 11.  3.  1. 11.  1.  0.  0.
  6.  0.  1.  3.  6.  6.  6.  8.  6.  6.  0.  0. 25. 22.  0.  8.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0] -> size -> 48 
action values: 0 
buys: 1 
player value: 6 
card supply: [23. 15. 30. 26. 30.  8.  0.  9.  0.  3.  4.  3.  9. 10.  6.  9. 10.] 
adversary cards in hand: [25. 11. 11.  8.  0.] 
adversary cards in discard: [ 1. 11.  8.  8.  0. 10. 25. 25. 25.  1.  1.  1. 11.  0.  1. 25. 29.  3.
 11.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1] -> size -> 40 
adversary victory points: 2
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1.  1. 16.  3.] 
cards in discard: [ 3.  0.  0. 29.  3.  0. 29. 14.  0.  1.  3. 11.  3.  1. 11.  1.  0.  0.
  6.  0.  1.  3.  6.  6.  6.  8.  6.  6.  0.  0. 25. 22.  0.  8.  6.  4.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4] -> size -> 49 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 15. 30. 26. 29.  8.  0.  9.  0.  3.  4.  3.  9. 10.  6.  9. 10.] 
adversary cards in hand: [25. 11. 11.  8.  0.] 
adversary cards in discard: [ 1. 11.  8.  8.  0. 10. 25. 25. 25.  1.  1.  1. 11.  0.  1. 25. 29.  3.
 11.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1] -> size -> 40 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [25. 11. 11.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 11.  8.] 
expected returns: [[-34.522568]
 [-18.211195]
 [-29.861834]
 [-29.861834]
 [-33.653088]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11. 11.  8.  0.] 
cards in discard: [ 1. 11.  8.  8.  0. 10. 25. 25. 25.  1.  1.  1. 11.  0.  1. 25. 29.  3.
 11.  0.  3.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 15. 30. 26. 29.  8.  0.  9.  0.  3.  4.  3.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 6.  0.  6. 29.  0.] 
adversary cards in discard: [ 3.  0.  0. 29.  3.  0. 29. 14.  0.  1.  3. 11.  3.  1. 11.  1.  0.  0.
  6.  0.  1.  3.  6.  6.  6.  8.  6.  6.  0.  0. 25. 22.  0.  8.  6.  4.
  1.  1.  1. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4] -> size -> 49 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 20.150800704956055



action possibilites: [-1] 
expected returns: [[-29.507833]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  8.  0.  8. 11.] 
cards in discard: [ 1. 11.  8.  8.  0. 10. 25. 25. 25.  1.  1.  1. 11.  0.  1. 25. 29.  3.
 11.  0.  3.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 15. 30. 26. 29.  8.  0.  9.  0.  3.  4.  3.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 6.  0.  6. 29.  0.] 
adversary cards in discard: [ 3.  0.  0. 29.  3.  0. 29. 14.  0.  1.  3. 11.  3.  1. 11.  1.  0.  0.
  6.  0.  1.  3.  6.  6.  6.  8.  6.  6.  0.  0. 25. 22.  0.  8.  6.  4.
  1.  1.  1. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4] -> size -> 49 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -18.211198806762695





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-36.375565]
 [-29.598627]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  8.  0.  8. 11.] 
cards in discard: [ 1. 11.  8.  8.  0. 10. 25. 25. 25.  1.  1.  1. 11.  0.  1. 25. 29.  3.
 11.  0.  3.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 15. 30. 26. 29.  8.  0.  9.  0.  3.  4.  3.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 6.  0.  6. 29.  0.] 
adversary cards in discard: [ 3.  0.  0. 29.  3.  0. 29. 14.  0.  1.  3. 11.  3.  1. 11.  1.  0.  0.
  6.  0.  1.  3.  6.  6.  6.  8.  6.  6.  0.  0. 25. 22.  0.  8.  6.  4.
  1.  1.  1. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4] -> size -> 49 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -29.50783348083496






Player: 1 
cards in hand: [ 6.  0.  6. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  6. 29.  0.] 
cards in discard: [ 3.  0.  0. 29.  3.  0. 29. 14.  0.  1.  3. 11.  3.  1. 11.  1.  0.  0.
  6.  0.  1.  3.  6.  6.  6.  8.  6.  6.  0.  0. 25. 22.  0.  8.  6.  4.
  1.  1.  1. 16.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 15. 30. 26. 29.  8.  0.  9.  0.  3.  4.  3.  9. 10.  6.  9. 10.] 
adversary cards in hand: [29.  0.  8. 11. 10.] 
adversary cards in discard: [ 1. 11.  8.  8.  0. 10. 25. 25. 25.  1.  1.  1. 11.  0.  1. 25. 29.  3.
 11.  0.  3.  1. 25. 11. 11.  8.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1] -> size -> 40 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0.] 
cards in discard: [ 3.  0.  0. 29.  3.  0. 29. 14.  0.  1.  3. 11.  3.  1. 11.  1.  0.  0.
  6.  0.  1.  3.  6.  6.  6.  8.  6.  6.  0.  0. 25. 22.  0.  8.  6.  4.
  1.  1.  1. 16.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4] -> size -> 49 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 15. 30. 26. 29.  8.  0.  9.  0.  3.  4.  3.  9. 10.  6.  9. 10.] 
adversary cards in hand: [29.  0.  8. 11. 10.] 
adversary cards in discard: [ 1. 11.  8.  8.  0. 10. 25. 25. 25.  1.  1.  1. 11.  0.  1. 25. 29.  3.
 11.  0.  3.  1. 25. 11. 11.  8.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1] -> size -> 40 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0.] 
cards in discard: [ 3.  0.  0. 29.  3.  0. 29. 14.  0.  1.  3. 11.  3.  1. 11.  1.  0.  0.
  6.  0.  1.  3.  6.  6.  6.  8.  6.  6.  0.  0. 25. 22.  0.  8.  6.  4.
  1.  1.  1. 16.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4] -> size -> 49 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 15. 30. 26. 29.  8.  0.  9.  0.  3.  4.  3.  9. 10.  6.  9. 10.] 
adversary cards in hand: [29.  0.  8. 11. 10.] 
adversary cards in discard: [ 1. 11.  8.  8.  0. 10. 25. 25. 25.  1.  1.  1. 11.  0.  1. 25. 29.  3.
 11.  0.  3.  1. 25. 11. 11.  8.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1] -> size -> 40 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0.] 
cards in discard: [ 3.  0.  0. 29.  3.  0. 29. 14.  0.  1.  3. 11.  3.  1. 11.  1.  0.  0.
  6.  0.  1.  3.  6.  6.  6.  8.  6.  6.  0.  0. 25. 22.  0.  8.  6.  4.
  1.  1.  1. 16.  3.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4  3] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 15. 30. 25. 29.  8.  0.  9.  0.  3.  4.  3.  9. 10.  6.  9. 10.] 
adversary cards in hand: [29.  0.  8. 11. 10.] 
adversary cards in discard: [ 1. 11.  8.  8.  0. 10. 25. 25. 25.  1.  1.  1. 11.  0.  1. 25. 29.  3.
 11.  0.  3.  1. 25. 11. 11.  8.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1] -> size -> 40 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [29.  0.  8. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 11. 10.] 
expected returns: [[-67.77315 ]
 [-58.39669 ]
 [-66.86884 ]
 [-62.562553]
 [-73.0998  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  8. 11. 10.] 
cards in discard: [ 1. 11.  8.  8.  0. 10. 25. 25. 25.  1.  1.  1. 11.  0.  1. 25. 29.  3.
 11.  0.  3.  1. 25. 11. 11.  8.  0.  8. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 15. 30. 25. 29.  8.  0.  9.  0.  3.  4.  3.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 6.  0.  3. 29.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4  3] -> size -> 50 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -29.598636627197266



action possibilites: [-1. 10.] 
expected returns: [[-72.124306]
 [-76.75299 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  1.] 
cards in discard: [ 1. 11.  8.  8.  0. 10. 25. 25. 25.  1.  1.  1. 11.  0.  1. 25. 29.  3.
 11.  0.  3.  1. 25. 11. 11.  8.  0.  8. 11.  8. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 15. 30. 25. 29.  8.  0.  9.  0.  3.  4.  3.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 6.  0.  3. 29.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4  3] -> size -> 50 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: -56.33158874511719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-78.266464]
 [-69.230095]
 [-74.56602 ]
 [-72.299866]
 [-71.41705 ]
 [-64.14243 ]
 [-84.48132 ]
 [-76.753   ]
 [-75.444954]
 [-72.124306]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  1.] 
cards in discard: [ 1. 11.  8.  8.  0. 10. 25. 25. 25.  1.  1.  1. 11.  0.  1. 25. 29.  3.
 11.  0.  3.  1. 25. 11. 11.  8.  0.  8. 11.  8. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 15. 30. 25. 29.  8.  0.  9.  0.  3.  4.  3.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 6.  0.  3. 29.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4  3] -> size -> 50 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -72.12430572509766



buy possibilites: [-1] 
expected returns: [[-67.92127]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  1.] 
cards in discard: [ 1. 11.  8.  8.  0. 10. 25. 25. 25.  1.  1.  1. 11.  0.  1. 25. 29.  3.
 11.  0.  3.  1. 25. 11. 11.  8.  0.  8. 11.  8. 11. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 15. 30. 25. 29.  8.  0.  9.  0.  3.  4.  2.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 6.  0.  3. 29.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4  3] -> size -> 50 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0 -60   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: -64.14242553710938






Player: 1 
cards in hand: [ 6.  0.  3. 29.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3. 29.  6.] 
cards in discard: [] 
cards in deck: 45 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4  3] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 15. 30. 25. 29.  8.  0.  9.  0.  3.  4.  2.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  0.  1. 29. 11.] 
adversary cards in discard: [ 1. 11.  8.  8.  0. 10. 25. 25. 25.  1.  1.  1. 11.  0.  1. 25. 29.  3.
 11.  0.  3.  1. 25. 11. 11.  8.  0.  8. 11.  8. 11. 29. 29.  0. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29] -> size -> 41 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6.] 
cards in discard: [3. 6.] 
cards in deck: 44 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4  3] -> size -> 50 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 15. 30. 25. 29.  8.  0.  9.  0.  3.  4.  2.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  0.  1. 29. 11.] 
adversary cards in discard: [ 1. 11.  8.  8.  0. 10. 25. 25. 25.  1.  1.  1. 11.  0.  1. 25. 29.  3.
 11.  0.  3.  1. 25. 11. 11.  8.  0.  8. 11.  8. 11. 29. 29.  0. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29] -> size -> 41 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6.] 
cards in discard: [3. 6.] 
cards in deck: 44 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4  3] -> size -> 50 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 15. 30. 25. 29.  8.  0.  9.  0.  3.  4.  2.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  0.  1. 29. 11.] 
adversary cards in discard: [ 1. 11.  8.  8.  0. 10. 25. 25. 25.  1.  1.  1. 11.  0.  1. 25. 29.  3.
 11.  0.  3.  1. 25. 11. 11.  8.  0.  8. 11.  8. 11. 29. 29.  0. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29] -> size -> 41 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6.] 
cards in discard: [3. 6. 3.] 
cards in deck: 44 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4  3  3] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 15. 30. 24. 29.  8.  0.  9.  0.  3.  4.  2.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  0.  1. 29. 11.] 
adversary cards in discard: [ 1. 11.  8.  8.  0. 10. 25. 25. 25.  1.  1.  1. 11.  0.  1. 25. 29.  3.
 11.  0.  3.  1. 25. 11. 11.  8.  0.  8. 11.  8. 11. 29. 29.  0. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29] -> size -> 41 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  1. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[-37.17447 ]
 [-26.701721]
 [-31.525545]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 29. 11.] 
cards in discard: [ 1. 11.  8.  8.  0. 10. 25. 25. 25.  1.  1.  1. 11.  0.  1. 25. 29.  3.
 11.  0.  3.  1. 25. 11. 11.  8.  0.  8. 11.  8. 11. 29. 29.  0. 10.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 15. 30. 24. 29.  8.  0.  9.  0.  3.  4.  2.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 1.  1. 29.  0.  6.] 
adversary cards in discard: [ 3.  6.  3. 29.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4  3  3] -> size -> 51 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -67.92127227783203



action possibilites: [-1. 11. 25.] 
expected returns: [[ 1.6927142]
 [ 9.728983 ]
 [28.477629 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11. 25.] 
cards in discard: [0. 0.] 
cards in deck: 35 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 15. 30. 24. 29.  8.  0.  9.  0.  3.  4.  2.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 1.  1. 29.  0.  6.] 
adversary cards in discard: [ 3.  6.  3. 29.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4  3  3] -> size -> 51 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -33.53092575073242



action possibilites: [-1] 
expected returns: [[38.77722]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11. 10. 25.] 
cards in discard: [0. 0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 15. 30. 24. 29.  8.  0.  9.  0.  3.  4.  2.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 1.  1. 29.  0.  6.] 
adversary cards in discard: [ 3.  6.  3. 29.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4  3  3] -> size -> 51 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 28.477628707885742





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[29.173021]
 [44.07754 ]
 [35.250313]
 [40.462666]
 [31.635443]
 [39.05025 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11. 10. 25.] 
cards in discard: [0. 0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 15. 30. 24. 29.  8.  0.  9.  0.  3.  4.  2.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 1.  1. 29.  0.  6.] 
adversary cards in discard: [ 3.  6.  3. 29.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4  3  3] -> size -> 51 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 38.7772216796875



buy possibilites: [-1] 
expected returns: [[54.49195]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11. 10. 25.] 
cards in discard: [0. 0. 1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 14. 30. 24. 29.  8.  0.  9.  0.  3.  4.  2.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 1.  1. 29.  0.  6.] 
adversary cards in discard: [ 3.  6.  3. 29.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4  3  3] -> size -> 51 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  30   0   0  40   0   0   0   0 -70   0   0  54   0] 
sum of rewards: 49 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 44.07754135131836






Player: 1 
cards in hand: [ 1.  1. 29.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1. 29.  0.  6.] 
cards in discard: [ 3.  6.  3. 29.  0.  6.  6.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4  3  3] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 14. 30. 24. 29.  8.  0.  9.  0.  3.  4.  2.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 1. 11. 29.  0.  8.] 
adversary cards in discard: [ 0.  0.  1. 29. 25.  1. 11. 10. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1] -> size -> 42 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 1.] 
cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0.] 
cards in deck: 38 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4  3  3] -> size -> 51 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 14. 30. 24. 29.  8.  0.  9.  0.  3.  4.  2.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 1. 11. 29.  0.  8.] 
adversary cards in discard: [ 0.  0.  1. 29. 25.  1. 11. 10. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1] -> size -> 42 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 1.] 
cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0.] 
cards in deck: 38 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4  3  3] -> size -> 51 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 14. 30. 24. 29.  8.  0.  9.  0.  3.  4.  2.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 1. 11. 29.  0.  8.] 
adversary cards in discard: [ 0.  0.  1. 29. 25.  1. 11. 10. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1] -> size -> 42 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 1.] 
cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15.] 
cards in deck: 38 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4  3  3 15] -> size -> 52 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 14. 30. 24. 29.  8.  0.  9.  0.  3.  4.  2.  9. 10.  6.  9.  9.] 
adversary cards in hand: [ 1. 11. 29.  0.  8.] 
adversary cards in discard: [ 0.  0.  1. 29. 25.  1. 11. 10. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1] -> size -> 42 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 1. 11. 29.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.  8.] 
expected returns: [[-1.1412721 ]
 [ 5.0902925 ]
 [10.074213  ]
 [ 0.04790545]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11. 29.  0.  8.] 
cards in discard: [ 0.  0.  1. 29. 25.  1. 11. 10. 25.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 14. 30. 24. 29.  8.  0.  9.  0.  3.  4.  2.  9. 10.  6.  9.  9.] 
adversary cards in hand: [25.  1.  1.  1. 11.] 
adversary cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15. 29.  1.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4  3  3 15] -> size -> 52 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 54.49195098876953



action possibilites: [-1. 11.] 
expected returns: [[ 9.105698]
 [15.578047]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  1.] 
cards in discard: [ 0.  0.  1. 29. 25.  1. 11. 10. 25.  0.  8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 14. 30. 24. 29.  8.  0.  9.  0.  3.  4.  2.  9. 10.  6.  9.  9.] 
adversary cards in hand: [25.  1.  1.  1. 11.] 
adversary cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15. 29.  1.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4  3  3 15] -> size -> 52 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 12.756155014038086



action possibilites: [-1] 
expected returns: [[2.4357257]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1.] 
cards in discard: [ 0.  0.  1. 29. 25.  1. 11. 10. 25.  0.  8.  1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 13. 30. 24. 29.  8.  0.  9.  0.  3.  4.  2.  9. 10.  6.  9.  9.] 
adversary cards in hand: [25.  1.  1.  1. 11.] 
adversary cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15. 29.  1.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4  3  3 15] -> size -> 52 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  30   0   0  40   0   0   0   0 -80   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 13.462610244750977





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ -5.6857133 ]
 [  6.17565   ]
 [ -0.82316923]
 [-15.829195  ]
 [  2.1896806 ]
 [  3.315329  ]
 [ 24.972322  ]
 [ 13.429495  ]
 [-13.997983  ]
 [ -3.1335459 ]
 [ -3.6835804 ]
 [-15.056244  ]
 [ -2.0078745 ]
 [  2.140798  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1.] 
cards in discard: [ 0.  0.  1. 29. 25.  1. 11. 10. 25.  0.  8.  1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1] -> size -> 43 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 13. 30. 24. 29.  8.  0.  9.  0.  3.  4.  2.  9. 10.  6.  9.  9.] 
adversary cards in hand: [25.  1.  1.  1. 11.] 
adversary cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15. 29.  1.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4  3  3 15] -> size -> 52 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 2.435725688934326



buy possibilites: [-1] 
expected returns: [[11.832064]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1.] 
cards in discard: [ 0.  0.  1. 29. 25.  1. 11. 10. 25.  0.  8.  1. 25.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1 25] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 13. 30. 24. 29.  8.  0.  9.  0.  3.  3.  2.  9. 10.  6.  9.  9.] 
adversary cards in hand: [25.  1.  1.  1. 11.] 
adversary cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15. 29.  1.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4  3  3 15] -> size -> 52 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  30   0   0  40   0   0   0   0 -90   0   0 250   0] 
sum of rewards: 225 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 24.972335815429688






Player: 1 
cards in hand: [25.  1.  1.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  1.  1. 11.] 
cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15. 29.  1.  6.  1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4  3  3 15] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 13. 30. 24. 29.  8.  0.  9.  0.  3.  3.  2.  9. 10.  6.  9.  9.] 
adversary cards in hand: [ 8. 11.  0.  0.  3.] 
adversary cards in discard: [ 0.  0.  1. 29. 25.  1. 11. 10. 25.  0.  8.  1. 25. 29. 11.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1 25] -> size -> 44 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1.  1.  1. 11.] 
cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15. 29.  1.  6.  1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4  3  3 15] -> size -> 52 
action values: 0 
buys: 1 
player value: 6 
card supply: [23. 13. 30. 24. 29.  8.  0.  9.  0.  3.  3.  2.  9. 10.  6.  9.  9.] 
adversary cards in hand: [ 8. 11.  0.  0.  3.] 
adversary cards in discard: [ 0.  0.  1. 29. 25.  1. 11. 10. 25.  0.  8.  1. 25. 29. 11.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1 25] -> size -> 44 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1.  1.  1. 11.] 
cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15. 29.  1.  6.  1. 22.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4  3  3 15 22] -> size -> 53 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 13. 30. 24. 29.  8.  0.  9.  0.  3.  3.  2.  9. 10.  6.  8.  9.] 
adversary cards in hand: [ 8. 11.  0.  0.  3.] 
adversary cards in discard: [ 0.  0.  1. 29. 25.  1. 11. 10. 25.  0.  8.  1. 25. 29. 11.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1 25] -> size -> 44 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 8. 11.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[-15.741003 ]
 [-14.82913  ]
 [-11.0624275]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.  0.  3.] 
cards in discard: [ 0.  0.  1. 29. 25.  1. 11. 10. 25.  0.  8.  1. 25. 29. 11.  1.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1 25] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 13. 30. 24. 29.  8.  0.  9.  0.  3.  3.  2.  9. 10.  6.  8.  9.] 
adversary cards in hand: [ 0.  0.  0.  3. 29.] 
adversary cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15. 29.  1.  6.  1. 22. 25.  1.  1.
  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4  3  3 15 22] -> size -> 53 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 11.832063674926758



action possibilites: [-1] 
expected returns: [[-30.199007]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3.] 
cards in discard: [ 0.  0.  1. 29. 25.  1. 11. 10. 25.  0.  8.  1. 25. 29. 11.  1.  1.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1 25  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 12. 30. 24. 29.  8.  0.  9.  0.  3.  3.  2.  9. 10.  6.  8.  9.] 
adversary cards in hand: [ 0.  0.  0.  3. 29.] 
adversary cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15. 29.  1.  6.  1. 22. 25.  1.  1.
  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4  3  3 15 22] -> size -> 53 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[  -5    0    0   30    0    0   20    0    0    0    0 -100    0    0
   27    0] 
sum of rewards: -28 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -12.589371681213379





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-37.599277]
 [-33.321857]
 [-29.645792]
 [-30.676205]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3.] 
cards in discard: [ 0.  0.  1. 29. 25.  1. 11. 10. 25.  0.  8.  1. 25. 29. 11.  1.  1.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1 25  1] -> size -> 45 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 12. 30. 24. 29.  8.  0.  9.  0.  3.  3.  2.  9. 10.  6.  8.  9.] 
adversary cards in hand: [ 0.  0.  0.  3. 29.] 
adversary cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15. 29.  1.  6.  1. 22. 25.  1.  1.
  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4  3  3 15 22] -> size -> 53 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: -30.199007034301758



buy possibilites: [-1] 
expected returns: [[-23.678347]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3.] 
cards in discard: [ 0.  0.  1. 29. 25.  1. 11. 10. 25.  0.  8.  1. 25. 29. 11.  1.  1.  1.
  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1 25  1  8] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 12. 30. 24. 29.  8.  0.  9.  0.  2.  3.  2.  9. 10.  6.  8.  9.] 
adversary cards in hand: [ 0.  0.  0.  3. 29.] 
adversary cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15. 29.  1.  6.  1. 22. 25.  1.  1.
  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4  3  3 15 22] -> size -> 53 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[  -5    0    0   30    0    0   20    0    0    0    0 -110    0    0
   16    0] 
sum of rewards: -49 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -29.64579200744629






Player: 1 
cards in hand: [ 0.  0.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 29.] 
cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15. 29.  1.  6.  1. 22. 25.  1.  1.
  1. 11.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4  3  3 15 22] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 12. 30. 24. 29.  8.  0.  9.  0.  2.  3.  2.  9. 10.  6.  8.  9.] 
adversary cards in hand: [29. 25.  1.  0.  1.] 
adversary cards in discard: [ 0.  0.  1. 29. 25.  1. 11. 10. 25.  0.  8.  1. 25. 29. 11.  1.  1.  1.
  8. 11.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1 25  1  8] -> size -> 46 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 29.] 
cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15. 29.  1.  6.  1. 22. 25.  1.  1.
  1. 11.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4  3  3 15 22] -> size -> 53 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 12. 30. 24. 29.  8.  0.  9.  0.  2.  3.  2.  9. 10.  6.  8.  9.] 
adversary cards in hand: [29. 25.  1.  0.  1.] 
adversary cards in discard: [ 0.  0.  1. 29. 25.  1. 11. 10. 25.  0.  8.  1. 25. 29. 11.  1.  1.  1.
  8. 11.  8.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1 25  1  8] -> size -> 46 
adversary victory points: 2
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [29. 25.  1.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[-13.494169 ]
 [ -4.3469877]
 [  4.355307 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  1.  0.  1.] 
cards in discard: [ 0.  0.  1. 29. 25.  1. 11. 10. 25.  0.  8.  1. 25. 29. 11.  1.  1.  1.
  8. 11.  8.  0.  0.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1 25  1  8] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 12. 30. 24. 29.  8.  0.  9.  0.  2.  3.  2.  9. 10.  6.  8.  9.] 
adversary cards in hand: [ 3.  0. 14.  6.  6.] 
adversary cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15. 29.  1.  6.  1. 22. 25.  1.  1.
  1. 11.  0.  0.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4  3  3 15 22] -> size -> 53 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -23.678346633911133



action possibilites: [-1] 
expected returns: [[-15.164284]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  0.  1. 11.  1.] 
cards in discard: [ 0.  0.  1. 29. 25.  1. 11. 10. 25.  0.  8.  1. 25. 29. 11.  1.  1.  1.
  8. 11.  8.  0.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1 25  1  8] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 12. 30. 24. 29.  8.  0.  9.  0.  2.  3.  2.  9. 10.  6.  8.  9.] 
adversary cards in hand: [ 3.  0. 14.  6.  6.] 
adversary cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15. 29.  1.  6.  1. 22. 25.  1.  1.
  1. 11.  0.  0.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4  3  3 15 22] -> size -> 53 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 4.355291843414307





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-21.213787 ]
 [-12.132881 ]
 [-26.587988 ]
 [-17.507078 ]
 [-28.997093 ]
 [-15.20512  ]
 [-14.33144  ]
 [  1.6434712]
 [ -7.025167 ]
 [-27.488943 ]
 [-19.28171  ]
 [-19.705637 ]
 [-28.362623 ]
 [-18.408033 ]
 [-15.164288 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  0.  1. 11.  1.] 
cards in discard: [ 0.  0.  1. 29. 25.  1. 11. 10. 25.  0.  8.  1. 25. 29. 11.  1.  1.  1.
  8. 11.  8.  0.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1 25  1  8] -> size -> 46 
action values: 0 
buys: 1 
player value: 7 
card supply: [23. 12. 30. 24. 29.  8.  0.  9.  0.  2.  3.  2.  9. 10.  6.  8.  9.] 
adversary cards in hand: [ 3.  0. 14.  6.  6.] 
adversary cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15. 29.  1.  6.  1. 22. 25.  1.  1.
  1. 11.  0.  0.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4  3  3 15 22] -> size -> 53 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: -15.164283752441406



buy possibilites: [-1] 
expected returns: [[-19.38186]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  0.  1. 11.  1.] 
cards in discard: [ 0.  0.  1. 29. 25.  1. 11. 10. 25.  0.  8.  1. 25. 29. 11.  1.  1.  1.
  8. 11.  8.  0.  0.  3. 25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1 25  1  8 25] -> size -> 47 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 12. 30. 24. 29.  8.  0.  9.  0.  2.  2.  2.  9. 10.  6.  8.  9.] 
adversary cards in hand: [ 3.  0. 14.  6.  6.] 
adversary cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15. 29.  1.  6.  1. 22. 25.  1.  1.
  1. 11.  0.  0.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4  3  3 15 22] -> size -> 53 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[  -5.     0.     0.    30.     0.     0.    20.     0.     0.     0.
    0.  -120.     0.     0.    62.5    0. ] 
sum of rewards: -12.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 1.643481731414795






Player: 1 
cards in hand: [ 3.  0. 14.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 14.  6.  6.] 
cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15. 29.  1.  6.  1. 22. 25.  1.  1.
  1. 11.  0.  0.  0.  3. 29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4  3  3 15 22] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 12. 30. 24. 29.  8.  0.  9.  0.  2.  2.  2.  9. 10.  6.  8.  9.] 
adversary cards in hand: [ 8. 11. 25.  0. 25.] 
adversary cards in discard: [ 0.  0.  1. 29. 25.  1. 11. 10. 25.  0.  8.  1. 25. 29. 11.  1.  1.  1.
  8. 11.  8.  0.  0.  3. 25. 25. 29.  1.  0.  1. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1 25  1  8 25] -> size -> 47 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 14.  6.  6.] 
cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15. 29.  1.  6.  1. 22. 25.  1.  1.
  1. 11.  0.  0.  0.  3. 29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4  3  3 15 22] -> size -> 53 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 12. 30. 24. 29.  8.  0.  9.  0.  2.  2.  2.  9. 10.  6.  8.  9.] 
adversary cards in hand: [ 8. 11. 25.  0. 25.] 
adversary cards in discard: [ 0.  0.  1. 29. 25.  1. 11. 10. 25.  0.  8.  1. 25. 29. 11.  1.  1.  1.
  8. 11.  8.  0.  0.  3. 25. 25. 29.  1.  0.  1. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1 25  1  8 25] -> size -> 47 
adversary victory points: 2
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 8. 11. 25.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 25. 25.] 
expected returns: [[-37.025085]
 [-35.28269 ]
 [-28.321295]
 [-11.411797]
 [-11.411797]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 25.  0. 25.] 
cards in discard: [ 0.  0.  1. 29. 25.  1. 11. 10. 25.  0.  8.  1. 25. 29. 11.  1.  1.  1.
  8. 11.  8.  0.  0.  3. 25. 25. 29.  1.  0.  1. 11.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1 25  1  8 25] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 12. 30. 24. 29.  8.  0.  9.  0.  2.  2.  2.  9. 10.  6.  8.  9.] 
adversary cards in hand: [ 0.  6. 16. 22.  1.] 
adversary cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15. 29.  1.  6.  1. 22. 25.  1.  1.
  1. 11.  0.  0.  0.  3. 29.  3.  0. 14.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4  3  3 15 22] -> size -> 53 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -19.381860733032227



action possibilites: [-1] 
expected returns: [[-51.657608]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0. 25.  1. 11.] 
cards in discard: [ 0.  0.  1. 29. 25.  1. 11. 10. 25.  0.  8.  1. 25. 29. 11.  1.  1.  1.
  8. 11.  8.  0.  0.  3. 25. 25. 29.  1.  0.  1. 11.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1 25  1  8 25] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 12. 30. 24. 29.  8.  0.  9.  0.  2.  2.  2.  9. 10.  6.  8.  9.] 
adversary cards in hand: [ 0.  6. 16. 22.  1.] 
adversary cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15. 29.  1.  6.  1. 22. 25.  1.  1.
  1. 11.  0.  0.  0.  3. 29.  3.  0. 14.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4  3  3 15 22] -> size -> 53 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -11.411783218383789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[-58.768612]
 [-47.97381 ]
 [-54.356   ]
 [-50.585796]
 [-56.967995]
 [-51.657597]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0. 25.  1. 11.] 
cards in discard: [ 0.  0.  1. 29. 25.  1. 11. 10. 25.  0.  8.  1. 25. 29. 11.  1.  1.  1.
  8. 11.  8.  0.  0.  3. 25. 25. 29.  1.  0.  1. 11.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1 25  1  8 25] -> size -> 47 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 12. 30. 24. 29.  8.  0.  9.  0.  2.  2.  2.  9. 10.  6.  8.  9.] 
adversary cards in hand: [ 0.  6. 16. 22.  1.] 
adversary cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15. 29.  1.  6.  1. 22. 25.  1.  1.
  1. 11.  0.  0.  0.  3. 29.  3.  0. 14.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4  3  3 15 22] -> size -> 53 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: -51.65760803222656



buy possibilites: [-1] 
expected returns: [[-35.00326]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  0. 25.  1. 11.] 
cards in discard: [ 0.  0.  1. 29. 25.  1. 11. 10. 25.  0.  8.  1. 25. 29. 11.  1.  1.  1.
  8. 11.  8.  0.  0.  3. 25. 25. 29.  1.  0.  1. 11.  1.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1 25  1  8 25  1] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 11. 30. 24. 29.  8.  0.  9.  0.  2.  2.  2.  9. 10.  6.  8.  9.] 
adversary cards in hand: [ 0.  6. 16. 22.  1.] 
adversary cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15. 29.  1.  6.  1. 22. 25.  1.  1.
  1. 11.  0.  0.  0.  3. 29.  3.  0. 14.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4  3  3 15 22] -> size -> 53 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[  -5    0    0   30    0    0   20    0    0    0    0 -130    0    0
   54    0] 
sum of rewards: -31 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -47.97382354736328






Player: 1 
cards in hand: [ 0.  6. 16. 22.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 22.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 16. 22.  1.] 
cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15. 29.  1.  6.  1. 22. 25.  1.  1.
  1. 11.  0.  0.  0.  3. 29.  3.  0. 14.  6.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6
  0  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0
  4  3  3 15 22] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 11. 30. 24. 29.  8.  0.  9.  0.  2.  2.  2.  9. 10.  6.  8.  9.] 
adversary cards in hand: [ 3.  8. 11. 11. 10.] 
adversary cards in discard: [ 0.  0.  1. 29. 25.  1. 11. 10. 25.  0.  8.  1. 25. 29. 11.  1.  1.  1.
  8. 11.  8.  0.  0.  3. 25. 25. 29.  1.  0.  1. 11.  1.  1. 25.  8. 11.
  0. 25.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1 25  1  8 25  1] -> size -> 48 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 22.  1.] 
cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15. 29.  1.  6.  1. 22. 25.  1.  1.
  1. 11.  0.  0.  0.  3. 29.  3.  0. 14.  6.  6.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6  0
  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0  4
  3  3 15 22  3] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 11. 30. 23. 29.  8.  0.  9.  0.  2.  2.  2.  9. 10.  6.  8.  9.] 
adversary cards in hand: [ 3.  8. 11. 11. 10.] 
adversary cards in discard: [ 0.  0.  1. 29. 25.  1. 11. 10. 25.  0.  8.  1. 25. 29. 11.  1.  1.  1.
  8. 11.  8.  0.  0.  3. 25. 25. 29.  1.  0.  1. 11.  1.  1. 25.  8. 11.
  0. 25.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1 25  1  8 25  1] -> size -> 48 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 22.  1.] 
cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15. 29.  1.  6.  1. 22. 25.  1.  1.
  1. 11.  0.  0.  0.  3. 29.  3.  0. 14.  6.  6.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6  0
  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0  4
  3  3 15 22  3] -> size -> 53 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 11. 30. 23. 29.  8.  0.  9.  0.  2.  2.  2.  9. 10.  6.  8.  9.] 
adversary cards in hand: [ 3.  8. 11. 11. 10.] 
adversary cards in discard: [ 0.  0.  1. 29. 25.  1. 11. 10. 25.  0.  8.  1. 25. 29. 11.  1.  1.  1.
  8. 11.  8.  0.  0.  3. 25. 25. 29.  1.  0.  1. 11.  1.  1. 25.  8. 11.
  0. 25.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1 25  1  8 25  1] -> size -> 48 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 3.  8. 11. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 11. 10.] 
expected returns: [[-71.56448]
 [-70.35869]
 [-65.53224]
 [-65.53224]
 [-77.38657]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 11. 11. 10.] 
cards in discard: [ 0.  0.  1. 29. 25.  1. 11. 10. 25.  0.  8.  1. 25. 29. 11.  1.  1.  1.
  8. 11.  8.  0.  0.  3. 25. 25. 29.  1.  0.  1. 11.  1.  1. 25.  8. 11.
  0. 25.  1. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1 25  1  8 25  1] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 11. 30. 23. 29.  8.  0.  9.  0.  2.  2.  2.  9. 10.  6.  8.  9.] 
adversary cards in hand: [ 0.  6. 11.  0.  8.] 
adversary cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15. 29.  1.  6.  1. 22. 25.  1.  1.
  1. 11.  0.  0.  0.  3. 29.  3.  0. 14.  6.  6.  3. 16.  6. 22.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6  0
  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0  4
  3  3 15 22  3] -> size -> 53 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -35.00326156616211



action possibilites: [-1] 
expected returns: [[-93.5832]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 11. 10.] 
cards in discard: [ 0.  0.  1. 29. 25.  1. 11. 10. 25.  0.  8.  1. 25. 29. 11.  1.  1.  1.
  8. 11.  8.  0.  0.  3. 25. 25. 29.  1.  0.  1. 11.  1.  1. 25.  8. 11.
  0. 25.  1. 11.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1 25  1  8 25  1
  1] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 10. 30. 23. 29.  8.  0.  9.  0.  2.  2.  2.  9. 10.  6.  8.  9.] 
adversary cards in hand: [ 0.  6. 11.  0.  8.] 
adversary cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15. 29.  1.  6.  1. 22. 25.  1.  1.
  1. 11.  0.  0.  0.  3. 29.  3.  0. 14.  6.  6.  3. 16.  6. 22.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6  0
  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0  4
  3  3 15 22  3] -> size -> 53 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0 -140    0    0
   27    0] 
sum of rewards: -98 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -68.8333969116211





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-100.12422 ]
 [ -93.583206]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 11. 10.] 
cards in discard: [ 0.  0.  1. 29. 25.  1. 11. 10. 25.  0.  8.  1. 25. 29. 11.  1.  1.  1.
  8. 11.  8.  0.  0.  3. 25. 25. 29.  1.  0.  1. 11.  1.  1. 25.  8. 11.
  0. 25.  1. 11.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1 25  1  8 25  1
  1] -> size -> 49 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 10. 30. 23. 29.  8.  0.  9.  0.  2.  2.  2.  9. 10.  6.  8.  9.] 
adversary cards in hand: [ 0.  6. 11.  0.  8.] 
adversary cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15. 29.  1.  6.  1. 22. 25.  1.  1.
  1. 11.  0.  0.  0.  3. 29.  3.  0. 14.  6.  6.  3. 16.  6. 22.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6  0
  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0  4
  3  3 15 22  3] -> size -> 53 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -93.58319854736328






Player: 1 
cards in hand: [ 0.  6. 11.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 11.  0.  8.] 
cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15. 29.  1.  6.  1. 22. 25.  1.  1.
  1. 11.  0.  0.  0.  3. 29.  3.  0. 14.  6.  6.  3. 16.  6. 22.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  0  0  8  6 22 11  6 11  6  1  6  0  6  1  6  0
  6 29  0  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0  4
  3  3 15 22  3] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 10. 30. 23. 29.  8.  0.  9.  0.  2.  2.  2.  9. 10.  6.  8.  9.] 
adversary cards in hand: [ 1. 25.  1.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1 25  1  8 25  1
  1] -> size -> 49 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15. 29.  1.  6.  1. 22. 25.  1.  1.
  1. 11.  0.  0.  0.  3. 29.  3.  0. 14.  6.  6.  3. 16.  6. 22.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  1  0  0  8  6 22  6 11  6  1  6  0  6  1  6  0  6 29  0
  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0  4  3  3 15
 22  3] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 10. 30. 23. 29.  8.  0.  9.  0.  2.  2.  2.  9. 10.  6.  8.  9.] 
adversary cards in hand: [ 1. 25.  1.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1 25  1  8 25  1
  1] -> size -> 49 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15. 29.  1.  6.  1. 22. 25.  1.  1.
  1. 11.  0.  0.  0.  3. 29.  3.  0. 14.  6.  6.  3. 16.  6. 22.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  1  0  0  8  6 22  6 11  6  1  6  0  6  1  6  0  6 29  0
  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0  4  3  3 15
 22  3] -> size -> 50 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 10. 30. 23. 29.  8.  0.  9.  0.  2.  2.  2.  9. 10.  6.  8.  9.] 
adversary cards in hand: [ 1. 25.  1.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1 25  1  8 25  1
  1] -> size -> 49 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [ 1. 25.  1.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8. 29.] 
expected returns: [[-22.517962 ]
 [  0.6655426]
 [-20.996475 ]
 [ -9.225134 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25.  1.  8. 29.] 
cards in discard: [] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1 25  1  8 25  1
  1] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 10. 30. 23. 29.  8.  0.  9.  0.  2.  2.  2.  9. 10.  6.  8.  9.] 
adversary cards in hand: [6. 3. 3. 8. 3.] 
adversary cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15. 29.  1.  6.  1. 22. 25.  1.  1.
  1. 11.  0.  0.  0.  3. 29.  3.  0. 14.  6.  6.  3. 16.  6. 22.  1.  8.
  6.] 
adversary owned cards: [ 0  0  0  3  3  1  0  0  8  6 22  6 11  6  1  6  0  6  1  6  0  6 29  0
  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0  4  3  3 15
 22  3] -> size -> 50 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -93.58319854736328



action possibilites: [-1] 
expected returns: [[7.2573266]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1.  8. 29. 25.  0.] 
cards in discard: [] 
cards in deck: 42 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1 25  1  8 25  1
  1] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 10. 30. 23. 29.  8.  0.  9.  0.  2.  2.  2.  9. 10.  6.  8.  9.] 
adversary cards in hand: [6. 3. 3. 8. 3.] 
adversary cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15. 29.  1.  6.  1. 22. 25.  1.  1.
  1. 11.  0.  0.  0.  3. 29.  3.  0. 14.  6.  6.  3. 16.  6. 22.  1.  8.
  6.] 
adversary owned cards: [ 0  0  0  3  3  1  0  0  8  6 22  6 11  6  1  6  0  6  1  6  0  6 29  0
  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0  4  3  3 15
 22  3] -> size -> 50 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 0.6655278205871582





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ -3.1121802 ]
 [ 10.82675   ]
 [  2.5740247 ]
 [-17.175594  ]
 [  6.101764  ]
 [  7.446337  ]
 [ 30.599215  ]
 [ 18.6477    ]
 [-14.348957  ]
 [ -0.16353893]
 [ -0.8063798 ]
 [-15.998369  ]
 [  1.1810241 ]
 [  6.153687  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1.  8. 29. 25.  0.] 
cards in discard: [] 
cards in deck: 42 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1 25  1  8 25  1
  1] -> size -> 49 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 10. 30. 23. 29.  8.  0.  9.  0.  2.  2.  2.  9. 10.  6.  8.  9.] 
adversary cards in hand: [6. 3. 3. 8. 3.] 
adversary cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15. 29.  1.  6.  1. 22. 25.  1.  1.
  1. 11.  0.  0.  0.  3. 29.  3.  0. 14.  6.  6.  3. 16.  6. 22.  1.  8.
  6.] 
adversary owned cards: [ 0  0  0  3  3  1  0  0  8  6 22  6 11  6  1  6  0  6  1  6  0  6 29  0
  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0  4  3  3 15
 22  3] -> size -> 50 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 7.257326602935791



buy possibilites: [-1] 
expected returns: [[34.42382]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1.  8. 29. 25.  0.] 
cards in discard: [25.] 
cards in deck: 42 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1 25  1  8 25  1
  1 25] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 10. 30. 23. 29.  8.  0.  9.  0.  2.  1.  2.  9. 10.  6.  8.  9.] 
adversary cards in hand: [6. 3. 3. 8. 3.] 
adversary cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15. 29.  1.  6.  1. 22. 25.  1.  1.
  1. 11.  0.  0.  0.  3. 29.  3.  0. 14.  6.  6.  3. 16.  6. 22.  1.  8.
  6.] 
adversary owned cards: [ 0  0  0  3  3  1  0  0  8  6 22  6 11  6  1  6  0  6  1  6  0  6 29  0
  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0  4  3  3 15
 22  3] -> size -> 50 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0 -150    0    0
  250    0] 
sum of rewards: 115 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 30.59922218322754






Player: 1 
cards in hand: [6. 3. 3. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 8. 3.] 
cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15. 29.  1.  6.  1. 22. 25.  1.  1.
  1. 11.  0.  0.  0.  3. 29.  3.  0. 14.  6.  6.  3. 16.  6. 22.  1.  8.
  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  0  8  6 22  6 11  6  1  6  0  6  1  6  0  6 29  0
  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0  4  3  3 15
 22  3] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 10. 30. 23. 29.  8.  0.  9.  0.  2.  1.  2.  9. 10.  6.  8.  9.] 
adversary cards in hand: [25. 29. 29.  1. 11.] 
adversary cards in discard: [25. 25.  1.  1.  8. 29. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1 25  1  8 25  1
  1 25] -> size -> 50 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 8. 3.] 
cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15. 29.  1.  6.  1. 22. 25.  1.  1.
  1. 11.  0.  0.  0.  3. 29.  3.  0. 14.  6.  6.  3. 16.  6. 22.  1.  8.
  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  0  8  6 22  6 11  6  1  6  0  6  1  6  0  6 29  0
  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0  4  3  3 15
 22  3] -> size -> 50 
action values: 1 
buys: 1 
player value: 0 
card supply: [23. 10. 30. 23. 29.  8.  0.  9.  0.  2.  1.  2.  9. 10.  6.  8.  9.] 
adversary cards in hand: [25. 29. 29.  1. 11.] 
adversary cards in discard: [25. 25.  1.  1.  8. 29. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1 25  1  8 25  1
  1 25] -> size -> 50 
adversary victory points: 2
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [25. 29. 29.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 29. 11.] 
expected returns: [[ 5.3073125]
 [26.327219 ]
 [16.521309 ]
 [16.521309 ]
 [11.59104  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 29.  1. 11.] 
cards in discard: [25. 25.  1.  1.  8. 29. 25.  0.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1 25  1  8 25  1
  1 25] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 10. 30. 23. 29.  8.  0.  9.  0.  2.  1.  2.  9. 10.  6.  8.  9.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15. 29.  1.  6.  1. 22. 25.  1.  1.
  1. 11.  0.  0.  0.  3. 29.  3.  0. 14.  6.  6.  3. 16.  6. 22.  1.  8.
  6.  6.  3.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3  1  0  0  8  6 22  6 11  6  1  6  0  6  1  6  0  6 29  0
  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0  4  3  3 15
 22  3] -> size -> 50 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 34.42382049560547



action possibilites: [-1] 
expected returns: [[-74.503105]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  1. 11. 25. 11.] 
cards in discard: [25. 25.  1.  1.  8. 29. 25.  0.] 
cards in deck: 35 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1 25  1  8 25  1
  1 25] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 10. 30. 23. 29.  8.  0.  9.  0.  2.  1.  2.  9. 10.  6.  8.  9.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15. 29.  1.  6.  1. 22. 25.  1.  1.
  1. 11.  0.  0.  0.  3. 29.  3.  0. 14.  6.  6.  3. 16.  6. 22.  1.  8.
  6.  6.  3.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3  1  0  0  8  6 22  6 11  6  1  6  0  6  1  6  0  6 29  0
  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0  4  3  3 15
 22  3] -> size -> 50 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 26.327238082885742





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-85.35772 ]
 [-79.749405]
 [-74.90529 ]
 [-76.40815 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29.  1. 11. 25. 11.] 
cards in discard: [25. 25.  1.  1.  8. 29. 25.  0.] 
cards in deck: 35 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1 25  1  8 25  1
  1 25] -> size -> 50 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 10. 30. 23. 29.  8.  0.  9.  0.  2.  1.  2.  9. 10.  6.  8.  9.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15. 29.  1.  6.  1. 22. 25.  1.  1.
  1. 11.  0.  0.  0.  3. 29.  3.  0. 14.  6.  6.  3. 16.  6. 22.  1.  8.
  6.  6.  3.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3  1  0  0  8  6 22  6 11  6  1  6  0  6  1  6  0  6 29  0
  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0  4  3  3 15
 22  3] -> size -> 50 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -74.50310516357422



buy possibilites: [-1] 
expected returns: [[-0.48991346]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29.  1. 11. 25. 11.] 
cards in discard: [25. 25.  1.  1.  8. 29. 25.  0.  8.] 
cards in deck: 35 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1 25  1  8 25  1
  1 25  8] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 10. 30. 23. 29.  8.  0.  9.  0.  1.  1.  2.  9. 10.  6.  8.  9.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15. 29.  1.  6.  1. 22. 25.  1.  1.
  1. 11.  0.  0.  0.  3. 29.  3.  0. 14.  6.  6.  3. 16.  6. 22.  1.  8.
  6.  6.  3.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3  1  0  0  8  6 22  6 11  6  1  6  0  6  1  6  0  6 29  0
  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0  4  3  3 15
 22  3] -> size -> 50 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0 -160    0    0
   16    0] 
sum of rewards: -129 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -74.90528869628906






Player: 1 
cards in hand: [ 0. 29.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  3.  0.] 
cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15. 29.  1.  6.  1. 22. 25.  1.  1.
  1. 11.  0.  0.  0.  3. 29.  3.  0. 14.  6.  6.  3. 16.  6. 22.  1.  8.
  6.  6.  3.  3.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  0  0  8  6 22  6 11  6  1  6  0  6  1  6  0  6 29  0
  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0  4  3  3 15
 22  3] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 10. 30. 23. 29.  8.  0.  9.  0.  1.  1.  2.  9. 10.  6.  8.  9.] 
adversary cards in hand: [ 3.  1. 11. 11. 10.] 
adversary cards in discard: [25. 25.  1.  1.  8. 29. 25.  0.  8. 25. 29. 29.  1. 11. 25. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1 25  1  8 25  1
  1 25  8] -> size -> 51 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15. 29.  1.  6.  1. 22. 25.  1.  1.
  1. 11.  0.  0.  0.  3. 29.  3.  0. 14.  6.  6.  3. 16.  6. 22.  1.  8.
  6.  6.  3.  3.  8.  3.  0.  4.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  1  0  0  8  6 22  6 11  6  1  6  0  6  1  6  0  6 29  0
  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0  4  3  3 15
 22  3] -> size -> 50 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 10. 30. 23. 29.  8.  0.  9.  0.  1.  1.  2.  9. 10.  6.  8.  9.] 
adversary cards in hand: [ 3.  1. 11. 11. 10.] 
adversary cards in discard: [25. 25.  1.  1.  8. 29. 25.  0.  8. 25. 29. 29.  1. 11. 25. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1 25  1  8 25  1
  1 25  8] -> size -> 51 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15. 29.  1.  6.  1. 22. 25.  1.  1.
  1. 11.  0.  0.  0.  3. 29.  3.  0. 14.  6.  6.  3. 16.  6. 22.  1.  8.
  6.  6.  3.  3.  8.  3.  0.  4.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  1  0  0  8  6 22  6 11  6  1  6  0  6  1  6  0  6 29  0
  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0  4  3  3 15
 22  3] -> size -> 50 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 10. 30. 23. 29.  8.  0.  9.  0.  1.  1.  2.  9. 10.  6.  8.  9.] 
adversary cards in hand: [ 3.  1. 11. 11. 10.] 
adversary cards in discard: [25. 25.  1.  1.  8. 29. 25.  0.  8. 25. 29. 29.  1. 11. 25. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1 25  1  8 25  1
  1 25  8] -> size -> 51 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 3.  6.  3. 29.  0.  6.  6.  1.  0. 15. 29.  1.  6.  1. 22. 25.  1.  1.
  1. 11.  0.  0.  0.  3. 29.  3.  0. 14.  6.  6.  3. 16.  6. 22.  1.  8.
  6.  6.  3.  3.  8.  3.  0.  4.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  1  0  0  8  6 22  6 11  6  1  6  0  6  1  6  0  6 29  0
  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0  4  3  3 15
 22  3  0] -> size -> 51 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 10. 30. 23. 29.  8.  0.  9.  0.  1.  1.  2.  9. 10.  6.  8.  9.] 
adversary cards in hand: [ 3.  1. 11. 11. 10.] 
adversary cards in discard: [25. 25.  1.  1.  8. 29. 25.  0.  8. 25. 29. 29.  1. 11. 25. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1 25  1  8 25  1
  1 25  8] -> size -> 51 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [ 3.  1. 11. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10.] 
expected returns: [[-27.952324]
 [-19.31876 ]
 [-19.31876 ]
 [-36.285732]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 11. 11. 10.] 
cards in discard: [25. 25.  1.  1.  8. 29. 25.  0.  8. 25. 29. 29.  1. 11. 25. 11.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1 25  1  8 25  1
  1 25  8] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 10. 30. 23. 29.  8.  0.  9.  0.  1.  1.  2.  9. 10.  6.  8.  9.] 
adversary cards in hand: [6. 3. 3. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  1  0  0  8  6 22  6 11  6  1  6  0  6  1  6  0  6 29  0
  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0  4  3  3 15
 22  3  0] -> size -> 51 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.4899134635925293



action possibilites: [-1] 
expected returns: [[8.182747]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 11. 10.] 
cards in discard: [25. 25.  1.  1.  8. 29. 25.  0.  8. 25. 29. 29.  1. 11. 25. 11.  1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1 25  1  8 25  1
  1 25  8  1] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [22.  9. 30. 23. 29.  8.  0.  9.  0.  1.  1.  2.  9. 10.  6.  8.  9.] 
adversary cards in hand: [6. 3. 3. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  1  0  0  8  6 22  6 11  6  1  6  0  6  1  6  0  6 29  0
  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0  4  3  3 15
 22  3  0] -> size -> 51 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0 -170    0    0
   27    0] 
sum of rewards: -128 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -22.110361099243164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[2.0747094]
 [5.862553 ]
 [9.12183  ]
 [8.18276  ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 11. 10.] 
cards in discard: [25. 25.  1.  1.  8. 29. 25.  0.  8. 25. 29. 29.  1. 11. 25. 11.  1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1 25  1  8 25  1
  1 25  8  1] -> size -> 52 
action values: 0 
buys: 1 
player value: 2 
card supply: [22.  9. 30. 23. 29.  8.  0.  9.  0.  1.  1.  2.  9. 10.  6.  8.  9.] 
adversary cards in hand: [6. 3. 3. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  1  0  0  8  6 22  6 11  6  1  6  0  6  1  6  0  6 29  0
  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0  4  3  3 15
 22  3  0] -> size -> 51 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 8.182746887207031



Game is draw!



Player 0 bought cards:
Copper: 0 
Silver: 4 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 8 
Chapel: 8 
Witch: 8 
Poacher: 4 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 3.  1. 11. 10.] 
cards in discard: [25. 25.  1.  1.  8. 29. 25.  0.  8. 25. 29. 29.  1. 11. 25. 11.  1.  8.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  8 25 29 11 11 25 11 11 11 25  8 11 11 10  8
 10 11  1  1  1  8  1  1 29  1 29 25  8  1 25  1 29  1  1 25  1  8 25  1
  1 25  8  1  8] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [22.  9. 30. 23. 29.  8.  0.  9.  0.  0.  1.  2.  9. 10.  6.  8.  9.] 
adversary cards in hand: [6. 3. 3. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  1  0  0  8  6 22  6 11  6  1  6  0  6  1  6  0  6 29  0
  6  1 25 29  6  3 16  3  6  8  1  1 14 29  3 29  3  1  0  0  4  3  3 15
 22  3  0] -> size -> 51 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0 -180    0    0
    8    0] 
sum of rewards: -157 

action type: buy - action 8.0
Learning step: -6.644872665405273
desired expected reward: 2.476957321166992



