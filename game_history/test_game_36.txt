 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[18.245853]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    0    0    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -505 

action type: buy - action -1.0
Learning step: -15.317499160766602
desired expected reward: -9.734197616577148





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[16.657404]
 [19.057861]
 [17.538185]
 [13.195269]
 [20.45259 ]
 [19.550219]
 [18.019287]
 [18.4484  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 18.61595344543457



buy possibilites: [-1] 
expected returns: [[18.971283]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 20.452587127685547






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[21.866093]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  3.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 18.971282958984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[20.836872]
 [23.266685]
 [21.719135]
 [17.36464 ]
 [21.536192]
 [24.67337 ]
 [23.759045]
 [24.93212 ]
 [20.23167 ]
 [22.206451]
 [22.647678]
 [22.645372]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  3.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 22.115886688232422



buy possibilites: [-1] 
expected returns: [[23.494698]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  3.  0.  3.  0.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 24.932117462158203






Player: 1 
cards in hand: [0. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[24.572855]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 23.49469757080078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[23.203367]
 [25.59949 ]
 [24.072872]
 [19.833792]
 [23.889929]
 [26.989487]
 [26.090176]
 [27.242653]
 [22.614887]
 [24.554276]
 [24.985611]
 [24.98339 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 24.856046676635742



buy possibilites: [-1] 
expected returns: [[28.821535]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 27.242652893066406






Player: 1 
cards in hand: [0. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 29.  3.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 29.  3.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 29.  3.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[24.909962]
 [26.87468 ]
 [27.122227]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 29.  3.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [29.  0.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 28.821535110473633



action possibilites: [-1. 11.] 
expected returns: [[32.31714]
 [34.3567 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3.  3.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [29.  0.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 27.23318099975586



action possibilites: [-1] 
expected returns: [[27.565601]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [29.  3.  0.  0.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [29.  0.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  9  0] 
sum of rewards: 44 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 35.54421615600586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[26.172476]
 [28.486519]
 [27.02306 ]
 [22.823381]
 [29.805456]
 [28.950663]
 [27.487206]
 [27.900867]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [29.  3.  0.  0.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [29.  0.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 27.565601348876953



buy possibilites: [-1] 
expected returns: [[32.687878]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [29.  3.  0.  0.  0.  0. 10. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [29.  0.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 18  0] 
sum of rewards: 53 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 29.80545425415039






Player: 1 
cards in hand: [3. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [29.  0.  0.  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [29.  0.  0.  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[25.55252 ]
 [27.793362]
 [27.54115 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  8. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 32.6878776550293



action possibilites: [-1. 11. 10.] 
expected returns: [[28.16348 ]
 [30.240334]
 [27.711428]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  6. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  8. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 28.049156188964844



action possibilites: [-1] 
expected returns: [[26.173428]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  3.  8. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  9  0] 
sum of rewards: 44 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 31.8323974609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[24.60177 ]
 [27.010098]
 [25.481152]
 [21.190924]
 [25.298733]
 [28.396734]
 [27.499607]
 [28.64928 ]
 [23.998543]
 [25.960958]
 [26.394733]
 [26.39237 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  3.  8. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 26.17342758178711



buy possibilites: [-1] 
expected returns: [[33.70912]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [10. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  5. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  3.  8. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 32  0] 
sum of rewards: 67 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 28.649280548095703






Player: 1 
cards in hand: [29.  3.  8. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  8. 29.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  5. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  3.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29] -> size -> 17 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  5. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  3.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29] -> size -> 17 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  5. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  3.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29] -> size -> 17 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 29.  0.  0.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  5. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  3.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29] -> size -> 17 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [11.  0.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[31.831148]
 [33.767223]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0.  3.] 
cards in discard: [10. 29. 29. 11.  0.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  5. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 0. 29.  3.  8. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 33.70912170410156



action possibilites: [-1] 
expected returns: [[31.564606]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [10. 29. 29. 11.  0.  0.  0. 10. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  5. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 0. 29.  3.  8. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 35.32673263549805





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[30.02014 ]
 [30.88575 ]
 [26.611883]
 [32.847317]
 [31.77897 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [10. 29. 29. 11.  0.  0.  0. 10. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  5. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 0. 29.  3.  8. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 31.564605712890625



buy possibilites: [-1] 
expected returns: [[29.693802]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [10. 29. 29. 11.  0.  0.  0. 10. 10.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  8. 10.  5. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 0. 29.  3.  8. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 23 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 32.84731674194336






Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 0. 29.  3.  8. 29.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  8. 10.  5. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10  8] -> size -> 19 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 0. 29.  3.  8. 29.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  8. 10.  5. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10  8] -> size -> 19 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 0. 29.  3.  8. 29.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  8. 10.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10  8] -> size -> 19 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[25.357178]
 [27.525349]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  8. 10.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 29.693801879882812



action possibilites: [-1. 29.] 
expected returns: [[29.407606]
 [31.552713]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  8. 10.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 27.631694793701172



action possibilites: [-1.] 
expected returns: [[32.729706]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  8. 10.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 31.55271339416504





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[31.519384]
 [34.04829 ]
 [29.92007 ]
 [32.448975]
 [29.444965]
 [27.867033]
 [32.25616 ]
 [35.485107]
 [34.55552 ]
 [37.821194]
 [35.74678 ]
 [30.881779]
 [31.111324]
 [32.956196]
 [28.582424]
 [33.410683]
 [33.408253]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 6 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  8. 10.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 32.729705810546875



buy possibilites: [-1] 
expected returns: [[34.95446]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10  8 25] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  8.  9.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
 12.5  0. ] 
sum of rewards: 47.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 37.821197509765625






Player: 1 
cards in hand: [ 8. 29.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  8.  9.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 11. 29.  0.] 
adversary cards in discard: [25. 29. 29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10  8 25] -> size -> 20 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  8.  9.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 11. 29.  0.] 
adversary cards in discard: [25. 29. 29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10  8 25] -> size -> 20 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.  0.  0.  0.] 
cards in discard: [11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  7.  8.  9.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 11. 29.  0.] 
adversary cards in discard: [25. 29. 29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10  8 25] -> size -> 20 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[31.340334]
 [33.24403 ]
 [33.48383 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 29.  0.] 
cards in discard: [25. 29. 29.  0.  3.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10  8 25] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  7.  8.  9.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  8. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 34.95446014404297



action possibilites: [-1. 11. 10.] 
expected returns: [[36.56492 ]
 [38.468613]
 [36.150578]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0. 10.] 
cards in discard: [25. 29. 29.  0.  3.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10  8 25] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  7.  8.  9.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  8. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 33.536495208740234



action possibilites: [-1] 
expected returns: [[31.279316]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [25. 29. 29.  0.  3.  0.  0.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10  8 25 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  7.  8.  9.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  8. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  9  0] 
sum of rewards: 44 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 39.92923355102539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[29.941122]
 [32.19409 ]
 [30.766973]
 [26.736961]
 [30.595722]
 [33.495953]
 [32.653664]
 [33.733013]
 [29.374575]
 [31.2176  ]
 [31.621187]
 [31.619144]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [25. 29. 29.  0.  3.  0.  0.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10  8 25 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  7.  8.  9.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  8. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 31.279315948486328



buy possibilites: [-1] 
expected returns: [[31.886297]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [25. 29. 29.  0.  3.  0.  0.  0. 10. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10  8 25 10 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  7.  8.  9.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  8. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 32  0] 
sum of rewards: 67 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 33.73301315307617






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  8. 29.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  7.  8.  9.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11.  3.  3. 10. 10.] 
adversary cards in discard: [25. 29. 29.  0.  3.  0.  0.  0. 10. 29. 29. 11.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10  8 25 10 29] -> size -> 22 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  8. 29.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  7.  8.  9.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11.  3.  3. 10. 10.] 
adversary cards in discard: [25. 29. 29.  0.  3.  0.  0.  0. 10. 29. 29. 11.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10  8 25 10 29] -> size -> 22 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  8. 29.  0.  0.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  6.  8.  9.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [11.  3.  3. 10. 10.] 
adversary cards in discard: [25. 29. 29.  0.  3.  0.  0.  0. 10. 29. 29. 11.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10  8 25 10 29] -> size -> 22 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [11.  3.  3. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10.] 
expected returns: [[36.29645 ]
 [38.190968]
 [35.884052]
 [35.884052]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  3. 10. 10.] 
cards in discard: [25. 29. 29.  0.  3.  0.  0.  0. 10. 29. 29. 11.  0.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10  8 25 10 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  6.  8.  9.  4. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  3. 10. 29.  3.] 
adversary cards in discard: [11.  8. 29.  0.  0.  0. 11.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 31.88629722595215



action possibilites: [-1] 
expected returns: [[30.689209]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10. 10.] 
cards in discard: [25. 29. 29.  0.  3.  0.  0.  0. 10. 29. 29. 11.  0.  0.  0. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10  8 25 10 29 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  6.  8.  9.  4. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  3. 10. 29.  3.] 
adversary cards in discard: [11.  8. 29.  0.  0.  0. 11.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 39.66291046142578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[29.00379 ]
 [25.768234]
 [30.70375 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10. 10.] 
cards in discard: [25. 29. 29.  0.  3.  0.  0.  0. 10. 29. 29. 11.  0.  0.  0. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10  8 25 10 29 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  6.  8.  9.  4. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  3. 10. 29.  3.] 
adversary cards in discard: [11.  8. 29.  0.  0.  0. 11.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 30.689208984375






Player: 1 
cards in hand: [ 0.  3. 10. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10. 29.  3.] 
cards in discard: [11.  8. 29.  0.  0.  0. 11.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  6.  8.  9.  4. 10. 10.  4. 10. 10.] 
adversary cards in hand: [29.  0. 10. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10  8 25 10 29 10] -> size -> 23 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  6.  8.  9.  4. 10. 10.  4. 10. 10.] 
adversary cards in hand: [29.  0. 10. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10  8 25 10 29 10] -> size -> 23 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11] -> size -> 17 
action values: 2 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  6.  8.  9.  4. 10. 10.  4. 10. 10.] 
adversary cards in hand: [29.  0. 10. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10  8 25 10 29 10] -> size -> 23 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  6.  8.  9.  4. 10. 10.  4. 10. 10.] 
adversary cards in hand: [29.  0. 10. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10  8 25 10 29 10] -> size -> 23 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  6.  8.  9.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [29.  0. 10. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10  8 25 10 29 10] -> size -> 23 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [29.  0. 10. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10.  8.] 
expected returns: [[31.37686 ]
 [33.55287 ]
 [30.9561  ]
 [30.9561  ]
 [32.444347]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 10. 10.  8.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10  8 25 10 29 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  6.  8.  9.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 11.  0.] 
adversary cards in discard: [15. 29. 10.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 30.703752517700195



action possibilites: [-1. 10. 10.  8. 29.] 
expected returns: [[33.2391  ]
 [32.826664]
 [32.826664]
 [34.30075 ]
 [35.40878 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.  8. 29.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10  8 25 10 29 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  6.  8.  9.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 11.  0.] 
adversary cards in discard: [15. 29. 10.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 33.61931228637695



action possibilites: [-1. 10. 10.  8.] 
expected returns: [[40.700264]
 [40.269997]
 [40.269997]
 [41.792427]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.  8.  3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 29 10  8 25 10 29 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  6.  8.  9.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 11.  0.] 
adversary cards in discard: [15. 29. 10.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 35.408775329589844



action possibilites: [-1] 
expected returns: [[27.006063]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  6.  8.  9.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 11.  0.] 
adversary cards in discard: [15. 29. 10.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15] -> size -> 18 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 43.97168731689453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[25.676731]
 [28.004694]
 [26.53246 ]
 [22.335049]
 [29.327301]
 [28.471577]
 [26.999342]
 [27.415392]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  6.  8.  9.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 11.  0.] 
adversary cards in discard: [15. 29. 10.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15] -> size -> 18 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 27.00606346130371



buy possibilites: [-1] 
expected returns: [[34.56588]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  5.  8.  9.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 11.  0.] 
adversary cards in discard: [15. 29. 10.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15] -> size -> 18 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0 18  0] 
sum of rewards: 73 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 29.327301025390625






Player: 1 
cards in hand: [ 0.  8.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 11.  0.] 
cards in discard: [15. 29. 10.  0.  3.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  5.  8.  9.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  0. 29. 29.  0.] 
adversary cards in discard: [11. 29. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11] -> size -> 21 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 11.  0.] 
cards in discard: [15. 29. 10.  0.  3.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  5.  8.  9.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  0. 29. 29.  0.] 
adversary cards in discard: [11. 29. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11] -> size -> 21 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 11.  0.] 
cards in discard: [15. 29. 10.  0.  3.  3.  0.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  5.  8.  9.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 3.  0. 29. 29.  0.] 
adversary cards in discard: [11. 29. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11] -> size -> 21 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[31.570835]
 [33.805214]
 [33.805214]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29. 29.  0.] 
cards in discard: [11. 29. 29.  8.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  5.  8.  9.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 29.  3.] 
adversary cards in discard: [15. 29. 10.  0.  3.  3.  0.  0.  1.  0.  8.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1] -> size -> 19 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 34.565879821777344



action possibilites: [-1. 29. 10.] 
expected returns: [[36.293396]
 [38.559677]
 [35.855286]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  0. 10.] 
cards in discard: [11. 29. 29.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  5.  8.  9.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 29.  3.] 
adversary cards in discard: [15. 29. 10.  0.  3.  3.  0.  0.  1.  0.  8.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1] -> size -> 19 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 33.87332534790039



action possibilites: [-1. 10.] 
expected returns: [[39.90492 ]
 [39.451633]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10.  3.] 
cards in discard: [11. 29. 29.  8.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  5.  8.  9.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 29.  3.] 
adversary cards in discard: [15. 29. 10.  0.  3.  3.  0.  0.  1.  0.  8.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1] -> size -> 19 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 38.55967712402344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[38.17765 ]
 [40.7132  ]
 [39.109657]
 [34.51772 ]
 [38.916332]
 [42.153736]
 [41.22172 ]
 [42.41611 ]
 [37.538338]
 [39.61819 ]
 [40.073887]
 [40.07147 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.  3.] 
cards in discard: [11. 29. 29.  8.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  5.  8.  9.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 29.  3.] 
adversary cards in discard: [15. 29. 10.  0.  3.  3.  0.  0.  1.  0.  8.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1] -> size -> 19 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 39.9049186706543



buy possibilites: [-1] 
expected returns: [[40.779102]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.  3.] 
cards in discard: [11. 29. 29.  8.  0. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  5.  8.  9.  3. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 29.  3.] 
adversary cards in discard: [15. 29. 10.  0.  3.  3.  0.  0.  1.  0.  8.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1] -> size -> 19 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 32  0] 
sum of rewards: 67 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 42.41611099243164






Player: 1 
cards in hand: [ 0.  0. 11. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 29.  3.] 
cards in discard: [15. 29. 10.  0.  3.  3.  0.  0.  1.  0.  8.  0. 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  5.  8.  9.  3. 10. 10.  4. 10.  9.] 
adversary cards in hand: [11. 11.  0. 25.  0.] 
adversary cards in discard: [11. 29. 29.  8.  0. 29. 29. 29.  3.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29] -> size -> 22 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3. 11.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  5.  8.  9.  3. 10. 10.  4. 10.  9.] 
adversary cards in hand: [11. 11.  0. 25.  0.] 
adversary cards in discard: [11. 29. 29.  8.  0. 29. 29. 29.  3.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29] -> size -> 22 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 11.] 
cards in discard: [16.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  5.  8.  9.  3. 10. 10.  4. 10.  9.] 
adversary cards in hand: [11. 11.  0. 25.  0.] 
adversary cards in discard: [11. 29. 29.  8.  0. 29. 29. 29.  3.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29] -> size -> 22 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 11.] 
cards in discard: [16.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  5.  8.  9.  3. 10. 10.  4. 10.  9.] 
adversary cards in hand: [11. 11.  0. 25.  0.] 
adversary cards in discard: [11. 29. 29.  8.  0. 29. 29. 29.  3.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29] -> size -> 22 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 11.] 
cards in discard: [16. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  5.  8.  9.  3. 10. 10.  3. 10.  9.] 
adversary cards in hand: [11. 11.  0. 25.  0.] 
adversary cards in discard: [11. 29. 29.  8.  0. 29. 29. 29.  3.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29] -> size -> 22 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [11. 11.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 25.] 
expected returns: [[32.144352]
 [33.909863]
 [33.909863]
 [35.927715]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0. 25.  0.] 
cards in discard: [11. 29. 29.  8.  0. 29. 29. 29.  3.  0.  0. 10.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10.  9.  5.  8.  9.  3. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  1. 15.  3.  0.] 
adversary cards in discard: [16. 10. 29. 11.  0.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 40.77910232543945



action possibilites: [-1] 
expected returns: [[30.642061]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0.  0.  0. 10.] 
cards in discard: [11. 29. 29.  8.  0. 29. 29. 29.  3.  0.  0. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9.  9.  5.  8.  9.  3. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  1. 15.  3.  0.] 
adversary cards in discard: [16. 10. 29. 11.  0.  0.  3. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 35.948509216308594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[29.790344]
 [31.706724]
 [30.494791]
 [27.034128]
 [32.796127]
 [32.091118]
 [30.87918 ]
 [31.221779]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  0.  0.  0. 10.] 
cards in discard: [11. 29. 29.  8.  0. 29. 29. 29.  3.  0.  0. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8.  9.  9.  5.  8.  9.  3. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  1. 15.  3.  0.] 
adversary cards in discard: [16. 10. 29. 11.  0.  0.  3. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 30.642061233520508



buy possibilites: [-1] 
expected returns: [[28.141485]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  0.  0.  0. 10.] 
cards in discard: [11. 29. 29.  8.  0. 29. 29. 29.  3.  0.  0. 10.  3. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9.  9.  4.  8.  9.  3. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  1. 15.  3.  0.] 
adversary cards in discard: [16. 10. 29. 11.  0.  0.  3. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 32.79612350463867






Player: 1 
cards in hand: [ 3.  1. 15.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 15.  3.  0.] 
cards in discard: [16. 10. 29. 11.  0.  0.  3. 11.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9.  9.  4.  8.  9.  3. 10. 10.  3. 10.  9.] 
adversary cards in hand: [10. 25.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11] -> size -> 23 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 3.] 
cards in discard: [16. 10. 29. 11.  0.  0.  3. 11.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8.  9.  9.  4.  8.  9.  3. 10. 10.  3. 10.  9.] 
adversary cards in hand: [10. 25.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11] -> size -> 23 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3.] 
cards in discard: [16. 10. 29. 11.  0.  0.  3. 11.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 30. 30.  8.  9.  9.  4.  8.  9.  3. 10. 10.  3. 10.  9.] 
adversary cards in hand: [10. 25.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11] -> size -> 23 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3.] 
cards in discard: [16. 10. 29. 11.  0.  0.  3. 11.  6. 23.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9.  9.  4.  8.  9.  3. 10.  9.  3. 10.  9.] 
adversary cards in hand: [10. 25.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11] -> size -> 23 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [10. 25.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 10.] 
expected returns: [[33.372204]
 [32.96472 ]
 [37.494694]
 [32.96472 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9.  9.  4.  8.  9.  3. 10.  9.  3. 10.  9.] 
adversary cards in hand: [10.  0.  0.  0. 29.] 
adversary cards in discard: [16. 10. 29. 11.  0.  0.  3. 11.  6. 23. 15.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23] -> size -> 22 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 28.1414852142334



action possibilites: [-1] 
expected returns: [[37.93179]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  8.  9.  4.  8.  9.  3. 10.  9.  3. 10.  9.] 
adversary cards in hand: [10.  0.  0.  0. 29.] 
adversary cards in discard: [16. 10. 29. 11.  0.  0.  3. 11.  6. 23. 15.  3.  1.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6] -> size -> 23 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 37.643959045410156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[36.72755 ]
 [39.088688]
 [37.59542 ]
 [33.310318]
 [40.43003 ]
 [39.562157]
 [38.06889 ]
 [38.49093 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8.  8.  9.  4.  8.  9.  3. 10.  9.  3. 10.  9.] 
adversary cards in hand: [10.  0.  0.  0. 29.] 
adversary cards in discard: [16. 10. 29. 11.  0.  0.  3. 11.  6. 23. 15.  3.  1.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6] -> size -> 23 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 37.93178939819336



buy possibilites: [-1] 
expected returns: [[43.345943]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  0.  0. 10.] 
cards in discard: [11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  8.  9.  3.  8.  9.  3. 10.  9.  3. 10.  9.] 
adversary cards in hand: [10.  0.  0.  0. 29.] 
adversary cards in discard: [16. 10. 29. 11.  0.  0.  3. 11.  6. 23. 15.  3.  1.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6] -> size -> 23 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 40.43002700805664






Player: 1 
cards in hand: [10.  0.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0. 29.] 
cards in discard: [16. 10. 29. 11.  0.  0.  3. 11.  6. 23. 15.  3.  1.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  8.  9.  3.  8.  9.  3. 10.  9.  3. 10.  9.] 
adversary cards in hand: [ 0.  0. 29. 29.  0.] 
adversary cards in discard: [11. 25. 10.  0. 10.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11] -> size -> 24 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0. 29.] 
cards in discard: [16. 10. 29. 11.  0.  0.  3. 11.  6. 23. 15.  3.  1.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8.  8.  9.  3.  8.  9.  3. 10.  9.  3. 10.  9.] 
adversary cards in hand: [ 0.  0. 29. 29.  0.] 
adversary cards in discard: [11. 25. 10.  0. 10.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11] -> size -> 24 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0. 29.] 
cards in discard: [16. 10. 29. 11.  0.  0.  3. 11.  6. 23. 15.  3.  1.  3.  6.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8.  8.  9.  3.  7.  9.  3. 10.  9.  3. 10.  9.] 
adversary cards in hand: [ 0.  0. 29. 29.  0.] 
adversary cards in discard: [11. 25. 10.  0. 10.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11] -> size -> 24 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[28.127121]
 [30.143028]
 [30.143028]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 29.  0.] 
cards in discard: [11. 25. 10.  0. 10.  0.  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  8.  9.  3.  7.  9.  3. 10.  9.  3. 10.  9.] 
adversary cards in hand: [11.  3.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8] -> size -> 24 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 43.345943450927734



action possibilites: [-1. 29. 29.] 
expected returns: [[35.21932]
 [37.3229 ]
 [37.3229 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0. 29.] 
cards in discard: [11. 25. 10.  0. 10.  0.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8.  8.  9.  3.  7.  9.  3. 10.  9.  3. 10.  9.] 
adversary cards in hand: [11.  3.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8] -> size -> 24 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 30.164722442626953



action possibilites: [-1. 29. 11.] 
expected returns: [[32.8653  ]
 [34.915577]
 [34.682922]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29. 11.] 
cards in discard: [11. 25. 10.  0. 10.  0.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8.  8.  9.  3.  7.  9.  3. 10.  9.  3. 10.  9.] 
adversary cards in hand: [11.  3.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8] -> size -> 24 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 37.32290267944336



action possibilites: [-1. 11.  8.] 
expected returns: [[41.441525]
 [43.311832]
 [42.47357 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.  8.] 
cards in discard: [11. 25. 10.  0. 10.  0.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8.  8.  9.  3.  7.  9.  3. 10.  9.  3. 10.  9.] 
adversary cards in hand: [11.  3.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8] -> size -> 24 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 34.91557693481445



action possibilites: [-1] 
expected returns: [[44.562634]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [11. 25. 10.  0. 10.  0.  0. 10. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8.  8.  9.  3.  7.  9.  3. 10.  9.  2. 10.  9.] 
adversary cards in hand: [11.  3.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8] -> size -> 24 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 80  0  0  0  0  0  0  0  9  0] 
sum of rewards: 84 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 44.76402282714844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[43.15661 ]
 [45.481865]
 [41.700047]
 [44.011295]
 [41.273502]
 [39.849865]
 [43.833897]
 [46.835224]
 [45.958702]
 [49.037937]
 [47.081898]
 [42.570244]
 [42.781254]
 [44.477573]
 [40.49897 ]
 [44.8955  ]
 [44.89323 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [11. 25. 10.  0. 10.  0.  0. 10. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 6 
card supply: [29. 29. 30. 30. 30.  8.  8.  9.  3.  7.  9.  3. 10.  9.  2. 10.  9.] 
adversary cards in hand: [11.  3.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8] -> size -> 24 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 44.5626335144043



buy possibilites: [-1] 
expected returns: [[41.112675]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [11. 25. 10.  0. 10.  0.  0. 10. 10. 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8.  8.  9.  3.  7.  8.  3. 10.  9.  2. 10.  9.] 
adversary cards in hand: [11.  3.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8] -> size -> 24 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  80.   0.   0.   0.   0.   0.   0.   0.
 12.5  0. ] 
sum of rewards: 87.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 49.03792953491211






Player: 1 
cards in hand: [11.  3.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  8.  9.  3.  7.  8.  3. 10.  9.  2. 10.  9.] 
adversary cards in hand: [ 3. 11. 11.  0. 29.] 
adversary cards in discard: [11. 25. 10.  0. 10.  0.  0. 10. 10. 25. 29. 29. 29. 11.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25] -> size -> 26 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8.  8.  9.  3.  7.  8.  3. 10.  9.  2. 10.  9.] 
adversary cards in hand: [ 3. 11. 11.  0. 29.] 
adversary cards in discard: [11. 25. 10.  0. 10.  0.  0. 10. 10. 25. 29. 29. 29. 11.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25] -> size -> 26 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  8.  0.  0.] 
cards in discard: [0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 30. 30.  8.  8.  9.  3.  7.  8.  3. 10.  9.  2. 10.  9.] 
adversary cards in hand: [ 3. 11. 11.  0. 29.] 
adversary cards in discard: [11. 25. 10.  0. 10.  0.  0. 10. 10. 25. 29. 29. 29. 11.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25] -> size -> 26 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 3. 11. 11.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 29.] 
expected returns: [[35.867016]
 [37.661404]
 [37.661404]
 [37.88753 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 11.  0. 29.] 
cards in discard: [11. 25. 10.  0. 10.  0.  0. 10. 10. 25. 29. 29. 29. 11.  0.  0.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  8.  9.  3.  7.  8.  3. 10.  9.  2. 10.  9.] 
adversary cards in hand: [ 0. 29.  6.  0. 10.] 
adversary cards in discard: [ 0. 11.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8
  0] -> size -> 25 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 41.112674713134766



action possibilites: [-1. 11. 11.] 
expected returns: [[37.929523]
 [39.7514  ]
 [39.7514  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 11.  0.  3.] 
cards in discard: [11. 25. 10.  0. 10.  0.  0. 10. 10. 25. 29. 29. 29. 11.  0.  0.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8.  8.  9.  3.  7.  8.  3. 10.  9.  2. 10.  9.] 
adversary cards in hand: [ 0. 29.  6.  0. 10.] 
adversary cards in discard: [ 0. 11.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8
  0] -> size -> 25 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 37.88752746582031



action possibilites: [-1] 
expected returns: [[37.84948]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  3.] 
cards in discard: [11. 25. 10.  0. 10.  0.  0. 10. 10. 25. 29. 29. 29. 11.  0.  0.  0.  8.
 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8.  8.  9.  3.  7.  8.  3. 10.  9.  1. 10.  9.] 
adversary cards in hand: [ 0. 29.  6.  0. 10.] 
adversary cards in discard: [ 0. 11.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8
  0] -> size -> 25 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  9  0] 
sum of rewards: 44 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 41.162391662597656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[36.183235]
 [37.029423]
 [32.851456]
 [38.94699 ]
 [37.90257 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  3.] 
cards in discard: [11. 25. 10.  0. 10.  0.  0. 10. 10. 25. 29. 29. 29. 11.  0.  0.  0.  8.
 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 30. 30.  8.  8.  9.  3.  7.  8.  3. 10.  9.  1. 10.  9.] 
adversary cards in hand: [ 0. 29.  6.  0. 10.] 
adversary cards in discard: [ 0. 11.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8
  0] -> size -> 25 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 37.84947967529297



buy possibilites: [-1] 
expected returns: [[35.57949]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  3.] 
cards in discard: [11. 25. 10.  0. 10.  0.  0. 10. 10. 25. 29. 29. 29. 11.  0.  0.  0.  8.
 10.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25 10  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  8.  9.  3.  6.  8.  3. 10.  9.  1. 10.  9.] 
adversary cards in hand: [ 0. 29.  6.  0. 10.] 
adversary cards in discard: [ 0. 11.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8
  0] -> size -> 25 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  8  0] 
sum of rewards: 43 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 38.946990966796875






Player: 1 
cards in hand: [ 0. 29.  6.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  6.  0. 10.] 
cards in discard: [ 0. 11.  3.  8.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  8.  9.  3.  6.  8.  3. 10.  9.  1. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25 10  8] -> size -> 28 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 10. 11.] 
cards in discard: [ 0. 11.  3.  8.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8.  8.  9.  3.  6.  8.  3. 10.  9.  1. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25 10  8] -> size -> 28 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 10. 11.] 
cards in discard: [ 0. 11.  3.  8.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8.  8.  9.  3.  6.  8.  3. 10.  9.  1. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25 10  8] -> size -> 28 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 10. 11.] 
cards in discard: [ 0. 11.  3.  8.  0.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8
  0  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8.  8.  9.  3.  6.  8.  3. 10.  9.  1. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25 10  8] -> size -> 28 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[35.944546]
 [37.856476]
 [38.097347]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11. 29.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25 10  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  8.  9.  3.  6.  8.  3. 10.  9.  1. 10.  9.] 
adversary cards in hand: [ 1.  3.  0.  0. 10.] 
adversary cards in discard: [ 0. 11.  3.  8.  0.  0.  3. 29.  0.  6.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8
  0  3] -> size -> 26 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 35.579490661621094



action possibilites: [-1. 11.] 
expected returns: [[40.16914 ]
 [42.159935]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25 10  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8.  8.  9.  3.  6.  8.  3. 10.  9.  1. 10.  9.] 
adversary cards in hand: [ 1.  3.  0.  0. 10.] 
adversary cards in discard: [ 0. 11.  3.  8.  0.  0.  3. 29.  0.  6.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8
  0  3] -> size -> 26 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 38.102657318115234



action possibilites: [-1] 
expected returns: [[39.357258]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25 10  8 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8.  8.  9.  3.  6.  8.  3. 10.  9.  0. 10.  9.] 
adversary cards in hand: [ 1.  3.  0.  0. 10.] 
adversary cards in discard: [ 0. 11.  3.  8.  0.  0.  3. 29.  0.  6.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8
  0  3] -> size -> 26 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  9  0] 
sum of rewards: 44 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 43.757564544677734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
expected returns: [[38.063786]
 [40.330425]
 [38.88321 ]
 [34.83748 ]
 [38.713184]
 [41.70871 ]
 [40.817   ]
 [41.95972 ]
 [37.501736]
 [39.737328]
 [39.7351  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25 10  8 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 29. 30.  8.  8.  9.  3.  6.  8.  3. 10.  9.  0. 10.  9.] 
adversary cards in hand: [ 1.  3.  0.  0. 10.] 
adversary cards in discard: [ 0. 11.  3.  8.  0.  0.  3. 29.  0.  6.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8
  0  3] -> size -> 26 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 39.35725784301758



buy possibilites: [-1] 
expected returns: [[42.534733]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10. 29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25 10  8 10 29] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  8.  9.  3.  6.  8.  2. 10.  9.  0. 10.  9.] 
adversary cards in hand: [ 1.  3.  0.  0. 10.] 
adversary cards in discard: [ 0. 11.  3.  8.  0.  0.  3. 29.  0.  6.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8
  0  3] -> size -> 26 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 32  0] 
sum of rewards: 67 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 41.959720611572266






Player: 1 
cards in hand: [ 1.  3.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0.  0. 10.] 
cards in discard: [ 0. 11.  3.  8.  0.  0.  3. 29.  0.  6.  0. 10. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8
  0  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  8.  9.  3.  6.  8.  2. 10.  9.  0. 10.  9.] 
adversary cards in hand: [ 0.  3. 10.  0.  0.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25 10  8 10 29] -> size -> 30 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0.  0. 10.] 
cards in discard: [ 0. 11.  3.  8.  0.  0.  3. 29.  0.  6.  0. 10. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8
  0  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 29. 30.  8.  8.  9.  3.  6.  8.  2. 10.  9.  0. 10.  9.] 
adversary cards in hand: [ 0.  3. 10.  0.  0.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25 10  8 10 29] -> size -> 30 
adversary victory points: 2
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[37.9665  ]
 [37.564327]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  0.  0.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25 10  8 10 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  8.  9.  3.  6.  8.  2. 10.  9.  0. 10.  9.] 
adversary cards in hand: [15.  0. 16.  3.  6.] 
adversary cards in discard: [ 0. 11.  3.  8.  0.  0.  3. 29.  0.  6.  0. 10. 11.  1.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8
  0  3] -> size -> 26 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 42.534732818603516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[36.499317]
 [38.74324 ]
 [37.32053 ]
 [33.33661 ]
 [40.021465]
 [39.1945  ]
 [38.173954]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0.  0.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25 10  8 10 29] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 29. 30.  8.  8.  9.  3.  6.  8.  2. 10.  9.  0. 10.  9.] 
adversary cards in hand: [15.  0. 16.  3.  6.] 
adversary cards in discard: [ 0. 11.  3.  8.  0.  0.  3. 29.  0.  6.  0. 10. 11.  1.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8
  0  3] -> size -> 26 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 37.966495513916016



buy possibilites: [-1] 
expected returns: [[36.4186]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0.  0.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25 10  8 10 29 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  8.  9.  2.  6.  8.  2. 10.  9.  0. 10.  9.] 
adversary cards in hand: [15.  0. 16.  3.  6.] 
adversary cards in discard: [ 0. 11.  3.  8.  0.  0.  3. 29.  0.  6.  0. 10. 11.  1.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8
  0  3] -> size -> 26 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 40.02146530151367






Player: 1 
cards in hand: [15.  0. 16.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 16.  3.  6.] 
cards in discard: [ 0. 11.  3.  8.  0.  0.  3. 29.  0.  6.  0. 10. 11.  1.  3.  0.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8
  0  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  8.  9.  2.  6.  8.  2. 10.  9.  0. 10.  9.] 
adversary cards in hand: [11.  0. 10. 29.  8.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 11.  0.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25 10  8 10 29 11] -> size -> 31 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  6.] 
cards in discard: [ 0. 11.  3.  8.  0.  0.  3. 29.  0.  6.  0. 10. 11.  1.  3.  0.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8  0
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 29. 30. 29. 30.  8.  8.  9.  2.  6.  8.  2. 10.  9.  0. 10.  9.] 
adversary cards in hand: [11.  0. 10. 29.  8.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 11.  0.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25 10  8 10 29 11] -> size -> 31 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  6.] 
cards in discard: [ 0. 11.  3.  8.  0.  0.  3. 29.  0.  6.  0. 10. 11.  1.  3.  0.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8  0
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 29. 30.  8.  8.  9.  2.  6.  8.  2. 10.  9.  0. 10.  9.] 
adversary cards in hand: [11.  0. 10. 29.  8.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 11.  0.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25 10  8 10 29 11] -> size -> 31 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  6.] 
cards in discard: [ 0. 11.  3.  8.  0.  0.  3. 29.  0.  6.  0. 10. 11.  1.  3.  0.  0. 10.
  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8  0
  3  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8.  8.  9.  2.  5.  8.  2. 10.  9.  0. 10.  9.] 
adversary cards in hand: [11.  0. 10. 29.  8.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 11.  0.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25 10  8 10 29 11] -> size -> 31 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [11.  0. 10. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29.  8.] 
expected returns: [[29.850695]
 [31.525665]
 [29.489403]
 [31.73919 ]
 [30.767624]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10. 29.  8.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 11.  0.  3. 10.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25 10  8 10 29 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  8.  9.  2.  5.  8.  2. 10.  9.  0. 10.  9.] 
adversary cards in hand: [ 6.  6.  8. 23. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8  0
  3  8] -> size -> 26 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 36.41859817504883



action possibilites: [-1. 11. 10. 29.] 
expected returns: [[35.951664]
 [37.845737]
 [35.54752 ]
 [38.0844  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10. 29.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 11.  0.  3. 10.  0.  0.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25 10  8 10 29 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8.  8.  9.  2.  5.  8.  2. 10.  9.  0. 10.  9.] 
adversary cards in hand: [ 6.  6.  8. 23. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8  0
  3  8] -> size -> 26 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 30.362228393554688



action possibilites: [-1. 11. 10. 11.] 
expected returns: [[36.8403  ]
 [38.651867]
 [36.446407]
 [38.651867]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 11.  0.  3. 10.  0.  0.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25 10  8 10 29 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 29. 30.  8.  8.  9.  2.  5.  8.  2. 10.  9.  0. 10.  9.] 
adversary cards in hand: [ 6.  6.  8. 23. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8  0
  3  8] -> size -> 26 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 36.53487014770508



action possibilites: [-1] 
expected returns: [[38.70061]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 11.  0.  3. 10.  0.  0.  8.  0. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25 10  8 10 29 11 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 29. 30.  8.  8.  9.  2.  5.  8.  2. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 6.  6.  8. 23. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8  0
  3  8] -> size -> 26 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0 16  0] 
sum of rewards: 71 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 40.0481071472168





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[37.03019 ]
 [37.841793]
 [33.834534]
 [39.681   ]
 [38.679253]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 11.  0.  3. 10.  0.  0.  8.  0. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25 10  8 10 29 11 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 29. 30.  8.  8.  9.  2.  5.  8.  2. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 6.  6.  8. 23. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8  0
  3  8] -> size -> 26 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 38.70061111450195



buy possibilites: [-1] 
expected returns: [[34.671402]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 11.  0.  3. 10.  0.  0.  8.  0. 15.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25 10  8 10 29 11 15  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  8.  9.  2.  4.  8.  2. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 6.  6.  8. 23. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8  0
  3  8] -> size -> 26 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  8  0] 
sum of rewards: 63 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 39.680999755859375






Player: 1 
cards in hand: [ 6.  6.  8. 23. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  8. 23. 29.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8  0
  3  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  8.  9.  2.  4.  8.  2. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 8. 11. 10. 29. 25.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 11.  0.  3. 10.  0.  0.  8.  0. 15.  8.
 29. 29. 11. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25 10  8 10 29 11 15  8] -> size -> 33 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  8. 23. 29.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8  0
  3  8] -> size -> 26 
action values: 1 
buys: 1 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  8.  9.  2.  4.  8.  2. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 8. 11. 10. 29. 25.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 11.  0.  3. 10.  0.  0.  8.  0. 15.  8.
 29. 29. 11. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25 10  8 10 29 11 15  8] -> size -> 33 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  8. 23. 29.] 
cards in discard: [0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8  0
  3  8  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  8.  9.  2.  4.  8.  2. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 8. 11. 10. 29. 25.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 11.  0.  3. 10.  0.  0.  8.  0. 15.  8.
 29. 29. 11. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25 10  8 10 29 11 15  8] -> size -> 33 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 8. 11. 10. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10. 29. 25.] 
expected returns: [[30.504751]
 [31.4578  ]
 [32.23003 ]
 [30.129328]
 [32.447266]
 [34.1721  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 10. 29. 25.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 11.  0.  3. 10.  0.  0.  8.  0. 15.  8.
 29. 29. 11. 10. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25 10  8 10 29 11 15  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  8.  9.  2.  4.  8.  2. 10.  9.  0. 10.  8.] 
adversary cards in hand: [29. 11.  0.  0.  3.] 
adversary cards in discard: [ 0.  6.  6.  8. 23. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8  0
  3  8  0] -> size -> 27 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 34.67140197753906



action possibilites: [-1] 
expected returns: [[25.331818]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 10. 29. 25. 10.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 11.  0.  3. 10.  0.  0.  8.  0. 15.  8.
 29. 29. 11. 10. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25 10  8 10 29 11 15  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  7.  9.  2.  4.  8.  2. 10.  9.  0. 10.  8.] 
adversary cards in hand: [29. 11.  0.  0.  3.] 
adversary cards in discard: [ 0.  6.  6.  8. 23. 29.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8  0
  3  8  0  6] -> size -> 28 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 34.17210006713867





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[23.954504]
 [21.262493]
 [25.380615]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11. 10. 29. 25. 10.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 11.  0.  3. 10.  0.  0.  8.  0. 15.  8.
 29. 29. 11. 10. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25 10  8 10 29 11 15  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  7.  9.  2.  4.  8.  2. 10.  9.  0. 10.  8.] 
adversary cards in hand: [29. 11.  0.  0.  3.] 
adversary cards in discard: [ 0.  6.  6.  8. 23. 29.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8  0
  3  8  0  6] -> size -> 28 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 25.331817626953125






Player: 1 
cards in hand: [29. 11.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  0.  0.  3.] 
cards in discard: [ 0.  6.  6.  8. 23. 29.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8  0
  3  8  0  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  7.  9.  2.  4.  8.  2. 10.  9.  0. 10.  8.] 
adversary cards in hand: [25. 11. 11. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25 10  8 10 29 11 15  8] -> size -> 33 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  3.] 
cards in discard: [ 0.  6.  6.  8. 23. 29.  6.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8  0
  3  8  0  6  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8.  7.  9.  2.  4.  8.  2. 10.  9.  0. 10.  8.] 
adversary cards in hand: [25. 11. 11. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25 10  8 10 29 11 15  8] -> size -> 33 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  3.] 
cards in discard: [ 0.  6.  6.  8. 23. 29.  6.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8  0
  3  8  0  6  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 29. 30.  8.  7.  9.  2.  4.  8.  2. 10.  9.  0. 10.  8.] 
adversary cards in hand: [25. 11. 11. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25 10  8 10 29 11 15  8] -> size -> 33 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  3.] 
cards in discard: [ 0.  6.  6.  8. 23. 29.  6.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8  0
  3  8  0  6  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 29. 30.  8.  7.  9.  2.  4.  8.  2. 10.  9.  0. 10.  8.] 
adversary cards in hand: [25. 11. 11. 29. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25 10  8 10 29 11 15  8] -> size -> 33 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [25. 11. 11. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 11. 29. 10.] 
expected returns: [[34.12896 ]
 [37.803307]
 [35.85676 ]
 [35.85676 ]
 [36.074726]
 [33.752983]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11. 11. 29. 10.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25 10  8 10 29 11 15  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  7.  9.  2.  4.  8.  2. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 0.  8.  3.  1. 10.] 
adversary cards in discard: [ 0.  6.  6.  8. 23. 29.  6.  0.  0. 11. 29.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8  0
  3  8  0  6  0  0] -> size -> 30 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 25.380611419677734



action possibilites: [-1] 
expected returns: [[33.869568]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 29. 10. 15. 25.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25 10  8 10 29 11 15  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  6.  9.  2.  4.  8.  2. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 0.  8.  3.  1. 10.] 
adversary cards in discard: [ 0.  6.  6.  8. 23. 29.  6.  0.  0. 11. 29.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8  0
  3  8  0  6  0  0  6] -> size -> 31 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 37.80331039428711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[32.43698 ]
 [29.559483]
 [33.96993 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 29. 10. 15. 25.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25 10  8 10 29 11 15  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  6.  9.  2.  4.  8.  2. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 0.  8.  3.  1. 10.] 
adversary cards in discard: [ 0.  6.  6.  8. 23. 29.  6.  0.  0. 11. 29.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8  0
  3  8  0  6  0  0  6] -> size -> 31 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 33.86956787109375






Player: 1 
cards in hand: [ 0.  8.  3.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  3.  1. 10.] 
cards in discard: [ 0.  6.  6.  8. 23. 29.  6.  0.  0. 11. 29.  0.  0.  3.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  8 29  0 10 11 11 15  1 16 10  6 23  6  8  0
  3  8  0  6  0  0  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  6.  9.  2.  4.  8.  2. 10.  9.  0. 10.  8.] 
adversary cards in hand: [29.  8.  0.  0.  8.] 
adversary cards in discard: [25. 11. 11. 29. 10. 15. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25 10  8 10 29 11 15  8] -> size -> 33 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1.] 
cards in discard: [ 0.  6.  6.  8. 23. 29.  6.  0.  0. 11. 29.  0.  0.  3.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8
  0  6  0  0  6] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  6.  9.  2.  4.  8.  2. 10.  9.  0. 10.  8.] 
adversary cards in hand: [29.  8.  0.  0.  8.] 
adversary cards in discard: [25. 11. 11. 29. 10. 15. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25 10  8 10 29 11 15  8] -> size -> 33 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1.] 
cards in discard: [ 0.  6.  6.  8. 23. 29.  6.  0.  0. 11. 29.  0.  0.  3.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8
  0  6  0  0  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 29. 30.  8.  6.  9.  2.  4.  8.  2. 10.  9.  0. 10.  8.] 
adversary cards in hand: [29.  8.  0.  0.  8.] 
adversary cards in discard: [25. 11. 11. 29. 10. 15. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25 10  8 10 29 11 15  8] -> size -> 33 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1.] 
cards in discard: [ 0.  6.  6.  8. 23. 29.  6.  0.  0. 11. 29.  0.  0.  3.  6. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8
  0  6  0  0  6 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  6.  9.  1.  4.  8.  2. 10.  9.  0. 10.  8.] 
adversary cards in hand: [29.  8.  0.  0.  8.] 
adversary cards in discard: [25. 11. 11. 29. 10. 15. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25 10  8 10 29 11 15  8] -> size -> 33 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [29.  8.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.  8.] 
expected returns: [[34.387943]
 [36.251766]
 [35.297394]
 [35.297394]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  0.  0.  8.] 
cards in discard: [25. 11. 11. 29. 10. 15. 25.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25 10  8 10 29 11 15  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  6.  9.  1.  4.  8.  2. 10.  9.  0. 10.  8.] 
adversary cards in hand: [10.  0. 15.  8. 16.] 
adversary cards in discard: [ 0.  6.  6.  8. 23. 29.  6.  0.  0. 11. 29.  0.  0.  3.  6. 11.  8.  0.
  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8
  0  6  0  0  6 11] -> size -> 30 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 33.96992874145508



action possibilites: [-1.  8. 10.] 
expected returns: [[34.64455 ]
 [35.668774]
 [34.241016]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 10.] 
cards in discard: [25. 11. 11. 29. 10. 15. 25.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29 10  8 25 10 29 10 11 29 11 11
 10 25 10  8 10 29 11 15  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 29. 30.  8.  6.  9.  1.  4.  8.  2. 10.  9.  0. 10.  8.] 
adversary cards in hand: [10.  0. 15.  8. 16.] 
adversary cards in discard: [ 0.  6.  6.  8. 23. 29.  6.  0.  0. 11. 29.  0.  0.  3.  6. 11.  8.  0.
  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8
  0  6  0  0  6 11] -> size -> 30 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 34.89387130737305



action possibilites: [-1] 
expected returns: [[35.474888]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [25. 11. 11. 29. 10. 15. 25.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 29. 30.  8.  6.  9.  1.  4.  8.  2. 10.  9.  0. 10.  8.] 
adversary cards in hand: [10.  0. 15.  8. 16.] 
adversary cards in discard: [ 0.  6.  6.  8. 23. 29.  6.  0.  0. 11. 29.  0.  0.  3.  6. 11.  8.  0.
  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8
  0  6  0  0  6 11] -> size -> 30 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 35.114173889160156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[34.096714]
 [36.237297]
 [34.870422]
 [31.088617]
 [37.493076]
 [36.67585 ]
 [35.688774]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [25. 11. 11. 29. 10. 15. 25.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 29. 30.  8.  6.  9.  1.  4.  8.  2. 10.  9.  0. 10.  8.] 
adversary cards in hand: [10.  0. 15.  8. 16.] 
adversary cards in discard: [ 0.  6.  6.  8. 23. 29.  6.  0.  0. 11. 29.  0.  0.  3.  6. 11.  8.  0.
  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8
  0  6  0  0  6 11] -> size -> 30 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 35.47488784790039



buy possibilites: [-1] 
expected returns: [[36.26068]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [25. 11. 11. 29. 10. 15. 25.  8. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  6.  9.  0.  4.  8.  2. 10.  9.  0. 10.  8.] 
adversary cards in hand: [10.  0. 15.  8. 16.] 
adversary cards in discard: [ 0.  6.  6.  8. 23. 29.  6.  0.  0. 11. 29.  0.  0.  3.  6. 11.  8.  0.
  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8
  0  6  0  0  6 11] -> size -> 30 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 18  0] 
sum of rewards: 53 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 37.493072509765625






Player: 1 
cards in hand: [10.  0. 15.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.  8. 16.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 15.  8. 16.] 
cards in discard: [ 0.  6.  6.  8. 23. 29.  6.  0.  0. 11. 29.  0.  0.  3.  6. 11.  8.  0.
  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8
  0  6  0  0  6 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  6.  9.  0.  4.  8.  2. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 0.  0. 10. 29. 10.] 
adversary cards in discard: [25. 11. 11. 29. 10. 15. 25.  8. 11. 29.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11] -> size -> 33 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 16.] 
cards in discard: [ 0.  6.  6.  8. 23. 29.  6.  0.  0. 11. 29.  0.  0.  3.  6. 11.  8.  0.
  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8  0
  6  0  0  6 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 29. 30. 29. 30.  8.  6.  9.  0.  4.  8.  2. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 0.  0. 10. 29. 10.] 
adversary cards in discard: [25. 11. 11. 29. 10. 15. 25.  8. 11. 29.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11] -> size -> 33 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 16.] 
cards in discard: [ 0.  6.  6.  8. 23. 29.  6.  0.  0. 11. 29.  0.  0.  3.  6. 11.  8.  0.
  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8  0
  6  0  0  6 11] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 29. 30.  8.  6.  9.  0.  4.  8.  2. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 0.  0. 10. 29. 10.] 
adversary cards in discard: [25. 11. 11. 29. 10. 15. 25.  8. 11. 29.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11] -> size -> 33 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 10. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 10.] 
expected returns: [[31.674683]
 [31.30716 ]
 [33.57627 ]
 [31.30716 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 29. 10.] 
cards in discard: [25. 11. 11. 29. 10. 15. 25.  8. 11. 29.  8.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  6.  9.  0.  4.  8.  2. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [ 0.  6.  6.  8. 23. 29.  6.  0.  0. 11. 29.  0.  0.  3.  6. 11.  8.  0.
  1. 15. 10.  8. 16.] 
adversary owned cards: [ 0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8  0
  6  0  0  6 11] -> size -> 29 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 36.26068115234375



action possibilites: [-1. 10. 10.] 
expected returns: [[26.279362]
 [25.944414]
 [25.944414]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3.] 
cards in discard: [25. 11. 11. 29. 10. 15. 25.  8. 11. 29.  8.  0.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 29. 30.  8.  6.  9.  0.  4.  8.  2. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [ 0.  6.  6.  8. 23. 29.  6.  0.  0. 11. 29.  0.  0.  3.  6. 11.  8.  0.
  1. 15. 10.  8. 16.] 
adversary owned cards: [ 0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8  0
  6  0  0  6 11] -> size -> 29 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 32.19521713256836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[24.951225]
 [22.336227]
 [26.350773]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  3.] 
cards in discard: [25. 11. 11. 29. 10. 15. 25.  8. 11. 29.  8.  0.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11] -> size -> 33 
action values: 1 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 29. 30.  8.  6.  9.  0.  4.  8.  2. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [ 0.  6.  6.  8. 23. 29.  6.  0.  0. 11. 29.  0.  0.  3.  6. 11.  8.  0.
  1. 15. 10.  8. 16.] 
adversary owned cards: [ 0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8  0
  6  0  0  6 11] -> size -> 29 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 26.279361724853516






Player: 1 
cards in hand: [ 3.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 11.] 
cards in discard: [ 0.  6.  6.  8. 23. 29.  6.  0.  0. 11. 29.  0.  0.  3.  6. 11.  8.  0.
  1. 15. 10.  8. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8  0
  6  0  0  6 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  6.  9.  0.  4.  8.  2. 10.  9.  0. 10.  8.] 
adversary cards in hand: [11. 29.  0. 29. 11.] 
adversary cards in discard: [25. 11. 11. 29. 10. 15. 25.  8. 11. 29.  8.  0.  0.  0.  0. 29. 10. 10.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11] -> size -> 33 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 0.  6.  6.  8. 23. 29.  6.  0.  0. 11. 29.  0.  0.  3.  6. 11.  8.  0.
  1. 15. 10.  8. 16.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8  0
  6  0  0  6 11  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  6.  9.  0.  4.  8.  2. 10.  9.  0. 10.  8.] 
adversary cards in hand: [11. 29.  0. 29. 11.] 
adversary cards in discard: [25. 11. 11. 29. 10. 15. 25.  8. 11. 29.  8.  0.  0.  0.  0. 29. 10. 10.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11] -> size -> 33 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 0.  6.  6.  8. 23. 29.  6.  0.  0. 11. 29.  0.  0.  3.  6. 11.  8.  0.
  1. 15. 10.  8. 16.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8  0
  6  0  0  6 11  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 29. 30.  8.  6.  9.  0.  4.  8.  2. 10.  9.  0. 10.  8.] 
adversary cards in hand: [11. 29.  0. 29. 11.] 
adversary cards in discard: [25. 11. 11. 29. 10. 15. 25.  8. 11. 29.  8.  0.  0.  0.  0. 29. 10. 10.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11] -> size -> 33 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [11. 29.  0. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 29. 11.] 
expected returns: [[26.097092]
 [27.627596]
 [27.824665]
 [27.824665]
 [27.627596]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  0. 29. 11.] 
cards in discard: [25. 11. 11. 29. 10. 15. 25.  8. 11. 29.  8.  0.  0.  0.  0. 29. 10. 10.
  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  6.  9.  0.  4.  8.  2. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 3.  8. 11. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8  0
  6  0  0  6 11  1] -> size -> 30 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 26.350772857666016



action possibilites: [-1. 29. 10.] 
expected returns: [[24.498737]
 [26.207773]
 [24.168383]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10.] 
cards in discard: [25. 11. 11. 29. 10. 15. 25.  8. 11. 29.  8.  0.  0.  0.  0. 29. 10. 10.
  3. 11. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 29. 30.  8.  6.  9.  0.  4.  8.  2. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 3.  8. 11. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8  0
  6  0  0  6 11  1] -> size -> 30 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 8
Learning step: 0
desired expected reward: 26.940488815307617



action possibilites: [-1.] 
expected returns: [[28.956831]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [25. 11. 11. 29. 10. 15. 25.  8. 11. 29.  8.  0.  0.  0.  0. 29. 10. 10.
  3. 11. 11.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 28. 30. 29. 30.  8.  6.  9.  0.  4.  8.  2. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 3.  8. 11. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8  0
  6  0  0  6 11  1] -> size -> 30 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 24.96662139892578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[27.690472]
 [28.33506 ]
 [25.152382]
 [29.861183]
 [29.005411]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [25. 11. 11. 29. 10. 15. 25.  8. 11. 29.  8.  0.  0.  0.  0. 29. 10. 10.
  3. 11. 11.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11] -> size -> 33 
action values: 1 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 29. 30.  8.  6.  9.  0.  4.  8.  2. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 3.  8. 11. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8  0
  6  0  0  6 11  1] -> size -> 30 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 28.956830978393555



buy possibilites: [-1] 
expected returns: [[33.10401]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [25. 11. 11. 29. 10. 15. 25.  8. 11. 29.  8.  0.  0.  0.  0. 29. 10. 10.
  3. 11. 11.  0. 10.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  6.  9.  0.  3.  8.  2. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 3.  8. 11. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8  0
  6  0  0  6 11  1] -> size -> 30 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  8  0] 
sum of rewards: 43 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 29.86118507385254






Player: 1 
cards in hand: [ 3.  8. 11. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 11. 11.  3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8  0
  6  0  0  6 11  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  6.  9.  0.  3.  8.  2. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 0.  0. 29. 10.  8.] 
adversary cards in discard: [25. 11. 11. 29. 10. 15. 25.  8. 11. 29.  8.  0.  0.  0.  0. 29. 10. 10.
  3. 11. 11.  0. 10.  8. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11  8] -> size -> 34 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 11.  3.] 
cards in discard: [29.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8  0
  6  0  0  6 11  1 29] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  6.  9.  0.  3.  8.  1. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 0.  0. 29. 10.  8.] 
adversary cards in discard: [25. 11. 11. 29. 10. 15. 25.  8. 11. 29.  8.  0.  0.  0.  0. 29. 10. 10.
  3. 11. 11.  0. 10.  8. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11  8] -> size -> 34 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 11.  3.] 
cards in discard: [29.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8  0
  6  0  0  6 11  1 29] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  6.  9.  0.  3.  8.  1. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 0.  0. 29. 10.  8.] 
adversary cards in discard: [25. 11. 11. 29. 10. 15. 25.  8. 11. 29.  8.  0.  0.  0.  0. 29. 10. 10.
  3. 11. 11.  0. 10.  8. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11  8] -> size -> 34 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 11.  3.] 
cards in discard: [29.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8  0
  6  0  0  6 11  1 29  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  6.  9.  0.  3.  8.  1. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 0.  0. 29. 10.  8.] 
adversary cards in discard: [25. 11. 11. 29. 10. 15. 25.  8. 11. 29.  8.  0.  0.  0.  0. 29. 10. 10.
  3. 11. 11.  0. 10.  8. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11  8] -> size -> 34 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 29. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.  8.] 
expected returns: [[28.82375 ]
 [30.597315]
 [28.486843]
 [29.688257]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 10.  8.] 
cards in discard: [25. 11. 11. 29. 10. 15. 25.  8. 11. 29.  8.  0.  0.  0.  0. 29. 10. 10.
  3. 11. 11.  0. 10.  8. 29. 29.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  6.  9.  0.  3.  8.  1. 10.  9.  0. 10.  8.] 
adversary cards in hand: [29. 29.  1. 23. 11.] 
adversary cards in discard: [29.  0. 11.  3.  8. 11.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8  0
  6  0  0  6 11  1 29  0] -> size -> 32 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 33.10401153564453



action possibilites: [-1.  8. 11.] 
expected returns: [[23.878923]
 [24.63991 ]
 [25.25636 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11.] 
cards in discard: [25. 11. 11. 29. 10. 15. 25.  8. 11. 29.  8.  0.  0.  0.  0. 29. 10. 10.
  3. 11. 11.  0. 10.  8. 29. 29.  3.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 29. 30.  8.  6.  9.  0.  3.  8.  1. 10.  9.  0. 10.  8.] 
adversary cards in hand: [29. 29.  1. 23. 11.] 
adversary cards in discard: [29.  0. 11.  3.  8. 11.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8  0
  6  0  0  6 11  1 29  0] -> size -> 32 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 29.301197052001953



action possibilites: [-1] 
expected returns: [[24.821915]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [25. 11. 11. 29. 10. 15. 25.  8. 11. 29.  8.  0.  0.  0.  0. 29. 10. 10.
  3. 11. 11.  0. 10.  8. 29. 29.  3.  0. 10. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11  8 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 29. 30.  8.  6.  9.  0.  3.  8.  1. 10.  9.  0. 10.  7.] 
adversary cards in hand: [29. 29.  1. 23. 11.] 
adversary cards in discard: [29.  0. 11.  3.  8. 11.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8  0
  6  0  0  6 11  1 29  0] -> size -> 32 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 51 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 24.639907836914062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[23.592289]
 [24.213062]
 [21.19246 ]
 [25.654263]
 [24.86731 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [25. 11. 11. 29. 10. 15. 25.  8. 11. 29.  8.  0.  0.  0.  0. 29. 10. 10.
  3. 11. 11.  0. 10.  8. 29. 29.  3.  0. 10. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11  8 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 29. 30.  8.  6.  9.  0.  3.  8.  1. 10.  9.  0. 10.  7.] 
adversary cards in hand: [29. 29.  1. 23. 11.] 
adversary cards in discard: [29.  0. 11.  3.  8. 11.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8  0
  6  0  0  6 11  1 29  0] -> size -> 32 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 24.821914672851562



buy possibilites: [-1] 
expected returns: [[23.699501]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [25. 11. 11. 29. 10. 15. 25.  8. 11. 29.  8.  0.  0.  0.  0. 29. 10. 10.
  3. 11. 11.  0. 10.  8. 29. 29.  3.  0. 10. 15.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11  8 15  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  6.  9.  0.  2.  8.  1. 10.  9.  0. 10.  7.] 
adversary cards in hand: [29. 29.  1. 23. 11.] 
adversary cards in discard: [29.  0. 11.  3.  8. 11.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8  0
  6  0  0  6 11  1 29  0] -> size -> 32 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0 -1  0  0  8  0] 
sum of rewards: 42 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 25.65426254272461






Player: 1 
cards in hand: [29. 29.  1. 23. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 23. 11.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  1. 23. 11.] 
cards in discard: [29.  0. 11.  3.  8. 11.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8  0
  6  0  0  6 11  1 29  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  6.  9.  0.  2.  8.  1. 10.  9.  0. 10.  7.] 
adversary cards in hand: [10. 29.  0. 25. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11  8 15  8] -> size -> 36 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1. 29. 29. 11.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  1. 11.  6.] 
cards in discard: [29.  0. 11.  3.  8. 11.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8  0
  6  0  0  6 11  1 29  0] -> size -> 32 
action values: 1 
buys: 1 
player value: 1 
card supply: [24. 28. 30. 29. 30.  8.  6.  9.  0.  2.  8.  1. 10.  9.  0. 10.  7.] 
adversary cards in hand: [10. 29.  0. 25. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11  8 15  8] -> size -> 36 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 6.] 
cards in discard: [29.  0. 11.  3.  8. 11.  3. 29. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [23. 29.] 
owned cards: [ 0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8  0
  6  0  0  6 11  1 29  0] -> size -> 32 
action values: 1 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 29. 30.  8.  6.  9.  0.  2.  8.  1. 10.  9.  0. 10.  7.] 
adversary cards in hand: [10. 29.  0. 25. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11  8 15  8] -> size -> 36 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 6.] 
cards in discard: [29.  0. 11.  3.  8. 11.  3. 29. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [23. 29.] 
owned cards: [ 0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8  0
  6  0  0  6 11  1 29  0] -> size -> 32 
action values: 0 
buys: 2 
player value: 4 
card supply: [24. 28. 30. 29. 30.  8.  6.  9.  0.  2.  8.  1. 10.  9.  0. 10.  7.] 
adversary cards in hand: [10. 29.  0. 25. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11  8 15  8] -> size -> 36 
adversary victory points: 2
player victory points: -1 


buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 6.] 
cards in discard: [29.  0. 11.  3.  8. 11.  3. 29. 11.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [23. 29.] 
owned cards: [ 0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8  0
  6  0  0  6 11  1 29  0  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 28. 30. 29. 30.  8.  6.  9.  0.  2.  8.  1. 10.  9.  0. 10.  7.] 
adversary cards in hand: [10. 29.  0. 25. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11  8 15  8] -> size -> 36 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 6.] 
cards in discard: [29.  0. 11.  3.  8. 11.  3. 29. 11.  0. 16.] 
cards in deck: 18 
card top of deck: [] 
played cards: [23. 29.] 
owned cards: [ 0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8  0
  6  0  0  6 11  1 29  0  0 16] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 29. 30.  8.  6.  8.  0.  2.  8.  1. 10.  9.  0. 10.  7.] 
adversary cards in hand: [10. 29.  0. 25. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11  8 15  8] -> size -> 36 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [10. 29.  0. 25. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 25. 11.] 
expected returns: [[36.366932]
 [35.97263 ]
 [38.44704 ]
 [40.298935]
 [38.214127]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  0. 25. 11.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11  8 15  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 29. 30.  8.  6.  8.  0.  2.  8.  1. 10.  9.  0. 10.  7.] 
adversary cards in hand: [ 0.  0.  8. 10.  0.] 
adversary cards in discard: [29.  0. 11.  3.  8. 11.  3. 29. 11.  0. 16. 23. 29.  1.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8  0
  6  0  0  6 11  1 29  0  0 16] -> size -> 34 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 23.699501037597656



action possibilites: [-1] 
expected returns: [[36.900333]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  0. 11. 15. 15.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11  8 15  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 29. 30.  8.  5.  8.  0.  2.  8.  1. 10.  9.  0. 10.  7.] 
adversary cards in hand: [ 0.  0.  8. 10.  0.] 
adversary cards in discard: [29.  0. 11.  3.  8. 11.  3. 29. 11.  0. 16. 23. 29.  1.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8  0
  6  0  0  6 11  1 29  0  0 16  6] -> size -> 35 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 40.29893493652344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[35.529205]
 [32.465683]
 [37.110046]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29.  0. 11. 15. 15.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11  8 15  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 30. 29. 30.  8.  5.  8.  0.  2.  8.  1. 10.  9.  0. 10.  7.] 
adversary cards in hand: [ 0.  0.  8. 10.  0.] 
adversary cards in discard: [29.  0. 11.  3.  8. 11.  3. 29. 11.  0. 16. 23. 29.  1.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8  0
  6  0  0  6 11  1 29  0  0 16  6] -> size -> 35 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 36.900333404541016






Player: 1 
cards in hand: [ 0.  0.  8. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 10.  0.] 
cards in discard: [29.  0. 11.  3.  8. 11.  3. 29. 11.  0. 16. 23. 29.  1.  6.  6.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8  0
  6  0  0  6 11  1 29  0  0 16  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 29. 30.  8.  5.  8.  0.  2.  8.  1. 10.  9.  0. 10.  7.] 
adversary cards in hand: [ 0. 29. 29.  8. 11.] 
adversary cards in discard: [25. 10. 29.  0. 11. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11  8 15  8] -> size -> 36 
adversary victory points: 2
player victory points: -2 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [29.  0. 11.  3.  8. 11.  3. 29. 11.  0. 16. 23. 29.  1.  6.  6.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8  0
  6  0  0  6 11  1 29  0  0 16  6] -> size -> 35 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 29. 30.  8.  5.  8.  0.  2.  8.  1. 10.  9.  0. 10.  7.] 
adversary cards in hand: [ 0. 29. 29.  8. 11.] 
adversary cards in discard: [25. 10. 29.  0. 11. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11  8 15  8] -> size -> 36 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [29.  0. 11.  3.  8. 11.  3. 29. 11.  0. 16. 23. 29.  1.  6.  6.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8  0
  6  0  0  6 11  1 29  0  0 16  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 28. 30. 29. 30.  8.  5.  8.  0.  2.  8.  1. 10.  9.  0. 10.  7.] 
adversary cards in hand: [ 0. 29. 29.  8. 11.] 
adversary cards in discard: [25. 10. 29.  0. 11. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11  8 15  8] -> size -> 36 
adversary victory points: 2
player victory points: -2 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 29.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.  8. 11.] 
expected returns: [[30.327562]
 [32.234238]
 [32.234238]
 [31.262072]
 [32.0208  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29.  8. 11.] 
cards in discard: [25. 10. 29.  0. 11. 15. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11  8 15  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 29. 30.  8.  5.  8.  0.  2.  8.  1. 10.  9.  0. 10.  7.] 
adversary cards in hand: [ 6.  0.  0.  3. 15.] 
adversary cards in discard: [29.  0. 11.  3.  8. 11.  3. 29. 11.  0. 16. 23. 29.  1.  6.  6.  6. 10.
  0.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8  0
  6  0  0  6 11  1 29  0  0 16  6] -> size -> 35 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 37.11004638671875



action possibilites: [-1. 11. 10.] 
expected returns: [[31.630575]
 [33.38621 ]
 [31.251873]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.] 
cards in discard: [25. 10. 29.  0. 11. 15. 15. 29.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11  8 15  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 29. 30.  8.  5.  8.  0.  2.  8.  1. 10.  9.  0. 10.  7.] 
adversary cards in hand: [ 6.  0.  0.  3. 15.] 
adversary cards in discard: [29.  0. 11.  3.  8. 11.  3. 29. 11.  0. 16. 23. 29.  1.  6.  6.  6. 10.
  0.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8  0
  6  0  0  6 11  1 29  0  0 16  6] -> size -> 35 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 33.34196853637695



action possibilites: [-1] 
expected returns: [[28.33696]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.] 
cards in discard: [25. 10. 29.  0. 11. 15. 15. 29.  8. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11  8 15  8 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 29. 30.  8.  5.  8.  0.  2.  8.  1. 10.  9.  0. 10.  6.] 
adversary cards in hand: [ 6.  0.  0.  3. 15.] 
adversary cards in discard: [29.  0. 11.  3.  8. 11.  3. 29. 11.  0. 16. 23. 29.  1.  6.  6.  6. 10.
  0.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8  0
  6  0  0  6 11  1 29  0  0 16  6] -> size -> 35 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0 -2  0  0 16  0] 
sum of rewards: 49 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 32.595943450927734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[27.025799]
 [27.710915]
 [24.32813 ]
 [29.265562]
 [28.41803 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.] 
cards in discard: [25. 10. 29.  0. 11. 15. 15. 29.  8. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11  8 15  8 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 28. 30. 29. 30.  8.  5.  8.  0.  2.  8.  1. 10.  9.  0. 10.  6.] 
adversary cards in hand: [ 6.  0.  0.  3. 15.] 
adversary cards in discard: [29.  0. 11.  3.  8. 11.  3. 29. 11.  0. 16. 23. 29.  1.  6.  6.  6. 10.
  0.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8  0
  6  0  0  6 11  1 29  0  0 16  6] -> size -> 35 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 28.336959838867188



buy possibilites: [-1] 
expected returns: [[30.280487]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.] 
cards in discard: [25. 10. 29.  0. 11. 15. 15. 29.  8. 15.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11  8 15  8 15  8] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 29. 30.  8.  5.  8.  0.  1.  8.  1. 10.  9.  0. 10.  6.] 
adversary cards in hand: [ 6.  0.  0.  3. 15.] 
adversary cards in discard: [29.  0. 11.  3.  8. 11.  3. 29. 11.  0. 16. 23. 29.  1.  6.  6.  6. 10.
  0.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8  0
  6  0  0  6 11  1 29  0  0 16  6] -> size -> 35 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0 -3  0  0  8  0] 
sum of rewards: 40 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 29.26556396484375






Player: 1 
cards in hand: [ 6.  0.  0.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0.  3. 15.] 
cards in discard: [29.  0. 11.  3.  8. 11.  3. 29. 11.  0. 16. 23. 29.  1.  6.  6.  6. 10.
  0.  0.  8.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8  0
  6  0  0  6 11  1 29  0  0 16  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 29. 30.  8.  5.  8.  0.  1.  8.  1. 10.  9.  0. 10.  6.] 
adversary cards in hand: [ 3. 11. 11. 11.  8.] 
adversary cards in discard: [25. 10. 29.  0. 11. 15. 15. 29.  8. 15.  8. 29. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11  8 15  8 15  8] -> size -> 38 
adversary victory points: 2
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3.] 
cards in discard: [29.  0. 11.  3.  8. 11.  3. 29. 11.  0. 16. 23. 29.  1.  6.  6.  6. 10.
  0.  0.  8.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8  0  6
  0  0  6 11  1 29  0  0 16  6] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 28. 30. 29. 30.  8.  5.  8.  0.  1.  8.  1. 10.  9.  0. 10.  6.] 
adversary cards in hand: [ 3. 11. 11. 11.  8.] 
adversary cards in discard: [25. 10. 29.  0. 11. 15. 15. 29.  8. 15.  8. 29. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11  8 15  8 15  8] -> size -> 38 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3.] 
cards in discard: [29.  0. 11.  3.  8. 11.  3. 29. 11.  0. 16. 23. 29.  1.  6.  6.  6. 10.
  0.  0.  8.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8  0  6
  0  0  6 11  1 29  0  0 16  6] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 28. 30. 29. 30.  8.  5.  8.  0.  1.  8.  1. 10.  9.  0. 10.  6.] 
adversary cards in hand: [ 3. 11. 11. 11.  8.] 
adversary cards in discard: [25. 10. 29.  0. 11. 15. 15. 29.  8. 15.  8. 29. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11  8 15  8 15  8] -> size -> 38 
adversary victory points: 2
player victory points: -2 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 3. 11. 11. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11.  8.] 
expected returns: [[26.840227]
 [28.523563]
 [28.523563]
 [28.523563]
 [27.770132]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 11. 11.  8.] 
cards in discard: [25. 10. 29.  0. 11. 15. 15. 29.  8. 15.  8. 29. 11.  0. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11  8 15  8 15  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 29. 30.  8.  5.  8.  0.  1.  8.  1. 10.  9.  0. 10.  6.] 
adversary cards in hand: [ 0.  0. 16.  6.  8.] 
adversary cards in discard: [29.  0. 11.  3.  8. 11.  3. 29. 11.  0. 16. 23. 29.  1.  6.  6.  6. 10.
  0.  0.  8.  0.  0. 15.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8  0  6
  0  0  6 11  1 29  0  0 16  6] -> size -> 34 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 30.280487060546875



action possibilites: [-1] 
expected returns: [[25.077286]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 11.  8.] 
cards in discard: [25. 10. 29.  0. 11. 15. 15. 29.  8. 15.  8. 29. 11.  0. 10. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11  8 15  8 15  8 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 29. 30.  8.  5.  8.  0.  1.  8.  1. 10.  9.  0. 10.  5.] 
adversary cards in hand: [ 0.  0. 16.  6.  8.] 
adversary cards in discard: [29.  0. 11.  3.  8. 11.  3. 29. 11.  0. 16. 23. 29.  1.  6.  6.  6. 10.
  0.  0.  8.  0.  0. 15.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8  0  6
  0  0  6 11  1 29  0  0 16  6] -> size -> 34 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -4  0  0 16  0] 
sum of rewards: 27 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 27.770130157470703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[23.6357  ]
 [20.816322]
 [25.090578]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 11.  8.] 
cards in discard: [25. 10. 29.  0. 11. 15. 15. 29.  8. 15.  8. 29. 11.  0. 10. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11  8 15  8 15  8 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 28. 30. 29. 30.  8.  5.  8.  0.  1.  8.  1. 10.  9.  0. 10.  5.] 
adversary cards in hand: [ 0.  0. 16.  6.  8.] 
adversary cards in discard: [29.  0. 11.  3.  8. 11.  3. 29. 11.  0. 16. 23. 29.  1.  6.  6.  6. 10.
  0.  0.  8.  0.  0. 15.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8  0  6
  0  0  6 11  1 29  0  0 16  6] -> size -> 34 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 25.077285766601562






Player: 1 
cards in hand: [ 0.  0. 16.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  6.  8.] 
cards in discard: [29.  0. 11.  3.  8. 11.  3. 29. 11.  0. 16. 23. 29.  1.  6.  6.  6. 10.
  0.  0.  8.  0.  0. 15.  6.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 29  8 29  0 11 11 15  1 16 10  6 23  6  8  0  3  8  0  6
  0  0  6 11  1 29  0  0 16  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 29. 30.  8.  5.  8.  0.  1.  8.  1. 10.  9.  0. 10.  5.] 
adversary cards in hand: [ 0.  0.  8. 10. 10.] 
adversary cards in discard: [25. 10. 29.  0. 11. 15. 15. 29.  8. 15.  8. 29. 11.  0. 10. 15. 11.  3.
 11. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11  8 15  8 15  8 15] -> size -> 39 
adversary victory points: 2
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.] 
cards in discard: [29.  0. 11.  3.  8. 11.  3. 29. 11.  0. 16. 23. 29.  1.  6.  6.  6. 10.
  0.  0.  8.  0.  0. 15.  6.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 29  8 29  0 11 11 15  1 16 10 23  6  8  0  3  8  0  6  0
  0  6 11  1 29  0  0 16  6] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 29. 30.  8.  5.  8.  0.  1.  8.  1. 10.  9.  0. 10.  5.] 
adversary cards in hand: [ 0.  0.  8. 10. 10.] 
adversary cards in discard: [25. 10. 29.  0. 11. 15. 15. 29.  8. 15.  8. 29. 11.  0. 10. 15. 11.  3.
 11. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11  8 15  8 15  8 15] -> size -> 39 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.] 
cards in discard: [29.  0. 11.  3.  8. 11.  3. 29. 11.  0. 16. 23. 29.  1.  6.  6.  6. 10.
  0.  0.  8.  0.  0. 15.  6.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 29  8 29  0 11 11 15  1 16 10 23  6  8  0  3  8  0  6  0
  0  6 11  1 29  0  0 16  6] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 28. 30. 29. 30.  8.  5.  8.  0.  1.  8.  1. 10.  9.  0. 10.  5.] 
adversary cards in hand: [ 0.  0.  8. 10. 10.] 
adversary cards in discard: [25. 10. 29.  0. 11. 15. 15. 29.  8. 15.  8. 29. 11.  0. 10. 15. 11.  3.
 11. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11  8 15  8 15  8 15] -> size -> 39 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.] 
cards in discard: [29.  0. 11.  3.  8. 11.  3. 29. 11.  0. 16. 23. 29.  1.  6.  6.  6. 10.
  0.  0.  8.  0.  0. 15.  6.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 29  8 29  0 11 11 15  1 16 10 23  6  8  0  3  8  0  6  0
  0  6 11  1 29  0  0 16  6  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  5.  8.  0.  1.  8.  1. 10.  9.  0. 10.  5.] 
adversary cards in hand: [ 0.  0.  8. 10. 10.] 
adversary cards in discard: [25. 10. 29.  0. 11. 15. 15. 29.  8. 15.  8. 29. 11.  0. 10. 15. 11.  3.
 11. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11  8 15  8 15  8 15] -> size -> 39 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  8. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10.] 
expected returns: [[25.471764]
 [26.38247 ]
 [25.112854]
 [25.112854]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 10. 10.] 
cards in discard: [25. 10. 29.  0. 11. 15. 15. 29.  8. 15.  8. 29. 11.  0. 10. 15. 11.  3.
 11. 11.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 10 29 10 11 29 11 11 10
 25 10  8 10 29 11 15  8 11  8 15  8 15  8 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  5.  8.  0.  1.  8.  1. 10.  9.  0. 10.  5.] 
adversary cards in hand: [ 8.  6. 11.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29  8 29  0 11 11 15  1 16 10 23  6  8  0  3  8  0  6  0
  0  6 11  1 29  0  0 16  6  3] -> size -> 34 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 25.090579986572266



action possibilites: [-1] 
expected returns: [[27.242508]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.] 
cards in discard: [25. 10. 29.  0. 11. 15. 15. 29.  8. 15.  8. 29. 11.  0. 10. 15. 11.  3.
 11. 11.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 29 10 11 29 11 11 10 25
 10  8 10 29 11 15  8 11  8 15  8 15  8 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  5.  8.  0.  1.  8.  1. 10.  9.  0. 10.  5.] 
adversary cards in hand: [ 8.  6. 11.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29  8 29  0 11 11 15  1 16 10 23  6  8  0  3  8  0  6  0
  0  6 11  1 29  0  0 16  6  3] -> size -> 34 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 25.992809295654297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[25.888231]
 [26.544193]
 [23.37078 ]
 [28.077692]
 [27.240711]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [25. 10. 29.  0. 11. 15. 15. 29.  8. 15.  8. 29. 11.  0. 10. 15. 11.  3.
 11. 11.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 29 10 11 29 11 11 10 25
 10  8 10 29 11 15  8 11  8 15  8 15  8 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 28. 30. 28. 30.  8.  5.  8.  0.  1.  8.  1. 10.  9.  0. 10.  5.] 
adversary cards in hand: [ 8.  6. 11.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29  8 29  0 11 11 15  1 16 10 23  6  8  0  3  8  0  6  0
  0  6 11  1 29  0  0 16  6  3] -> size -> 34 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 27.242507934570312



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 7 
Chapel: 7 
Witch: 2 
Poacher: 6 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 0.  0. 10.] 
cards in discard: [25. 10. 29.  0. 11. 15. 15. 29.  8. 15.  8. 29. 11.  0. 10. 15. 11.  3.
 11. 11.  8.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 11 29  8 25 29 10 11 29 11 11 10 25
 10  8 10 29 11 15  8 11  8 15  8 15  8 15  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  5.  8.  0.  0.  8.  1. 10.  9.  0. 10.  5.] 
adversary cards in hand: [ 8.  6. 11.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 29  8 29  0 11 11 15  1 16 10 23  6  8  0  3  8  0  6  0
  0  6 11  1 29  0  0 16  6  3] -> size -> 34 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[ -5 500   0   0   0   0  20   0   0   0   0  -4   0   0   4   0] 
sum of rewards: 515 

action type: buy - action 8.0
Learning step: 14.60766887664795
desired expected reward: 42.685359954833984



