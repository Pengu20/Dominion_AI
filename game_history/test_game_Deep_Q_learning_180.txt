 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[30.3278]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -330        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000335 

action type: buy - action -1.0
Learning step: -120004.4765625
desired expected reward: -120227.3828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 24.481014]
 [ 43.72714 ]
 [ 37.327286]
 [-39.249447]
 [ 44.81652 ]
 [ 31.899773]
 [ 39.209072]
 [ 30.530834]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 30.537757873535156



buy possibilites: [-1] 
expected returns: [[29.23524]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 44.81651306152344






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[34.292034]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.  3.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [14.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 29.235240936279297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 27.331627]
 [ 46.198345]
 [ 40.820152]
 [-51.237053]
 [ 49.8415  ]
 [ 48.316494]
 [ 34.482002]
 [ 56.037006]
 [ -4.550828]
 [ 42.918484]
 [ 34.47575 ]
 [ 32.289227]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.  3.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [14.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 33.56732177734375



buy possibilites: [-1] 
expected returns: [[34.10668]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [11.  3.  0.  3.  0.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [14.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 56.037010192871094






Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [14.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [14.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [14.  0.  3.  0.  0.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[25.274921]
 [38.430527]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 34.10668182373047



action possibilites: [-1] 
expected returns: [[21.125732]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 41.53974533081055





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 17.106739]
 [ 35.8277  ]
 [ 27.964931]
 [-53.544174]
 [ 37.76426 ]
 [ 34.788982]
 [ 24.138653]
 [ 43.154633]
 [ -7.371457]
 [ 29.270565]
 [ 20.728062]
 [ 21.637787]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 21.125732421875



buy possibilites: [-1] 
expected returns: [[32.541954]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 43.154624938964844






Player: 1 
cards in hand: [ 3. 14.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 29.  0.] 
adversary cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 29.  0.] 
adversary cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  0.  0.  0.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 29.  0.] 
adversary cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[15.065995]
 [34.6323  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 29.  0.] 
cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [ 0.  3. 14.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 32.541954040527344



action possibilites: [-1.] 
expected returns: [[16.206726]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [ 0.  3. 14.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 33.92013168334961





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 13.644832 ]
 [ 26.41996  ]
 [ 22.306679 ]
 [-35.83498  ]
 [ 27.625927 ]
 [ 25.038372 ]
 [ 17.17868  ]
 [ 33.88371  ]
 [  2.6774845]
 [ 23.689804 ]
 [ 21.935196 ]
 [ 16.254456 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [ 0.  3. 14.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 16.20672607421875



buy possibilites: [-1] 
expected returns: [[34.07463]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [10. 29. 11.  0.  0.  0.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [ 0.  3. 14.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 33.883697509765625






Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 0.  3. 14.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [10.  0.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 0.  3. 14.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [10.  0.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 0.  3. 14.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [10.  0.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [10.  0.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[25.517452]
 [32.390987]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [14.  3.  3.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 34.07463073730469



action possibilites: [-1.] 
expected returns: [[27.127075]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [14.  3.  3.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 31.49890899658203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 23.613167]
 [ 41.709164]
 [ 33.723595]
 [-24.923115]
 [ 40.481663]
 [ 30.43129 ]
 [ 35.056404]
 [ 28.192966]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [14.  3.  3.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 27.1270751953125



buy possibilites: [-1] 
expected returns: [[44.570293]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [14.  3.  3.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 41.70917510986328






Player: 1 
cards in hand: [14.  3.  3.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  3.  0.  1.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  0.  0.] 
adversary cards in discard: [ 1. 10.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1] -> size -> 16 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 1.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [ 1. 10.  0.  0.  3.  3.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1] -> size -> 16 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 1.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [ 1. 10.  0.  0.  3.  3.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1] -> size -> 16 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 1.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 5 
card supply: [28. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [ 1. 10.  0.  0.  3.  3.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1] -> size -> 16 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[49.965584]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [ 1. 10.  0.  0.  3.  3.  0.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 0. 14.  3.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0 246   0] 
sum of rewards: 211 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 36.99388122558594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[40.704334 ]
 [50.89567  ]
 [-1.4732065]
 [50.86403  ]
 [52.080025 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 1. 10.  0.  0.  3.  3.  0.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 0. 14.  3.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 49.45234680175781



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 0. 14.  3.  3.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29. 29. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1] -> size -> 16 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 0. 14.  3.  3.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 29. 30.  8. 10. 10.  9. 10. 10.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29. 29. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1] -> size -> 16 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 0. 14.  3.  3.  0.  1.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  9. 10. 10.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29. 29. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1] -> size -> 16 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 29. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 11.] 
expected returns: [[36.890236]
 [55.10057 ]
 [55.10057 ]
 [49.47421 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29. 11.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  9. 10. 10.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 52.08002471923828



action possibilites: [-1. 29. 11.] 
expected returns: [[27.201408]
 [43.82762 ]
 [37.474907]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  9. 10. 10.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 53.23487091064453



action possibilites: [-1. 11.] 
expected returns: [[38.204063]
 [48.83749 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  9. 10. 10.  7.  9. 10.  9. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 43.8276252746582



action possibilites: [-1] 
expected returns: [[42.59402]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  9. 10. 10.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0  27   0] 
sum of rewards: 22 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 53.216514587402344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[41.070885 ]
 [57.375706 ]
 [49.560936 ]
 [24.485767 ]
 [-1.2068896]
 [59.220665 ]
 [56.15211  ]
 [47.42398  ]
 [67.90939  ]
 [63.037743 ]
 [17.076595 ]
 [50.57558  ]
 [51.10392  ]
 [31.120327 ]
 [41.7728   ]
 [44.860523 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  9. 10. 10.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 42.59402084350586



buy possibilites: [-1] 
expected returns: [[72.57273]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10. 25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  9. 10.  9.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 245 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 67.9094009399414






Player: 1 
cards in hand: [1. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  9. 10.  9.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  3.  1.  3. 10.] 
adversary cards in discard: [10. 25. 29. 29. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25] -> size -> 18 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  9. 10.  9.  7.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  3.  1.  3. 10.] 
adversary cards in discard: [10. 25. 29. 29. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25] -> size -> 18 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 0.] 
cards in discard: [23.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  9. 10.  9.  7.  9.  9.  8. 10. 10.] 
adversary cards in hand: [29.  3.  1.  3. 10.] 
adversary cards in discard: [10. 25. 29. 29. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25] -> size -> 18 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [29.  3.  1.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[39.252014]
 [58.299763]
 [46.248203]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  1.  3. 10.] 
cards in discard: [10. 25. 29. 29. 11.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  9. 10.  9.  7.  9.  9.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [23.  1.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 72.5727310180664



action possibilites: [-1. 10.] 
expected returns: [[43.4964  ]
 [50.289566]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  3. 10.  0.] 
cards in discard: [10. 25. 29. 29. 11.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  9. 10.  9.  7.  9.  9.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [23.  1.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 57.76676940917969



action possibilites: [-1.] 
expected returns: [[37.868713]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 3. 0. 0.] 
cards in discard: [10. 25. 29. 29. 11.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25] -> size -> 18 
action values: 2 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  9. 10.  9.  7.  9.  9.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [23.  1.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 50.28960037231445





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[35.32985  ]
 [51.569748 ]
 [45.821873 ]
 [20.161938 ]
 [-1.8942356]
 [53.800114 ]
 [51.7668   ]
 [40.784397 ]
 [62.716812 ]
 [57.69899  ]
 [13.463105 ]
 [47.962242 ]
 [46.690807 ]
 [28.445454 ]
 [38.300724 ]
 [38.97636  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 0. 0.] 
cards in discard: [10. 25. 29. 29. 11.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  9. 10.  9.  7.  9.  9.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [23.  1.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 37.86871337890625



buy possibilites: [-1] 
expected returns: [[56.22731]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 0. 0.] 
cards in discard: [10. 25. 29. 29. 11.  0.  0.  3.  0. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  9. 10.  8.  7.  9.  9.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [23.  1.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 225 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 62.71680450439453






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [23.  1.  3.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  9. 10.  8.  7.  9.  9.  8. 10. 10.] 
adversary cards in hand: [10. 25.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25] -> size -> 19 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [23.  1.  3.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  9. 10.  8.  7.  9.  9.  8. 10. 10.] 
adversary cards in hand: [10. 25.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25] -> size -> 19 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [23.  1.  3.  0.  0.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  9. 10.  8.  7.  9.  9.  7. 10. 10.] 
adversary cards in hand: [10. 25.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25] -> size -> 19 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [10. 25.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[37.956776]
 [43.657352]
 [60.75659 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25.  1.  0.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8. 10. 10.  9. 10.  8.  7.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3.  3.  3. 14.  3.] 
adversary cards in discard: [23.  1.  3.  0.  0.  0. 10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 56.22731018066406



action possibilites: [-1] 
expected returns: [[38.54807]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  0.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  9. 10.  9. 10.  8.  7.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3.  3.  3. 14.  3.] 
adversary cards in discard: [23.  1.  3.  0.  0.  0. 10.  0.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 60.07615661621094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 35.53542 ]
 [ 51.288353]
 [ 43.31176 ]
 [ 19.742878]
 [-13.324671]
 [ 51.81151 ]
 [ 48.686165]
 [ 40.896133]
 [ 58.97148 ]
 [ 55.412323]
 [ 11.981566]
 [ 43.51447 ]
 [ 43.77848 ]
 [ 24.90799 ]
 [ 35.639015]
 [ 40.46527 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  0.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 28. 30. 28. 30.  8.  9. 10.  9. 10.  8.  7.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3.  3.  3. 14.  3.] 
adversary cards in discard: [23.  1.  3.  0.  0.  0. 10.  0.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 38.54806900024414



buy possibilites: [-1] 
expected returns: [[51.260704]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  0.  0.  0.  3.] 
cards in discard: [25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  9. 10.  9. 10.  7.  7.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3.  3.  3. 14.  3.] 
adversary cards in discard: [23.  1.  3.  0.  0.  0. 10.  0.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 205 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 58.97148895263672






Player: 1 
cards in hand: [ 3.  3.  3. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3. 14.  3.] 
cards in discard: [23.  1.  3.  0.  0.  0. 10.  0.  0.  0.  0.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  9. 10.  9. 10.  7.  7.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 29. 29.  3.] 
adversary cards in discard: [25. 25. 10.  1.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25] -> size -> 20 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 3.] 
cards in discard: [23.  1.  3.  0.  0.  0. 10.  0.  0.  0.  0.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 28. 30.  8.  9. 10.  9. 10.  7.  7.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0. 29. 29.] 
adversary cards in discard: [25. 25. 10.  1.  0.  0.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25] -> size -> 20 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 3.] 
cards in discard: [23.  1.  3.  0.  0.  0. 10.  0.  0.  0.  0.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 28. 30.  8.  9. 10.  9. 10.  7.  7.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0. 29. 29.] 
adversary cards in discard: [25. 25. 10.  1.  0.  0.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25] -> size -> 20 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 3.] 
cards in discard: [23.  1.  3.  0.  0.  0. 10.  0.  0.  0.  0.  0.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 28. 30.  8.  9. 10.  9. 10.  7.  7.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0. 29. 29.] 
adversary cards in discard: [25. 25. 10.  1.  0.  0.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25] -> size -> 20 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[115.41403]
 [129.88829]
 [129.88829]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29.] 
cards in discard: [25. 25. 10.  1.  0.  0.  0.  3.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8.  9. 10.  9. 10.  7.  7.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3. 10.  3. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0 621   0] 
sum of rewards: 586 

action type: discard_down_to_3_cards - action 5
Learning step: 0
desired expected reward: 127.5880126953125



action possibilites: [-1. 29.] 
expected returns: [[78.93447 ]
 [98.493576]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.] 
cards in discard: [25. 25. 10.  1.  0.  0.  0.  3.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 28. 30.  8.  9. 10.  9. 10.  7.  7.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3. 10.  3. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 128.44558715820312



action possibilites: [-1. 10.] 
expected returns: [[86.30408]
 [90.21501]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.] 
cards in discard: [25. 25. 10.  1.  0.  0.  0.  3.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25] -> size -> 20 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 28. 30.  8.  9. 10.  9. 10.  7.  7.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3. 10.  3. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 98.49354553222656



action possibilites: [-1.] 
expected returns: [[76.2554]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [25. 25. 10.  1.  0.  0.  0.  3.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25] -> size -> 20 
action values: 2 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 28. 30.  8.  9. 10.  9. 10.  7.  7.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3. 10.  3. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 90.21500396728516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 73.59514 ]
 [ 89.60787 ]
 [ 83.816345]
 [ 57.838985]
 [ 34.06713 ]
 [ 91.91027 ]
 [ 90.33742 ]
 [ 79.28611 ]
 [101.11983 ]
 [ 95.931114]
 [ 51.433628]
 [ 85.439575]
 [ 85.117165]
 [ 66.15293 ]
 [ 75.95037 ]
 [ 77.22702 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [25. 25. 10.  1.  0.  0.  0.  3.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 28. 30. 28. 30.  8.  9. 10.  9. 10.  7.  7.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3. 10.  3. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 76.25540161132812



buy possibilites: [-1] 
expected returns: [[82.458496]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [25. 25. 10.  1.  0.  0.  0.  3.  3.  3. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8.  9. 10.  9. 10.  6.  7.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3. 10.  3. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 275 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 101.11982727050781






Player: 1 
cards in hand: [ 3. 10.  3. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3. 14.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 28. 30.  8.  9. 10.  9. 10.  6.  7.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0. 25. 29. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25] -> size -> 21 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 28. 30.  8.  9. 10.  9. 10.  6.  7.  9.  9.  7. 10. 10.] 
adversary cards in hand: [25. 11.  0.] 
adversary cards in discard: [29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25] -> size -> 21 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 28. 30.  8.  9. 10.  9. 10.  6.  7.  9.  9.  7. 10. 10.] 
adversary cards in hand: [25. 11.  0.] 
adversary cards in discard: [29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25] -> size -> 21 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  0.] 
cards in discard: [1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 30.  8.  9. 10.  9. 10.  6.  7.  9.  9.  7. 10. 10.] 
adversary cards in hand: [25. 11.  0.] 
adversary cards in discard: [29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25] -> size -> 21 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [25. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[53.467804]
 [72.20175 ]
 [62.544968]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11.  0.] 
cards in discard: [29.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 30.  8.  9. 10.  9. 10.  6.  7.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 23.  6.] 
adversary cards in discard: [ 1. 14.  3. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0 746   0] 
sum of rewards: 711 

action type: discard_down_to_3_cards - action 5
Learning step: 0
desired expected reward: 98.06275939941406



action possibilites: [-1] 
expected returns: [[55.398403]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 10.] 
cards in discard: [29.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 30.  8.  8. 10.  9. 10.  6.  7.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 23.  6.] 
adversary cards in discard: [ 1. 14.  3. 10.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 71.64886474609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[54.562992]
 [61.990685]
 [16.138424]
 [59.093315]
 [56.740364]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0. 10.] 
cards in discard: [29.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 28. 30.  8.  8. 10.  9. 10.  6.  7.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 23.  6.] 
adversary cards in discard: [ 1. 14.  3. 10.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 55.39840316772461



buy possibilites: [-1] 
expected returns: [[70.21571]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0. 10.] 
cards in discard: [29.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  8. 10.  9. 10.  6.  7.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 23.  6.] 
adversary cards in discard: [ 1. 14.  3. 10.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6] -> size -> 22 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 61.990684509277344






Player: 1 
cards in hand: [ 3.  0.  0. 23.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 23.  6.] 
cards in discard: [ 1. 14.  3. 10.  3.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  8. 10.  9. 10.  6.  7.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3. 25. 25.  0.  0.] 
adversary cards in discard: [29.  0.  3. 25. 11.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3] -> size -> 22 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 6. 0.] 
cards in discard: [ 1. 14.  3. 10.  3.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6] -> size -> 22 
action values: 1 
buys: 1 
player value: 1 
card supply: [27. 27. 30. 27. 30.  8.  8. 10.  9. 10.  6.  7.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3. 25. 25.  0.  0.] 
adversary cards in discard: [29.  0.  3. 25. 11.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3] -> size -> 22 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 0.] 
cards in discard: [ 1. 14.  3. 10.  3.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6] -> size -> 22 
action values: 0 
buys: 2 
player value: 4 
card supply: [27. 27. 30. 27. 30.  8.  8. 10.  9. 10.  6.  7.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3. 25. 25.  0.  0.] 
adversary cards in discard: [29.  0.  3. 25. 11.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3] -> size -> 22 
adversary victory points: 4
player victory points: 3 


buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 0.] 
cards in discard: [ 1. 14.  3. 10.  3.  0.  6. 16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  8.  9.  9. 10.  6.  7.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3. 25. 25.  0.  0.] 
adversary cards in discard: [29.  0.  3. 25. 11.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3] -> size -> 22 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 3. 25. 25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[67.09462 ]
 [88.469925]
 [88.469925]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 25.  0.  0.] 
cards in discard: [29.  0.  3. 25. 11.  0.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  8.  9.  9. 10.  6.  7.  9.  9.  7. 10. 10.] 
adversary cards in hand: [3. 3. 1. 0. 0.] 
adversary cards in discard: [ 1. 14.  3. 10.  3.  0.  6. 16. 23.  3.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16] -> size -> 23 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 70.21571350097656



action possibilites: [-1] 
expected returns: [[34.750046]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  0.  0.  1. 29.] 
cards in discard: [29.  0.  3. 25. 11.  0.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  7.  9.  9. 10.  6.  7.  9.  9.  7. 10. 10.] 
adversary cards in hand: [3. 3. 1. 0. 0.] 
adversary cards in discard: [ 1. 14.  3. 10.  3.  0.  6. 16. 23.  3.  0.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6] -> size -> 24 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 88.50056457519531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[30.678162]
 [45.56199 ]
 [40.331535]
 [-4.041071]
 [48.844482]
 [46.447227]
 [36.127274]
 [52.62285 ]
 [10.475663]
 [41.66275 ]
 [33.249317]
 [35.235874]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25.  0.  0.  1. 29.] 
cards in discard: [29.  0.  3. 25. 11.  0.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 27. 30. 27. 30.  8.  7.  9.  9. 10.  6.  7.  9.  9.  7. 10. 10.] 
adversary cards in hand: [3. 3. 1. 0. 0.] 
adversary cards in discard: [ 1. 14.  3. 10.  3.  0.  6. 16. 23.  3.  0.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6] -> size -> 24 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 34.75004577636719



buy possibilites: [-1] 
expected returns: [[36.488213]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25.  0.  0.  1. 29.] 
cards in discard: [29.  0.  3. 25. 11.  0.  0. 10. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  7.  9.  9. 10.  6.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [3. 3. 1. 0. 0.] 
adversary cards in discard: [ 1. 14.  3. 10.  3.  0.  6. 16. 23.  3.  0.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6] -> size -> 24 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 173 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 52.62285232543945






Player: 1 
cards in hand: [3. 3. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 1. 0. 0.] 
cards in discard: [ 1. 14.  3. 10.  3.  0.  6. 16. 23.  3.  0.  0.  6.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  7.  9.  9. 10.  6.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3. 25.  0. 29. 10.] 
adversary cards in discard: [29.  0.  3. 25. 11.  0.  0. 10. 29. 25.  3. 25.  0.  0.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29] -> size -> 23 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 0. 0.] 
cards in discard: [ 1. 14.  3. 10.  3.  0.  6. 16. 23.  3.  0.  0.  6.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 27. 30. 27. 30.  8.  7.  9.  9. 10.  6.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3. 25.  0. 29. 10.] 
adversary cards in discard: [29.  0.  3. 25. 11.  0.  0. 10. 29. 25.  3. 25.  0.  0.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29] -> size -> 23 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 0. 0.] 
cards in discard: [ 1. 14.  3. 10.  3.  0.  6. 16. 23.  3.  0.  0.  6.  0.  6.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 27. 30.  8.  7.  9.  9. 10.  6.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3. 25.  0. 29. 10.] 
adversary cards in discard: [29.  0.  3. 25. 11.  0.  0. 10. 29. 25.  3. 25.  0.  0.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29] -> size -> 23 
adversary victory points: 4
player victory points: 2 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 3. 25.  0. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 10.] 
expected returns: [[66.15784]
 [86.37373]
 [80.69657]
 [71.86618]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  0. 29. 10.] 
cards in discard: [29.  0.  3. 25. 11.  0.  0. 10. 29. 25.  3. 25.  0.  0.  1. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 27. 30.  8.  7.  9.  9. 10.  6.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1] -> size -> 25 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 36.48821258544922



action possibilites: [-1] 
expected returns: [[62.498055]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29. 10.  0.  3.] 
cards in discard: [29.  0.  3. 25. 11.  0.  0. 10. 29. 25.  3. 25.  0.  0.  1. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 27. 30.  8.  6.  9.  9. 10.  6.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6] -> size -> 26 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 86.37373352050781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[56.363724]
 [66.22649 ]
 [19.294376]
 [62.28163 ]
 [64.553406]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29. 10.  0.  3.] 
cards in discard: [29.  0.  3. 25. 11.  0.  0. 10. 29. 25.  3. 25.  0.  0.  1. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 26. 30. 27. 30.  8.  6.  9.  9. 10.  6.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6] -> size -> 26 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 62.49805450439453



buy possibilites: [-1] 
expected returns: [[70.60712]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29. 10.  0.  3.] 
cards in discard: [29.  0.  3. 25. 11.  0.  0. 10. 29. 25.  3. 25.  0.  0.  1. 29.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 26. 30.  8.  6.  9.  9. 10.  6.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6] -> size -> 26 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 121 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 66.2264633178711






Player: 1 
cards in hand: [10.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  0.] 
cards in discard: [6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 26. 30.  8.  6.  9.  9. 10.  6.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [10.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3] -> size -> 24 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  0.] 
cards in discard: [6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 26. 30. 26. 30.  8.  6.  9.  9. 10.  6.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [10.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3] -> size -> 24 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  0.] 
cards in discard: [ 6. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 26. 30.  8.  6.  9.  9. 10.  6.  5.  9.  9.  7. 10. 10.] 
adversary cards in hand: [10.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3] -> size -> 24 
adversary victory points: 5
player victory points: 1 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [10.  0. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[21.643639]
 [27.118614]
 [37.09337 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 26. 30.  8.  6.  9.  9. 10.  6.  5.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  1.  6.] 
adversary cards in discard: [ 6. 29. 10.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29] -> size -> 27 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 70.60711669921875



action possibilites: [-1. 10.] 
expected returns: [[20.108574]
 [25.03595 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 26. 30.  8.  6.  9.  9. 10.  6.  5.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  1.  6.] 
adversary cards in discard: [ 6. 29. 10.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29] -> size -> 27 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 37.38538360595703



action possibilites: [-1.] 
expected returns: [[48.254486]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3] -> size -> 24 
action values: 2 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 26. 30.  8.  6.  9.  9. 10.  6.  5.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  1.  6.] 
adversary cards in discard: [ 6. 29. 10.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29] -> size -> 27 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 25.035938262939453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[41.38616  ]
 [55.859432 ]
 [48.832848 ]
 [25.622818 ]
 [ 3.2854166]
 [59.509727 ]
 [55.901154 ]
 [47.67458  ]
 [68.64014  ]
 [63.65899  ]
 [19.478065 ]
 [51.723614 ]
 [51.40737  ]
 [33.11173  ]
 [42.178486 ]
 [47.456738 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 26. 30. 26. 30.  8.  6.  9.  9. 10.  6.  5.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  1.  6.] 
adversary cards in discard: [ 6. 29. 10.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29] -> size -> 27 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 48.254486083984375



buy possibilites: [-1] 
expected returns: [[55.24092]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [25.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 26. 30.  8.  6.  9.  9. 10.  5.  5.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  1.  6.] 
adversary cards in discard: [ 6. 29. 10.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29] -> size -> 27 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 405 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 68.64012908935547






Player: 1 
cards in hand: [ 3. 14.  0.  1.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  0.  1.  6.] 
cards in discard: [ 6. 29. 10.  0.  0.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 26. 30.  8.  6.  9.  9. 10.  5.  5.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  3.  1.] 
adversary cards in discard: [25. 29. 10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25] -> size -> 25 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  0.  1.  6.] 
cards in discard: [ 6. 29. 10.  0.  0.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 26. 30. 26. 30.  8.  6.  9.  9. 10.  5.  5.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  3.  1.] 
adversary cards in discard: [25. 29. 10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25] -> size -> 25 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  0.  1.  6.] 
cards in discard: [ 6. 29. 10.  0.  0.  0.  0. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 26. 30.  8.  6.  9.  8. 10.  5.  5.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  3.  1.] 
adversary cards in discard: [25. 29. 10.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25] -> size -> 25 
adversary victory points: 5
player victory points: 1 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 10.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[62.80533]
 [73.09573]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  3.  1.] 
cards in discard: [25. 29. 10.  0.  0.  0.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 26. 30.  8.  6.  9.  8. 10.  5.  5.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 6. 23.  1.  0.  0.] 
adversary cards in discard: [ 6. 29. 10.  0.  0.  0.  0. 11.  3. 14.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11] -> size -> 28 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 55.24092102050781



action possibilites: [-1.] 
expected returns: [[49.984936]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 1. 0.] 
cards in discard: [25. 29. 10.  0.  0.  0.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 26. 30.  8.  6.  9.  8. 10.  5.  5.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 6. 23.  1.  0.  0.] 
adversary cards in discard: [ 6. 29. 10.  0.  0.  0.  0. 11.  3. 14.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11] -> size -> 28 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 73.09571075439453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[50.198635]
 [62.95021 ]
 [58.93203 ]
 [19.86547 ]
 [65.96565 ]
 [64.03549 ]
 [54.653713]
 [69.08761 ]
 [33.793423]
 [60.52809 ]
 [53.700428]
 [51.705112]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 1. 0.] 
cards in discard: [25. 29. 10.  0.  0.  0.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 26. 30. 26. 30.  8.  6.  9.  8. 10.  5.  5.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 6. 23.  1.  0.  0.] 
adversary cards in discard: [ 6. 29. 10.  0.  0.  0.  0. 11.  3. 14.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11] -> size -> 28 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 49.98493576049805



buy possibilites: [-1] 
expected returns: [[62.85045]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 1. 0.] 
cards in discard: [25. 29. 10.  0.  0.  0.  3.  0. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 26. 30.  8.  6.  9.  8. 10.  5.  4.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 6. 23.  1.  0.  0.] 
adversary cards in discard: [ 6. 29. 10.  0.  0.  0.  0. 11.  3. 14.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11] -> size -> 28 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 263 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 69.08759307861328






Player: 1 
cards in hand: [ 6. 23.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 23.  1.  0.  0.] 
cards in discard: [ 6. 29. 10.  0.  0.  0.  0. 11.  3. 14.  0.  1.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 26. 30.  8.  6.  9.  8. 10.  5.  4.  9.  9.  7. 10. 10.] 
adversary cards in hand: [29. 25. 29. 11.  0.] 
adversary cards in discard: [25. 29. 10.  0.  0.  0.  3.  0. 29. 10.  0.  3.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29] -> size -> 26 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 23.  1.  0.  0.] 
cards in discard: [ 6. 29. 10.  0.  0.  0.  0. 11.  3. 14.  0.  1.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 26. 30. 26. 30.  8.  6.  9.  8. 10.  5.  4.  9.  9.  7. 10. 10.] 
adversary cards in hand: [29. 25. 29. 11.  0.] 
adversary cards in discard: [25. 29. 10.  0.  0.  0.  3.  0. 29. 10.  0.  3.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29] -> size -> 26 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 23.  1.  0.  0.] 
cards in discard: [ 6. 29. 10.  0.  0.  0.  0. 11.  3. 14.  0.  1.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 4 
card supply: [26. 26. 30. 26. 30.  8.  6.  9.  8. 10.  5.  4.  9.  9.  7. 10. 10.] 
adversary cards in hand: [29. 25. 29. 11.  0.] 
adversary cards in discard: [25. 29. 10.  0.  0.  0.  3.  0. 29. 10.  0.  3.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29] -> size -> 26 
adversary victory points: 5
player victory points: 1 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [29. 25. 29. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29. 11.] 
expected returns: [[116.20805]
 [129.11456]
 [132.71323]
 [129.11456]
 [123.33284]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 29. 11.  0.] 
cards in discard: [25. 29. 10.  0.  0.  0.  3.  0. 29. 10.  0.  3.  3.  1.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  6.  9.  8. 10.  5.  4.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3. 16.  3.  1.  0.] 
adversary cards in discard: [ 6. 29. 10.  0.  0.  0.  0. 11.  3. 14.  0.  1.  6.  0.  6. 23.  1.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11  0] -> size -> 29 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 62.85044860839844



action possibilites: [-1] 
expected returns: [[79.66634]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 11.  0. 25.  3.] 
cards in discard: [25. 29. 10.  0.  0.  0.  3.  0. 29. 10.  0.  3.  3.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  5.  9.  8. 10.  5.  4.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3. 16.  3.  1.  0.] 
adversary cards in discard: [ 6. 29. 10.  0.  0.  0.  0. 11.  3. 14.  0.  1.  6.  0.  6. 23.  1.  0.
  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11  0  6] -> size -> 30 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 132.71322631835938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[75.84512]
 [16.13475]
 [81.47572]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29. 11.  0. 25.  3.] 
cards in discard: [25. 29. 10.  0.  0.  0.  3.  0. 29. 10.  0.  3.  3.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 26. 30. 26. 30.  8.  5.  9.  8. 10.  5.  4.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3. 16.  3.  1.  0.] 
adversary cards in discard: [ 6. 29. 10.  0.  0.  0.  0. 11.  3. 14.  0.  1.  6.  0.  6. 23.  1.  0.
  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11  0  6] -> size -> 30 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 79.66634368896484






Player: 1 
cards in hand: [ 3. 16.  3.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  3.  1.  0.] 
cards in discard: [ 6. 29. 10.  0.  0.  0.  0. 11.  3. 14.  0.  1.  6.  0.  6. 23.  1.  0.
  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11  0  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  5.  9.  8. 10.  5.  4.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3. 29. 25.  3. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29] -> size -> 26 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  3.  1.  0.] 
cards in discard: [ 6. 29. 10.  0.  0.  0.  0. 11.  3. 14.  0.  1.  6.  0.  6. 23.  1.  0.
  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11  0  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 26. 30. 26. 30.  8.  5.  9.  8. 10.  5.  4.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3. 29. 25.  3. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29] -> size -> 26 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  3.  1.  0.] 
cards in discard: [ 6. 29. 10.  0.  0.  0.  0. 11.  3. 14.  0.  1.  6.  0.  6. 23.  1.  0.
  0.  6. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11  0  6 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  5.  9.  8. 10.  5.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 3. 29. 25.  3. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29] -> size -> 26 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 3. 29. 25.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 25.] 
expected returns: [[40.507282]
 [54.19333 ]
 [59.542007]
 [59.542007]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 25.  3. 25.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  5.  9.  8. 10.  5.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [3. 0. 6. 0. 3.] 
adversary cards in discard: [ 6. 29. 10.  0.  0.  0.  0. 11.  3. 14.  0.  1.  6.  0.  6. 23.  1.  0.
  0.  6. 10.  3. 16.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11  0  6 10] -> size -> 31 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 81.47574615478516



action possibilites: [-1] 
expected returns: [[53.644634]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3. 25.  0. 11.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  4.  9.  8. 10.  5.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [3. 0. 6. 0. 3.] 
adversary cards in discard: [ 6. 29. 10.  0.  0.  0.  0. 11.  3. 14.  0.  1.  6.  0.  6. 23.  1.  0.
  0.  6. 10.  3. 16.  3.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11  0  6 10  6] -> size -> 32 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 59.12586975097656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[52.495422]
 [ 9.903024]
 [55.583084]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  3. 25.  0. 11.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 26. 30. 26. 30.  8.  4.  9.  8. 10.  5.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [3. 0. 6. 0. 3.] 
adversary cards in discard: [ 6. 29. 10.  0.  0.  0.  0. 11.  3. 14.  0.  1.  6.  0.  6. 23.  1.  0.
  0.  6. 10.  3. 16.  3.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11  0  6 10  6] -> size -> 32 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 53.64463424682617






Player: 1 
cards in hand: [3. 0. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 0. 3.] 
cards in discard: [ 6. 29. 10.  0.  0.  0.  0. 11.  3. 14.  0.  1.  6.  0.  6. 23.  1.  0.
  0.  6. 10.  3. 16.  3.  1.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11  0  6 10  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  4.  9.  8. 10.  5.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [29.  1. 10.  0.  3.] 
adversary cards in discard: [25.  3. 29.  3. 25.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29] -> size -> 26 
adversary victory points: 5
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 3.] 
cards in discard: [ 6. 29. 10.  0.  0.  0.  0. 11.  3. 14.  0.  1.  6.  0.  6. 23.  1.  0.
  0.  6. 10.  3. 16.  3.  1.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11  0  6 10  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 26. 30. 26. 30.  8.  4.  9.  8. 10.  5.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [29.  1. 10.  0.  3.] 
adversary cards in discard: [25.  3. 29.  3. 25.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29] -> size -> 26 
adversary victory points: 5
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 3.] 
cards in discard: [ 6. 29. 10.  0.  0.  0.  0. 11.  3. 14.  0.  1.  6.  0.  6. 23.  1.  0.
  0.  6. 10.  3. 16.  3.  1.  0.  6.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11  0  6 10  6  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  4.  9.  8.  9.  5.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [29.  1. 10.  0.  3.] 
adversary cards in discard: [25.  3. 29.  3. 25.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29] -> size -> 26 
adversary victory points: 5
player victory points: -1 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [29.  1. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[13.924386]
 [25.44508 ]
 [21.044205]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1. 10.  0.  3.] 
cards in discard: [25.  3. 29.  3. 25.  0. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  4.  9.  8.  9.  5.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [10.  0. 23. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11  0  6 10  6  8] -> size -> 33 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 55.58308410644531



action possibilites: [-1. 10.] 
expected returns: [[24.11182 ]
 [25.326653]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  0.  3.  0.] 
cards in discard: [25.  3. 29.  3. 25.  0. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 26. 30.  8.  4.  9.  8.  9.  5.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [10.  0. 23. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11  0  6 10  6  8] -> size -> 33 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 25.445091247558594



action possibilites: [-1.] 
expected returns: [[27.255287]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [25.  3. 29.  3. 25.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29] -> size -> 26 
action values: 2 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 26. 30.  8.  4.  9.  8.  9.  5.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [10.  0. 23. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11  0  6 10  6  8] -> size -> 33 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 25.326637268066406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 23.676682 ]
 [ 38.39319  ]
 [ 19.524986 ]
 [ 30.337566 ]
 [  8.6532755]
 [-13.628168 ]
 [ 41.393932 ]
 [ 36.917297 ]
 [ 29.868553 ]
 [ 49.423874 ]
 [ 44.677803 ]
 [  2.1611896]
 [ 32.967594 ]
 [ 32.431515 ]
 [ 15.2629385]
 [ 23.937828 ]
 [ 29.825623 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [25.  3. 29.  3. 25.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29] -> size -> 26 
action values: 0 
buys: 1 
player value: 6 
card supply: [26. 26. 30. 26. 30.  8.  4.  9.  8.  9.  5.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [10.  0. 23. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11  0  6 10  6  8] -> size -> 33 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 27.255287170410156



buy possibilites: [-1] 
expected returns: [[67.75229]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [25.  3. 29.  3. 25.  0. 11. 25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 26. 30.  8.  4.  9.  8.  9.  4.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [10.  0. 23. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11  0  6 10  6  8] -> size -> 33 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5.    0.    0.  180.    0.    0.   40.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 277.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 49.42387008666992






Player: 1 
cards in hand: [10.  0. 23. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 23. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 23. 10.  0.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11  0  6 10  6  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  4.  9.  8.  9.  4.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [25.  3.  0. 29. 25.] 
adversary cards in discard: [25.  3. 29.  3. 25.  0. 11. 25. 29. 10.  1.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25] -> size -> 27 
adversary victory points: 5
player victory points: -1 


action possibilites: [-1. 23. 10.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 23. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11  0  6 10  6  8] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  4.  9.  8.  9.  4.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [25.  3.  0. 29. 25.] 
adversary cards in discard: [25.  3. 29.  3. 25.  0. 11. 25. 29. 10.  1.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25] -> size -> 27 
adversary victory points: 5
player victory points: -1 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  1.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [10. 23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11  0  6 10  6  8] -> size -> 33 
action values: 2 
buys: 1 
player value: 1 
card supply: [26. 26. 30. 26. 30.  8.  4.  9.  8.  9.  4.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [25.  3.  0. 29. 25.] 
adversary cards in discard: [25.  3. 29.  3. 25.  0. 11. 25. 29. 10.  1.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25] -> size -> 27 
adversary victory points: 5
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.  1.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [10. 23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11  0  6 10  6  8] -> size -> 33 
action values: 0 
buys: 2 
player value: 6 
card supply: [26. 26. 30. 26. 30.  8.  4.  9.  8.  9.  4.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [25.  3.  0. 29. 25.] 
adversary cards in discard: [25.  3. 29.  3. 25.  0. 11. 25. 29. 10.  1.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25] -> size -> 27 
adversary victory points: 5
player victory points: -1 


buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.  1.] 
cards in discard: [2.] 
cards in deck: 26 
card top of deck: [] 
played cards: [10. 23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11  0  6 10  6  8  2] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 26. 29. 26. 30.  8.  4.  9.  8.  9.  4.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [25.  3.  0. 29. 25.] 
adversary cards in discard: [25.  3. 29.  3. 25.  0. 11. 25. 29. 10.  1.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25] -> size -> 27 
adversary victory points: 5
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.  1.] 
cards in discard: [2. 0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [10. 23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11  0  6 10  6  8  2  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 29. 26. 30.  8.  4.  9.  8.  9.  4.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [25.  3.  0. 29. 25.] 
adversary cards in discard: [25.  3. 29.  3. 25.  0. 11. 25. 29. 10.  1.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25] -> size -> 27 
adversary victory points: 5
player victory points: -1 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [25.  3.  0. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25.] 
expected returns: [[ 95.06649 ]
 [110.91611 ]
 [107.511444]
 [110.91611 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0. 29. 25.] 
cards in discard: [25.  3. 29.  3. 25.  0. 11. 25. 29. 10.  1.  0.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 29. 26. 30.  8.  4.  9.  8.  9.  4.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  0.  6. 16.  3.] 
adversary cards in discard: [ 2.  0. 10. 23.  0. 10.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11  0  6 10  6  8  2  0] -> size -> 35 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 67.75228881835938



action possibilites: [-1] 
expected returns: [[92.900734]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29. 25. 25. 10.] 
cards in discard: [25.  3. 29.  3. 25.  0. 11. 25. 29. 10.  1.  0.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 29. 26. 30.  8.  3.  9.  8.  9.  4.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  0.  6. 16.  3.] 
adversary cards in discard: [ 2.  0. 10. 23.  0. 10.  0.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11  0  6 10  6  8  2  0  6] -> size -> 36 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 110.91610717773438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[88.01864]
 [30.44933]
 [95.34984]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29. 25. 25. 10.] 
cards in discard: [25.  3. 29.  3. 25.  0. 11. 25. 29. 10.  1.  0.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 26. 29. 26. 30.  8.  3.  9.  8.  9.  4.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  0.  6. 16.  3.] 
adversary cards in discard: [ 2.  0. 10. 23.  0. 10.  0.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11  0  6 10  6  8  2  0  6] -> size -> 36 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 92.9007339477539






Player: 1 
cards in hand: [ 3.  0.  6. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  6. 16.  3.] 
cards in discard: [ 2.  0. 10. 23.  0. 10.  0.  0.  1.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11  0  6 10  6  8  2  0  6] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 29. 26. 30.  8.  3.  9.  8.  9.  4.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [29.  0. 29.  0.  3.] 
adversary cards in discard: [25.  3. 29.  3. 25.  0. 11. 25. 29. 10.  1.  0.  3.  0.  0. 25.  3.  0.
 29. 25. 25. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25] -> size -> 27 
adversary victory points: 5
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  6. 16.  3.] 
cards in discard: [ 2.  0. 10. 23.  0. 10.  0.  0.  1.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11  0  6 10  6  8  2  0  6] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 26. 29. 26. 30.  8.  3.  9.  8.  9.  4.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [29.  0. 29.  0.  3.] 
adversary cards in discard: [25.  3. 29.  3. 25.  0. 11. 25. 29. 10.  1.  0.  3.  0.  0. 25.  3.  0.
 29. 25. 25. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25] -> size -> 27 
adversary victory points: 5
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [29.  0. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[68.0001 ]
 [81.99182]
 [81.99182]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29.  0.  3.] 
cards in discard: [25.  3. 29.  3. 25.  0. 11. 25. 29. 10.  1.  0.  3.  0.  0. 25.  3.  0.
 29. 25. 25. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 29. 26. 30.  8.  3.  9.  8.  9.  4.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [0. 6. 1. 6. 0.] 
adversary cards in discard: [ 2.  0. 10. 23.  0. 10.  0.  0.  1.  6.  3.  0.  6. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11  0  6 10  6  8  2  0  6] -> size -> 36 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 95.34986114501953



action possibilites: [-1. 29.] 
expected returns: [[46.871307]
 [61.59133 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 26. 29. 26. 30.  8.  3.  9.  8.  9.  4.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [0. 6. 1. 6. 0.] 
adversary cards in discard: [ 2.  0. 10. 23.  0. 10.  0.  0.  1.  6.  3.  0.  6. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11  0  6 10  6  8  2  0  6] -> size -> 36 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 81.99180603027344



action possibilites: [-1. 25.] 
expected returns: [[25.70805]
 [47.08008]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 25.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25] -> size -> 27 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 26. 29. 26. 30.  8.  3.  9.  8.  9.  4.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [0. 6. 1. 6. 0.] 
adversary cards in discard: [ 2.  0. 10. 23.  0. 10.  0.  0.  1.  6.  3.  0.  6. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11  0  6 10  6  8  2  0  6] -> size -> 36 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 61.59132385253906



action possibilites: [-1] 
expected returns: [[38.479378]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 29. 10.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 26. 29. 26. 30.  8.  2.  9.  8.  9.  4.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [0. 6. 1. 6. 0.] 
adversary cards in discard: [ 2.  0. 10. 23.  0. 10.  0.  0.  1.  6.  3.  0.  6. 16.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11  0  6 10  6  8  2  0  6  6] -> size -> 37 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 47.08006286621094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[39.493774]
 [47.857555]
 [44.14646 ]
 [29.442368]
 [ 9.653264]
 [49.376377]
 [46.480778]
 [40.92197 ]
 [50.66614 ]
 [51.283894]
 [23.93346 ]
 [44.898075]
 [44.548332]
 [32.1868  ]
 [39.36852 ]
 [41.44058 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 29. 10.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 26. 29. 26. 30.  8.  2.  9.  8.  9.  4.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [0. 6. 1. 6. 0.] 
adversary cards in discard: [ 2.  0. 10. 23.  0. 10.  0.  0.  1.  6.  3.  0.  6. 16.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11  0  6 10  6  8  2  0  6  6] -> size -> 37 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: take_action - action -1
Learning step: 0
desired expected reward: 38.47937774658203



buy possibilites: [-1] 
expected returns: [[34.089382]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 29. 10.] 
cards in discard: [29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 26. 29. 26. 30.  8.  2.  9.  8.  9.  4.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [0. 6. 1. 6. 0.] 
adversary cards in discard: [ 2.  0. 10. 23.  0. 10.  0.  0.  1.  6.  3.  0.  6. 16.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11  0  6 10  6  8  2  0  6  6] -> size -> 37 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5.   0.   0. 210.   0.   0.  60.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: 297.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 51.28388977050781






Player: 1 
cards in hand: [0. 6. 1. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 1. 6. 0.] 
cards in discard: [ 2.  0. 10. 23.  0. 10.  0.  0.  1.  6.  3.  0.  6. 16.  3.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11  0  6 10  6  8  2  0  6  6] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 29. 26. 30.  8.  2.  9.  8.  9.  4.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 3. 10. 29. 25.  1.] 
adversary cards in discard: [29. 29. 29. 25.  0.  0.  3.  0. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29] -> size -> 28 
adversary victory points: 5
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 1. 6. 0.] 
cards in discard: [ 2.  0. 10. 23.  0. 10.  0.  0.  1.  6.  3.  0.  6. 16.  3.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11  0  6 10  6  8  2  0  6  6] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 26. 29. 26. 30.  8.  2.  9.  8.  9.  4.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 3. 10. 29. 25.  1.] 
adversary cards in discard: [29. 29. 29. 25.  0.  0.  3.  0. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29] -> size -> 28 
adversary victory points: 5
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 1. 6. 0.] 
cards in discard: [ 2.  0. 10. 23.  0. 10.  0.  0.  1.  6.  3.  0.  6. 16.  3.  6.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11  0  6 10  6  8  2  0  6  6  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 26. 29. 25. 30.  8.  2.  9.  8.  9.  4.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 3. 10. 29. 25.  1.] 
adversary cards in discard: [29. 29. 29. 25.  0.  0.  3.  0. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29] -> size -> 28 
adversary victory points: 5
player victory points: -2 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 29. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 25.] 
expected returns: [[55.34314 ]
 [59.24936 ]
 [66.922485]
 [70.876495]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 29. 25.  1.] 
cards in discard: [29. 29. 29. 25.  0.  0.  3.  0. 29. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 29. 25. 30.  8.  2.  9.  8.  9.  4.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [14. 11.  8.  0.  0.] 
adversary cards in discard: [ 2.  0. 10. 23.  0. 10.  0.  0.  1.  6.  3.  0.  6. 16.  3.  6.  3.  0.
  6.  1.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11  0  6 10  6  8  2  0  6  6  3] -> size -> 38 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 34.08938217163086



action possibilites: [-1] 
expected returns: [[94.51781]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 29.  1.  3. 25.] 
cards in discard: [29. 29. 29. 25.  0.  0.  3.  0. 29. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 29. 25. 30.  8.  1.  9.  8.  9.  4.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [14. 11.  8.  0.  0.] 
adversary cards in discard: [ 2.  0. 10. 23.  0. 10.  0.  0.  1.  6.  3.  0.  6. 16.  3.  6.  3.  0.
  6.  1.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11  0  6 10  6  8  2  0  6  6  3  6] -> size -> 39 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 70.8764877319336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 90.14973 ]
 [101.34342 ]
 [ 47.420647]
 [ 95.77773 ]
 [ 96.03002 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 29.  1.  3. 25.] 
cards in discard: [29. 29. 29. 25.  0.  0.  3.  0. 29. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 26. 29. 25. 30.  8.  1.  9.  8.  9.  4.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [14. 11.  8.  0.  0.] 
adversary cards in discard: [ 2.  0. 10. 23.  0. 10.  0.  0.  1.  6.  3.  0.  6. 16.  3.  6.  3.  0.
  6.  1.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11  0  6 10  6  8  2  0  6  6  3  6] -> size -> 39 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 94.51780700683594



buy possibilites: [-1] 
expected returns: [[41.74717]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 29.  1.  3. 25.] 
cards in discard: [29. 29. 29. 25.  0.  0.  3.  0. 29. 10.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 29. 24. 30.  8.  1.  9.  8.  9.  4.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [14. 11.  8.  0.  0.] 
adversary cards in discard: [ 2.  0. 10. 23.  0. 10.  0.  0.  1.  6.  3.  0.  6. 16.  3.  6.  3.  0.
  6.  1.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11  0  6 10  6  8  2  0  6  6  3  6] -> size -> 39 
adversary victory points: -2
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 271 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 101.34342956542969






Player: 1 
cards in hand: [14. 11.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 11.  8.  0.  0.] 
cards in discard: [ 2.  0. 10. 23.  0. 10.  0.  0.  1.  6.  3.  0.  6. 16.  3.  6.  3.  0.
  6.  1.  6.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6
  1  6 29 11  0  6 10  6  8  2  0  6  6  3  6] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 29. 24. 30.  8.  1.  9.  8.  9.  4.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [25. 25. 29.  3.  0.] 
adversary cards in discard: [29. 29. 29. 25.  0.  0.  3.  0. 29. 10.  3. 25.  3. 10. 29.  1.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3] -> size -> 29 
adversary victory points: 6
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.] 
cards in discard: [ 2.  0. 10. 23.  0. 10.  0.  0.  1.  6.  3.  0.  6. 16.  3.  6.  3.  0.
  6.  1.  6.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1
  6 29  0  6 10  6  8  2  0  6  6  3  6] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 29. 24. 30.  8.  1.  9.  8.  9.  4.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [25. 25. 29.  3.  0.] 
adversary cards in discard: [29. 29. 29. 25.  0.  0.  3.  0. 29. 10.  3. 25.  3. 10. 29.  1.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3] -> size -> 29 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.] 
cards in discard: [ 2.  0. 10. 23.  0. 10.  0.  0.  1.  6.  3.  0.  6. 16.  3.  6.  3.  0.
  6.  1.  6.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1
  6 29  0  6 10  6  8  2  0  6  6  3  6] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 26. 29. 24. 30.  8.  1.  9.  8.  9.  4.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [25. 25. 29.  3.  0.] 
adversary cards in discard: [29. 29. 29. 25.  0.  0.  3.  0. 29. 10.  3. 25.  3. 10. 29.  1.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3] -> size -> 29 
adversary victory points: 6
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.] 
cards in discard: [ 2.  0. 10. 23.  0. 10.  0.  0.  1.  6.  3.  0.  6. 16.  3.  6.  3.  0.
  6.  1.  6.  0.  6.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1
  6 29  0  6 10  6  8  2  0  6  6  3  6  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 26. 29. 24. 30.  8.  1.  9.  8.  9.  4.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [25. 25. 29.  3.  0.] 
adversary cards in discard: [29. 29. 29. 25.  0.  0.  3.  0. 29. 10.  3. 25.  3. 10. 29.  1.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3] -> size -> 29 
adversary victory points: 6
player victory points: -3 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [25. 25. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 29.] 
expected returns: [[50.550514]
 [77.04712 ]
 [77.04712 ]
 [71.13397 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25. 29.  3.  0.] 
cards in discard: [29. 29. 29. 25.  0.  0.  3.  0. 29. 10.  3. 25.  3. 10. 29.  1.  3. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 24. 30.  8.  1.  9.  8.  9.  4.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [29.  1.  3.  0.  6.] 
adversary cards in discard: [ 2.  0. 10. 23.  0. 10.  0.  0.  1.  6.  3.  0.  6. 16.  3.  6.  3.  0.
  6.  1.  6.  0.  6.  0.  8. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1
  6 29  0  6 10  6  8  2  0  6  6  3  6  0] -> size -> 38 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 41.747169494628906



action possibilites: [-1] 
expected returns: [[56.214443]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29.  3.  0. 25.  0.] 
cards in discard: [29. 29. 29. 25.  0.  0.  3.  0. 29. 10.  3. 25.  3. 10. 29.  1.  3. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 24. 30.  8.  0.  9.  8.  9.  4.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [29.  1.  3.  0.  6.] 
adversary cards in discard: [ 2.  0. 10. 23.  0. 10.  0.  0.  1.  6.  3.  0.  6. 16.  3.  6.  3.  0.
  6.  1.  6.  0.  6.  0.  8. 14.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1
  6 29  0  6 10  6  8  2  0  6  6  3  6  0  6] -> size -> 39 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 77.04711151123047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[52.33574 ]
 [58.20685 ]
 [56.824158]
 [58.75801 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 29.  3.  0. 25.  0.] 
cards in discard: [29. 29. 29. 25.  0.  0.  3.  0. 29. 10.  3. 25.  3. 10. 29.  1.  3. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 29. 24. 30.  8.  0.  9.  8.  9.  4.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [29.  1.  3.  0.  6.] 
adversary cards in discard: [ 2.  0. 10. 23.  0. 10.  0.  0.  1.  6.  3.  0.  6. 16.  3.  6.  3.  0.
  6.  1.  6.  0.  6.  0.  8. 14.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1
  6 29  0  6 10  6  8  2  0  6  6  3  6  0  6] -> size -> 39 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 56.21444320678711






Player: 1 
cards in hand: [29.  1.  3.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  3.  0.  6.] 
cards in discard: [ 2.  0. 10. 23.  0. 10.  0.  0.  1.  6.  3.  0.  6. 16.  3.  6.  3.  0.
  6.  1.  6.  0.  6.  0.  8. 14.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1
  6 29  0  6 10  6  8  2  0  6  6  3  6  0  6] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 24. 30.  8.  0.  9.  8.  9.  4.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [25.  3. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3] -> size -> 29 
adversary victory points: 6
player victory points: -4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 3.] 
cards in discard: [ 2.  0. 10. 23.  0. 10.  0.  0.  1.  6.  3.  0.  6. 16.  3.  6.  3.  0.
  6.  1.  6.  0.  6.  0.  8. 14.  0.  6.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1
  6 29  0  6 10  6  8  2  0  6  6  3  6  0  6] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 26. 29. 24. 30.  8.  0.  9.  8.  9.  4.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [25.  3. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3] -> size -> 29 
adversary victory points: 6
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3.] 
cards in discard: [ 2.  0. 10. 23.  0. 10.  0.  0.  1.  6.  3.  0.  6. 16.  3.  6.  3.  0.
  6.  1.  6.  0.  6.  0.  8. 14.  0.  6.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1
  6 29  0  6 10  6  8  2  0  6  6  3  6  0  6] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 29. 24. 30.  8.  0.  9.  8.  9.  4.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [25.  3. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3] -> size -> 29 
adversary victory points: 6
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3.] 
cards in discard: [ 2.  0. 10. 23.  0. 10.  0.  0.  1.  6.  3.  0.  6. 16.  3.  6.  3.  0.
  6.  1.  6.  0.  6.  0.  8. 14.  0.  6.  1.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1
  6 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 24. 30.  8.  0.  9.  8.  8.  4.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [25.  3. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3] -> size -> 29 
adversary victory points: 6
player victory points: -4 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [25.  3. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[30.85318]
 [50.55529]
 [38.16163]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 24. 30.  8.  0.  9.  8.  8.  4.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [3. 6. 6. 0. 0.] 
adversary cards in discard: [ 2.  0. 10. 23.  0. 10.  0.  0.  1.  6.  3.  0.  6. 16.  3.  6.  3.  0.
  6.  1.  6.  0.  6.  0.  8. 14.  0.  6.  1.  8. 29.  3.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1
  6 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8] -> size -> 40 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 58.75801086425781



action possibilites: [-1] 
expected returns: [[-26.026802]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.  3. 25.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 24. 30.  8.  0.  9.  8.  8.  4.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [3. 6. 6. 0. 0.] 
adversary cards in discard: [ 2.  0. 10. 23.  0. 10.  0.  0.  1.  6.  3.  0.  6. 16.  3.  6.  3.  0.
  6.  1.  6.  0.  6.  0.  8. 14.  0.  6.  1.  8. 29.  3.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1
  6 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8] -> size -> 40 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 50.555267333984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-35.309727]
 [-29.610485]
 [-17.924099]
 [-18.793259]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  0.  3. 25.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 29. 24. 30.  8.  0.  9.  8.  8.  4.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [3. 6. 6. 0. 0.] 
adversary cards in discard: [ 2.  0. 10. 23.  0. 10.  0.  0.  1.  6.  3.  0.  6. 16.  3.  6.  3.  0.
  6.  1.  6.  0.  6.  0.  8. 14.  0.  6.  1.  8. 29.  3.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1
  6 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8] -> size -> 40 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: -26.02680206298828



buy possibilites: [-1] 
expected returns: [[11.6590605]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  0.  3. 25.] 
cards in discard: [8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 24. 30.  8.  0.  9.  8.  7.  4.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [3. 6. 6. 0. 0.] 
adversary cards in discard: [ 2.  0. 10. 23.  0. 10.  0.  0.  1.  6.  3.  0.  6. 16.  3.  6.  3.  0.
  6.  1.  6.  0.  6.  0.  8. 14.  0.  6.  1.  8. 29.  3.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1
  6 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8] -> size -> 40 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 331 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -17.924156188964844






Player: 1 
cards in hand: [3. 6. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 0. 0.] 
cards in discard: [ 2.  0. 10. 23.  0. 10.  0.  0.  1.  6.  3.  0.  6. 16.  3.  6.  3.  0.
  6.  1.  6.  0.  6.  0.  8. 14.  0.  6.  1.  8. 29.  3.  0.  6.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1
  6 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 24. 30.  8.  0.  9.  8.  7.  4.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  0.  1. 29. 25.] 
adversary cards in discard: [ 8. 25.  3. 11.  0.  0.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8] -> size -> 30 
adversary victory points: 6
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 0. 0.] 
cards in discard: [ 2.  0. 10. 23.  0. 10.  0.  0.  1.  6.  3.  0.  6. 16.  3.  6.  3.  0.
  6.  1.  6.  0.  6.  0.  8. 14.  0.  6.  1.  8. 29.  3.  0.  6.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1
  6 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 29. 24. 30.  8.  0.  9.  8.  7.  4.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  0.  1. 29. 25.] 
adversary cards in discard: [ 8. 25.  3. 11.  0.  0.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8] -> size -> 30 
adversary victory points: 6
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 0. 0.] 
cards in discard: [ 2.  0. 10. 23.  0. 10.  0.  0.  1.  6.  3.  0.  6. 16.  3.  6.  3.  0.
  6.  1.  6.  0.  6.  0.  8. 14.  0.  6.  1.  8. 29.  3.  0.  6.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1
  6 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 23. 30.  8.  0.  9.  8.  7.  4.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  0.  1. 29. 25.] 
adversary cards in discard: [ 8. 25.  3. 11.  0.  0.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8] -> size -> 30 
adversary victory points: 6
player victory points: -3 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  1. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[11.914393]
 [25.099403]
 [26.640034]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  1. 29. 25.] 
cards in discard: [ 8. 25.  3. 11.  0.  0.  3. 25.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 23. 30.  8.  0.  9.  8.  7.  4.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [10.  1.  0.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1
  6 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3] -> size -> 41 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 11.65906047821045



action possibilites: [-1] 
expected returns: [[48.35089]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  1. 29. 29.  0.] 
cards in discard: [ 8. 25.  3. 11.  0.  0.  3. 25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 23. 30.  8.  0.  9.  8.  7.  4.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [10.  1.  0.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1
  6 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3] -> size -> 41 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 26.640037536621094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[45.30347 ]
 [58.141193]
 [52.450287]
 [60.21705 ]
 [57.288685]
 [49.685738]
 [62.334343]
 [26.065666]
 [53.29103 ]
 [45.599354]
 [48.131542]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  1. 29. 29.  0.] 
cards in discard: [ 8. 25.  3. 11.  0.  0.  3. 25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 26. 29. 23. 30.  8.  0.  9.  8.  7.  4.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [10.  1.  0.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1
  6 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3] -> size -> 41 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 48.35089111328125



buy possibilites: [-1] 
expected returns: [[39.881653]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  1. 29. 29.  0.] 
cards in discard: [ 8. 25.  3. 11.  0.  0.  3. 25. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 23. 30.  8.  0.  9.  8.  7.  4.  2.  9.  9.  6. 10. 10.] 
adversary cards in hand: [10.  1.  0.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1
  6 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3] -> size -> 41 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 413 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 62.33433532714844






Player: 1 
cards in hand: [10.  1.  0.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  0.  6.  0.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1
  6 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 23. 30.  8.  0.  9.  8.  7.  4.  2.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 3. 10.  0. 29. 25.] 
adversary cards in discard: [ 8. 25.  3. 11.  0.  0.  3. 25. 29. 25.  3.  0.  1. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29] -> size -> 31 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  0.  6.  0.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1
  6 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 26. 29. 23. 30.  8.  0.  9.  8.  7.  4.  2.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 3. 10.  0. 29. 25.] 
adversary cards in discard: [ 8. 25.  3. 11.  0.  0.  3. 25. 29. 25.  3.  0.  1. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29] -> size -> 31 
adversary victory points: 6
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  0.  6.  0.] 
cards in discard: [11.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1
  6 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 26. 29. 23. 30.  8.  0.  9.  7.  7.  4.  2.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 3. 10.  0. 29. 25.] 
adversary cards in discard: [ 8. 25.  3. 11.  0.  0.  3. 25. 29. 25.  3.  0.  1. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29] -> size -> 31 
adversary victory points: 6
player victory points: -3 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 3. 10.  0. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 25.] 
expected returns: [[ 86.93293]
 [ 89.28104]
 [ 99.024  ]
 [103.77077]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0. 29. 25.] 
cards in discard: [ 8. 25.  3. 11.  0.  0.  3. 25. 29. 25.  3.  0.  1. 29. 29.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 23. 30.  8.  0.  9.  7.  7.  4.  2.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  6. 14.  3.  6.] 
adversary cards in discard: [11. 10.  1.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1
  6 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11] -> size -> 42 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 39.88165283203125



action possibilites: [-1] 
expected returns: [[70.28406]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0. 29. 29.  0.] 
cards in discard: [ 8. 25.  3. 11.  0.  0.  3. 25. 29. 25.  3.  0.  1. 29. 29.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 23. 30.  8.  0.  9.  7.  7.  4.  2.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  6. 14.  3.  6.] 
adversary cards in discard: [11. 10.  1.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1
  6 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11] -> size -> 42 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 103.7707748413086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[66.0709 ]
 [76.8693 ]
 [70.00858]
 [70.18337]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0. 29. 29.  0.] 
cards in discard: [ 8. 25.  3. 11.  0.  0.  3. 25. 29. 25.  3.  0.  1. 29. 29.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 29. 23. 30.  8.  0.  9.  7.  7.  4.  2.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  6. 14.  3.  6.] 
adversary cards in discard: [11. 10.  1.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1
  6 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11] -> size -> 42 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 70.2840576171875



buy possibilites: [-1] 
expected returns: [[62.324783]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0. 29. 29.  0.] 
cards in discard: [ 8. 25.  3. 11.  0.  0.  3. 25. 29. 25.  3.  0.  1. 29. 29.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 22. 30.  8.  0.  9.  7.  7.  4.  2.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  6. 14.  3.  6.] 
adversary cards in discard: [11. 10.  1.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1
  6 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11] -> size -> 42 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 331 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 76.86927795410156






Player: 1 
cards in hand: [ 3.  6. 14.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 14.  3.  6.] 
cards in discard: [11. 10.  1.  0.  6.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1
  6 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 22. 30.  8.  0.  9.  7.  7.  4.  2.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 29. 25. 10.] 
adversary cards in discard: [ 8. 25.  3. 11.  0.  0.  3. 25. 29. 25.  3.  0.  1. 29. 29.  0.  3. 25.
  3. 10.  0. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3] -> size -> 32 
adversary victory points: 7
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 14.  3.  6.] 
cards in discard: [11. 10.  1.  0.  6.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1
  6 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11] -> size -> 42 
action values: 1 
buys: 1 
player value: 0 
card supply: [24. 26. 29. 22. 30.  8.  0.  9.  7.  7.  4.  2.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 29. 25. 10.] 
adversary cards in discard: [ 8. 25.  3. 11.  0.  0.  3. 25. 29. 25.  3.  0.  1. 29. 29.  0.  3. 25.
  3. 10.  0. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3] -> size -> 32 
adversary victory points: 7
player victory points: -3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 29. 25. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 10.] 
expected returns: [[115.41444 ]
 [125.90753 ]
 [129.66254 ]
 [115.279335]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29. 25. 10.] 
cards in discard: [ 8. 25.  3. 11.  0.  0.  3. 25. 29. 25.  3.  0.  1. 29. 29.  0.  3. 25.
  3. 10.  0. 29. 29.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 22. 30.  8.  0.  9.  7.  7.  4.  2.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 6.  6.  0.  0. 10.] 
adversary cards in discard: [11. 10.  1.  0.  6.  0.  3.  6. 14.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1
  6 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11] -> size -> 42 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 62.32478332519531



action possibilites: [-1] 
expected returns: [[89.89484]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29. 10. 25.  3.] 
cards in discard: [ 8. 25.  3. 11.  0.  0.  3. 25. 29. 25.  3.  0.  1. 29. 29.  0.  3. 25.
  3. 10.  0. 29. 29.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 22. 30.  8.  0.  9.  7.  7.  4.  2.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 6.  6.  0.  0. 10.] 
adversary cards in discard: [11. 10.  1.  0.  6.  0.  3.  6. 14.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1
  6 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11] -> size -> 42 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 129.6625518798828





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[83.68048]
 [90.42959]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29. 10. 25.  3.] 
cards in discard: [ 8. 25.  3. 11.  0.  0.  3. 25. 29. 25.  3.  0.  1. 29. 29.  0.  3. 25.
  3. 10.  0. 29. 29.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 29. 22. 30.  8.  0.  9.  7.  7.  4.  2.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 6.  6.  0.  0. 10.] 
adversary cards in discard: [11. 10.  1.  0.  6.  0.  3.  6. 14.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1
  6 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11] -> size -> 42 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: 89.89483642578125






Player: 1 
cards in hand: [ 6.  6.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0.  0. 10.] 
cards in discard: [11. 10.  1.  0.  6.  0.  3.  6. 14.  3.  6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1
  6 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 22. 30.  8.  0.  9.  7.  7.  4.  2.  9.  9.  6. 10. 10.] 
adversary cards in hand: [25.  3.  1.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3] -> size -> 32 
adversary victory points: 7
player victory points: -3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 0. 0.] 
cards in discard: [11. 10.  1.  0.  6.  0.  3.  6. 14.  3.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1
  6 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11] -> size -> 42 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 22. 30.  8.  0.  9.  7.  7.  4.  2.  9.  9.  6. 10. 10.] 
adversary cards in hand: [25.  3.  1.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3] -> size -> 32 
adversary victory points: 7
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 0. 0.] 
cards in discard: [11. 10.  1.  0.  6.  0.  3.  6. 14.  3.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1
  6 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 26. 29. 22. 30.  8.  0.  9.  7.  7.  4.  2.  9.  9.  6. 10. 10.] 
adversary cards in hand: [25.  3.  1.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3] -> size -> 32 
adversary victory points: 7
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 0. 0.] 
cards in discard: [11. 10.  1.  0.  6.  0.  3.  6. 14.  3.  6.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1
  6 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 22. 30.  8.  0.  9.  7.  7.  4.  2.  9.  9.  6. 10. 10.] 
adversary cards in hand: [25.  3.  1.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3] -> size -> 32 
adversary victory points: 7
player victory points: -3 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [25.  3.  1.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8. 29.] 
expected returns: [[ 9.800768]
 [29.517681]
 [12.725968]
 [24.777493]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  1.  8. 29.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 22. 30.  8.  0.  9.  7.  7.  4.  2.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 16.  2.  0.] 
adversary cards in discard: [11. 10.  1.  0.  6.  0.  3.  6. 14.  3.  6.  1. 10.  6.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1
  6 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1] -> size -> 43 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 90.4295883178711



action possibilites: [-1] 
expected returns: [[25.17553]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  8. 29.  3. 25.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 22. 30.  8.  0.  9.  7.  7.  4.  2.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 16.  2.  0.] 
adversary cards in discard: [11. 10.  1.  0.  6.  0.  3.  6. 14.  3.  6.  1. 10.  6.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1
  6 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1] -> size -> 43 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 29.51767349243164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[24.971783]
 [28.94891 ]
 [33.19137 ]
 [28.040321]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  8. 29.  3. 25.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 25. 29. 22. 30.  8.  0.  9.  7.  7.  4.  2.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 16.  2.  0.] 
adversary cards in discard: [11. 10.  1.  0.  6.  0.  3.  6. 14.  3.  6.  1. 10.  6.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1
  6 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1] -> size -> 43 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: 25.17552947998047



buy possibilites: [-1] 
expected returns: [[45.80275]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  8. 29.  3. 25.] 
cards in discard: [8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 22. 30.  8.  0.  9.  7.  6.  4.  2.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 16.  2.  0.] 
adversary cards in discard: [11. 10.  1.  0.  6.  0.  3.  6. 14.  3.  6.  1. 10.  6.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1
  6 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1] -> size -> 43 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 331 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 33.191383361816406






Player: 1 
cards in hand: [ 3.  0. 16.  2.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 16.  2.  0.] 
cards in discard: [11. 10.  1.  0.  6.  0.  3.  6. 14.  3.  6.  1. 10.  6.  6.  0.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1
  6 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 22. 30.  8.  0.  9.  7.  6.  4.  2.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 0. 29. 25.  0. 10.] 
adversary cards in discard: [ 8. 25.  3.  1.  8. 29.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8] -> size -> 33 
adversary victory points: 7
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 2. 0.] 
cards in discard: [11. 10.  1.  0.  6.  0.  3.  6. 14.  3.  6.  1. 10.  6.  6.  0.  0.  0.
 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 22. 30.  8.  0.  9.  6.  6.  4.  2.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 0. 29. 25.  0. 10.] 
adversary cards in discard: [ 8. 25.  3.  1.  8. 29.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8] -> size -> 33 
adversary victory points: 7
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 2. 0.] 
cards in discard: [11. 10.  1.  0.  6.  0.  3.  6. 14.  3.  6.  1. 10.  6.  6.  0.  0.  0.
 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11] -> size -> 43 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 25. 29. 22. 30.  8.  0.  9.  6.  6.  4.  2.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 0. 29. 25.  0. 10.] 
adversary cards in discard: [ 8. 25.  3.  1.  8. 29.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8] -> size -> 33 
adversary victory points: 7
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 2. 0.] 
cards in discard: [11. 10.  1.  0.  6.  0.  3.  6. 14.  3.  6.  1. 10.  6.  6.  0.  0.  0.
 11. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11] -> size -> 44 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 25. 29. 22. 30.  8.  0.  9.  5.  6.  4.  2.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 0. 29. 25.  0. 10.] 
adversary cards in discard: [ 8. 25.  3.  1.  8. 29.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8] -> size -> 33 
adversary victory points: 7
player victory points: -4 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 25.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 10.] 
expected returns: [[70.000725]
 [86.904755]
 [92.46736 ]
 [79.33905 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 25.  0. 10.] 
cards in discard: [ 8. 25.  3.  1.  8. 29.  3. 25.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 22. 30.  8.  0.  9.  5.  6.  4.  2.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 6. 29.  6.  6.  6.] 
adversary cards in discard: [11. 10.  1.  0.  6.  0.  3.  6. 14.  3.  6.  1. 10.  6.  6.  0.  0.  0.
 11. 11. 16.  0.  2.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11] -> size -> 44 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 45.80274963378906



action possibilites: [-1] 
expected returns: [[38.207832]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 10. 25. 25.] 
cards in discard: [ 8. 25.  3.  1.  8. 29.  3. 25.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 22. 30.  8.  0.  9.  5.  6.  4.  2.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 6. 29.  6.  6.  6.] 
adversary cards in discard: [11. 10.  1.  0.  6.  0.  3.  6. 14.  3.  6.  1. 10.  6.  6.  0.  0.  0.
 11. 11. 16.  0.  2.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11] -> size -> 44 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 92.46736145019531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[37.207207]
 [43.733284]
 [41.57915 ]
 [39.21006 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0. 10. 25. 25.] 
cards in discard: [ 8. 25.  3.  1.  8. 29.  3. 25.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 25. 29. 22. 30.  8.  0.  9.  5.  6.  4.  2.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 6. 29.  6.  6.  6.] 
adversary cards in discard: [11. 10.  1.  0.  6.  0.  3.  6. 14.  3.  6.  1. 10.  6.  6.  0.  0.  0.
 11. 11. 16.  0.  2.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11] -> size -> 44 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: 38.20783233642578



buy possibilites: [-1] 
expected returns: [[60.22087]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0. 10. 25. 25.] 
cards in discard: [ 8. 25.  3.  1.  8. 29.  3. 25.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 21. 30.  8.  0.  9.  5.  6.  4.  2.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 6. 29.  6.  6.  6.] 
adversary cards in discard: [11. 10.  1.  0.  6.  0.  3.  6. 14.  3.  6.  1. 10.  6.  6.  0.  0.  0.
 11. 11. 16.  0.  2.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11] -> size -> 44 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 391 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 43.73329162597656






Player: 1 
cards in hand: [ 6. 29.  6.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29.  6.  6.  6.] 
cards in discard: [11. 10.  1.  0.  6.  0.  3.  6. 14.  3.  6.  1. 10.  6.  6.  0.  0.  0.
 11. 11. 16.  0.  2.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 21. 30.  8.  0.  9.  5.  6.  4.  2.  9.  9.  6. 10. 10.] 
adversary cards in hand: [29. 29. 29.  0.  3.] 
adversary cards in discard: [ 8. 25.  3.  1.  8. 29.  3. 25.  3. 25.  0. 29.  0. 10. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3] -> size -> 34 
adversary victory points: 8
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 29.  6.  6.  6.] 
cards in discard: [11. 10.  1.  0.  6.  0.  3.  6. 14.  3.  6.  1. 10.  6.  6.  0.  0.  0.
 11. 11. 16.  0.  2.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11] -> size -> 44 
action values: 1 
buys: 1 
player value: 0 
card supply: [24. 25. 29. 21. 30.  8.  0.  9.  5.  6.  4.  2.  9.  9.  6. 10. 10.] 
adversary cards in hand: [29. 29. 29.  0.  3.] 
adversary cards in discard: [ 8. 25.  3.  1.  8. 29.  3. 25.  3. 25.  0. 29.  0. 10. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3] -> size -> 34 
adversary victory points: 8
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 29.  6.  6.  6.] 
cards in discard: [11. 10.  1.  0.  6.  0.  3.  6. 14.  3.  6.  1. 10.  6.  6.  0.  0.  0.
 11. 11. 16.  0.  2.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 29. 21. 30.  8.  0.  9.  5.  6.  4.  2.  9.  9.  6. 10. 10.] 
adversary cards in hand: [29. 29. 29.  0.  3.] 
adversary cards in discard: [ 8. 25.  3.  1.  8. 29.  3. 25.  3. 25.  0. 29.  0. 10. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3] -> size -> 34 
adversary victory points: 8
player victory points: -4 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [29. 29. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[ 99.39282 ]
 [105.182144]
 [105.182144]
 [105.182144]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29.  0.  3.] 
cards in discard: [ 8. 25.  3.  1.  8. 29.  3. 25.  3. 25.  0. 29.  0. 10. 25. 25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 29. 21. 30.  8.  0.  9.  5.  6.  4.  2.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 1.  0.  3. 23.  1.] 
adversary cards in discard: [11. 10.  1.  0.  6.  0.  3.  6. 14.  3.  6.  1. 10.  6.  6.  0.  0.  0.
 11. 11. 16.  0.  2.  0.  0.  6. 29.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0] -> size -> 45 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1
Learning step: 0
desired expected reward: 60.22087097167969



action possibilites: [-1. 29.] 
expected returns: [[68.88069]
 [81.41031]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  3.] 
cards in discard: [ 8. 25.  3.  1.  8. 29.  3. 25.  3. 25.  0. 29.  0. 10. 25. 25. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 25. 29. 21. 30.  8.  0.  9.  5.  6.  4.  2.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 1.  0.  3. 23.  1.] 
adversary cards in discard: [11. 10.  1.  0.  6.  0.  3.  6. 14.  3.  6.  1. 10.  6.  6.  0.  0.  0.
 11. 11. 16.  0.  2.  0.  0.  6. 29.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0] -> size -> 45 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 102.98759460449219



action possibilites: [-1.] 
expected returns: [[84.35915]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [ 8. 25.  3.  1.  8. 29.  3. 25.  3. 25.  0. 29.  0. 10. 25. 25. 29.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 2 
card supply: [23. 25. 29. 21. 30.  8.  0.  9.  5.  6.  4.  2.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 1.  0.  3. 23.  1.] 
adversary cards in discard: [11. 10.  1.  0.  6.  0.  3.  6. 14.  3.  6.  1. 10.  6.  6.  0.  0.  0.
 11. 11. 16.  0.  2.  0.  0.  6. 29.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0] -> size -> 45 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 395 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 71.93887329101562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[76.17791 ]
 [89.72623 ]
 [83.14006 ]
 [92.96659 ]
 [89.044495]
 [81.6169  ]
 [96.03437 ]
 [55.601936]
 [84.80189 ]
 [76.37974 ]
 [84.61717 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 8. 25.  3.  1.  8. 29.  3. 25.  3. 25.  0. 29.  0. 10. 25. 25. 29.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 25. 29. 21. 30.  8.  0.  9.  5.  6.  4.  2.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 1.  0.  3. 23.  1.] 
adversary cards in discard: [11. 10.  1.  0.  6.  0.  3.  6. 14.  3.  6.  1. 10.  6.  6.  0.  0.  0.
 11. 11. 16.  0.  2.  0.  0.  6. 29.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0] -> size -> 45 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 395 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 84.3591537475586



buy possibilites: [-1] 
expected returns: [[98.5679]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 8. 25.  3.  1.  8. 29.  3. 25.  3. 25.  0. 29.  0. 10. 25. 25. 29.  3.
 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 29. 21. 30.  8.  0.  9.  5.  6.  4.  1.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 1.  0.  3. 23.  1.] 
adversary cards in discard: [11. 10.  1.  0.  6.  0.  3.  6. 14.  3.  6.  1. 10.  6.  6.  0.  0.  0.
 11. 11. 16.  0.  2.  0.  0.  6. 29.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0] -> size -> 45 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 523 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 96.03438568115234






Player: 1 
cards in hand: [ 1.  0.  3. 23.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3. 23.  1.] 
cards in discard: [11. 10.  1.  0.  6.  0.  3.  6. 14.  3.  6.  1. 10.  6.  6.  0.  0.  0.
 11. 11. 16.  0.  2.  0.  0.  6. 29.  6.  6.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 29. 21. 30.  8.  0.  9.  5.  6.  4.  1.  9.  9.  6. 10. 10.] 
adversary cards in hand: [11. 29.  0.  3.  3.] 
adversary cards in discard: [ 8. 25.  3.  1.  8. 29.  3. 25.  3. 25.  0. 29.  0. 10. 25. 25. 29.  3.
 29. 29. 29.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29] -> size -> 35 
adversary victory points: 8
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3. 23.  1.] 
cards in discard: [11. 10.  1.  0.  6.  0.  3.  6. 14.  3.  6.  1. 10.  6.  6.  0.  0.  0.
 11. 11. 16.  0.  2.  0.  0.  6. 29.  6.  6.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0] -> size -> 45 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 25. 29. 21. 30.  8.  0.  9.  5.  6.  4.  1.  9.  9.  6. 10. 10.] 
adversary cards in hand: [11. 29.  0.  3.  3.] 
adversary cards in discard: [ 8. 25.  3.  1.  8. 29.  3. 25.  3. 25.  0. 29.  0. 10. 25. 25. 29.  3.
 29. 29. 29.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29] -> size -> 35 
adversary victory points: 8
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3. 23.  1.] 
cards in discard: [11. 10.  1.  0.  6.  0.  3.  6. 14.  3.  6.  1. 10.  6.  6.  0.  0.  0.
 11. 11. 16.  0.  2.  0.  0.  6. 29.  6.  6.  6. 22.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 29. 21. 30.  8.  0.  9.  5.  6.  4.  1.  9.  9.  6.  9. 10.] 
adversary cards in hand: [11. 29.  0.  3.  3.] 
adversary cards in discard: [ 8. 25.  3.  1.  8. 29.  3. 25.  3. 25.  0. 29.  0. 10. 25. 25. 29.  3.
 29. 29. 29.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29] -> size -> 35 
adversary victory points: 8
player victory points: -4 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [11. 29.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[ 90.73146]
 [ 95.31523]
 [101.74861]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  0.  3.  3.] 
cards in discard: [ 8. 25.  3.  1.  8. 29.  3. 25.  3. 25.  0. 29.  0. 10. 25. 25. 29.  3.
 29. 29. 29.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 29. 21. 30.  8.  0.  9.  5.  6.  4.  1.  9.  9.  6.  9. 10.] 
adversary cards in hand: [3. 0. 8. 3. 0.] 
adversary cards in discard: [11. 10.  1.  0.  6.  0.  3.  6. 14.  3.  6.  1. 10.  6.  6.  0.  0.  0.
 11. 11. 16.  0.  2.  0.  0.  6. 29.  6.  6.  6. 22.  1.  0.  3. 23.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22] -> size -> 46 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1
Learning step: 0
desired expected reward: 98.56790161132812



action possibilites: [-1. 11.] 
expected returns: [[85.63547]
 [89.90747]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  3.  0.] 
cards in discard: [ 8. 25.  3.  1.  8. 29.  3. 25.  3. 25.  0. 29.  0. 10. 25. 25. 29.  3.
 29. 29. 29.  0.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 25. 29. 21. 30.  8.  0.  9.  5.  6.  4.  1.  9.  9.  6.  9. 10.] 
adversary cards in hand: [3. 0. 8. 3. 0.] 
adversary cards in discard: [11. 10.  1.  0.  6.  0.  3.  6. 14.  3.  6.  1. 10.  6.  6.  0.  0.  0.
 11. 11. 16.  0.  2.  0.  0.  6. 29.  6.  6.  6. 22.  1.  0.  3. 23.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22] -> size -> 46 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 96.4287109375



action possibilites: [-1] 
expected returns: [[140.14445]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [ 8. 25.  3.  1.  8. 29.  3. 25.  3. 25.  0. 29.  0. 10. 25. 25. 29.  3.
 29. 29. 29.  0.  3.  0.  0. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 25. 29. 21. 30.  8.  0.  9.  5.  6.  4.  1.  9.  9.  6.  9.  9.] 
adversary cards in hand: [3. 0. 8. 3. 0.] 
adversary cards in discard: [11. 10.  1.  0.  6.  0.  3.  6. 14.  3.  6.  1. 10.  6.  6.  0.  0.  0.
 11. 11. 16.  0.  2.  0.  0.  6. 29.  6.  6.  6. 22.  1.  0.  3. 23.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22] -> size -> 46 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0  40   0   0   0   0 -10   0   0  64   0] 
sum of rewards: 449 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 93.41938018798828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[132.6872 ]
 [140.415  ]
 [137.77429]
 [140.96356]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 8. 25.  3.  1.  8. 29.  3. 25.  3. 25.  0. 29.  0. 10. 25. 25. 29.  3.
 29. 29. 29.  0.  3.  0.  0. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 25. 29. 21. 30.  8.  0.  9.  5.  6.  4.  1.  9.  9.  6.  9.  9.] 
adversary cards in hand: [3. 0. 8. 3. 0.] 
adversary cards in discard: [11. 10.  1.  0.  6.  0.  3.  6. 14.  3.  6.  1. 10.  6.  6.  0.  0.  0.
 11. 11. 16.  0.  2.  0.  0.  6. 29.  6.  6.  6. 22.  1.  0.  3. 23.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22] -> size -> 46 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 395 

action type: take_action - action -1
Learning step: 0
desired expected reward: 140.1444549560547






Player: 1 
cards in hand: [3. 0. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 3. 0.] 
cards in discard: [11. 10.  1.  0.  6.  0.  3.  6. 14.  3.  6.  1. 10.  6.  6.  0.  0.  0.
 11. 11. 16.  0.  2.  0.  0.  6. 29.  6.  6.  6. 22.  1.  0.  3. 23.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 29. 21. 30.  8.  0.  9.  5.  6.  4.  1.  9.  9.  6.  9.  9.] 
adversary cards in hand: [25.  0.  3. 10. 29.] 
adversary cards in discard: [ 8. 25.  3.  1.  8. 29.  3. 25.  3. 25.  0. 29.  0. 10. 25. 25. 29.  3.
 29. 29. 29.  0.  3.  0.  0. 15. 29. 11.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15] -> size -> 36 
adversary victory points: 8
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 3. 0.] 
cards in discard: [11. 10.  1.  0.  6.  0.  3.  6. 14.  3.  6.  1. 10.  6.  6.  0.  0.  0.
 11. 11. 16.  0.  2.  0.  0.  6. 29.  6.  6.  6. 22.  1.  0.  3. 23.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 25. 29. 21. 30.  8.  0.  9.  5.  6.  4.  1.  9.  9.  6.  9.  9.] 
adversary cards in hand: [25.  0.  3. 10. 29.] 
adversary cards in discard: [ 8. 25.  3.  1.  8. 29.  3. 25.  3. 25.  0. 29.  0. 10. 25. 25. 29.  3.
 29. 29. 29.  0.  3.  0.  0. 15. 29. 11.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15] -> size -> 36 
adversary victory points: 8
player victory points: -4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [25.  0.  3. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 29.] 
expected returns: [[ 88.42467]
 [101.23749]
 [ 88.82272]
 [ 99.21161]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  3. 10. 29.] 
cards in discard: [ 8. 25.  3.  1.  8. 29.  3. 25.  3. 25.  0. 29.  0. 10. 25. 25. 29.  3.
 29. 29. 29.  0.  3.  0.  0. 15. 29. 11.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 29. 21. 30.  8.  0.  9.  5.  6.  4.  1.  9.  9.  6.  9.  9.] 
adversary cards in hand: [6. 0. 8. 0. 3.] 
adversary cards in discard: [11. 10.  1.  0.  6.  0.  3.  6. 14.  3.  6.  1. 10.  6.  6.  0.  0.  0.
 11. 11. 16.  0.  2.  0.  0.  6. 29.  6.  6.  6. 22.  1.  0.  3. 23.  1.
  3.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22] -> size -> 46 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 140.9635467529297



action possibilites: [-1] 
expected returns: [[30.15525]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10. 29. 29. 29.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 29. 21. 30.  8.  0.  9.  5.  6.  4.  1.  9.  9.  6.  9.  9.] 
adversary cards in hand: [6. 0. 8. 0. 3.] 
adversary cards in discard: [11. 10.  1.  0.  6.  0.  3.  6. 14.  3.  6.  1. 10.  6.  6.  0.  0.  0.
 11. 11. 16.  0.  2.  0.  0.  6. 29.  6.  6.  6. 22.  1.  0.  3. 23.  1.
  3.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22] -> size -> 46 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 101.23747253417969





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[27.518936]
 [29.960423]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10. 29. 29. 29.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 25. 29. 21. 30.  8.  0.  9.  5.  6.  4.  1.  9.  9.  6.  9.  9.] 
adversary cards in hand: [6. 0. 8. 0. 3.] 
adversary cards in discard: [11. 10.  1.  0.  6.  0.  3.  6. 14.  3.  6.  1. 10.  6.  6.  0.  0.  0.
 11. 11. 16.  0.  2.  0.  0.  6. 29.  6.  6.  6. 22.  1.  0.  3. 23.  1.
  3.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22] -> size -> 46 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action -1
Learning step: 0
desired expected reward: 30.155250549316406






Player: 1 
cards in hand: [6. 0. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 0. 3.] 
cards in discard: [11. 10.  1.  0.  6.  0.  3.  6. 14.  3.  6.  1. 10.  6.  6.  0.  0.  0.
 11. 11. 16.  0.  2.  0.  0.  6. 29.  6.  6.  6. 22.  1.  0.  3. 23.  1.
  3.  0.  8.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 29. 21. 30.  8.  0.  9.  5.  6.  4.  1.  9.  9.  6.  9.  9.] 
adversary cards in hand: [29. 11.  3.  3. 25.] 
adversary cards in discard: [25.  0.  3. 10. 29. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15] -> size -> 36 
adversary victory points: 8
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 0. 3.] 
cards in discard: [11. 10.  1.  0.  6.  0.  3.  6. 14.  3.  6.  1. 10.  6.  6.  0.  0.  0.
 11. 11. 16.  0.  2.  0.  0.  6. 29.  6.  6.  6. 22.  1.  0.  3. 23.  1.
  3.  0.  8.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 25. 29. 21. 30.  8.  0.  9.  5.  6.  4.  1.  9.  9.  6.  9.  9.] 
adversary cards in hand: [29. 11.  3.  3. 25.] 
adversary cards in discard: [25.  0.  3. 10. 29. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15] -> size -> 36 
adversary victory points: 8
player victory points: -4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [29. 11.  3.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 25.] 
expected returns: [[24.876945]
 [36.909706]
 [31.627186]
 [40.97637 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  3.  3. 25.] 
cards in discard: [25.  0.  3. 10. 29. 29. 29.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 29. 21. 30.  8.  0.  9.  5.  6.  4.  1.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 0. 22.  6.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22] -> size -> 46 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 29.960418701171875



action possibilites: [-1] 
expected returns: [[49.32608]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  3.  3.  3.  3.] 
cards in discard: [25.  0.  3. 10. 29. 29. 29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 29. 21. 30.  8.  0.  9.  5.  6.  4.  1.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 0. 22.  6.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22] -> size -> 46 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 40.97637939453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[45.30707]
 [50.09221]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11.  3.  3.  3.  3.] 
cards in discard: [25.  0.  3. 10. 29. 29. 29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 25. 29. 21. 30.  8.  0.  9.  5.  6.  4.  1.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 0. 22.  6.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22] -> size -> 46 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action -1
Learning step: 0
desired expected reward: 49.326080322265625






Player: 1 
cards in hand: [ 0. 22.  6.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22.  6.  6.  3.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 29. 21. 30.  8.  0.  9.  5.  6.  4.  1.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 1. 25.  0. 29.  8.] 
adversary cards in discard: [25.  0.  3. 10. 29. 29. 29. 25. 29. 11.  3.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15] -> size -> 36 
adversary victory points: 8
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 22.  6.  6.  3.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22] -> size -> 46 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 25. 29. 21. 30.  8.  0.  9.  5.  6.  4.  1.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 1. 25.  0. 29.  8.] 
adversary cards in discard: [25.  0.  3. 10. 29. 29. 29. 25. 29. 11.  3.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15] -> size -> 36 
adversary victory points: 8
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 22.  6.  6.  3.] 
cards in discard: [0.] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0] -> size -> 47 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 25. 29. 21. 30.  8.  0.  9.  5.  6.  4.  1.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 1. 25.  0. 29.  8.] 
adversary cards in discard: [25.  0.  3. 10. 29. 29. 29. 25. 29. 11.  3.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15] -> size -> 36 
adversary victory points: 8
player victory points: -4 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 1. 25.  0. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.  8.] 
expected returns: [[56.589924]
 [73.03476 ]
 [68.68941 ]
 [56.74923 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25.  0. 29.  8.] 
cards in discard: [25.  0.  3. 10. 29. 29. 29. 25. 29. 11.  3.  3.  3.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 29. 21. 30.  8.  0.  9.  5.  6.  4.  1.  9.  9.  6.  9.  9.] 
adversary cards in hand: [16.  6.  1.  0. 11.] 
adversary cards in discard: [ 0.  0. 22.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0] -> size -> 47 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 50.09221649169922



action possibilites: [-1] 
expected returns: [[143.95386]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 29.  8. 29.  0.] 
cards in discard: [25.  0.  3. 10. 29. 29. 29. 25. 29. 11.  3.  3.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 29. 21. 30.  8.  0.  9.  5.  6.  4.  1.  9.  9.  6.  9.  9.] 
adversary cards in hand: [16.  6.  1.  0. 11.] 
adversary cards in discard: [ 0.  0. 22.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0] -> size -> 47 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 73.03474426269531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[139.66298]
 [153.02327]
 [145.78387]
 [153.76608]
 [150.43712]
 [144.03877]
 [156.00487]
 [117.99941]
 [145.93965]
 [138.07376]
 [144.45883]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 29.  8. 29.  0.] 
cards in discard: [25.  0.  3. 10. 29. 29. 29. 25. 29. 11.  3.  3.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 25. 29. 21. 30.  8.  0.  9.  5.  6.  4.  1.  9.  9.  6.  9.  9.] 
adversary cards in hand: [16.  6.  1.  0. 11.] 
adversary cards in discard: [ 0.  0. 22.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0] -> size -> 47 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action -1
Learning step: 0
desired expected reward: 143.953857421875



buy possibilites: [-1] 
expected returns: [[120.67307]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 29.  8. 29.  0.] 
cards in discard: [25.  0.  3. 10. 29. 29. 29. 25. 29. 11.  3.  3.  3.  3. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 29. 21. 30.  8.  0.  9.  5.  6.  4.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [16.  6.  1.  0. 11.] 
adversary cards in discard: [ 0.  0. 22.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0] -> size -> 47 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0 -20   0   0 128   0] 
sum of rewards: 483 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 156.00486755371094






Player: 1 
cards in hand: [16.  6.  1.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6.  1.  0. 11.] 
cards in discard: [ 0.  0. 22.  6.  6.  3.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 29. 21. 30.  8.  0.  9.  5.  6.  4.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [25. 25. 10.  0. 25.] 
adversary cards in discard: [25.  0.  3. 10. 29. 29. 29. 25. 29. 11.  3.  3.  3.  3. 29. 25.  1.  0.
 29.  8. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29] -> size -> 37 
adversary victory points: 8
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6.  1.  0.] 
cards in discard: [ 0.  0. 22.  6.  6.  3.  0.] 
cards in deck: 36 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 21. 30.  8.  0.  9.  5.  6.  4.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [25. 25. 10.  0. 25.] 
adversary cards in discard: [25.  0.  3. 10. 29. 29. 29. 25. 29. 11.  3.  3.  3.  3. 29. 25.  1.  0.
 29.  8. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29] -> size -> 37 
adversary victory points: 8
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6.  1.  0.] 
cards in discard: [ 0.  0. 22.  6.  6.  3.  0.] 
cards in deck: 36 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0] -> size -> 48 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 25. 29. 21. 30.  8.  0.  9.  5.  6.  4.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [25. 25. 10.  0. 25.] 
adversary cards in discard: [25.  0.  3. 10. 29. 29. 29. 25. 29. 11.  3.  3.  3.  3. 29. 25.  1.  0.
 29.  8. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29] -> size -> 37 
adversary victory points: 8
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6.  1.  0.] 
cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3.] 
cards in deck: 36 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3] -> size -> 49 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 25. 29. 20. 30.  8.  0.  9.  5.  6.  4.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [25. 25. 10.  0. 25.] 
adversary cards in discard: [25.  0.  3. 10. 29. 29. 29. 25. 29. 11.  3.  3.  3.  3. 29. 25.  1.  0.
 29.  8. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29] -> size -> 37 
adversary victory points: 8
player victory points: -3 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [25. 25. 10.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 10. 25.] 
expected returns: [[111.384575]
 [125.479675]
 [125.479675]
 [110.5354  ]
 [125.479675]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25. 10.  0. 25.] 
cards in discard: [25.  0.  3. 10. 29. 29. 29. 25. 29. 11.  3.  3.  3.  3. 29. 25.  1.  0.
 29.  8. 29.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 20. 30.  8.  0.  9.  5.  6.  4.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3. 11. 16.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3] -> size -> 49 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 120.6730728149414



action possibilites: [-1] 
expected returns: [[101.84803]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10.  0. 25.  3. 29.] 
cards in discard: [25.  0.  3. 10. 29. 29. 29. 25. 29. 11.  3.  3.  3.  3. 29. 25.  1.  0.
 29.  8. 29.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 20. 30.  8.  0.  9.  5.  6.  4.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3. 11. 16.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3] -> size -> 49 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 125.47969055175781





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 93.83244]
 [102.7009 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 10.  0. 25.  3. 29.] 
cards in discard: [25.  0.  3. 10. 29. 29. 29. 25. 29. 11.  3.  3.  3.  3. 29. 25.  1.  0.
 29.  8. 29.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 25. 29. 20. 30.  8.  0.  9.  5.  6.  4.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3. 11. 16.  6.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3] -> size -> 49 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: 101.84803009033203






Player: 1 
cards in hand: [3. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3. 11. 16.  6.  1.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 20. 30.  8.  0.  9.  5.  6.  4.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 3.  3. 15. 29.  8.] 
adversary cards in discard: [25.  0.  3. 10. 29. 29. 29. 25. 29. 11.  3.  3.  3.  3. 29. 25.  1.  0.
 29.  8. 29.  0. 25. 25. 10.  0. 25.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29] -> size -> 37 
adversary victory points: 8
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3. 11. 16.  6.  1.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3] -> size -> 49 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 25. 29. 20. 30.  8.  0.  9.  5.  6.  4.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 3.  3. 15. 29.  8.] 
adversary cards in discard: [25.  0.  3. 10. 29. 29. 29. 25. 29. 11.  3.  3.  3.  3. 29. 25.  1.  0.
 29.  8. 29.  0. 25. 25. 10.  0. 25.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29] -> size -> 37 
adversary victory points: 8
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3. 11. 16.  6.  1.  0.  8.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3  8] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 20. 30.  8.  0.  9.  5.  5.  4.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 3.  3. 15. 29.  8.] 
adversary cards in discard: [25.  0.  3. 10. 29. 29. 29. 25. 29. 11.  3.  3.  3.  3. 29. 25.  1.  0.
 29.  8. 29.  0. 25. 25. 10.  0. 25.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29] -> size -> 37 
adversary victory points: 8
player victory points: -3 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 3.  3. 15. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.  8.] 
expected returns: [[76.4143 ]
 [71.56325]
 [87.89171]
 [72.19439]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 15. 29.  8.] 
cards in discard: [25.  0.  3. 10. 29. 29. 29. 25. 29. 11.  3.  3.  3.  3. 29. 25.  1.  0.
 29.  8. 29.  0. 25. 25. 10.  0. 25.  3. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 20. 30.  8.  0.  9.  5.  5.  4.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [6. 0. 3. 0. 1.] 
adversary cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3. 11. 16.  6.  1.  0.  8.  3.  3.  0.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3  8] -> size -> 50 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 102.70091247558594



action possibilites: [-1. 15.  8.] 
expected returns: [[88.57703]
 [83.37999]
 [87.03651]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  0.] 
cards in discard: [25.  0.  3. 10. 29. 29. 29. 25. 29. 11.  3.  3.  3.  3. 29. 25.  1.  0.
 29.  8. 29.  0. 25. 25. 10.  0. 25.  3. 29.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 25. 29. 20. 30.  8.  0.  9.  5.  5.  4.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [6. 0. 3. 0. 1.] 
adversary cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3. 11. 16.  6.  1.  0.  8.  3.  3.  0.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3  8] -> size -> 50 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: discard_n_cards - action 5
Learning step: 0
desired expected reward: 83.35831451416016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[81.68581]
 [88.44833]
 [86.96503]
 [88.51075]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8.  0.] 
cards in discard: [25.  0.  3. 10. 29. 29. 29. 25. 29. 11.  3.  3.  3.  3. 29. 25.  1.  0.
 29.  8. 29.  0. 25. 25. 10.  0. 25.  3. 29.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 25. 29. 20. 30.  8.  0.  9.  5.  5.  4.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [6. 0. 3. 0. 1.] 
adversary cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3. 11. 16.  6.  1.  0.  8.  3.  3.  0.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3  8] -> size -> 50 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 88.5770492553711






Player: 1 
cards in hand: [6. 0. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0. 1.] 
cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3. 11. 16.  6.  1.  0.  8.  3.  3.  0.  0.
  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3  8] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 29. 20. 30.  8.  0.  9.  5.  5.  4.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 0.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29] -> size -> 37 
adversary victory points: 8
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 1.] 
cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3. 11. 16.  6.  1.  0.  8.  3.  3.  0.  0.
  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3  8] -> size -> 50 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 25. 29. 20. 30.  8.  0.  9.  5.  5.  4.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 0.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29] -> size -> 37 
adversary victory points: 8
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 1.] 
cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3. 11. 16.  6.  1.  0.  8.  3.  3.  0.  0.
  3.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3  8  1] -> size -> 51 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 24. 29. 20. 30.  8.  0.  9.  5.  5.  4.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [ 0.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29] -> size -> 37 
adversary victory points: 8
player victory points: -3 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[44.35205 ]
 [58.894806]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 24. 29. 20. 30.  8.  0.  9.  5.  5.  4.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [10.  1.  0.  6.  6.] 
adversary cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3. 11. 16.  6.  1.  0.  8.  3.  3.  0.  0.
  3.  1.  6.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3  8  1] -> size -> 51 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 88.51073455810547



action possibilites: [-1.] 
expected returns: [[39.200085]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [3. 0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 24. 29. 20. 30.  8.  0.  9.  5.  5.  4.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [10.  1.  0.  6.  6.] 
adversary cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3. 11. 16.  6.  1.  0.  8.  3.  3.  0.  0.
  3.  1.  6.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3  8  1] -> size -> 51 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 53.6509895324707





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[34.71402 ]
 [48.54705 ]
 [40.987305]
 [50.721523]
 [47.302097]
 [40.292183]
 [11.861531]
 [42.603195]
 [32.75649 ]
 [38.88153 ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [3. 0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 24. 29. 20. 30.  8.  0.  9.  5.  5.  4.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [10.  1.  0.  6.  6.] 
adversary cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3. 11. 16.  6.  1.  0.  8.  3.  3.  0.  0.
  3.  1.  6.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3  8  1] -> size -> 51 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 39.2000846862793



buy possibilites: [-1] 
expected returns: [[7.4746885]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3.  0. 16.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 24. 29. 20. 30.  8.  0.  8.  5.  5.  4.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [10.  1.  0.  6.  6.] 
adversary cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3. 11. 16.  6.  1.  0.  8.  3.  3.  0.  0.
  3.  1.  6.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3  8  1] -> size -> 51 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0 -30   0   0 128   0] 
sum of rewards: 443 

action type: buy - action 16.0
Learning step: 0
desired expected reward: 50.72153091430664






Player: 1 
cards in hand: [10.  1.  0.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  0.  6.  6.] 
cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3. 11. 16.  6.  1.  0.  8.  3.  3.  0.  0.
  3.  1.  6.  0.  3.  0.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3  8  1] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 24. 29. 20. 30.  8.  0.  8.  5.  5.  4.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [25. 25. 15. 25. 29.] 
adversary cards in discard: [ 3.  0. 16. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16] -> size -> 38 
adversary victory points: 8
player victory points: -3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 6. 6. 0.] 
cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3. 11. 16.  6.  1.  0.  8.  3.  3.  0.  0.
  3.  1.  6.  0.  3.  0.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3  8  1] -> size -> 51 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 24. 29. 20. 30.  8.  0.  8.  5.  5.  4.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [25. 25. 15. 25. 29.] 
adversary cards in discard: [ 3.  0. 16. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16] -> size -> 38 
adversary victory points: 8
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6. 6. 0.] 
cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3. 11. 16.  6.  1.  0.  8.  3.  3.  0.  0.
  3.  1.  6.  0.  3.  0.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3  8  1] -> size -> 51 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 24. 29. 20. 30.  8.  0.  8.  5.  5.  4.  0.  9.  9.  6.  9.  9.] 
adversary cards in hand: [25. 25. 15. 25. 29.] 
adversary cards in discard: [ 3.  0. 16. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16] -> size -> 38 
adversary victory points: 8
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6. 6. 0.] 
cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3. 11. 16.  6.  1.  0.  8.  3.  3.  0.  0.
  3.  1.  6.  0.  3.  0.  1. 14.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3  8  1 14] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 24. 29. 20. 30.  8.  0.  8.  5.  5.  4.  0.  8.  9.  6.  9.  9.] 
adversary cards in hand: [25. 25. 15. 25. 29.] 
adversary cards in discard: [ 3.  0. 16. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16] -> size -> 38 
adversary victory points: 8
player victory points: -3 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [25. 25. 15. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 15. 25. 29.] 
expected returns: [[61.40577]
 [79.62249]
 [79.62249]
 [52.62724]
 [79.62249]
 [73.60095]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25. 15. 25. 29.] 
cards in discard: [ 3.  0. 16. 29.  0.  0.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 24. 29. 20. 30.  8.  0.  8.  5.  5.  4.  0.  8.  9.  6.  9.  9.] 
adversary cards in hand: [ 8. 10.  8.  6. 23.] 
adversary cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3. 11. 16.  6.  1.  0.  8.  3.  3.  0.  0.
  3.  1.  6.  0.  3.  0.  1. 14. 10.  1.  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3  8  1 14] -> size -> 52 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 7.474688529968262



action possibilites: [-1] 
expected returns: [[82.63005]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 15. 25. 29.  1.  3.] 
cards in discard: [ 3.  0. 16. 29.  0.  0.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 24. 29. 20. 30.  8.  0.  8.  5.  5.  4.  0.  8.  9.  6.  9.  9.] 
adversary cards in hand: [ 8. 10.  8.  6. 23.] 
adversary cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3. 11. 16.  6.  1.  0.  8.  3.  3.  0.  0.
  3.  1.  6.  0.  3.  0.  1. 14. 10.  1.  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3  8  1 14] -> size -> 52 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 79.62249755859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[77.76668]
 [85.27406]
 [83.14377]
 [84.22213]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 15. 25. 29.  1.  3.] 
cards in discard: [ 3.  0. 16. 29.  0.  0.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 24. 29. 20. 30.  8.  0.  8.  5.  5.  4.  0.  8.  9.  6.  9.  9.] 
adversary cards in hand: [ 8. 10.  8.  6. 23.] 
adversary cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3. 11. 16.  6.  1.  0.  8.  3.  3.  0.  0.
  3.  1.  6.  0.  3.  0.  1. 14. 10.  1.  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3  8  1 14] -> size -> 52 
adversary victory points: -3
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: 82.63005065917969



buy possibilites: [-1] 
expected returns: [[65.239685]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 15. 25. 29.  1.  3.] 
cards in discard: [ 3.  0. 16. 29.  0.  0.  0.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 24. 29. 19. 30.  8.  0.  8.  5.  5.  4.  0.  8.  9.  6.  9.  9.] 
adversary cards in hand: [ 8. 10.  8.  6. 23.] 
adversary cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3. 11. 16.  6.  1.  0.  8.  3.  3.  0.  0.
  3.  1.  6.  0.  3.  0.  1. 14. 10.  1.  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3  8  1 14] -> size -> 52 
adversary victory points: -3
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0 -40   0   0  16   0] 
sum of rewards: 351 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 85.27407836914062






Player: 1 
cards in hand: [ 8. 10.  8.  6. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  8.  6. 23.] 
cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3. 11. 16.  6.  1.  0.  8.  3.  3.  0.  0.
  3.  1.  6.  0.  3.  0.  1. 14. 10.  1.  0.  6.  6.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3  8  1 14] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 24. 29. 19. 30.  8.  0.  8.  5.  5.  4.  0.  8.  9.  6.  9.  9.] 
adversary cards in hand: [ 8. 29. 29. 25.  3.] 
adversary cards in discard: [ 3.  0. 16. 29.  0.  0.  0.  3. 25. 25. 15. 25. 29.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3] -> size -> 39 
adversary victory points: 9
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  8.  6. 23.] 
cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3. 11. 16.  6.  1.  0.  8.  3.  3.  0.  0.
  3.  1.  6.  0.  3.  0.  1. 14. 10.  1.  0.  6.  6.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3  8  1 14] -> size -> 52 
action values: 1 
buys: 1 
player value: 0 
card supply: [21. 24. 29. 19. 30.  8.  0.  8.  5.  5.  4.  0.  8.  9.  6.  9.  9.] 
adversary cards in hand: [ 8. 29. 29. 25.  3.] 
adversary cards in discard: [ 3.  0. 16. 29.  0.  0.  0.  3. 25. 25. 15. 25. 29.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3] -> size -> 39 
adversary victory points: 9
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  8.  6. 23.] 
cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3. 11. 16.  6.  1.  0.  8.  3.  3.  0.  0.
  3.  1.  6.  0.  3.  0.  1. 14. 10.  1.  0.  6.  6.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3  8  1 14  0] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 29. 19. 30.  8.  0.  8.  5.  5.  4.  0.  8.  9.  6.  9.  9.] 
adversary cards in hand: [ 8. 29. 29. 25.  3.] 
adversary cards in discard: [ 3.  0. 16. 29.  0.  0.  0.  3. 25. 25. 15. 25. 29.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3] -> size -> 39 
adversary victory points: 9
player victory points: -3 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 8. 29. 29. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 29. 25.] 
expected returns: [[105.62579 ]
 [ 95.897606]
 [119.49524 ]
 [119.49524 ]
 [119.920685]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29. 29. 25.  3.] 
cards in discard: [ 3.  0. 16. 29.  0.  0.  0.  3. 25. 25. 15. 25. 29.  1.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 29. 19. 30.  8.  0.  8.  5.  5.  4.  0.  8.  9.  6.  9.  9.] 
adversary cards in hand: [ 0.  2. 14.  3. 11.] 
adversary cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3. 11. 16.  6.  1.  0.  8.  3.  3.  0.  0.
  3.  1.  6.  0.  3.  0.  1. 14. 10.  1.  0.  6.  6.  0.  0.  8. 10.  8.
  6. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3  8  1 14  0] -> size -> 53 
adversary victory points: -3
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1
Learning step: 0
desired expected reward: 65.23968505859375



action possibilites: [-1] 
expected returns: [[108.29651]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29. 29.  3. 10. 10.] 
cards in discard: [ 3.  0. 16. 29.  0.  0.  0.  3. 25. 25. 15. 25. 29.  1.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 24. 29. 19. 30.  8.  0.  8.  5.  5.  4.  0.  8.  9.  6.  9.  9.] 
adversary cards in hand: [ 0.  2. 14.  3. 11.] 
adversary cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3. 11. 16.  6.  1.  0.  8.  3.  3.  0.  0.
  3.  1.  6.  0.  3.  0.  1. 14. 10.  1.  0.  6.  6.  0.  0.  8. 10.  8.
  6. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3  8  1 14  0] -> size -> 53 
adversary victory points: -3
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 119.92066955566406





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 99.75972 ]
 [108.720436]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29. 29.  3. 10. 10.] 
cards in discard: [ 3.  0. 16. 29.  0.  0.  0.  3. 25. 25. 15. 25. 29.  1.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 24. 29. 19. 30.  8.  0.  8.  5.  5.  4.  0.  8.  9.  6.  9.  9.] 
adversary cards in hand: [ 0.  2. 14.  3. 11.] 
adversary cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3. 11. 16.  6.  1.  0.  8.  3.  3.  0.  0.
  3.  1.  6.  0.  3.  0.  1. 14. 10.  1.  0.  6.  6.  0.  0.  8. 10.  8.
  6. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3  8  1 14  0] -> size -> 53 
adversary victory points: -3
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action -1
Learning step: 0
desired expected reward: 108.2965087890625






Player: 1 
cards in hand: [ 0.  2. 14.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  2. 14.  3. 11.] 
cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3. 11. 16.  6.  1.  0.  8.  3.  3.  0.  0.
  3.  1.  6.  0.  3.  0.  1. 14. 10.  1.  0.  6.  6.  0.  0.  8. 10.  8.
  6. 23.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3  8  1 14  0] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 29. 19. 30.  8.  0.  8.  5.  5.  4.  0.  8.  9.  6.  9.  9.] 
adversary cards in hand: [ 3.  3.  3.  3. 29.] 
adversary cards in discard: [ 3.  0. 16. 29.  0.  0.  0.  3. 25. 25. 15. 25. 29.  1.  3. 25.  8. 29.
 29.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3] -> size -> 39 
adversary victory points: 9
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  2. 14.  3.] 
cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3. 11. 16.  6.  1.  0.  8.  3.  3.  0.  0.
  3.  1.  6.  0.  3.  0.  1. 14. 10.  1.  0.  6.  6.  0.  0.  8. 10.  8.
  6. 23.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3  8  1 14  0  3] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 24. 29. 18. 30.  8.  0.  8.  5.  5.  4.  0.  8.  9.  6.  9.  9.] 
adversary cards in hand: [ 3.  3.  3.  3. 29.] 
adversary cards in discard: [ 3.  0. 16. 29.  0.  0.  0.  3. 25. 25. 15. 25. 29.  1.  3. 25.  8. 29.
 29.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3] -> size -> 39 
adversary victory points: 9
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  2. 14.  3.] 
cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3. 11. 16.  6.  1.  0.  8.  3.  3.  0.  0.
  3.  1.  6.  0.  3.  0.  1. 14. 10.  1.  0.  6.  6.  0.  0.  8. 10.  8.
  6. 23.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3  8  1 14  0  3] -> size -> 54 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 24. 29. 18. 30.  8.  0.  8.  5.  5.  4.  0.  8.  9.  6.  9.  9.] 
adversary cards in hand: [ 3.  3.  3.  3. 29.] 
adversary cards in discard: [ 3.  0. 16. 29.  0.  0.  0.  3. 25. 25. 15. 25. 29.  1.  3. 25.  8. 29.
 29.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3] -> size -> 39 
adversary victory points: 9
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  2. 14.  3.] 
cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3. 11. 16.  6.  1.  0.  8.  3.  3.  0.  0.
  3.  1.  6.  0.  3.  0.  1. 14. 10.  1.  0.  6.  6.  0.  0.  8. 10.  8.
  6. 23.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3  8  1 14  0  3  3] -> size -> 55 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 24. 29. 17. 30.  8.  0.  8.  5.  5.  4.  0.  8.  9.  6.  9.  9.] 
adversary cards in hand: [ 3.  3.  3.  3. 29.] 
adversary cards in discard: [ 3.  0. 16. 29.  0.  0.  0.  3. 25. 25. 15. 25. 29.  1.  3. 25.  8. 29.
 29.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3] -> size -> 39 
adversary victory points: 9
player victory points: -1 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  3.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[127.261536]
 [138.49933 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3.  3. 29.] 
cards in discard: [ 3.  0. 16. 29.  0.  0.  0.  3. 25. 25. 15. 25. 29.  1.  3. 25.  8. 29.
 29.  3. 10. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 29. 17. 30.  8.  0.  8.  5.  5.  4.  0.  8.  9.  6.  9.  9.] 
adversary cards in hand: [29. 11.  0.  0.  1.] 
adversary cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3. 11. 16.  6.  1.  0.  8.  3.  3.  0.  0.
  3.  1.  6.  0.  3.  0.  1. 14. 10.  1.  0.  6.  6.  0.  0.  8. 10.  8.
  6. 23.  3.  3. 11.  0.  2. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3  8  1 14  0  3  3] -> size -> 55 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 108.72044372558594



action possibilites: [-1.] 
expected returns: [[158.314]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3.] 
cards in discard: [ 3.  0. 16. 29.  0.  0.  0.  3. 25. 25. 15. 25. 29.  1.  3. 25.  8. 29.
 29.  3. 10. 10.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 24. 29. 17. 30.  8.  0.  8.  5.  5.  4.  0.  8.  9.  6.  9.  9.] 
adversary cards in hand: [29. 11.  0.  0.  1.] 
adversary cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3. 11. 16.  6.  1.  0.  8.  3.  3.  0.  0.
  3.  1.  6.  0.  3.  0.  1. 14. 10.  1.  0.  6.  6.  0.  0.  8. 10.  8.
  6. 23.  3.  3. 11.  0.  2. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3  8  1 14  0  3  3] -> size -> 55 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 133.60934448242188





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[152.09915]
 [158.76352]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3.] 
cards in discard: [ 3.  0. 16. 29.  0.  0.  0.  3. 25. 25. 15. 25. 29.  1.  3. 25.  8. 29.
 29.  3. 10. 10.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3] -> size -> 39 
action values: 1 
buys: 1 
player value: 1 
card supply: [20. 24. 29. 17. 30.  8.  0.  8.  5.  5.  4.  0.  8.  9.  6.  9.  9.] 
adversary cards in hand: [29. 11.  0.  0.  1.] 
adversary cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3. 11. 16.  6.  1.  0.  8.  3.  3.  0.  0.
  3.  1.  6.  0.  3.  0.  1. 14. 10.  1.  0.  6.  6.  0.  0.  8. 10.  8.
  6. 23.  3.  3. 11.  0.  2. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3  8  1 14  0  3  3] -> size -> 55 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 158.31399536132812






Player: 1 
cards in hand: [29. 11.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  0.  0.  1.] 
cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3. 11. 16.  6.  1.  0.  8.  3.  3.  0.  0.
  3.  1.  6.  0.  3.  0.  1. 14. 10.  1.  0.  6.  6.  0.  0.  8. 10.  8.
  6. 23.  3.  3. 11.  0.  2. 14.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3  8  1 14  0  3  3] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 29. 17. 30.  8.  0.  8.  5.  5.  4.  0.  8.  9.  6.  9.  9.] 
adversary cards in hand: [29. 29.  0. 29. 11.] 
adversary cards in discard: [ 3.  0. 16. 29.  0.  0.  0.  3. 25. 25. 15. 25. 29.  1.  3. 25.  8. 29.
 29.  3. 10. 10.  3.  0. 29.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3] -> size -> 39 
adversary victory points: 9
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11.  0.  0.  1.] 
cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3. 11. 16.  6.  1.  0.  8.  3.  3.  0.  0.
  3.  1.  6.  0.  3.  0.  1. 14. 10.  1.  0.  6.  6.  0.  0.  8. 10.  8.
  6. 23.  3.  3. 11.  0.  2. 14.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3  8  1 14  0  3  3] -> size -> 55 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 24. 29. 17. 30.  8.  0.  8.  5.  5.  4.  0.  8.  9.  6.  9.  9.] 
adversary cards in hand: [29. 29.  0. 29. 11.] 
adversary cards in discard: [ 3.  0. 16. 29.  0.  0.  0.  3. 25. 25. 15. 25. 29.  1.  3. 25.  8. 29.
 29.  3. 10. 10.  3.  0. 29.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3] -> size -> 39 
adversary victory points: 9
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [29. 29.  0. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29. 11.] 
expected returns: [[81.7848  ]
 [93.627045]
 [93.627045]
 [93.627045]
 [87.85435 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0. 29. 11.] 
cards in discard: [ 3.  0. 16. 29.  0.  0.  0.  3. 25. 25. 15. 25. 29.  1.  3. 25.  8. 29.
 29.  3. 10. 10.  3.  0. 29.  3.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 29. 17. 30.  8.  0.  8.  5.  5.  4.  0.  8.  9.  6.  9.  9.] 
adversary cards in hand: [6. 6. 0. 0. 6.] 
adversary cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3. 11. 16.  6.  1.  0.  8.  3.  3.  0.  0.
  3.  1.  6.  0.  3.  0.  1. 14. 10.  1.  0.  6.  6.  0.  0.  8. 10.  8.
  6. 23.  3.  3. 11.  0.  2. 14.  3. 29. 11.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3  8  1 14  0  3  3] -> size -> 55 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 158.7635498046875



action possibilites: [-1. 29. 29.] 
expected returns: [[151.53781]
 [165.27988]
 [165.27988]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29.] 
cards in discard: [ 3.  0. 16. 29.  0.  0.  0.  3. 25. 25. 15. 25. 29.  1.  3. 25.  8. 29.
 29.  3. 10. 10.  3.  0. 29.  3.  3.  3. 11. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 24. 29. 17. 30.  8.  0.  8.  5.  5.  4.  0.  8.  9.  6.  9.  9.] 
adversary cards in hand: [6. 6. 0. 0. 6.] 
adversary cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3. 11. 16.  6.  1.  0.  8.  3.  3.  0.  0.
  3.  1.  6.  0.  3.  0.  1. 14. 10.  1.  0.  6.  6.  0.  0.  8. 10.  8.
  6. 23.  3.  3. 11.  0.  2. 14.  3. 29. 11.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3  8  1 14  0  3  3] -> size -> 55 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: discard_n_cards - action 5
Learning step: 0
desired expected reward: 87.79930114746094



action possibilites: [-1.] 
expected returns: [[131.10147]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 3.  0. 16. 29.  0.  0.  0.  3. 25. 25. 15. 25. 29.  1.  3. 25.  8. 29.
 29.  3. 10. 10.  3.  0. 29.  3.  3.  3. 11. 25. 29.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 2 
card supply: [20. 24. 29. 17. 30.  8.  0.  8.  5.  5.  4.  0.  8.  9.  6.  9.  9.] 
adversary cards in hand: [6. 6. 0. 0. 6.] 
adversary cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3. 11. 16.  6.  1.  0.  8.  3.  3.  0.  0.
  3.  1.  6.  0.  3.  0.  1. 14. 10.  1.  0.  6.  6.  0.  0.  8. 10.  8.
  6. 23.  3.  3. 11.  0.  2. 14.  3. 29. 11.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3  8  1 14  0  3  3] -> size -> 55 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 158.45599365234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[115.24786]
 [131.99039]
 [124.47908]
 [139.34895]
 [127.64317]
 [133.56561]
 [131.10146]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3.  0. 16. 29.  0.  0.  0.  3. 25. 25. 15. 25. 29.  1.  3. 25.  8. 29.
 29.  3. 10. 10.  3.  0. 29.  3.  3.  3. 11. 25. 29.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 24. 29. 17. 30.  8.  0.  8.  5.  5.  4.  0.  8.  9.  6.  9.  9.] 
adversary cards in hand: [6. 6. 0. 0. 6.] 
adversary cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3. 11. 16.  6.  1.  0.  8.  3.  3.  0.  0.
  3.  1.  6.  0.  3.  0.  1. 14. 10.  1.  0.  6.  6.  0.  0.  8. 10.  8.
  6. 23.  3.  3. 11.  0.  2. 14.  3. 29. 11.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3  8  1 14  0  3  3] -> size -> 55 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 131.10147094726562



buy possibilites: [-1] 
expected returns: [[87.693405]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3.  0. 16. 29.  0.  0.  0.  3. 25. 25. 15. 25. 29.  1.  3. 25.  8. 29.
 29.  3. 10. 10.  3.  0. 29.  3.  3.  3. 11. 25. 29.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3 11] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 24. 29. 17. 30.  8.  0.  8.  4.  5.  4.  0.  8.  9.  6.  9.  9.] 
adversary cards in hand: [6. 6. 0. 0. 6.] 
adversary cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3. 11. 16.  6.  1.  0.  8.  3.  3.  0.  0.
  3.  1.  6.  0.  3.  0.  1. 14. 10.  1.  0.  6.  6.  0.  0.  8. 10.  8.
  6. 23.  3.  3. 11.  0.  2. 14.  3. 29. 11.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3  8  1 14  0  3  3] -> size -> 55 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0 -50   0   0  54   0] 
sum of rewards: 339 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 139.34896850585938






Player: 1 
cards in hand: [6. 6. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 0. 6.] 
cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3. 11. 16.  6.  1.  0.  8.  3.  3.  0.  0.
  3.  1.  6.  0.  3.  0.  1. 14. 10.  1.  0.  6.  6.  0.  0.  8. 10.  8.
  6. 23.  3.  3. 11.  0.  2. 14.  3. 29. 11.  0.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3  8  1 14  0  3  3] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 29. 17. 30.  8.  0.  8.  4.  5.  4.  0.  8.  9.  6.  9.  9.] 
adversary cards in hand: [ 0.  3. 29.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3 11] -> size -> 40 
adversary victory points: 9
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 0. 6.] 
cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3. 11. 16.  6.  1.  0.  8.  3.  3.  0.  0.
  3.  1.  6.  0.  3.  0.  1. 14. 10.  1.  0.  6.  6.  0.  0.  8. 10.  8.
  6. 23.  3.  3. 11.  0.  2. 14.  3. 29. 11.  0.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3  8  1 14  0  3  3] -> size -> 55 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 24. 29. 17. 30.  8.  0.  8.  4.  5.  4.  0.  8.  9.  6.  9.  9.] 
adversary cards in hand: [ 0.  3. 29.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3 11] -> size -> 40 
adversary victory points: 9
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 0. 6.] 
cards in discard: [ 0.  0. 22.  6.  6.  3.  0.  3. 11. 16.  6.  1.  0.  8.  3.  3.  0.  0.
  3.  1.  6.  0.  3.  0.  1. 14. 10.  1.  0.  6.  6.  0.  0.  8. 10.  8.
  6. 23.  3.  3. 11.  0.  2. 14.  3. 29. 11.  0.  0.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3  8  1 14  0  3  3  0] -> size -> 56 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 24. 29. 17. 30.  8.  0.  8.  4.  5.  4.  0.  8.  9.  6.  9.  9.] 
adversary cards in hand: [ 0.  3. 29.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3 11] -> size -> 40 
adversary victory points: 9
player victory points: -1 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 29.  8. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 25.] 
expected returns: [[67.86457 ]
 [81.7263  ]
 [69.89952 ]
 [87.725586]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  8. 25.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3 11] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 17. 30.  8.  0.  8.  4.  5.  4.  0.  8.  9.  6.  9.  9.] 
adversary cards in hand: [2. 0. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3  8  1 14  0  3  3  0] -> size -> 56 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 87.69340515136719



action possibilites: [-1] 
expected returns: [[31.86625]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  8. 11. 15.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3 11] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 17. 30.  8.  0.  8.  4.  5.  4.  0.  8.  9.  6.  9.  9.] 
adversary cards in hand: [2. 0. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3  8  1 14  0  3  3  0] -> size -> 56 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 87.72557830810547





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[25.86602]
 [30.33377]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 29.  8. 11. 15.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3 11] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 24. 29. 17. 30.  8.  0.  8.  4.  5.  4.  0.  8.  9.  6.  9.  9.] 
adversary cards in hand: [2. 0. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3  8  1 14  0  3  3  0] -> size -> 56 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: 31.866249084472656






Player: 1 
cards in hand: [2. 0. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [2. 0. 0. 8. 3.] 
cards in discard: [] 
cards in deck: 51 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6
 29  0  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0
  3  8  1 14  0  3  3  0] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 17. 30.  8.  0.  8.  4.  5.  4.  0.  8.  9.  6.  9.  9.] 
adversary cards in hand: [29. 25. 29. 29.  3.] 
adversary cards in discard: [25.  0.  3. 29.  8. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3 11] -> size -> 40 
adversary victory points: 9
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [2. 0.] 
cards in discard: [] 
cards in deck: 51 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6 29  0
  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0  3  8
  1 14  0  3  3  0] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 17. 30.  8.  0.  8.  4.  5.  4.  0.  8.  9.  6.  9.  9.] 
adversary cards in hand: [29. 25. 29. 29.  3.] 
adversary cards in discard: [25.  0.  3. 29.  8. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3 11] -> size -> 40 
adversary victory points: 9
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 0.] 
cards in discard: [] 
cards in deck: 51 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6 29  0
  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0  3  8
  1 14  0  3  3  0] -> size -> 54 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 24. 29. 17. 30.  8.  0.  8.  4.  5.  4.  0.  8.  9.  6.  9.  9.] 
adversary cards in hand: [29. 25. 29. 29.  3.] 
adversary cards in discard: [25.  0.  3. 29.  8. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3 11] -> size -> 40 
adversary victory points: 9
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 0.] 
cards in discard: [11.] 
cards in deck: 51 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6 29  0
  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0  3  8
  1 14  0  3  3  0 11] -> size -> 55 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 24. 29. 17. 30.  8.  0.  8.  3.  5.  4.  0.  8.  9.  6.  9.  9.] 
adversary cards in hand: [29. 25. 29. 29.  3.] 
adversary cards in discard: [25.  0.  3. 29.  8. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3 11] -> size -> 40 
adversary victory points: 9
player victory points: -2 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [29. 25. 29. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29. 29.] 
expected returns: [[42.48742 ]
 [54.987614]
 [59.547737]
 [54.987614]
 [54.987614]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 29. 29.  3.] 
cards in discard: [25.  0.  3. 29.  8. 11. 15.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3 11] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 17. 30.  8.  0.  8.  3.  5.  4.  0.  8.  9.  6.  9.  9.] 
adversary cards in hand: [3. 0. 0. 3. 1.] 
adversary cards in discard: [11.  8.  2.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6 29  0
  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0  3  8
  1 14  0  3  3  0 11] -> size -> 55 
adversary victory points: -2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 30.333770751953125



action possibilites: [-1] 
expected returns: [[45.25731]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29.  3. 10. 29.] 
cards in discard: [25.  0.  3. 29.  8. 11. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3 11] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 17. 30.  8.  0.  8.  3.  5.  4.  0.  8.  9.  6.  9.  9.] 
adversary cards in hand: [3. 0. 0. 3. 1.] 
adversary cards in discard: [11.  8.  2.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6 29  0
  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0  3  8
  1 14  0  3  3  0 11] -> size -> 55 
adversary victory points: -2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 59.54774475097656





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[41.988075]
 [45.763508]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29. 29.  3. 10. 29.] 
cards in discard: [25.  0.  3. 29.  8. 11. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3 11] -> size -> 40 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 24. 29. 17. 30.  8.  0.  8.  3.  5.  4.  0.  8.  9.  6.  9.  9.] 
adversary cards in hand: [3. 0. 0. 3. 1.] 
adversary cards in discard: [11.  8.  2.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6 29  0
  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0  3  8
  1 14  0  3  3  0 11] -> size -> 55 
adversary victory points: -2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: 45.25730895996094






Player: 1 
cards in hand: [3. 0. 0. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 1.] 
cards in discard: [11.  8.  2.  0.] 
cards in deck: 46 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6 29  0
  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0  3  8
  1 14  0  3  3  0 11] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 17. 30.  8.  0.  8.  3.  5.  4.  0.  8.  9.  6.  9.  9.] 
adversary cards in hand: [29. 10.  0. 25.  8.] 
adversary cards in discard: [25.  0.  3. 29.  8. 11. 15. 25. 29. 29. 29.  3. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3 11] -> size -> 40 
adversary victory points: 9
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 1.] 
cards in discard: [11.  8.  2.  0.] 
cards in deck: 46 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6 29  0
  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0  3  8
  1 14  0  3  3  0 11] -> size -> 55 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 24. 29. 17. 30.  8.  0.  8.  3.  5.  4.  0.  8.  9.  6.  9.  9.] 
adversary cards in hand: [29. 10.  0. 25.  8.] 
adversary cards in discard: [25.  0.  3. 29.  8. 11. 15. 25. 29. 29. 29.  3. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3 11] -> size -> 40 
adversary victory points: 9
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 1.] 
cards in discard: [11.  8.  2.  0. 15.] 
cards in deck: 46 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6 29  0
  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0  3  8
  1 14  0  3  3  0 11 15] -> size -> 56 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 17. 30.  8.  0.  8.  3.  5.  4.  0.  8.  9.  6.  9.  8.] 
adversary cards in hand: [29. 10.  0. 25.  8.] 
adversary cards in discard: [25.  0.  3. 29.  8. 11. 15. 25. 29. 29. 29.  3. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3 11] -> size -> 40 
adversary victory points: 9
player victory points: -2 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [29. 10.  0. 25.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 25.  8.] 
expected returns: [[75.75427]
 [86.58947]
 [76.58201]
 [90.63093]
 [72.23547]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  0. 25.  8.] 
cards in discard: [25.  0.  3. 29.  8. 11. 15. 25. 29. 29. 29.  3. 10. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3 11] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 17. 30.  8.  0.  8.  3.  5.  4.  0.  8.  9.  6.  9.  8.] 
adversary cards in hand: [ 1.  0.  3.  0. 22.] 
adversary cards in discard: [11.  8.  2.  0. 15.  3.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6 29  0
  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0  3  8
  1 14  0  3  3  0 11 15] -> size -> 56 
adversary victory points: -2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 45.76349639892578



action possibilites: [-1] 
expected returns: [[128.00705]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  0.  8.  0.  3.] 
cards in discard: [25.  0.  3. 29.  8. 11. 15. 25. 29. 29. 29.  3. 10. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3 11] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 17. 30.  8.  0.  8.  3.  5.  4.  0.  8.  9.  6.  9.  8.] 
adversary cards in hand: [ 1.  0.  3.  0. 22.] 
adversary cards in discard: [11.  8.  2.  0. 15.  3.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6 29  0
  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0  3  8
  1 14  0  3  3  0 11 15] -> size -> 56 
adversary victory points: -2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 90.63092803955078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[123.70715]
 [130.07278]
 [127.95561]
 [128.77289]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 10.  0.  8.  0.  3.] 
cards in discard: [25.  0.  3. 29.  8. 11. 15. 25. 29. 29. 29.  3. 10. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3 11] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 24. 29. 17. 30.  8.  0.  8.  3.  5.  4.  0.  8.  9.  6.  9.  8.] 
adversary cards in hand: [ 1.  0.  3.  0. 22.] 
adversary cards in discard: [11.  8.  2.  0. 15.  3.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6 29  0
  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0  3  8
  1 14  0  3  3  0 11 15] -> size -> 56 
adversary victory points: -2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: 128.00704956054688



buy possibilites: [-1] 
expected returns: [[127.65172]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 10.  0.  8.  0.  3.] 
cards in discard: [25.  0.  3. 29.  8. 11. 15. 25. 29. 29. 29.  3. 10. 29.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3 11  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 16. 30.  8.  0.  8.  3.  5.  4.  0.  8.  9.  6.  9.  8.] 
adversary cards in hand: [ 1.  0.  3.  0. 22.] 
adversary cards in discard: [11.  8.  2.  0. 15.  3.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6 29  0
  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0  3  8
  1 14  0  3  3  0 11 15] -> size -> 56 
adversary victory points: -2
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0 -60   0   0  16   0] 
sum of rewards: 331 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 130.07278442382812






Player: 1 
cards in hand: [ 1.  0.  3.  0. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3.  0. 22.] 
cards in discard: [11.  8.  2.  0. 15.  3.  0.  0.  3.  1.] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6 29  0
  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0  3  8
  1 14  0  3  3  0 11 15] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 16. 30.  8.  0.  8.  3.  5.  4.  0.  8.  9.  6.  9.  8.] 
adversary cards in hand: [ 1.  0. 29. 11. 29.] 
adversary cards in discard: [25.  0.  3. 29.  8. 11. 15. 25. 29. 29. 29.  3. 10. 29.  3. 25. 29. 10.
  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3 11  3] -> size -> 41 
adversary victory points: 10
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3.  0. 22.] 
cards in discard: [11.  8.  2.  0. 15.  3.  0.  0.  3.  1.] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6 29  0
  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0  3  8
  1 14  0  3  3  0 11 15] -> size -> 56 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 24. 29. 16. 30.  8.  0.  8.  3.  5.  4.  0.  8.  9.  6.  9.  8.] 
adversary cards in hand: [ 1.  0. 29. 11. 29.] 
adversary cards in discard: [25.  0.  3. 29.  8. 11. 15. 25. 29. 29. 29.  3. 10. 29.  3. 25. 29. 10.
  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3 11  3] -> size -> 41 
adversary victory points: 10
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3.  0. 22.] 
cards in discard: [11.  8.  2.  0. 15.  3.  0.  0.  3.  1. 15.] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6 29  0
  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0  3  8
  1 14  0  3  3  0 11 15 15] -> size -> 57 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 16. 30.  8.  0.  8.  3.  5.  4.  0.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 1.  0. 29. 11. 29.] 
adversary cards in discard: [25.  0.  3. 29.  8. 11. 15. 25. 29. 29. 29.  3. 10. 29.  3. 25. 29. 10.
  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3 11  3] -> size -> 41 
adversary victory points: 10
player victory points: -2 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [ 1.  0. 29. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 29.] 
expected returns: [[140.79924]
 [153.0474 ]
 [146.31458]
 [153.0474 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 29. 11. 29.] 
cards in discard: [25.  0.  3. 29.  8. 11. 15. 25. 29. 29. 29.  3. 10. 29.  3. 25. 29. 10.
  0.  8.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3 11  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 16. 30.  8.  0.  8.  3.  5.  4.  0.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 6. 11.  0.  0.  0.] 
adversary cards in discard: [11.  8.  2.  0. 15.  3.  0.  0.  3.  1. 15.  1.  0.  3.  0. 22.] 
adversary owned cards: [ 0  0  0  0  0  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6 29  0
  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0  3  8
  1 14  0  3  3  0 11 15 15] -> size -> 57 
adversary victory points: -2
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1
Learning step: 0
desired expected reward: 127.65171813964844



action possibilites: [-1. 29.] 
expected returns: [[139.66101]
 [151.46315]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  3.] 
cards in discard: [25.  0.  3. 29.  8. 11. 15. 25. 29. 29. 29.  3. 10. 29.  3. 25. 29. 10.
  0.  8.  0.  3.  0. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3 11  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 24. 29. 16. 30.  8.  0.  8.  3.  5.  4.  0.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 6. 11.  0.  0.  0.] 
adversary cards in discard: [11.  8.  2.  0. 15.  3.  0.  0.  3.  1. 15.  1.  0.  3.  0. 22.] 
adversary owned cards: [ 0  0  0  0  0  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6 29  0
  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0  3  8
  1 14  0  3  3  0 11 15 15] -> size -> 57 
adversary victory points: -2
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 149.17388916015625



action possibilites: [-1.] 
expected returns: [[141.5756]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [25.  0.  3. 29.  8. 11. 15. 25. 29. 29. 29.  3. 10. 29.  3. 25. 29. 10.
  0.  8.  0.  3.  0. 11.  1.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3 11  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 2 
card supply: [19. 24. 29. 16. 30.  8.  0.  8.  3.  5.  4.  0.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 6. 11.  0.  0.  0.] 
adversary cards in discard: [11.  8.  2.  0. 15.  3.  0.  0.  3.  1. 15.  1.  0.  3.  0. 22.] 
adversary owned cards: [ 0  0  0  0  0  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6 29  0
  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0  3  8
  1 14  0  3  3  0 11 15 15] -> size -> 57 
adversary victory points: -2
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 360   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 395 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 145.8766632080078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[130.51418]
 [143.37257]
 [136.64885]
 [144.10205]
 [136.81099]
 [139.61018]
 [142.05516]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [25.  0.  3. 29.  8. 11. 15. 25. 29. 29. 29.  3. 10. 29.  3. 25. 29. 10.
  0.  8.  0.  3.  0. 11.  1.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3 11  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 24. 29. 16. 30.  8.  0.  8.  3.  5.  4.  0.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 6. 11.  0.  0.  0.] 
adversary cards in discard: [11.  8.  2.  0. 15.  3.  0.  0.  3.  1. 15.  1.  0.  3.  0. 22.] 
adversary owned cards: [ 0  0  0  0  0  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6 29  0
  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0  3  8
  1 14  0  3  3  0 11 15 15] -> size -> 57 
adversary victory points: -2
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 360   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 395 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 141.5756072998047



buy possibilites: [-1] 
expected returns: [[125.8038]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [25.  0.  3. 29.  8. 11. 15. 25. 29. 29. 29.  3. 10. 29.  3. 25. 29. 10.
  0.  8.  0.  3.  0. 11.  1.  3. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3 11  3 11] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 16. 30.  8.  0.  8.  2.  5.  4.  0.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 6. 11.  0.  0.  0.] 
adversary cards in discard: [11.  8.  2.  0. 15.  3.  0.  0.  3.  1. 15.  1.  0.  3.  0. 22.] 
adversary owned cards: [ 0  0  0  0  0  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6 29  0
  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0  3  8
  1 14  0  3  3  0 11 15 15] -> size -> 57 
adversary victory points: -2
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 360   0   0  40   0   0   0   0 -70   0   0  54   0] 
sum of rewards: 379 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 144.10205078125






Player: 1 
cards in hand: [ 6. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0.  0.  0.] 
cards in discard: [11.  8.  2.  0. 15.  3.  0.  0.  3.  1. 15.  1.  0.  3.  0. 22.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6 29  0
  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0  3  8
  1 14  0  3  3  0 11 15 15] -> size -> 57 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 16. 30.  8.  0.  8.  2.  5.  4.  0.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 3.  3. 25. 16. 25.] 
adversary cards in discard: [25.  0.  3. 29.  8. 11. 15. 25. 29. 29. 29.  3. 10. 29.  3. 25. 29. 10.
  0.  8.  0.  3.  0. 11.  1.  3. 11. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3 11  3 11] -> size -> 42 
adversary victory points: 10
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  0.  0.  0.] 
cards in discard: [11.  8.  2.  0. 15.  3.  0.  0.  3.  1. 15.  1.  0.  3.  0. 22.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6 29  0
  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0  3  8
  1 14  0  3  3  0 11 15 15] -> size -> 57 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 24. 29. 16. 30.  8.  0.  8.  2.  5.  4.  0.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 3.  3. 25. 16. 25.] 
adversary cards in discard: [25.  0.  3. 29.  8. 11. 15. 25. 29. 29. 29.  3. 10. 29.  3. 25. 29. 10.
  0.  8.  0.  3.  0. 11.  1.  3. 11. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3 11  3 11] -> size -> 42 
adversary victory points: 10
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  0.  0.  0.] 
cards in discard: [11.  8.  2.  0. 15.  3.  0.  0.  3.  1. 15.  1.  0.  3.  0. 22. 11.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6 29  0
  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0  3  8
  1 14  0  3  3  0 11 15 15 11] -> size -> 58 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 16. 30.  8.  0.  8.  1.  5.  4.  0.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 3.  3. 25. 16. 25.] 
adversary cards in discard: [25.  0.  3. 29.  8. 11. 15. 25. 29. 29. 29.  3. 10. 29.  3. 25. 29. 10.
  0.  8.  0.  3.  0. 11.  1.  3. 11. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3 11  3 11] -> size -> 42 
adversary victory points: 10
player victory points: -2 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [ 3.  3. 25. 16. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 16. 25.] 
expected returns: [[105.01308]
 [129.87506]
 [114.5739 ]
 [129.87506]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 25. 16. 25.] 
cards in discard: [25.  0.  3. 29.  8. 11. 15. 25. 29. 29. 29.  3. 10. 29.  3. 25. 29. 10.
  0.  8.  0.  3.  0. 11.  1.  3. 11. 29. 29.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3 11  3 11] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 16. 30.  8.  0.  8.  1.  5.  4.  0.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 3.  0.  6. 23.  6.] 
adversary cards in discard: [11.  8.  2.  0. 15.  3.  0.  0.  3.  1. 15.  1.  0.  3.  0. 22. 11.  6.
 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6 29  0
  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0  3  8
  1 14  0  3  3  0 11 15 15 11] -> size -> 58 
adversary victory points: -2
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1
Learning step: 0
desired expected reward: 125.80380249023438



action possibilites: [-1] 
expected returns: [[120.12956]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 16. 25.  3.  0.] 
cards in discard: [25.  0.  3. 29.  8. 11. 15. 25. 29. 29. 29.  3. 10. 29.  3. 25. 29. 10.
  0.  8.  0.  3.  0. 11.  1.  3. 11. 29. 29.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3 11  3 11] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 16. 30.  8.  0.  8.  1.  5.  4.  0.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 3.  0.  6. 23.  6.] 
adversary cards in discard: [11.  8.  2.  0. 15.  3.  0.  0.  3.  1. 15.  1.  0.  3.  0. 22. 11.  6.
 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6 29  0
  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0  3  8
  1 14  0  3  3  0 11 15 15 11] -> size -> 58 
adversary victory points: -2
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 129.87509155273438





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[113.65631 ]
 [120.129585]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 16. 25.  3.  0.] 
cards in discard: [25.  0.  3. 29.  8. 11. 15. 25. 29. 29. 29.  3. 10. 29.  3. 25. 29. 10.
  0.  8.  0.  3.  0. 11.  1.  3. 11. 29. 29.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3 11  3 11] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 24. 29. 16. 30.  8.  0.  8.  1.  5.  4.  0.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 3.  0.  6. 23.  6.] 
adversary cards in discard: [11.  8.  2.  0. 15.  3.  0.  0.  3.  1. 15.  1.  0.  3.  0. 22. 11.  6.
 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6 29  0
  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0  3  8
  1 14  0  3  3  0 11 15 15 11] -> size -> 58 
adversary victory points: -2
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action -1
Learning step: 0
desired expected reward: 120.12956237792969






Player: 1 
cards in hand: [ 3.  0.  6. 23.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  6. 23.  6.] 
cards in discard: [11.  8.  2.  0. 15.  3.  0.  0.  3.  1. 15.  1.  0.  3.  0. 22. 11.  6.
 11.  0.  0.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6 29  0
  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0  3  8
  1 14  0  3  3  0 11 15 15 11] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 16. 30.  8.  0.  8.  1.  5.  4.  0.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 3. 29.  3. 25.  0.] 
adversary cards in discard: [25.  0.  3. 29.  8. 11. 15. 25. 29. 29. 29.  3. 10. 29.  3. 25. 29. 10.
  0.  8.  0.  3.  0. 11.  1.  3. 11. 29. 29.  0. 25.  3.  3. 16. 25.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3 11  3 11] -> size -> 42 
adversary victory points: 10
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  6. 23.  6.] 
cards in discard: [11.  8.  2.  0. 15.  3.  0.  0.  3.  1. 15.  1.  0.  3.  0. 22. 11.  6.
 11.  0.  0.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6 29  0
  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0  3  8
  1 14  0  3  3  0 11 15 15 11] -> size -> 58 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 24. 29. 16. 30.  8.  0.  8.  1.  5.  4.  0.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 3. 29.  3. 25.  0.] 
adversary cards in discard: [25.  0.  3. 29.  8. 11. 15. 25. 29. 29. 29.  3. 10. 29.  3. 25. 29. 10.
  0.  8.  0.  3.  0. 11.  1.  3. 11. 29. 29.  0. 25.  3.  3. 16. 25.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3 11  3 11] -> size -> 42 
adversary victory points: 10
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [ 3. 29.  3. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[69.67942 ]
 [84.169815]
 [89.63727 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3. 25.  0.] 
cards in discard: [25.  0.  3. 29.  8. 11. 15. 25. 29. 29. 29.  3. 10. 29.  3. 25. 29. 10.
  0.  8.  0.  3.  0. 11.  1.  3. 11. 29. 29.  0. 25.  3.  3. 16. 25.  3.
  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3 11  3 11] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 16. 30.  8.  0.  8.  1.  5.  4.  0.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 1. 29.  3.  6.  0.] 
adversary cards in discard: [11.  8.  2.  0. 15.  3.  0.  0.  3.  1. 15.  1.  0.  3.  0. 22. 11.  6.
 11.  0.  0.  0.  3.  0.  6. 23.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6 29  0
  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0  3  8
  1 14  0  3  3  0 11 15 15 11] -> size -> 58 
adversary victory points: -2
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 120.12956237792969



action possibilites: [-1] 
expected returns: [[-5.500488]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3.  0. 10. 29.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3 11  3 11] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 16. 30.  8.  0.  8.  1.  5.  4.  0.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 1. 29.  3.  6.  0.] 
adversary cards in discard: [11.  8.  2.  0. 15.  3.  0.  0.  3.  1. 15.  1.  0.  3.  0. 22. 11.  6.
 11.  0.  0.  0.  3.  0.  6. 23.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6 29  0
  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0  3  8
  1 14  0  3  3  0 11 15 15 11] -> size -> 58 
adversary victory points: -2
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 89.63728332519531





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-17.81712  ]
 [ -3.1522863]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  3.  0. 10. 29.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3 11  3 11] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 24. 29. 16. 30.  8.  0.  8.  1.  5.  4.  0.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 1. 29.  3.  6.  0.] 
adversary cards in discard: [11.  8.  2.  0. 15.  3.  0.  0.  3.  1. 15.  1.  0.  3.  0. 22. 11.  6.
 11.  0.  0.  0.  3.  0.  6. 23.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6 29  0
  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0  3  8
  1 14  0  3  3  0 11 15 15 11] -> size -> 58 
adversary victory points: -2
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action -1
Learning step: 0
desired expected reward: -5.500487804412842






Player: 1 
cards in hand: [ 1. 29.  3.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  3.  6.  0.] 
cards in discard: [11.  8.  2.  0. 15.  3.  0.  0.  3.  1. 15.  1.  0.  3.  0. 22. 11.  6.
 11.  0.  0.  0.  3.  0.  6. 23.  6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6 29  0
  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0  3  8
  1 14  0  3  3  0 11 15 15 11] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 16. 30.  8.  0.  8.  1.  5.  4.  0.  8.  9.  6.  9.  7.] 
adversary cards in hand: [11. 25. 11.  0.  0.] 
adversary cards in discard: [25.  3. 29.  3.  0. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3 11  3 11] -> size -> 42 
adversary victory points: 10
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.  3.  6.  0.] 
cards in discard: [11.  8.  2.  0. 15.  3.  0.  0.  3.  1. 15.  1.  0.  3.  0. 22. 11.  6.
 11.  0.  0.  0.  3.  0.  6. 23.  6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6 29  0
  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0  3  8
  1 14  0  3  3  0 11 15 15 11] -> size -> 58 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 24. 29. 16. 30.  8.  0.  8.  1.  5.  4.  0.  8.  9.  6.  9.  7.] 
adversary cards in hand: [11. 25. 11.  0.  0.] 
adversary cards in discard: [25.  3. 29.  3.  0. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3 11  3 11] -> size -> 42 
adversary victory points: 10
player victory points: -2 


Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 1 
Gold: 0 
Estate: 7 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 1 
Workshop: 3 
Chapel: 2 
Witch: 6 
Poacher: 9 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [11. 25. 11.  0.  0.] 
cards in discard: [25.  3. 29.  3.  0. 10. 29.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  1 10 25 25 25 25  3 29  3
 25 29 25 29  3  8 29  3  8  3 29 15 29 16  3 11  3 11] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 29. 16. 30.  8.  0.  8.  0.  5.  4.  0.  8.  9.  6.  9.  7.] 
adversary cards in hand: [ 1. 29.  3.  6.  0.] 
adversary cards in discard: [11.  8.  2.  0. 15.  3.  0.  0.  3.  1. 15.  1.  0.  3.  0. 22. 11.  6.
 11.  0.  0.  0.  3.  0.  6. 23.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  3 14  1  0  3  0  3 23 10  6  0  1  6 16  6  1  6 29  0
  6 10  6  8  2  0  6  6  3  6  0  6  8  3 11  1 11 11  0 22  0  0  3  8
  1 14  0  3  3  0 11 15 15 11 11] -> size -> 59 
adversary victory points: -2
player victory points: 10 

Reward from previous game state: 
[     -5 3000000       0     360       0       0       0       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000355 

action type: buy - action -1.0
Learning step: 120014.328125
desired expected reward: 120011.1796875



