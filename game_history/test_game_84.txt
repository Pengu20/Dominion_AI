 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[10.639212]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [11.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0      -90        0        0        0        0
        0        0        0      -60        0     -300        0        0] 
sum of rewards: -3000455 

action type: buy - action 6.0
Learning step: -120009.546875
desired expected reward: -120225.8359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 10.321432]
 [ 24.847921]
 [ 13.951996]
 [-25.210533]
 [-72.237976]
 [ 19.397104]
 [ 22.041555]
 [ 11.154446]
 [ 25.95593 ]
 [ 32.760185]
 [ 21.582455]
 [ 24.930822]
 [ 19.58604 ]
 [ 19.396318]
 [ 25.098595]
 [  8.334553]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [11.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 10.111879348754883



buy possibilites: [-1] 
expected returns: [[5.6629777]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [11.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 27.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 32.76019287109375






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [11.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [11.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [11.  0.  0.  0.  0.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-12.58382]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [29.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 5.662977695465088





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ -9.863634]
 [ -6.319442]
 [-97.371414]
 [ -9.01306 ]
 [-11.840443]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [29.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.081544876098633



buy possibilites: [-1] 
expected returns: [[-12.541777]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [29.  0.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0 16  0] 
sum of rewards: 41 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -6.3194427490234375






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[2.1008434]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [0. 0. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -12.541776657104492





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[  4.035516 ]
 [ 18.572685 ]
 [  7.5863166]
 [-75.96169  ]
 [ 15.533457 ]
 [  4.6411643]
 [ 13.146088 ]
 [  2.6306548]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [0. 0. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 0.6244187355041504



buy possibilites: [-1] 
expected returns: [[8.6111145]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [0. 0. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 79 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 18.57268524169922






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [10.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  0.] 
cards in discard: [0. 0. 0. 3. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  3.] 
adversary cards in discard: [1. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1] -> size -> 13 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [0. 0. 0. 3. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0] -> size -> 13 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  3.] 
adversary cards in discard: [1. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1] -> size -> 13 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [0. 0. 0. 3. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  3.] 
adversary cards in discard: [1. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1] -> size -> 13 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [0. 0. 0. 3. 0. 3. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  3.] 
adversary cards in discard: [1. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1] -> size -> 13 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [29.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-20.239117]
 [  3.461802]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0.  3.] 
cards in discard: [1. 0. 0. 3. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 8.611114501953125



action possibilites: [-1.] 
expected returns: [[12.043884]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [1. 0. 0. 3. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 2.180203437805176





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 18.979788]
 [ 33.092712]
 [ 22.626207]
 [-61.57242 ]
 [ 28.00692 ]
 [ 30.693066]
 [ 19.966799]
 [ 40.610126]
 [ 30.244144]
 [ 28.282495]
 [ 33.57205 ]
 [ 17.289993]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [1. 0. 0. 3. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 12.04388427734375



buy possibilites: [-1] 
expected returns: [[-5.312495]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 1.  0.  0.  3.  3.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3] -> size -> 14 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 40.61012268066406






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29] -> size -> 14 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29] -> size -> 14 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.  3.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29] -> size -> 14 
adversary victory points: 4
player victory points: 5 





Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-7.8688645]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [ 3.  0. 10.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3  3] -> size -> 15 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -5.312495231628418





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[  -5.290842 ]
 [   8.893684 ]
 [  -1.6743984]
 [-117.03011  ]
 [   6.423844 ]
 [  -4.2954526]
 [   4.0425167]
 [  -6.56921  ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [ 3.  0. 10.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3  3] -> size -> 15 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -9.24660587310791



buy possibilites: [-1] 
expected returns: [[11.35758]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [ 3.  0. 10.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3  3] -> size -> 15 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0  54   0] 
sum of rewards: 19 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 8.893692016601562






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0.  0.] 
cards in discard: [ 3.  0. 10.  3.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [1. 3. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1] -> size -> 15 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  0.  0.] 
cards in discard: [ 3.  0. 10.  3.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 27. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [1. 3. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1] -> size -> 15 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  0.  0.] 
cards in discard: [ 3.  0. 10.  3.  0.  3. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3  3 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [1. 3. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1] -> size -> 15 
adversary victory points: 4
player victory points: 5 





Player: 0 
cards in hand: [3. 0. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[18.367561]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [1. 3. 0. 3. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3  3 10] -> size -> 16 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 11.357580184936523





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 20.34507 ]
 [ 34.076275]
 [ 24.044155]
 [-15.301134]
 [-58.304825]
 [ 29.223091]
 [ 31.816933]
 [ 21.120811]
 [ 35.23354 ]
 [ 41.31038 ]
 [ 31.384926]
 [ 34.306683]
 [ 29.453094]
 [ 29.3278  ]
 [ 34.57768 ]
 [ 18.9188  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [1. 3. 0. 3. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 28. 30. 27. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3  3 10] -> size -> 16 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 17.373376846313477



buy possibilites: [-1] 
expected returns: [[5.1757913]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [ 1.  3.  0.  3.  0.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 27. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3  3 10] -> size -> 16 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: -3.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 41.31038284301758






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3  3 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 29. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29] -> size -> 16 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3  3 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 27. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 29. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29] -> size -> 16 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3  3 10  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 27. 30.  8. 10. 10.  9.  9. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 29. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29] -> size -> 16 
adversary victory points: 4
player victory points: 5 





Player: 0 
cards in hand: [ 3. 29. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[-17.108175 ]
 [  4.4916673]
 [  4.4916673]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8. 10. 10.  9.  9. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0.  0.] 
adversary cards in discard: [8. 0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3  3 10  8] -> size -> 17 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 5.175791263580322



action possibilites: [-1. 29.] 
expected returns: [[-11.529705]
 [ 13.096985]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 27. 30.  8. 10. 10.  9.  9. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0.  0.] 
adversary cards in discard: [8. 0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3  3 10  8] -> size -> 17 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 1.5179972648620605



action possibilites: [-1.] 
expected returns: [[8.230787]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 27. 30.  8. 10. 10.  9.  9. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0.  0.] 
adversary cards in discard: [8. 0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3  3 10  8] -> size -> 17 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 13.096988677978516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 10.135992]
 [ 24.866848]
 [ 14.07044 ]
 [-94.10553 ]
 [ 19.747707]
 [ 22.433521]
 [ 10.966753]
 [ 32.500813]
 [ 21.98193 ]
 [ 19.92886 ]
 [ 25.347448]
 [  8.950951]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 27. 30.  8. 10. 10.  9.  9. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0.  0.] 
adversary cards in discard: [8. 0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3  3 10  8] -> size -> 17 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 8.23078727722168



buy possibilites: [-1] 
expected returns: [[10.450911]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8. 10. 10.  9.  9. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0.  0.] 
adversary cards in discard: [8. 0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3  3 10  8] -> size -> 17 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 133 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 32.50080871582031






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  0.  0.] 
cards in discard: [8. 0. 3. 0. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3  3 10  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8. 10. 10.  9.  9. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  1. 29.  0.  0.] 
adversary cards in discard: [29. 29. 29.  3.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29] -> size -> 17 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [8. 0. 3. 0. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3  3 10  8] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8. 10. 10.  9.  9. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  1. 29.  0.  0.] 
adversary cards in discard: [29. 29. 29.  3.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29] -> size -> 17 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [8. 0. 3. 0. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3  3 10  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 27. 30.  8. 10. 10.  9.  9. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  1. 29.  0.  0.] 
adversary cards in discard: [29. 29. 29.  3.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29] -> size -> 17 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [8. 0. 3. 0. 0. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3  3 10  8  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 28. 30. 27. 30.  8. 10. 10.  9.  9. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  1. 29.  0.  0.] 
adversary cards in discard: [29. 29. 29.  3.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29] -> size -> 17 
adversary victory points: 4
player victory points: 5 





Player: 0 
cards in hand: [ 0.  1. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 5.907535]
 [29.23117 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 29.  0.  0.] 
cards in discard: [29. 29. 29.  3.  3.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8. 10. 10.  9.  9. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  3. 10.  3.] 
adversary cards in discard: [ 8.  0.  3.  0.  0.  0.  0. 10.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3  3 10  8  0] -> size -> 18 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 10.450910568237305



action possibilites: [-1.] 
expected returns: [[25.703588]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [29. 29. 29.  3.  3.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 27. 30.  8. 10. 10.  9.  9. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  3. 10.  3.] 
adversary cards in discard: [ 8.  0.  3.  0.  0.  0.  0. 10.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3  3 10  8  0] -> size -> 18 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 27.112895965576172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 29.97015  ]
 [ 44.298866 ]
 [ -4.559209 ]
 [ 33.52518  ]
 [ -6.1026917]
 [-61.86982  ]
 [ 39.037197 ]
 [ 41.5271   ]
 [ 30.772491 ]
 [ 45.34666  ]
 [ 51.942448 ]
 [ 41.089024 ]
 [ 44.35654  ]
 [ 39.140884 ]
 [ 39.00304  ]
 [ 44.480804 ]
 [ 28.448017 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [29. 29. 29.  3.  3.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 7 
card supply: [28. 28. 30. 27. 30.  8. 10. 10.  9.  9. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  3. 10.  3.] 
adversary cards in discard: [ 8.  0.  3.  0.  0.  0.  0. 10.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3  3 10  8  0] -> size -> 18 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 25.703588485717773



buy possibilites: [-1] 
expected returns: [[39.754272]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [29. 29. 29.  3.  3.  0.  0.  3. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 28. 30. 27. 30.  8. 10. 10.  9.  9. 10.  5. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  3. 10.  3.] 
adversary cards in discard: [ 8.  0.  3.  0.  0.  0.  0. 10.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3  3 10  8  0] -> size -> 18 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: 17.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 51.94245147705078






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [11.  0.  3. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3. 10.  3.] 
cards in discard: [ 8.  0.  3.  0.  0.  0.  0. 10.  0.  3.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3  3 10  8  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8. 10. 10.  9.  9. 10.  5. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  3.  1.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29] -> size -> 18 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  3.] 
cards in discard: [ 8.  0.  3.  0.  0.  0.  0. 10.  0.  3.  0.  0.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3  3 10  8  0 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8. 10. 10.  9.  9. 10.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  3.  1.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29] -> size -> 18 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  3.] 
cards in discard: [ 8.  0.  3.  0.  0.  0.  0. 10.  0.  3.  0.  0.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3  3 10  8  0 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 28. 30. 27. 30.  8. 10. 10.  9.  9. 10.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  3.  1.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29] -> size -> 18 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  3.] 
cards in discard: [ 8.  0.  3.  0.  0.  0.  0. 10.  0.  3.  0.  0.  3. 29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3  3 10  8  0 29  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 27. 30.  8. 10. 10.  9.  9. 10.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  3.  1.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29] -> size -> 18 
adversary victory points: 4
player victory points: 5 





Player: 0 
cards in hand: [29.  3.  1.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 1.4595942]
 [22.756088 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  1.  3.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8. 10. 10.  9.  9. 10.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3  3 10  8  0 29  0] -> size -> 20 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 39.7542724609375



action possibilites: [-1.] 
expected returns: [[-0.7075052]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 3. 0. 1.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 27. 30.  8. 10. 10.  9.  9. 10.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3  3 10  8  0 29  0] -> size -> 20 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 21.37921905517578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[   2.499967 ]
 [  16.810349 ]
 [ -32.23805  ]
 [   6.4326777]
 [ -35.83707  ]
 [-100.02316  ]
 [  11.932724 ]
 [  14.406406 ]
 [   3.1050262]
 [  18.027617 ]
 [  24.759485 ]
 [  13.990803 ]
 [  17.00516  ]
 [  12.013102 ]
 [  12.011818 ]
 [  17.259375 ]
 [   1.9982085]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 0. 1.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 6 
card supply: [27. 28. 30. 27. 30.  8. 10. 10.  9.  9. 10.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3  3 10  8  0 29  0] -> size -> 20 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.7075052261352539



buy possibilites: [-1] 
expected returns: [[-13.116646]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 0. 1.] 
cards in discard: [29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 27. 30.  8. 10. 10.  9.  9. 10.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3  3 10  8  0 29  0] -> size -> 20 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: 17.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 24.75948715209961






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3  3 10  8  0 29  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8. 10. 10.  9.  9. 10.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [29. 29.  3.  1.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29] -> size -> 19 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3  3 10  8  0 29  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 27. 30.  8. 10. 10.  9.  9. 10.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [29. 29.  3.  1.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29] -> size -> 19 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3  3 10  8  0 29  0  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8. 10. 10.  9.  9. 10.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [29. 29.  3.  1.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29] -> size -> 19 
adversary victory points: 4
player victory points: 5 





Player: 0 
cards in hand: [29.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[21.021175]
 [43.536568]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0.  0.] 
cards in discard: [29. 29.  3.  1.  3.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8. 10. 10.  9.  9. 10.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [1. 0. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3  3 10  8  0 29  0  1] -> size -> 21 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -13.116645812988281



action possibilites: [-1.] 
expected returns: [[25.801563]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29. 29.  3.  1.  3.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 27. 30.  8. 10. 10.  9.  9. 10.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [1. 0. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3  3 10  8  0 29  0  1] -> size -> 21 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 40.44683837890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 32.887314 ]
 [ 46.729202 ]
 [ 36.293095 ]
 [ -5.1851735]
 [-48.82347  ]
 [ 41.934715 ]
 [ 44.327522 ]
 [ 33.96877  ]
 [ 47.774208 ]
 [ 53.796535 ]
 [ 43.916218 ]
 [ 46.86436  ]
 [ 42.056335 ]
 [ 41.957745 ]
 [ 47.040115 ]
 [ 32.047924 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29. 29.  3.  1.  3.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 27. 30. 27. 30.  8. 10. 10.  9.  9. 10.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [1. 0. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3  3 10  8  0 29  0  1] -> size -> 21 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 25.801563262939453



buy possibilites: [-1] 
expected returns: [[24.616367]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29. 29.  3.  1.  3.  0.  1. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 27. 30.  8. 10. 10.  9.  9. 10.  2. 10. 10.  8. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [1. 0. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3  3 10  8  0 29  0  1] -> size -> 21 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: 17.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 53.796531677246094






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [8. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [1. 0. 0. 3. 0. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  3  3 10  8  0 29  0  1] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8. 10. 10.  9.  9. 10.  2. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 29. 29.  0.  0.] 
adversary cards in discard: [29. 29.  3.  1.  3.  0.  1. 29. 29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29] -> size -> 20 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [1. 0. 0. 3. 0. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 11 10  0  3  3 10  8  0 29  0  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8. 10. 10.  9.  9. 10.  2. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 29. 29.  0.  0.] 
adversary cards in discard: [29. 29.  3.  1.  3.  0.  1. 29. 29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29] -> size -> 20 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [1. 0. 0. 3. 0. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 11 10  0  3  3 10  8  0 29  0  1] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 27. 30. 27. 30.  8. 10. 10.  9.  9. 10.  2. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 29. 29.  0.  0.] 
adversary cards in discard: [29. 29.  3.  1.  3.  0.  1. 29. 29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29] -> size -> 20 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [1. 0. 0. 3. 0. 3. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 11 10  0  3  3 10  8  0 29  0  1  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 27. 30.  8. 10. 10.  9.  9. 10.  2. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 29. 29.  0.  0.] 
adversary cards in discard: [29. 29.  3.  1.  3.  0.  1. 29. 29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29] -> size -> 20 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [29. 29. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[25.321714]
 [48.00106 ]
 [48.00106 ]
 [48.00106 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29.  0.  0.] 
cards in discard: [29. 29.  3.  1.  3.  0.  1. 29. 29.  0.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8. 10. 10.  9.  9. 10.  2. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0. 11.] 
adversary cards in discard: [1. 0. 0. 3. 0. 3. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  0  3  3 10  8  0 29  0  1  0] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 24.61636734008789



action possibilites: [-1. 29. 29.] 
expected returns: [[ 82.41806 ]
 [104.359924]
 [104.359924]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0.  0.  3.] 
cards in discard: [29. 29.  3.  1.  3.  0.  1. 29. 29.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 27. 30.  8. 10. 10.  9.  9. 10.  2. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0. 11.] 
adversary cards in discard: [1. 0. 0. 3. 0. 3. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  0  3  3 10  8  0 29  0  1  0] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 46.9490966796875



action possibilites: [-1. 29. 29.] 
expected returns: [[ 9.369457]
 [30.525623]
 [30.525623]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  3. 29.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 27. 30. 27. 30.  8. 10. 10.  9.  9. 10.  2. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0. 11.] 
adversary cards in discard: [1. 0. 0. 3. 0. 3. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  0  3  3 10  8  0 29  0  1  0] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 104.35993957519531



action possibilites: [-1. 29. 29.] 
expected returns: [[37.934517]
 [59.49613 ]
 [59.49613 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 29. 29.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 3 
card supply: [26. 27. 30. 27. 30.  8. 10. 10.  9.  9. 10.  2. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0. 11.] 
adversary cards in discard: [1. 0. 0. 3. 0. 3. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  0  3  3 10  8  0 29  0  1  0] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 30.525619506835938



action possibilites: [-1. 29.] 
expected returns: [[41.455395]
 [61.741135]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 29.  1.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 4 
card supply: [26. 27. 30. 27. 30.  8. 10. 10.  9.  9. 10.  2. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0. 11.] 
adversary cards in discard: [1. 0. 0. 3. 0. 3. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  0  3  3 10  8  0 29  0  1  0] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 59.496124267578125



action possibilites: [-1.] 
expected returns: [[61.298714]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 1. 1.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 5 
card supply: [26. 27. 30. 27. 30.  8. 10. 10.  9.  9. 10.  2. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0. 11.] 
adversary cards in discard: [1. 0. 0. 3. 0. 3. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  0  3  3 10  8  0 29  0  1  0] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0   0   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 95 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 61.74113464355469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[66.59008 ]
 [79.68955 ]
 [34.846394]
 [70.2786  ]
 [32.645668]
 [71.86111 ]
 [-8.016579]
 [75.34426 ]
 [77.625145]
 [67.06104 ]
 [80.74869 ]
 [86.26062 ]
 [77.2401  ]
 [79.9115  ]
 [75.39676 ]
 [75.40663 ]
 [80.1198  ]
 [66.12924 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 1.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 11 
card supply: [26. 27. 30. 27. 30.  8. 10. 10.  9.  9. 10.  2. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0. 11.] 
adversary cards in discard: [1. 0. 0. 3. 0. 3. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  0  3  3 10  8  0 29  0  1  0] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0   0   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 61.29871368408203



buy possibilites: [-1] 
expected returns: [[58.567215]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 1.] 
cards in discard: [29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 7 
card supply: [26. 27. 30. 27. 30.  8. 10. 10.  9.  9. 10.  1. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0. 11.] 
adversary cards in discard: [1. 0. 0. 3. 0. 3. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  0  3  3 10  8  0 29  0  1  0] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0. 100.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: 127.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 86.26061248779297






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0. 11.] 
cards in discard: [1. 0. 0. 3. 0. 3. 0. 8. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 10  0  3  3 10  8  0 29  0  1  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8. 10. 10.  9.  9. 10.  1. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  0.  0.] 
adversary cards in discard: [29. 29. 29. 29. 29. 29.  0.  0.  3.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29] -> size -> 21 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0. 11.] 
cards in discard: [1. 0. 0. 3. 0. 3. 0. 8. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 10  0  3  3 10  8  0 29  0  1  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 27. 30.  8. 10. 10.  9.  9. 10.  1. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  0.  0.] 
adversary cards in discard: [29. 29. 29. 29. 29. 29.  0.  0.  3.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29] -> size -> 21 
adversary victory points: 4
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3. 29.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[30.664413]
 [51.370796]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  0.  0.] 
cards in discard: [29. 29. 29. 29. 29. 29.  0.  0.  3.  1.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8. 10. 10.  9.  9. 10.  1. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 10. 29.  3.  0.] 
adversary cards in discard: [ 1.  0.  0.  3.  0.  3.  0.  8.  0.  0. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  0  3  3 10  8  0 29  0  1  0] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 58.56721496582031



action possibilites: [-1.] 
expected returns: [[48.30986]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [29. 29. 29. 29. 29. 29.  0.  0.  3.  1.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 27. 30.  8. 10. 10.  9.  9. 10.  1. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 10. 29.  3.  0.] 
adversary cards in discard: [ 1.  0.  0.  3.  0.  3.  0.  8.  0.  0. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  0  3  3 10  8  0 29  0  1  0] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 49.057857513427734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 52.866177]
 [ 66.49888 ]
 [ 56.195885]
 [ 16.393476]
 [-27.178854]
 [ 61.72358 ]
 [ 63.949165]
 [ 53.729153]
 [ 67.45274 ]
 [ 73.47472 ]
 [ 63.553726]
 [ 66.551094]
 [ 61.73481 ]
 [ 61.67074 ]
 [ 66.63964 ]
 [ 52.142845]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [29. 29. 29. 29. 29. 29.  0.  0.  3.  1.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 27. 30. 27. 30.  8. 10. 10.  9.  9. 10.  1. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 10. 29.  3.  0.] 
adversary cards in discard: [ 1.  0.  0.  3.  0.  3.  0.  8.  0.  0. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  0  3  3 10  8  0 29  0  1  0] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 48.30986022949219



buy possibilites: [-1] 
expected returns: [[118.07452]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [29. 29. 29. 29. 29. 29.  0.  0.  3.  1.  1. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 27. 30.  8. 10. 10.  9.  9. 10.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 10. 29.  3.  0.] 
adversary cards in discard: [ 1.  0.  0.  3.  0.  3.  0.  8.  0.  0. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  0  3  3 10  8  0 29  0  1  0] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 47.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 73.4747314453125






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 3. 10. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 29.  3.  0.] 
cards in discard: [ 1.  0.  0.  3.  0.  3.  0.  8.  0.  0. 10.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 10  0  3  3 10  8  0 29  0  1  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8. 10. 10.  9.  9. 10.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 29.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29] -> size -> 22 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 29.  3.  0.] 
cards in discard: [ 1.  0.  0.  3.  0.  3.  0.  8.  0.  0. 10.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 10  0  3  3 10  8  0 29  0  1  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 27. 30. 27. 30.  8. 10. 10.  9.  9. 10.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 29.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29] -> size -> 22 
adversary victory points: 4
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29. 29.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[-5.3715005]
 [16.122164 ]
 [16.122164 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8. 10. 10.  9.  9. 10.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  0  3  3 10  8  0 29  0  1  0] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 118.07451629638672



action possibilites: [-1.] 
expected returns: [[42.337208]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 27. 30.  8. 10. 10.  9.  9. 10.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  0  3  3 10  8  0 29  0  1  0] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 6.0667805671691895





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 46.323093]
 [ 59.805313]
 [ 49.75629 ]
 [-30.567564]
 [ 57.451267]
 [ 47.277096]
 [ 55.159164]
 [ 44.672455]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 27. 30.  8. 10. 10.  9.  9. 10.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  0  3  3 10  8  0 29  0  1  0] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 42.33720779418945



buy possibilites: [-1] 
expected returns: [[51.143738]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [29.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8. 10. 10.  9.  9. 10.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  0  3  3 10  8  0 29  0  1  0] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 59.80530548095703






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [10.  3.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 10  0  3  3 10  8  0 29  0  1  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 30.  8. 10. 10.  9.  9. 10.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0. 29.  1.  3.] 
adversary cards in discard: [29.  1. 29.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1] -> size -> 23 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 10  0  3  3 10  8  0 29  0  1  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 26. 30. 27. 30.  8. 10. 10.  9.  9. 10.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0. 29.  1.  3.] 
adversary cards in discard: [29.  1. 29.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1] -> size -> 23 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  3.  3.] 
cards in discard: [0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 10  0  3  3 10  8  0 29  0  1  0  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 27. 30.  8. 10. 10.  9.  9. 10.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0. 29.  1.  3.] 
adversary cards in discard: [29.  1. 29.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1] -> size -> 23 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [29.  0. 29.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[20.953571]
 [42.96934 ]
 [42.96934 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29.  1.  3.] 
cards in discard: [29.  1. 29.  3.  3.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 30.  8. 10. 10.  9.  9. 10.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  8.  0. 29.  0.] 
adversary cards in discard: [ 0. 10.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  0  3  3 10  8  0 29  0  1  0  0] -> size -> 20 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 51.14373779296875



action possibilites: [-1.] 
expected returns: [[62.325493]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 0.] 
cards in discard: [29.  1. 29.  3.  3.  0.  0. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 27. 30.  8. 10. 10.  9.  9. 10.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  8.  0. 29.  0.] 
adversary cards in discard: [ 0. 10.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  0  3  3 10  8  0 29  0  1  0  0] -> size -> 20 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 32.86920928955078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 66.65977 ]
 [ 80.64666 ]
 [ 70.270935]
 [ 27.80693 ]
 [-16.954723]
 [ 76.09946 ]
 [ 78.52611 ]
 [ 67.77441 ]
 [ 81.7621  ]
 [ 78.120224]
 [ 80.88762 ]
 [ 76.22243 ]
 [ 76.18754 ]
 [ 81.131165]
 [ 66.43178 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0.] 
cards in discard: [29.  1. 29.  3.  3.  0.  0. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 26. 30. 27. 30.  8. 10. 10.  9.  9. 10.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  8.  0. 29.  0.] 
adversary cards in discard: [ 0. 10.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  0  3  3 10  8  0 29  0  1  0  0] -> size -> 20 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 62.32549285888672



buy possibilites: [-1] 
expected returns: [[49.82663]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0.] 
cards in discard: [29.  1. 29.  3.  3.  0.  0. 29. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 30.  8. 10. 10.  9.  9.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  8.  0. 29.  0.] 
adversary cards in discard: [ 0. 10.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 10  0  3  3 10  8  0 29  0  1  0  0] -> size -> 20 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 265 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 81.7621078491211






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 29.  0.] 
cards in discard: [ 0. 10.  3.  0.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 10  0  3  3 10  8  0 29  0  1  0  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 30.  8. 10. 10.  9.  9.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 29. 29.  0.  3.] 
adversary cards in discard: [29.  1. 29.  3.  3.  0.  0. 29. 25. 29.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25] -> size -> 24 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0. 10.  3.  0.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 30.  8. 10. 10.  9.  9.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 29. 29.  0.  3.] 
adversary cards in discard: [29.  1. 29.  3.  3.  0.  0. 29. 25. 29.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25] -> size -> 24 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0. 10.  3.  0.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 26. 30. 27. 30.  8. 10. 10.  9.  9.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 29. 29.  0.  3.] 
adversary cards in discard: [29.  1. 29.  3.  3.  0.  0. 29. 25. 29.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25] -> size -> 24 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0. 10.  3.  0.  3.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 27. 30.  8. 10. 10.  9.  9.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 29. 29.  0.  3.] 
adversary cards in discard: [29.  1. 29.  3.  3.  0.  0. 29. 25. 29.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25] -> size -> 24 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [29. 29. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[79.142075]
 [96.088554]
 [96.088554]
 [96.088554]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29.  0.  3.] 
cards in discard: [29.  1. 29.  3.  3.  0.  0. 29. 25. 29.  0.  1.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8. 10. 10.  9.  9.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 10.  3.  0.  3.  3.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0] -> size -> 18 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 49.826629638671875



action possibilites: [-1. 29.] 
expected returns: [[147.7717 ]
 [166.77472]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  0.] 
cards in discard: [29.  1. 29.  3.  3.  0.  0. 29. 25. 29.  0.  1.  3.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 27. 30.  8. 10. 10.  9.  9.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 10.  3.  0.  3.  3.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0] -> size -> 18 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 88.46295166015625



action possibilites: [-1.] 
expected returns: [[139.28871]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [29.  1. 29.  3.  3.  0.  0. 29. 25. 29.  0.  1.  3.  0. 29. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 2 
card supply: [24. 26. 30. 27. 30.  8. 10. 10.  9.  9.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 10.  3.  0.  3.  3.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0] -> size -> 18 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 160.61541748046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[137.81937]
 [150.86116]
 [141.96034]
 [ 56.66642]
 [147.46579]
 [149.55618]
 [138.15546]
 [149.22174]
 [147.35838]
 [151.60278]
 [139.57127]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [29.  1. 29.  3.  3.  0.  0. 29. 25. 29.  0.  1.  3.  0. 29. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 26. 30. 27. 30.  8. 10. 10.  9.  9.  9.  0. 10. 10.  8. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 10.  3.  0.  3.  3.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0] -> size -> 18 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 139.28871154785156



buy possibilites: [-1] 
expected returns: [[100.361534]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [29.  1. 29.  3.  3.  0.  0. 29. 25. 29.  0.  1.  3.  0. 29. 29. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25
 15] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8. 10. 10.  9.  9.  9.  0. 10. 10.  8. 10.  9.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 10.  3.  0.  3.  3.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0] -> size -> 18 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 163 

action type: buy - action 15.0
Learning step: 0
desired expected reward: 151.60279846191406






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [1. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [ 0. 10.  3.  0.  3.  3.  0.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8. 10. 10.  9.  9.  9.  0. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 25.  1. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25
 15] -> size -> 25 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [ 0. 10.  3.  0.  3.  3.  0.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 6 
card supply: [24. 26. 30. 27. 30.  8. 10. 10.  9.  9.  9.  0. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 25.  1. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25
 15] -> size -> 25 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [ 0. 10.  3.  0.  3.  3.  0.  8.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 26. 30. 27. 30.  8. 10. 10.  8.  9.  9.  0. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 25.  1. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25
 15] -> size -> 25 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [ 0. 25.  1. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[43.013115]
 [58.897476]
 [65.185196]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  1. 29.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25
 15] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8. 10. 10.  8.  9.  9.  0. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 11.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 100.36153411865234



action possibilites: [-1. 25. 29.] 
expected returns: [[25.515852]
 [41.824028]
 [48.070152]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0. 29.] 
cards in discard: [1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25
 15] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 27. 30.  8. 10. 10.  8.  9.  9.  0. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 11.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 53.4612922668457



action possibilites: [-1. 15.] 
expected returns: [[41.286392]
 [56.04284 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.] 
cards in discard: [ 1. 25.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25
 15] -> size -> 25 
action values: 1 
buys: 0 
player value: 2 
card supply: [24. 26. 30. 27. 30.  8. 10. 10.  8.  9.  9.  0. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 11.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 39.27373123168945



action possibilites: [-1] 
expected returns: [[8.6788025]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 1. 25.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15] -> size -> 24 
action values: 0 
buys: 0 
player value: 5 
card supply: [24. 26. 30. 27. 30.  8. 10. 10.  8.  9.  9.  0. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 11.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 56.0428352355957





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 10.607243 ]
 [ 24.341492 ]
 [-22.605639 ]
 [ 14.6544285]
 [-25.19174  ]
 [-65.37567  ]
 [ 20.08626  ]
 [ 22.235928 ]
 [ 10.744003 ]
 [ 25.386658 ]
 [ 21.864067 ]
 [ 24.559162 ]
 [ 19.931845 ]
 [ 20.09341  ]
 [ 24.703402 ]
 [ 11.133959 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 1. 25.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15] -> size -> 24 
action values: 0 
buys: 1 
player value: 6 
card supply: [24. 26. 30. 27. 30.  8. 10. 10.  8.  9.  9.  0. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 11.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 8.678802490234375



buy possibilites: [-1] 
expected returns: [[47.572113]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 1. 25. 25.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 27. 30.  8. 10. 10.  8.  9.  8.  0. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 3. 11.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  60.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 117.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 25.386661529541016






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 3. 11.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0. 10.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8. 10. 10.  8.  9.  8.  0. 10. 10.  8. 10.  9.] 
adversary cards in hand: [29.  1.  0.  3. 29.] 
adversary cards in discard: [ 1. 25. 25. 29. 29. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15
 25] -> size -> 25 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0. 10.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 27. 30.  8. 10. 10.  8.  9.  8.  0. 10. 10.  8. 10.  9.] 
adversary cards in hand: [29.  1.  0.  3. 29.] 
adversary cards in discard: [ 1. 25. 25. 29. 29. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15
 25] -> size -> 25 
adversary victory points: 4
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29.  1.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[52.291588]
 [70.652794]
 [70.652794]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  0.  3. 29.] 
cards in discard: [ 1. 25. 25. 29. 29. 15.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8. 10. 10.  8.  9.  8.  0. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 11.  1.] 
adversary cards in discard: [ 3. 11.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 47.572113037109375



action possibilites: [-1. 29. 29.] 
expected returns: [[56.828415]
 [78.24086 ]
 [78.24086 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29. 29.] 
cards in discard: [ 1. 25. 25. 29. 29. 15.  0.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 27. 30.  8. 10. 10.  8.  9.  8.  0. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 11.  1.] 
adversary cards in discard: [ 3. 11.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 61.972312927246094



action possibilites: [-1. 29.] 
expected returns: [[71.66739 ]
 [92.305756]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.] 
cards in discard: [ 1. 25. 25. 29. 29. 15.  0.  1. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 2 
card supply: [24. 26. 30. 27. 30.  8. 10. 10.  8.  9.  8.  0. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 11.  1.] 
adversary cards in discard: [ 3. 11.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 71.19621276855469



action possibilites: [-1.] 
expected returns: [[142.11168]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 1. 25. 25. 29. 29. 15.  0.  1. 29.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 3 
card supply: [24. 26. 30. 27. 30.  8. 10. 10.  8.  9.  8.  0. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 11.  1.] 
adversary cards in discard: [ 3. 11.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 85.61749267578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[141.9964  ]
 [154.70479 ]
 [145.40298 ]
 [104.756775]
 [ 62.546852]
 [150.83066 ]
 [152.8846  ]
 [142.83197 ]
 [155.68846 ]
 [152.53824 ]
 [154.93623 ]
 [150.8153  ]
 [150.88902 ]
 [155.12604 ]
 [142.54398 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 1. 25. 25. 29. 29. 15.  0.  1. 29.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15
 25] -> size -> 25 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 26. 30. 27. 30.  8. 10. 10.  8.  9.  8.  0. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 11.  1.] 
adversary cards in discard: [ 3. 11.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 142.11167907714844



buy possibilites: [-1] 
expected returns: [[136.56761]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 1. 25. 25. 29. 29. 15.  0.  1. 29.  3. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15
 25 25] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8. 10. 10.  8.  9.  7.  0. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 11.  1.] 
adversary cards in discard: [ 3. 11.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11] -> size -> 19 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0   0   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 305 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 155.6884765625






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.  1.] 
cards in discard: [ 3. 11.  0. 10.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8. 10. 10.  8.  9.  7.  0. 10. 10.  8. 10.  9.] 
adversary cards in hand: [29. 29.  3.  0.  3.] 
adversary cards in discard: [ 1. 25. 25. 29. 29. 15.  0.  1. 29.  3. 25. 29. 29. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15
 25 25] -> size -> 26 
adversary victory points: 4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.  1.] 
cards in discard: [ 3. 11.  0. 10.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 26. 30. 27. 30.  8. 10. 10.  8.  9.  7.  0. 10. 10.  8. 10.  9.] 
adversary cards in hand: [29. 29.  3.  0.  3.] 
adversary cards in discard: [ 1. 25. 25. 29. 29. 15.  0.  1. 29.  3. 25. 29. 29. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15
 25 25] -> size -> 26 
adversary victory points: 4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.  1.] 
cards in discard: [ 3. 11.  0. 10.  3. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 27. 30.  8. 10. 10.  8.  9.  7.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [29. 29.  3.  0.  3.] 
adversary cards in discard: [ 1. 25. 25. 29. 29. 15.  0.  1. 29.  3. 25. 29. 29. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15
 25 25] -> size -> 26 
adversary victory points: 4
player victory points: 4 





Player: 0 
cards in hand: [29. 29.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[81.86428 ]
 [97.271126]
 [97.271126]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  3.  0.  3.] 
cards in discard: [ 1. 25. 25. 29. 29. 15.  0.  1. 29.  3. 25. 29. 29. 29.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15
 25 25] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 30.  8. 10. 10.  8.  9.  7.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  3.  3.] 
adversary cards in discard: [ 3. 11.  0. 10.  3. 14.  0.  0.  0. 11.  1.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14] -> size -> 20 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 136.56761169433594



action possibilites: [-1.] 
expected returns: [[90.73948]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3.] 
cards in discard: [ 1. 25. 25. 29. 29. 15.  0.  1. 29.  3. 25. 29. 29. 29.  0.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15
 25 25] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 27. 30.  8. 10. 10.  8.  9.  7.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  3.  3.] 
adversary cards in discard: [ 3. 11.  0. 10.  3. 14.  0.  0.  0. 11.  1.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14] -> size -> 20 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 91.99540710449219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[87.032715]
 [91.36443 ]
 [ 8.942013]
 [86.46119 ]
 [90.34298 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3.] 
cards in discard: [ 1. 25. 25. 29. 29. 15.  0.  1. 29.  3. 25. 29. 29. 29.  0.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15
 25 25] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 30. 27. 30.  8. 10. 10.  8.  9.  7.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  3.  3.] 
adversary cards in discard: [ 3. 11.  0. 10.  3. 14.  0.  0.  0. 11.  1.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14] -> size -> 20 
adversary victory points: 4
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 90.7394790649414



buy possibilites: [-1] 
expected returns: [[44.526573]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3.] 
cards in discard: [ 1. 25. 25. 29. 29. 15.  0.  1. 29.  3. 25. 29. 29. 29.  0.  0. 29.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15
 25 25  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 26. 30.  8. 10. 10.  8.  9.  7.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  3.  3.] 
adversary cards in discard: [ 3. 11.  0. 10.  3. 14.  0.  0.  0. 11.  1.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14] -> size -> 20 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 61 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 91.36445617675781






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3.  3.] 
cards in discard: [ 3. 11.  0. 10.  3. 14.  0.  0.  0. 11.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 26. 30.  8. 10. 10.  8.  9.  7.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  1. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15
 25 25  3] -> size -> 27 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 8.] 
cards in discard: [ 3. 11.  0. 10.  3. 14.  0.  0.  0. 11.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 26. 30.  8. 10. 10.  8.  9.  7.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  1. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15
 25 25  3] -> size -> 27 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 8.] 
cards in discard: [ 3. 11.  0. 10.  3. 14.  0.  0.  0. 11.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 30. 26. 30.  8. 10. 10.  8.  9.  7.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  1. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15
 25 25  3] -> size -> 27 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 8.] 
cards in discard: [ 3. 11.  0. 10.  3. 14.  0.  0.  0. 11.  1.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 25. 30.  8. 10. 10.  8.  9.  7.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  1. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15
 25 25  3] -> size -> 27 
adversary victory points: 5
player victory points: 5 





Player: 0 
cards in hand: [ 3.  1. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 1.1833315]
 [21.123482 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15
 25 25  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 25. 30.  8. 10. 10.  8.  9.  7.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [10.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3] -> size -> 21 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 44.526573181152344



action possibilites: [-1. 29.] 
expected returns: [[22.522135]
 [43.91017 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 29.] 
cards in discard: [1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15
 25 25  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 25. 30.  8. 10. 10.  8.  9.  7.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [10.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3] -> size -> 21 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 9.90243911743164



action possibilites: [-1.] 
expected returns: [[34.051758]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [ 1. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15
 25 25  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 2 
card supply: [24. 26. 30. 25. 30.  8. 10. 10.  8.  9.  7.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [10.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3] -> size -> 21 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 36.909000396728516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[ 35.93233 ]
 [ 49.71011 ]
 [ 39.76361 ]
 [-43.73725 ]
 [ 45.322136]
 [ 47.701244]
 [ 36.653393]
 [ 47.30492 ]
 [ 45.387066]
 [ 50.23429 ]
 [ 35.868908]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 1. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15
 25 25  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 26. 30. 25. 30.  8. 10. 10.  8.  9.  7.  0.  9. 10.  8. 10.  9.] 
adversary cards in hand: [10.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3] -> size -> 21 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 34.0517578125



buy possibilites: [-1] 
expected returns: [[42.1619]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 1. 29. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15
 25 25  3 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 25. 30.  8. 10. 10.  8.  9.  7.  0.  9. 10.  8. 10.  8.] 
adversary cards in hand: [10.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3] -> size -> 21 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 163 

action type: buy - action 15.0
Learning step: 0
desired expected reward: 50.23430633544922






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [10.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 25. 30.  8. 10. 10.  8.  9.  7.  0.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 15. 29.] 
adversary cards in discard: [ 1. 29. 15. 29. 29.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15
 25 25  3 15] -> size -> 28 
adversary victory points: 5
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 25. 30.  8. 10. 10.  8.  9.  7.  0.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 15. 29.] 
adversary cards in discard: [ 1. 29. 15. 29. 29.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15
 25 25  3 15] -> size -> 28 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 26. 30. 25. 30.  8. 10. 10.  8.  9.  7.  0.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 15. 29.] 
adversary cards in discard: [ 1. 29. 15. 29. 29.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15
 25 25  3 15] -> size -> 28 
adversary victory points: 5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 24. 30.  8. 10. 10.  8.  9.  7.  0.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 15. 29.] 
adversary cards in discard: [ 1. 29. 15. 29. 29.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15
 25 25  3 15] -> size -> 28 
adversary victory points: 5
player victory points: 6 





Player: 0 
cards in hand: [ 3.  0.  0. 15. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
expected returns: [[ 89.13872 ]
 [103.466675]
 [110.03781 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 15. 29.] 
cards in discard: [ 1. 29. 15. 29. 29.  3.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15
 25 25  3 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 24. 30.  8. 10. 10.  8.  9.  7.  0.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  3.  0. 14. 11.] 
adversary cards in discard: [ 3. 10.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3] -> size -> 22 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 42.16189956665039



action possibilites: [-1. 15.] 
expected returns: [[ 94.53125]
 [108.65738]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 15.] 
cards in discard: [ 1. 29. 15. 29. 29.  3.  0.  0. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15
 25 25  3 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 24. 30.  8. 10. 10.  8.  9.  7.  0.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  3.  0. 14. 11.] 
adversary cards in discard: [ 3. 10.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3] -> size -> 22 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 102.98443603515625



action possibilites: [-1] 
expected returns: [[69.69493]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [ 1. 29. 15. 29. 29.  3.  0.  0. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15] -> size -> 27 
action values: 0 
buys: 0 
player value: 4 
card supply: [24. 26. 30. 24. 30.  8. 10. 10.  8.  9.  7.  0.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  3.  0. 14. 11.] 
adversary cards in discard: [ 3. 10.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3] -> size -> 22 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 108.65737915039062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[69.89129 ]
 [82.48943 ]
 [73.24279 ]
 [35.69348 ]
 [-4.507841]
 [78.39707 ]
 [80.375984]
 [70.43528 ]
 [83.39793 ]
 [80.028404]
 [82.61357 ]
 [78.316765]
 [78.37335 ]
 [82.71578 ]
 [69.998856]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 1. 29. 15. 29. 29.  3.  0.  0. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 26. 30. 24. 30.  8. 10. 10.  8.  9.  7.  0.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  3.  0. 14. 11.] 
adversary cards in discard: [ 3. 10.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3] -> size -> 22 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 69.69493103027344



buy possibilites: [-1] 
expected returns: [[94.12355]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 1. 29. 15. 29. 29.  3.  0.  0. 29. 25.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 24. 30.  8. 10. 10.  8.  9.  6.  0.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  3.  0. 14. 11.] 
adversary cards in discard: [ 3. 10.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3] -> size -> 22 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 255 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 83.39791870117188






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  0. 14. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 14. 11.] 
cards in discard: [ 3. 10.  3.  0.  0.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 24. 30.  8. 10. 10.  8.  9.  6.  0.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  3. 25. 25. 25.] 
adversary cards in discard: [ 1. 29. 15. 29. 29.  3.  0.  0. 29. 25. 29. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25] -> size -> 28 
adversary victory points: 5
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 11.] 
cards in discard: [ 3. 10.  3.  0.  0.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 26. 30. 24. 30.  8. 10. 10.  8.  9.  6.  0.  9. 10.  8. 10.  8.] 
adversary cards in hand: [25. 25. 25.] 
adversary cards in discard: [ 1. 29. 15. 29. 29.  3.  0.  0. 29. 25. 29. 15.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25] -> size -> 28 
adversary victory points: 5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 11.] 
cards in discard: [ 3. 10.  3.  0.  0.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 26. 30. 24. 30.  8. 10. 10.  8.  9.  6.  0.  9. 10.  8. 10.  8.] 
adversary cards in hand: [25. 25. 25.] 
adversary cards in discard: [ 1. 29. 15. 29. 29.  3.  0.  0. 29. 25. 29. 15.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25] -> size -> 28 
adversary victory points: 5
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 11.] 
cards in discard: [ 3. 10.  3.  0.  0.  0.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 23. 30.  8. 10. 10.  8.  9.  6.  0.  9. 10.  8. 10.  8.] 
adversary cards in hand: [25. 25. 25.] 
adversary cards in discard: [ 1. 29. 15. 29. 29.  3.  0.  0. 29. 25. 29. 15.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25] -> size -> 28 
adversary victory points: 5
player victory points: 7 





Player: 0 
cards in hand: [25. 25. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 25.] 
expected returns: [[117.891426]
 [129.63644 ]
 [129.63644 ]
 [129.63644 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25. 25.] 
cards in discard: [ 1. 29. 15. 29. 29.  3.  0.  0. 29. 25. 29. 15.  3.  0.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 23. 30.  8. 10. 10.  8.  9.  6.  0.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0.  0.  8. 11.] 
adversary cards in discard: [ 3. 10.  3.  0.  0.  0.  3.  3. 14.  3.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3] -> size -> 23 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[  -5    0    0  -60    0    0    0    0    0    0    0    0    0    0
 1258    0] 
sum of rewards: 1193 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 11.150449752807617



action possibilites: [-1] 
expected returns: [[97.1391]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25.  0. 29.] 
cards in discard: [ 1. 29. 15. 29. 29.  3.  0.  0. 29. 25. 29. 15.  3.  0.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 23. 30.  8.  9. 10.  8.  9.  6.  0.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0.  0.  8. 11.] 
adversary cards in discard: [ 3. 10.  3.  0.  0.  0.  3.  3. 14.  3.  3.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6] -> size -> 24 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 129.636474609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[94.05522 ]
 [19.648678]
 [96.77293 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 25.  0. 29.] 
cards in discard: [ 1. 29. 15. 29. 29.  3.  0.  0. 29. 25. 29. 15.  3.  0.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 23. 30.  8.  9. 10.  8.  9.  6.  0.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  0.  0.  8. 11.] 
adversary cards in discard: [ 3. 10.  3.  0.  0.  0.  3.  3. 14.  3.  3.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6] -> size -> 24 
adversary victory points: 7
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 97.13909912109375






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  8. 11.] 
cards in discard: [ 3. 10.  3.  0.  0.  0.  3.  3. 14.  3.  3.  0. 11.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 23. 30.  8.  9. 10.  8.  9.  6.  0.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 1. 29. 29.  1.  0.] 
adversary cards in discard: [ 1. 29. 15. 29. 29.  3.  0.  0. 29. 25. 29. 15.  3.  0.  3.  3. 25. 25.
 25.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25] -> size -> 28 
adversary victory points: 5
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [ 3. 10.  3.  0.  0.  0.  3.  3. 14.  3.  3.  0. 11.  6. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 23. 30.  8.  9. 10.  8.  9.  6.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 1. 29. 29.  1.  0.] 
adversary cards in discard: [ 1. 29. 15. 29. 29.  3.  0.  0. 29. 25. 29. 15.  3.  0.  3.  3. 25. 25.
 25.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25] -> size -> 28 
adversary victory points: 5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [ 3. 10.  3.  0.  0.  0.  3.  3. 14.  3.  3.  0. 11.  6. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 26. 30. 23. 30.  8.  9. 10.  8.  9.  6.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 1. 29. 29.  1.  0.] 
adversary cards in discard: [ 1. 29. 15. 29. 29.  3.  0.  0. 29. 25. 29. 15.  3.  0.  3.  3. 25. 25.
 25.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25] -> size -> 28 
adversary victory points: 5
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [ 3. 10.  3.  0.  0.  0.  3.  3. 14.  3.  3.  0. 11.  6. 14. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 23. 30.  8.  9. 10.  7.  9.  6.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 1. 29. 29.  1.  0.] 
adversary cards in discard: [ 1. 29. 15. 29. 29.  3.  0.  0. 29. 25. 29. 15.  3.  0.  3.  3. 25. 25.
 25.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25] -> size -> 28 
adversary victory points: 5
player victory points: 6 





Player: 0 
cards in hand: [ 1. 29. 29.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[ 7.5376 ]
 [25.04191]
 [25.04191]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 29.  1.  0.] 
cards in discard: [ 1. 29. 15. 29. 29.  3.  0.  0. 29. 25. 29. 15.  3.  0.  3.  3. 25. 25.
 25.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 23. 30.  8.  9. 10.  7.  9.  6.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 3. 10.  1.  0.  0.] 
adversary cards in discard: [ 3. 10.  3.  0.  0.  0.  3.  3. 14.  3.  3.  0. 11.  6. 14. 11. 11.  0.
  0.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11] -> size -> 26 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 96.77291107177734



action possibilites: [-1. 29.] 
expected returns: [[ 1.9333959]
 [19.437717 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  0.  3.] 
cards in discard: [ 1. 29. 15. 29. 29.  3.  0.  0. 29. 25. 29. 15.  3.  0.  3.  3. 25. 25.
 25.  0. 29.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 23. 30.  8.  9. 10.  7.  9.  6.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 3. 10.  1.  0.  0.] 
adversary cards in discard: [ 3. 10.  3.  0.  0.  0.  3.  3. 14.  3.  3.  0. 11.  6. 14. 11. 11.  0.
  0.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11] -> size -> 26 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 19.12957191467285



action possibilites: [-1. 29.] 
expected returns: [[ 4.1118593]
 [21.875315 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.] 
cards in discard: [ 1. 29. 15. 29. 29.  3.  0.  0. 29. 25. 29. 15.  3.  0.  3.  3. 25. 25.
 25.  0. 29.  1.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 2 
card supply: [24. 26. 30. 23. 30.  8.  9. 10.  7.  9.  6.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 3. 10.  1.  0.  0.] 
adversary cards in discard: [ 3. 10.  3.  0.  0.  0.  3.  3. 14.  3.  3.  0. 11.  6. 14. 11. 11.  0.
  0.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11] -> size -> 26 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 13.525362014770508



action possibilites: [-1. 25.] 
expected returns: [[-20.029394 ]
 [ -6.7349186]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.] 
cards in discard: [3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 3 
card supply: [24. 26. 30. 23. 30.  8.  9. 10.  7.  9.  6.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 3. 10.  1.  0.  0.] 
adversary cards in discard: [ 3. 10.  3.  0.  0.  0.  3.  3. 14.  3.  3.  0. 11.  6. 14. 11. 11.  0.
  0.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11] -> size -> 26 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 15.807220458984375



action possibilites: [-1] 
expected returns: [[13.334969]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.] 
cards in discard: [3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25] -> size -> 28 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 26. 30. 23. 30.  8.  8. 10.  7.  9.  6.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 3. 10.  1.  0.  0.] 
adversary cards in discard: [ 3. 10.  3.  0.  0.  0.  3.  3. 14.  3.  3.  0. 11.  6. 14. 11. 11.  0.
  0.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6] -> size -> 27 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -30   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -6.734923362731934





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 11.933386]
 [ 24.791357]
 [ 15.75152 ]
 [-22.17978 ]
 [-61.481277]
 [ 20.98923 ]
 [ 22.88972 ]
 [ 12.026133]
 [ 25.741783]
 [ 22.55816 ]
 [ 24.996471]
 [ 20.762579]
 [ 20.97936 ]
 [ 25.107674]
 [ 12.990742]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.] 
cards in discard: [3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25] -> size -> 28 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 26. 30. 23. 30.  8.  8. 10.  7.  9.  6.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 3. 10.  1.  0.  0.] 
adversary cards in discard: [ 3. 10.  3.  0.  0.  0.  3.  3. 14.  3.  3.  0. 11.  6. 14. 11. 11.  0.
  0.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6] -> size -> 27 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -30   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 13.334968566894531



buy possibilites: [-1] 
expected returns: [[21.130163]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.] 
cards in discard: [ 3. 25.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 29. 29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 23. 30.  8.  8. 10.  7.  9.  5.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 3. 10.  1.  0.  0.] 
adversary cards in discard: [ 3. 10.  3.  0.  0.  0.  3.  3. 14.  3.  3.  0. 11.  6. 14. 11. 11.  0.
  0.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6] -> size -> 27 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -30   0   0  80   0   0   0   0   0   0   0 250   0] 
sum of rewards: 295 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 25.741796493530273






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 3. 10.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  1.  0.  0.] 
cards in discard: [ 3. 10.  3.  0.  0.  0.  3.  3. 14.  3.  3.  0. 11.  6. 14. 11. 11.  0.
  0.  0.  8.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 23. 30.  8.  8. 10.  7.  9.  5.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [29. 29. 29.  1.  3.] 
adversary cards in discard: [ 3. 25. 29. 29. 29. 25.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25] -> size -> 29 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  1.  0.  0.] 
cards in discard: [ 3. 10.  3.  0.  0.  0.  3.  3. 14.  3.  3.  0. 11.  6. 14. 11. 11.  0.
  0.  0.  8.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 26. 30. 23. 30.  8.  8. 10.  7.  9.  5.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [29. 29. 29.  1.  3.] 
adversary cards in discard: [ 3. 25. 29. 29. 29. 25.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25] -> size -> 29 
adversary victory points: 5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  1.  0.  0.] 
cards in discard: [ 3. 10.  3.  0.  0.  0.  3.  3. 14.  3.  3.  0. 11.  6. 14. 11. 11.  0.
  0.  0.  8.  6.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 26. 30. 22. 30.  8.  8. 10.  7.  9.  5.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [29. 29. 29.  1.  3.] 
adversary cards in discard: [ 3. 25. 29. 29. 29. 25.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25] -> size -> 29 
adversary victory points: 5
player victory points: 6 





Player: 0 
cards in hand: [29. 29. 29.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[30.919579]
 [47.556076]
 [47.556076]
 [47.556076]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29.  1.  3.] 
cards in discard: [ 3. 25. 29. 29. 29. 25.  0.  0. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 22. 30.  8.  8. 10.  7.  9.  5.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [10.  0.  3.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3] -> size -> 28 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 21.130163192749023



action possibilites: [-1. 29.] 
expected returns: [[51.37544]
 [67.20477]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  3.  0.] 
cards in discard: [ 3. 25. 29. 29. 29. 25.  0.  0. 29. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 22. 30.  8.  8. 10.  7.  9.  5.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [10.  0.  3.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3] -> size -> 28 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 41.94200134277344



action possibilites: [-1.] 
expected returns: [[78.47242]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [ 3. 25. 29. 29. 29. 25.  0.  0. 29. 29.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25] -> size -> 29 
action values: 1 
buys: 0 
player value: 2 
card supply: [24. 26. 30. 22. 30.  8.  8. 10.  7.  9.  5.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [10.  0.  3.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3] -> size -> 28 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 61.84423065185547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[76.53428  ]
 [89.91696  ]
 [80.5354   ]
 [ 1.3850417]
 [87.894394 ]
 [76.51969  ]
 [85.69971  ]
 [78.50949  ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [ 3. 25. 29. 29. 29. 25.  0.  0. 29. 29.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 26. 30. 22. 30.  8.  8. 10.  7.  9.  5.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [10.  0.  3.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3] -> size -> 28 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 78.47241973876953



buy possibilites: [-1] 
expected returns: [[35.723343]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [ 3. 25. 29. 29. 29. 25.  0.  0. 29. 29.  1.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 22. 30.  8.  8. 10.  7.  9.  5.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [10.  0.  3.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3] -> size -> 28 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 59 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 89.91699981689453






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [10.  0.  3.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  1.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 22. 30.  8.  8. 10.  7.  9.  5.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [29.  1. 15. 15. 25.] 
adversary cards in discard: [ 3. 25. 29. 29. 29. 25.  0.  0. 29. 29.  1.  1. 29. 29.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1] -> size -> 30 
adversary victory points: 5
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 0. 3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 22. 30.  8.  8. 10.  7.  9.  5.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [29.  1. 15. 15. 25.] 
adversary cards in discard: [ 3. 25. 29. 29. 29. 25.  0.  0. 29. 29.  1.  1. 29. 29.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1] -> size -> 30 
adversary victory points: 5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 25. 30. 22. 30.  8.  8. 10.  7.  9.  5.  0.  8. 10.  8. 10.  8.] 
adversary cards in hand: [29.  1. 15. 15. 25.] 
adversary cards in discard: [ 3. 25. 29. 29. 29. 25.  0.  0. 29. 29.  1.  1. 29. 29.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1] -> size -> 30 
adversary victory points: 5
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 3.] 
cards in discard: [10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 25. 30. 22. 30.  8.  8. 10.  7.  9.  5.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [29.  1. 15. 15. 25.] 
adversary cards in discard: [ 3. 25. 29. 29. 29. 25.  0.  0. 29. 29.  1.  1. 29. 29.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1] -> size -> 30 
adversary victory points: 5
player victory points: 6 





Player: 0 
cards in hand: [29.  1. 15. 15. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 15. 25.] 
expected returns: [[41.261906]
 [57.797604]
 [52.355404]
 [52.355404]
 [53.051056]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1. 15. 15. 25.] 
cards in discard: [ 3. 25. 29. 29. 29. 25.  0.  0. 29. 29.  1.  1. 29. 29.  3.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 22. 30.  8.  8. 10.  7.  9.  5.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [10.  3.  0. 11. 14.] 
adversary cards in discard: [10. 10.  0.  3.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10] -> size -> 29 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 35.72334289550781



action possibilites: [-1. 15. 15. 25.] 
expected returns: [[ 96.43164 ]
 [106.892914]
 [106.892914]
 [107.52234 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15. 15. 25.] 
cards in discard: [ 3. 25. 29. 29. 29. 25.  0.  0. 29. 29.  1.  1. 29. 29.  3.  0.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 25. 30. 22. 30.  8.  8. 10.  7.  9.  5.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [10.  3.  0. 11. 14.] 
adversary cards in discard: [10. 10.  0.  3.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10] -> size -> 29 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 52.224891662597656



action possibilites: [-1] 
expected returns: [[18.391579]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15. 15. 25. 29.] 
cards in discard: [ 3. 25. 29. 29. 29. 25.  0.  0. 29. 29.  1.  1. 29. 29.  3.  0.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 25. 30. 22. 30.  8.  7. 10.  7.  9.  5.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [10.  3.  0. 11. 14.] 
adversary cards in discard: [10. 10.  0.  3.  1.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6] -> size -> 30 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 107.52238464355469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 17.412174]
 [ 29.712753]
 [ 21.039448]
 [-51.910908]
 [ 27.582954]
 [ 17.112675]
 [ 25.593388]
 [ 18.750647]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15. 15. 25. 29.] 
cards in discard: [ 3. 25. 29. 29. 29. 25.  0.  0. 29. 29.  1.  1. 29. 29.  3.  0.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 25. 30. 22. 30.  8.  7. 10.  7.  9.  5.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [10.  3.  0. 11. 14.] 
adversary cards in discard: [10. 10.  0.  3.  1.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6] -> size -> 30 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 18.391578674316406



buy possibilites: [-1] 
expected returns: [[5.195417]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15. 15. 25. 29.] 
cards in discard: [ 3. 25. 29. 29. 29. 25.  0.  0. 29. 29.  1.  1. 29. 29.  3.  0.  3.  3.
  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 22. 30.  8.  7. 10.  7.  9.  5.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [10.  3.  0. 11. 14.] 
adversary cards in discard: [10. 10.  0.  3.  1.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6] -> size -> 30 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 59 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 29.712772369384766






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [10.  3.  0. 11. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 14.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0. 11. 14.] 
cards in discard: [10. 10.  0.  3.  1.  0.  3.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 22. 30.  8.  7. 10.  7.  9.  5.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 25.  0.  3.  1.] 
adversary cards in discard: [ 3. 25. 29. 29. 29. 25.  0.  0. 29. 29.  1.  1. 29. 29.  3.  0.  3.  3.
  1. 29. 25.  1. 15. 15. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1] -> size -> 31 
adversary victory points: 5
player victory points: 5 


action possibilites: [-1. 11. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11. 14.  3.] 
cards in discard: [10. 10.  0.  3.  1.  0.  3.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 22. 30.  8.  7. 10.  7.  9.  5.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 25.  0.  3.  1.] 
adversary cards in discard: [ 3. 25. 29. 29. 29. 25.  0.  0. 29. 29.  1.  1. 29. 29.  3.  0.  3.  3.
  1. 29. 25.  1. 15. 15. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1] -> size -> 31 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11. 14.  3.] 
cards in discard: [10. 10.  0.  3.  1.  0.  3.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 24. 30. 22. 30.  8.  7. 10.  7.  9.  5.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 25.  0.  3.  1.] 
adversary cards in discard: [ 3. 25. 29. 29. 29. 25.  0.  0. 29. 29.  1.  1. 29. 29.  3.  0.  3.  3.
  1. 29. 25.  1. 15. 15. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1] -> size -> 31 
adversary victory points: 5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11. 14.  3.] 
cards in discard: [10. 10.  0.  3.  1.  0.  3.  6.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 24. 30. 22. 30.  8.  7. 10.  7.  9.  5.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 25.  0.  3.  1.] 
adversary cards in discard: [ 3. 25. 29. 29. 29. 25.  0.  0. 29. 29.  1.  1. 29. 29.  3.  0.  3.  3.
  1. 29. 25.  1. 15. 15. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1] -> size -> 31 
adversary victory points: 5
player victory points: 5 





Player: 0 
cards in hand: [ 0. 25.  0.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[19.64561 ]
 [32.042976]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.  3.  1.] 
cards in discard: [ 3. 25. 29. 29. 29. 25.  0.  0. 29. 29.  1.  1. 29. 29.  3.  0.  3.  3.
  1. 29. 25.  1. 15. 15. 25. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 22. 30.  8.  7. 10.  7.  9.  5.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  6.  0. 14.  0.] 
adversary cards in discard: [10. 10.  0.  3.  1.  0.  3.  6.  0. 10.  3.  0. 11. 14.  3.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0] -> size -> 31 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 5.1954169273376465



action possibilites: [-1] 
expected returns: [[-9.292097]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 1. 1. 0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 22. 30.  8.  6. 10.  7.  9.  5.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  6.  0. 14.  0.] 
adversary cards in discard: [10. 10.  0.  3.  1.  0.  3.  6.  0. 10.  3.  0. 11. 14.  3.  6.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6] -> size -> 32 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 32.04299545288086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ -7.092494 ]
 [  5.7825627]
 [-37.344074 ]
 [ -3.5427768]
 [-38.752747 ]
 [-77.99664  ]
 [  1.3241453]
 [  3.5374832]
 [ -6.72814  ]
 [  6.776836 ]
 [  3.1548223]
 [  5.9257016]
 [  1.3503795]
 [  1.3326879]
 [  6.0754085]
 [ -7.887249 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 1. 0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1] -> size -> 31 
action values: 0 
buys: 1 
player value: 7 
card supply: [23. 24. 30. 22. 30.  8.  6. 10.  7.  9.  5.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  6.  0. 14.  0.] 
adversary cards in discard: [10. 10.  0.  3.  1.  0.  3.  6.  0. 10.  3.  0. 11. 14.  3.  6.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6] -> size -> 32 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -9.292097091674805



buy possibilites: [-1] 
expected returns: [[31.319973]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 1. 0.] 
cards in discard: [25.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1 25] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 24. 30. 22. 30.  8.  6. 10.  7.  9.  4.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  6.  0. 14.  0.] 
adversary cards in discard: [10. 10.  0.  3.  1.  0.  3.  6.  0. 10.  3.  0. 11. 14.  3.  6.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6] -> size -> 32 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 77.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 6.776829242706299






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 3.  6.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  0. 14.  0.] 
cards in discard: [10. 10.  0.  3.  1.  0.  3.  6.  0. 10.  3.  0. 11. 14.  3.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 22. 30.  8.  6. 10.  7.  9.  4.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [25. 29. 29.  3.  0.] 
adversary cards in discard: [25. 25.  0.  0.  3.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1 25] -> size -> 32 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  0. 14.  0.] 
cards in discard: [10. 10.  0.  3.  1.  0.  3.  6.  0. 10.  3.  0. 11. 14.  3.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 24. 30. 22. 30.  8.  6. 10.  7.  9.  4.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [25. 29. 29.  3.  0.] 
adversary cards in discard: [25. 25.  0.  0.  3.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1 25] -> size -> 32 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  0. 14.  0.] 
cards in discard: [10. 10.  0.  3.  1.  0.  3.  6.  0. 10.  3.  0. 11. 14.  3.  6.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 21. 30.  8.  6. 10.  7.  9.  4.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [25. 29. 29.  3.  0.] 
adversary cards in discard: [25. 25.  0.  0.  3.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1 25] -> size -> 32 
adversary victory points: 5
player victory points: 5 





Player: 0 
cards in hand: [25. 29. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 29.] 
expected returns: [[32.227345]
 [45.85321 ]
 [51.123344]
 [51.123344]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 29.  3.  0.] 
cards in discard: [25. 25.  0.  0.  3.  1.  1.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 21. 30.  8.  6. 10.  7.  9.  4.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  8. 11.  0.  0.] 
adversary cards in discard: [10. 10.  0.  3.  1.  0.  3.  6.  0. 10.  3.  0. 11. 14.  3.  6.  3.  3.
  6.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3] -> size -> 33 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 31.31997299194336



action possibilites: [-1. 25. 29.] 
expected returns: [[63.65132]
 [77.40365]
 [82.7048 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0. 29.] 
cards in discard: [25. 25.  0.  0.  3.  1.  1.  0. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 24. 30. 21. 30.  8.  6. 10.  7.  9.  4.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  8. 11.  0.  0.] 
adversary cards in discard: [10. 10.  0.  3.  1.  0.  3.  6.  0. 10.  3.  0. 11. 14.  3.  6.  3.  3.
  6.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3] -> size -> 33 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 44.91905212402344



action possibilites: [-1. 25.] 
expected returns: [[84.917694]
 [98.34042 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  3.] 
cards in discard: [25. 25.  0.  0.  3.  1.  1.  0. 29.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 2 
card supply: [23. 24. 30. 21. 30.  8.  6. 10.  7.  9.  4.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  8. 11.  0.  0.] 
adversary cards in discard: [10. 10.  0.  3.  1.  0.  3.  6.  0. 10.  3.  0. 11. 14.  3.  6.  3.  3.
  6.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3] -> size -> 33 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 76.45943450927734



action possibilites: [-1] 
expected returns: [[55.506012]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 29.] 
cards in discard: [25. 25.  0.  0.  3.  1.  1.  0. 29.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1 25] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 24. 30. 21. 30.  8.  5. 10.  7.  9.  4.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  8. 11.  0.  0.] 
adversary cards in discard: [10. 10.  0.  3.  1.  0.  3.  6.  0. 10.  3.  0. 11. 14.  3.  6.  3.  3.
  6.  0. 14.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6] -> size -> 34 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 98.34042358398438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 52.87594 ]
 [ 65.671616]
 [ 56.735065]
 [-19.696508]
 [ 63.751495]
 [ 52.7866  ]
 [ 61.650085]
 [ 54.339096]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 29.] 
cards in discard: [25. 25.  0.  0.  3.  1.  1.  0. 29.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1 25] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 24. 30. 21. 30.  8.  5. 10.  7.  9.  4.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  8. 11.  0.  0.] 
adversary cards in discard: [10. 10.  0.  3.  1.  0.  3.  6.  0. 10.  3.  0. 11. 14.  3.  6.  3.  3.
  6.  0. 14.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6] -> size -> 34 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 55.506011962890625



buy possibilites: [-1] 
expected returns: [[23.165096]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 29.] 
cards in discard: [25. 25.  0.  0.  3.  1.  1.  0. 29.  3.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1 25  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 21. 30.  8.  5. 10.  7.  9.  4.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  8. 11.  0.  0.] 
adversary cards in discard: [10. 10.  0.  3.  1.  0.  3.  6.  0. 10.  3.  0. 11. 14.  3.  6.  3.  3.
  6.  0. 14.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6] -> size -> 34 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0 54  0] 
sum of rewards: 109 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 65.67161560058594






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 0.  8. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11.  0.  0.] 
cards in discard: [10. 10.  0.  3.  1.  0.  3.  6.  0. 10.  3.  0. 11. 14.  3.  6.  3.  3.
  6.  0. 14.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 21. 30.  8.  5. 10.  7.  9.  4.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [15.  1. 29. 15.  1.] 
adversary cards in discard: [25. 25.  0.  0.  3.  1.  1.  0. 29.  3.  1. 29. 29. 25.  0.  3.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1 25  1] -> size -> 33 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0.] 
cards in discard: [10. 10.  0.  3.  1.  0.  3.  6.  0. 10.  3.  0. 11. 14.  3.  6.  3.  3.
  6.  0. 14.  0.  6.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 21. 30.  8.  5. 10.  7.  9.  4.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [15.  1. 29. 15.  1.] 
adversary cards in discard: [25. 25.  0.  0.  3.  1.  1.  0. 29.  3.  1. 29. 29. 25.  0.  3.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1 25  1] -> size -> 33 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0.] 
cards in discard: [10. 10.  0.  3.  1.  0.  3.  6.  0. 10.  3.  0. 11. 14.  3.  6.  3.  3.
  6.  0. 14.  0.  6.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 22. 30. 21. 30.  8.  5. 10.  7.  9.  4.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [15.  1. 29. 15.  1.] 
adversary cards in discard: [25. 25.  0.  0.  3.  1.  1.  0. 29.  3.  1. 29. 29. 25.  0.  3.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1 25  1] -> size -> 33 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0.] 
cards in discard: [10. 10.  0.  3.  1.  0.  3.  6.  0. 10.  3.  0. 11. 14.  3.  6.  3.  3.
  6.  0. 14.  0.  6.  1.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 22. 30. 21. 30.  8.  5. 10.  7.  9.  4.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [15.  1. 29. 15.  1.] 
adversary cards in discard: [25. 25.  0.  0.  3.  1.  1.  0. 29.  3.  1. 29. 29. 25.  0.  3.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1 25  1] -> size -> 33 
adversary victory points: 5
player victory points: 4 





Player: 0 
cards in hand: [15.  1. 29. 15.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29. 15.] 
expected returns: [[-6.21033 ]
 [ 5.298289]
 [11.19183 ]
 [ 5.298289]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1. 29. 15.  1.] 
cards in discard: [25. 25.  0.  0.  3.  1.  1.  0. 29.  3.  1. 29. 29. 25.  0.  3.  3. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1 25  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 21. 30.  8.  5. 10.  7.  9.  4.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 3. 11.  6.  3.  3.] 
adversary cards in discard: [10. 10.  0.  3.  1.  0.  3.  6.  0. 10.  3.  0. 11. 14.  3.  6.  3.  3.
  6.  0. 14.  0.  6.  1.  0. 11.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0] -> size -> 36 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 23.165096282958984



action possibilites: [-1. 15. 15.] 
expected returns: [[ 4.5696874]
 [15.725889 ]
 [15.725889 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1. 15.  1.] 
cards in discard: [25. 25.  0.  0.  3.  1.  1.  0. 29.  3.  1. 29. 29. 25.  0.  3.  3. 29.
  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1 25  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 22. 30. 21. 30.  8.  5. 10.  7.  9.  4.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 3. 11.  6.  3.  3.] 
adversary cards in discard: [10. 10.  0.  3.  1.  0.  3.  6.  0. 10.  3.  0. 11. 14.  3.  6.  3.  3.
  6.  0. 14.  0.  6.  1.  0. 11.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0] -> size -> 36 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 5.3070454597473145



action possibilites: [-1] 
expected returns: [[82.21177]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15.  1.] 
cards in discard: [25. 25.  0.  0.  3.  1.  1.  0. 29.  3.  1. 29. 29. 25.  0.  3.  3. 29.
  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1 25  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 22. 30. 21. 30.  8.  5. 10.  7.  9.  4.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 3. 11.  6.  3.  3.] 
adversary cards in discard: [10. 10.  0.  3.  1.  0.  3.  6.  0. 10.  3.  0. 11. 14.  3.  6.  3.  3.
  6.  0. 14.  0.  6.  1.  0. 11.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0] -> size -> 36 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 15.725889205932617





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 78.934105]
 [ 91.59103 ]
 [ 83.21412 ]
 [ 44.233063]
 [-14.224266]
 [ 88.400894]
 [ 90.173836]
 [ 78.5613  ]
 [ 92.59481 ]
 [ 89.874825]
 [ 91.945366]
 [ 88.04152 ]
 [ 88.45108 ]
 [ 92.10903 ]
 [ 81.246994]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  1.] 
cards in discard: [25. 25.  0.  0.  3.  1.  1.  0. 29.  3.  1. 29. 29. 25.  0.  3.  3. 29.
  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1 25  1] -> size -> 33 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 22. 30. 21. 30.  8.  5. 10.  7.  9.  4.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 3. 11.  6.  3.  3.] 
adversary cards in discard: [10. 10.  0.  3.  1.  0.  3.  6.  0. 10.  3.  0. 11. 14.  3.  6.  3.  3.
  6.  0. 14.  0.  6.  1.  0. 11.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0] -> size -> 36 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 82.2117691040039



buy possibilites: [-1] 
expected returns: [[2.177967]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  1.] 
cards in discard: [25. 25.  0.  0.  3.  1.  1.  0. 29.  3.  1. 29. 29. 25.  0.  3.  3. 29.
  3. 25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1 25  1 25] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 21. 30.  8.  5. 10.  7.  9.  3.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 3. 11.  6.  3.  3.] 
adversary cards in discard: [10. 10.  0.  3.  1.  0.  3.  6.  0. 10.  3.  0. 11. 14.  3.  6.  3.  3.
  6.  0. 14.  0.  6.  1.  0. 11.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0] -> size -> 36 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0  30   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 315 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 92.59481811523438






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 3. 11.  6.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  6.  3.  3.] 
cards in discard: [10. 10.  0.  3.  1.  0.  3.  6.  0. 10.  3.  0. 11. 14.  3.  6.  3.  3.
  6.  0. 14.  0.  6.  1.  0. 11.  0.  8.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 21. 30.  8.  5. 10.  7.  9.  3.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [29. 29. 29. 25.  1.] 
adversary cards in discard: [25. 25.  0.  0.  3.  1.  1.  0. 29.  3.  1. 29. 29. 25.  0.  3.  3. 29.
  3. 25. 29. 15.  1. 15.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1 25  1 25] -> size -> 34 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 3.] 
cards in discard: [10. 10.  0.  3.  1.  0.  3.  6.  0. 10.  3.  0. 11. 14.  3.  6.  3.  3.
  6.  0. 14.  0.  6.  1.  0. 11.  0.  8.  0.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 21. 30.  8.  5. 10.  7.  8.  3.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [29. 29. 29. 25.  1.] 
adversary cards in discard: [25. 25.  0.  0.  3.  1.  1.  0. 29.  3.  1. 29. 29. 25.  0.  3.  3. 29.
  3. 25. 29. 15.  1. 15.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1 25  1 25] -> size -> 34 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 3.] 
cards in discard: [10. 10.  0.  3.  1.  0.  3.  6.  0. 10.  3.  0. 11. 14.  3.  6.  3.  3.
  6.  0. 14.  0.  6.  1.  0. 11.  0.  8.  0.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 22. 30. 21. 30.  8.  5. 10.  7.  8.  3.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [29. 29. 29. 25.  1.] 
adversary cards in discard: [25. 25.  0.  0.  3.  1.  1.  0. 29.  3.  1. 29. 29. 25.  0.  3.  3. 29.
  3. 25. 29. 15.  1. 15.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1 25  1 25] -> size -> 34 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 3.] 
cards in discard: [10. 10.  0.  3.  1.  0.  3.  6.  0. 10.  3.  0. 11. 14.  3.  6.  3.  3.
  6.  0. 14.  0.  6.  1.  0. 11.  0.  8.  0.  0.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 21. 30.  8.  5. 10.  7.  8.  3.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [29. 29. 29. 25.  1.] 
adversary cards in discard: [25. 25.  0.  0.  3.  1.  1.  0. 29.  3.  1. 29. 29. 25.  0.  3.  3. 29.
  3. 25. 29. 15.  1. 15.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1 25  1 25] -> size -> 34 
adversary victory points: 5
player victory points: 4 





Player: 0 
cards in hand: [29. 29. 29. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29. 25.] 
expected returns: [[16.774296]
 [35.123466]
 [35.123466]
 [35.123466]
 [29.548775]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29. 25.  1.] 
cards in discard: [25. 25.  0.  0.  3.  1.  1.  0. 29.  3.  1. 29. 29. 25.  0.  3.  3. 29.
  3. 25. 29. 15.  1. 15.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1 25  1 25] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 21. 30.  8.  5. 10.  7.  8.  3.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  3.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0] -> size -> 38 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 2.177967071533203



action possibilites: [-1. 29. 29. 25. 25.] 
expected returns: [[11.35541 ]
 [28.880043]
 [28.880043]
 [23.78284 ]
 [23.78284 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 25. 25.] 
cards in discard: [25. 25.  0.  0.  3.  1.  1.  0. 29.  3.  1. 29. 29. 25.  0.  3.  3. 29.
  3. 25. 29. 15.  1. 15.  1.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1 25  1 25] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 22. 30. 21. 30.  8.  5. 10.  7.  8.  3.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  3.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0] -> size -> 38 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 28.70383071899414



action possibilites: [-1. 25. 25.] 
expected returns: [[-11.450306 ]
 [  0.8291297]
 [  0.8291297]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25.  0.] 
cards in discard: [25. 25.  0.  0.  3.  1.  1.  0. 29.  3.  1. 29. 29. 25.  0.  3.  3. 29.
  3. 25. 29. 15.  1. 15.  1.  1. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1 25  1 25] -> size -> 34 
action values: 1 
buys: 0 
player value: 2 
card supply: [21. 22. 30. 21. 30.  8.  5. 10.  7.  8.  3.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  3.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0] -> size -> 38 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 22.948211669921875



action possibilites: [-1] 
expected returns: [[11.019529]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 25. 29.] 
cards in discard: [25. 25.  0.  0.  3.  1.  1.  0. 29.  3.  1. 29. 29. 25.  0.  3.  3. 29.
  3. 25. 29. 15.  1. 15.  1.  1. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1 25  1 25] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 22. 30. 21. 30.  8.  4. 10.  7.  8.  3.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  3.  3. 11.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6] -> size -> 39 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 0.8291068077087402





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[  9.14278 ]
 [ 22.04061 ]
 [ 13.252785]
 [-59.421825]
 [ 19.868235]
 [  8.40929 ]
 [ 17.713453]
 [ 10.466822]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0. 25. 29.] 
cards in discard: [25. 25.  0.  0.  3.  1.  1.  0. 29.  3.  1. 29. 29. 25.  0.  3.  3. 29.
  3. 25. 29. 15.  1. 15.  1.  1. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1 25  1 25] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 22. 30. 21. 30.  8.  4. 10.  7.  8.  3.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  3.  3. 11.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6] -> size -> 39 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1
Learning step: 0
desired expected reward: 11.019529342651367



buy possibilites: [-1] 
expected returns: [[-10.176378]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0. 25. 29.] 
cards in discard: [25. 25.  0.  0.  3.  1.  1.  0. 29.  3.  1. 29. 29. 25.  0.  3.  3. 29.
  3. 25. 29. 15.  1. 15.  1.  1. 29.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1 25  1 25  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 21. 30.  8.  4. 10.  7.  8.  3.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 0.  3.  3. 11.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6] -> size -> 39 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0 54  0] 
sum of rewards: 139 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 22.040632247924805






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 11.  0.] 
cards in discard: [6.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 21. 30.  8.  4. 10.  7.  8.  3.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [25. 29.  1.  3.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1 25  1 25  1] -> size -> 35 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 11.  0.] 
cards in discard: [6.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 21. 30. 21. 30.  8.  4. 10.  7.  8.  3.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [25. 29.  1.  3.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1 25  1 25  1] -> size -> 35 
adversary victory points: 5
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [25. 29.  1.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[-27.350925 ]
 [-12.64566  ]
 [ -6.6936398]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29.  1.  3.  1.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1 25  1 25  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 21. 30.  8.  4. 10.  7.  8.  3.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [ 6.  0.  3.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6] -> size -> 39 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.17637825012207



action possibilites: [-1. 25. 29.] 
expected returns: [[ 6.1335692]
 [21.50838  ]
 [27.278683 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  1. 29.] 
cards in discard: [3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1 25  1 25  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 21. 30. 21. 30.  8.  4. 10.  7.  8.  3.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [ 6.  0.  3.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6] -> size -> 39 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -13.629522323608398



action possibilites: [-1. 29.] 
expected returns: [[ 1.7110972]
 [20.853577 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1. 29.] 
cards in discard: [ 3. 25.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1 25  1 25  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 2 
card supply: [21. 21. 30. 21. 30.  8.  4. 10.  7.  8.  3.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [ 6.  0.  3.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6] -> size -> 39 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 20.35312271118164



action possibilites: [-1.] 
expected returns: [[33.541077]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1.] 
cards in discard: [ 3. 25. 29.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1 25  1 25  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 3 
card supply: [21. 21. 30. 21. 30.  8.  4. 10.  7.  8.  3.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [ 6.  0.  3.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6] -> size -> 39 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 14.488100051879883





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 34.17887   ]
 [ 47.32872   ]
 [  3.5449252 ]
 [ 38.430893  ]
 [  0.92937565]
 [-39.17793   ]
 [ 43.44601   ]
 [ 45.5579    ]
 [ 33.957214  ]
 [ 48.441532  ]
 [ 45.203186  ]
 [ 47.657196  ]
 [ 43.284733  ]
 [ 43.51411   ]
 [ 47.885902  ]
 [ 34.96743   ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1.] 
cards in discard: [ 3. 25. 29.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1 25  1 25  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 7 
card supply: [21. 21. 30. 21. 30.  8.  4. 10.  7.  8.  3.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [ 6.  0.  3.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6] -> size -> 39 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 33.54107666015625



buy possibilites: [-1] 
expected returns: [[-7.8712783]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1.] 
cards in discard: [ 3. 25. 29. 25.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1 25  1 25  1 25] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 21. 30. 21. 30.  8.  4. 10.  7.  8.  2.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [ 6.  0.  3.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6] -> size -> 39 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[ -5.    0.    0.   60.    0.    0.   60.    0.    0.    0.    0.  -10.
   0.    0.   62.5   0. ] 
sum of rewards: 167.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 48.44154357910156






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0.  0.] 
cards in discard: [ 6.  0.  3.  3. 11.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 21. 30.  8.  4. 10.  7.  8.  2.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 3. 15. 29. 29. 15.] 
adversary cards in discard: [ 3. 25. 29. 25. 29. 29. 29.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1 25  1 25  1 25] -> size -> 36 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  0.  0.] 
cards in discard: [ 6.  0.  3.  3. 11.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 21. 30. 21. 30.  8.  4. 10.  7.  8.  2.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 3. 15. 29. 29. 15.] 
adversary cards in discard: [ 3. 25. 29. 25. 29. 29. 29.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1 25  1 25  1 25] -> size -> 36 
adversary victory points: 5
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  0.  0.] 
cards in discard: [ 6.  0.  3.  3. 11.  0.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 21. 30. 20. 30.  8.  4. 10.  7.  8.  2.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 3. 15. 29. 29. 15.] 
adversary cards in discard: [ 3. 25. 29. 25. 29. 29. 29.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1 25  1 25  1 25] -> size -> 36 
adversary victory points: 5
player victory points: 4 





Player: 0 
cards in hand: [ 3. 15. 29. 29. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29. 29. 15.] 
expected returns: [[33.599064]
 [44.256927]
 [49.637154]
 [49.637154]
 [44.256927]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 29. 29. 15.] 
cards in discard: [ 3. 25. 29. 25. 29. 29. 29.  1.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1 25  1 25  1 25] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 20. 30.  8.  4. 10.  7.  8.  2.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 1. 11. 11.  3.  3.] 
adversary cards in discard: [ 6.  0.  3.  3. 11.  0.  3.  3.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6  3] -> size -> 40 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -7.871278285980225



action possibilites: [-1. 15. 15.] 
expected returns: [[15.542736]
 [26.278242]
 [26.278242]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 15.  0.] 
cards in discard: [ 3. 25. 29. 25. 29. 29. 29.  1.  1. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25
 25  3 15 25 25  1  1 25  1 25  1 25] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 21. 30. 20. 30.  8.  4. 10.  7.  8.  2.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 1. 11. 11.  3.  3.] 
adversary cards in discard: [ 6.  0.  3.  3. 11.  0.  3.  3.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6  3] -> size -> 40 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 44.194183349609375



action possibilites: [-1] 
expected returns: [[61.34732]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.] 
cards in discard: [ 3. 25. 29. 25. 29. 29. 29.  1.  1. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25 25
  3 15 25 25  1  1 25  1 25  1 25] -> size -> 35 
action values: 0 
buys: 0 
player value: 4 
card supply: [21. 21. 30. 20. 30.  8.  4. 10.  7.  8.  2.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 1. 11. 11.  3.  3.] 
adversary cards in discard: [ 6.  0.  3.  3. 11.  0.  3.  3.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6  3] -> size -> 40 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 26.27825164794922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[ 60.858704]
 [ 73.37525 ]
 [ 64.29586 ]
 [-11.893475]
 [ 69.37843 ]
 [ 71.26425 ]
 [ 61.173065]
 [ 70.92821 ]
 [ 69.21672 ]
 [ 73.55654 ]
 [ 61.231453]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.] 
cards in discard: [ 3. 25. 29. 25. 29. 29. 29.  1.  1. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25 25
  3 15 25 25  1  1 25  1 25  1 25] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 21. 30. 20. 30.  8.  4. 10.  7.  8.  2.  0.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 1. 11. 11.  3.  3.] 
adversary cards in discard: [ 6.  0.  3.  3. 11.  0.  3.  3.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6  3] -> size -> 40 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 61.347320556640625



buy possibilites: [-1] 
expected returns: [[30.670914]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.] 
cards in discard: [ 3. 25. 29. 25. 29. 29. 29.  1.  1. 29. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25 25
  3 15 25 25  1  1 25  1 25  1 25 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 20. 30.  8.  4. 10.  7.  8.  2.  0.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 1. 11. 11.  3.  3.] 
adversary cards in discard: [ 6.  0.  3.  3. 11.  0.  3.  3.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6  3] -> size -> 40 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0  30   0   0  40   0   0   0   0 -10   0   0 128   0] 
sum of rewards: 183 

action type: buy - action 15.0
Learning step: 0
desired expected reward: 73.55657196044922






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 1. 11. 11.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11. 11.  3.  3.] 
cards in discard: [ 6.  0.  3.  3. 11.  0.  3.  3.  0. 10.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 20. 30.  8.  4. 10.  7.  8.  2.  0.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 1. 25. 25. 29.  3.] 
adversary cards in discard: [ 3. 25. 29. 25. 29. 29. 29.  1.  1. 29. 15. 29. 15.  3. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25 25
  3 15 25 25  1  1 25  1 25  1 25 15] -> size -> 36 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11. 11.  3.  3.] 
cards in discard: [ 6.  0.  3.  3. 11.  0.  3.  3.  0. 10.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6  3] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 21. 30. 20. 30.  8.  4. 10.  7.  8.  2.  0.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 1. 25. 25. 29.  3.] 
adversary cards in discard: [ 3. 25. 29. 25. 29. 29. 29.  1.  1. 29. 15. 29. 15.  3. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25 25
  3 15 25 25  1  1 25  1 25  1 25 15] -> size -> 36 
adversary victory points: 5
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 1. 25. 25. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 29.] 
expected returns: [[43.070656]
 [53.683754]
 [53.683754]
 [57.940258]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25. 25. 29.  3.] 
cards in discard: [ 3. 25. 29. 25. 29. 29. 29.  1.  1. 29. 15. 29. 15.  3. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25 25
  3 15 25 25  1  1 25  1 25  1 25 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 20. 30.  8.  4. 10.  7.  8.  2.  0.  8. 10.  7. 10.  7.] 
adversary cards in hand: [6. 6. 3. 3. 0.] 
adversary cards in discard: [ 6.  0.  3.  3. 11.  0.  3.  3.  0. 10.  0.  0.  1. 11. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6  3] -> size -> 40 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 30.670913696289062



action possibilites: [-1. 25. 25. 25.] 
expected returns: [[18.565361]
 [30.345196]
 [30.345196]
 [30.345196]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25. 25. 25.] 
cards in discard: [ 3. 25. 29. 25. 29. 29. 29.  1.  1. 29. 15. 29. 15.  3. 15.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25 25
  3 15 25 25  1  1 25  1 25  1 25 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 21. 30. 20. 30.  8.  4. 10.  7.  8.  2.  0.  8. 10.  7. 10.  7.] 
adversary cards in hand: [6. 6. 3. 3. 0.] 
adversary cards in discard: [ 6.  0.  3.  3. 11.  0.  3.  3.  0. 10.  0.  0.  1. 11. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6  3] -> size -> 40 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 52.8017463684082



action possibilites: [-1] 
expected returns: [[3.7240958]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25. 25.  1.  0.] 
cards in discard: [ 3. 25. 29. 25. 29. 29. 29.  1.  1. 29. 15. 29. 15.  3. 15.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25 25
  3 15 25 25  1  1 25  1 25  1 25 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 21. 30. 20. 30.  8.  3. 10.  7.  8.  2.  0.  8. 10.  7. 10.  7.] 
adversary cards in hand: [6. 6. 3. 3. 0.] 
adversary cards in discard: [ 6.  0.  3.  3. 11.  0.  3.  3.  0. 10.  0.  0.  1. 11. 11.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6  3  6] -> size -> 41 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 30.345199584960938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[  2.1836538]
 [ 14.518303 ]
 [-27.395626 ]
 [  6.0186057]
 [-30.052923 ]
 [-67.72641  ]
 [ 10.95672  ]
 [ 12.71397  ]
 [  1.9768624]
 [ 15.421766 ]
 [ 12.404278 ]
 [ 14.720732 ]
 [ 10.657551 ]
 [ 10.929586 ]
 [ 14.805378 ]
 [  3.4677262]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 25. 25.  1.  0.] 
cards in discard: [ 3. 25. 29. 25. 29. 29. 29.  1.  1. 29. 15. 29. 15.  3. 15.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25 25
  3 15 25 25  1  1 25  1 25  1 25 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 6 
card supply: [21. 21. 30. 20. 30.  8.  3. 10.  7.  8.  2.  0.  8. 10.  7. 10.  7.] 
adversary cards in hand: [6. 6. 3. 3. 0.] 
adversary cards in discard: [ 6.  0.  3.  3. 11.  0.  3.  3.  0. 10.  0.  0.  1. 11. 11.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6  3  6] -> size -> 41 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 3.7240958213806152



buy possibilites: [-1] 
expected returns: [[-3.6492782]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 25. 25.  1.  0.] 
cards in discard: [ 3. 25. 29. 25. 29. 29. 29.  1.  1. 29. 15. 29. 15.  3. 15.  3. 25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25 25
  3 15 25 25  1  1 25  1 25  1 25 15 25] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 21. 30. 20. 30.  8.  3. 10.  7.  8.  1.  0.  8. 10.  7. 10.  7.] 
adversary cards in hand: [6. 6. 3. 3. 0.] 
adversary cards in discard: [ 6.  0.  3.  3. 11.  0.  3.  3.  0. 10.  0.  0.  1. 11. 11.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6  3  6] -> size -> 41 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[ -5.    0.    0.   30.    0.    0.   40.    0.    0.    0.    0.  -20.
   0.    0.   62.5   0. ] 
sum of rewards: 107.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 15.421760559082031






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [6. 6. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 3. 3. 0.] 
cards in discard: [ 6.  0.  3.  3. 11.  0.  3.  3.  0. 10.  0.  0.  1. 11. 11.  3.  3.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6  3  6] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 20. 30.  8.  3. 10.  7.  8.  1.  0.  8. 10.  7. 10.  7.] 
adversary cards in hand: [25.  0. 29.  1.  0.] 
adversary cards in discard: [ 3. 25. 29. 25. 29. 29. 29.  1.  1. 29. 15. 29. 15.  3. 15.  3. 25. 29.
 25.  1. 25. 25.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25 25
  3 15 25 25  1  1 25  1 25  1 25 15 25] -> size -> 37 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3. 3. 0.] 
cards in discard: [ 6.  0.  3.  3. 11.  0.  3.  3.  0. 10.  0.  0.  1. 11. 11.  3.  3.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6  3  6] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 21. 30. 20. 30.  8.  3. 10.  7.  8.  1.  0.  8. 10.  7. 10.  7.] 
adversary cards in hand: [25.  0. 29.  1.  0.] 
adversary cards in discard: [ 3. 25. 29. 25. 29. 29. 29.  1.  1. 29. 15. 29. 15.  3. 15.  3. 25. 29.
 25.  1. 25. 25.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25 25
  3 15 25 25  1  1 25  1 25  1 25 15 25] -> size -> 37 
adversary victory points: 5
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [25.  0. 29.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[ 7.687386]
 [20.084743]
 [25.191704]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 29.  1.  0.] 
cards in discard: [ 3. 25. 29. 25. 29. 29. 29.  1.  1. 29. 15. 29. 15.  3. 15.  3. 25. 29.
 25.  1. 25. 25.  1.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25 25
  3 15 25 25  1  1 25  1 25  1 25 15 25] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 20. 30.  8.  3. 10.  7.  8.  1.  0.  8. 10.  7. 10.  7.] 
adversary cards in hand: [3. 3. 6. 6. 0.] 
adversary cards in discard: [ 6.  0.  3.  3. 11.  0.  3.  3.  0. 10.  0.  0.  1. 11. 11.  3.  3.  6.
  6.  6.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6  3  6] -> size -> 41 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: -3.649278163909912



action possibilites: [-1. 25. 29.] 
expected returns: [[11.318775]
 [23.716127]
 [28.823093]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0. 29.] 
cards in discard: [ 3. 25. 29. 25. 29. 29. 29.  1.  1. 29. 15. 29. 15.  3. 15.  3. 25. 29.
 25.  1. 25. 25.  1.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25 25
  3 15 25 25  1  1 25  1 25  1 25 15 25] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 21. 30. 20. 30.  8.  3. 10.  7.  8.  1.  0.  8. 10.  7. 10.  7.] 
adversary cards in hand: [3. 3. 6. 6. 0.] 
adversary cards in discard: [ 6.  0.  3.  3. 11.  0.  3.  3.  0. 10.  0.  0.  1. 11. 11.  3.  3.  6.
  6.  6.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6  3  6] -> size -> 41 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 19.27936363220215



action possibilites: [-1.] 
expected returns: [[-16.876337]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3. 25. 29. 25. 29. 29. 29.  1.  1. 29. 15. 29. 15.  3. 15.  3. 25. 29.
 25.  1. 25. 25.  1.  0.  1. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25 25
  3 15 25 25  1  1 25  1 25  1 25 15 25] -> size -> 37 
action values: 1 
buys: 0 
player value: 2 
card supply: [21. 21. 30. 20. 30.  8.  3. 10.  7.  8.  1.  0.  8. 10.  7. 10.  7.] 
adversary cards in hand: [3. 3. 6. 6. 0.] 
adversary cards in discard: [ 6.  0.  3.  3. 11.  0.  3.  3.  0. 10.  0.  0.  1. 11. 11.  3.  3.  6.
  6.  6.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6  3  6] -> size -> 41 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 22.91075897216797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-18.438982 ]
 [ -5.332017 ]
 [-14.539183 ]
 [-48.66756  ]
 [-84.42221  ]
 [ -9.628342 ]
 [ -7.803413 ]
 [-18.926865 ]
 [ -4.479372 ]
 [ -8.1472   ]
 [ -5.3026175]
 [ -9.992406 ]
 [ -9.784222 ]
 [ -5.3435526]
 [-18.06752  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3. 25. 29. 25. 29. 29. 29.  1.  1. 29. 15. 29. 15.  3. 15.  3. 25. 29.
 25.  1. 25. 25.  1.  0.  1. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25 25
  3 15 25 25  1  1 25  1 25  1 25 15 25] -> size -> 37 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 21. 30. 20. 30.  8.  3. 10.  7.  8.  1.  0.  8. 10.  7. 10.  7.] 
adversary cards in hand: [3. 3. 6. 6. 0.] 
adversary cards in discard: [ 6.  0.  3.  3. 11.  0.  3.  3.  0. 10.  0.  0.  1. 11. 11.  3.  3.  6.
  6.  6.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6  3  6] -> size -> 41 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.8763370513916



buy possibilites: [-1] 
expected returns: [[-33.6434]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3. 25. 29. 25. 29. 29. 29.  1.  1. 29. 15. 29. 15.  3. 15.  3. 25. 29.
 25.  1. 25. 25.  1.  0.  1. 25. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25 25
  3 15 25 25  1  1 25  1 25  1 25 15 25 25] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 20. 30.  8.  3. 10.  7.  8.  0.  0.  8. 10.  7. 10.  7.] 
adversary cards in hand: [3. 3. 6. 6. 0.] 
adversary cards in discard: [ 6.  0.  3.  3. 11.  0.  3.  3.  0. 10.  0.  0.  1. 11. 11.  3.  3.  6.
  6.  6.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6  3  6] -> size -> 41 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0  60   0   0  40   0   0   0   0 -30   0   0 250   0] 
sum of rewards: 315 

action type: buy - action 25.0
Learning step: 0
desired expected reward: -4.479365348815918






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [3. 3. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 6. 0.] 
cards in discard: [ 6.  0.  3.  3. 11.  0.  3.  3.  0. 10.  0.  0.  1. 11. 11.  3.  3.  6.
  6.  6.  3.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6  3  6] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 20. 30.  8.  3. 10.  7.  8.  0.  0.  8. 10.  7. 10.  7.] 
adversary cards in hand: [25. 25.  3.  3.  1.] 
adversary cards in discard: [ 3. 25. 29. 25. 29. 29. 29.  1.  1. 29. 15. 29. 15.  3. 15.  3. 25. 29.
 25.  1. 25. 25.  1.  0.  1. 25. 25. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25 25
  3 15 25 25  1  1 25  1 25  1 25 15 25 25] -> size -> 38 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 6. 0.] 
cards in discard: [ 6.  0.  3.  3. 11.  0.  3.  3.  0. 10.  0.  0.  1. 11. 11.  3.  3.  6.
  6.  6.  3.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6  3  6] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 21. 30. 20. 30.  8.  3. 10.  7.  8.  0.  0.  8. 10.  7. 10.  7.] 
adversary cards in hand: [25. 25.  3.  3.  1.] 
adversary cards in discard: [ 3. 25. 29. 25. 29. 29. 29.  1.  1. 29. 15. 29. 15.  3. 15.  3. 25. 29.
 25.  1. 25. 25.  1.  0.  1. 25. 25. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25 25
  3 15 25 25  1  1 25  1 25  1 25 15 25 25] -> size -> 38 
adversary victory points: 5
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [25. 25.  3.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[-18.62961 ]
 [ -6.232258]
 [ -6.232258]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25.  3.  3.  1.] 
cards in discard: [ 3. 25. 29. 25. 29. 29. 29.  1.  1. 29. 15. 29. 15.  3. 15.  3. 25. 29.
 25.  1. 25. 25.  1.  0.  1. 25. 25. 29. 29.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25 25
  3 15 25 25  1  1 25  1 25  1 25 15 25 25] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 20. 30.  8.  3. 10.  7.  8.  0.  0.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 6. 14.  0. 10.  0.] 
adversary cards in discard: [ 6.  0.  3.  3. 11.  0.  3.  3.  0. 10.  0.  0.  1. 11. 11.  3.  3.  6.
  6.  6.  3.  3.  0.  3.  3.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6  3  6] -> size -> 41 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: -33.64339828491211



action possibilites: [-1] 
expected returns: [[36.035606]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  3.  1.  1.  1.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25 25
  3 15 25 25  1  1 25  1 25  1 25 15 25 25] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 20. 30.  8.  2. 10.  7.  8.  0.  0.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 6. 14.  0. 10.  0.] 
adversary cards in discard: [ 6.  0.  3.  3. 11.  0.  3.  3.  0. 10.  0.  0.  1. 11. 11.  3.  3.  6.
  6.  6.  3.  3.  0.  3.  3.  6.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6  3  6  6] -> size -> 42 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -6.232229709625244





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 36.574047 ]
 [ 49.492264 ]
 [  6.383281 ]
 [ 40.491776 ]
 [  4.1403823]
 [-35.016567 ]
 [ 45.514374 ]
 [ 47.42935  ]
 [ 36.388786 ]
 [ 47.089565 ]
 [ 49.659443 ]
 [ 45.260334 ]
 [ 45.47157  ]
 [ 49.803802 ]
 [ 37.284573 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3.  3.  1.  1.  1.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25 25
  3 15 25 25  1  1 25  1 25  1 25 15 25 25] -> size -> 38 
action values: 0 
buys: 1 
player value: 6 
card supply: [21. 21. 30. 20. 30.  8.  2. 10.  7.  8.  0.  0.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 6. 14.  0. 10.  0.] 
adversary cards in discard: [ 6.  0.  3.  3. 11.  0.  3.  3.  0. 10.  0.  0.  1. 11. 11.  3.  3.  6.
  6.  6.  3.  3.  0.  3.  3.  6.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6  3  6  6] -> size -> 42 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 36.035606384277344



buy possibilites: [-1] 
expected returns: [[29.43835]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3.  3.  1.  1.  1.] 
cards in discard: [15.] 
cards in deck: 31 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25 25
  3 15 25 25  1  1 25  1 25  1 25 15 25 25 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 21. 30. 20. 30.  8.  2. 10.  7.  8.  0.  0.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 6. 14.  0. 10.  0.] 
adversary cards in discard: [ 6.  0.  3.  3. 11.  0.  3.  3.  0. 10.  0.  0.  1. 11. 11.  3.  3.  6.
  6.  6.  3.  3.  0.  3.  3.  6.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6  3  6  6] -> size -> 42 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[ -5.   0.   0.  60.   0.   0.  20.   0.   0.   0.   0. -40.   0.   0.
  32.   0.] 
sum of rewards: 67.0 

action type: buy - action 15.0
Learning step: 0
desired expected reward: 49.80378341674805






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [ 6. 14.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.  0. 10.  0.] 
cards in discard: [ 6.  0.  3.  3. 11.  0.  3.  3.  0. 10.  0.  0.  1. 11. 11.  3.  3.  6.
  6.  6.  3.  3.  0.  3.  3.  6.  6.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6  3  6  6] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 20. 30.  8.  2. 10.  7.  8.  0.  0.  8. 10.  7. 10.  6.] 
adversary cards in hand: [25.  3.  0. 25.  1.] 
adversary cards in discard: [15. 25. 25.  3.  3.  1.  1.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25 25
  3 15 25 25  1  1 25  1 25  1 25 15 25 25 15] -> size -> 39 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.  0. 10.  0.] 
cards in discard: [ 6.  0.  3.  3. 11.  0.  3.  3.  0. 10.  0.  0.  1. 11. 11.  3.  3.  6.
  6.  6.  3.  3.  0.  3.  3.  6.  6.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6  3  6  6] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 21. 30. 20. 30.  8.  2. 10.  7.  8.  0.  0.  8. 10.  7. 10.  6.] 
adversary cards in hand: [25.  3.  0. 25.  1.] 
adversary cards in discard: [15. 25. 25.  3.  3.  1.  1.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25 25
  3 15 25 25  1  1 25  1 25  1 25 15 25 25 15] -> size -> 39 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.  0. 10.  0.] 
cards in discard: [ 6.  0.  3.  3. 11.  0.  3.  3.  0. 10.  0.  0.  1. 11. 11.  3.  3.  6.
  6.  6.  3.  3.  0.  3.  3.  6.  6.  0.  6.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6  3  6  6  3] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 19. 30.  8.  2. 10.  7.  8.  0.  0.  8. 10.  7. 10.  6.] 
adversary cards in hand: [25.  3.  0. 25.  1.] 
adversary cards in discard: [15. 25. 25.  3.  3.  1.  1.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25 25
  3 15 25 25  1  1 25  1 25  1 25 15 25 25 15] -> size -> 39 
adversary victory points: 5
player victory points: 3 





Player: 0 
cards in hand: [25.  3.  0. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[27.036783]
 [39.16877 ]
 [39.16877 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0. 25.  1.] 
cards in discard: [15. 25. 25.  3.  3.  1.  1.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25 25
  3 15 25 25  1  1 25  1 25  1 25 15 25 25 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 19. 30.  8.  2. 10.  7.  8.  0.  0.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 0. 14.  0. 10.  0.] 
adversary cards in discard: [ 6.  0.  3.  3. 11.  0.  3.  3.  0. 10.  0.  0.  1. 11. 11.  3.  3.  6.
  6.  6.  3.  3.  0.  3.  3.  6.  6.  0.  6.  3.  6. 14.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6  3  6  6  3] -> size -> 43 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 29.438350677490234



action possibilites: [-1] 
expected returns: [[27.427563]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 25.  1. 25. 15.] 
cards in discard: [15. 25. 25.  3.  3.  1.  1.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25 25
  3 15 25 25  1  1 25  1 25  1 25 15 25 25 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 19. 30.  8.  1. 10.  7.  8.  0.  0.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 0. 14.  0. 10.  0.] 
adversary cards in discard: [ 6.  0.  3.  3. 11.  0.  3.  3.  0. 10.  0.  0.  1. 11. 11.  3.  3.  6.
  6.  6.  3.  3.  0.  3.  3.  6.  6.  0.  6.  3.  6. 14.  0. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6  3  6  6  3  6] -> size -> 44 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 39.16881561279297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 26.281874]
 [ 38.702045]
 [ 29.964504]
 [-44.664623]
 [ 36.617104]
 [ 26.04852 ]
 [ 34.621845]
 [ 27.469929]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 25.  1. 25. 15.] 
cards in discard: [15. 25. 25.  3.  3.  1.  1.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25 25
  3 15 25 25  1  1 25  1 25  1 25 15 25 25 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 21. 30. 19. 30.  8.  1. 10.  7.  8.  0.  0.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 0. 14.  0. 10.  0.] 
adversary cards in discard: [ 6.  0.  3.  3. 11.  0.  3.  3.  0. 10.  0.  0.  1. 11. 11.  3.  3.  6.
  6.  6.  3.  3.  0.  3.  3.  6.  6.  0.  6.  3.  6. 14.  0. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6  3  6  6  3  6] -> size -> 44 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 27.427562713623047



buy possibilites: [-1] 
expected returns: [[17.82008]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 25.  1. 25. 15.] 
cards in discard: [15. 25. 25.  3.  3.  1.  1.  1.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25 25
  3 15 25 25  1  1 25  1 25  1 25 15 25 25 15  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 20. 30. 19. 30.  8.  1. 10.  7.  8.  0.  0.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 0. 14.  0. 10.  0.] 
adversary cards in discard: [ 6.  0.  3.  3. 11.  0.  3.  3.  0. 10.  0.  0.  1. 11. 11.  3.  3.  6.
  6.  6.  3.  3.  0.  3.  3.  6.  6.  0.  6.  3.  6. 14.  0. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6  3  6  6  3  6] -> size -> 44 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0 -50   0   0  54   0] 
sum of rewards: 79 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 38.70204544067383






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 0. 14.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0. 10.  0.] 
cards in discard: [ 6.  0.  3.  3. 11.  0.  3.  3.  0. 10.  0.  0.  1. 11. 11.  3.  3.  6.
  6.  6.  3.  3.  0.  3.  3.  6.  6.  0.  6.  3.  6. 14.  0. 10.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6  3  6  6  3  6] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 20. 30. 19. 30.  8.  1. 10.  7.  8.  0.  0.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 1. 29. 25.  0. 29.] 
adversary cards in discard: [15. 25. 25.  3.  3.  1.  1.  1.  1. 25.  3.  0. 25.  1. 25. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25 25
  3 15 25 25  1  1 25  1 25  1 25 15 25 25 15  1] -> size -> 40 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0. 10.  0.] 
cards in discard: [ 6.  0.  3.  3. 11.  0.  3.  3.  0. 10.  0.  0.  1. 11. 11.  3.  3.  6.
  6.  6.  3.  3.  0.  3.  3.  6.  6.  0.  6.  3.  6. 14.  0. 10.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6  3  6  6  3  6] -> size -> 44 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 20. 30. 19. 30.  8.  1. 10.  7.  8.  0.  0.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 1. 29. 25.  0. 29.] 
adversary cards in discard: [15. 25. 25.  3.  3.  1.  1.  1.  1. 25.  3.  0. 25.  1. 25. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25 25
  3 15 25 25  1  1 25  1 25  1 25 15 25 25 15  1] -> size -> 40 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0. 10.  0.] 
cards in discard: [ 6.  0.  3.  3. 11.  0.  3.  3.  0. 10.  0.  0.  1. 11. 11.  3.  3.  6.
  6.  6.  3.  3.  0.  3.  3.  6.  6.  0.  6.  3.  6. 14.  0. 10.  0.  6.
 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6  3  6  6  3  6 11] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 20. 30. 19. 30.  8.  1. 10.  6.  8.  0.  0.  8. 10.  7. 10.  6.] 
adversary cards in hand: [ 1. 29. 25.  0. 29.] 
adversary cards in discard: [15. 25. 25.  3.  3.  1.  1.  1.  1. 25.  3.  0. 25.  1. 25. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25 25
  3 15 25 25  1  1 25  1 25  1 25 15 25 25 15  1] -> size -> 40 
adversary victory points: 5
player victory points: 2 





Player: 0 
cards in hand: [ 1. 29. 25.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29.] 
expected returns: [[32.95008 ]
 [49.18251 ]
 [44.715378]
 [49.18251 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 25.  0. 29.] 
cards in discard: [15. 25. 25.  3.  3.  1.  1.  1.  1. 25.  3.  0. 25.  1. 25. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25 25
  3 15 25 25  1  1 25  1 25  1 25 15 25 25 15  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 20. 30. 19. 30.  8.  1. 10.  6.  8.  0.  0.  8. 10.  7. 10.  6.] 
adversary cards in hand: [0. 6. 8. 1. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6  3  6  6  3  6 11] -> size -> 45 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 17.820079803466797



action possibilites: [-1. 25.] 
expected returns: [[35.71673 ]
 [46.588318]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 25.] 
cards in discard: [15. 25. 25.  3.  3.  1.  1.  1.  1. 25.  3.  0. 25.  1. 25. 15. 25. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25 25
  3 15 25 25  1  1 25  1 25  1 25 15 25 25 15  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 20. 30. 19. 30.  8.  1. 10.  6.  8.  0.  0.  8. 10.  7. 10.  6.] 
adversary cards in hand: [0. 6. 8. 1. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6  3  6  6  3  6 11] -> size -> 45 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 43.71595764160156



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 8 
Gold: 0 
Estate: 2 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 0 
Chapel: 0 
Witch: 10 
Poacher: 9 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 4 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 1.  0. 25.  0.] 
cards in discard: [15. 25. 25.  3.  3.  1.  1.  1.  1. 25.  3.  0. 25.  1. 25. 15. 25. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3  3  3 29  3  1 29  1 29 29 29 29 29 29 29  1 25 15 25 25
  3 15 25 25  1  1 25  1 25  1 25 15 25 25 15  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 20. 30. 19. 30.  8.  0. 10.  6.  8.  0.  0.  8. 10.  7. 10.  6.] 
adversary cards in hand: [0. 6. 8. 1. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  3  3 11 10  0  3  3 10  8  0  0  1  0  0  0 11 14  3  3  3  6
 14 11  6  3 10  6  0  6  3  6  1  0  8  0  6  3  6  6  3  6 11  6] -> size -> 46 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[     -5 3000000       0      90       0       0      40       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000125 

action type: take_action - action 25.0
Learning step: 120003.140625
desired expected reward: 120049.7265625



