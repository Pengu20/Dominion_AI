 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[108.30445]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [15.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0      -90        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000095 

action type: buy - action -1.0
Learning step: -120004.34375
desired expected reward: -119990.515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 93.01016 ]
 [105.392334]
 [ 99.35862 ]
 [ 81.04013 ]
 [101.76988 ]
 [109.611885]
 [102.71268 ]
 [117.6097  ]
 [ 89.95806 ]
 [ 96.80091 ]
 [102.07755 ]
 [107.14087 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [15.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 110.99820709228516



buy possibilites: [-1] 
expected returns: [[102.67863]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [15.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 117.60967254638672






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [15.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [15.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [15.  0.  0.  0.  0.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[123.81815]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 102.67862701416016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[107.42663 ]
 [121.71134 ]
 [114.96847 ]
 [ 92.73677 ]
 [126.3173  ]
 [118.72103 ]
 [111.99505 ]
 [123.623215]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 125.32587432861328



buy possibilites: [-1] 
expected returns: [[118.918236]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [29.  0.  3.  0.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 126.3172836303711






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [11.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [11.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [11.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [11.  0. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[90.815834]
 [92.79305 ]
 [99.21919 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [11. 15.  3.  3.  0.] 
adversary cards in discard: [8. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 118.9182357788086



action possibilites: [-1. 11.] 
expected returns: [[88.236824]
 [90.26571 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [11. 15.  3.  3.  0.] 
adversary cards in discard: [8. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 101.37230682373047



action possibilites: [-1] 
expected returns: [[91.70417]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11. 15.  3.  3.  0.] 
adversary cards in discard: [8. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 93.93732452392578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[78.72141 ]
 [88.6914  ]
 [83.85779 ]
 [69.095825]
 [85.78973 ]
 [92.00168 ]
 [86.54759 ]
 [98.27602 ]
 [76.33726 ]
 [81.71484 ]
 [86.03986 ]
 [90.06677 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11. 15.  3.  3.  0.] 
adversary cards in discard: [8. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 91.70417022705078



buy possibilites: [-1] 
expected returns: [[100.10157]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11. 15.  3.  3.  0.] 
adversary cards in discard: [8. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 163 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 98.27600860595703






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [11. 15.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15.  3.  3.  0.] 
cards in discard: [8. 0. 0. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  3.] 
cards in discard: [8. 0. 0. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  3.] 
cards in discard: [8. 0. 0. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  3.] 
cards in discard: [8. 0. 0. 0. 0. 3. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  8. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[89.67234]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [10. 29. 29. 11.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  8. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 100.10157012939453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[81.24625 ]
 [91.57981 ]
 [86.71465 ]
 [70.68194 ]
 [94.912926]
 [89.42346 ]
 [84.55821 ]
 [92.99478 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [10. 29. 29. 11.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  8. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 89.38391876220703



buy possibilites: [-1] 
expected returns: [[88.36969]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [10. 29. 29. 11.  0.  0.  0.  3. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  7.  8. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 94.91293334960938






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [ 3. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  7.  8. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [10.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  7.  8. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [10.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  0.  0.] 
cards in discard: [11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  8 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  6.  8. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [10.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [10.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[89.47759]
 [80.76412]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  6.  8. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 8. 3. 8.] 
adversary cards in discard: [11.  3. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  8 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 88.36968994140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[78.072426]
 [88.79728 ]
 [83.75439 ]
 [67.59041 ]
 [92.243546]
 [86.561584]
 [81.518684]
 [90.23217 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  6.  8. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 8. 3. 8.] 
adversary cards in discard: [11.  3. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  8 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 90.78456115722656



buy possibilites: [-1] 
expected returns: [[102.02841]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.  0.] 
cards in discard: [11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  5.  8. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 8. 3. 8.] 
adversary cards in discard: [11.  3. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  8 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 92.2435302734375






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [3. 0. 8. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 3. 8.] 
cards in discard: [11.  3. 11.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  8 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  5.  8. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  0. 29.] 
adversary cards in discard: [11. 10.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 3. 8.] 
cards in discard: [11.  3. 11.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  8 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  5.  8. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  0. 29.] 
adversary cards in discard: [11. 10.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3.  0.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[105.5218  ]
 [113.001465]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 29.] 
cards in discard: [11. 10.  3.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  5.  8. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  8. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  8 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 102.02841186523438



action possibilites: [-1.] 
expected returns: [[127.17892]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11. 10.  3.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  5.  8. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  8. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  8 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 112.45655059814453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[117.66381 ]
 [130.48363 ]
 [124.44953 ]
 [110.37557 ]
 [104.67584 ]
 [126.85352 ]
 [134.61546 ]
 [127.810036]
 [150.60225 ]
 [142.70529 ]
 [114.407   ]
 [126.225365]
 [121.775925]
 [113.47061 ]
 [127.18186 ]
 [132.22313 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11. 10.  3.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  5.  8. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  8. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  8 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 127.17891693115234



buy possibilites: [-1] 
expected returns: [[143.33061]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11. 10.  3.  0.  0.  0. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  5.  8.  9.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  8. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  8 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 265 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 150.6022186279297






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [11.  8. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 15.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  8 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  5.  8.  9.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 11. 11. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25] -> size -> 17 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8. 15.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  8 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  5.  8.  9.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 11. 11. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25] -> size -> 17 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8. 15.  0.  0.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  8 11  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  5.  8.  9.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 11. 11. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25] -> size -> 17 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0. 11. 11. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 29.] 
expected returns: [[76.93034]
 [78.84266]
 [78.84266]
 [85.11661]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11. 29.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  5.  8.  9.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  3.  8.  0. 11.] 
adversary cards in discard: [ 0. 11.  8. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  8 11  0] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 143.3306121826172



action possibilites: [-1. 11. 11. 25.] 
expected returns: [[ 93.72799 ]
 [ 95.469826]
 [ 95.469826]
 [106.73994 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  3. 25.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  5.  8.  9.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  3.  8.  0. 11.] 
adversary cards in discard: [ 0. 11.  8. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  8 11  0] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 85.6871566772461



action possibilites: [-1] 
expected returns: [[125.34431]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8.  9. 10.  5.  8.  9.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  3.  8.  0. 11.] 
adversary cards in discard: [ 0. 11.  8. 15.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  8 11  0  6] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 106.73994445800781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[118.40246 ]
 [128.757   ]
 [123.81294 ]
 [107.85766 ]
 [125.74998 ]
 [132.17548 ]
 [126.54711 ]
 [138.80696 ]
 [115.81193 ]
 [121.65188 ]
 [126.033134]
 [130.21477 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 11.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8.  9. 10.  5.  8.  9.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  3.  8.  0. 11.] 
adversary cards in discard: [ 0. 11.  8. 15.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  8 11  0  6] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 125.34430694580078



buy possibilites: [-1] 
expected returns: [[133.62943]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 11.  3.  0.  0.] 
cards in discard: [29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9. 10.  5.  8.  9.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  3.  8.  0. 11.] 
adversary cards in discard: [ 0. 11.  8. 15.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  8 11  0  6] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 163 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 138.8069610595703






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  8.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  8.  0. 11.] 
cards in discard: [ 0. 11.  8. 15.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  8 11  0  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9. 10.  5.  8.  9.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  3. 10. 29. 11.] 
adversary cards in discard: [29. 29. 25.  0. 11. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29] -> size -> 18 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8. 0.] 
cards in discard: [ 0. 11.  8. 15.  0.  0.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  8 11  0  6  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  5.  8.  9.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  3. 10. 29. 11.] 
adversary cards in discard: [29. 29. 25.  0. 11. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29] -> size -> 18 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 0.] 
cards in discard: [ 0. 11.  8. 15.  0.  0.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  8 11  0  6  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8.  9. 10.  5.  8.  9.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  3. 10. 29. 11.] 
adversary cards in discard: [29. 29. 25.  0. 11. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29] -> size -> 18 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 0.] 
cards in discard: [ 0. 11.  8. 15.  0.  0.  6.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  8 11  0  6  0  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 30. 30.  8.  9. 10.  5.  8.  9.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  3. 10. 29. 11.] 
adversary cards in discard: [29. 29. 25.  0. 11. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29] -> size -> 18 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 3.  3. 10. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11.] 
expected returns: [[92.96512]
 [87.22884]
 [99.16862]
 [94.36135]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10. 29. 11.] 
cards in discard: [29. 29. 25.  0. 11. 11.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8.  9. 10.  5.  8.  9.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  8 11  0  6  0  0] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 133.62942504882812



action possibilites: [-1. 10. 11.] 
expected returns: [[131.29309]
 [122.9049 ]
 [133.23863]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10. 11.  0.] 
cards in discard: [29. 29. 25.  0. 11. 11.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 30. 30.  8.  9. 10.  5.  8.  9.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  8 11  0  6  0  0] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 96.35262298583984



action possibilites: [-1] 
expected returns: [[154.27274]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.  0.] 
cards in discard: [29. 29. 25.  0. 11. 11.  3.  0.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 30. 30.  8.  9. 10.  5.  8.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  8 11  0  6  0  0] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 92 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 138.4931182861328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[145.21408]
 [152.13518]
 [132.6015 ]
 [155.66457]
 [160.3098 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.  0.] 
cards in discard: [29. 29. 25.  0. 11. 11.  3.  0.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 30. 30.  8.  9. 10.  5.  8.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  8 11  0  6  0  0] -> size -> 18 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 154.27273559570312






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  8 11  0  6  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8.  9. 10.  5.  8.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10] -> size -> 19 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  8 11  0  6  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 30. 30.  8.  9. 10.  5.  8.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10] -> size -> 19 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [14.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  8 11  0  6  0  0 14] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8.  9. 10.  5.  8.  9.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10] -> size -> 19 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[85.31937]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8.  9. 10.  5.  8.  9.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0.  8.  3. 15.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  8 11  0  6  0  0 14] -> size -> 19 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 160.309814453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[78.702354]
 [86.55695 ]
 [82.80911 ]
 [70.693535]
 [84.27599 ]
 [89.241684]
 [84.879524]
 [94.51513 ]
 [76.7133  ]
 [81.19591 ]
 [84.48893 ]
 [87.6613  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 30. 30.  8.  9. 10.  5.  8.  9.  7.  9. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0.  8.  3. 15.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  8 11  0  6  0  0 14] -> size -> 19 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 84.7709732055664



buy possibilites: [-1] 
expected returns: [[116.46667]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8.  9. 10.  5.  8.  9.  6.  9. 10.  8. 10.  9.] 
adversary cards in hand: [11.  0.  8.  3. 15.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  8 11  0  6  0  0 14] -> size -> 19 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 153 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 94.51512908935547






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [11.  0.  8.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8.  3. 15.] 
cards in discard: [14.  0.  0.  0.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  8  8 11  0  6  0  0 14] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8.  9. 10.  5.  8.  9.  6.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3. 29. 25.  0.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29] -> size -> 20 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  3.] 
cards in discard: [14.  0.  0.  0.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  8 11  0  6  0  0 14] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 30. 30. 30. 30.  8.  9. 10.  5.  8.  9.  6.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3. 29. 25.  0.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29] -> size -> 20 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  3.] 
cards in discard: [14.  0.  0.  0.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  8 11  0  6  0  0 14] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 30. 30.  8.  9. 10.  5.  8.  9.  6.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3. 29. 25.  0.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29] -> size -> 20 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  3.] 
cards in discard: [14.  0.  0.  0.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  8 11  0  6  0  0 14  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 30. 30. 30. 30.  8.  9. 10.  5.  8.  9.  6.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3. 29. 25.  0.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29] -> size -> 20 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 0.  3. 29. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[135.45973]
 [144.38657]
 [150.87111]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29. 25.  0.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 30.  8.  9. 10.  5.  8.  9.  6.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6. 11.  0.  0.  3.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3.  0. 15. 11.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  8 11  0  6  0  0 14  0] -> size -> 19 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 116.46666717529297



action possibilites: [-1] 
expected returns: [[156.54901]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  0. 11. 29.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 30.  8.  8. 10.  5.  8.  9.  6.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6. 11.  0.  0.  3.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3.  0. 15. 11.  8.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  8 11  0  6  0  0 14  0  6] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 148.09979248046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[147.87244]
 [154.51854]
 [135.4548 ]
 [157.85799]
 [162.24405]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 29.  0. 11. 29.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 30. 30.  8.  8. 10.  5.  8.  9.  6.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 6. 11.  0.  0.  3.] 
adversary cards in discard: [14.  0.  0.  0.  0.  3.  0. 15. 11.  8.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  8 11  0  6  0  0 14  0  6] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 156.54901123046875






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 6. 11.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0.  0.  3.] 
cards in discard: [14.  0.  0.  0.  0.  3.  0. 15. 11.  8.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  8 11  0  6  0  0 14  0  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 30.  8.  8. 10.  5.  8.  9.  6.  9. 10.  8. 10.  9.] 
adversary cards in hand: [11.  3. 10. 10.  0.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0. 25.  0.  3. 29.  0. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29] -> size -> 20 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  0.  0.  3.] 
cards in discard: [14.  0.  0.  0.  0.  3.  0. 15. 11.  8.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  8 11  0  6  0  0 14  0  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 30. 30.  8.  8. 10.  5.  8.  9.  6.  9. 10.  8. 10.  9.] 
adversary cards in hand: [11.  3. 10. 10.  0.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0. 25.  0.  3. 29.  0. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29] -> size -> 20 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  0.  0.  3.] 
cards in discard: [14.  0.  0.  0.  0.  3.  0. 15. 11.  8.  3.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  8 11  0  6  0  0 14  0  6  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 30. 30. 30. 30.  8.  8. 10.  5.  8.  9.  6.  9. 10.  8. 10.  9.] 
adversary cards in hand: [11.  3. 10. 10.  0.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0. 25.  0.  3. 29.  0. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29] -> size -> 20 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [11.  3. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10.] 
expected returns: [[137.96315]
 [140.36952]
 [128.69893]
 [128.69893]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 10. 10.  0.] 
cards in discard: [29.  3.  0.  0.  0.  0. 25.  0.  3. 29.  0. 11. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 30. 30.  8.  8. 10.  5.  8.  9.  6.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  8 11  0  6  0  0 14  0  6  0] -> size -> 21 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 162.2440643310547



action possibilites: [-1] 
expected returns: [[111.25974]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10.  0.] 
cards in discard: [29.  3.  0.  0.  0.  0. 25.  0.  3. 29.  0. 11. 29. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 30. 30.  8.  8. 10.  5.  8.  9.  6.  9. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  8 11  0  6  0  0 14  0  6  0] -> size -> 21 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 102 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 143.5698699951172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 99.56724]
 [ 88.25829]
 [111.99996]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 10.  0.] 
cards in discard: [29.  3.  0.  0.  0.  0. 25.  0.  3. 29.  0. 11. 29. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 30. 30. 30. 30.  8.  8. 10.  5.  8.  9.  6.  9. 10.  7. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  8 11  0  6  0  0 14  0  6  0] -> size -> 21 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 111.2597427368164






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [0. 8. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 11  8  8 11  0  6  0  0 14  0  6  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 30. 30.  8.  8. 10.  5.  8.  9.  6.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 29. 10. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10] -> size -> 21 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 30. 30.  8.  8. 10.  5.  8.  9.  6.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 29. 10. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10] -> size -> 21 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 30. 30. 30. 30.  8.  8. 10.  5.  8.  9.  6.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 29. 10. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10] -> size -> 21 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 0. 29. 10. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 29. 11.] 
expected returns: [[66.88773]
 [71.50386]
 [62.87811]
 [71.50386]
 [67.88813]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10. 29. 11.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 30. 30.  8.  8. 10.  5.  8.  9.  6.  9. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0] -> size -> 19 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 111.99996185302734



action possibilites: [-1. 10. 29. 11.] 
expected returns: [[ 95.14556 ]
 [ 88.265755]
 [102.0226  ]
 [ 96.71702 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 29. 11.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 30. 30.  8.  8. 10.  5.  8.  9.  6.  9. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0] -> size -> 19 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 70.38507843017578



action possibilites: [-1. 10. 11. 11.] 
expected returns: [[104.518776]
 [ 99.16753 ]
 [105.72834 ]
 [105.72834 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  0. 11.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 30. 30. 30. 30.  8.  8. 10.  5.  8.  9.  6.  9. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0] -> size -> 19 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 102.02259063720703



action possibilites: [-1] 
expected returns: [[114.74029]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 11.] 
cards in discard: [10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 30. 30. 30. 30.  8.  8. 10.  5.  8.  9.  6.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0] -> size -> 19 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 142 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 108.98906707763672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[112.33936 ]
 [117.72824 ]
 [115.17125 ]
 [106.773125]
 [116.183975]
 [119.48911 ]
 [116.59101 ]
 [122.78602 ]
 [110.96585 ]
 [114.06298 ]
 [116.32534 ]
 [118.47336 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 11.] 
cards in discard: [10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 30. 30. 30. 30.  8.  8. 10.  5.  8.  9.  6.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0] -> size -> 19 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action -1
Learning step: 0
desired expected reward: 114.74028778076172



buy possibilites: [-1] 
expected returns: [[165.77011]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 11.] 
cards in discard: [10. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 30. 30.  8.  8. 10.  5.  8.  9.  5.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0] -> size -> 19 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 243 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 122.78601837158203






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [8. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 30. 30.  8.  8. 10.  5.  8.  9.  5.  9. 10.  6. 10.  9.] 
adversary cards in hand: [10. 25.  0.  0.  3.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29] -> size -> 23 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [8. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 30. 30. 30. 30.  8.  8. 10.  5.  8.  9.  5.  9. 10.  6. 10.  9.] 
adversary cards in hand: [10. 25.  0.  0.  3.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29] -> size -> 23 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [8. 0. 0. 1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8.  8. 10.  5.  8.  9.  5.  9. 10.  6. 10.  9.] 
adversary cards in hand: [10. 25.  0.  0.  3.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29] -> size -> 23 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [10. 25.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[144.11816]
 [136.17204]
 [157.87288]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25.  0.  0.  3.] 
cards in discard: [10. 29. 29. 29. 11.  0. 10.  0. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8.  8. 10.  5.  8.  9.  5.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 6.  6. 11.  0. 15.] 
adversary cards in discard: [8. 0. 0. 1. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1] -> size -> 20 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 165.77011108398438



action possibilites: [-1] 
expected returns: [[178.48009]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3.  3.  0.] 
cards in discard: [10. 29. 29. 29. 11.  0. 10.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8.  7. 10.  5.  8.  9.  5.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 6.  6. 11.  0. 15.] 
adversary cards in discard: [8. 0. 0. 1. 0. 0. 0. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6] -> size -> 21 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 154.4403533935547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[162.9131 ]
 [174.07886]
 [168.80144]
 [151.61215]
 [177.69133]
 [171.73976]
 [166.46236]
 [175.60054]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.  3.  0.] 
cards in discard: [10. 29. 29. 29. 11.  0. 10.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 30. 30.  8.  7. 10.  5.  8.  9.  5.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 6.  6. 11.  0. 15.] 
adversary cards in discard: [8. 0. 0. 1. 0. 0. 0. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6] -> size -> 21 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 178.48008728027344



buy possibilites: [-1] 
expected returns: [[176.18503]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.  3.  0.] 
cards in discard: [10. 29. 29. 29. 11.  0. 10.  0. 11. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8.  7. 10.  4.  8.  9.  5.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 6.  6. 11.  0. 15.] 
adversary cards in discard: [8. 0. 0. 1. 0. 0. 0. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6] -> size -> 21 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 129 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 177.69134521484375






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 6.  6. 11.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 11.  0. 15.] 
cards in discard: [8. 0. 0. 1. 0. 0. 0. 3. 3. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 30. 30.  8.  7. 10.  4.  8.  9.  5.  9. 10.  6. 10.  9.] 
adversary cards in hand: [10.  0.  3.  0. 29.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0. 10.  0. 11. 11. 25. 10.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11] -> size -> 24 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0. 15.] 
cards in discard: [8. 0. 0. 1. 0. 0. 0. 3. 3. 6. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 30. 30.  8.  7. 10.  4.  8.  9.  5.  9. 10.  6. 10.  9.] 
adversary cards in hand: [10.  0.  3.  0. 29.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0. 10.  0. 11. 11. 25. 10.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11] -> size -> 24 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0. 15.] 
cards in discard: [8. 0. 0. 1. 0. 0. 0. 3. 3. 6. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 29. 30. 30. 30.  8.  7. 10.  4.  8.  9.  5.  9. 10.  6. 10.  9.] 
adversary cards in hand: [10.  0.  3.  0. 29.] 
adversary cards in discard: [10. 29. 29. 29. 11.  0. 10.  0. 11. 11. 25. 10.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11] -> size -> 24 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [10.  0.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[87.83749]
 [81.22813]
 [94.60709]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0. 29.] 
cards in discard: [10. 29. 29. 29. 11.  0. 10.  0. 11. 11. 25. 10.  0.  0.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 30. 30.  8.  7. 10.  4.  8.  9.  5.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 14.  0.] 
adversary cards in discard: [ 8.  0.  0.  1.  0.  0.  0.  3.  3.  6.  0. 11.  6.  6.  0. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0] -> size -> 22 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 176.18502807617188



action possibilites: [-1. 10. 11.] 
expected returns: [[117.55195]
 [109.79941]
 [119.43602]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0. 11.] 
cards in discard: [10. 29. 29. 29. 11.  0. 10.  0. 11. 11. 25. 10.  0.  0.  3.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 30. 30.  8.  7. 10.  4.  8.  9.  5.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 14.  0.] 
adversary cards in discard: [ 8.  0.  0.  1.  0.  0.  0.  3.  3.  6.  0. 11.  6.  6.  0. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0] -> size -> 22 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 94.6070785522461



action possibilites: [-1] 
expected returns: [[102.12296]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [10. 29. 29. 29. 11.  0. 10.  0. 11. 11. 25. 10.  0.  0.  3.  3.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 30. 30.  8.  7. 10.  4.  8.  9.  5.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 14.  0.] 
adversary cards in discard: [ 8.  0.  0.  1.  0.  0.  0.  3.  3.  6.  0. 11.  6.  6.  0. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0] -> size -> 22 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 152 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 124.16727447509766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 92.46158 ]
 [101.129745]
 [ 97.03175 ]
 [ 84.04891 ]
 [103.936935]
 [ 99.3089  ]
 [ 95.228806]
 [102.27971 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [10. 29. 29. 29. 11.  0. 10.  0. 11. 11. 25. 10.  0.  0.  3.  3.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 29. 30. 30. 30.  8.  7. 10.  4.  8.  9.  5.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 14.  0.] 
adversary cards in discard: [ 8.  0.  0.  1.  0.  0.  0.  3.  3.  6.  0. 11.  6.  6.  0. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0] -> size -> 22 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 102.12296295166016



buy possibilites: [-1] 
expected returns: [[129.01884]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [10. 29. 29. 29. 11.  0. 10.  0. 11. 11. 25. 10.  0.  0.  3.  3.  0. 10.
 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 30. 30.  8.  7. 10.  3.  8.  9.  5.  9. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 14.  0.] 
adversary cards in discard: [ 8.  0.  0.  1.  0.  0.  0.  3.  3.  6.  0. 11.  6.  6.  0. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0] -> size -> 22 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 179 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 103.93692016601562






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 14.  0.] 
cards in discard: [ 8.  0.  0.  1.  0.  0.  0.  3.  3.  6.  0. 11.  6.  6.  0. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 30. 30.  8.  7. 10.  3.  8.  9.  5.  9. 10.  5. 10.  9.] 
adversary cards in hand: [11. 10. 29.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11] -> size -> 26 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 14.  0.] 
cards in discard: [ 8.  0.  0.  1.  0.  0.  0.  3.  3.  6.  0. 11.  6.  6.  0. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 29. 30. 30. 30.  8.  7. 10.  3.  8.  9.  5.  9. 10.  5. 10.  9.] 
adversary cards in hand: [11. 10. 29.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11] -> size -> 26 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11. 10. 29.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29. 29.] 
expected returns: [[ 98.00604 ]
 [ 98.99789 ]
 [ 93.667274]
 [102.243454]
 [102.243454]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 29.  0. 29.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 30. 30.  8.  7. 10.  3.  8.  9.  5.  9. 10.  5. 10.  9.] 
adversary cards in hand: [11.  3.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0] -> size -> 22 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 129.0188446044922



action possibilites: [-1. 11. 10. 29. 11.] 
expected returns: [[ 96.38357 ]
 [ 97.39997 ]
 [ 92.266556]
 [100.896355]
 [ 97.39997 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0. 29. 11.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 30. 30.  8.  7. 10.  3.  8.  9.  5.  9. 10.  5. 10.  9.] 
adversary cards in hand: [11.  3.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0] -> size -> 22 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 98.26783752441406



action possibilites: [-1. 11. 10. 11. 10.] 
expected returns: [[124.9692  ]
 [126.07656 ]
 [120.192116]
 [126.07656 ]
 [120.192116]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0. 11. 10.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 2 
card supply: [24. 29. 30. 30. 30.  8.  7. 10.  3.  8.  9.  5.  9. 10.  5. 10.  9.] 
adversary cards in hand: [11.  3.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0] -> size -> 22 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 100.89634704589844



action possibilites: [-1] 
expected returns: [[134.96751]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11. 10.] 
cards in discard: [10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 29. 30. 30. 30.  8.  7. 10.  3.  8.  9.  5.  9. 10.  4. 10.  9.] 
adversary cards in hand: [11.  3.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0] -> size -> 22 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 172 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 128.93331909179688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[130.46878]
 [136.80913]
 [133.7025 ]
 [124.21909]
 [138.98528]
 [135.4333 ]
 [132.40999]
 [137.69998]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11. 10.] 
cards in discard: [10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 29. 30. 30. 30.  8.  7. 10.  3.  8.  9.  5.  9. 10.  4. 10.  9.] 
adversary cards in hand: [11.  3.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0] -> size -> 22 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: take_action - action -1
Learning step: 0
desired expected reward: 134.96751403808594



buy possibilites: [-1] 
expected returns: [[164.91069]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11. 10.] 
cards in discard: [10. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 30. 30.  8.  7. 10.  2.  8.  9.  5.  9. 10.  4. 10.  9.] 
adversary cards in hand: [11.  3.  3.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0] -> size -> 22 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0 54  0] 
sum of rewards: 199 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 138.98529052734375






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [11.  3.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 30. 30.  8.  7. 10.  2.  8.  9.  5.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 11.  0. 10.  3.] 
adversary cards in discard: [10. 11. 29. 29. 11. 10.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11] -> size -> 28 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 29. 30. 30. 30.  8.  7. 10.  2.  8.  9.  5.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 11.  0. 10.  3.] 
adversary cards in discard: [10. 11. 29. 29. 11. 10.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11] -> size -> 28 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  3.  0. 11.] 
cards in discard: [0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 30. 30.  8.  7. 10.  2.  8.  9.  5.  9. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 11.  0. 10.  3.] 
adversary cards in discard: [10. 11. 29. 29. 11. 10.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11] -> size -> 28 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 0. 11.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[97.80863]
 [99.36441]
 [91.64354]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 10.  3.] 
cards in discard: [10. 11. 29. 29. 11. 10.  0. 11. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 30. 30.  8.  7. 10.  2.  8.  9.  5.  9. 10.  4. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [ 0. 11.  3.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0] -> size -> 23 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 164.9106903076172



action possibilites: [-1] 
expected returns: [[81.56964]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3.] 
cards in discard: [10. 11. 29. 29. 11. 10.  0. 11. 10. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 30. 30.  8.  7. 10.  2.  8.  9.  5.  9. 10.  3. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [ 0. 11.  3.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0] -> size -> 23 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 132 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 103.40052032470703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[73.905914]
 [77.72122 ]
 [66.81942 ]
 [79.60758 ]
 [82.0709  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.] 
cards in discard: [10. 11. 29. 29. 11. 10.  0. 11. 10. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 30. 30.  8.  7. 10.  2.  8.  9.  5.  9. 10.  3. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [ 0. 11.  3.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0] -> size -> 23 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 81.56964111328125






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [0. 6. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [ 0. 11.  3.  3.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 30. 30.  8.  7. 10.  2.  8.  9.  5.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  3. 10.] 
adversary cards in discard: [10. 11. 29. 29. 11. 10.  0. 11. 10. 10. 11.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10] -> size -> 29 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [ 0. 11.  3.  3.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 29. 30. 30. 30.  8.  7. 10.  2.  8.  9.  5.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  3. 10.] 
adversary cards in discard: [10. 11. 29. 29. 11. 10.  0. 11. 10. 10. 11.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10] -> size -> 29 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [ 0. 11.  3.  3.  0. 11.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 29. 30. 30. 30.  8.  7. 10.  2.  7.  9.  5.  9. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  3. 10.] 
adversary cards in discard: [10. 11. 29. 29. 11. 10.  0. 11. 10. 10. 11.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10] -> size -> 29 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 0. 29.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[ 95.37904]
 [101.38496]
 [ 89.43815]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  3. 10.] 
cards in discard: [10. 11. 29. 29. 11. 10.  0. 11. 10. 10. 11.  0.  0. 10.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 30. 30.  8.  7. 10.  2.  7.  9.  5.  9. 10.  3. 10.  9.] 
adversary cards in hand: [14.  6.  0.  0.  0.] 
adversary cards in discard: [ 0. 11.  3.  3.  0. 11.  8.  0.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 82.0708999633789



action possibilites: [-1. 10. 29.] 
expected returns: [[ 99.039696]
 [ 91.63767 ]
 [106.67117 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 10. 29.] 
cards in discard: [10. 11. 29. 29. 11. 10.  0. 11. 10. 10. 11.  0.  0. 10.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 30. 30.  8.  7. 10.  2.  7.  9.  5.  9. 10.  3. 10.  9.] 
adversary cards in hand: [14.  6.  0.  0.  0.] 
adversary cards in discard: [ 0. 11.  3.  3.  0. 11.  8.  0.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 101.38494873046875



action possibilites: [-1. 10. 29.] 
expected returns: [[ 98.13392]
 [ 90.52567]
 [105.73072]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 10. 29.] 
cards in discard: [10. 11. 29. 29. 11. 10.  0. 11. 10. 10. 11.  0.  0. 10.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10] -> size -> 29 
action values: 1 
buys: 0 
player value: 2 
card supply: [23. 29. 30. 30. 30.  8.  7. 10.  2.  7.  9.  5.  9. 10.  3. 10.  9.] 
adversary cards in hand: [14.  6.  0.  0.  0.] 
adversary cards in discard: [ 0. 11.  3.  3.  0. 11.  8.  0.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 106.67117309570312



action possibilites: [-1. 10. 11.] 
expected returns: [[92.134674]
 [86.82873 ]
 [93.41072 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 10. 11.] 
cards in discard: [10. 11. 29. 29. 11. 10.  0. 11. 10. 10. 11.  0.  0. 10.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10] -> size -> 29 
action values: 1 
buys: 0 
player value: 3 
card supply: [23. 29. 30. 30. 30.  8.  7. 10.  2.  7.  9.  5.  9. 10.  3. 10.  9.] 
adversary cards in hand: [14.  6.  0.  0.  0.] 
adversary cards in discard: [ 0. 11.  3.  3.  0. 11.  8.  0.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 105.730712890625



action possibilites: [-1] 
expected returns: [[80.00529]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 10.] 
cards in discard: [10. 11. 29. 29. 11. 10.  0. 11. 10. 10. 11.  0.  0. 10.  3. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 29. 30. 30. 30.  8.  7. 10.  2.  7.  9.  5.  9. 10.  2. 10.  9.] 
adversary cards in hand: [14.  6.  0.  0.  0.] 
adversary cards in discard: [ 0. 11.  3.  3.  0. 11.  8.  0.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 80  0  0  0  0  0  0  0 27  0] 
sum of rewards: 192 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 96.56707000732422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[71.69957 ]
 [79.56348 ]
 [75.86313 ]
 [67.14293 ]
 [63.4894  ]
 [77.35474 ]
 [82.08871 ]
 [77.925156]
 [91.4883  ]
 [86.887596]
 [69.66815 ]
 [76.961655]
 [74.22479 ]
 [69.09774 ]
 [77.53207 ]
 [80.59159 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 10.] 
cards in discard: [10. 11. 29. 29. 11. 10.  0. 11. 10. 10. 11.  0.  0. 10.  3. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 29. 30. 30. 30.  8.  7. 10.  2.  7.  9.  5.  9. 10.  2. 10.  9.] 
adversary cards in hand: [14.  6.  0.  0.  0.] 
adversary cards in discard: [ 0. 11.  3.  3.  0. 11.  8.  0.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 80.00528717041016



buy possibilites: [-1] 
expected returns: [[112.04555]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 10.] 
cards in discard: [10. 11. 29. 29. 11. 10.  0. 11. 10. 10. 11.  0.  0. 10.  3. 10. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 30. 30.  8.  7. 10.  2.  7.  8.  5.  9. 10.  2. 10.  9.] 
adversary cards in hand: [14.  6.  0.  0.  0.] 
adversary cards in discard: [ 0. 11.  3.  3.  0. 11.  8.  0.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0  80   0   0   0   0   0   0   0 250   0] 
sum of rewards: 415 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 91.4883041381836






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [14.  6.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6.  0.  0.  0.] 
cards in discard: [ 0. 11.  3.  3.  0. 11.  8.  0.  6.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 30. 30.  8.  7. 10.  2.  7.  8.  5.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  3. 11.  0. 10.] 
adversary cards in discard: [10. 11. 29. 29. 11. 10.  0. 11. 10. 10. 11.  0.  0. 10.  3. 10. 25. 29.
 29. 29. 11.  0.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25] -> size -> 31 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [ 0. 11.  3.  3.  0. 11.  8.  0.  6.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 29. 30. 30. 30.  8.  7. 10.  2.  7.  8.  5.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.] 
adversary cards in discard: [10. 11. 29. 29. 11. 10.  0. 11. 10. 10. 11.  0.  0. 10.  3. 10. 25. 29.
 29. 29. 11.  0.  0.  3. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25] -> size -> 31 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [ 0. 11.  3.  3.  0. 11.  8.  0.  6.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 29. 30. 30. 30.  8.  7. 10.  2.  7.  8.  5.  9. 10.  2. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.] 
adversary cards in discard: [10. 11. 29. 29. 11. 10.  0. 11. 10. 10. 11.  0.  0. 10.  3. 10. 25. 29.
 29. 29. 11.  0.  0.  3. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25] -> size -> 31 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [ 0. 11.  3.  3.  0. 11.  8.  0.  6.  0.  0.  0. 22.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 30. 30.  8.  7. 10.  2.  7.  8.  5.  9. 10.  2.  9.  9.] 
adversary cards in hand: [ 3. 11.  0.] 
adversary cards in discard: [10. 11. 29. 29. 11. 10.  0. 11. 10. 10. 11.  0.  0. 10.  3. 10. 25. 29.
 29. 29. 11.  0.  0.  3. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25] -> size -> 31 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[90.360985]
 [91.60148 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.] 
cards in discard: [10. 11. 29. 29. 11. 10.  0. 11. 10. 10. 11.  0.  0. 10.  3. 10. 25. 29.
 29. 29. 11.  0.  0.  3. 10.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 30. 30.  8.  7. 10.  2.  7.  8.  5.  9. 10.  2.  9.  9.] 
adversary cards in hand: [ 8.  3.  0. 15.  6.] 
adversary cards in discard: [ 0. 11.  3.  3.  0. 11.  8.  0.  6.  0.  0.  0. 22. 14.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22] -> size -> 25 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0   0   0   0   0   0   0   0   0 894   0] 
sum of rewards: 979 

action type: discard_down_to_3_cards - action 0
Learning step: 0
desired expected reward: -12.859183311462402



action possibilites: [-1] 
expected returns: [[64.17356]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [10. 11. 29. 29. 11. 10.  0. 11. 10. 10. 11.  0.  0. 10.  3. 10. 25. 29.
 29. 29. 11.  0.  0.  3. 10.  0. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 30. 30.  8.  7. 10.  2.  7.  8.  5.  9. 10.  1.  9.  9.] 
adversary cards in hand: [ 8.  3.  0. 15.  6.] 
adversary cards in discard: [ 0. 11.  3.  3.  0. 11.  8.  0.  6.  0.  0.  0. 22. 14.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22] -> size -> 25 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 132 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 94.89012145996094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[57.19666 ]
 [51.808796]
 [63.405933]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [10. 11. 29. 29. 11. 10.  0. 11. 10. 10. 11.  0.  0. 10.  3. 10. 25. 29.
 29. 29. 11.  0.  0.  3. 10.  0. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 29. 30. 30. 30.  8.  7. 10.  2.  7.  8.  5.  9. 10.  1.  9.  9.] 
adversary cards in hand: [ 8.  3.  0. 15.  6.] 
adversary cards in discard: [ 0. 11.  3.  3.  0. 11.  8.  0.  6.  0.  0.  0. 22. 14.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22] -> size -> 25 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 64.1735610961914






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 8.  3.  0. 15.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0. 15.  6.] 
cards in discard: [ 0. 11.  3.  3.  0. 11.  8.  0.  6.  0.  0.  0. 22. 14.  6.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 30. 30.  8.  7. 10.  2.  7.  8.  5.  9. 10.  1.  9.  9.] 
adversary cards in hand: [29. 10. 10. 11. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10] -> size -> 32 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  0. 15.  6.] 
cards in discard: [ 0. 11.  3.  3.  0. 11.  8.  0.  6.  0.  0.  0. 22. 14.  6.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 29. 30. 30. 30.  8.  7. 10.  2.  7.  8.  5.  9. 10.  1.  9.  9.] 
adversary cards in hand: [29. 10. 10. 11. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10] -> size -> 32 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  0. 15.  6.] 
cards in discard: [ 0. 11.  3.  3.  0. 11.  8.  0.  6.  0.  0.  0. 22. 14.  6.  0.  0.  0.
  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 29. 30. 30. 30.  8.  7. 10.  2.  7.  8.  5.  9. 10.  1.  9.  9.] 
adversary cards in hand: [29. 10. 10. 11. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10] -> size -> 32 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [29. 10. 10. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10. 11. 25.] 
expected returns: [[ 95.850685]
 [100.43728 ]
 [ 91.127235]
 [ 91.127235]
 [ 96.91676 ]
 [103.78616 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 10. 11. 25.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 30. 30.  8.  7. 10.  2.  7.  8.  5.  9. 10.  1.  9.  9.] 
adversary cards in hand: [ 0.  8. 11.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0] -> size -> 26 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 63.40593338012695



action possibilites: [-1] 
expected returns: [[99.9941]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 10. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 30. 30.  8.  6. 10.  2.  7.  8.  5.  9. 10.  1.  9.  9.] 
adversary cards in hand: [ 0.  8. 11.  0.  1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6] -> size -> 27 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 103.2074966430664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 93.17735]
 [ 96.80341]
 [ 86.75169]
 [ 98.75869]
 [101.46448]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 10. 10. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 29. 30. 30. 30.  8.  6. 10.  2.  7.  8.  5.  9. 10.  1.  9.  9.] 
adversary cards in hand: [ 0.  8. 11.  0.  1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6] -> size -> 27 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 99.99410247802734






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 0.  8. 11.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11.  0.  1.] 
cards in discard: [6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 30. 30.  8.  6. 10.  2.  7.  8.  5.  9. 10.  1.  9.  9.] 
adversary cards in hand: [11. 29.  3. 29.  0.] 
adversary cards in discard: [25. 29. 10. 10. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10] -> size -> 32 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 11.  0.  1.] 
cards in discard: [6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 29. 30. 30. 30.  8.  6. 10.  2.  7.  8.  5.  9. 10.  1.  9.  9.] 
adversary cards in hand: [11. 29.  3. 29.  0.] 
adversary cards in discard: [25. 29. 10. 10. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10] -> size -> 32 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 11.  0.  1.] 
cards in discard: [6. 8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 29. 30. 30. 30.  8.  6. 10.  2.  6.  8.  5.  9. 10.  1.  9.  9.] 
adversary cards in hand: [11. 29.  3. 29.  0.] 
adversary cards in discard: [25. 29. 10. 10. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10] -> size -> 32 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [11. 29.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 29.] 
expected returns: [[ 96.09782 ]
 [ 97.708046]
 [102.965416]
 [102.965416]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  3. 29.  0.] 
cards in discard: [25. 29. 10. 10. 11.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 30. 30.  8.  6. 10.  2.  6.  8.  5.  9. 10.  1.  9.  9.] 
adversary cards in hand: [0. 3. 8. 3. 0.] 
adversary cards in discard: [ 6.  8.  0.  8. 11.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8] -> size -> 28 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 101.4644775390625



action possibilites: [-1. 11. 29.] 
expected returns: [[117.57656]
 [119.4263 ]
 [125.50675]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 29.  0.  3.] 
cards in discard: [25. 29. 10. 10. 11.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 29. 30. 30. 30.  8.  6. 10.  2.  6.  8.  5.  9. 10.  1.  9.  9.] 
adversary cards in hand: [0. 3. 8. 3. 0.] 
adversary cards in discard: [ 6.  8.  0.  8. 11.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8] -> size -> 28 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 102.96541595458984



action possibilites: [-1. 11. 10.] 
expected returns: [[143.63962]
 [145.5428 ]
 [135.31042]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  3. 10.] 
cards in discard: [25. 29. 10. 10. 11.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 2 
card supply: [22. 29. 30. 30. 30.  8.  6. 10.  2.  6.  8.  5.  9. 10.  1.  9.  9.] 
adversary cards in hand: [0. 3. 8. 3. 0.] 
adversary cards in discard: [ 6.  8.  0.  8. 11.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8] -> size -> 28 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 125.5067367553711



action possibilites: [-1] 
expected returns: [[127.555626]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 10.] 
cards in discard: [25. 29. 10. 10. 11.  0.  0. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 29. 30. 30. 30.  8.  6. 10.  2.  6.  8.  5.  9. 10.  0.  9.  9.] 
adversary cards in hand: [0. 3. 8. 3. 0.] 
adversary cards in discard: [ 6.  8.  0.  8. 11.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8] -> size -> 28 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0  27   0] 
sum of rewards: 202 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 150.54078674316406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[113.52376 ]
 [126.10018 ]
 [120.15516 ]
 [102.593285]
 [130.17114 ]
 [123.46407 ]
 [127.82484 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 10.] 
cards in discard: [25. 29. 10. 10. 11.  0.  0. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 29. 30. 30. 30.  8.  6. 10.  2.  6.  8.  5.  9. 10.  0.  9.  9.] 
adversary cards in hand: [0. 3. 8. 3. 0.] 
adversary cards in discard: [ 6.  8.  0.  8. 11.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8] -> size -> 28 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1
Learning step: 0
desired expected reward: 127.55562591552734



buy possibilites: [-1] 
expected returns: [[91.25283]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 10.] 
cards in discard: [25. 29. 10. 10. 11.  0.  0. 10. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 30. 30.  8.  6. 10.  1.  6.  8.  5.  9. 10.  0.  9.  9.] 
adversary cards in hand: [0. 3. 8. 3. 0.] 
adversary cards in discard: [ 6.  8.  0.  8. 11.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8] -> size -> 28 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0  54   0] 
sum of rewards: 229 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 130.17111206054688






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [0. 3. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 3. 0.] 
cards in discard: [ 6.  8.  0.  8. 11.  0.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 30. 30.  8.  6. 10.  1.  6.  8.  5.  9. 10.  0.  9.  9.] 
adversary cards in hand: [10.  0. 10. 11. 29.] 
adversary cards in discard: [25. 29. 10. 10. 11.  0.  0. 10. 11. 29. 29. 11.  3.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11] -> size -> 34 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 3. 0.] 
cards in discard: [ 6.  8.  0.  8. 11.  0.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 29. 30. 30. 30.  8.  6. 10.  1.  6.  8.  5.  9. 10.  0.  9.  9.] 
adversary cards in hand: [10.  0. 10. 11. 29.] 
adversary cards in discard: [25. 29. 10. 10. 11.  0.  0. 10. 11. 29. 29. 11.  3.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11] -> size -> 34 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 3. 0.] 
cards in discard: [ 6.  8.  0.  8. 11.  0.  1.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 30. 30.  8.  6. 10.  1.  5.  8.  5.  9. 10.  0.  9.  9.] 
adversary cards in hand: [10.  0. 10. 11. 29.] 
adversary cards in discard: [25. 29. 10. 10. 11.  0.  0. 10. 11. 29. 29. 11.  3.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11] -> size -> 34 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [10.  0. 10. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11. 29.] 
expected returns: [[61.429157]
 [56.41507 ]
 [56.41507 ]
 [62.621502]
 [66.44208 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10. 11. 29.] 
cards in discard: [25. 29. 10. 10. 11.  0.  0. 10. 11. 29. 29. 11.  3.  0.  3. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 30. 30.  8.  6. 10.  1.  5.  8.  5.  9. 10.  0.  9.  9.] 
adversary cards in hand: [0. 6. 3. 0. 6.] 
adversary cards in discard: [ 6.  8.  0.  8. 11.  0.  1.  8.  0.  3.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8  8] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 91.2528305053711



action possibilites: [-1. 10. 10. 10.] 
expected returns: [[62.000195]
 [54.204983]
 [54.204983]
 [54.204983]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10. 10.] 
cards in discard: [25. 29. 10. 10. 11.  0.  0. 10. 11. 29. 29. 11.  3.  0.  3. 10. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 29. 30. 30. 30.  8.  6. 10.  1.  5.  8.  5.  9. 10.  0.  9.  9.] 
adversary cards in hand: [0. 6. 3. 0. 6.] 
adversary cards in discard: [ 6.  8.  0.  8. 11.  0.  1.  8.  0.  3.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8  8] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 60.620670318603516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[51.29142 ]
 [56.296417]
 [41.7776  ]
 [58.817436]
 [62.11459 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10. 10.] 
cards in discard: [25. 29. 10. 10. 11.  0.  0. 10. 11. 29. 29. 11.  3.  0.  3. 10. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 29. 30. 30. 30.  8.  6. 10.  1.  5.  8.  5.  9. 10.  0.  9.  9.] 
adversary cards in hand: [0. 6. 3. 0. 6.] 
adversary cards in discard: [ 6.  8.  0.  8. 11.  0.  1.  8.  0.  3.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8  8] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 62.00019454956055






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [0. 6. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 0. 6.] 
cards in discard: [ 6.  8.  0.  8. 11.  0.  1.  8.  0.  3.  8.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 30. 30.  8.  6. 10.  1.  5.  8.  5.  9. 10.  0.  9.  9.] 
adversary cards in hand: [29. 10. 25.  3. 10.] 
adversary cards in discard: [25. 29. 10. 10. 11.  0.  0. 10. 11. 29. 29. 11.  3.  0.  3. 10. 11. 29.
 10.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11] -> size -> 34 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 6.] 
cards in discard: [ 6.  8.  0.  8. 11.  0.  1.  8.  0.  3.  8.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8  8] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 29. 30. 30. 30.  8.  6. 10.  1.  5.  8.  5.  9. 10.  0.  9.  9.] 
adversary cards in hand: [29. 10. 25.  3. 10.] 
adversary cards in discard: [25. 29. 10. 10. 11.  0.  0. 10. 11. 29. 29. 11.  3.  0.  3. 10. 11. 29.
 10.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11] -> size -> 34 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 6.] 
cards in discard: [ 6.  8.  0.  8. 11.  0.  1.  8.  0.  3.  8.  3.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8  8  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 29. 30. 30. 30.  8.  6. 10.  1.  5.  8.  5.  9. 10.  0.  9.  9.] 
adversary cards in hand: [29. 10. 25.  3. 10.] 
adversary cards in discard: [25. 29. 10. 10. 11.  0.  0. 10. 11. 29. 29. 11.  3.  0.  3. 10. 11. 29.
 10.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11] -> size -> 34 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [29. 10. 25.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 25. 10.] 
expected returns: [[55.480778]
 [61.92033 ]
 [49.1398  ]
 [67.53652 ]
 [49.1398  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 25.  3. 10.] 
cards in discard: [25. 29. 10. 10. 11.  0.  0. 10. 11. 29. 29. 11.  3.  0.  3. 10. 11. 29.
 10.  0. 10. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 30. 30.  8.  6. 10.  1.  5.  8.  5.  9. 10.  0.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 22. 14.] 
adversary cards in discard: [ 6.  8.  0.  8. 11.  0.  1.  8.  0.  3.  8.  3.  0.  0.  0.  6.  3.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8  8  0] -> size -> 30 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 62.11458969116211



action possibilites: [-1] 
expected returns: [[9.847164]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  3. 10.  0. 10.] 
cards in discard: [25. 29. 10. 10. 11.  0.  0. 10. 11. 29. 29. 11.  3.  0.  3. 10. 11. 29.
 10.  0. 10. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 30. 30.  8.  5. 10.  1.  5.  8.  5.  9. 10.  0.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 22. 14.] 
adversary cards in discard: [ 6.  8.  0.  8. 11.  0.  1.  8.  0.  3.  8.  3.  0.  0.  0.  6.  3.  0.
  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8  8  0  6] -> size -> 31 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 67.5365219116211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[4.8230686]
 [2.6467428]
 [8.924533 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 10.  3. 10.  0. 10.] 
cards in discard: [25. 29. 10. 10. 11.  0.  0. 10. 11. 29. 29. 11.  3.  0.  3. 10. 11. 29.
 10.  0. 10. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 29. 30. 30. 30.  8.  5. 10.  1.  5.  8.  5.  9. 10.  0.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 22. 14.] 
adversary cards in discard: [ 6.  8.  0.  8. 11.  0.  1.  8.  0.  3.  8.  3.  0.  0.  0.  6.  3.  0.
  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8  8  0  6] -> size -> 31 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 9.847164154052734






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 22. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 22. 14.] 
cards in discard: [ 6.  8.  0.  8. 11.  0.  1.  8.  0.  3.  8.  3.  0.  0.  0.  6.  3.  0.
  6.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8  8  0  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 30. 30.  8.  5. 10.  1.  5.  8.  5.  9. 10.  0.  9.  9.] 
adversary cards in hand: [11. 11.  0.  0. 11.] 
adversary cards in discard: [25. 29. 10. 10. 11.  0.  0. 10. 11. 29. 29. 11.  3.  0.  3. 10. 11. 29.
 10.  0. 10. 10. 25. 29. 10.  3. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11] -> size -> 34 
adversary victory points: 3
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 22.] 
cards in discard: [ 6.  8.  0.  8. 11.  0.  1.  8.  0.  3.  8.  3.  0.  0.  0.  6.  3.  0.
  6.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8  8  0  6] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 29. 30. 30. 30.  8.  5. 10.  1.  5.  8.  5.  9. 10.  0.  9.  9.] 
adversary cards in hand: [11.  0. 11.] 
adversary cards in discard: [25. 29. 10. 10. 11.  0.  0. 10. 11. 29. 29. 11.  3.  0.  3. 10. 11. 29.
 10.  0. 10. 10. 25. 29. 10.  3. 10.  0. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11] -> size -> 34 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 22.] 
cards in discard: [ 6.  8.  0.  8. 11.  0.  1.  8.  0.  3.  8.  3.  0.  0.  0.  6.  3.  0.
  6.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8  8  0  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 29. 30. 30. 30.  8.  5. 10.  1.  5.  8.  5.  9. 10.  0.  9.  9.] 
adversary cards in hand: [11.  0. 11.] 
adversary cards in discard: [25. 29. 10. 10. 11.  0.  0. 10. 11. 29. 29. 11.  3.  0.  3. 10. 11. 29.
 10.  0. 10. 10. 25. 29. 10.  3. 10.  0. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11] -> size -> 34 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 22.] 
cards in discard: [ 6.  8.  0.  8. 11.  0.  1.  8.  0.  3.  8.  3.  0.  0.  0.  6.  3.  0.
  6.  6. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8  8  0  6 14] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 30. 30.  8.  5. 10.  1.  5.  8.  5.  8. 10.  0.  9.  9.] 
adversary cards in hand: [11.  0. 11.] 
adversary cards in discard: [25. 29. 10. 10. 11.  0.  0. 10. 11. 29. 29. 11.  3.  0.  3. 10. 11. 29.
 10.  0. 10. 10. 25. 29. 10.  3. 10.  0. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11] -> size -> 34 
adversary victory points: 3
player victory points: -2 





Player: 0 
cards in hand: [11.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[10.622207]
 [11.326288]
 [11.326288]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11.] 
cards in discard: [25. 29. 10. 10. 11.  0.  0. 10. 11. 29. 29. 11.  3.  0.  3. 10. 11. 29.
 10.  0. 10. 10. 25. 29. 10.  3. 10.  0. 10.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 30. 30.  8.  5. 10.  1.  5.  8.  5.  8. 10.  0.  9.  9.] 
adversary cards in hand: [ 0.  0. 11.  6.  0.] 
adversary cards in discard: [ 6.  8.  0.  8. 11.  0.  1.  8.  0.  3.  8.  3.  0.  0.  0.  6.  3.  0.
  6.  6. 14. 14.  0.  0.  0. 22.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8  8  0  6 14] -> size -> 32 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0 975   0] 
sum of rewards: 1120 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 3.213571548461914



action possibilites: [-1] 
expected returns: [[6.2270527]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.] 
cards in discard: [25. 29. 10. 10. 11.  0.  0. 10. 11. 29. 29. 11.  3.  0.  3. 10. 11. 29.
 10.  0. 10. 10. 25. 29. 10.  3. 10.  0. 10.  0. 11. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 30. 30.  8.  5. 10.  1.  5.  8.  5.  8. 10.  0.  9.  8.] 
adversary cards in hand: [ 0.  0. 11.  6.  0.] 
adversary cards in discard: [ 6.  8.  0.  8. 11.  0.  1.  8.  0.  3.  8.  3.  0.  0.  0.  6.  3.  0.
  6.  6. 14. 14.  0.  0.  0. 22.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8  8  0  6 14] -> size -> 32 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 229 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 13.069748878479004





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 1.3962216]
 [-1.5686018]
 [ 5.3025484]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.] 
cards in discard: [25. 29. 10. 10. 11.  0.  0. 10. 11. 29. 29. 11.  3.  0.  3. 10. 11. 29.
 10.  0. 10. 10. 25. 29. 10.  3. 10.  0. 10.  0. 11. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 29. 30. 30. 30.  8.  5. 10.  1.  5.  8.  5.  8. 10.  0.  9.  8.] 
adversary cards in hand: [ 0.  0. 11.  6.  0.] 
adversary cards in discard: [ 6.  8.  0.  8. 11.  0.  1.  8.  0.  3.  8.  3.  0.  0.  0.  6.  3.  0.
  6.  6. 14. 14.  0.  0.  0. 22.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8  8  0  6 14] -> size -> 32 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 6.227052688598633






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 11.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  6.  0.] 
cards in discard: [ 6.  8.  0.  8. 11.  0.  1.  8.  0.  3.  8.  3.  0.  0.  0.  6.  3.  0.
  6.  6. 14. 14.  0.  0.  0. 22.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8  8  0  6 14] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 30. 30.  8.  5. 10.  1.  5.  8.  5.  8. 10.  0.  9.  8.] 
adversary cards in hand: [ 3.  0. 15. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15] -> size -> 35 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  6.  0.] 
cards in discard: [ 6.  8.  0.  8. 11.  0.  1.  8.  0.  3.  8.  3.  0.  0.  0.  6.  3.  0.
  6.  6. 14. 14.  0.  0.  0. 22.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8  8  0  6 14] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 29. 30. 30. 30.  8.  5. 10.  1.  5.  8.  5.  8. 10.  0.  9.  8.] 
adversary cards in hand: [ 3.  0. 15. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15] -> size -> 35 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  6.  0.] 
cards in discard: [ 6.  8.  0.  8. 11.  0.  1.  8.  0.  3.  8.  3.  0.  0.  0.  6.  3.  0.
  6.  6. 14. 14.  0.  0.  0. 22.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8  8  0  6 14  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 29. 30.  8.  5. 10.  1.  5.  8.  5.  8. 10.  0.  9.  8.] 
adversary cards in hand: [ 3.  0. 15. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15] -> size -> 35 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [ 3.  0. 15. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29. 11.] 
expected returns: [[79.32749]
 [77.15164]
 [83.70531]
 [80.34614]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15. 29. 11.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 29. 30.  8.  5. 10.  1.  5.  8.  5.  8. 10.  0.  9.  8.] 
adversary cards in hand: [14. 22.  0.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8  8  0  6 14  3] -> size -> 33 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 5.302534103393555



action possibilites: [-1. 15. 11.] 
expected returns: [[118.31951 ]
 [115.73413 ]
 [119.528336]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 11.  0.] 
cards in discard: [3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 29. 30.  8.  5. 10.  1.  5.  8.  5.  8. 10.  0.  9.  8.] 
adversary cards in hand: [14. 22.  0.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8  8  0  6 14  3] -> size -> 33 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 78.56600952148438



action possibilites: [-1] 
expected returns: [[126.8254]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.] 
cards in discard: [ 3. 15.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 29. 30.  8.  5. 10.  1.  5.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [14. 22.  0.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8  8  0  6 14  3] -> size -> 33 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0 -10   0   0  64   0] 
sum of rewards: 209 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 122.62000274658203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[119.03537 ]
 [126.02982 ]
 [122.7433  ]
 [111.74253 ]
 [128.28209 ]
 [124.574165]
 [126.983635]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0.] 
cards in discard: [ 3. 15.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 29. 30. 29. 30.  8.  5. 10.  1.  5.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [14. 22.  0.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8  8  0  6 14  3] -> size -> 33 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: 126.82540130615234



buy possibilites: [-1] 
expected returns: [[118.39495]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0.] 
cards in discard: [ 3. 15. 11.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 29. 30.  8.  5. 10.  0.  5.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [14. 22.  0.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8  8  0  6 14  3] -> size -> 33 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0 -20   0   0  54   0] 
sum of rewards: 189 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 128.28207397460938






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [14. 22.  0.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 22.  8. 15.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 22.  0.  8. 15.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8  8  0  6 14  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 29. 30.  8.  5. 10.  0.  5.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [29. 10.  0. 11.  0.] 
adversary cards in discard: [ 3. 15. 11. 29. 11.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11] -> size -> 37 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  0.  8. 15.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8  8  0  6 14  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 29. 30. 29. 30.  8.  5. 10.  0.  5.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [29. 10. 11.] 
adversary cards in discard: [ 3. 15. 11. 29. 11.  0. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11] -> size -> 37 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  0.  8. 15.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8  8  0  6 14  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 29. 30. 29. 30.  8.  5. 10.  0.  5.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [29. 10. 11.] 
adversary cards in discard: [ 3. 15. 11. 29. 11.  0. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11] -> size -> 37 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  0.  8. 15.] 
cards in discard: [1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8  8  0  6 14  3  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 29. 30.  8.  5. 10.  0.  5.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [29. 10. 11.] 
adversary cards in discard: [ 3. 15. 11. 29. 11.  0. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11] -> size -> 37 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [29. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 11.] 
expected returns: [[ 93.99465 ]
 [102.27229 ]
 [ 86.548454]
 [ 95.93017 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 11.] 
cards in discard: [ 3. 15. 11. 29. 11.  0. 15.  0.  0.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 29. 30.  8.  5. 10.  0.  5.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [ 6.  0.  1.  0. 11.] 
adversary cards in discard: [ 1. 14. 22.  0.  8. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8  8  0  6 14  3  1] -> size -> 34 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[  -5    0    0  120    0    0    0    0    0    0    0  -20    0    0
 1066    0] 
sum of rewards: 1161 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -9.045723915100098



action possibilites: [-1. 11.] 
expected returns: [[ 99.03698]
 [101.24128]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [ 3. 15. 11. 29. 11.  0. 15.  0.  0.  0. 10.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 28. 30. 29. 30.  8.  5. 10.  0.  5.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [ 6.  0.  1.  0. 11.] 
adversary cards in discard: [ 1. 14. 22.  0.  8. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8  8  0  6 14  3  1] -> size -> 34 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 92.64448547363281



action possibilites: [-1] 
expected returns: [[84.03268]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 3. 15. 11. 29. 11.  0. 15.  0.  0.  0. 10.  0.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 27. 30. 29. 30.  8.  5. 10.  0.  5.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [ 6.  0.  1.  0. 11.] 
adversary cards in discard: [ 1. 14. 22.  0.  8. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8  8  0  6 14  3  1] -> size -> 34 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0 -30   0   0  27   0] 
sum of rewards: 152 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 97.46515655517578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[74.656166]
 [66.12553 ]
 [84.19776 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3. 15. 11. 29. 11.  0. 15.  0.  0.  0. 10.  0.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 27. 30. 29. 30.  8.  5. 10.  0.  5.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [ 6.  0.  1.  0. 11.] 
adversary cards in discard: [ 1. 14. 22.  0.  8. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8  8  0  6 14  3  1] -> size -> 34 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: 84.03267669677734






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 6.  0.  1.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  1.  0. 11.] 
cards in discard: [ 1. 14. 22.  0.  8. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8  8  0  6 14  3  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 29. 30.  8.  5. 10.  0.  5.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [11. 29. 25. 10. 11.] 
adversary cards in discard: [ 3. 15. 11. 29. 11.  0. 15.  0.  0.  0. 10.  0.  1. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1] -> size -> 38 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  1.  0. 11.] 
cards in discard: [ 1. 14. 22.  0.  8. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8  8  0  6 14  3  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 27. 30. 29. 30.  8.  5. 10.  0.  5.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [11. 29. 25. 10. 11.] 
adversary cards in discard: [ 3. 15. 11. 29. 11.  0. 15.  0.  0.  0. 10.  0.  1. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1] -> size -> 38 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  1.  0. 11.] 
cards in discard: [ 1. 14. 22.  0.  8. 15.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8  8  0  6 14  3  1  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 29. 30.  8.  5. 10.  0.  5.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [11. 29. 25. 10. 11.] 
adversary cards in discard: [ 3. 15. 11. 29. 11.  0. 15.  0.  0.  0. 10.  0.  1. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1] -> size -> 38 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [11. 29. 25. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 25. 10. 11.] 
expected returns: [[ 99.13525 ]
 [100.97767 ]
 [107.00184 ]
 [112.778206]
 [ 91.10455 ]
 [100.97767 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 25. 10. 11.] 
cards in discard: [ 3. 15. 11. 29. 11.  0. 15.  0.  0.  0. 10.  0.  1. 29. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 29. 30.  8.  5. 10.  0.  5.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [0. 8. 0. 6. 0.] 
adversary cards in discard: [ 1. 14. 22.  0.  8. 15.  1.  6.  0.  1.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8  8  0  6 14  3  1  1] -> size -> 35 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 84.19775390625



action possibilites: [-1] 
expected returns: [[89.069145]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 10. 11.  0. 10.] 
cards in discard: [ 3. 15. 11. 29. 11.  0. 15.  0.  0.  0. 10.  0.  1. 29. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 29. 30.  8.  4. 10.  0.  5.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [0. 8. 0. 6. 0.] 
adversary cards in discard: [ 1. 14. 22.  0.  8. 15.  1.  6.  0.  1.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8  8  0  6 14  3  1  1  6] -> size -> 36 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 112.7781982421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[78.90992 ]
 [70.413605]
 [89.19157 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29. 10. 11.  0. 10.] 
cards in discard: [ 3. 15. 11. 29. 11.  0. 15.  0.  0.  0. 10.  0.  1. 29. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 26. 30. 29. 30.  8.  4. 10.  0.  5.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [0. 8. 0. 6. 0.] 
adversary cards in discard: [ 1. 14. 22.  0.  8. 15.  1.  6.  0.  1.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8  8  0  6 14  3  1  1  6] -> size -> 36 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 89.06914520263672






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [0. 8. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 6. 0.] 
cards in discard: [ 1. 14. 22.  0.  8. 15.  1.  6.  0.  1.  0. 11.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8
 22  0  6  8  8  0  6 14  3  1  1  6] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 29. 30.  8.  4. 10.  0.  5.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [ 3. 29. 11. 10. 25.] 
adversary cards in discard: [ 3. 15. 11. 29. 11.  0. 15.  0.  0.  0. 10.  0.  1. 29. 11. 25. 11. 29.
 10. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1] -> size -> 38 
adversary victory points: 3
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0.] 
cards in discard: [ 1. 14. 22.  0.  8. 15.  1.  6.  0.  1.  0. 11.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8 22
  0  6  8  8  0  6 14  3  1  1  6] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 29. 30.  8.  4. 10.  0.  5.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [ 3. 29. 11. 10. 25.] 
adversary cards in discard: [ 3. 15. 11. 29. 11.  0. 15.  0.  0.  0. 10.  0.  1. 29. 11. 25. 11. 29.
 10. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1] -> size -> 38 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0.] 
cards in discard: [ 1. 14. 22.  0.  8. 15.  1.  6.  0.  1.  0. 11.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8 22
  0  6  8  8  0  6 14  3  1  1  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 26. 30. 29. 30.  8.  4. 10.  0.  5.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [ 3. 29. 11. 10. 25.] 
adversary cards in discard: [ 3. 15. 11. 29. 11.  0. 15.  0.  0.  0. 10.  0.  1. 29. 11. 25. 11. 29.
 10. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1] -> size -> 38 
adversary victory points: 3
player victory points: -2 





Player: 0 
cards in hand: [ 3. 29. 11. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 10. 25.] 
expected returns: [[40.88954 ]
 [45.10484 ]
 [41.89885 ]
 [36.686028]
 [48.144535]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 11. 10. 25.] 
cards in discard: [ 3. 15. 11. 29. 11.  0. 15.  0.  0.  0. 10.  0.  1. 29. 11. 25. 11. 29.
 10. 11.  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 29. 30.  8.  4. 10.  0.  5.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [0. 3. 3. 3. 6.] 
adversary cards in discard: [ 1. 14. 22.  0.  8. 15.  1.  6.  0.  1.  0. 11.  6.  8.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8 22
  0  6  8  8  0  6 14  3  1  1  6] -> size -> 35 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 89.19155883789062



action possibilites: [-1] 
expected returns: [[32.763813]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 11. 10. 29. 10.] 
cards in discard: [ 3. 15. 11. 29. 11.  0. 15.  0.  0.  0. 10.  0.  1. 29. 11. 25. 11. 29.
 10. 11.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 29. 30.  8.  3. 10.  0.  5.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [0. 3. 3. 3. 6.] 
adversary cards in discard: [ 1. 14. 22.  0.  8. 15.  1.  6.  0.  1.  0. 11.  6.  8.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8 22
  0  6  8  8  0  6 14  3  1  1  6  6] -> size -> 36 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 48.14453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[27.604286]
 [23.922813]
 [32.46446 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29. 11. 10. 29. 10.] 
cards in discard: [ 3. 15. 11. 29. 11.  0. 15.  0.  0.  0. 10.  0.  1. 29. 11. 25. 11. 29.
 10. 11.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 26. 30. 29. 30.  8.  3. 10.  0.  5.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [0. 3. 3. 3. 6.] 
adversary cards in discard: [ 1. 14. 22.  0.  8. 15.  1.  6.  0.  1.  0. 11.  6.  8.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8 22
  0  6  8  8  0  6 14  3  1  1  6  6] -> size -> 36 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 32.76381301879883






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 6.] 
cards in discard: [ 1. 14. 22.  0.  8. 15.  1.  6.  0.  1.  0. 11.  6.  8.  0.  6.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8 22
  0  6  8  8  0  6 14  3  1  1  6  6] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 29. 30.  8.  3. 10.  0.  5.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [ 3. 10. 10.  0. 10.] 
adversary cards in discard: [ 3. 15. 11. 29. 11.  0. 15.  0.  0.  0. 10.  0.  1. 29. 11. 25. 11. 29.
 10. 11.  0. 10. 25.  3. 29. 11. 10. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1] -> size -> 38 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 6.] 
cards in discard: [ 1. 14. 22.  0.  8. 15.  1.  6.  0.  1.  0. 11.  6.  8.  0.  6.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8 22
  0  6  8  8  0  6 14  3  1  1  6  6] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 26. 30. 29. 30.  8.  3. 10.  0.  5.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [ 3. 10. 10.  0. 10.] 
adversary cards in discard: [ 3. 15. 11. 29. 11.  0. 15.  0.  0.  0. 10.  0.  1. 29. 11. 25. 11. 29.
 10. 11.  0. 10. 25.  3. 29. 11. 10. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1] -> size -> 38 
adversary victory points: 3
player victory points: -3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3. 10. 10.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10.] 
expected returns: [[39.832226]
 [35.97019 ]
 [35.97019 ]
 [35.97019 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10.  0. 10.] 
cards in discard: [ 3. 15. 11. 29. 11.  0. 15.  0.  0.  0. 10.  0.  1. 29. 11. 25. 11. 29.
 10. 11.  0. 10. 25.  3. 29. 11. 10. 29. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 29. 30.  8.  3. 10.  0.  5.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [0. 8. 0. 8. 0.] 
adversary cards in discard: [ 1. 14. 22.  0.  8. 15.  1.  6.  0.  1.  0. 11.  6.  8.  0.  6.  0.  6.
  0.  3.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8 22
  0  6  8  8  0  6 14  3  1  1  6  6] -> size -> 36 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 32.464454650878906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[35.22459 ]
 [30.383896]
 [40.607056]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 10.  0. 10.] 
cards in discard: [ 3. 15. 11. 29. 11.  0. 15.  0.  0.  0. 10.  0.  1. 29. 11. 25. 11. 29.
 10. 11.  0. 10. 25.  3. 29. 11. 10. 29. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 26. 30. 29. 30.  8.  3. 10.  0.  5.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [0. 8. 0. 8. 0.] 
adversary cards in discard: [ 1. 14. 22.  0.  8. 15.  1.  6.  0.  1.  0. 11.  6.  8.  0.  6.  0.  6.
  0.  3.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8 22
  0  6  8  8  0  6 14  3  1  1  6  6] -> size -> 36 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 39.83222579956055



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [0. 8. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 8. 0.] 
cards in discard: [ 1. 14. 22.  0.  8. 15.  1.  6.  0.  1.  0. 11.  6.  8.  0.  6.  0.  6.
  0.  3.  3.  3.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8 22
  0  6  8  8  0  6 14  3  1  1  6  6] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 29. 30.  8.  3. 10.  0.  5.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [29. 11. 11. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1] -> size -> 38 
adversary victory points: 3
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0.] 
cards in discard: [ 1. 14. 22.  0.  8. 15.  1.  6.  0.  1.  0. 11.  6.  8.  0.  6.  0.  6.
  0.  3.  3.  3.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8 22  0
  6  8  8  0  6 14  3  1  1  6  6] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 29. 30.  8.  3. 10.  0.  5.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [29. 11. 11. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1] -> size -> 38 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [ 1. 14. 22.  0.  8. 15.  1.  6.  0.  1.  0. 11.  6.  8.  0.  6.  0.  6.
  0.  3.  3.  3.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8 22  0
  6  8  8  0  6 14  3  1  1  6  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 26. 30. 29. 30.  8.  3. 10.  0.  5.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [29. 11. 11. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1] -> size -> 38 
adversary victory points: 3
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [ 1. 14. 22.  0.  8. 15.  1.  6.  0.  1.  0. 11.  6.  8.  0.  6.  0.  6.
  0.  3.  3.  3.  6.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8 22  0
  6  8  8  0  6 14  3  1  1  6  6  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 29. 30.  8.  3. 10.  0.  4.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [29. 11. 11. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1] -> size -> 38 
adversary victory points: 3
player victory points: -3 





Player: 0 
cards in hand: [29. 11. 11. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11. 10. 10.] 
expected returns: [[94.82225 ]
 [99.718666]
 [95.95865 ]
 [95.95865 ]
 [89.77213 ]
 [89.77213 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 11. 10. 10.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 29. 30.  8.  3. 10.  0.  4.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [11.  0.  0.  6.  6.] 
adversary cards in discard: [ 1. 14. 22.  0.  8. 15.  1.  6.  0.  1.  0. 11.  6.  8.  0.  6.  0.  6.
  0.  3.  3.  3.  6.  8.  8.  0.  8.  0.] 
adversary owned cards: [ 0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8 22  0
  6  8  8  0  6 14  3  1  1  6  6  8] -> size -> 36 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 40.607051849365234



action possibilites: [-1. 11. 10. 10.] 
expected returns: [[91.384964]
 [92.48478 ]
 [86.49891 ]
 [86.49891 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 10.] 
cards in discard: [11. 10.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 29. 30.  8.  3. 10.  0.  4.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [11.  0.  0.  6.  6.] 
adversary cards in discard: [ 1. 14. 22.  0.  8. 15.  1.  6.  0.  1.  0. 11.  6.  8.  0.  6.  0.  6.
  0.  3.  3.  3.  6.  8.  8.  0.  8.  0.] 
adversary owned cards: [ 0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8 22  0
  6  8  8  0  6 14  3  1  1  6  6  8] -> size -> 36 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 93.96398162841797



action possibilites: [-1] 
expected returns: [[80.42493]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.] 
cards in discard: [11. 10.  1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 25. 30. 29. 30.  8.  3. 10.  0.  4.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [11.  0.  0.  6.  6.] 
adversary cards in discard: [ 1. 14. 22.  0.  8. 15.  1.  6.  0.  1.  0. 11.  6.  8.  0.  6.  0.  6.
  0.  3.  3.  3.  6.  8.  8.  0.  8.  0.] 
adversary owned cards: [ 0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8 22  0
  6  8  8  0  6 14  3  1  1  6  6  8] -> size -> 36 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0 -40   0   0  27   0] 
sum of rewards: 202 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 90.55646514892578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[74.98214 ]
 [70.236435]
 [80.534615]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.] 
cards in discard: [11. 10.  1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 25. 30. 29. 30.  8.  3. 10.  0.  4.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [11.  0.  0.  6.  6.] 
adversary cards in discard: [ 1. 14. 22.  0.  8. 15.  1.  6.  0.  1.  0. 11.  6.  8.  0.  6.  0.  6.
  0.  3.  3.  3.  6.  8.  8.  0.  8.  0.] 
adversary owned cards: [ 0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8 22  0
  6  8  8  0  6 14  3  1  1  6  6  8] -> size -> 36 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1
Learning step: 0
desired expected reward: 80.4249267578125






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [11.  0.  0.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  6.  6.] 
cards in discard: [ 1. 14. 22.  0.  8. 15.  1.  6.  0.  1.  0. 11.  6.  8.  0.  6.  0.  6.
  0.  3.  3.  3.  6.  8.  8.  0.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8 22  0
  6  8  8  0  6 14  3  1  1  6  6  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 29. 30.  8.  3. 10.  0.  4.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [15. 25. 29. 29. 10.] 
adversary cards in discard: [11. 10.  1. 29. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1  1] -> size -> 39 
adversary victory points: 3
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 6.] 
cards in discard: [ 1. 14. 22.  0.  8. 15.  1.  6.  0.  1.  0. 11.  6.  8.  0.  6.  0.  6.
  0.  3.  3.  3.  6.  8.  8.  0.  8.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8 22  0
  6  8  8  0  6 14  3  1  1  6  6  8  6] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 29. 30.  8.  2. 10.  0.  4.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [15. 25. 29. 29. 10.] 
adversary cards in discard: [11. 10.  1. 29. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1  1] -> size -> 39 
adversary victory points: 3
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6.] 
cards in discard: [ 1. 14. 22.  0.  8. 15.  1.  6.  0.  1.  0. 11.  6.  8.  0.  6.  0.  6.
  0.  3.  3.  3.  6.  8.  8.  0.  8.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8 22  0
  6  8  8  0  6 14  3  1  1  6  6  8  6] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 25. 30. 29. 30.  8.  2. 10.  0.  4.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [15. 25. 29. 29. 10.] 
adversary cards in discard: [11. 10.  1. 29. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1  1] -> size -> 39 
adversary victory points: 3
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6.] 
cards in discard: [ 1. 14. 22.  0.  8. 15.  1.  6.  0.  1.  0. 11.  6.  8.  0.  6.  0.  6.
  0.  3.  3.  3.  6.  8.  8.  0.  8.  0.  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8 22  0
  6  8  8  0  6 14  3  1  1  6  6  8  6  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 28. 30.  8.  2. 10.  0.  4.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [15. 25. 29. 29. 10.] 
adversary cards in discard: [11. 10.  1. 29. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1  1] -> size -> 39 
adversary victory points: 3
player victory points: -3 





Player: 0 
cards in hand: [15. 25. 29. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25. 29. 29. 10.] 
expected returns: [[50.62573 ]
 [47.413944]
 [61.844997]
 [57.11552 ]
 [57.11552 ]
 [43.97154 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 25. 29. 29. 10.] 
cards in discard: [11. 10.  1. 29. 11. 10. 10.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 28. 30.  8.  2. 10.  0.  4.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [22.  8.  3. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8 22  0
  6  8  8  0  6 14  3  1  1  6  6  8  6  3] -> size -> 38 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 80.53461456298828



action possibilites: [-1] 
expected returns: [[52.00205]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29. 29. 10.  0. 25.] 
cards in discard: [11. 10.  1. 29. 11. 10. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 28. 30.  8.  1. 10.  0.  4.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [22.  8.  3. 14.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8 22  0
  6  8  8  0  6 14  3  1  1  6  6  8  6  3  6] -> size -> 39 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 61.8449821472168





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[43.011036]
 [37.07577 ]
 [51.19334 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 29. 29. 10.  0. 25.] 
cards in discard: [11. 10.  1. 29. 11. 10. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 25. 30. 28. 30.  8.  1. 10.  0.  4.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [22.  8.  3. 14.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8 22  0
  6  8  8  0  6 14  3  1  1  6  6  8  6  3  6] -> size -> 39 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 52.00204849243164






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [22.  8.  3. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  8.  3. 14.  0.] 
cards in discard: [6.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15 11  8 11  0  6  0  0 14  0  6  0  1  6  0  0  8 22  0
  6  8  8  0  6 14  3  1  1  6  6  8  6  3  6] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 28. 30.  8.  1. 10.  0.  4.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [15.  0.  0. 29.  0.] 
adversary cards in discard: [11. 10.  1. 29. 11. 10. 10. 25. 15. 29. 29. 10.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1  1] -> size -> 39 
adversary victory points: 3
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [6.] 
cards in deck: 33 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3 15 11  8 11  0  6  0  0  0  6  0  1  6  0  0  8  0  6  8  8  0
  6 14  3  1  1  6  6  8  6  3  6] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 28. 30.  8.  1. 10.  0.  4.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [15.  0.  0. 29.  0.] 
adversary cards in discard: [11. 10.  1. 29. 11. 10. 10. 25. 15. 29. 29. 10.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1  1] -> size -> 39 
adversary victory points: 3
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [6.] 
cards in deck: 33 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3 15 11  8 11  0  6  0  0  0  6  0  1  6  0  0  8  0  6  8  8  0
  6 14  3  1  1  6  6  8  6  3  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 25. 30. 28. 30.  8.  1. 10.  0.  4.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [15.  0.  0. 29.  0.] 
adversary cards in discard: [11. 10.  1. 29. 11. 10. 10. 25. 15. 29. 29. 10.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1  1] -> size -> 39 
adversary victory points: 3
player victory points: -5 





Player: 0 
cards in hand: [15.  0.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
expected returns: [[36.629383]
 [34.02033 ]
 [42.03137 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0. 29.  0.] 
cards in discard: [11. 10.  1. 29. 11. 10. 10. 25. 15. 29. 29. 10.  0. 25.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 28. 30.  8.  1. 10.  0.  4.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [ 6.  6.  3. 11.  3.] 
adversary cards in discard: [6. 8.] 
adversary owned cards: [ 0  3  3 15 11  8 11  0  6  0  0  0  6  0  1  6  0  0  8  0  6  8  8  0
  6 14  3  1  1  6  6  8  6  3  6] -> size -> 35 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 51.19334030151367



action possibilites: [-1. 11.] 
expected returns: [[37.405952]
 [38.380116]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.] 
cards in discard: [11. 10.  1. 29. 11. 10. 10. 25. 15. 29. 29. 10.  0. 25. 15.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 25. 30. 28. 30.  8.  1. 10.  0.  4.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [ 6.  6.  3. 11.  3.] 
adversary cards in discard: [6. 8.] 
adversary owned cards: [ 0  3  3 15 11  8 11  0  6  0  0  0  6  0  1  6  0  0  8  0  6  8  8  0
  6 14  3  1  1  6  6  8  6  3  6] -> size -> 35 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 35.74357223510742



action possibilites: [-1] 
expected returns: [[48.683407]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [11. 10.  1. 29. 11. 10. 10. 25. 15. 29. 29. 10.  0. 25. 15.  0.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1  1  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 24. 30. 28. 30.  8.  1. 10.  0.  4.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [ 6.  6.  3. 11.  3.] 
adversary cards in discard: [6. 8.] 
adversary owned cards: [ 0  3  3 15 11  8 11  0  6  0  0  0  6  0  1  6  0  0  8  0  6  8  8  0
  6 14  3  1  1  6  6  8  6  3  6] -> size -> 35 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0 -50   0   0  27   0] 
sum of rewards: 252 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 36.77401351928711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[43.506546]
 [47.85285 ]
 [45.80033 ]
 [39.021873]
 [46.939087]
 [48.422   ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [11. 10.  1. 29. 11. 10. 10. 25. 15. 29. 29. 10.  0. 25. 15.  0.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1  1  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 24. 30. 28. 30.  8.  1. 10.  0.  4.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [ 6.  6.  3. 11.  3.] 
adversary cards in discard: [6. 8.] 
adversary owned cards: [ 0  3  3 15 11  8 11  0  6  0  0  0  6  0  1  6  0  0  8  0  6  8  8  0
  6 14  3  1  1  6  6  8  6  3  6] -> size -> 35 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1
Learning step: 0
desired expected reward: 48.683406829833984






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 6.  6.  3. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  3. 11.  3.] 
cards in discard: [6. 8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 15 11  8 11  0  6  0  0  0  6  0  1  6  0  0  8  0  6  8  8  0
  6 14  3  1  1  6  6  8  6  3  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 24. 30. 28. 30.  8.  1. 10.  0.  4.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [11.  0. 11. 11. 10.] 
adversary cards in discard: [11. 10.  1. 29. 11. 10. 10. 25. 15. 29. 29. 10.  0. 25. 15.  0.  1. 29.
 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1  1  1] -> size -> 40 
adversary victory points: 3
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  3. 11.  3.] 
cards in discard: [6. 8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 15 11  8 11  0  6  0  0  0  6  0  1  6  0  0  8  0  6  8  8  0
  6 14  3  1  1  6  6  8  6  3  6] -> size -> 35 
action values: 1 
buys: 1 
player value: 0 
card supply: [21. 24. 30. 28. 30.  8.  1. 10.  0.  4.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [11.  0. 11. 11. 10.] 
adversary cards in discard: [11. 10.  1. 29. 11. 10. 10. 25. 15. 29. 29. 10.  0. 25. 15.  0.  1. 29.
 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1  1  1] -> size -> 40 
adversary victory points: 3
player victory points: -5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11.  0. 11. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11. 10.] 
expected returns: [[37.849476]
 [38.667244]
 [38.667244]
 [38.667244]
 [34.43275 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11. 11. 10.] 
cards in discard: [11. 10.  1. 29. 11. 10. 10. 25. 15. 29. 29. 10.  0. 25. 15.  0.  1. 29.
 11.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1  1  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 24. 30. 28. 30.  8.  1. 10.  0.  4.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [ 0. 14.  0.  1. 15.] 
adversary cards in discard: [ 6.  8.  6.  6.  3. 11.  3.] 
adversary owned cards: [ 0  3  3 15 11  8 11  0  6  0  0  0  6  0  1  6  0  0  8  0  6  8  8  0
  6 14  3  1  1  6  6  8  6  3  6] -> size -> 35 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 48.42198944091797



action possibilites: [-1] 
expected returns: [[37.155567]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11. 10.] 
cards in discard: [11. 10.  1. 29. 11. 10. 10. 25. 15. 29. 29. 10.  0. 25. 15.  0.  1. 29.
 11.  0.  0.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1  1  1  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 28. 30.  8.  1. 10.  0.  4.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [ 0. 14.  0.  1. 15.] 
adversary cards in discard: [ 6.  8.  6.  6.  3. 11.  3.] 
adversary owned cards: [ 0  3  3 15 11  8 11  0  6  0  0  0  6  0  1  6  0  0  8  0  6  8  8  0
  6 14  3  1  1  6  6  8  6  3  6] -> size -> 35 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0 -60   0   0  27   0] 
sum of rewards: 222 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 37.30828094482422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[29.381638]
 [23.296719]
 [36.076572]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 11. 10.] 
cards in discard: [11. 10.  1. 29. 11. 10. 10. 25. 15. 29. 29. 10.  0. 25. 15.  0.  1. 29.
 11.  0.  0.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1  1  1  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 23. 30. 28. 30.  8.  1. 10.  0.  4.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [ 0. 14.  0.  1. 15.] 
adversary cards in discard: [ 6.  8.  6.  6.  3. 11.  3.] 
adversary owned cards: [ 0  3  3 15 11  8 11  0  6  0  0  0  6  0  1  6  0  0  8  0  6  8  8  0
  6 14  3  1  1  6  6  8  6  3  6] -> size -> 35 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 37.15556716918945






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 0. 14.  0.  1. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  1. 15.] 
cards in discard: [ 6.  8.  6.  6.  3. 11.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 15 11  8 11  0  6  0  0  0  6  0  1  6  0  0  8  0  6  8  8  0
  6 14  3  1  1  6  6  8  6  3  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 28. 30.  8.  1. 10.  0.  4.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [ 3.  1. 10.  0. 10.] 
adversary cards in discard: [11. 10.  1. 29. 11. 10. 10. 25. 15. 29. 29. 10.  0. 25. 15.  0.  1. 29.
 11.  0.  0.  1. 11.  0. 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1  1  1  1] -> size -> 41 
adversary victory points: 3
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  1.] 
cards in discard: [ 6.  8.  6.  6.  3. 11.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 15 11  8 11  0  6  0  0  0  6  0  1  6  0  0  8  0  6  8  8  0  6
 14  3  1  1  6  6  8  6  3  6] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 23. 30. 28. 30.  8.  1. 10.  0.  4.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [ 3.  1. 10.  0. 10.] 
adversary cards in discard: [11. 10.  1. 29. 11. 10. 10. 25. 15. 29. 29. 10.  0. 25. 15.  0.  1. 29.
 11.  0.  0.  1. 11.  0. 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1  1  1  1] -> size -> 41 
adversary victory points: 3
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  1.] 
cards in discard: [ 6.  8.  6.  6.  3. 11.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 15 11  8 11  0  6  0  0  0  6  0  1  6  0  0  8  0  6  8  8  0  6
 14  3  1  1  6  6  8  6  3  6] -> size -> 34 
action values: 0 
buys: 1 
player value: 6 
card supply: [21. 23. 30. 28. 30.  8.  1. 10.  0.  4.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [ 3.  1. 10.  0. 10.] 
adversary cards in discard: [11. 10.  1. 29. 11. 10. 10. 25. 15. 29. 29. 10.  0. 25. 15.  0.  1. 29.
 11.  0.  0.  1. 11.  0. 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1  1  1  1] -> size -> 41 
adversary victory points: 3
player victory points: -5 





Player: 0 
cards in hand: [ 3.  1. 10.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[17.259151 ]
 [15.2535925]
 [15.2535925]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 10.  0. 10.] 
cards in discard: [11. 10.  1. 29. 11. 10. 10. 25. 15. 29. 29. 10.  0. 25. 15.  0.  1. 29.
 11.  0.  0.  1. 11.  0. 11. 11. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1  1  1  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 28. 30.  8.  1. 10.  0.  4.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [ 6. 11.  0.  3.  1.] 
adversary cards in discard: [ 6.  8.  6.  6.  3. 11.  3. 15. 14.  0.  1.] 
adversary owned cards: [ 3  3 15 11  8 11  0  6  0  0  0  6  0  1  6  0  0  8  0  6  8  8  0  6
 14  3  1  1  6  6  8  6  3  6] -> size -> 34 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 36.07656478881836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[14.596496]
 [16.958012]
 [15.773608]
 [12.793153]
 [16.436436]
 [17.259151]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 10.  0. 10.] 
cards in discard: [11. 10.  1. 29. 11. 10. 10. 25. 15. 29. 29. 10.  0. 25. 15.  0.  1. 29.
 11.  0.  0.  1. 11.  0. 11. 11. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1  1  1  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 23. 30. 28. 30.  8.  1. 10.  0.  4.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [ 6. 11.  0.  3.  1.] 
adversary cards in discard: [ 6.  8.  6.  6.  3. 11.  3. 15. 14.  0.  1.] 
adversary owned cards: [ 3  3 15 11  8 11  0  6  0  0  0  6  0  1  6  0  0  8  0  6  8  8  0  6
 14  3  1  1  6  6  8  6  3  6] -> size -> 34 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 17.259151458740234



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [ 6. 11.  0.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0.  3.  1.] 
cards in discard: [ 6.  8.  6.  6.  3. 11.  3. 15. 14.  0.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 11  8 11  0  6  0  0  0  6  0  1  6  0  0  8  0  6  8  8  0  6
 14  3  1  1  6  6  8  6  3  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 28. 30.  8.  1. 10.  0.  4.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [10. 11.  0.  3. 10.] 
adversary cards in discard: [11. 10.  1. 29. 11. 10. 10. 25. 15. 29. 29. 10.  0. 25. 15.  0.  1. 29.
 11.  0.  0.  1. 11.  0. 11. 11. 10.  3.  1. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1  1  1  1] -> size -> 41 
adversary victory points: 3
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 1.] 
cards in discard: [ 6.  8.  6.  6.  3. 11.  3. 15. 14.  0.  1.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 15 11  8 11  0  6  0  0  0  6  0  1  6  0  0  8  0  6  8  8  0  6
 14  3  1  1  6  6  8  6  3  6  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 28. 30.  8.  1. 10.  0.  4.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [10. 11.  0.  3. 10.] 
adversary cards in discard: [11. 10.  1. 29. 11. 10. 10. 25. 15. 29. 29. 10.  0. 25. 15.  0.  1. 29.
 11.  0.  0.  1. 11.  0. 11. 11. 10.  3.  1. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1  1  1  1] -> size -> 41 
adversary victory points: 3
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 1.] 
cards in discard: [ 6.  8.  6.  6.  3. 11.  3. 15. 14.  0.  1.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 15 11  8 11  0  6  0  0  0  6  0  1  6  0  0  8  0  6  8  8  0  6
 14  3  1  1  6  6  8  6  3  6  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 23. 30. 28. 30.  8.  1. 10.  0.  4.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [10. 11.  0.  3. 10.] 
adversary cards in discard: [11. 10.  1. 29. 11. 10. 10. 25. 15. 29. 29. 10.  0. 25. 15.  0.  1. 29.
 11.  0.  0.  1. 11.  0. 11. 11. 10.  3.  1. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1  1  1  1] -> size -> 41 
adversary victory points: 3
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 1.] 
cards in discard: [ 6.  8.  6.  6.  3. 11.  3. 15. 14.  0.  1.  0.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 15 11  8 11  0  6  0  0  0  6  0  1  6  0  0  8  0  6  8  8  0  6
 14  3  1  1  6  6  8  6  3  6  0  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 23. 30. 28. 30.  8.  1. 10.  0.  3.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [10. 11.  0.  3. 10.] 
adversary cards in discard: [11. 10.  1. 29. 11. 10. 10. 25. 15. 29. 29. 10.  0. 25. 15.  0.  1. 29.
 11.  0.  0.  1. 11.  0. 11. 11. 10.  3.  1. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1  1  1  1] -> size -> 41 
adversary victory points: 3
player victory points: -5 





Player: 0 
cards in hand: [10. 11.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.] 
expected returns: [[5.210868 ]
 [4.2197704]
 [5.4887   ]
 [4.2197704]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0.  3. 10.] 
cards in discard: [11. 10.  1. 29. 11. 10. 10. 25. 15. 29. 29. 10.  0. 25. 15.  0.  1. 29.
 11.  0.  0.  1. 11.  0. 11. 11. 10.  3.  1. 10.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1  1  1  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 28. 30.  8.  1. 10.  0.  3.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [0. 6. 8. 0. 6.] 
adversary cards in discard: [ 6.  8.  6.  6.  3. 11.  3. 15. 14.  0.  1.  0.  8. 11.  6.  0.  3.  1.] 
adversary owned cards: [ 3  3 15 11  8 11  0  6  0  0  0  6  0  1  6  0  0  8  0  6  8  8  0  6
 14  3  1  1  6  6  8  6  3  6  0  8] -> size -> 36 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 17.259151458740234



action possibilites: [-1] 
expected returns: [[-2.237125]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3. 10.] 
cards in discard: [11. 10.  1. 29. 11. 10. 10. 25. 15. 29. 29. 10.  0. 25. 15.  0.  1. 29.
 11.  0.  0.  1. 11.  0. 11. 11. 10.  3.  1. 10.  0. 10.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1  1  1  1  1] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 22. 30. 28. 30.  8.  1. 10.  0.  3.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [0. 6. 8. 0. 6.] 
adversary cards in discard: [ 6.  8.  6.  6.  3. 11.  3. 15. 14.  0.  1.  0.  8. 11.  6.  0.  3.  1.] 
adversary owned cards: [ 3  3 15 11  8 11  0  6  0  0  0  6  0  1  6  0  0  8  0  6  8  8  0  6
 14  3  1  1  6  6  8  6  3  6  0  8] -> size -> 36 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0 -70   0   0  27   0] 
sum of rewards: 212 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 5.08480167388916





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-2.4805562]
 [-2.7700934]
 [-2.2371264]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3. 10.] 
cards in discard: [11. 10.  1. 29. 11. 10. 10. 25. 15. 29. 29. 10.  0. 25. 15.  0.  1. 29.
 11.  0.  0.  1. 11.  0. 11. 11. 10.  3.  1. 10.  0. 10.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1  1  1  1  1] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 22. 30. 28. 30.  8.  1. 10.  0.  3.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [0. 6. 8. 0. 6.] 
adversary cards in discard: [ 6.  8.  6.  6.  3. 11.  3. 15. 14.  0.  1.  0.  8. 11.  6.  0.  3.  1.] 
adversary owned cards: [ 3  3 15 11  8 11  0  6  0  0  0  6  0  1  6  0  0  8  0  6  8  8  0  6
 14  3  1  1  6  6  8  6  3  6  0  8] -> size -> 36 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: -2.2371249198913574






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [0. 6. 8. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8. 0. 6.] 
cards in discard: [ 6.  8.  6.  6.  3. 11.  3. 15. 14.  0.  1.  0.  8. 11.  6.  0.  3.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 11  8 11  0  6  0  0  0  6  0  1  6  0  0  8  0  6  8  8  0  6
 14  3  1  1  6  6  8  6  3  6  0  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 22. 30. 28. 30.  8.  1. 10.  0.  3.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [ 1. 11. 10. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1  1  1  1  1] -> size -> 42 
adversary victory points: 3
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 6.  8.  6.  6.  3. 11.  3. 15. 14.  0.  1.  0.  8. 11.  6.  0.  3.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 15 11  8 11  0  0  0  0  1  6  0  0  8  0  6  8  8  0  6 14  3  1
  1  6  6  8  6  3  6  0  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 22. 30. 28. 30.  8.  1. 10.  0.  3.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [ 1. 11. 10. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1  1  1  1  1] -> size -> 42 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 6.  8.  6.  6.  3. 11.  3. 15. 14.  0.  1.  0.  8. 11.  6.  0.  3.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 15 11  8 11  0  0  0  0  1  6  0  0  8  0  6  8  8  0  6 14  3  1
  1  6  6  8  6  3  6  0  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 22. 30. 28. 30.  8.  1. 10.  0.  3.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [ 1. 11. 10. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1  1  1  1  1] -> size -> 42 
adversary victory points: 3
player victory points: -3 





Player: 0 
cards in hand: [ 1. 11. 10. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29.] 
expected returns: [[79.42858 ]
 [80.418884]
 [75.06608 ]
 [83.69917 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11. 10. 29.  3.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1  1  1  1  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 22. 30. 28. 30.  8.  1. 10.  0.  3.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [6. 0. 8. 1. 0.] 
adversary cards in discard: [ 6.  8.  6.  6.  3. 11.  3. 15. 14.  0.  1.  0.  8. 11.  6.  0.  3.  1.
  8.  0.] 
adversary owned cards: [ 3  3 15 11  8 11  0  0  0  0  1  6  0  0  8  0  6  8  8  0  6 14  3  1
  1  6  6  8  6  3  6  0  8] -> size -> 33 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -2.2371249198913574



action possibilites: [-1. 11. 10.] 
expected returns: [[84.65955 ]
 [85.611305]
 [80.696175]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.] 
cards in discard: [1. 3.] 
cards in deck: 36 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1  1  1  1  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 22. 30. 28. 30.  8.  1. 10.  0.  3.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [6. 0. 8. 1. 0.] 
adversary cards in discard: [ 6.  8.  6.  6.  3. 11.  3. 15. 14.  0.  1.  0.  8. 11.  6.  0.  3.  1.
  8.  0.] 
adversary owned cards: [ 3  3 15 11  8 11  0  0  0  0  1  6  0  0  8  0  6  8  8  0  6 14  3  1
  1  6  6  8  6  3  6  0  8] -> size -> 33 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 82.93849182128906



action possibilites: [-1] 
expected returns: [[83.68438]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.] 
cards in discard: [1. 3. 1.] 
cards in deck: 36 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1  1  1  1  1  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 21. 30. 28. 30.  8.  1. 10.  0.  3.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [6. 0. 8. 1. 0.] 
adversary cards in discard: [ 6.  8.  6.  6.  3. 11.  3. 15. 14.  0.  1.  0.  8. 11.  6.  0.  3.  1.
  8.  0.] 
adversary owned cards: [ 3  3 15 11  8 11  0  0  0  0  1  6  0  0  8  0  6  8  8  0  6 14  3  1
  1  6  6  8  6  3  6  0  8] -> size -> 33 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0 -80   0   0  27   0] 
sum of rewards: 162 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 83.96886444091797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[78.48175 ]
 [80.925896]
 [73.708496]
 [82.14178 ]
 [83.7324  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [1. 3. 1.] 
cards in deck: 36 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1  1  1  1  1  1] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 21. 30. 28. 30.  8.  1. 10.  0.  3.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [6. 0. 8. 1. 0.] 
adversary cards in discard: [ 6.  8.  6.  6.  3. 11.  3. 15. 14.  0.  1.  0.  8. 11.  6.  0.  3.  1.
  8.  0.] 
adversary owned cards: [ 3  3 15 11  8 11  0  0  0  0  1  6  0  0  8  0  6  8  8  0  6 14  3  1
  1  6  6  8  6  3  6  0  8] -> size -> 33 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1
Learning step: 0
desired expected reward: 83.68437957763672






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [6. 0. 8. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 1. 0.] 
cards in discard: [ 6.  8.  6.  6.  3. 11.  3. 15. 14.  0.  1.  0.  8. 11.  6.  0.  3.  1.
  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 11  8 11  0  0  0  0  1  6  0  0  8  0  6  8  8  0  6 14  3  1
  1  6  6  8  6  3  6  0  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 28. 30.  8.  1. 10.  0.  3.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [25. 29. 10. 11. 10.] 
adversary cards in discard: [ 1.  3.  1. 29. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1  1  1  1  1  1] -> size -> 43 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 1. 0.] 
cards in discard: [ 6.  8.  6.  6.  3. 11.  3. 15. 14.  0.  1.  0.  8. 11.  6.  0.  3.  1.
  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 11  8 11  0  0  0  0  1  6  0  0  8  0  6  8  8  0  6 14  3  1
  1  6  6  8  6  3  6  0  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 21. 30. 28. 30.  8.  1. 10.  0.  3.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [25. 29. 10. 11. 10.] 
adversary cards in discard: [ 1.  3.  1. 29. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1  1  1  1  1  1] -> size -> 43 
adversary victory points: 3
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 1. 0.] 
cards in discard: [ 6.  8.  6.  6.  3. 11.  3. 15. 14.  0.  1.  0.  8. 11.  6.  0.  3.  1.
  8.  0. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 15 11  8 11  0  0  0  0  1  6  0  0  8  0  6  8  8  0  6 14  3  1
  1  6  6  8  6  3  6  0  8 16] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 28. 30.  8.  1.  9.  0.  3.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [25. 29. 10. 11. 10.] 
adversary cards in discard: [ 1.  3.  1. 29. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1  1  1  1  1  1] -> size -> 43 
adversary victory points: 3
player victory points: -3 





Player: 0 
cards in hand: [25. 29. 10. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 10. 11. 10.] 
expected returns: [[69.94093 ]
 [82.48449 ]
 [77.168724]
 [63.08887 ]
 [71.62612 ]
 [63.08887 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 10. 11. 10.] 
cards in discard: [ 1.  3.  1. 29. 11. 10.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1  1  1  1  1  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 28. 30.  8.  1.  9.  0.  3.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [0. 8. 6. 8. 0.] 
adversary cards in discard: [ 6.  8.  6.  6.  3. 11.  3. 15. 14.  0.  1.  0.  8. 11.  6.  0.  3.  1.
  8.  0. 16.  6.  0.  8.  1.  0.] 
adversary owned cards: [ 3  3 15 11  8 11  0  0  0  0  1  6  0  0  8  0  6  8  8  0  6 14  3  1
  1  6  6  8  6  3  6  0  8 16] -> size -> 34 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 83.7323989868164



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 8 
Chapel: 0 
Witch: 2 
Poacher: 5 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [29. 10. 11. 10. 10. 11.] 
cards in discard: [ 1.  3.  1. 29. 11. 10.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 11 25 29 10 29 10 10 29 11
 10 11 10 11 10 10 25 10 10 11 15 15 11  1  1  1  1  1  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 28. 30.  8.  0.  9.  0.  3.  8.  5.  8. 10.  0.  9.  7.] 
adversary cards in hand: [0. 8. 6. 8. 0.] 
adversary cards in discard: [ 6.  8.  6.  6.  3. 11.  3. 15. 14.  0.  1.  0.  8. 11.  6.  0.  3.  1.
  8.  0. 16.  6.  0.  8.  1.  0.  6.] 
adversary owned cards: [ 3  3 15 11  8 11  0  0  0  0  1  6  0  0  8  0  6  8  8  0  6 14  3  1
  1  6  6  8  6  3  6  0  8 16  6] -> size -> 35 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0     180       0       0      20       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000195 

action type: take_action - action 25.0
Learning step: 120004.5
desired expected reward: 120086.984375



