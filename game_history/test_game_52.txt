 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [3. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[10.088675]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0      -60        0        0        0        0
        0        0        0     -310        0     -300        0        0] 
sum of rewards: -3000675 

action type: buy - action 6.0
Learning step: -120021.078125
desired expected reward: -120169.09375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[  8.34033 ]
 [ 21.342964]
 [ 13.436735]
 [-47.99908 ]
 [ 18.701677]
 [ 11.11352 ]
 [ 15.519724]
 [  8.511494]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 10.288036346435547



buy possibilites: [-1] 
expected returns: [[11.325853]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 21.342958450317383






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3. 3. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3. 3. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 3.  3.  3.  0.  0. 22.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 22] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [1. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[14.353346]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [1. 0. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 3. 22.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 22] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 11.32585334777832





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 13.78838 ]
 [ 26.386732]
 [ 18.883707]
 [-40.738907]
 [ 19.790333]
 [ 23.792849]
 [ 16.11704 ]
 [ 31.892195]
 [ 20.622698]
 [ 20.859371]
 [ 26.834831]
 [ 14.129   ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [1. 0. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 3. 22.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 22] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 13.816423416137695



buy possibilites: [-1] 
expected returns: [[-10.004937]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 1.  0.  3.  0.  0.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 3. 22.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 22] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 31.892194747924805






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [ 3. 22.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 22.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 22] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0.  0.  1.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 22.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 22] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0.  0.  1.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 22.  0.  3.  0.] 
cards in discard: [3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0.  0.  1.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0.  1.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 7.8200116]
 [23.803625 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1.  0. 29.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 3.  3. 22.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.004937171936035



action possibilites: [-1.] 
expected returns: [[11.08432]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 3.  3. 22.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 22.59602928161621





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 14.117168 ]
 [ 27.154806 ]
 [-16.219646 ]
 [ 19.38748  ]
 [-10.872368 ]
 [-45.918747 ]
 [ 20.496025 ]
 [ 24.766413 ]
 [ 17.24715  ]
 [ 29.208551 ]
 [ 32.82454  ]
 [ 21.38191  ]
 [ 26.376402 ]
 [ 21.63459  ]
 [  6.2399125]
 [ 27.75248  ]
 [ 14.634338 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 7 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 3.  3. 22.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 11.084320068359375



buy possibilites: [-1] 
expected returns: [[3.255509]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 3.  3. 22.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: 17.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 32.82454299926758






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 3.  3. 22.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [29. 29.  0.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 3.  3. 22.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [29. 29.  0.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 3.  3. 22.  0.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  3  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 29. 30. 28. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [29. 29.  0.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [0. 3. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-7.9868617]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [29. 29.  0.  0.  1.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 3.  0.  3. 22.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  3  3] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 3.2555088996887207





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ -8.810454 ]
 [ -3.893393 ]
 [-62.65712  ]
 [ -6.7216864]
 [ -7.791813 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [29. 29.  0.  0.  1.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 28. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 3.  0.  3. 22.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  3  3] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -7.999659061431885



buy possibilites: [-1] 
expected returns: [[-4.9510727]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [29. 29.  0.  0.  1.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 3.  0.  3. 22.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  3  3] -> size -> 13 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0  16   0] 
sum of rewards: -19 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -3.89339542388916






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  3. 22.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 22.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  3  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 3. 29.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3] -> size -> 14 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 22.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  3  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 27. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 3. 29.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3] -> size -> 14 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 22.  0.] 
cards in discard: [3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  3  3  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 26. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 3. 29.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3] -> size -> 14 
adversary victory points: 4
player victory points: 6 





Player: 0 
cards in hand: [ 3. 29.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-3.0259488]
 [12.385363 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 26. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10. 10.  9. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 3.  3.  0.  3. 22.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  3  3  3] -> size -> 14 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -4.951072692871094



action possibilites: [-1.] 
expected returns: [[-5.108133]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 26. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10. 10.  9. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 3.  3.  0.  3. 22.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  3  3  3] -> size -> 14 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 9.208030700683594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-7.9437442e+00]
 [ 4.8012910e+00]
 [-2.5094151e+00]
 [-7.0347450e+01]
 [ 2.8299327e+00]
 [-5.1173491e+00]
 [-3.3238173e-02]
 [-6.6066122e+00]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 26. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10. 10.  9. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 3.  3.  0.  3. 22.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  3  3  3] -> size -> 14 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -5.108132839202881



buy possibilites: [-1] 
expected returns: [[3.1417203]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 26. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10. 10.  9. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 3.  3.  0.  3. 22.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  3  3  3] -> size -> 14 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 9 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 4.801289081573486






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 3.  3.  0.  3. 22.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  3  3  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 26. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 1. 29.  3.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1] -> size -> 15 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 3.  3.  0.  3. 22.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  3  3  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 26. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 1. 29.  3.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1] -> size -> 15 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 3.  3.  0.  3. 22.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  3  3  3  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 26. 30.  8. 10. 10. 10.  9. 10.  8. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 1. 29.  3.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1] -> size -> 15 
adversary victory points: 4
player victory points: 6 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-9.13422]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 1. 29.  3.  3.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 26. 30.  8. 10. 10. 10.  9. 10.  8. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  3  3  3  8] -> size -> 15 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 3.1417202949523926





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ -9.149883 ]
 [  3.2939816]
 [ -4.0898857]
 [-66.369514 ]
 [ -3.0105648]
 [  0.7807908]
 [ -6.881585 ]
 [  8.543325 ]
 [ -2.2249486]
 [ -2.000548 ]
 [  3.701994 ]
 [ -8.382017 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 1. 29.  3.  3.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 26. 30.  8. 10. 10. 10.  9. 10.  8. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  3  3  3  8] -> size -> 15 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -9.041206359863281



buy possibilites: [-1] 
expected returns: [[-17.17813]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 1. 29.  3.  3.  0.  0.  3. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 26. 30.  8. 10. 10. 10.  9. 10.  7. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  3  3  3  8] -> size -> 15 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 63 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 8.543315887451172






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  3  3  3  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 26. 30.  8. 10. 10. 10.  9. 10.  7. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 3. 29. 29.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29] -> size -> 16 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  3  3  3  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 26. 30.  8. 10. 10. 10.  9. 10.  7. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 3. 29. 29.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29] -> size -> 16 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  3  3  3  8  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 26. 30.  8. 10. 10. 10.  9. 10.  7. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 3. 29. 29.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29] -> size -> 16 
adversary victory points: 4
player victory points: 6 





Player: 0 
cards in hand: [ 3. 29. 29.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[ 7.71893 ]
 [23.855698]
 [23.855698]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 29.  1.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 26. 30.  8. 10. 10. 10.  9. 10.  7. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 3.  8.  0.  3. 22.] 
adversary cards in discard: [1. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  3  3  3  8  1] -> size -> 16 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -17.178129196166992



action possibilites: [-1. 29.] 
expected returns: [[-11.922913 ]
 [  5.7732577]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  1.  0.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 26. 30.  8. 10. 10. 10.  9. 10.  7. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 3.  8.  0.  3. 22.] 
adversary cards in discard: [1. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  3  3  3  8  1] -> size -> 16 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 21.105350494384766



action possibilites: [-1.] 
expected returns: [[-14.319948]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 27. 30. 26. 30.  8. 10. 10. 10.  9. 10.  7. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 3.  8.  0.  3. 22.] 
adversary cards in discard: [1. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  3  3  3  8  1] -> size -> 16 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 5.773263454437256





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-14.900227  ]
 [ -1.5907431 ]
 [ -9.352524  ]
 [-40.46622   ]
 [-73.90889   ]
 [ -7.987999  ]
 [ -4.0851607 ]
 [-12.555088  ]
 [  0.27213955]
 [  3.8714366 ]
 [ -7.174612  ]
 [ -2.381229  ]
 [ -6.9439597 ]
 [-22.613995  ]
 [ -1.143578  ]
 [-13.503149  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 27. 30. 26. 30.  8. 10. 10. 10.  9. 10.  7. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 3.  8.  0.  3. 22.] 
adversary cards in discard: [1. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  3  3  3  8  1] -> size -> 16 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.319948196411133



buy possibilites: [-1] 
expected returns: [[7.4358525]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 3. 3.] 
cards in discard: [29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 26. 30.  8. 10. 10. 10.  9. 10.  6. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 3.  8.  0.  3. 22.] 
adversary cards in discard: [1. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  3  3  3  8  1] -> size -> 16 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: 7.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 3.871433734893799






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [ 3.  8.  0.  3. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0.  3. 22.] 
cards in discard: [1. 0. 3. 3. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 22  3  3  3  8  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 26. 30.  8. 10. 10. 10.  9. 10.  6. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  1.] 
adversary cards in discard: [29. 29. 29.  3.  1.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29] -> size -> 17 
adversary victory points: 4
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 22.] 
cards in discard: [1. 0. 3. 3. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 26. 30.  8. 10. 10. 10.  9. 10.  6. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  1.] 
adversary cards in discard: [29. 29. 29.  3.  1.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29] -> size -> 17 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 22.] 
cards in discard: [1. 0. 3. 3. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [30. 27. 30. 26. 30.  8. 10. 10. 10.  9. 10.  6. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  1.] 
adversary cards in discard: [29. 29. 29.  3.  1.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29] -> size -> 17 
adversary victory points: 4
player victory points: 6 





Player: 0 
cards in hand: [ 0.  0. 29.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-4.70174 ]
 [11.619701]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  1.] 
cards in discard: [29. 29. 29.  3.  1.  0.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 26. 30.  8. 10. 10. 10.  9. 10.  6. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 1.  0.  3.  3.  0.  0.  8.  3.  3. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1] -> size -> 15 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 7.435852527618408



action possibilites: [-1.] 
expected returns: [[7.6237636]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [29. 29. 29.  3.  1.  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 26. 30.  8. 10. 10. 10.  9. 10.  6. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 1.  0.  3.  3.  0.  0.  8.  3.  3. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1] -> size -> 15 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 11.418495178222656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 7.9036460e+00]
 [ 2.0580143e+01]
 [-2.3224823e+01]
 [ 1.2995024e+01]
 [-1.7911098e+01]
 [-5.3556564e+01]
 [ 1.4575481e+01]
 [ 1.8022379e+01]
 [ 1.0310591e+01]
 [ 2.2076700e+01]
 [ 2.5519350e+01]
 [ 1.5275953e+01]
 [ 1.9790865e+01]
 [ 1.5480989e+01]
 [-4.7474623e-02]
 [ 2.0871103e+01]
 [ 9.6500854e+00]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [29. 29. 29.  3.  1.  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 7 
card supply: [30. 27. 30. 26. 30.  8. 10. 10. 10.  9. 10.  6. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 1.  0.  3.  3.  0.  0.  8.  3.  3. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1] -> size -> 15 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 7.623763561248779



buy possibilites: [-1] 
expected returns: [[17.210714]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 0.] 
cards in discard: [29. 29. 29.  3.  1.  0.  3.  3. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 27. 30. 26. 30.  8. 10. 10. 10.  9. 10.  5. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 1.  0.  3.  3.  0.  0.  8.  3.  3. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1] -> size -> 15 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: -13.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 25.519350051879883






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 1.  0.  3.  3.  0.  0.  8.  3.  3. 22.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 26. 30.  8. 10. 10. 10.  9. 10.  5. 10. 10. 10.  9. 10.] 
adversary cards in hand: [29. 29.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29] -> size -> 18 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 1.  0.  3.  3.  0.  0.  8.  3.  3. 22.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 27. 30. 26. 30.  8. 10. 10. 10.  9. 10.  5. 10. 10. 10.  9. 10.] 
adversary cards in hand: [29. 29.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29] -> size -> 18 
adversary victory points: 4
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29. 29.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[-26.393757]
 [-10.613367]
 [-10.613367]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 26. 30.  8. 10. 10. 10.  9. 10.  5. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1] -> size -> 15 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 17.21071434020996



action possibilites: [-1. 29. 29.] 
expected returns: [[-31.635098]
 [-14.763096]
 [-14.763096]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 26. 30.  8. 10. 10. 10.  9. 10.  5. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1] -> size -> 15 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: -12.060569763183594



action possibilites: [-1. 29.] 
expected returns: [[-4.4285398]
 [12.960239 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 27. 30. 26. 30.  8. 10. 10. 10.  9. 10.  5. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1] -> size -> 15 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: -14.763092041015625



action possibilites: [-1. 29.] 
expected returns: [[ 2.3793454]
 [19.076906 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 3 
card supply: [30. 27. 30. 26. 30.  8. 10. 10. 10.  9. 10.  5. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1] -> size -> 15 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 12.96023941040039



action possibilites: [-1.] 
expected returns: [[20.4969]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 4 
card supply: [30. 27. 30. 26. 30.  8. 10. 10. 10.  9. 10.  5. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1] -> size -> 15 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -60   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 19.076900482177734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 20.316376 ]
 [ 32.597054 ]
 [ -7.8484697]
 [ 25.282806 ]
 [ -2.8005977]
 [ 34.037807 ]
 [-35.594124 ]
 [ 26.491085 ]
 [ 30.14042  ]
 [ 22.572954 ]
 [ 34.2834   ]
 [ 37.741932 ]
 [ 27.23389  ]
 [ 31.82281  ]
 [ 27.447943 ]
 [ 13.174688 ]
 [ 32.999973 ]
 [ 21.360888 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 8 
card supply: [30. 27. 30. 26. 30.  8. 10. 10. 10.  9. 10.  5. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1] -> size -> 15 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -60   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 20.49690055847168



buy possibilites: [-1] 
expected returns: [[30.579718]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 4 
card supply: [30. 27. 30. 26. 30.  8. 10. 10. 10.  9. 10.  4. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1] -> size -> 15 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.  80.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: 47.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 37.7419319152832






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 26. 30.  8. 10. 10. 10.  9. 10.  4. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 1. 0. 0. 3.] 
adversary cards in discard: [29. 29. 29. 29. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29] -> size -> 19 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 27. 30. 26. 30.  8. 10. 10. 10.  9. 10.  4. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 1. 0. 0. 3.] 
adversary cards in discard: [29. 29. 29. 29. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29] -> size -> 19 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 26. 30.  8. 10. 10.  9.  9. 10.  4. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 1. 0. 0. 3.] 
adversary cards in discard: [29. 29. 29. 29. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29] -> size -> 19 
adversary victory points: 4
player victory points: 6 





Player: 0 
cards in hand: [0. 1. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[13.053572]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0. 3.] 
cards in discard: [29. 29. 29. 29. 29.  3.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 26. 30.  8. 10. 10.  9.  9. 10.  4. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 3.  1. 22.  3.  0.] 
adversary cards in discard: [11.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1 11] -> size -> 16 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 30.5797176361084





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 12.613354 ]
 [ 25.335478 ]
 [ 17.785685 ]
 [-14.611742 ]
 [-50.37886  ]
 [ 19.353296 ]
 [ 22.862204 ]
 [ 15.249004 ]
 [ 26.88949  ]
 [ 30.283789 ]
 [ 20.072948 ]
 [ 24.565525 ]
 [ 20.281187 ]
 [  4.218431 ]
 [ 25.669918 ]
 [ 14.3593445]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 3.] 
cards in discard: [29. 29. 29. 29. 29.  3.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 27. 30. 26. 30.  8. 10. 10.  9.  9. 10.  4. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 3.  1. 22.  3.  0.] 
adversary cards in discard: [11.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1 11] -> size -> 16 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 10.798646926879883



buy possibilites: [-1] 
expected returns: [[85.06011]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 3.] 
cards in discard: [29. 29. 29. 29. 29.  3.  0.  0.  0.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 26. 30.  8. 10. 10.  9.  9. 10.  3. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 3.  1. 22.  3.  0.] 
adversary cards in discard: [11.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1 11] -> size -> 16 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: -33.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 30.28379249572754






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 3.  1. 22.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 22.  3.  0.] 
cards in discard: [11.  0.  0.  0.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 26. 30.  8. 10. 10.  9.  9. 10.  3. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0. 29.  1.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29] -> size -> 20 
adversary victory points: 4
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 3. 0. 8. 0. 3.] 
cards in discard: [11.  0.  0.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 26. 30.  8. 10. 10.  9.  9. 10.  3. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0. 29.  1.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29] -> size -> 20 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 0. 8. 0. 3.] 
cards in discard: [11.  0.  0.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 27. 30. 26. 30.  8. 10. 10.  9.  9. 10.  3. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0. 29.  1.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29] -> size -> 20 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 0. 8. 0. 3.] 
cards in discard: [11.  0.  0.  0.  3.  3. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1 11 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 26. 30.  8. 10. 10.  8.  9. 10.  3. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0. 29.  1.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29] -> size -> 20 
adversary victory points: 4
player victory points: 6 





Player: 0 
cards in hand: [ 0. 29.  1.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-13.626173 ]
 [  3.4272313]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  1.  3.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 26. 30.  8. 10. 10.  8.  9. 10.  3. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1 11 11] -> size -> 17 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 85.06011199951172



action possibilites: [-1.] 
expected returns: [[-4.548683]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 26. 30.  8. 10. 10.  8.  9. 10.  3. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1 11 11] -> size -> 17 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 1.345813274383545





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ -4.7150826]
 [  7.840259 ]
 [  0.3962276]
 [-28.706518 ]
 [-62.783703 ]
 [  1.6671991]
 [  5.3432813]
 [ -2.4060166]
 [  9.490337 ]
 [ 12.966791 ]
 [  2.4258866]
 [  7.057813 ]
 [  2.6436925]
 [-12.070883 ]
 [  8.218218 ]
 [ -3.5502021]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 27. 30. 26. 30.  8. 10. 10.  8.  9. 10.  3. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1 11 11] -> size -> 17 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -4.548683166503906



buy possibilites: [-1] 
expected returns: [[29.488047]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 3. 0.] 
cards in discard: [29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 26. 30.  8. 10. 10.  8.  9. 10.  2. 10. 10. 10.  9. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1 11 11] -> size -> 17 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: -13.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 12.966785430908203






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1 11 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 26. 30.  8. 10. 10.  8.  9. 10.  2. 10. 10. 10.  9. 10.] 
adversary cards in hand: [29. 29.  1.  3.  3.] 
adversary cards in discard: [29. 29.  0.  1.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29] -> size -> 21 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1 11 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 27. 30. 26. 30.  8. 10. 10.  8.  9. 10.  2. 10. 10. 10.  9. 10.] 
adversary cards in hand: [29. 29.  1.  3.  3.] 
adversary cards in discard: [29. 29.  0.  1.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29] -> size -> 21 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1 11 11  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 26. 30.  8. 10. 10.  8.  8. 10.  2. 10. 10. 10.  9. 10.] 
adversary cards in hand: [29. 29.  1.  3.  3.] 
adversary cards in discard: [29. 29.  0.  1.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29] -> size -> 21 
adversary victory points: 4
player victory points: 6 





Player: 0 
cards in hand: [29. 29.  1.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[20.295416]
 [35.840435]
 [35.840435]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  1.  3.  3.] 
cards in discard: [29. 29.  0.  1.  3.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 26. 30.  8. 10. 10.  8.  8. 10.  2. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 1. 11.  0.  3.  0.] 
adversary cards in discard: [8. 0. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1 11 11  8] -> size -> 18 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 29.488046646118164



action possibilites: [-1. 29. 29.] 
expected returns: [[44.762257]
 [60.713757]
 [60.713757]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  3.  3. 29.] 
cards in discard: [29. 29.  0.  1.  3.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 26. 30.  8. 10. 10.  8.  8. 10.  2. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 1. 11.  0.  3.  0.] 
adversary cards in discard: [8. 0. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1 11 11  8] -> size -> 18 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 34.97892379760742



action possibilites: [-1. 29.] 
expected returns: [[67.756195]
 [83.89258 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  3. 29.  0.] 
cards in discard: [29. 29.  0.  1.  3.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 27. 30. 26. 30.  8. 10. 10.  8.  8. 10.  2. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 1. 11.  0.  3.  0.] 
adversary cards in discard: [8. 0. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1 11 11  8] -> size -> 18 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 60.71376419067383



action possibilites: [-1.] 
expected returns: [[79.14667]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3. 0. 0.] 
cards in discard: [29. 29.  0.  1.  3.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 3 
card supply: [30. 27. 30. 26. 30.  8. 10. 10.  8.  8. 10.  2. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 1. 11.  0.  3.  0.] 
adversary cards in discard: [8. 0. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1 11 11  8] -> size -> 18 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 83.89257049560547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[82.865974]
 [94.70912 ]
 [51.699303]
 [87.7801  ]
 [56.26766 ]
 [ 9.867544]
 [89.188034]
 [92.57673 ]
 [85.198875]
 [96.26981 ]
 [99.33134 ]
 [89.89595 ]
 [94.03135 ]
 [90.09609 ]
 [75.483734]
 [95.10718 ]
 [84.40458 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 0. 0.] 
cards in discard: [29. 29.  0.  1.  3.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29] -> size -> 21 
action values: 0 
buys: 1 
player value: 7 
card supply: [30. 27. 30. 26. 30.  8. 10. 10.  8.  8. 10.  2. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 1. 11.  0.  3.  0.] 
adversary cards in discard: [8. 0. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1 11 11  8] -> size -> 18 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 79.14666748046875



buy possibilites: [-1] 
expected returns: [[90.66113]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 0. 0.] 
cards in discard: [29. 29.  0.  1.  3.  3.  0. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 27. 30. 26. 30.  8. 10. 10.  8.  8. 10.  1. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 1. 11.  0.  3.  0.] 
adversary cards in discard: [8. 0. 3. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1 11 11  8] -> size -> 18 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.  60.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: 27.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 99.33134460449219






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 1. 11.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  0.  3.  0.] 
cards in discard: [8. 0. 3. 3. 3. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1 11 11  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 26. 30.  8. 10. 10.  8.  8. 10.  1. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0. 29. 29. 29.  0.] 
adversary cards in discard: [29. 29.  0.  1.  3.  3.  0. 29. 29. 29. 29.  1.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29] -> size -> 22 
adversary victory points: 4
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 0.] 
cards in discard: [8. 0. 3. 3. 3. 0. 6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1 11 11  8  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 26. 30.  8.  9. 10.  8.  8. 10.  1. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0. 29. 29. 29.  0.] 
adversary cards in discard: [29. 29.  0.  1.  3.  3.  0. 29. 29. 29. 29.  1.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29] -> size -> 22 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0.] 
cards in discard: [8. 0. 3. 3. 3. 0. 6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1 11 11  8  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 27. 30. 26. 30.  8.  9. 10.  8.  8. 10.  1. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0. 29. 29. 29.  0.] 
adversary cards in discard: [29. 29.  0.  1.  3.  3.  0. 29. 29. 29. 29.  1.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29] -> size -> 22 
adversary victory points: 4
player victory points: 5 





Player: 0 
cards in hand: [ 0. 29. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[38.510857]
 [51.694904]
 [51.694904]
 [51.694904]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29. 29.  0.] 
cards in discard: [29. 29.  0.  1.  3.  3.  0. 29. 29. 29. 29.  1.  3.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 26. 30.  8.  9. 10.  8.  8. 10.  1. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0.  3.  3. 22. 11.] 
adversary cards in discard: [ 8.  0.  3.  3.  3.  0.  6. 11.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1 11 11  8  6] -> size -> 19 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 90.6611328125



action possibilites: [-1. 29. 29.] 
expected returns: [[20.32392 ]
 [32.611652]
 [32.611652]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29.  0.  0.] 
cards in discard: [29. 29.  0.  1.  3.  3.  0. 29. 29. 29. 29.  1.  3.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 26. 30.  8.  9. 10.  8.  8. 10.  1. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0.  3.  3. 22. 11.] 
adversary cards in discard: [ 8.  0.  3.  3.  3.  0.  6. 11.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1 11 11  8  6] -> size -> 19 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 50.92668533325195



action possibilites: [-1. 29. 29.] 
expected returns: [[17.18958 ]
 [31.870752]
 [31.870752]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 27. 30. 26. 30.  8.  9. 10.  8.  8. 10.  1. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0.  3.  3. 22. 11.] 
adversary cards in discard: [ 8.  0.  3.  3.  3.  0.  6. 11.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1 11 11  8  6] -> size -> 19 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 32.611656188964844



action possibilites: [-1. 29.] 
expected returns: [[18.273645]
 [34.26974 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 3 
card supply: [30. 27. 30. 26. 30.  8.  9. 10.  8.  8. 10.  1. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0.  3.  3. 22. 11.] 
adversary cards in discard: [ 8.  0.  3.  3.  3.  0.  6. 11.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1 11 11  8  6] -> size -> 19 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 31.870752334594727



action possibilites: [-1.] 
expected returns: [[23.856985]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 4 
card supply: [30. 27. 30. 26. 30.  8.  9. 10.  8.  8. 10.  1. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0.  3.  3. 22. 11.] 
adversary cards in discard: [ 8.  0.  3.  3.  3.  0.  6. 11.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1 11 11  8  6] -> size -> 19 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 34.26974868774414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 25.47915  ]
 [ 37.58     ]
 [ -1.6810291]
 [ 30.518686 ]
 [  3.3496585]
 [-29.241087 ]
 [ 31.629599 ]
 [ 35.224648 ]
 [ 27.445242 ]
 [ 39.213955 ]
 [ 42.540604 ]
 [ 32.37593  ]
 [ 36.837044 ]
 [ 32.58861  ]
 [ 18.786652 ]
 [ 37.975006 ]
 [ 26.540533 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 7 
card supply: [30. 27. 30. 26. 30.  8.  9. 10.  8.  8. 10.  1. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0.  3.  3. 22. 11.] 
adversary cards in discard: [ 8.  0.  3.  3.  3.  0.  6. 11.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1 11 11  8  6] -> size -> 19 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 23.856985092163086



buy possibilites: [-1] 
expected returns: [[50.50566]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 27. 30. 26. 30.  8.  9. 10.  8.  8. 10.  0. 10. 10. 10.  9. 10.] 
adversary cards in hand: [ 0.  3.  3. 22. 11.] 
adversary cards in discard: [ 8.  0.  3.  3.  3.  0.  6. 11.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1 11 11  8  6] -> size -> 19 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.  80.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: 77.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 42.540592193603516






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  3. 22. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 22. 11.] 
cards in discard: [ 8.  0.  3.  3.  3.  0.  6. 11.  1.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1 11 11  8  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 26. 30.  8.  9. 10.  8.  8. 10.  0. 10. 10. 10.  9. 10.] 
adversary cards in hand: [29. 29.  3.  0.  0.] 
adversary cards in discard: [29. 29. 29. 29. 29.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29] -> size -> 23 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 22. 11.] 
cards in discard: [ 8.  0.  3.  3.  3.  0.  6. 11.  1.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1 11 11  8  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 27. 30. 26. 30.  8.  9. 10.  8.  8. 10.  0. 10. 10. 10.  9. 10.] 
adversary cards in hand: [29. 29.  3.  0.  0.] 
adversary cards in discard: [29. 29. 29. 29. 29.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29] -> size -> 23 
adversary victory points: 4
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29. 29.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[50.386463]
 [63.239376]
 [63.239376]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  3.  0.  0.] 
cards in discard: [29. 29. 29. 29. 29.  0.  0.  0.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 26. 30.  8.  9. 10.  8.  8. 10.  0. 10. 10. 10.  9. 10.] 
adversary cards in hand: [22. 11.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1 11 11  8  6] -> size -> 19 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 50.50566101074219



action possibilites: [-1.] 
expected returns: [[77.48744]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [29. 29. 29. 29. 29.  0.  0.  0.  3.  3. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 27. 30. 26. 30.  8.  9. 10.  8.  8. 10.  0. 10. 10. 10.  9. 10.] 
adversary cards in hand: [22. 11.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1 11 11  8  6] -> size -> 19 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 56.11223220825195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[76.91179  ]
 [88.73539  ]
 [81.85724  ]
 [15.1681595]
 [83.591965 ]
 [86.655266 ]
 [79.37044  ]
 [84.22439  ]
 [84.40588  ]
 [89.05684  ]
 [79.2449   ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [29. 29. 29. 29. 29.  0.  0.  0.  3.  3. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 27. 30. 26. 30.  8.  9. 10.  8.  8. 10.  0. 10. 10. 10.  9. 10.] 
adversary cards in hand: [22. 11.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1 11 11  8  6] -> size -> 19 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 77.48744201660156



buy possibilites: [-1] 
expected returns: [[127.37048]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [29. 29. 29. 29. 29.  0.  0.  0.  3.  3. 29. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 26. 30.  8.  9. 10.  8.  8. 10.  0. 10. 10. 10.  9.  9.] 
adversary cards in hand: [22. 11.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1 11 11  8  6] -> size -> 19 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 113 

action type: buy - action 15.0
Learning step: 0
desired expected reward: 89.05685424804688






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [22. 11.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22. 11.  0.  8.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 22  3  3  3  8  1 11 11  8  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 26. 30.  8.  9. 10.  8.  8. 10.  0. 10. 10. 10.  9.  9.] 
adversary cards in hand: [ 3.  1. 29. 29.  1.] 
adversary cards in discard: [29. 29. 29. 29. 29.  0.  0.  0.  3.  3. 29. 15. 29.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15] -> size -> 24 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 22  3  3  3  8  1 11  8  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 26. 30.  8.  9. 10.  8.  8. 10.  0. 10. 10. 10.  9.  9.] 
adversary cards in hand: [ 3.  1. 29. 29.  1.] 
adversary cards in discard: [29. 29. 29. 29. 29.  0.  0.  0.  3.  3. 29. 15. 29.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15] -> size -> 24 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 22  3  3  3  8  1 11  8  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [30. 27. 30. 26. 30.  8.  9. 10.  8.  8. 10.  0. 10. 10. 10.  9.  9.] 
adversary cards in hand: [ 3.  1. 29. 29.  1.] 
adversary cards in discard: [29. 29. 29. 29. 29.  0.  0.  0.  3.  3. 29. 15. 29.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15] -> size -> 24 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.] 
cards in discard: [0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 22  3  3  3  8  1 11  8  6  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 26. 30.  8.  9. 10.  8.  8. 10.  0. 10. 10. 10.  9.  9.] 
adversary cards in hand: [ 3.  1. 29. 29.  1.] 
adversary cards in discard: [29. 29. 29. 29. 29.  0.  0.  0.  3.  3. 29. 15. 29.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15] -> size -> 24 
adversary victory points: 4
player victory points: 5 





Player: 0 
cards in hand: [ 3.  1. 29. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[39.686024]
 [52.06808 ]
 [52.06808 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 29. 29.  1.] 
cards in discard: [29. 29. 29. 29. 29.  0.  0.  0.  3.  3. 29. 15. 29.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 26. 30.  8.  9. 10.  8.  8. 10.  0. 10. 10. 10.  9.  9.] 
adversary cards in hand: [0. 0. 3. 3. 8.] 
adversary cards in discard: [ 0.  8. 22.] 
adversary owned cards: [ 0  0  0  0  3  3  3 22  3  3  3  8  1 11  8  6  0] -> size -> 17 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 127.3704833984375



action possibilites: [-1. 29.] 
expected returns: [[-2.0680795]
 [10.324749 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  1.  0.] 
cards in discard: [29. 29. 29. 29. 29.  0.  0.  0.  3.  3. 29. 15. 29.  3.  0.  0.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 27. 30. 26. 30.  8.  9. 10.  8.  8. 10.  0. 10. 10. 10.  9.  9.] 
adversary cards in hand: [0. 0. 3. 3. 8.] 
adversary cards in discard: [ 0.  8. 22.] 
adversary owned cards: [ 0  0  0  0  3  3  3 22  3  3  3  8  1 11  8  6  0] -> size -> 17 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 48.06110763549805



action possibilites: [-1. 29.] 
expected returns: [[21.506536]
 [33.800774]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.] 
cards in discard: [29. 29. 29. 29. 29.  0.  0.  0.  3.  3. 29. 15. 29.  3.  0.  0.  0.  1.
  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15] -> size -> 24 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 27. 30. 26. 30.  8.  9. 10.  8.  8. 10.  0. 10. 10. 10.  9.  9.] 
adversary cards in hand: [0. 0. 3. 3. 8.] 
adversary cards in discard: [ 0.  8. 22.] 
adversary owned cards: [ 0  0  0  0  3  3  3 22  3  3  3  8  1 11  8  6  0] -> size -> 17 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 6.467016696929932



action possibilites: [-1.] 
expected returns: [[8.146206]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15] -> size -> 24 
action values: 1 
buys: 0 
player value: 3 
card supply: [29. 27. 30. 26. 30.  8.  9. 10.  8.  8. 10.  0. 10. 10. 10.  9.  9.] 
adversary cards in hand: [0. 0. 3. 3. 8.] 
adversary cards in discard: [ 0.  8. 22.] 
adversary owned cards: [ 0  0  0  0  3  3  3 22  3  3  3  8  1 11  8  6  0] -> size -> 17 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 29.970125198364258





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[  8.062794]
 [ 20.478792]
 [ 13.053057]
 [-50.595272]
 [ 14.335215]
 [ 17.988415]
 [ 10.22241 ]
 [ 15.088533]
 [ 15.304972]
 [ 20.852192]
 [  9.523964]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 27. 30. 26. 30.  8.  9. 10.  8.  8. 10.  0. 10. 10. 10.  9.  9.] 
adversary cards in hand: [0. 0. 3. 3. 8.] 
adversary cards in discard: [ 0.  8. 22.] 
adversary owned cards: [ 0  0  0  0  3  3  3 22  3  3  3  8  1 11  8  6  0] -> size -> 17 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 8.14620590209961



buy possibilites: [-1] 
expected returns: [[19.968292]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [29. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15
 15] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 26. 30.  8.  9. 10.  8.  8. 10.  0. 10. 10. 10.  9.  8.] 
adversary cards in hand: [0. 0. 3. 3. 8.] 
adversary cards in discard: [ 0.  8. 22.] 
adversary owned cards: [ 0  0  0  0  3  3  3 22  3  3  3  8  1 11  8  6  0] -> size -> 17 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 153 

action type: buy - action 15.0
Learning step: 0
desired expected reward: 20.852197647094727






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 8.] 
cards in discard: [ 0.  8. 22.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 22  3  3  3  8  1 11  8  6  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 26. 30.  8.  9. 10.  8.  8. 10.  0. 10. 10. 10.  9.  8.] 
adversary cards in hand: [29.  1.  0. 29.  0.] 
adversary cards in discard: [29. 15. 29. 29. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15
 15] -> size -> 25 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [ 0.  8. 22.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 26. 30.  8.  9. 10.  8.  8. 10.  0. 10. 10. 10.  9.  8.] 
adversary cards in hand: [29.  1.  0. 29.  0.] 
adversary cards in discard: [29. 15. 29. 29. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15
 15] -> size -> 25 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [ 0.  8. 22.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 27. 30. 26. 30.  8.  9. 10.  8.  8. 10.  0. 10. 10. 10.  9.  8.] 
adversary cards in hand: [29.  1.  0. 29.  0.] 
adversary cards in discard: [29. 15. 29. 29. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15
 15] -> size -> 25 
adversary victory points: 4
player victory points: 5 





Player: 0 
cards in hand: [29.  1.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[ 89.00816]
 [101.57803]
 [101.57803]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  0. 29.  0.] 
cards in discard: [29. 15. 29. 29. 29.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15
 15] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 26. 30.  8.  9. 10.  8.  8. 10.  0. 10. 10. 10.  9.  8.] 
adversary cards in hand: [3. 3. 1. 3. 3.] 
adversary cards in discard: [ 0.  8. 22.  8.  3.  3.] 
adversary owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0] -> size -> 15 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 19.968292236328125



action possibilites: [-1. 29.] 
expected returns: [[ 99.88615]
 [113.47319]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.] 
cards in discard: [29. 15. 29. 29. 29.  3.  0.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15
 15] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 27. 30. 26. 30.  8.  9. 10.  8.  8. 10.  0. 10. 10. 10.  9.  8.] 
adversary cards in hand: [3. 3. 1. 3. 3.] 
adversary cards in discard: [ 0.  8. 22.  8.  3.  3.] 
adversary owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0] -> size -> 15 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 92.98957824707031



action possibilites: [-1.] 
expected returns: [[136.63272]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [29. 15. 29. 29. 29.  3.  0.  1. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15
 15] -> size -> 25 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 27. 30. 26. 30.  8.  9. 10.  8.  8. 10.  0. 10. 10. 10.  9.  8.] 
adversary cards in hand: [3. 3. 1. 3. 3.] 
adversary cards in discard: [ 0.  8. 22.  8.  3.  3.] 
adversary owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0] -> size -> 15 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 109.38972473144531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[137.69771]
 [149.22867]
 [142.70192]
 [110.11318]
 [ 74.83537]
 [144.53468]
 [147.58286]
 [140.09836]
 [150.69626]
 [145.1852 ]
 [148.68895]
 [145.36418]
 [129.73006]
 [149.66653]
 [140.27623]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [29. 15. 29. 29. 29.  3.  0.  1. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15
 15] -> size -> 25 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 27. 30. 26. 30.  8.  9. 10.  8.  8. 10.  0. 10. 10. 10.  9.  8.] 
adversary cards in hand: [3. 3. 1. 3. 3.] 
adversary cards in discard: [ 0.  8. 22.  8.  3.  3.] 
adversary owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0] -> size -> 15 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 136.63272094726562



buy possibilites: [-1] 
expected returns: [[193.09044]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [29. 15. 29. 29. 29.  3.  0.  1. 29. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15
 15 25] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 26. 30.  8.  9. 10.  8.  8.  9.  0. 10. 10. 10.  9.  8.] 
adversary cards in hand: [3. 3. 1. 3. 3.] 
adversary cards in discard: [ 0.  8. 22.  8.  3.  3.] 
adversary owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0] -> size -> 15 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 255 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 150.6962432861328






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [3. 3. 1. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 1. 3. 3.] 
cards in discard: [ 0.  8. 22.  8.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 26. 30.  8.  9. 10.  8.  8.  9.  0. 10. 10. 10.  9.  8.] 
adversary cards in hand: [29.  3. 29.  3.  3.] 
adversary cards in discard: [29. 15. 29. 29. 29.  3.  0.  1. 29. 25. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15
 15 25] -> size -> 26 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 3. 3.] 
cards in discard: [ 0.  8. 22.  8.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 27. 30. 26. 30.  8.  9. 10.  8.  8.  9.  0. 10. 10. 10.  9.  8.] 
adversary cards in hand: [29.  3. 29.  3.  3.] 
adversary cards in discard: [29. 15. 29. 29. 29.  3.  0.  1. 29. 25. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15
 15 25] -> size -> 26 
adversary victory points: 4
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29.  3. 29.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[38.684837]
 [49.40756 ]
 [49.40756 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 29.  3.  3.] 
cards in discard: [29. 15. 29. 29. 29.  3.  0.  1. 29. 25. 29. 29.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15
 15 25] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 26. 30.  8.  9. 10.  8.  8.  9.  0. 10. 10. 10.  9.  8.] 
adversary cards in hand: [ 3.  0.  6. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0] -> size -> 15 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 193.09043884277344



action possibilites: [-1. 29. 15.] 
expected returns: [[ 95.87663 ]
 [108.32691 ]
 [104.670746]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  3. 15.] 
cards in discard: [29. 15. 29. 29. 29.  3.  0.  1. 29. 25. 29. 29.  0.  0.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15
 15 25] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 27. 30. 26. 30.  8.  9. 10.  8.  8.  9.  0. 10. 10. 10.  9.  8.] 
adversary cards in hand: [ 3.  0.  6. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0] -> size -> 15 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 45.06267547607422



action possibilites: [-1. 15.] 
expected returns: [[71.60011]
 [81.09253]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0.] 
cards in discard: [29. 15. 29. 29. 29.  3.  0.  1. 29. 25. 29. 29.  0.  0.  0.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15
 15 25] -> size -> 26 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 27. 30. 26. 30.  8.  9. 10.  8.  8.  9.  0. 10. 10. 10.  9.  8.] 
adversary cards in hand: [ 3.  0.  6. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0] -> size -> 15 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 104.46824645996094



action possibilites: [-1] 
expected returns: [[53.96015]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [29. 15. 29. 29. 29.  3.  0.  1. 29. 25. 29. 29.  0.  0.  0.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 5 
card supply: [29. 27. 30. 26. 30.  8.  9. 10.  8.  8.  9.  0. 10. 10. 10.  9.  8.] 
adversary cards in hand: [ 3.  0.  6. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0] -> size -> 15 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 81.09252166748047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[49.9047  ]
 [60.0493  ]
 [54.39786 ]
 [26.16825 ]
 [-5.731253]
 [56.297596]
 [58.316673]
 [50.95706 ]
 [60.988094]
 [56.69795 ]
 [59.51783 ]
 [56.8188  ]
 [43.37077 ]
 [60.19422 ]
 [53.374123]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [29. 15. 29. 29. 29.  3.  0.  1. 29. 25. 29. 29.  0.  0.  0.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25] -> size -> 25 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 27. 30. 26. 30.  8.  9. 10.  8.  8.  9.  0. 10. 10. 10.  9.  8.] 
adversary cards in hand: [ 3.  0.  6. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0] -> size -> 15 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 53.96015167236328



buy possibilites: [-1] 
expected returns: [[21.470629]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [29. 15. 29. 29. 29.  3.  0.  1. 29. 25. 29. 29.  0.  0.  0.  3.  3. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 26. 30.  8.  9. 10.  8.  8.  8.  0. 10. 10. 10.  9.  8.] 
adversary cards in hand: [ 3.  0.  6. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0] -> size -> 15 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 275 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 60.9881477355957






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  6. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  6. 11.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 26. 30.  8.  9. 10.  8.  8.  8.  0. 10. 10. 10.  9.  8.] 
adversary cards in hand: [25. 29.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25] -> size -> 26 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  6. 11.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 27. 30. 26. 30.  8.  9. 10.  8.  8.  8.  0. 10. 10. 10.  9.  8.] 
adversary cards in hand: [25. 29.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25] -> size -> 26 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  6. 11.  0.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 27. 30. 26. 30.  8.  9. 10.  8.  8.  8.  0. 10. 10. 10.  9.  8.] 
adversary cards in hand: [25. 29.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25] -> size -> 26 
adversary victory points: 4
player victory points: 5 





Player: 0 
cards in hand: [25. 29.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[ 7.8607945]
 [19.136806 ]
 [22.374332 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29.  1.  0.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 26. 30.  8.  9. 10.  8.  8.  8.  0. 10. 10. 10.  9.  8.] 
adversary cards in hand: [ 0.  8.  3.  3. 22.] 
adversary cards in discard: [ 0.  3.  0.  6. 11.  0.] 
adversary owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0  0] -> size -> 16 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 21.47062873840332



action possibilites: [-1. 25. 29.] 
expected returns: [[10.820984]
 [22.5137  ]
 [25.661304]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0. 29.] 
cards in discard: [1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 26. 30.  8.  9. 10.  8.  8.  8.  0. 10. 10. 10.  9.  8.] 
adversary cards in hand: [ 0.  8.  3.  3. 22.] 
adversary cards in discard: [ 0.  3.  0.  6. 11.  0.] 
adversary owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0  0] -> size -> 16 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 16.020139694213867



action possibilites: [-1.] 
expected returns: [[50.34615]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 1. 25.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25] -> size -> 26 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 27. 30. 26. 30.  8.  9. 10.  8.  8.  8.  0. 10. 10. 10.  9.  8.] 
adversary cards in hand: [ 0.  8.  3.  3. 22.] 
adversary cards in discard: [ 0.  3.  0.  6. 11.  0.] 
adversary owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0  0] -> size -> 16 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 20.415639877319336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[49.509056]
 [62.1105  ]
 [54.640873]
 [25.329962]
 [-9.249817]
 [56.038765]
 [59.63547 ]
 [51.86179 ]
 [63.717472]
 [56.779465]
 [61.336742]
 [56.99269 ]
 [41.99727 ]
 [62.470943]
 [50.929115]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 1. 25.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25] -> size -> 26 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 27. 30. 26. 30.  8.  9. 10.  8.  8.  8.  0. 10. 10. 10.  9.  8.] 
adversary cards in hand: [ 0.  8.  3.  3. 22.] 
adversary cards in discard: [ 0.  3.  0.  6. 11.  0.] 
adversary owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0  0] -> size -> 16 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 50.34614944458008



buy possibilites: [-1] 
expected returns: [[42.541904]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 1. 25. 25.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 26. 30.  8.  9. 10.  8.  8.  7.  0. 10. 10. 10.  9.  8.] 
adversary cards in hand: [ 0.  8.  3.  3. 22.] 
adversary cards in discard: [ 0.  3.  0.  6. 11.  0.] 
adversary owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0  0] -> size -> 16 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 255 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 63.71747970581055






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  3.  3. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  3.  3. 22.] 
cards in discard: [ 0.  3.  0.  6. 11.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 26. 30.  8.  9. 10.  8.  8.  7.  0. 10. 10. 10.  9.  8.] 
adversary cards in hand: [ 0.  0.  1. 29.  3.] 
adversary cards in discard: [ 1. 25. 25. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25] -> size -> 27 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 3. 1. 3. 3.] 
cards in discard: [ 0.  3.  0.  6. 11.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 26. 30.  8.  9. 10.  8.  8.  7.  0. 10. 10. 10.  9.  8.] 
adversary cards in hand: [ 0.  0.  1. 29.  3.] 
adversary cards in discard: [ 1. 25. 25. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25] -> size -> 27 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 3. 1. 3. 3.] 
cards in discard: [ 0.  3.  0.  6. 11.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 27. 30. 26. 30.  8.  9. 10.  8.  8.  7.  0. 10. 10. 10.  9.  8.] 
adversary cards in hand: [ 0.  0.  1. 29.  3.] 
adversary cards in discard: [ 1. 25. 25. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25] -> size -> 27 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 3. 1. 3. 3.] 
cards in discard: [ 0.  3.  0.  6. 11.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 27. 30. 26. 30.  8.  9. 10.  8.  8.  7.  0. 10. 10. 10.  9.  8.] 
adversary cards in hand: [ 0.  0.  1. 29.  3.] 
adversary cards in discard: [ 1. 25. 25. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25] -> size -> 27 
adversary victory points: 4
player victory points: 5 





Player: 0 
cards in hand: [ 0.  0.  1. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[137.05534]
 [150.59767]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 29.  3.] 
cards in discard: [ 1. 25. 25. 29. 29.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 26. 30.  8.  9. 10.  8.  8.  7.  0. 10. 10. 10.  9.  8.] 
adversary cards in hand: [ 3. 11.  6.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0  0  0] -> size -> 17 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 42.54190444946289



action possibilites: [-1.] 
expected returns: [[146.3261]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 1. 25. 25. 29. 29.  0.  0.  0.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 26. 30.  8.  9. 10.  8.  8.  7.  0. 10. 10. 10.  9.  8.] 
adversary cards in hand: [ 3. 11.  6.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0  0  0] -> size -> 17 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 143.01942443847656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[144.08928]
 [155.97154]
 [149.01242]
 [ 85.10227]
 [150.55005]
 [154.0047 ]
 [146.85716]
 [151.2822 ]
 [151.48544]
 [156.43802]
 [145.70534]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 1. 25. 25. 29. 29.  0.  0.  0.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 27. 30. 26. 30.  8.  9. 10.  8.  8.  7.  0. 10. 10. 10.  9.  8.] 
adversary cards in hand: [ 3. 11.  6.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0  0  0] -> size -> 17 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 146.3260955810547



buy possibilites: [-1] 
expected returns: [[136.97803]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 1. 25. 25. 29. 29.  0.  0.  0.  1. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 26. 30.  8.  9. 10.  8.  8.  7.  0. 10. 10. 10.  9.  7.] 
adversary cards in hand: [ 3. 11.  6.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0  0  0] -> size -> 17 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 113 

action type: buy - action 15.0
Learning step: 0
desired expected reward: 156.4380340576172






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 3. 11.  6.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  6.  8.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 26. 30.  8.  9. 10.  8.  8.  7.  0. 10. 10. 10.  9.  7.] 
adversary cards in hand: [ 3. 29.  3.  3. 15.] 
adversary cards in discard: [ 1. 25. 25. 29. 29.  0.  0.  0.  1. 15. 29.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15] -> size -> 28 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 8. 3.] 
cards in discard: [10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0  0  0 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 26. 30.  8.  9. 10.  8.  8.  7.  0. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3. 29.  3.  3. 15.] 
adversary cards in discard: [ 1. 25. 25. 29. 29.  0.  0.  0.  1. 15. 29.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15] -> size -> 28 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 8. 3.] 
cards in discard: [10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0  0  0 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 27. 30. 26. 30.  8.  9. 10.  8.  8.  7.  0. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3. 29.  3.  3. 15.] 
adversary cards in discard: [ 1. 25. 25. 29. 29.  0.  0.  0.  1. 15. 29.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15] -> size -> 28 
adversary victory points: 4
player victory points: 5 





Player: 0 
cards in hand: [ 3. 29.  3.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
expected returns: [[29.459513]
 [42.172638]
 [38.331345]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3.  3. 15.] 
cards in discard: [ 1. 25. 25. 29. 29.  0.  0.  0.  1. 15. 29.  0.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 26. 30.  8.  9. 10.  8.  8.  7.  0. 10. 10.  9.  9.  7.] 
adversary cards in hand: [1. 3. 0. 8. 3.] 
adversary cards in discard: [10. 11.  3.  6.  8.  3.] 
adversary owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0  0  0 10] -> size -> 18 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 136.97802734375



action possibilites: [-1. 15. 29.] 
expected returns: [[24.184374]
 [33.762287]
 [37.769398]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 15. 29.] 
cards in discard: [ 1. 25. 25. 29. 29.  0.  0.  0.  1. 15. 29.  0.  0.  3.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 26. 30.  8.  9. 10.  8.  8.  7.  0. 10. 10.  9.  9.  7.] 
adversary cards in hand: [1. 3. 0. 8. 3.] 
adversary cards in discard: [10. 11.  3.  6.  8.  3.] 
adversary owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0  0  0 10] -> size -> 18 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 38.1970100402832



action possibilites: [-1. 15. 29.] 
expected returns: [[42.90534 ]
 [52.664257]
 [56.69912 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 29.] 
cards in discard: [ 1. 25. 25. 29. 29.  0.  0.  0.  1. 15. 29.  0.  0.  3.  0.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 27. 30. 26. 30.  8.  9. 10.  8.  8.  7.  0. 10. 10.  9.  9.  7.] 
adversary cards in hand: [1. 3. 0. 8. 3.] 
adversary cards in discard: [10. 11.  3.  6.  8.  3.] 
adversary owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0  0  0 10] -> size -> 18 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 33.536346435546875



action possibilites: [-1. 15.] 
expected returns: [[63.55881]
 [74.1667 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.] 
cards in discard: [ 1. 25. 25. 29. 29.  0.  0.  0.  1. 15. 29.  0.  0.  3.  0.  3.  3. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 3 
card supply: [27. 27. 30. 26. 30.  8.  9. 10.  8.  8.  7.  0. 10. 10.  9.  9.  7.] 
adversary cards in hand: [1. 3. 0. 8. 3.] 
adversary cards in discard: [10. 11.  3.  6.  8.  3.] 
adversary owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0  0  0 10] -> size -> 18 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 52.40675735473633



action possibilites: [-1] 
expected returns: [[51.68248]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 1. 25. 25. 29. 29.  0.  0.  0.  1. 15. 29.  0.  0.  3.  0.  3.  3. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 27. 30. 26. 30.  8.  9. 10.  8.  8.  7.  0. 10. 10.  9.  9.  7.] 
adversary cards in hand: [1. 3. 0. 8. 3.] 
adversary cards in discard: [10. 11.  3.  6.  8.  3.] 
adversary owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0  0  0 10] -> size -> 18 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 45 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 74.16671752929688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[49.92921  ]
 [61.45653  ]
 [54.70943  ]
 [-5.1336055]
 [59.200874 ]
 [51.767918 ]
 [56.8687   ]
 [51.517807 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 1. 25. 25. 29. 29.  0.  0.  0.  1. 15. 29.  0.  0.  3.  0.  3.  3. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 27. 30. 26. 30.  8.  9. 10.  8.  8.  7.  0. 10. 10.  9.  9.  7.] 
adversary cards in hand: [1. 3. 0. 8. 3.] 
adversary cards in discard: [10. 11.  3.  6.  8.  3.] 
adversary owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0  0  0 10] -> size -> 18 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 51.68247985839844



buy possibilites: [-1] 
expected returns: [[-32.525555]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 1. 25. 25. 29. 29.  0.  0.  0.  1. 15. 29.  0.  0.  3.  0.  3.  3. 15.
  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 26. 30.  8.  9. 10.  8.  8.  7.  0. 10. 10.  9.  9.  7.] 
adversary cards in hand: [1. 3. 0. 8. 3.] 
adversary cards in discard: [10. 11.  3.  6.  8.  3.] 
adversary owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0  0  0 10] -> size -> 18 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  80   0   0   0   0   0   0   0  54   0] 
sum of rewards: 99 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 61.45656967163086






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [1. 3. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 8. 3.] 
cards in discard: [10. 11.  3.  6.  8.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0  0  0 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 26. 30.  8.  9. 10.  8.  8.  7.  0. 10. 10.  9.  9.  7.] 
adversary cards in hand: [29. 25. 29. 29. 29.] 
adversary cards in discard: [ 1. 25. 25. 29. 29.  0.  0.  0.  1. 15. 29.  0.  0.  3.  0.  3.  3. 15.
  1. 29. 29. 29. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15  1] -> size -> 29 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 8. 3.] 
cards in discard: [10. 11.  3.  6.  8.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0  0  0 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 26. 30. 26. 30.  8.  9. 10.  8.  8.  7.  0. 10. 10.  9.  9.  7.] 
adversary cards in hand: [29. 25. 29. 29. 29.] 
adversary cards in discard: [ 1. 25. 25. 29. 29.  0.  0.  0.  1. 15. 29.  0.  0.  3.  0.  3.  3. 15.
  1. 29. 29. 29. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15  1] -> size -> 29 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 8. 3.] 
cards in discard: [10. 11.  3.  6.  8.  3.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0  0  0 10  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 26. 30.  8.  9. 10.  8.  7.  7.  0. 10. 10.  9.  9.  7.] 
adversary cards in hand: [29. 25. 29. 29. 29.] 
adversary cards in discard: [ 1. 25. 25. 29. 29.  0.  0.  0.  1. 15. 29.  0.  0.  3.  0.  3.  3. 15.
  1. 29. 29. 29. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15  1] -> size -> 29 
adversary victory points: 4
player victory points: 5 





Player: 0 
cards in hand: [29. 25. 29. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29. 29. 29.] 
expected returns: [[13.33313 ]
 [25.038727]
 [22.269922]
 [25.038727]
 [25.038727]
 [25.038727]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 29. 29. 29.] 
cards in discard: [ 1. 25. 25. 29. 29.  0.  0.  0.  1. 15. 29.  0.  0.  3.  0.  3.  3. 15.
  1. 29. 29. 29. 15.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 26. 30.  8.  9. 10.  8.  7.  7.  0. 10. 10.  9.  9.  7.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [10. 11.  3.  6.  8.  3.  8.  1.  3.  0.  8.  3.] 
adversary owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0  0  0 10  8] -> size -> 19 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -32.52555465698242



action possibilites: [-1. 29. 29. 29. 29.] 
expected returns: [[-6.388966]
 [ 7.721872]
 [ 7.721872]
 [ 7.721872]
 [ 7.721872]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29. 29.] 
cards in discard: [25.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 26. 30.  8.  9. 10.  8.  7.  7.  0. 10. 10.  9.  9.  7.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [10. 11.  3.  6.  8.  3.  8.  1.  3.  0.  8.  3.] 
adversary owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0  0  0 10  8] -> size -> 19 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 21.36473846435547



action possibilites: [-1. 29. 29. 29.] 
expected returns: [[10.725636]
 [24.174543]
 [24.174543]
 [24.174543]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29.] 
cards in discard: [25.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 26. 30. 26. 30.  8.  9. 10.  8.  7.  7.  0. 10. 10.  9.  9.  7.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [10. 11.  3.  6.  8.  3.  8.  1.  3.  0.  8.  3.] 
adversary owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0  0  0 10  8] -> size -> 19 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 3.315093517303467



action possibilites: [-1. 29.] 
expected returns: [[22.574205]
 [35.910885]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.] 
cards in discard: [25.  1. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 3 
card supply: [27. 26. 30. 26. 30.  8.  9. 10.  8.  7.  7.  0. 10. 10.  9.  9.  7.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [10. 11.  3.  6.  8.  3.  8.  1.  3.  0.  8.  3.] 
adversary owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0  0  0 10  8] -> size -> 19 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 19.951053619384766



action possibilites: [-1.] 
expected returns: [[30.954058]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [25.  1. 29. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 4 
card supply: [27. 26. 30. 26. 30.  8.  9. 10.  8.  7.  7.  0. 10. 10.  9.  9.  7.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [10. 11.  3.  6.  8.  3.  8.  1.  3.  0.  8.  3.] 
adversary owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0  0  0 10  8] -> size -> 19 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 31.800260543823242





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 30.981726]
 [ 42.637367]
 [ 35.684036]
 [  6.708467]
 [-27.588617]
 [ 37.26862 ]
 [ 40.24299 ]
 [ 32.968143]
 [ 43.884968]
 [ 37.863594]
 [ 41.908173]
 [ 38.041237]
 [ 23.65734 ]
 [ 42.833572]
 [ 32.994183]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [25.  1. 29. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15  1] -> size -> 29 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 26. 30. 26. 30.  8.  9. 10.  8.  7.  7.  0. 10. 10.  9.  9.  7.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [10. 11.  3.  6.  8.  3.  8.  1.  3.  0.  8.  3.] 
adversary owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0  0  0 10  8] -> size -> 19 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 30.954057693481445



buy possibilites: [-1] 
expected returns: [[84.846375]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [25.  1. 29. 29. 25.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15  1 25] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 26. 30.  8.  9. 10.  8.  7.  6.  0. 10. 10.  9.  9.  7.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [10. 11.  3.  6.  8.  3.  8.  1.  3.  0.  8.  3.] 
adversary owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0  0  0 10  8] -> size -> 19 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  80   0   0   0   0   0   0   0 250   0] 
sum of rewards: 295 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 43.88499450683594






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [10. 11.  3.  6.  8.  3.  8.  1.  3.  0.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0  0  0 10  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 26. 30.  8.  9. 10.  8.  7.  6.  0. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  3. 25.  1.  0.] 
adversary cards in discard: [25.  1. 29. 29. 25. 29. 29. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15  1 25] -> size -> 30 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [10. 11.  3.  6.  8.  3.  8.  1.  3.  0.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0  0  0 10  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 26. 30. 26. 30.  8.  9. 10.  8.  7.  6.  0. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  3. 25.  1.  0.] 
adversary cards in discard: [25.  1. 29. 29. 25. 29. 29. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15  1 25] -> size -> 30 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [10. 11.  3.  6.  8.  3.  8.  1.  3.  0.  8.  3. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0  0  0 10  8 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 26. 30.  8.  9. 10.  7.  7.  6.  0. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 0.  3. 25.  1.  0.] 
adversary cards in discard: [25.  1. 29. 29. 25. 29. 29. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15  1 25] -> size -> 30 
adversary victory points: 4
player victory points: 5 





Player: 0 
cards in hand: [ 0.  3. 25.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[20.637468]
 [29.52997 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25.  1.  0.] 
cards in discard: [25.  1. 29. 29. 25. 29. 29. 29. 29.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15  1 25] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 26. 30.  8.  9. 10.  7.  7.  6.  0. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3.  8.  3.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0  0  0 10  8 11] -> size -> 20 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 84.84637451171875



action possibilites: [-1] 
expected returns: [[34.691597]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1.  0. 29. 29.] 
cards in discard: [25.  1. 29. 29. 25. 29. 29. 29. 29.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15  1 25] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 26. 30.  8.  8. 10.  7.  7.  6.  0. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3.  8.  3.  0. 22.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0  0  0 10  8 11  6] -> size -> 21 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 29.52996253967285





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[ 30.991415]
 [ 41.874218]
 [ 35.575153]
 [-22.13611 ]
 [ 37.22145 ]
 [ 39.698383]
 [ 32.2084  ]
 [ 37.70778 ]
 [ 37.856384]
 [ 41.98428 ]
 [ 33.64161 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1.  0. 29. 29.] 
cards in discard: [25.  1. 29. 29. 25. 29. 29. 29. 29.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15  1 25] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 26. 30. 26. 30.  8.  8. 10.  7.  7.  6.  0. 10. 10.  9.  9.  7.] 
adversary cards in hand: [ 3.  8.  3.  0. 22.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0  0  0 10  8 11  6] -> size -> 21 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 34.69159698486328



buy possibilites: [-1] 
expected returns: [[59.23531]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1.  0. 29. 29.] 
cards in discard: [25.  1. 29. 29. 25. 29. 29. 29. 29.  0. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15  1 25 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 26. 30.  8.  8. 10.  7.  7.  6.  0. 10. 10.  9.  9.  6.] 
adversary cards in hand: [ 3.  8.  3.  0. 22.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0  0  0 10  8 11  6] -> size -> 21 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 113 

action type: buy - action 15.0
Learning step: 0
desired expected reward: 41.98430252075195






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 3.  8.  3.  0. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  3.  0. 22.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 22  3  3  3  8  1 11  8  6  0  0  0 10  8 11  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 26. 30.  8.  8. 10.  7.  7.  6.  0. 10. 10.  9.  9.  6.] 
adversary cards in hand: [ 0.  0. 15. 25.  0.] 
adversary cards in discard: [25.  1. 29. 29. 25. 29. 29. 29. 29.  0. 15. 25.  0.  3.  1.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15  1 25 15] -> size -> 31 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  3  3  8  1 11  8  6  0  0  0 10  8 11  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 26. 30.  8.  8. 10.  7.  7.  6.  0. 10. 10.  9.  9.  6.] 
adversary cards in hand: [ 0.  0. 15. 25.  0.] 
adversary cards in discard: [25.  1. 29. 29. 25. 29. 29. 29. 29.  0. 15. 25.  0.  3.  1.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15  1 25 15] -> size -> 31 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  3  3  8  1 11  8  6  0  0  0 10  8 11  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 26. 30. 26. 30.  8.  8. 10.  7.  7.  6.  0. 10. 10.  9.  9.  6.] 
adversary cards in hand: [ 0.  0. 15. 25.  0.] 
adversary cards in discard: [25.  1. 29. 29. 25. 29. 29. 29. 29.  0. 15. 25.  0.  3.  1.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15  1 25 15] -> size -> 31 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [6. 0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  3  3  8  1 11  8  6  0  0  0 10  8 11  6  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 26. 30.  8.  8. 10.  7.  7.  6.  0. 10. 10.  9.  9.  6.] 
adversary cards in hand: [ 0.  0. 15. 25.  0.] 
adversary cards in discard: [25.  1. 29. 29. 25. 29. 29. 29. 29.  0. 15. 25.  0.  3.  1.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15  1 25 15] -> size -> 31 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0. 15. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25.] 
expected returns: [[13.381937]
 [21.630682]
 [22.502977]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15. 25.  0.] 
cards in discard: [25.  1. 29. 29. 25. 29. 29. 29. 29.  0. 15. 25.  0.  3.  1.  0. 29. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15  1 25 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  8. 10.  7.  7.  6.  0. 10. 10.  9.  9.  6.] 
adversary cards in hand: [3. 0. 8. 3. 3.] 
adversary cards in discard: [6. 0. 8. 3. 0.] 
adversary owned cards: [ 0  0  3  3  3  3  3  8  1 11  8  6  0  0  0 10  8 11  6  0] -> size -> 20 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 59.23530960083008



action possibilites: [-1] 
expected returns: [[-20.131872]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  0. 15. 29.] 
cards in discard: [25.  1. 29. 29. 25. 29. 29. 29. 29.  0. 15. 25.  0.  3.  1.  0. 29. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15  1 25 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  7. 10.  7.  7.  6.  0. 10. 10.  9.  9.  6.] 
adversary cards in hand: [3. 0. 8. 3. 3.] 
adversary cards in discard: [6. 0. 8. 3. 0. 6.] 
adversary owned cards: [ 0  0  3  3  3  3  3  8  1 11  8  6  0  0  0 10  8 11  6  0  6] -> size -> 21 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 22.502971649169922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-23.0471  ]
 [-12.236813]
 [-18.380568]
 [-74.782486]
 [-14.454014]
 [-22.349638]
 [-16.260176]
 [-20.404228]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  0. 15. 29.] 
cards in discard: [25.  1. 29. 29. 25. 29. 29. 29. 29.  0. 15. 25.  0.  3.  1.  0. 29. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15  1 25 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 26. 30. 26. 30.  8.  7. 10.  7.  7.  6.  0. 10. 10.  9.  9.  6.] 
adversary cards in hand: [3. 0. 8. 3. 3.] 
adversary cards in discard: [6. 0. 8. 3. 0. 6.] 
adversary owned cards: [ 0  0  3  3  3  3  3  8  1 11  8  6  0  0  0 10  8 11  6  0  6] -> size -> 21 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: -20.131872177124023



buy possibilites: [-1] 
expected returns: [[-25.915007]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  0. 15. 29.] 
cards in discard: [25.  1. 29. 29. 25. 29. 29. 29. 29.  0. 15. 25.  0.  3.  1.  0. 29. 29.
  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15  1 25 15  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 26. 30.  8.  7. 10.  7.  7.  6.  0. 10. 10.  9.  9.  6.] 
adversary cards in hand: [3. 0. 8. 3. 3.] 
adversary cards in discard: [6. 0. 8. 3. 0. 6.] 
adversary owned cards: [ 0  0  3  3  3  3  3  8  1 11  8  6  0  0  0 10  8 11  6  0  6] -> size -> 21 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 99 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -12.236799240112305






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [3. 0. 8. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 3. 3.] 
cards in discard: [6. 0. 8. 3. 0. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  3  3  8  1 11  8  6  0  0  0 10  8 11  6  0  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 26. 30.  8.  7. 10.  7.  7.  6.  0. 10. 10.  9.  9.  6.] 
adversary cards in hand: [ 3. 15.  1. 29.  3.] 
adversary cards in discard: [25.  1. 29. 29. 25. 29. 29. 29. 29.  0. 15. 25.  0.  3.  1.  0. 29. 29.
  1. 25.  0.  0. 15.  0. 15. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15  1 25 15  1] -> size -> 32 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3.] 
cards in discard: [6. 0. 8. 3. 0. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3  3  3  8  1 11  8  6  0  0  0 10  8 11  6  0  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 26. 30.  8.  7. 10.  7.  7.  6.  0. 10. 10.  9.  9.  6.] 
adversary cards in hand: [ 3. 15.  1. 29.  3.] 
adversary cards in discard: [25.  1. 29. 29. 25. 29. 29. 29. 29.  0. 15. 25.  0.  3.  1.  0. 29. 29.
  1. 25.  0.  0. 15.  0. 15. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15  1 25 15  1] -> size -> 32 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3.] 
cards in discard: [6. 0. 8. 3. 0. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3  3  3  8  1 11  8  6  0  0  0 10  8 11  6  0  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 25. 30. 26. 30.  8.  7. 10.  7.  7.  6.  0. 10. 10.  9.  9.  6.] 
adversary cards in hand: [ 3. 15.  1. 29.  3.] 
adversary cards in discard: [25.  1. 29. 29. 25. 29. 29. 29. 29.  0. 15. 25.  0.  3.  1.  0. 29. 29.
  1. 25.  0.  0. 15.  0. 15. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15  1 25 15  1] -> size -> 32 
adversary victory points: 4
player victory points: 2 





Player: 0 
cards in hand: [ 3. 15.  1. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
expected returns: [[11.046108]
 [20.337042]
 [24.320261]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  1. 29.  3.] 
cards in discard: [25.  1. 29. 29. 25. 29. 29. 29. 29.  0. 15. 25.  0.  3.  1.  0. 29. 29.
  1. 25.  0.  0. 15.  0. 15. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15  1 25 15  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 26. 30.  8.  7. 10.  7.  7.  6.  0. 10. 10.  9.  9.  6.] 
adversary cards in hand: [ 1.  0.  0.  3. 11.] 
adversary cards in discard: [6. 0. 8. 3. 0. 6. 8. 3. 3. 3.] 
adversary owned cards: [ 0  3  3  3  3  3  8  1 11  8  6  0  0  0 10  8 11  6  0  6] -> size -> 20 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: -25.915006637573242



action possibilites: [-1. 15.] 
expected returns: [[-8.771421  ]
 [-0.21366644]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1.  3.  3.] 
cards in discard: [25.  1. 29. 29. 25. 29. 29. 29. 29.  0. 15. 25.  0.  3.  1.  0. 29. 29.
  1. 25.  0.  0. 15.  0. 15. 29.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15  1 25 15  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 26. 30.  8.  7. 10.  7.  7.  6.  0. 10. 10.  9.  9.  6.] 
adversary cards in hand: [ 1.  0.  0.  3. 11.] 
adversary cards in discard: [6. 0. 8. 3. 0. 6. 8. 3. 3. 3.] 
adversary owned cards: [ 0  3  3  3  3  3  8  1 11  8  6  0  0  0 10  8 11  6  0  6] -> size -> 20 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 20.17281723022461



action possibilites: [-1] 
expected returns: [[11.214943]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3.] 
cards in discard: [25.  1. 29. 29. 25. 29. 29. 29. 29.  0. 15. 25.  0.  3.  1.  0. 29. 29.
  1. 25.  0.  0. 15.  0. 15. 29.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15  1 25 15  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 26. 30.  8.  7. 10.  7.  7.  6.  0. 10. 10.  9.  9.  6.] 
adversary cards in hand: [ 1.  0.  0.  3. 11.] 
adversary cards in discard: [6. 0. 8. 3. 0. 6. 8. 3. 3. 3.] 
adversary owned cards: [ 0  3  3  3  3  3  8  1 11  8  6  0  0  0 10  8 11  6  0  6] -> size -> 20 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: -0.21365952491760254





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[  8.940836 ]
 [ 19.367085 ]
 [ 13.378414 ]
 [-37.571712 ]
 [ 17.114328 ]
 [  9.633968 ]
 [ 15.2318535]
 [ 10.91272  ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3.] 
cards in discard: [25.  1. 29. 29. 25. 29. 29. 29. 29.  0. 15. 25.  0.  3.  1.  0. 29. 29.
  1. 25.  0.  0. 15.  0. 15. 29.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15  1 25 15  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 25. 30. 26. 30.  8.  7. 10.  7.  7.  6.  0. 10. 10.  9.  9.  6.] 
adversary cards in hand: [ 1.  0.  0.  3. 11.] 
adversary cards in discard: [6. 0. 8. 3. 0. 6. 8. 3. 3. 3.] 
adversary owned cards: [ 0  3  3  3  3  3  8  1 11  8  6  0  0  0 10  8 11  6  0  6] -> size -> 20 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 11.214942932128906



buy possibilites: [-1] 
expected returns: [[0.8011837]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3.] 
cards in discard: [25.  1. 29. 29. 25. 29. 29. 29. 29.  0. 15. 25.  0.  3.  1.  0. 29. 29.
  1. 25.  0.  0. 15.  0. 15. 29.  3.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15  1 25 15  1  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 26. 30.  8.  7. 10.  7.  7.  6.  0. 10. 10.  9.  9.  6.] 
adversary cards in hand: [ 1.  0.  0.  3. 11.] 
adversary cards in discard: [6. 0. 8. 3. 0. 6. 8. 3. 3. 3.] 
adversary owned cards: [ 0  3  3  3  3  3  8  1 11  8  6  0  0  0 10  8 11  6  0  6] -> size -> 20 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 149 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 19.367088317871094






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 1.  0.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0.  3. 11.] 
cards in discard: [6. 0. 8. 3. 0. 6. 8. 3. 3. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  3  3  8  1 11  8  6  0  0  0 10  8 11  6  0  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 26. 30.  8.  7. 10.  7.  7.  6.  0. 10. 10.  9.  9.  6.] 
adversary cards in hand: [ 0.  3.  0. 15. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15  1 25 15  1  1] -> size -> 33 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0.  3. 11.] 
cards in discard: [6. 0. 8. 3. 0. 6. 8. 3. 3. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  3  3  8  1 11  8  6  0  0  0 10  8 11  6  0  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 24. 30. 26. 30.  8.  7. 10.  7.  7.  6.  0. 10. 10.  9.  9.  6.] 
adversary cards in hand: [ 0.  3.  0. 15. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15  1 25 15  1  1] -> size -> 33 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0.  3. 11.] 
cards in discard: [6. 0. 8. 3. 0. 6. 8. 3. 3. 3. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  3  3  8  1 11  8  6  0  0  0 10  8 11  6  0  6  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 24. 30. 25. 30.  8.  7. 10.  7.  7.  6.  0. 10. 10.  9.  9.  6.] 
adversary cards in hand: [ 0.  3.  0. 15. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15  1 25 15  1  1] -> size -> 33 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [ 0.  3.  0. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
expected returns: [[ 6.7723174]
 [18.069752 ]
 [18.069752 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 15. 15.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15
 25 25 25 15  1 25 15  1  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 25. 30.  8.  7. 10.  7.  7.  6.  0. 10. 10.  9.  9.  6.] 
adversary cards in hand: [ 0.  8.  6. 11. 10.] 
adversary cards in discard: [ 6.  0.  8.  3.  0.  6.  8.  3.  3.  3.  3.  1.  0.  0.  3. 11.] 
adversary owned cards: [ 0  3  3  3  3  3  8  1 11  8  6  0  0  0 10  8 11  6  0  6  3] -> size -> 21 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 0.8011837005615234



action possibilites: [-1] 
expected returns: [[-5.5173454]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 24. 30. 25. 30.  8.  7. 10.  7.  7.  6.  0. 10. 10.  9.  9.  6.] 
adversary cards in hand: [ 0.  8.  6. 11. 10.] 
adversary cards in discard: [ 6.  0.  8.  3.  0.  6.  8.  3.  3.  3.  3.  1.  0.  0.  3. 11.] 
adversary owned cards: [ 0  3  3  3  3  3  8  1 11  8  6  0  0  0 10  8 11  6  0  6  3] -> size -> 21 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 17.43413543701172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[ -7.2685757 ]
 [  4.1357923 ]
 [ -2.4047518 ]
 [-62.9382    ]
 [ -0.800992  ]
 [  1.882894  ]
 [ -6.0994453 ]
 [ -0.26874995]
 [ -0.10811257]
 [  4.285744  ]
 [ -4.6708555 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 15.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 24. 30. 25. 30.  8.  7. 10.  7.  7.  6.  0. 10. 10.  9.  9.  6.] 
adversary cards in hand: [ 0.  8.  6. 11. 10.] 
adversary cards in discard: [ 6.  0.  8.  3.  0.  6.  8.  3.  3.  3.  3.  1.  0.  0.  3. 11.] 
adversary owned cards: [ 0  3  3  3  3  3  8  1 11  8  6  0  0  0 10  8 11  6  0  6  3] -> size -> 21 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: -5.517345428466797



buy possibilites: [-1] 
expected returns: [[-9.800362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 15.] 
cards in discard: [15.] 
cards in deck: 28 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 25. 30.  8.  7. 10.  7.  7.  6.  0. 10. 10.  9.  9.  5.] 
adversary cards in hand: [ 0.  8.  6. 11. 10.] 
adversary cards in discard: [ 6.  0.  8.  3.  0.  6.  8.  3.  3.  3.  3.  1.  0.  0.  3. 11.] 
adversary owned cards: [ 0  3  3  3  3  3  8  1 11  8  6  0  0  0 10  8 11  6  0  6  3] -> size -> 21 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 173 

action type: buy - action 15.0
Learning step: 0
desired expected reward: 4.285754680633545






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  6. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  6. 11. 10.] 
cards in discard: [ 6.  0.  8.  3.  0.  6.  8.  3.  3.  3.  3.  1.  0.  0.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  3  3  8  1 11  8  6  0  0  0 10  8 11  6  0  6  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 25. 30.  8.  7. 10.  7.  7.  6.  0. 10. 10.  9.  9.  5.] 
adversary cards in hand: [29. 29.  3.  0. 25.] 
adversary cards in discard: [15. 15.  3.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15] -> size -> 33 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  6. 11. 10.] 
cards in discard: [ 6.  0.  8.  3.  0.  6.  8.  3.  3.  3.  3.  1.  0.  0.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  3  3  8  1 11  8  6  0  0  0 10  8 11  6  0  6  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 24. 30. 25. 30.  8.  7. 10.  7.  7.  6.  0. 10. 10.  9.  9.  5.] 
adversary cards in hand: [29. 29.  3.  0. 25.] 
adversary cards in discard: [15. 15.  3.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15] -> size -> 33 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  6. 11. 10.] 
cards in discard: [ 6.  0.  8.  3.  0.  6.  8.  3.  3.  3.  3.  1.  0.  0.  3. 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  3  3  8  1 11  8  6  0  0  0 10  8 11  6  0  6  3  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 24. 30. 25. 30.  8.  7. 10.  7.  7.  6.  0. 10. 10.  9.  9.  5.] 
adversary cards in hand: [29. 29.  3.  0. 25.] 
adversary cards in discard: [15. 15.  3.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15] -> size -> 33 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [29. 29.  3.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 25.] 
expected returns: [[43.469334]
 [57.762886]
 [57.762886]
 [54.58942 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  3.  0. 25.] 
cards in discard: [15. 15.  3.  0. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 25. 30.  8.  7. 10.  7.  7.  6.  0. 10. 10.  9.  9.  5.] 
adversary cards in hand: [ 8.  3.  6. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  3  3  8  1 11  8  6  0  0  0 10  8 11  6  0  6  3  0] -> size -> 22 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -9.800361633300781



action possibilites: [-1. 29.] 
expected returns: [[45.269783]
 [59.48466 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  1.] 
cards in discard: [15. 15.  3.  0. 15. 25.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 24. 30. 25. 30.  8.  7. 10.  7.  7.  6.  0. 10. 10.  9.  9.  5.] 
adversary cards in hand: [ 8.  3.  6. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  3  3  8  1 11  8  6  0  0  0 10  8 11  6  0  6  3  0] -> size -> 22 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 53.304412841796875



action possibilites: [-1.] 
expected returns: [[51.166794]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1.] 
cards in discard: [15. 15.  3.  0. 15. 25.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 24. 30. 25. 30.  8.  7. 10.  7.  7.  6.  0. 10. 10.  9.  9.  5.] 
adversary cards in hand: [ 8.  3.  6. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  3  3  8  1 11  8  6  0  0  0 10  8 11  6  0  6  3  0] -> size -> 22 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 55.05836868286133





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[50.87259 ]
 [62.826122]
 [55.913586]
 [26.758356]
 [-6.852911]
 [57.30101 ]
 [60.768055]
 [53.17305 ]
 [64.45185 ]
 [58.031536]
 [62.164455]
 [58.23584 ]
 [43.52324 ]
 [63.26961 ]
 [52.425953]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1.] 
cards in discard: [15. 15.  3.  0. 15. 25.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 24. 30. 25. 30.  8.  7. 10.  7.  7.  6.  0. 10. 10.  9.  9.  5.] 
adversary cards in hand: [ 8.  3.  6. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  3  3  8  1 11  8  6  0  0  0 10  8 11  6  0  6  3  0] -> size -> 22 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 51.16679382324219



buy possibilites: [-1] 
expected returns: [[38.217766]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1.] 
cards in discard: [15. 15.  3.  0. 15. 25.  1. 25.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 25. 30.  8.  7. 10.  7.  7.  5.  0. 10. 10.  9.  9.  5.] 
adversary cards in hand: [ 8.  3.  6. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  3  3  8  1 11  8  6  0  0  0 10  8 11  6  0  6  3  0] -> size -> 22 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  30   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 315 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 64.45184326171875






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 8.  3.  6. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  6. 11. 11.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  3  3  8  1 11  8  6  0  0  0 10  8 11  6  0  6  3  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 25. 30.  8.  7. 10.  7.  7.  5.  0. 10. 10.  9.  9.  5.] 
adversary cards in hand: [ 1. 29. 25. 25.  0.] 
adversary cards in discard: [15. 15.  3.  0. 15. 25.  1. 25. 29. 29.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25] -> size -> 34 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  6. 11.] 
cards in discard: [11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3  3  3  8  1 11  8  6  0  0  0 10  8 11  6  0  6  3  0 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 25. 30.  8.  7. 10.  6.  7.  5.  0. 10. 10.  9.  9.  5.] 
adversary cards in hand: [ 1. 29. 25. 25.  0.] 
adversary cards in discard: [15. 15.  3.  0. 15. 25.  1. 25. 29. 29.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25] -> size -> 34 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  6. 11.] 
cards in discard: [11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3  3  3  8  1 11  8  6  0  0  0 10  8 11  6  0  6  3  0 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 24. 30. 25. 30.  8.  7. 10.  6.  7.  5.  0. 10. 10.  9.  9.  5.] 
adversary cards in hand: [ 1. 29. 25. 25.  0.] 
adversary cards in discard: [15. 15.  3.  0. 15. 25.  1. 25. 29. 29.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25] -> size -> 34 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  6. 11.] 
cards in discard: [11.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3  3  3  3  3  8  1 11  8  6  0  0  0 10  8 11  6  0  6  3  0 11  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 25. 30.  8.  7. 10.  6.  7.  5.  0. 10. 10.  9.  9.  5.] 
adversary cards in hand: [ 1. 29. 25. 25.  0.] 
adversary cards in discard: [15. 15.  3.  0. 15. 25.  1. 25. 29. 29.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25] -> size -> 34 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [ 1. 29. 25. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 25.] 
expected returns: [[ 3.2981286]
 [14.921768 ]
 [12.249834 ]
 [12.249834 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 25. 25.  0.] 
cards in discard: [15. 15.  3.  0. 15. 25.  1. 25. 29. 29.  3.  0.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 25. 30.  8.  7. 10.  6.  7.  5.  0. 10. 10.  9.  9.  5.] 
adversary cards in hand: [3. 8. 0. 3. 6.] 
adversary cards in discard: [11.  0. 11.  8.  3.  6. 11.] 
adversary owned cards: [ 0  3  3  3  3  3  8  1 11  8  6  0  0  0 10  8 11  6  0  6  3  0 11  0] -> size -> 24 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 38.21776580810547



action possibilites: [-1. 25. 25. 15.] 
expected returns: [[19.919909]
 [28.676233]
 [28.676233]
 [27.830452]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25.  0. 15.] 
cards in discard: [15. 15.  3.  0. 15. 25.  1. 25. 29. 29.  3.  0.  1.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 24. 30. 25. 30.  8.  7. 10.  6.  7.  5.  0. 10. 10.  9.  9.  5.] 
adversary cards in hand: [3. 8. 0. 3. 6.] 
adversary cards in discard: [11.  0. 11.  8.  3.  6. 11.] 
adversary owned cards: [ 0  3  3  3  3  3  8  1 11  8  6  0  0  0 10  8 11  6  0  6  3  0 11  0] -> size -> 24 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 11.325759887695312



action possibilites: [-1] 
expected returns: [[-11.388453]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 15. 25.  1.] 
cards in discard: [15. 15.  3.  0. 15. 25.  1. 25. 29. 29.  3.  0.  1.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 24. 30. 25. 30.  8.  6. 10.  6.  7.  5.  0. 10. 10.  9.  9.  5.] 
adversary cards in hand: [3. 8. 0. 3. 6.] 
adversary cards in discard: [11.  0. 11.  8.  3.  6. 11.  6.] 
adversary owned cards: [ 0  3  3  3  3  3  8  1 11  8  6  0  0  0 10  8 11  6  0  6  3  0 11  0
  6] -> size -> 25 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 28.676225662231445





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[-14.698942 ]
 [ -4.4207287]
 [-10.32779  ]
 [-64.133575 ]
 [ -8.908419 ]
 [ -6.4644794]
 [-13.635975 ]
 [ -8.423378 ]
 [ -8.27713  ]
 [ -4.2819138]
 [-12.426659 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0. 15. 25.  1.] 
cards in discard: [15. 15.  3.  0. 15. 25.  1. 25. 29. 29.  3.  0.  1.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 24. 30. 25. 30.  8.  6. 10.  6.  7.  5.  0. 10. 10.  9.  9.  5.] 
adversary cards in hand: [3. 8. 0. 3. 6.] 
adversary cards in discard: [11.  0. 11.  8.  3.  6. 11.  6.] 
adversary owned cards: [ 0  3  3  3  3  3  8  1 11  8  6  0  0  0 10  8 11  6  0  6  3  0 11  0
  6] -> size -> 25 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: -11.388452529907227



buy possibilites: [-1] 
expected returns: [[5.5404487]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0. 15. 25.  1.] 
cards in discard: [15. 15.  3.  0. 15. 25.  1. 25. 29. 29.  3.  0.  1.  1. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 25. 30.  8.  6. 10.  6.  7.  5.  0. 10. 10.  9.  9.  4.] 
adversary cards in hand: [3. 8. 0. 3. 6.] 
adversary cards in discard: [11.  0. 11.  8.  3.  6. 11.  6.] 
adversary owned cards: [ 0  3  3  3  3  3  8  1 11  8  6  0  0  0 10  8 11  6  0  6  3  0 11  0
  6] -> size -> 25 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  30   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 193 

action type: buy - action 15.0
Learning step: 0
desired expected reward: -4.281911849975586






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [3. 8. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 3. 6.] 
cards in discard: [11.  0. 11.  8.  3.  6. 11.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  3  3  8  1 11  8  6  0  0  0 10  8 11  6  0  6  3  0 11  0
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 25. 30.  8.  6. 10.  6.  7.  5.  0. 10. 10.  9.  9.  4.] 
adversary cards in hand: [ 0. 29. 29. 29. 29.] 
adversary cards in discard: [15. 15.  3.  0. 15. 25.  1. 25. 29. 29.  3.  0.  1.  1. 15. 29. 25. 25.
  0. 15. 25.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15] -> size -> 35 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [11.  0. 11.  8.  3.  6. 11.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3  8  1 11  8  0  0  0 10  8 11  6  0  6  3  0 11  0  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 25. 30.  8.  6. 10.  6.  7.  5.  0. 10. 10.  9.  9.  4.] 
adversary cards in hand: [ 0. 29. 29. 29. 29.] 
adversary cards in discard: [15. 15.  3.  0. 15. 25.  1. 25. 29. 29.  3.  0.  1.  1. 15. 29. 25. 25.
  0. 15. 25.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15] -> size -> 35 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [11.  0. 11.  8.  3.  6. 11.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3  8  1 11  8  0  0  0 10  8 11  6  0  6  3  0 11  0  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 24. 30. 25. 30.  8.  6. 10.  6.  7.  5.  0. 10. 10.  9.  9.  4.] 
adversary cards in hand: [ 0. 29. 29. 29. 29.] 
adversary cards in discard: [15. 15.  3.  0. 15. 25.  1. 25. 29. 29.  3.  0.  1.  1. 15. 29. 25. 25.
  0. 15. 25.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15] -> size -> 35 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [11.  0. 11.  8.  3.  6. 11.  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3  8  1 11  8  0  0  0 10  8 11  6  0  6  3  0 11  0  6  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 25. 30.  8.  6. 10.  6.  7.  5.  0. 10. 10.  9.  9.  4.] 
adversary cards in hand: [ 0. 29. 29. 29. 29.] 
adversary cards in discard: [15. 15.  3.  0. 15. 25.  1. 25. 29. 29.  3.  0.  1.  1. 15. 29. 25. 25.
  0. 15. 25.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15] -> size -> 35 
adversary victory points: 4
player victory points: 1 





Player: 0 
cards in hand: [ 0. 29. 29. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29. 29.] 
expected returns: [[ 9.060831]
 [20.76643 ]
 [20.76643 ]
 [20.76643 ]
 [20.76643 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29. 29. 29.] 
cards in discard: [15. 15.  3.  0. 15. 25.  1. 25. 29. 29.  3.  0.  1.  1. 15. 29. 25. 25.
  0. 15. 25.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 25. 30.  8.  6. 10.  6.  7.  5.  0. 10. 10.  9.  9.  4.] 
adversary cards in hand: [ 3.  3.  3. 10.  6.] 
adversary cards in discard: [11.  0. 11.  8.  3.  6. 11.  6.  0.  8.] 
adversary owned cards: [ 3  3  3  8  1 11  8  0  0  0 10  8 11  6  0  6  3  0 11  0  6  0] -> size -> 22 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 5.5404486656188965



action possibilites: [-1. 29. 29. 29.] 
expected returns: [[ 9.044998]
 [20.75059 ]
 [20.75059 ]
 [20.75059 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29. 29.] 
cards in discard: [15. 15.  3.  0. 15. 25.  1. 25. 29. 29.  3.  0.  1.  1. 15. 29. 25. 25.
  0. 15. 25.  1. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 24. 30. 25. 30.  8.  6. 10.  6.  7.  5.  0. 10. 10.  9.  9.  4.] 
adversary cards in hand: [ 3.  3.  3. 10.  6.] 
adversary cards in discard: [11.  0. 11.  8.  3.  6. 11.  6.  0.  8.] 
adversary owned cards: [ 3  3  3  8  1 11  8  0  0  0 10  8 11  6  0  6  3  0 11  0  6  0] -> size -> 22 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 17.092458724975586



action possibilites: [-1. 29. 15.] 
expected returns: [[-2.7086124]
 [ 9.605858 ]
 [ 5.8491483]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 15.] 
cards in discard: [15. 15.  3.  0. 15. 25.  1. 25. 29. 29.  3.  0.  1.  1. 15. 29. 25. 25.
  0. 15. 25.  1. 29. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 2 
card supply: [23. 24. 30. 25. 30.  8.  6. 10.  6.  7.  5.  0. 10. 10.  9.  9.  4.] 
adversary cards in hand: [ 3.  3.  3. 10.  6.] 
adversary cards in discard: [11.  0. 11.  8.  3.  6. 11.  6.  0.  8.] 
adversary owned cards: [ 3  3  3  8  1 11  8  0  0  0 10  8 11  6  0  6  3  0 11  0  6  0] -> size -> 22 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 17.07660484313965



action possibilites: [-1.] 
expected returns: [[3.2540355]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [15. 15.  3.  0. 15. 25.  1. 25. 29. 29.  3.  0.  1.  1. 15. 29. 25. 25.
  0. 15. 25.  1. 29. 29. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 3 
card supply: [23. 24. 30. 25. 30.  8.  6. 10.  6.  7.  5.  0. 10. 10.  9.  9.  4.] 
adversary cards in hand: [ 3.  3.  3. 10.  6.] 
adversary cards in discard: [11.  0. 11.  8.  3.  6. 11.  6.  0.  8.] 
adversary owned cards: [ 3  3  3  8  1 11  8  0  0  0 10  8 11  6  0  6  3  0 11  0  6  0] -> size -> 22 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 5.74576997756958





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[  0.96137094]
 [ 11.387621  ]
 [  5.398954  ]
 [-17.564568  ]
 [-45.552494  ]
 [  6.605429  ]
 [  9.134867  ]
 [  1.6545072 ]
 [ 12.397909  ]
 [  7.100511  ]
 [ 10.711874  ]
 [  7.2523875 ]
 [ -4.355865  ]
 [ 11.490995  ]
 [  2.9332585 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [15. 15.  3.  0. 15. 25.  1. 25. 29. 29.  3.  0.  1.  1. 15. 29. 25. 25.
  0. 15. 25.  1. 29. 29. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 24. 30. 25. 30.  8.  6. 10.  6.  7.  5.  0. 10. 10.  9.  9.  4.] 
adversary cards in hand: [ 3.  3.  3. 10.  6.] 
adversary cards in discard: [11.  0. 11.  8.  3.  6. 11.  6.  0.  8.] 
adversary owned cards: [ 3  3  3  8  1 11  8  0  0  0 10  8 11  6  0  6  3  0 11  0  6  0] -> size -> 22 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 3.254035472869873



buy possibilites: [-1] 
expected returns: [[3.5555358]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [15. 15.  3.  0. 15. 25.  1. 25. 29. 29.  3.  0.  1.  1. 15. 29. 25. 25.
  0. 15. 25.  1. 29. 29. 15. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 25. 30.  8.  6. 10.  6.  7.  4.  0. 10. 10.  9.  9.  4.] 
adversary cards in hand: [ 3.  3.  3. 10.  6.] 
adversary cards in discard: [11.  0. 11.  8.  3.  6. 11.  6.  0.  8.] 
adversary owned cards: [ 3  3  3  8  1 11  8  0  0  0 10  8 11  6  0  6  3  0 11  0  6  0] -> size -> 22 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  90   0   0  60   0   0   0   0 -10   0   0 250   0] 
sum of rewards: 385 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 12.397916793823242






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  3. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3. 10.  6.] 
cards in discard: [11.  0. 11.  8.  3.  6. 11.  6.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  1 11  8  0  0  0 10  8 11  6  0  6  3  0 11  0  6  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 25. 30.  8.  6. 10.  6.  7.  4.  0. 10. 10.  9.  9.  4.] 
adversary cards in hand: [ 3.  1.  3. 29. 29.] 
adversary cards in discard: [15. 15.  3.  0. 15. 25.  1. 25. 29. 29.  3.  0.  1.  1. 15. 29. 25. 25.
  0. 15. 25.  1. 29. 29. 15. 25. 29. 29. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25] -> size -> 36 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3. 10.  6.] 
cards in discard: [11.  0. 11.  8.  3.  6. 11.  6.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  1 11  8  0  0  0 10  8 11  6  0  6  3  0 11  0  6  0] -> size -> 22 
action values: 1 
buys: 1 
player value: 0 
card supply: [23. 24. 30. 25. 30.  8.  6. 10.  6.  7.  4.  0. 10. 10.  9.  9.  4.] 
adversary cards in hand: [ 3.  1.  3. 29. 29.] 
adversary cards in discard: [15. 15.  3.  0. 15. 25.  1. 25. 29. 29.  3.  0.  1.  1. 15. 29. 25. 25.
  0. 15. 25.  1. 29. 29. 15. 25. 29. 29. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25] -> size -> 36 
adversary victory points: 4
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3.  1.  3. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[ 6.4675975]
 [20.2837   ]
 [20.2837   ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  3. 29. 29.] 
cards in discard: [15. 15.  3.  0. 15. 25.  1. 25. 29. 29.  3.  0.  1.  1. 15. 29. 25. 25.
  0. 15. 25.  1. 29. 29. 15. 25. 29. 29. 29.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 25. 30.  8.  6. 10.  6.  7.  4.  0. 10. 10.  9.  9.  4.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [11.  0. 11.  8.  3.  6. 11.  6.  0.  8.  3.  3.  3. 10.  6.] 
adversary owned cards: [ 3  3  3  8  1 11  8  0  0  0 10  8 11  6  0  6  3  0 11  0  6  0] -> size -> 22 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 3.5555357933044434



action possibilites: [-1. 29. 29.] 
expected returns: [[15.130217]
 [29.320223]
 [29.320223]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 29. 29.] 
cards in discard: [3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 24. 30. 25. 30.  8.  6. 10.  6.  7.  4.  0. 10. 10.  9.  9.  4.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [11.  0. 11.  8.  3.  6. 11.  6.  0.  8.  3.  3.  3. 10.  6.] 
adversary owned cards: [ 3  3  3  8  1 11  8  0  0  0 10  8 11  6  0  6  3  0 11  0  6  0] -> size -> 22 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 15.698423385620117



action possibilites: [-1. 29.] 
expected returns: [[ 3.947454]
 [19.16068 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  3.] 
cards in discard: [3. 3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25] -> size -> 36 
action values: 1 
buys: 0 
player value: 2 
card supply: [23. 24. 30. 25. 30.  8.  6. 10.  6.  7.  4.  0. 10. 10.  9.  9.  4.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [11.  0. 11.  8.  3.  6. 11.  6.  0.  8.  3.  3.  3. 10.  6.] 
adversary owned cards: [ 3  3  3  8  1 11  8  0  0  0 10  8 11  6  0  6  3  0 11  0  6  0] -> size -> 22 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 24.83408546447754



action possibilites: [-1.] 
expected returns: [[9.510185]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [3. 3. 1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25] -> size -> 36 
action values: 1 
buys: 0 
player value: 3 
card supply: [23. 24. 30. 25. 30.  8.  6. 10.  6.  7.  4.  0. 10. 10.  9.  9.  4.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [11.  0. 11.  8.  3.  6. 11.  6.  0.  8.  3.  3.  3. 10.  6.] 
adversary owned cards: [ 3  3  3  8  1 11  8  0  0  0 10  8 11  6  0  6  3  0 11  0  6  0] -> size -> 22 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 14.411067962646484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[  8.090313]
 [ 19.230026]
 [ 12.826794]
 [-43.029186]
 [ 14.078848]
 [ 16.992794]
 [  9.290916]
 [ 14.667236]
 [ 14.840857]
 [ 19.45403 ]
 [  9.903471]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [3. 3. 1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 24. 30. 25. 30.  8.  6. 10.  6.  7.  4.  0. 10. 10.  9.  9.  4.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [11.  0. 11.  8.  3.  6. 11.  6.  0.  8.  3.  3.  3. 10.  6.] 
adversary owned cards: [ 3  3  3  8  1 11  8  0  0  0 10  8 11  6  0  6  3  0 11  0  6  0] -> size -> 22 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 9.510185241699219



buy possibilites: [-1] 
expected returns: [[46.65621]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 3.  3.  1. 15.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 25. 30.  8.  6. 10.  6.  7.  4.  0. 10. 10.  9.  9.  3.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [11.  0. 11.  8.  3.  6. 11.  6.  0.  8.  3.  3.  3. 10.  6.] 
adversary owned cards: [ 3  3  3  8  1 11  8  0  0  0 10  8 11  6  0  6  3  0 11  0  6  0] -> size -> 22 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  90   0   0  60   0   0   0   0 -20   0   0 128   0] 
sum of rewards: 253 

action type: buy - action 15.0
Learning step: 0
desired expected reward: 19.454038619995117






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [8. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [11.  0. 11.  8.  3.  6. 11.  6.  0.  8.  3.  3.  3. 10.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  1 11  8  0  0  0 10  8 11  6  0  6  3  0 11  0  6  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 25. 30.  8.  6. 10.  6.  7.  4.  0. 10. 10.  9.  9.  3.] 
adversary cards in hand: [15.  0.  1. 25. 15.] 
adversary cards in discard: [ 3.  3.  1. 15. 29. 29. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15] -> size -> 37 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [11.  0. 11.  8.  3.  6. 11.  6.  0.  8.  3.  3.  3. 10.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3  8  1 11  8  0  0 10  8 11  6  0  6  3  0 11  0  6  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 25. 30.  8.  6. 10.  6.  7.  4.  0. 10. 10.  9.  9.  3.] 
adversary cards in hand: [15.  0.  1. 25. 15.] 
adversary cards in discard: [ 3.  3.  1. 15. 29. 29. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15] -> size -> 37 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [11.  0. 11.  8.  3.  6. 11.  6.  0.  8.  3.  3.  3. 10.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3  8  1 11  8  0  0 10  8 11  6  0  6  3  0 11  0  6  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 24. 30. 25. 30.  8.  6. 10.  6.  7.  4.  0. 10. 10.  9.  9.  3.] 
adversary cards in hand: [15.  0.  1. 25. 15.] 
adversary cards in discard: [ 3.  3.  1. 15. 29. 29. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15] -> size -> 37 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [11.  0. 11.  8.  3.  6. 11.  6.  0.  8.  3.  3.  3. 10.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3  8  1 11  8  0  0 10  8 11  6  0  6  3  0 11  0  6  0  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 24. 30. 25. 30.  8.  6. 10.  6.  7.  4.  0. 10. 10.  9.  9.  3.] 
adversary cards in hand: [15.  0.  1. 25. 15.] 
adversary cards in discard: [ 3.  3.  1. 15. 29. 29. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15] -> size -> 37 
adversary victory points: 4
player victory points: 1 





Player: 0 
cards in hand: [15.  0.  1. 25. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25. 15.] 
expected returns: [[66.89875 ]
 [76.514694]
 [77.554085]
 [76.514694]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  1. 25. 15.] 
cards in discard: [ 3.  3.  1. 15. 29. 29. 29.  3.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 25. 30.  8.  6. 10.  6.  7.  4.  0. 10. 10.  9.  9.  3.] 
adversary cards in hand: [0. 8. 8. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3  8  1 11  8  0  0 10  8 11  6  0  6  3  0 11  0  6  0  0] -> size -> 22 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 46.656211853027344



action possibilites: [-1] 
expected returns: [[63.895847]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  1. 15. 25. 25.] 
cards in discard: [ 3.  3.  1. 15. 29. 29. 29.  3.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 25. 30.  8.  5. 10.  6.  7.  4.  0. 10. 10.  9.  9.  3.] 
adversary cards in hand: [0. 8. 8. 0. 1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 3  3  3  8  1 11  8  0  0 10  8 11  6  0  6  3  0 11  0  6  0  0  6] -> size -> 23 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 77.55404663085938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[59.177727]
 [70.25309 ]
 [63.91702 ]
 [ 4.060927]
 [68.246735]
 [60.722897]
 [66.1726  ]
 [61.42029 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  1. 15. 25. 25.] 
cards in discard: [ 3.  3.  1. 15. 29. 29. 29.  3.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 24. 30. 25. 30.  8.  5. 10.  6.  7.  4.  0. 10. 10.  9.  9.  3.] 
adversary cards in hand: [0. 8. 8. 0. 1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 3  3  3  8  1 11  8  0  0 10  8 11  6  0  6  3  0 11  0  6  0  0  6] -> size -> 23 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 63.89584732055664



buy possibilites: [-1] 
expected returns: [[41.22438]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  1. 15. 25. 25.] 
cards in discard: [ 3.  3.  1. 15. 29. 29. 29.  3.  0.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 25. 30.  8.  5. 10.  6.  7.  4.  0. 10. 10.  9.  9.  3.] 
adversary cards in hand: [0. 8. 8. 0. 1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 3  3  3  8  1 11  8  0  0 10  8 11  6  0  6  3  0 11  0  6  0  0  6] -> size -> 23 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0 -30   0   0  54   0] 
sum of rewards: 129 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 70.25309753417969






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [0. 8. 8. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 0. 1.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  8  1 11  8  0  0 10  8 11  6  0  6  3  0 11  0  6  0  0  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 25. 30.  8.  5. 10.  6.  7.  4.  0. 10. 10.  9.  9.  3.] 
adversary cards in hand: [ 0. 25. 15. 29. 29.] 
adversary cards in discard: [ 3.  3.  1. 15. 29. 29. 29.  3.  0.  1. 25. 15.  0.  1. 15. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15  1] -> size -> 38 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 11  8  0 10  8 11  6  0  6  3  0 11  0  6  0  0  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 25. 30.  8.  5. 10.  6.  7.  4.  0. 10. 10.  9.  9.  3.] 
adversary cards in hand: [ 0. 25. 15. 29. 29.] 
adversary cards in discard: [ 3.  3.  1. 15. 29. 29. 29.  3.  0.  1. 25. 15.  0.  1. 15. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15  1] -> size -> 38 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 11  8  0 10  8 11  6  0  6  3  0 11  0  6  0  0  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 23. 30. 25. 30.  8.  5. 10.  6.  7.  4.  0. 10. 10.  9.  9.  3.] 
adversary cards in hand: [ 0. 25. 15. 29. 29.] 
adversary cards in discard: [ 3.  3.  1. 15. 29. 29. 29.  3.  0.  1. 25. 15.  0.  1. 15. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15  1] -> size -> 38 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [6. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 11  8  0 10  8 11  6  0  6  3  0 11  0  6  0  0  6  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 23. 30. 25. 30.  8.  5. 10.  6.  7.  4.  0. 10. 10.  9.  9.  3.] 
adversary cards in hand: [ 0. 25. 15. 29. 29.] 
adversary cards in discard: [ 3.  3.  1. 15. 29. 29. 29.  3.  0.  1. 25. 15.  0.  1. 15. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15  1] -> size -> 38 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [ 0. 25. 15. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15. 29. 29.] 
expected returns: [[-12.696877 ]
 [ -3.2089758]
 [ -4.141613 ]
 [ -0.3660679]
 [ -0.3660679]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 15. 29. 29.] 
cards in discard: [ 3.  3.  1. 15. 29. 29. 29.  3.  0.  1. 25. 15.  0.  1. 15. 25. 25.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 25. 30.  8.  5. 10.  6.  7.  4.  0. 10. 10.  9.  9.  3.] 
adversary cards in hand: [11.  6. 11.  3.  0.] 
adversary cards in discard: [6. 0. 8. 0.] 
adversary owned cards: [ 3  3  3 11  8  0 10  8 11  6  0  6  3  0 11  0  6  0  0  6  0] -> size -> 21 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 41.22438049316406



action possibilites: [-1. 25. 15. 25.] 
expected returns: [[-37.583378]
 [-32.121025]
 [-32.281055]
 [-32.121025]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 15. 25.] 
cards in discard: [ 3.  3.  1. 15. 29. 29. 29.  3.  0.  1. 25. 15.  0.  1. 15. 25. 25. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 23. 30. 25. 30.  8.  5. 10.  6.  7.  4.  0. 10. 10.  9.  9.  3.] 
adversary cards in hand: [11.  6. 11.  3.  0.] 
adversary cards in discard: [6. 0. 8. 0.] 
adversary owned cards: [ 3  3  3 11  8  0 10  8 11  6  0  6  3  0 11  0  6  0  0  6  0] -> size -> 21 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -4.2850823402404785



action possibilites: [-1] 
expected returns: [[-20.890257]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 25.  1. 29.] 
cards in discard: [ 3.  3.  1. 15. 29. 29. 29.  3.  0.  1. 25. 15.  0.  1. 15. 25. 25. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 23. 30. 25. 30.  8.  4. 10.  6.  7.  4.  0. 10. 10.  9.  9.  3.] 
adversary cards in hand: [11.  6. 11.  3.  0.] 
adversary cards in discard: [6. 0. 8. 0. 6.] 
adversary owned cards: [ 3  3  3 11  8  0 10  8 11  6  0  6  3  0 11  0  6  0  0  6  0  6] -> size -> 22 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -32.12102127075195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[-23.039999]
 [-12.402916]
 [-18.539963]
 [-70.18087 ]
 [-17.338669]
 [-14.676584]
 [-22.157919]
 [-16.812534]
 [-16.653067]
 [-12.263233]
 [-21.187891]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 25.  1. 29.] 
cards in discard: [ 3.  3.  1. 15. 29. 29. 29.  3.  0.  1. 25. 15.  0.  1. 15. 25. 25. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 23. 30. 25. 30.  8.  4. 10.  6.  7.  4.  0. 10. 10.  9.  9.  3.] 
adversary cards in hand: [11.  6. 11.  3.  0.] 
adversary cards in discard: [6. 0. 8. 0. 6.] 
adversary owned cards: [ 3  3  3 11  8  0 10  8 11  6  0  6  3  0 11  0  6  0  0  6  0  6] -> size -> 22 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: -20.890256881713867



buy possibilites: [-1] 
expected returns: [[-7.565741]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 25.  1. 29.] 
cards in discard: [ 3.  3.  1. 15. 29. 29. 29.  3.  0.  1. 25. 15.  0.  1. 15. 25. 25. 29.
 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15  1 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 25. 30.  8.  4. 10.  6.  7.  4.  0. 10. 10.  9.  9.  2.] 
adversary cards in hand: [11.  6. 11.  3.  0.] 
adversary cards in discard: [6. 0. 8. 0. 6.] 
adversary owned cards: [ 3  3  3 11  8  0 10  8 11  6  0  6  3  0 11  0  6  0  0  6  0  6] -> size -> 22 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0 -40   0   0 128   0] 
sum of rewards: 243 

action type: buy - action 15.0
Learning step: 0
desired expected reward: -12.263221740722656






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [11.  6. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6. 11.  3.  0.] 
cards in discard: [6. 0. 8. 0. 6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 11  8  0 10  8 11  6  0  6  3  0 11  0  6  0  0  6  0  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 25. 30.  8.  4. 10.  6.  7.  4.  0. 10. 10.  9.  9.  2.] 
adversary cards in hand: [ 3. 25. 29.  1. 15.] 
adversary cards in discard: [ 3.  3.  1. 15. 29. 29. 29.  3.  0.  1. 25. 15.  0.  1. 15. 25. 25. 29.
 15. 29. 25.  0. 15. 25.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15  1 15] -> size -> 39 
adversary victory points: 4
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  3.  0.] 
cards in discard: [ 6.  0.  8.  0.  6. 16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3 11  8  0 10  8 11  6  0  6  3  0 11  0  6  0  0  6  0  6 16] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 25. 30.  8.  4.  9.  6.  7.  4.  0. 10. 10.  9.  9.  2.] 
adversary cards in hand: [ 3. 25. 29.  1. 15.] 
adversary cards in discard: [ 3.  3.  1. 15. 29. 29. 29.  3.  0.  1. 25. 15.  0.  1. 15. 25. 25. 29.
 15. 29. 25.  0. 15. 25.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15  1 15] -> size -> 39 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  3.  0.] 
cards in discard: [ 6.  0.  8.  0.  6. 16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3 11  8  0 10  8 11  6  0  6  3  0 11  0  6  0  0  6  0  6 16] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 23. 30. 25. 30.  8.  4.  9.  6.  7.  4.  0. 10. 10.  9.  9.  2.] 
adversary cards in hand: [ 3. 25. 29.  1. 15.] 
adversary cards in discard: [ 3.  3.  1. 15. 29. 29. 29.  3.  0.  1. 25. 15.  0.  1. 15. 25. 25. 29.
 15. 29. 25.  0. 15. 25.  1. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15  1 15] -> size -> 39 
adversary victory points: 4
player victory points: -1 





Player: 0 
cards in hand: [ 3. 25. 29.  1. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 15.] 
expected returns: [[12.010635]
 [21.47529 ]
 [24.31921 ]
 [20.568377]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 29.  1. 15.] 
cards in discard: [ 3.  3.  1. 15. 29. 29. 29.  3.  0.  1. 25. 15.  0.  1. 15. 25. 25. 29.
 15. 29. 25.  0. 15. 25.  1. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15  1 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 25. 30.  8.  4.  9.  6.  7.  4.  0. 10. 10.  9.  9.  2.] 
adversary cards in hand: [ 0.  0. 10.  0.  0.] 
adversary cards in discard: [ 6.  0.  8.  0.  6. 16. 11.  6. 11.  3.  0.] 
adversary owned cards: [ 3  3  3 11  8  0 10  8 11  6  0  6  3  0 11  0  6  0  0  6  0  6 16] -> size -> 23 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: -7.565741062164307



action possibilites: [-1. 25. 15. 15.] 
expected returns: [[ 1.7167697]
 [10.996431 ]
 [10.102493 ]
 [10.102493 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1. 15. 15.] 
cards in discard: [ 3.  3.  1. 15. 29. 29. 29.  3.  0.  1. 25. 15.  0.  1. 15. 25. 25. 29.
 15. 29. 25.  0. 15. 25.  1. 29.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15  1 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 23. 30. 25. 30.  8.  4.  9.  6.  7.  4.  0. 10. 10.  9.  9.  2.] 
adversary cards in hand: [ 0.  0. 10.  0.  0.] 
adversary cards in discard: [ 6.  0.  8.  0.  6. 16. 11.  6. 11.  3.  0.] 
adversary owned cards: [ 3  3  3 11  8  0 10  8 11  6  0  6  3  0 11  0  6  0  0  6  0  6 16] -> size -> 23 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 20.465011596679688



action possibilites: [-1] 
expected returns: [[-5.0172586]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15. 15.  0. 29.] 
cards in discard: [ 3.  3.  1. 15. 29. 29. 29.  3.  0.  1. 25. 15.  0.  1. 15. 25. 25. 29.
 15. 29. 25.  0. 15. 25.  1. 29.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15  1 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 23. 30. 25. 30.  8.  3.  9.  6.  7.  4.  0. 10. 10.  9.  9.  2.] 
adversary cards in hand: [ 0.  0. 10.  0.  0.] 
adversary cards in discard: [ 6.  0.  8.  0.  6. 16. 11.  6. 11.  3.  0.  6.] 
adversary owned cards: [ 3  3  3 11  8  0 10  8 11  6  0  6  3  0 11  0  6  0  0  6  0  6 16  6] -> size -> 24 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 10.996444702148438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[ -6.989313  ]
 [  3.4371223 ]
 [ -2.5516162 ]
 [-53.503403  ]
 [ -1.345062  ]
 [  1.1843853 ]
 [ -6.2961655 ]
 [ -0.8499837 ]
 [ -0.69810104]
 [  3.5404992 ]
 [ -5.017263  ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15. 15.  0. 29.] 
cards in discard: [ 3.  3.  1. 15. 29. 29. 29.  3.  0.  1. 25. 15.  0.  1. 15. 25. 25. 29.
 15. 29. 25.  0. 15. 25.  1. 29.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15  1 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 23. 30. 25. 30.  8.  3.  9.  6.  7.  4.  0. 10. 10.  9.  9.  2.] 
adversary cards in hand: [ 0.  0. 10.  0.  0.] 
adversary cards in discard: [ 6.  0.  8.  0.  6. 16. 11.  6. 11.  3.  0.  6.] 
adversary owned cards: [ 3  3  3 11  8  0 10  8 11  6  0  6  3  0 11  0  6  0  0  6  0  6 16  6] -> size -> 24 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: -5.017258644104004



buy possibilites: [-1] 
expected returns: [[-6.946398]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15. 15.  0. 29.] 
cards in discard: [ 3.  3.  1. 15. 29. 29. 29.  3.  0.  1. 25. 15.  0.  1. 15. 25. 25. 29.
 15. 29. 25.  0. 15. 25.  1. 29.  3. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15  1 15 15] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 25. 30.  8.  3.  9.  6.  7.  4.  0. 10. 10.  9.  9.  1.] 
adversary cards in hand: [ 0.  0. 10.  0.  0.] 
adversary cards in discard: [ 6.  0.  8.  0.  6. 16. 11.  6. 11.  3.  0.  6.] 
adversary owned cards: [ 3  3  3 11  8  0 10  8 11  6  0  6  3  0 11  0  6  0  0  6  0  6 16  6] -> size -> 24 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0 -50   0   0 128   0] 
sum of rewards: 263 

action type: buy - action 15.0
Learning step: 0
desired expected reward: 3.5405006408691406






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  0.] 
cards in discard: [ 6.  0.  8.  0.  6. 16. 11.  6. 11.  3.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 11  8  0 10  8 11  6  0  6  3  0 11  0  6  0  0  6  0  6 16  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 25. 30.  8.  3.  9.  6.  7.  4.  0. 10. 10.  9.  9.  1.] 
adversary cards in hand: [ 1. 29. 29.  0. 15.] 
adversary cards in discard: [ 3.  3.  1. 15. 29. 29. 29.  3.  0.  1. 25. 15.  0.  1. 15. 25. 25. 29.
 15. 29. 25.  0. 15. 25.  1. 29.  3. 15. 29. 25.  1. 15. 15.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15  1 15 15] -> size -> 40 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  0.] 
cards in discard: [ 6.  0.  8.  0.  6. 16. 11.  6. 11.  3.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 11  8  0 10  8 11  6  0  6  3  0 11  0  6  0  0  6  0  6 16  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 23. 30. 25. 30.  8.  3.  9.  6.  7.  4.  0. 10. 10.  9.  9.  1.] 
adversary cards in hand: [ 1. 29. 29.  0. 15.] 
adversary cards in discard: [ 3.  3.  1. 15. 29. 29. 29.  3.  0.  1. 25. 15.  0.  1. 15. 25. 25. 29.
 15. 29. 25.  0. 15. 25.  1. 29.  3. 15. 29. 25.  1. 15. 15.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15  1 15 15] -> size -> 40 
adversary victory points: 4
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  0.] 
cards in discard: [ 6.  0.  8.  0.  6. 16. 11.  6. 11.  3.  0.  6.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 11  8  0 10  8 11  6  0  6  3  0 11  0  6  0  0  6  0  6 16  6
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 23. 30. 24. 30.  8.  3.  9.  6.  7.  4.  0. 10. 10.  9.  9.  1.] 
adversary cards in hand: [ 1. 29. 29.  0. 15.] 
adversary cards in discard: [ 3.  3.  1. 15. 29. 29. 29.  3.  0.  1. 25. 15.  0.  1. 15. 25. 25. 29.
 15. 29. 25.  0. 15. 25.  1. 29.  3. 15. 29. 25.  1. 15. 15.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15  1 15 15] -> size -> 40 
adversary victory points: 4
player victory points: -1 





Player: 0 
cards in hand: [ 1. 29. 29.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 15.] 
expected returns: [[16.306568]
 [29.864214]
 [29.864214]
 [25.759129]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 29.  0. 15.] 
cards in discard: [ 3.  3.  1. 15. 29. 29. 29.  3.  0.  1. 25. 15.  0.  1. 15. 25. 25. 29.
 15. 29. 25.  0. 15. 25.  1. 29.  3. 15. 29. 25.  1. 15. 15.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15  1 15 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 24. 30.  8.  3.  9.  6.  7.  4.  0. 10. 10.  9.  9.  1.] 
adversary cards in hand: [3. 3. 6. 8. 6.] 
adversary cards in discard: [ 6.  0.  8.  0.  6. 16. 11.  6. 11.  3.  0.  6.  3.  0.  0. 10.  0.  0.] 
adversary owned cards: [ 3  3  3 11  8  0 10  8 11  6  0  6  3  0 11  0  6  0  0  6  0  6 16  6
  3] -> size -> 25 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: -6.94639778137207



action possibilites: [-1. 29. 15. 29.] 
expected returns: [[ 2.910111]
 [11.286228]
 [ 8.675268]
 [11.286228]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 15. 29.] 
cards in discard: [1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15  1 15 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 23. 30. 24. 30.  8.  3.  9.  6.  7.  4.  0. 10. 10.  9.  9.  1.] 
adversary cards in hand: [3. 3. 6. 8. 6.] 
adversary cards in discard: [ 6.  0.  8.  0.  6. 16. 11.  6. 11.  3.  0.  6.  3.  0.  0. 10.  0.  0.] 
adversary owned cards: [ 3  3  3 11  8  0 10  8 11  6  0  6  3  0 11  0  6  0  0  6  0  6 16  6
  3] -> size -> 25 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 25.62165069580078



action possibilites: [-1. 15. 25.] 
expected returns: [[ 1.4654665]
 [12.190926 ]
 [13.346939 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 25.] 
cards in discard: [ 1. 29.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15  1 15 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 2 
card supply: [21. 23. 30. 24. 30.  8.  3.  9.  6.  7.  4.  0. 10. 10.  9.  9.  1.] 
adversary cards in hand: [3. 3. 6. 8. 6.] 
adversary cards in discard: [ 6.  0.  8.  0.  6. 16. 11.  6. 11.  3.  0.  6.  3.  0.  0. 10.  0.  0.] 
adversary owned cards: [ 3  3  3 11  8  0 10  8 11  6  0  6  3  0 11  0  6  0  0  6  0  6 16  6
  3] -> size -> 25 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 9.268657684326172



action possibilites: [-1] 
expected returns: [[22.975637]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 25.  1.] 
cards in discard: [ 1. 29.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15  1 15 15] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 23. 30. 24. 30.  8.  2.  9.  6.  7.  4.  0. 10. 10.  9.  9.  1.] 
adversary cards in hand: [3. 3. 6. 8. 6.] 
adversary cards in discard: [ 6.  0.  8.  0.  6. 16. 11.  6. 11.  3.  0.  6.  3.  0.  0. 10.  0.  0.
  6.] 
adversary owned cards: [ 3  3  3 11  8  0 10  8 11  6  0  6  3  0 11  0  6  0  0  6  0  6 16  6
  3  6] -> size -> 26 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 13.346940994262695





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 21.1415    ]
 [ 32.554962  ]
 [ 25.889275  ]
 [  0.53657293]
 [-30.327084  ]
 [ 27.12157   ]
 [ 30.113024  ]
 [ 22.402515  ]
 [ 33.809616  ]
 [ 27.718622  ]
 [ 31.811415  ]
 [ 27.897387  ]
 [ 15.037069  ]
 [ 32.745605  ]
 [ 22.81385   ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 25.  1.] 
cards in discard: [ 1. 29.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15  1 15 15] -> size -> 40 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 23. 30. 24. 30.  8.  2.  9.  6.  7.  4.  0. 10. 10.  9.  9.  1.] 
adversary cards in hand: [3. 3. 6. 8. 6.] 
adversary cards in discard: [ 6.  0.  8.  0.  6. 16. 11.  6. 11.  3.  0.  6.  3.  0.  0. 10.  0.  0.
  6.] 
adversary owned cards: [ 3  3  3 11  8  0 10  8 11  6  0  6  3  0 11  0  6  0  0  6  0  6 16  6
  3  6] -> size -> 26 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: take_action - action -1
Learning step: 0
desired expected reward: 22.975637435913086



buy possibilites: [-1] 
expected returns: [[8.456909]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 25.  1.] 
cards in discard: [ 1. 29. 25.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15  1 15 15 25] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 24. 30.  8.  2.  9.  6.  7.  3.  0. 10. 10.  9.  9.  1.] 
adversary cards in hand: [3. 3. 6. 8. 6.] 
adversary cards in discard: [ 6.  0.  8.  0.  6. 16. 11.  6. 11.  3.  0.  6.  3.  0.  0. 10.  0.  0.
  6.] 
adversary owned cards: [ 3  3  3 11  8  0 10  8 11  6  0  6  3  0 11  0  6  0  0  6  0  6 16  6
  3  6] -> size -> 26 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  60   0   0   0   0 -60   0   0 250   0] 
sum of rewards: 395 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 33.80959701538086






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [3. 3. 6. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 8. 6.] 
cards in discard: [ 6.  0.  8.  0.  6. 16. 11.  6. 11.  3.  0.  6.  3.  0.  0. 10.  0.  0.
  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 11  8  0 10  8 11  6  0  6  3  0 11  0  6  0  0  6  0  6 16  6
  3  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 24. 30.  8.  2.  9.  6.  7.  3.  0. 10. 10.  9.  9.  1.] 
adversary cards in hand: [29.  0.  1.  0. 29.] 
adversary cards in discard: [ 1. 29. 25. 29. 29. 25.  0. 15. 25.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15  1 15 15 25] -> size -> 41 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 8. 6.] 
cards in discard: [ 6.  0.  8.  0.  6. 16. 11.  6. 11.  3.  0.  6.  3.  0.  0. 10.  0.  0.
  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 11  8  0 10  8 11  6  0  6  3  0 11  0  6  0  0  6  0  6 16  6
  3  6] -> size -> 26 
action values: 1 
buys: 1 
player value: 0 
card supply: [21. 23. 30. 24. 30.  8.  2.  9.  6.  7.  3.  0. 10. 10.  9.  9.  1.] 
adversary cards in hand: [29.  0.  1.  0. 29.] 
adversary cards in discard: [ 1. 29. 25. 29. 29. 25.  0. 15. 25.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15  1 15 15 25] -> size -> 41 
adversary victory points: 4
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29.  0.  1.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[54.247902]
 [66.4561  ]
 [66.4561  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  1.  0. 29.] 
cards in discard: [ 1. 29. 25. 29. 29. 25.  0. 15. 25.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15  1 15 15 25] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 24. 30.  8.  2.  9.  6.  7.  3.  0. 10. 10.  9.  9.  1.] 
adversary cards in hand: [ 3.  6.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 11  8  0 10  8 11  6  0  6  3  0 11  0  6  0  0  6  0  6 16  6
  3  6] -> size -> 26 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 8.4569091796875



action possibilites: [-1. 29.] 
expected returns: [[32.301914]
 [44.586723]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  3.] 
cards in discard: [ 1. 29. 25. 29. 29. 25.  0. 15. 25.  1.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15  1 15 15 25] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 23. 30. 24. 30.  8.  2.  9.  6.  7.  3.  0. 10. 10.  9.  9.  1.] 
adversary cards in hand: [ 3.  6.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 11  8  0 10  8 11  6  0  6  3  0 11  0  6  0  0  6  0  6 16  6
  3  6] -> size -> 26 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 62.709041595458984



action possibilites: [-1.] 
expected returns: [[37.21837]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [ 1. 29. 25. 29. 29. 25.  0. 15. 25.  1.  1.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15  1 15 15 25] -> size -> 41 
action values: 1 
buys: 0 
player value: 2 
card supply: [21. 23. 30. 24. 30.  8.  2.  9.  6.  7.  3.  0. 10. 10.  9.  9.  1.] 
adversary cards in hand: [ 3.  6.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 11  8  0 10  8 11  6  0  6  3  0 11  0  6  0  0  6  0  6 16  6
  3  6] -> size -> 26 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 40.72223663330078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[ 34.740505]
 [ 45.690304]
 [ 39.292896]
 [-17.474615]
 [ 40.693657]
 [ 43.466835]
 [ 36.08812 ]
 [ 41.24886 ]
 [ 41.414448]
 [ 45.875843]
 [ 36.757458]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 1. 29. 25. 29. 29. 25.  0. 15. 25.  1.  1.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15  1 15 15 25] -> size -> 41 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 23. 30. 24. 30.  8.  2.  9.  6.  7.  3.  0. 10. 10.  9.  9.  1.] 
adversary cards in hand: [ 3.  6.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 11  8  0 10  8 11  6  0  6  3  0 11  0  6  0  0  6  0  6 16  6
  3  6] -> size -> 26 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 37.21836853027344



buy possibilites: [-1] 
expected returns: [[33.50083]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 1. 29. 25. 29. 29. 25.  0. 15. 25.  1.  1.  3. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15  1 15 15 25 15] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 24. 30.  8.  2.  9.  6.  7.  3.  0. 10. 10.  9.  9.  0.] 
adversary cards in hand: [ 3.  6.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  3 11  8  0 10  8 11  6  0  6  3  0 11  0  6  0  0  6  0  6 16  6
  3  6] -> size -> 26 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0 -70   0   0 128   0] 
sum of rewards: 273 

action type: buy - action 15.0
Learning step: 0
desired expected reward: 45.875858306884766






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 3.  6.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  0.  3. 11.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 11  8  0 10  8 11  6  0  6  3  0 11  0  6  0  0  6  0  6 16  6
  3  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 24. 30.  8.  2.  9.  6.  7.  3.  0. 10. 10.  9.  9.  0.] 
adversary cards in hand: [15. 29. 15.  1. 25.] 
adversary cards in discard: [ 1. 29. 25. 29. 29. 25.  0. 15. 25.  1.  1.  3. 15. 29. 29.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15  1 15 15 25 15] -> size -> 42 
adversary victory points: 4
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 3.] 
cards in discard: [6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3 11  8  0 10  8 11  6  0  6  3  0 11  0  6  0  0  6  0  6 16  6
  3  6  6] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 24. 30.  8.  1.  9.  6.  7.  3.  0. 10. 10.  9.  9.  0.] 
adversary cards in hand: [15. 29. 15.  1. 25.] 
adversary cards in discard: [ 1. 29. 25. 29. 29. 25.  0. 15. 25.  1.  1.  3. 15. 29. 29.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15  1 15 15 25 15] -> size -> 42 
adversary victory points: 4
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 3.] 
cards in discard: [6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3 11  8  0 10  8 11  6  0  6  3  0 11  0  6  0  0  6  0  6 16  6
  3  6  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 23. 30. 24. 30.  8.  1.  9.  6.  7.  3.  0. 10. 10.  9.  9.  0.] 
adversary cards in hand: [15. 29. 15.  1. 25.] 
adversary cards in discard: [ 1. 29. 25. 29. 29. 25.  0. 15. 25.  1.  1.  3. 15. 29. 29.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15  1 15 15 25 15] -> size -> 42 
adversary victory points: 4
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 3.] 
cards in discard: [6. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  3 11  8  0 10  8 11  6  0  6  3  0 11  0  6  0  0  6  0  6 16  6
  3  6  6  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 23. 30. 24. 30.  8.  1.  9.  6.  7.  3.  0. 10. 10.  9.  9.  0.] 
adversary cards in hand: [15. 29. 15.  1. 25.] 
adversary cards in discard: [ 1. 29. 25. 29. 29. 25.  0. 15. 25.  1.  1.  3. 15. 29. 29.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15  1 15 15 25 15] -> size -> 42 
adversary victory points: 4
player victory points: -3 





Player: 0 
cards in hand: [15. 29. 15.  1. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29. 15. 25.] 
expected returns: [[-38.513092]
 [-30.42127 ]
 [-26.829567]
 [-30.42127 ]
 [-29.577003]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29. 15.  1. 25.] 
cards in discard: [ 1. 29. 25. 29. 29. 25.  0. 15. 25.  1.  1.  3. 15. 29. 29.  0.  0.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15  1 15 15 25 15] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 24. 30.  8.  1.  9.  6.  7.  3.  0. 10. 10.  9.  9.  0.] 
adversary cards in hand: [6. 6. 8. 6. 0.] 
adversary cards in discard: [ 6.  0. 11.  3.  6.  0.  3.] 
adversary owned cards: [ 3  3  3 11  8  0 10  8 11  6  0  6  3  0 11  0  6  0  0  6  0  6 16  6
  3  6  6  0] -> size -> 28 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 33.500831604003906



action possibilites: [-1. 15. 15. 29.] 
expected returns: [[-55.734745]
 [-59.039326]
 [-59.039326]
 [-61.068077]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 29.] 
cards in discard: [ 1. 29. 25. 29. 29. 25.  0. 15. 25.  1.  1.  3. 15. 29. 29.  0.  0.  3.
  1. 25.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15  1 15 15 25 15] -> size -> 42 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 23. 30. 24. 30.  8.  1.  9.  6.  7.  3.  0. 10. 10.  9.  9.  0.] 
adversary cards in hand: [6. 6. 8. 6. 0.] 
adversary cards in discard: [ 6.  0. 11.  3.  6.  0.  3.] 
adversary owned cards: [ 3  3  3 11  8  0 10  8 11  6  0  6  3  0 11  0  6  0  0  6  0  6 16  6
  3  6  6  0] -> size -> 28 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 5
Learning step: 0
desired expected reward: -29.495046615600586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -66.4059  ]
 [-126.60619 ]
 [ -56.031094]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15. 29.] 
cards in discard: [ 1. 29. 25. 29. 29. 25.  0. 15. 25.  1.  1.  3. 15. 29. 29.  0.  0.  3.
  1. 25.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15  1 15 15 25 15] -> size -> 42 
action values: 1 
buys: 1 
player value: 1 
card supply: [20. 23. 30. 24. 30.  8.  1.  9.  6.  7.  3.  0. 10. 10.  9.  9.  0.] 
adversary cards in hand: [6. 6. 8. 6. 0.] 
adversary cards in discard: [ 6.  0. 11.  3.  6.  0.  3.] 
adversary owned cards: [ 3  3  3 11  8  0 10  8 11  6  0  6  3  0 11  0  6  0  0  6  0  6 16  6
  3  6  6  0] -> size -> 28 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -55.73472595214844






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [6. 6. 8. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 8. 6. 0.] 
cards in discard: [ 6.  0. 11.  3.  6.  0.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3 11  8  0 10  8 11  6  0  6  3  0 11  0  6  0  0  6  0  6 16  6
  3  6  6  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 24. 30.  8.  1.  9.  6.  7.  3.  0. 10. 10.  9.  9.  0.] 
adversary cards in hand: [25.  1. 25. 15. 15.] 
adversary cards in discard: [ 1. 29. 25. 29. 29. 25.  0. 15. 25.  1.  1.  3. 15. 29. 29.  0.  0.  3.
  1. 25. 29. 15. 15. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15  1 15 15 25 15] -> size -> 42 
adversary victory points: 4
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6.] 
cards in discard: [ 6.  0. 11.  3.  6.  0.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 11  8 10  8 11  0  6  3  0 11  0  6  0  0  6  0  6 16  6  3  6
  6  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 24. 30.  8.  1.  9.  6.  7.  3.  0. 10. 10.  9.  9.  0.] 
adversary cards in hand: [25.  1. 25. 15. 15.] 
adversary cards in discard: [ 1. 29. 25. 29. 29. 25.  0. 15. 25.  1.  1.  3. 15. 29. 29.  0.  0.  3.
  1. 25. 29. 15. 15. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15  1 15 15 25 15] -> size -> 42 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6.] 
cards in discard: [ 6.  0. 11.  3.  6.  0.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 11  8 10  8 11  0  6  3  0 11  0  6  0  0  6  0  6 16  6  3  6
  6  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 23. 30. 24. 30.  8.  1.  9.  6.  7.  3.  0. 10. 10.  9.  9.  0.] 
adversary cards in hand: [25.  1. 25. 15. 15.] 
adversary cards in discard: [ 1. 29. 25. 29. 29. 25.  0. 15. 25.  1.  1.  3. 15. 29. 29.  0.  0.  3.
  1. 25. 29. 15. 15. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15  1 15 15 25 15] -> size -> 42 
adversary victory points: 4
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6.] 
cards in discard: [ 6.  0. 11.  3.  6.  0.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3 11  8 10  8 11  0  6  3  0 11  0  6  0  0  6  0  6 16  6  3  6
  6  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 24. 30.  8.  1.  9.  6.  7.  3.  0. 10. 10.  9.  9.  0.] 
adversary cards in hand: [25.  1. 25. 15. 15.] 
adversary cards in discard: [ 1. 29. 25. 29. 29. 25.  0. 15. 25.  1.  1.  3. 15. 29. 29.  0.  0.  3.
  1. 25. 29. 15. 15. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15  1 15 15 25 15] -> size -> 42 
adversary victory points: 4
player victory points: -2 





Player: 0 
cards in hand: [25.  1. 25. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 15. 15.] 
expected returns: [[-22.932125]
 [-13.636866]
 [-13.636866]
 [-14.53566 ]
 [-14.53566 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1. 25. 15. 15.] 
cards in discard: [ 1. 29. 25. 29. 29. 25.  0. 15. 25.  1.  1.  3. 15. 29. 29.  0.  0.  3.
  1. 25. 29. 15. 15. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15  1 15 15 25 15] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 24. 30.  8.  1.  9.  6.  7.  3.  0. 10. 10.  9.  9.  0.] 
adversary cards in hand: [ 0.  3. 10. 11.  0.] 
adversary cards in discard: [ 6.  0. 11.  3.  6.  0.  3.  0.  8.  6.  6.] 
adversary owned cards: [ 3  3  3 11  8 10  8 11  0  6  3  0 11  0  6  0  0  6  0  6 16  6  3  6
  6  0  0] -> size -> 27 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -56.03108596801758



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 6 
Gold: 0 
Estate: 1 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 0 
Chapel: 0 
Witch: 7 
Poacher: 10 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 10 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 1. 25. 15. 15.  3.  0.] 
cards in discard: [ 1. 29. 25. 29. 29. 25.  0. 15. 25.  1.  1.  3. 15. 29. 29.  0.  0.  3.
  1. 25. 29. 15. 15. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 29 29  3  1 29 29 29 29 29 29 29 29 15 15 25
 25 25 15  1 25 15  1  1 15 25 15 25 15  1 15 15 25 15] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 24. 30.  8.  0.  9.  6.  7.  3.  0. 10. 10.  9.  9.  0.] 
adversary cards in hand: [ 0.  3. 10. 11.  0.] 
adversary cards in discard: [ 6.  0. 11.  3.  6.  0.  3.  0.  8.  6.  6.  6.] 
adversary owned cards: [ 3  3  3 11  8 10  8 11  0  6  3  0 11  0  6  0  0  6  0  6 16  6  3  6
  6  0  0  6] -> size -> 28 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[     -5 3000000       0     180       0       0      20       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000195 

action type: take_action - action 25.0
Learning step: 120008.34375
desired expected reward: 119994.703125



