 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[96.589584]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0      -30        0        0        0        0
        0        0        0     -250        0        0       27        0] 
sum of rewards: -3000258 

action type: buy - action 10.0
Learning step: -120010.3203125
desired expected reward: -120010.265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[92.57589 ]
 [94.087234]
 [93.17872 ]
 [91.4714  ]
 [94.09862 ]
 [93.49578 ]
 [92.58728 ]
 [96.47489 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 97.97515869140625



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [3. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [3. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [3. 3. 0. 0. 0. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[101.68493]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 96.47489166259766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 99.93607 ]
 [101.44742 ]
 [100.53892 ]
 [ 98.83158 ]
 [102.48122 ]
 [101.4588  ]
 [100.855965]
 [104.67599 ]
 [ 99.71102 ]
 [ 99.947464]
 [101.22234 ]
 [103.83508 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 102.49932861328125



buy possibilites: [-1] 
expected returns: [[108.3028]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 0.  3.  0.  0.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 104.67598724365234






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 3.  3.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[95.59211]
 [96.43302]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [8. 0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 108.30280303955078



action possibilites: [-1.] 
expected returns: [[103.21142]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [8. 0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 97.50841522216797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 99.92745 ]
 [101.43878 ]
 [100.53028 ]
 [ 98.82295 ]
 [102.47258 ]
 [101.45017 ]
 [100.84735 ]
 [104.66736 ]
 [ 99.702385]
 [ 99.93884 ]
 [101.21372 ]
 [103.82644 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [8. 0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 103.21141815185547



buy possibilites: [-1] 
expected returns: [[105.36497]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [8. 0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 104.66736602783203






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 0.] 
cards in discard: [8. 0. 0. 3. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [29. 29.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8. 0.] 
cards in discard: [8. 0. 0. 3. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [29. 29.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8. 0.] 
cards in discard: [8. 0. 0. 3. 0. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 0] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [29. 29.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[125.18811]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [29. 29.  3.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 105.3649673461914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[122.872345]
 [124.38368 ]
 [123.47519 ]
 [121.76785 ]
 [125.41748 ]
 [124.39507 ]
 [123.79224 ]
 [127.61228 ]
 [122.64729 ]
 [122.88373 ]
 [124.15863 ]
 [126.77135 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [29. 29.  3.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 125.6247787475586



buy possibilites: [-1] 
expected returns: [[108.30544]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [29. 29.  3.  3.  0.  0.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 127.61226654052734






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 0] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 0 0] -> size -> 14 
action values: 0 
buys: 0 
player value: 5 
card supply: [28. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0. 29. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[87.23001]
 [88.07092]
 [88.07092]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 8. 3. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 0 0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 108.3054428100586



action possibilites: [-1. 29.] 
expected returns: [[89.92155]
 [90.76246]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 8. 3. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 0 0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 88.67023468017578



action possibilites: [-1.] 
expected returns: [[103.19062]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 8. 3. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 0 0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 90.76245880126953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[101.12368 ]
 [102.63501 ]
 [100.21519 ]
 [101.72652 ]
 [100.887245]
 [100.01917 ]
 [103.66881 ]
 [102.6464  ]
 [102.04357 ]
 [106.100044]
 [105.86361 ]
 [100.89863 ]
 [104.0352  ]
 [101.13506 ]
 [102.52388 ]
 [102.409966]
 [105.02269 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29] -> size -> 13 
action values: 0 
buys: 1 
player value: 7 
card supply: [28. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 8. 3. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 0 0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 103.19062042236328



buy possibilites: [-1] 
expected returns: [[127.171776]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 30. 30.  8. 10. 10. 10.  8.  9.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 8. 3. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 0 0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 97.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 106.10005187988281






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [3. 8. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3. 3. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 0 0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10. 10.  8.  9.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  3. 29.] 
adversary cards in discard: [25. 29. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3. 3. 0.] 
cards in discard: [0. 0. 0. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 0 0] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8. 10. 10. 10.  8.  9.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  3. 29.] 
adversary cards in discard: [25. 29. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25] -> size -> 14 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3.  0.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[122.736084]
 [123.577   ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  3. 29.] 
cards in discard: [25. 29. 29.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10. 10.  8.  9.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 0 0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 127.1717758178711



action possibilites: [-1.] 
expected returns: [[129.43343]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [25. 29. 29.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8. 10. 10. 10.  8.  9.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 0 0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 123.7692642211914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[126.11933 ]
 [127.63065 ]
 [126.722145]
 [125.014824]
 [127.64204 ]
 [127.0392  ]
 [126.130714]
 [130.01833 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [25. 29. 29.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8. 10. 10. 10.  8.  9.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 0 0] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 129.4334259033203






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 0 0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10. 10.  8.  9.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 0 0] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 30. 30.  8. 10. 10. 10.  8.  9.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 0 0 1] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  8.  9.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25] -> size -> 14 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0.  3. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[82.67829]
 [83.5192 ]
 [83.5192 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 29. 29.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  8.  9.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 8. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 8.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 0 0 1] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 130.01832580566406



action possibilites: [-1. 29.] 
expected returns: [[96.38009]
 [97.221  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 29.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  8.  9.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 8. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 8.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 0 0 1] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 84.17644500732422



action possibilites: [-1.] 
expected returns: [[107.9847]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25] -> size -> 14 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  8.  9.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 8. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 8.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 0 0 1] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 97.22099304199219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[103.89016 ]
 [105.40148 ]
 [104.49299 ]
 [103.65371 ]
 [102.785645]
 [106.43529 ]
 [105.41288 ]
 [104.81005 ]
 [108.866516]
 [108.63007 ]
 [103.6651  ]
 [106.80168 ]
 [103.90155 ]
 [105.29035 ]
 [105.17643 ]
 [107.789154]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  8.  9.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 8. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 8.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 0 0 1] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 107.98470306396484



buy possibilites: [-1] 
expected returns: [[136.72504]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  8.  8.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 8. 0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 8.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 0 0 1] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 285 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 108.86652374267578






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8. 0.] 
cards in discard: [1. 0. 0. 0. 0. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 0 0 1] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  8.  8.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  3.  0. 25.] 
adversary cards in discard: [25. 29. 29.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 8. 0.] 
cards in discard: [1. 0. 0. 0. 0. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 0 0 1] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  8.  8.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  3.  0. 25.] 
adversary cards in discard: [25. 29. 29.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 8. 0.] 
cards in discard: [1. 0. 0. 0. 0. 8. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 0 0 1 8] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  7.  8.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  3.  0. 25.] 
adversary cards in discard: [25. 29. 29.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25] -> size -> 15 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [29.  0.  3.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[122.32122 ]
 [123.149895]
 [123.382904]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  0. 25.] 
cards in discard: [25. 29. 29.  0.  0.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10. 10.  7.  8.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 0 0 1 8] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 136.72503662109375



action possibilites: [-1] 
expected returns: [[155.20827]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  0.  0.  0.] 
cards in discard: [25. 29. 29.  0.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  9. 10. 10.  7.  8.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 0 0 1 8 6] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 123.42565155029297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[154.62967]
 [156.14099]
 [155.2325 ]
 [153.52516]
 [157.1748 ]
 [156.15239]
 [155.54956]
 [159.3696 ]
 [154.40459]
 [154.64104]
 [155.91594]
 [158.52867]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.  0.  0.  0.] 
cards in discard: [25. 29. 29.  0.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 30. 30.  8.  9. 10. 10.  7.  8.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 0 0 1 8 6] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 155.20826721191406



buy possibilites: [-1] 
expected returns: [[186.65059]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.  0.  0.  0.] 
cards in discard: [25. 29. 29.  0.  0.  3.  3.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  9. 10. 10.  7.  8.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 0 0 1 8 6] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 159.3695831298828






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [8. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3. 3.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 0 0 1 8 6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  9. 10. 10.  7.  8.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29] -> size -> 16 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 3 3 8 8 0 0 1 8 6] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  9. 10. 10.  7.  8.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29] -> size -> 16 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 3 3 8 8 0 0 1 8 6] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8.  9. 10. 10.  7.  8.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29] -> size -> 16 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [6. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 3 3 8 8 0 0 1 8 6 0] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8.  9. 10. 10.  7.  8.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29] -> size -> 16 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 3.  0.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[101.20234]
 [102.27969]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 25.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  9. 10. 10.  7.  8.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [6. 0. 8. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 3 3 8 8 0 0 1 8 6 0] -> size -> 16 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 186.6505889892578



action possibilites: [-1] 
expected returns: [[126.20379]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  8. 10. 10.  7.  8.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [6. 0. 8. 0. 3. 6.] 
adversary owned cards: [0 0 0 0 0 0 3 3 8 8 0 0 1 8 6 0 6] -> size -> 17 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 102.71634674072266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[123.60327 ]
 [125.1146  ]
 [124.206085]
 [122.498764]
 [126.148415]
 [125.125984]
 [124.523155]
 [128.34319 ]
 [123.378204]
 [123.61466 ]
 [124.88954 ]
 [127.50227 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 30. 30.  8.  8. 10. 10.  7.  8.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [6. 0. 8. 0. 3. 6.] 
adversary owned cards: [0 0 0 0 0 0 3 3 8 8 0 0 1 8 6 0 6] -> size -> 17 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 126.20378875732422



buy possibilites: [-1] 
expected returns: [[131.9171]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 29.  0.] 
cards in discard: [29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  8. 10. 10.  7.  8.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [6. 0. 8. 0. 3. 6.] 
adversary owned cards: [0 0 0 0 0 0 3 3 8 8 0 0 1 8 6 0 6] -> size -> 17 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 203 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 128.34320068359375






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [6. 0. 8. 0. 3. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 8 8 0 0 1 8 6 0 6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  8. 10. 10.  7.  8.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  0. 29.  3.] 
adversary cards in discard: [29. 25.  3.  0.  0.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29] -> size -> 17 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [6. 0. 8. 0. 3. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 3 3 8 8 0 0 1 8 6 0 6] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8.  8. 10. 10.  7.  8.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  0. 29.  3.] 
adversary cards in discard: [29. 25.  3.  0.  0.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29] -> size -> 17 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [6. 0. 8. 0. 3. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 3 3 8 8 0 0 1 8 6 0 6] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 30. 30.  8.  8. 10. 10.  7.  8.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  0. 29.  3.] 
adversary cards in discard: [29. 25.  3.  0.  0.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29] -> size -> 17 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [6. 0. 8. 0. 3. 6. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 3 3 8 8 0 0 1 8 6 0 6 0] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 30. 30.  8.  8. 10. 10.  7.  8.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  0. 29.  3.] 
adversary cards in discard: [29. 25.  3.  0.  0.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29] -> size -> 17 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [29.  0.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[151.57286]
 [152.41377]
 [152.41377]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 29.  3.] 
cards in discard: [29. 25.  3.  0.  0.  0. 29.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8.  8. 10. 10.  7.  8.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 1. 8.] 
adversary cards in discard: [6. 0. 8. 0. 3. 6. 0. 8. 0. 0.] 
adversary owned cards: [0 0 0 0 3 3 8 8 0 0 1 8 6 0 6 0] -> size -> 16 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 131.91709899902344



action possibilites: [-1. 29.] 
expected returns: [[167.98938]
 [168.83029]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  3.  0.] 
cards in discard: [29. 25.  3.  0.  0.  0. 29.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 30. 30.  8.  8. 10. 10.  7.  8.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 1. 8.] 
adversary cards in discard: [6. 0. 8. 0. 3. 6. 0. 8. 0. 0.] 
adversary owned cards: [0 0 0 0 3 3 8 8 0 0 1 8 6 0 6 0] -> size -> 16 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 152.160888671875



action possibilites: [-1.] 
expected returns: [[179.13206]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [29. 25.  3.  0.  0.  0. 29.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 30. 30.  8.  8. 10. 10.  7.  8.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 1. 8.] 
adversary cards in discard: [6. 0. 8. 0. 3. 6. 0. 8. 0. 0.] 
adversary owned cards: [0 0 0 0 3 3 8 8 0 0 1 8 6 0 6 0] -> size -> 16 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 168.83029174804688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[176.57649]
 [178.08781]
 [177.17934]
 [176.34006]
 [175.472  ]
 [179.12164]
 [178.09923]
 [177.4964 ]
 [181.55289]
 [181.31642]
 [176.35146]
 [179.48802]
 [176.58789]
 [177.9767 ]
 [177.8628 ]
 [180.4755 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [29. 25.  3.  0.  0.  0. 29.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 29. 30. 30. 30.  8.  8. 10. 10.  7.  8.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 1. 8.] 
adversary cards in discard: [6. 0. 8. 0. 3. 6. 0. 8. 0. 0.] 
adversary owned cards: [0 0 0 0 3 3 8 8 0 0 1 8 6 0 6 0] -> size -> 16 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 179.13206481933594



buy possibilites: [-1] 
expected returns: [[195.41264]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [29. 25.  3.  0.  0.  0. 29.  0. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8.  8. 10. 10.  7.  7.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 1. 8.] 
adversary cards in discard: [6. 0. 8. 0. 3. 6. 0. 8. 0. 0.] 
adversary owned cards: [0 0 0 0 3 3 8 8 0 0 1 8 6 0 6 0] -> size -> 16 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 375 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 181.5528564453125






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 1. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 1. 8.] 
cards in discard: [6. 0. 8. 0. 3. 6. 0. 8. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 3 8 8 0 0 1 8 6 0 6 0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 30. 30.  8.  8. 10. 10.  7.  7.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 25. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25] -> size -> 18 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 8.] 
cards in discard: [6. 0. 8. 0. 3. 6. 0. 8. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 3 8 8 0 0 1 8 6 0 6 0] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 30. 30.  8.  8. 10. 10.  7.  7.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 25. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25] -> size -> 18 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 8.] 
cards in discard: [6. 0. 8. 0. 3. 6. 0. 8. 0. 0. 1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 3 8 8 0 0 1 8 6 0 6 0 1] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 30. 30.  8.  8. 10. 10.  7.  7.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 25. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25] -> size -> 18 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 0.  0.  0. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[116.82228 ]
 [117.899635]
 [117.6632  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 25. 29.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8.  8. 10. 10.  7.  7.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 0. 8. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 3 3 8 8 0 0 1 8 6 0 6 0 1] -> size -> 17 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 195.4126434326172



action possibilites: [-1] 
expected returns: [[124.647545]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.  3.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8.  7. 10. 10.  7.  7.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 0. 8. 1. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 0 0 0 3 3 8 8 0 0 1 8 6 0 6 0 1 6] -> size -> 18 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 118.25270080566406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[122.649925]
 [124.16128 ]
 [123.25276 ]
 [121.54543 ]
 [124.172646]
 [123.56981 ]
 [122.66131 ]
 [126.54893 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29.  3.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 30. 30.  8.  7. 10. 10.  7.  7.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 0. 8. 1. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 0 0 0 3 3 8 8 0 0 1 8 6 0 6 0 1 6] -> size -> 18 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 124.64754486083984






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [6. 0. 8. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 1. 0.] 
cards in discard: [6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 3 8 8 0 0 1 8 6 0 6 0 1 6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8.  7. 10. 10.  7.  7.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0. 25.  0.  0.] 
adversary cards in discard: [25.  0.  0.  0. 29.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25] -> size -> 18 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 3 3 8 8 0 0 8 0 6 0 1 6] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8.  7. 10. 10.  7.  7.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0. 25.  0.  0.] 
adversary cards in discard: [25.  0.  0.  0. 29.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25] -> size -> 18 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 3 3 8 8 0 0 8 0 6 0 1 6] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 30. 30.  8.  7. 10. 10.  7.  7.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0. 25.  0.  0.] 
adversary cards in discard: [25.  0.  0.  0. 29.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25] -> size -> 18 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [29.  0. 25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[152.64352]
 [153.48445]
 [153.72089]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 25.  0.  0.] 
cards in discard: [25.  0.  0.  0. 29.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8.  7. 10. 10.  7.  7.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 1. 0.] 
adversary cards in discard: [6. 8. 0.] 
adversary owned cards: [0 0 0 3 3 8 8 0 0 8 0 6 0 1 6] -> size -> 15 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 126.5489273071289



action possibilites: [-1] 
expected returns: [[161.807]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0.  3. 29.] 
cards in discard: [25.  0.  0.  0. 29.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8.  6. 10. 10.  7.  7.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 1. 0.] 
adversary cards in discard: [6. 8. 0. 6.] 
adversary owned cards: [0 0 0 3 3 8 8 0 0 8 0 6 0 1 6 6] -> size -> 16 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 153.7244873046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[158.87883]
 [160.39017]
 [159.48166]
 [157.77434]
 [160.40155]
 [159.7987 ]
 [158.89021]
 [162.77782]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  0.  3. 29.] 
cards in discard: [25.  0.  0.  0. 29.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 30. 30.  8.  6. 10. 10.  7.  7.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 8. 1. 0.] 
adversary cards in discard: [6. 8. 0. 6.] 
adversary owned cards: [0 0 0 3 3 8 8 0 0 8 0 6 0 1 6 6] -> size -> 16 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 161.8070068359375






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 1. 0.] 
cards in discard: [6. 8. 0. 6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 3 3 8 8 0 0 8 0 6 0 1 6 6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8.  6. 10. 10.  7.  7.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 25. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25] -> size -> 18 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [6. 8. 0. 6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 3 3 8 8 0 0 8 0 6 0 6 6] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8.  6. 10. 10.  7.  7.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 25. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25] -> size -> 18 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [6. 8. 0. 6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 3 3 8 8 0 0 8 0 6 0 6 6] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 30. 30.  8.  6. 10. 10.  7.  7.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 25. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25] -> size -> 18 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [ 3. 25. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 29.] 
expected returns: [[114.657616]
 [115.73498 ]
 [115.49854 ]
 [115.49854 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 29. 29.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8.  6. 10. 10.  7.  7.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 6. 8. 3. 0.] 
adversary cards in discard: [6. 8. 0. 6. 8. 0.] 
adversary owned cards: [0 3 3 8 8 0 0 8 0 6 0 6 6] -> size -> 13 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 162.77784729003906



action possibilites: [-1] 
expected returns: [[121.75768]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 29.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8.  5. 10. 10.  7.  7.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 6. 8. 3. 0.] 
adversary cards in discard: [6. 8. 0. 6. 8. 0. 6.] 
adversary owned cards: [0 3 3 8 8 0 0 8 0 6 0 6 6 6] -> size -> 14 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 116.24539184570312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[121.54474]
 [122.14758]
 [120.44024]
 [122.46463]
 [125.44374]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29. 29.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 30. 30.  8.  5. 10. 10.  7.  7.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 6. 8. 3. 0.] 
adversary cards in discard: [6. 8. 0. 6. 8. 0. 6.] 
adversary owned cards: [0 3 3 8 8 0 0 8 0 6 0 6 6 6] -> size -> 14 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 121.75768280029297






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [0. 6. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8. 3. 0.] 
cards in discard: [6. 8. 0. 6. 8. 0. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 3 3 8 8 0 0 8 0 6 0 6 6 6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8.  5. 10. 10.  7.  7.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 25.  0.  0.  0.] 
adversary cards in discard: [25.  3. 29. 29.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25] -> size -> 18 
adversary victory points: 3
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [6. 8. 0. 6. 8. 0. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 3 8 8 0 0 8 0 0 6 6 6] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8.  5. 10. 10.  7.  7.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 25.  0.  0.  0.] 
adversary cards in discard: [25.  3. 29. 29.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25] -> size -> 18 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [6. 8. 0. 6. 8. 0. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 3 8 8 0 0 8 0 0 6 6 6] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 30. 30.  8.  5. 10. 10.  7.  7.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 25.  0.  0.  0.] 
adversary cards in discard: [25.  3. 29. 29.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25] -> size -> 18 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [ 3. 25.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[160.82706]
 [161.90442]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  0.  0.  0.] 
cards in discard: [25.  3. 29. 29.  0.  0. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8.  5. 10. 10.  7.  7.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [3 3 8 8 0 0 8 0 0 6 6 6] -> size -> 12 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 125.4437484741211



action possibilites: [-1] 
expected returns: [[140.8531]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 29. 29.] 
cards in discard: [25.  3. 29. 29.  0.  0. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8.  4. 10. 10.  7.  7.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 3. 0. 0. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [3 3 8 8 0 0 8 0 0 6 6 6 6] -> size -> 13 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 162.09823608398438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[141.73701]
 [143.24834]
 [142.33986]
 [140.63252]
 [143.25974]
 [142.6569 ]
 [141.7484 ]
 [145.63602]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 29. 29.] 
cards in discard: [25.  3. 29. 29.  0.  0. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 30. 30.  8.  4. 10. 10.  7.  7.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 3. 0. 0. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [3 3 8 8 0 0 8 0 0 6 6 6 6] -> size -> 13 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 140.8531036376953






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [6. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 0. 3.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 8 8 0 0 8 0 0 6 6 6 6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 30. 30.  8.  4. 10. 10.  7.  7.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25] -> size -> 18 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0. 3.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 8 8 0 0 8 0 0 6 6 6 6] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 30. 30.  8.  4. 10. 10.  7.  7.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25] -> size -> 18 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0. 3.] 
cards in discard: [6. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 8 8 0 0 8 0 0 6 6 6 6 3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  4. 10. 10.  7.  7.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25] -> size -> 18 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [ 0. 29.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[119.74499]
 [120.5859 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  4. 10. 10.  7.  7.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 0. 8. 8. 0.] 
adversary cards in discard: [6. 3. 6. 3. 0. 0. 3.] 
adversary owned cards: [3 3 8 8 0 0 8 0 0 6 6 6 6 3] -> size -> 14 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 145.6360321044922



action possibilites: [-1. 25.] 
expected returns: [[117.76014]
 [118.8375 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 29. 30.  8.  4. 10. 10.  7.  7.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 0. 8. 8. 0.] 
adversary cards in discard: [6. 3. 6. 3. 0. 0. 3.] 
adversary owned cards: [3 3 8 8 0 0 8 0 0 6 6 6 6 3] -> size -> 14 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 121.02255249023438



action possibilites: [-1] 
expected returns: [[137.57532]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 29. 30.  8.  3. 10. 10.  7.  7.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 0. 8. 8. 0.] 
adversary cards in discard: [6. 3. 6. 3. 0. 0. 3. 6.] 
adversary owned cards: [3 3 8 8 0 0 8 0 0 6 6 6 6 3 6] -> size -> 15 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 118.8375015258789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[136.62088]
 [138.13223]
 [137.22372]
 [136.38445]
 [135.5164 ]
 [139.16602]
 [138.14362]
 [137.54077]
 [141.59726]
 [141.36081]
 [136.39583]
 [139.53241]
 [136.63228]
 [138.02109]
 [137.90717]
 [140.5199 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 28. 30. 29. 30.  8.  3. 10. 10.  7.  7.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 0. 8. 8. 0.] 
adversary cards in discard: [6. 3. 6. 3. 0. 0. 3. 6.] 
adversary owned cards: [3 3 8 8 0 0 8 0 0 6 6 6 6 3 6] -> size -> 15 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: 137.5753173828125



buy possibilites: [-1] 
expected returns: [[150.47203]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0.  0. 29.] 
cards in discard: [25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  3. 10. 10.  7.  6.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 0. 8. 8. 0.] 
adversary cards in discard: [6. 3. 6. 3. 0. 0. 3. 6.] 
adversary owned cards: [3 3 8 8 0 0 8 0 0 6 6 6 6 3 6] -> size -> 15 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 405 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 141.59725952148438






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [6. 0. 8. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 8. 0.] 
cards in discard: [6. 3. 6. 3. 0. 0. 3. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 8 8 0 0 8 0 0 6 6 6 6 3 6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  3. 10. 10.  7.  6.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29. 29.  0.  3. 25.] 
adversary cards in discard: [25. 29. 25.  0.  3.  0.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25] -> size -> 19 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 8. 0.] 
cards in discard: [6. 3. 6. 3. 0. 0. 3. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 8 8 0 0 8 0 0 6 6 6 6 3 6] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 29. 30.  8.  3. 10. 10.  7.  6.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29. 29.  0.  3. 25.] 
adversary cards in discard: [25. 29. 25.  0.  3.  0.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25] -> size -> 19 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 8. 0.] 
cards in discard: [6. 3. 6. 3. 0. 0. 3. 6. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 8 8 0 0 8 0 0 6 6 6 6 3 6 3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  3. 10. 10.  7.  6.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29. 29.  0.  3. 25.] 
adversary cards in discard: [25. 29. 25.  0.  3.  0.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25] -> size -> 19 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [29. 29.  0.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 25.] 
expected returns: [[155.8473 ]
 [156.6882 ]
 [156.6882 ]
 [156.92464]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0.  3. 25.] 
cards in discard: [25. 29. 25.  0.  3.  0.  0.  0. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  3. 10. 10.  7.  6.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 6. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [3 3 8 8 0 0 8 0 0 6 6 6 6 3 6 3] -> size -> 16 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 150.47203063964844



action possibilites: [-1] 
expected returns: [[205.79901]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0.  3. 29.  0.] 
cards in discard: [25. 29. 25.  0.  3.  0.  0.  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  2. 10. 10.  7.  6.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 6. 6. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [3 3 8 8 0 0 8 0 0 6 6 6 6 3 6 3 6] -> size -> 17 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 156.23211669921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[203.97644]
 [204.57928]
 [202.87196]
 [204.89633]
 [207.87544]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29.  0.  3. 29.  0.] 
cards in discard: [25. 29. 25.  0.  3.  0.  0.  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 28. 30.  8.  2. 10. 10.  7.  6.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 6. 6. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [3 3 8 8 0 0 8 0 0 6 6 6 6 3 6 3 6] -> size -> 17 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 205.79901123046875






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [0. 8. 6. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 6. 8.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 8 8 0 0 8 0 0 6 6 6 6 3 6 3 6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  2. 10. 10.  7.  6.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25] -> size -> 19 
adversary victory points: 3
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 3 8 8 0 0 8 0 0 6 6 6 3 6 3 6] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  2. 10. 10.  7.  6.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25] -> size -> 19 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 3 8 8 0 0 8 0 0 6 6 6 3 6 3 6] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 28. 30.  8.  2. 10. 10.  7.  6.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25] -> size -> 19 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [29.  0. 25.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[115.317955]
 [116.15887 ]
 [116.39531 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 25.  3.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  2. 10. 10.  7.  6.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 0. 3. 0. 3.] 
adversary cards in discard: [6. 8. 0. 6. 8.] 
adversary owned cards: [3 3 8 8 0 0 8 0 0 6 6 6 3 6 3 6] -> size -> 16 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 207.87547302246094



action possibilites: [-1] 
expected returns: [[140.08118]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  1. 10. 10.  7.  6.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 0. 3. 0. 3.] 
adversary cards in discard: [6. 8. 0. 6. 8. 6.] 
adversary owned cards: [3 3 8 8 0 0 8 0 0 6 6 6 3 6 3 6 6] -> size -> 17 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 116.74837493896484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[139.88521]
 [141.39656]
 [140.48805]
 [138.7807 ]
 [142.43034]
 [141.40793]
 [140.80511]
 [144.6251 ]
 [139.66016]
 [139.8966 ]
 [141.17148]
 [143.78421]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 28. 30. 28. 30.  8.  1. 10. 10.  7.  6.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 0. 3. 0. 3.] 
adversary cards in discard: [6. 8. 0. 6. 8. 6.] 
adversary owned cards: [3 3 8 8 0 0 8 0 0 6 6 6 3 6 3 6 6] -> size -> 17 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 140.0811767578125



buy possibilites: [-1] 
expected returns: [[150.62697]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.  0.  0.  0.] 
cards in discard: [29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  1. 10. 10.  7.  6.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 0. 3. 0. 3.] 
adversary cards in discard: [6. 8. 0. 6. 8. 6.] 
adversary owned cards: [3 3 8 8 0 0 8 0 0 6 6 6 3 6 3 6 6] -> size -> 17 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 263 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 144.62513732910156






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [6. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0. 3.] 
cards in discard: [6. 8. 0. 6. 8. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 8 8 0 0 8 0 0 6 6 6 3 6 3 6 6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  1. 10. 10.  7.  6.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25.  3. 29.  3.  0.] 
adversary cards in discard: [29. 25. 29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29] -> size -> 20 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 3.] 
cards in discard: [6. 8. 0. 6. 8. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 8 8 0 0 8 0 0 6 6 6 3 6 3 6 6] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 28. 30.  8.  1. 10. 10.  7.  6.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25.  3. 29.  3.  0.] 
adversary cards in discard: [29. 25. 29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29] -> size -> 20 
adversary victory points: 3
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [25.  3. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[170.14299]
 [171.22035]
 [170.9839 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3. 29.  3.  0.] 
cards in discard: [29. 25. 29.  0.  3.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  1. 10. 10.  7.  6.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 3. 8. 3. 0.] 
adversary cards in discard: [6. 8. 0. 6. 8. 6. 6. 0. 3. 0. 3.] 
adversary owned cards: [3 3 8 8 0 0 8 0 0 6 6 6 3 6 3 6 6] -> size -> 17 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 150.62696838378906



action possibilites: [-1] 
expected returns: [[197.17796]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3.  0. 29.  0.] 
cards in discard: [29. 25. 29.  0.  3.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  0. 10. 10.  7.  6.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 3. 8. 3. 0.] 
adversary cards in discard: [6. 8. 0. 6. 8. 6. 6. 0. 3. 0. 3. 6.] 
adversary owned cards: [3 3 8 8 0 0 8 0 0 6 6 6 3 6 3 6 6 6] -> size -> 18 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 170.25782775878906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[195.78545]
 [196.38828]
 [196.70534]
 [199.68445]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  3.  0. 29.  0.] 
cards in discard: [29. 25. 29.  0.  3.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 28. 30.  8.  0. 10. 10.  7.  6.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 3. 8. 3. 0.] 
adversary cards in discard: [6. 8. 0. 6. 8. 6. 6. 0. 3. 0. 3. 6.] 
adversary owned cards: [3 3 8 8 0 0 8 0 0 6 6 6 3 6 3 6 6 6] -> size -> 18 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 197.17796325683594






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [6. 3. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 8. 3. 0.] 
cards in discard: [6. 8. 0. 6. 8. 6. 6. 0. 3. 0. 3. 6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 8 8 0 0 8 0 0 6 6 6 3 6 3 6 6 6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  0. 10. 10.  7.  6.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29. 25. 29.  0. 25.] 
adversary cards in discard: [29. 25. 29.  0.  3.  0.  0.  0. 25.  3. 29.  3.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29] -> size -> 20 
adversary victory points: 3
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0.] 
cards in discard: [6. 8. 0. 6. 8. 6. 6. 0. 3. 0. 3. 6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 8 8 0 0 8 0 0 6 6 6 3 6 3 6 6 6] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  0. 10. 10.  7.  6.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29. 25. 29.  0. 25.] 
adversary cards in discard: [29. 25. 29.  0.  3.  0.  0.  0. 25.  3. 29.  3.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29] -> size -> 20 
adversary victory points: 3
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0.] 
cards in discard: [6. 8. 0. 6. 8. 6. 6. 0. 3. 0. 3. 6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 8 8 0 0 8 0 0 6 6 6 3 6 3 6 6 6] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 28. 30.  8.  0. 10. 10.  7.  6.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29. 25. 29.  0. 25.] 
adversary cards in discard: [29. 25. 29.  0.  3.  0.  0.  0. 25.  3. 29.  3.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29] -> size -> 20 
adversary victory points: 3
player victory points: -4 





Player: 0 
cards in hand: [29. 25. 29.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29. 25.] 
expected returns: [[173.37675]
 [174.21767]
 [174.4541 ]
 [174.21767]
 [174.4541 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 29.  0. 25.] 
cards in discard: [29. 25. 29.  0.  3.  0.  0.  0. 25.  3. 29.  3.  0. 29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  0. 10. 10.  7.  6.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 6. 6. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [3 8 8 0 0 8 0 0 6 6 6 3 6 3 6 6 6] -> size -> 17 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 199.68446350097656



action possibilites: [-1] 
expected returns: [[130.66762]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0. 25. 29.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  0. 10. 10.  7.  6.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 6. 6. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [3 8 8 0 0 8 0 0 6 6 6 3 6 3 6 6 6] -> size -> 17 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 173.0527801513672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[128.12404]
 [128.7182 ]
 [129.03067]
 [131.99498]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29.  0. 25. 29.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 28. 30.  8.  0. 10. 10.  7.  6.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 6. 6. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [3 8 8 0 0 8 0 0 6 6 6 3 6 3 6 6 6] -> size -> 17 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 130.66761779785156






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [3. 6. 6. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 3. 6.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [3 8 8 0 0 8 0 0 6 6 6 3 6 3 6 6 6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  0. 10. 10.  7.  6.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25. 29.  0.  3.  3.] 
adversary cards in discard: [25. 29. 29.  0. 25. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29] -> size -> 20 
adversary victory points: 3
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 3. 6.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [3 8 8 0 0 8 0 0 6 6 6 3 6 3 6 6 6] -> size -> 17 
action values: 1 
buys: 1 
player value: 0 
card supply: [26. 28. 30. 28. 30.  8.  0. 10. 10.  7.  6.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25. 29.  0.  3.  3.] 
adversary cards in discard: [25. 29. 29.  0. 25. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29] -> size -> 20 
adversary victory points: 3
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 3. 6.] 
cards in discard: [0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [3 8 8 0 0 8 0 0 6 6 6 3 6 3 6 6 6 0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  0. 10. 10.  7.  6.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25. 29.  0.  3.  3.] 
adversary cards in discard: [25. 29. 29.  0. 25. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29] -> size -> 20 
adversary victory points: 3
player victory points: -4 





Player: 0 
cards in hand: [25. 29.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[150.61055]
 [151.68791]
 [151.45148]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29.  0.  3.  3.] 
cards in discard: [25. 29. 29.  0. 25. 29.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  0. 10. 10.  7.  6.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 8. 6. 0.] 
adversary cards in discard: [0. 3. 6. 6. 3. 6.] 
adversary owned cards: [3 8 8 0 0 8 0 0 6 6 6 3 6 3 6 6 6 0] -> size -> 18 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 131.9949951171875



action possibilites: [-1] 
expected returns: [[172.72514]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  3.  0. 25.] 
cards in discard: [25. 29. 29.  0. 25. 29.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  0. 10. 10.  7.  6.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 8. 6. 0.] 
adversary cards in discard: [0. 3. 6. 6. 3. 6.] 
adversary owned cards: [3 8 8 0 0 8 0 0 6 6 6 3 6 3 6 6 6 0] -> size -> 18 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 150.72540283203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[171.43971]
 [172.04256]
 [172.3596 ]
 [175.33873]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.  3.  0. 25.] 
cards in discard: [25. 29. 29.  0. 25. 29.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 28. 30.  8.  0. 10. 10.  7.  6.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 8. 6. 0.] 
adversary cards in discard: [0. 3. 6. 6. 3. 6.] 
adversary owned cards: [3 8 8 0 0 8 0 0 6 6 6 3 6 3 6 6 6 0] -> size -> 18 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 172.7251434326172






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [8. 0. 8. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 6. 0.] 
cards in discard: [0. 3. 6. 6. 3. 6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [3 8 8 0 0 8 0 0 6 6 6 3 6 3 6 6 6 0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  0. 10. 10.  7.  6.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  0. 29.  3.] 
adversary cards in discard: [25. 29. 29.  0. 25. 29.  0. 25. 29.  0.  3.  3.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29] -> size -> 20 
adversary victory points: 3
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [0. 3. 6. 6. 3. 6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 8 8 0 8 0 0 6 6 3 6 3 6 6 6 0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  0. 10. 10.  7.  6.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  0. 29.  3.] 
adversary cards in discard: [25. 29. 29.  0. 25. 29.  0. 25. 29.  0.  3.  3.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29] -> size -> 20 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [0. 3. 6. 6. 3. 6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 8 8 0 8 0 0 6 6 3 6 3 6 6 6 0] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 28. 30.  8.  0. 10. 10.  7.  6.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  0. 29.  3.] 
adversary cards in discard: [25. 29. 29.  0. 25. 29.  0. 25. 29.  0.  3.  3.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29] -> size -> 20 
adversary victory points: 3
player victory points: -3 





Player: 0 
cards in hand: [29.  0.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[128.37598]
 [129.21689]
 [129.21689]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 29.  3.] 
cards in discard: [25. 29. 29.  0. 25. 29.  0. 25. 29.  0.  3.  3.  0. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  0. 10. 10.  7.  6.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 3. 0. 8. 6.] 
adversary cards in discard: [0. 3. 6. 6. 3. 6. 8. 8. 0.] 
adversary owned cards: [3 8 8 0 8 0 0 6 6 3 6 3 6 6 6 0] -> size -> 16 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 175.33872985839844



action possibilites: [-1.] 
expected returns: [[162.36479]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [25. 29. 29.  0. 25. 29.  0. 25. 29.  0.  3.  3.  0. 25. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 28. 30.  8.  0. 10. 10.  7.  6.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 3. 0. 8. 6.] 
adversary cards in discard: [0. 3. 6. 6. 3. 6. 8. 8. 0.] 
adversary owned cards: [3 8 8 0 8 0 0 6 6 3 6 3 6 6 6 0] -> size -> 16 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 124.39769744873047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[160.16124]
 [161.67258]
 [160.76407]
 [162.70638]
 [161.68398]
 [161.08113]
 [164.90115]
 [159.9362 ]
 [160.17264]
 [161.44751]
 [164.06026]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [25. 29. 29.  0. 25. 29.  0. 25. 29.  0.  3.  3.  0. 25. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 28. 30. 28. 30.  8.  0. 10. 10.  7.  6.  4. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 3. 0. 8. 6.] 
adversary cards in discard: [0. 3. 6. 6. 3. 6. 8. 8. 0.] 
adversary owned cards: [3 8 8 0 8 0 0 6 6 3 6 3 6 6 6 0] -> size -> 16 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 162.3647918701172



buy possibilites: [-1] 
expected returns: [[173.65987]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [25. 29. 29.  0. 25. 29.  0. 25. 29.  0.  3.  3.  0. 25. 29. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  0. 10. 10.  7.  6.  3. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 3. 0. 8. 6.] 
adversary cards in discard: [0. 3. 6. 6. 3. 6. 8. 8. 0.] 
adversary owned cards: [3 8 8 0 8 0 0 6 6 3 6 3 6 6 6 0] -> size -> 16 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 323 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 164.90115356445312






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [6. 3. 0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 8. 6.] 
cards in discard: [0. 3. 6. 6. 3. 6. 8. 8. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [3 8 8 0 8 0 0 6 6 3 6 3 6 6 6 0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  0. 10. 10.  7.  6.  3. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25.  3.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29] -> size -> 21 
adversary victory points: 3
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [0. 3. 6. 6. 3. 6. 8. 8. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 8 8 0 8 0 0 3 6 3 6 6 6 0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  0. 10. 10.  7.  6.  3. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25.  3.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29] -> size -> 21 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [0. 3. 6. 6. 3. 6. 8. 8. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 8 8 0 8 0 0 3 6 3 6 6 6 0] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 28. 30.  8.  0. 10. 10.  7.  6.  3. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25.  3.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29] -> size -> 21 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [25.  3.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[121.95368]
 [123.01536]
 [122.78234]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  0. 10. 10.  7.  6.  3. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [3 8 8 0 8 0 0 3 6 3 6 6 6 0] -> size -> 14 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 173.6598663330078



action possibilites: [-1] 
expected returns: [[134.67844]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 29.  0. 29.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  0. 10. 10.  7.  6.  3. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [3 8 8 0 8 0 0 3 6 3 6 6 6 0] -> size -> 14 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 123.35591888427734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[132.4595 ]
 [133.97083]
 [133.06233]
 [133.98222]
 [133.37938]
 [132.47089]
 [136.35849]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 29.  0. 29.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 28. 30.  8.  0. 10. 10.  7.  6.  3. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [3 8 8 0 8 0 0 3 6 3 6 6 6 0] -> size -> 14 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 134.67843627929688






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [3 8 8 0 8 0 0 3 6 3 6 6 6 0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  0. 10. 10.  7.  6.  3. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29. 29. 29.  0.] 
adversary cards in discard: [25.  3.  0.  0. 29.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29] -> size -> 21 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [3 8 8 0 8 0 0 3 6 3 6 6 6 0] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 28. 30. 28. 30.  8.  0. 10. 10.  7.  6.  3. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29. 29. 29.  0.] 
adversary cards in discard: [25.  3.  0.  0. 29.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29] -> size -> 21 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  8  0  8  0  0  3  6  3  6  6  6  0 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  0. 10. 10.  7.  6.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29. 29. 29.  0.] 
adversary cards in discard: [25.  3.  0.  0. 29.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29] -> size -> 21 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [ 0. 29. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[156.80263]
 [157.64354]
 [157.64354]
 [157.64354]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29. 29.  0.] 
cards in discard: [25.  3.  0.  0. 29.  0. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  0. 10. 10.  7.  6.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 6. 8. 8. 3.] 
adversary cards in discard: [29.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 3  8  8  0  8  0  0  3  6  3  6  6  6  0 29] -> size -> 15 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 136.35850524902344



action possibilites: [-1. 29.] 
expected returns: [[199.61746]
 [200.45837]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.] 
cards in discard: [25.  3.  0.  0. 29.  0. 29. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 28. 30.  8.  0. 10. 10.  7.  6.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 6. 8. 8. 3.] 
adversary cards in discard: [29.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 3  8  8  0  8  0  0  3  6  3  6  6  6  0 29] -> size -> 15 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 153.00621032714844



action possibilites: [-1.] 
expected returns: [[161.75427]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [25.  3.  0.  0. 29.  0. 29. 29. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 28. 30. 28. 30.  8.  0. 10. 10.  7.  6.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 6. 8. 8. 3.] 
adversary cards in discard: [29.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 3  8  8  0  8  0  0  3  6  3  6  6  6  0 29] -> size -> 15 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 196.31378173828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[159.90512]
 [161.41647]
 [160.50798]
 [159.66869]
 [162.45026]
 [161.42784]
 [160.82501]
 [164.88148]
 [164.64505]
 [159.68007]
 [162.81665]
 [159.91652]
 [161.30531]
 [161.1914 ]
 [163.80414]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [25.  3.  0.  0. 29.  0. 29. 29. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 28. 30. 28. 30.  8.  0. 10. 10.  7.  6.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 6. 8. 8. 3.] 
adversary cards in discard: [29.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 3  8  8  0  8  0  0  3  6  3  6  6  6  0 29] -> size -> 15 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 161.7542724609375



buy possibilites: [-1] 
expected returns: [[169.11214]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [25.  3.  0.  0. 29.  0. 29. 29. 25. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  0. 10. 10.  7.  5.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 6. 8. 8. 3.] 
adversary cards in discard: [29.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 3  8  8  0  8  0  0  3  6  3  6  6  6  0 29] -> size -> 15 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 405 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 164.88148498535156






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [6. 6. 8. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 8. 8. 3.] 
cards in discard: [29.  0.  0.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  8  0  8  0  0  3  6  3  6  6  6  0 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  0. 10. 10.  7.  5.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  0. 25.] 
adversary cards in discard: [25.  3.  0.  0. 29.  0. 29. 29. 25. 25. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25] -> size -> 22 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6.] 
cards in discard: [29.  0.  0.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  0. 10. 10.  7.  5.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  0. 25.] 
adversary cards in discard: [25.  3.  0.  0. 29.  0. 29. 29. 25. 25. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25] -> size -> 22 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6.] 
cards in discard: [29.  0.  0.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  0. 10. 10.  7.  5.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  0. 25.] 
adversary cards in discard: [25.  3.  0.  0. 29.  0. 29. 29. 25. 25. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25] -> size -> 22 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6.] 
cards in discard: [29.  0.  0.  0.  0.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  0. 10. 10.  7.  5.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  0. 25.] 
adversary cards in discard: [25.  3.  0.  0. 29.  0. 29. 29. 25. 25. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25] -> size -> 22 
adversary victory points: 3
player victory points: -2 





Player: 0 
cards in hand: [ 3. 29.  3.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[155.81906]
 [156.65997]
 [156.89642]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3.  0. 25.] 
cards in discard: [25.  3.  0.  0. 29.  0. 29. 29. 25. 25. 29. 29.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  0. 10. 10.  7.  5.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 6. 3. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0] -> size -> 14 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 169.1121368408203



action possibilites: [-1] 
expected returns: [[160.27919]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3.  0. 25. 29.] 
cards in discard: [25.  3.  0.  0. 29.  0. 29. 29. 25. 25. 29. 29.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  0. 10. 10.  7.  5.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 6. 3. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0] -> size -> 14 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 155.34727478027344





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[157.62964]
 [161.52864]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  3.  0. 25. 29.] 
cards in discard: [25.  3.  0.  0. 29.  0. 29. 29. 25. 25. 29. 29.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 28. 30. 28. 30.  8.  0. 10. 10.  7.  5.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 6. 3. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0] -> size -> 14 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 160.27919006347656






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [6. 6. 3. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 3. 3. 8.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  0. 10. 10.  7.  5.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25] -> size -> 22 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3. 3. 8.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0] -> size -> 14 
action values: 1 
buys: 1 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  0. 10. 10.  7.  5.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25] -> size -> 22 
adversary victory points: 3
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  0. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[117.73142]
 [118.57234]
 [118.57234]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 29.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  0. 10. 10.  7.  5.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [6. 6. 3. 3. 8.] 
adversary owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0] -> size -> 14 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 161.5286407470703



action possibilites: [-1.] 
expected returns: [[133.52751]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 28. 30.  8.  0. 10. 10.  7.  5.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [6. 6. 3. 3. 8.] 
adversary owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0] -> size -> 14 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 115.46770477294922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[131.12152]
 [132.63287]
 [131.72435]
 [130.88509]
 [133.66667]
 [132.64426]
 [132.04141]
 [136.09789]
 [135.86143]
 [130.89647]
 [134.03305]
 [131.13292]
 [132.52171]
 [132.40779]
 [135.02052]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 28. 30. 28. 30.  8.  0. 10. 10.  7.  5.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [6. 6. 3. 3. 8.] 
adversary owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0] -> size -> 14 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 133.5275115966797



buy possibilites: [-1] 
expected returns: [[176.63217]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [29. 25.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  0. 10. 10.  7.  4.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [6. 6. 3. 3. 8.] 
adversary owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0] -> size -> 14 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 415 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 136.09788513183594






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [6. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [6. 6. 3. 3. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  0. 10. 10.  7.  4.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25. 29.  3.  0.  3.] 
adversary cards in discard: [29. 25. 29.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25] -> size -> 23 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [6. 6. 3. 3. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 28. 30. 28. 30.  8.  0. 10. 10.  7.  4.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25. 29.  3.  0.  3.] 
adversary cards in discard: [29. 25. 29.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25] -> size -> 23 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [ 6.  6.  3.  3.  8. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  0.  9. 10.  7.  4.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [25. 29.  3.  0.  3.] 
adversary cards in discard: [29. 25. 29.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25] -> size -> 23 
adversary victory points: 3
player victory points: -2 





Player: 0 
cards in hand: [25. 29.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[192.43135]
 [193.50871]
 [193.27226]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29.  3.  0.  3.] 
cards in discard: [29. 25. 29.  0.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  0.  9. 10.  7.  4.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16] -> size -> 15 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 176.63217163085938



action possibilites: [-1] 
expected returns: [[209.92287]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  3. 25.  0.] 
cards in discard: [29. 25. 29.  0.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  0.  9. 10.  7.  4.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16] -> size -> 15 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 192.5461883544922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[208.40068]
 [209.00352]
 [209.32057]
 [212.29968]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0.  3. 25.  0.] 
cards in discard: [29. 25. 29.  0.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 28. 30.  8.  0.  9. 10.  7.  4.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 29.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16] -> size -> 15 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 209.92286682128906






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 29.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  6.  8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  0.  9. 10.  7.  4.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 25. 29. 29. 29.] 
adversary cards in discard: [29. 25. 29.  0.  0.  0.  0. 25. 29.  3.  0.  3. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25] -> size -> 23 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  6.  8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 28. 30. 28. 30.  8.  0.  9. 10.  7.  4.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 25. 29. 29. 29.] 
adversary cards in discard: [29. 25. 29.  0.  0.  0.  0. 25. 29.  3.  0.  3. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25] -> size -> 23 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  6.  8.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 28. 30.  8.  0.  9. 10.  7.  4.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 25. 29. 29. 29.] 
adversary cards in discard: [29. 25. 29.  0.  0.  0.  0. 25. 29.  3.  0.  3. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25] -> size -> 23 
adversary victory points: 3
player victory points: -2 





Player: 0 
cards in hand: [ 3. 25. 29. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 29. 29.] 
expected returns: [[155.795  ]
 [156.87234]
 [156.63591]
 [156.63591]
 [156.63591]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 29. 29. 29.] 
cards in discard: [29. 25. 29.  0.  0.  0.  0. 25. 29.  3.  0.  3. 25.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  0.  9. 10.  7.  4.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 6. 16.  0.  0.  0.] 
adversary cards in discard: [ 0.  3.  0. 29.  6.  8.] 
adversary owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0] -> size -> 16 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 212.29966735839844



action possibilites: [-1] 
expected returns: [[201.02916]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 29. 29. 29. 25.] 
cards in discard: [29. 25. 29.  0.  0.  0.  0. 25. 29.  3.  0.  3. 25.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  0.  9. 10.  7.  4.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 6. 16.  0.  0.  0.] 
adversary cards in discard: [ 0.  3.  0. 29.  6.  8.] 
adversary owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0] -> size -> 16 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 155.55975341796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[197.69597]
 [201.59497]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29. 29. 29. 29. 25.] 
cards in discard: [29. 25. 29.  0.  0.  0.  0. 25. 29.  3.  0.  3. 25.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  0.  9. 10.  7.  4.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 6. 16.  0.  0.  0.] 
adversary cards in discard: [ 0.  3.  0. 29.  6.  8.] 
adversary owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0] -> size -> 16 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 201.02915954589844






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 6. 16.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 16.  0.  0.  0.] 
cards in discard: [ 0.  3.  0. 29.  6.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  0.  9. 10.  7.  4.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 25. 29. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25] -> size -> 23 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 16.  0.  0.  0.] 
cards in discard: [ 0.  3.  0. 29.  6.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 28. 30. 28. 30.  8.  0.  9. 10.  7.  4.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 25. 29. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25] -> size -> 23 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 16.  0.  0.  0.] 
cards in discard: [ 0.  3.  0. 29.  6.  8.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 28. 30.  8.  0.  9. 10.  6.  4.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 25. 29. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25] -> size -> 23 
adversary victory points: 3
player victory points: -2 





Player: 0 
cards in hand: [ 0. 25. 29. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25.] 
expected returns: [[133.31287]
 [134.39023]
 [134.1538 ]
 [134.39023]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 29. 25.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  0.  9. 10.  6.  4.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 0. 3. 8. 6.] 
adversary cards in discard: [ 0.  3.  0. 29.  6.  8.  8.  6. 16.  0.  0.  0.] 
adversary owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0  8] -> size -> 17 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 201.594970703125



action possibilites: [-1] 
expected returns: [[174.91516]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 25.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  0.  9. 10.  6.  4.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 0. 3. 8. 6.] 
adversary cards in discard: [ 0.  3.  0. 29.  6.  8.  8.  6. 16.  0.  0.  0.] 
adversary owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0  8] -> size -> 17 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 134.3938446044922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[173.79054]
 [175.3019 ]
 [174.39339]
 [176.3357 ]
 [175.31328]
 [174.71045]
 [178.53046]
 [173.5655 ]
 [173.80193]
 [175.07683]
 [177.68954]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 25.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 28. 30. 28. 30.  8.  0.  9. 10.  6.  4.  2. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 0. 3. 8. 6.] 
adversary cards in discard: [ 0.  3.  0. 29.  6.  8.  8.  6. 16.  0.  0.  0.] 
adversary owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0  8] -> size -> 17 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 174.9151611328125



buy possibilites: [-1] 
expected returns: [[179.96608]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 25.  0.  0.  0.] 
cards in discard: [29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  0.  9. 10.  6.  4.  1. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 0. 3. 8. 6.] 
adversary cards in discard: [ 0.  3.  0. 29.  6.  8.  8.  6. 16.  0.  0.  0.] 
adversary owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0  8] -> size -> 17 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 293 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 178.5304718017578






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [6. 0. 3. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 8. 6.] 
cards in discard: [ 0.  3.  0. 29.  6.  8.  8.  6. 16.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  0.  9. 10.  6.  4.  1. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 25.  0. 29.  0.] 
adversary cards in discard: [29. 25.  0. 29. 25.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29] -> size -> 24 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 8. 6.] 
cards in discard: [ 0.  3.  0. 29.  6.  8.  8.  6. 16.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 30. 28. 30.  8.  0.  9. 10.  6.  4.  1. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 25.  0. 29.  0.] 
adversary cards in discard: [29. 25.  0. 29. 25.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29] -> size -> 24 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 8. 6.] 
cards in discard: [ 0.  3.  0. 29.  6.  8.  8.  6. 16.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0  8  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 28. 30.  8.  0.  9. 10.  6.  4.  1. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 25.  0. 29.  0.] 
adversary cards in discard: [29. 25.  0. 29. 25.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29] -> size -> 24 
adversary victory points: 3
player victory points: -2 





Player: 0 
cards in hand: [ 3. 25.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[205.7859 ]
 [206.86327]
 [206.62682]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  0. 29.  0.] 
cards in discard: [29. 25.  0. 29. 25.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 28. 30.  8.  0.  9. 10.  6.  4.  1. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0  8  0] -> size -> 18 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 179.96607971191406



action possibilites: [-1] 
expected returns: [[189.82268]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  0. 29. 29.] 
cards in discard: [29. 25.  0. 29. 25.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 28. 30.  8.  0.  9. 10.  6.  4.  1. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0  8  0] -> size -> 18 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 205.28294372558594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[187.67825]
 [188.28107]
 [188.59813]
 [191.57726]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  0. 29. 29.] 
cards in discard: [29. 25.  0. 29. 25.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 28. 30.  8.  0.  9. 10.  6.  4.  1. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0  8  0] -> size -> 18 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 189.8226776123047






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [8. 0. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0  8  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 28. 30.  8.  0.  9. 10.  6.  4.  1. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 25. 29. 29.  3.] 
adversary cards in discard: [29. 25.  0. 29. 25.  0.  0.  0. 25.  3.  0. 29.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29] -> size -> 24 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0  8  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 28. 30. 28. 30.  8.  0.  9. 10.  6.  4.  1. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 25. 29. 29.  3.] 
adversary cards in discard: [29. 25.  0. 29. 25.  0.  0.  0. 25.  3.  0. 29.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29] -> size -> 24 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 6. 0.] 
cards in discard: [11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0  8  0 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 28. 30.  8.  0.  9.  9.  6.  4.  1. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 25. 29. 29.  3.] 
adversary cards in discard: [29. 25.  0. 29. 25.  0.  0.  0. 25.  3.  0. 29.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29] -> size -> 24 
adversary victory points: 3
player victory points: -2 





Player: 0 
cards in hand: [ 3. 25. 29. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 29.] 
expected returns: [[193.13216]
 [194.20952]
 [193.97305]
 [193.97305]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 29. 29.  3.] 
cards in discard: [29. 25.  0. 29. 25.  0.  0.  0. 25.  3.  0. 29.  0. 29. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 28. 30.  8.  0.  9.  9.  6.  4.  1. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  8. 16.  6.  6.] 
adversary cards in discard: [11.  8.  0.  0.  6.  0.] 
adversary owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0  8  0 11] -> size -> 19 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 191.57725524902344



action possibilites: [-1] 
expected returns: [[155.0472]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 29.  3. 25. 29.] 
cards in discard: [29. 25.  0. 29. 25.  0.  0.  0. 25.  3.  0. 29.  0. 29. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 28. 30.  8.  0.  9.  9.  6.  4.  1. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  8. 16.  6.  6.] 
adversary cards in discard: [11.  8.  0.  0.  6.  0.] 
adversary owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0  8  0 11] -> size -> 19 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 193.90602111816406





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[150.95807]
 [154.85707]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29. 29.  3. 25. 29.] 
cards in discard: [29. 25.  0. 29. 25.  0.  0.  0. 25.  3.  0. 29.  0. 29. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 28. 30. 28. 30.  8.  0.  9.  9.  6.  4.  1. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  8. 16.  6.  6.] 
adversary cards in discard: [11.  8.  0.  0.  6.  0.] 
adversary owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0  8  0 11] -> size -> 19 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 155.0471954345703






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 0.  8. 16.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 16.  6.  6.] 
cards in discard: [11.  8.  0.  0.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0  8  0 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 28. 30.  8.  0.  9.  9.  6.  4.  1. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 25. 25. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29] -> size -> 24 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 16.  6.  6.] 
cards in discard: [11.  8.  0.  0.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0  8  0 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 28. 30. 28. 30.  8.  0.  9.  9.  6.  4.  1. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 25. 25. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29] -> size -> 24 
adversary victory points: 3
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3. 25. 25. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 25.] 
expected returns: [[147.39818]
 [148.47554]
 [148.47554]
 [148.47554]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 25. 25.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 28. 30.  8.  0.  9.  9.  6.  4.  1. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [11.  8.  0.  0.  6.  0.  0.  8. 16.  6.  6.] 
adversary owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0  8  0 11] -> size -> 19 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 154.85707092285156



action possibilites: [-1] 
expected returns: [[158.82254]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 25.  0.  3. 29.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 28. 30.  8.  0.  9.  9.  6.  4.  1. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [11.  8.  0.  0.  6.  0.  0.  8. 16.  6.  6.] 
adversary owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0  8  0 11] -> size -> 19 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 148.06590270996094





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[156.91585]
 [160.81487]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25. 25.  0.  3. 29.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 28. 30. 28. 30.  8.  0.  9.  9.  6.  4.  1. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [11.  8.  0.  0.  6.  0.  0.  8. 16.  6.  6.] 
adversary owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0  8  0 11] -> size -> 19 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 158.82254028320312






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [0. 8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0. 0.] 
cards in discard: [11.  8.  0.  0.  6.  0.  0.  8. 16.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0  8  0 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 28. 30.  8.  0.  9.  9.  6.  4.  1. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 25.  0. 29. 29.] 
adversary cards in discard: [25.  3. 25. 25.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29] -> size -> 24 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 0. 0.] 
cards in discard: [11.  8.  0.  0.  6.  0.  0.  8. 16.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0  8  0 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 28. 30. 28. 30.  8.  0.  9.  9.  6.  4.  1. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 25.  0. 29. 29.] 
adversary cards in discard: [25.  3. 25. 25.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29] -> size -> 24 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 0. 0.] 
cards in discard: [11.  8.  0.  0.  6.  0.  0.  8. 16.  6.  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0  8  0 11  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 27. 30.  8.  0.  9.  9.  6.  4.  1. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 25.  0. 29. 29.] 
adversary cards in discard: [25.  3. 25. 25.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29] -> size -> 24 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [ 3. 25.  0. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 29.] 
expected returns: [[202.50291]
 [203.58028]
 [203.34383]
 [203.34383]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  0. 29. 29.] 
cards in discard: [25.  3. 25. 25.  0.  3. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  0.  9.  9.  6.  4.  1. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  3. 29.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0  8  0 11  3] -> size -> 20 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 160.8148651123047



action possibilites: [-1] 
expected returns: [[183.61043]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29. 29. 29.  0.] 
cards in discard: [25.  3. 25. 25.  0.  3. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  0.  9.  9.  6.  4.  1. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  3. 29.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0  8  0 11  3] -> size -> 20 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 202.03114318847656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[181.42497]
 [182.02782]
 [182.3449 ]
 [185.32399]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29. 29. 29.  0.] 
cards in discard: [25.  3. 25. 25.  0.  3. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 27. 30.  8.  0.  9.  9.  6.  4.  1. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 11.  3. 29.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0  8  0 11  3] -> size -> 20 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 183.6104278564453






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  3. 29.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3. 29.  6.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0  8  0 11  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  0.  9.  9.  6.  4.  1. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 25. 25. 29. 29.] 
adversary cards in discard: [25.  3. 25. 25.  0.  3. 29. 25.  3.  0. 29. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29] -> size -> 24 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  6.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0  8  0 11  3 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  0.  9.  9.  6.  4.  1. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 25. 25. 29. 29.] 
adversary cards in discard: [25.  3. 25. 25.  0.  3. 29. 25.  3.  0. 29. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29] -> size -> 24 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 29.  6.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0  8  0 11  3 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 28. 30. 27. 30.  8.  0.  9.  9.  6.  4.  1. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 25. 25. 29. 29.] 
adversary cards in discard: [25.  3. 25. 25.  0.  3. 29. 25.  3.  0. 29. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29] -> size -> 24 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [ 0. 25. 25. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 29. 29.] 
expected returns: [[149.20062]
 [150.27798]
 [150.27798]
 [150.04152]
 [150.04152]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 25. 29. 29.] 
cards in discard: [25.  3. 25. 25.  0.  3. 29. 25.  3.  0. 29. 29. 29.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  0.  9.  9.  6.  4.  1. 10. 10.  9. 10. 10.] 
adversary cards in hand: [6. 0. 8. 0. 0.] 
adversary cards in discard: [10. 11.  0.  3. 29.  6.] 
adversary owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0  8  0 11  3 10] -> size -> 21 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 185.32398986816406



action possibilites: [-1] 
expected returns: [[127.18126]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 29. 29. 29.  0.] 
cards in discard: [25.  3. 25. 25.  0.  3. 29. 25.  3.  0. 29. 29. 29.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  0.  9.  9.  6.  4.  1. 10. 10.  9. 10. 10.] 
adversary cards in hand: [6. 0. 8. 0. 0.] 
adversary cards in discard: [10. 11.  0.  3. 29.  6.] 
adversary owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0  8  0 11  3 10] -> size -> 21 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 150.27796936035156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[123.20927 ]
 [123.812096]
 [124.12916 ]
 [127.10828 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25. 29. 29. 29.  0.] 
cards in discard: [25.  3. 25. 25.  0.  3. 29. 25.  3.  0. 29. 29. 29.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 27. 30.  8.  0.  9.  9.  6.  4.  1. 10. 10.  9. 10. 10.] 
adversary cards in hand: [6. 0. 8. 0. 0.] 
adversary cards in discard: [10. 11.  0.  3. 29.  6.] 
adversary owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0  8  0 11  3 10] -> size -> 21 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 127.18125915527344






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [6. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 0. 0.] 
cards in discard: [10. 11.  0.  3. 29.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0  8  0 11  3 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  0.  9.  9.  6.  4.  1. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 29. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29] -> size -> 24 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 0. 0.] 
cards in discard: [10. 11.  0.  3. 29.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0  8  0 11  3 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 28. 30. 27. 30.  8.  0.  9.  9.  6.  4.  1. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 29. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29] -> size -> 24 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 0. 0.] 
cards in discard: [10. 11.  0.  3. 29.  6. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0  8  0 11  3 10 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  0.  9.  8.  6.  4.  1. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 29. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29] -> size -> 24 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [ 3. 29. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[149.84673]
 [150.68767]
 [150.68767]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  0.  9.  8.  6.  4.  1. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 16.  0.  0.  6.] 
adversary cards in discard: [10. 11.  0.  3. 29.  6. 11.  6.  0.  8.  0.  0.] 
adversary owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0  8  0 11  3 10 11] -> size -> 22 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 127.10826873779297



action possibilites: [-1. 25.] 
expected returns: [[154.31291]
 [155.39026]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 25.] 
cards in discard: [29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 27. 30.  8.  0.  9.  8.  6.  4.  1. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 16.  0.  0.  6.] 
adversary cards in discard: [10. 11.  0.  3. 29.  6. 11.  6.  0.  8.  0.  0.] 
adversary owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0  8  0 11  3 10 11] -> size -> 22 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 145.82437133789062



action possibilites: [-1] 
expected returns: [[199.55386]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 25.] 
cards in discard: [29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 27. 30.  8.  0.  9.  8.  6.  4.  1. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 16.  0.  0.  6.] 
adversary cards in discard: [10. 11.  0.  3. 29.  6. 11.  6.  0.  8.  0.  0.] 
adversary owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0  8  0 11  3 10 11] -> size -> 22 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 155.3902587890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[198.56009]
 [200.07141]
 [199.16292]
 [201.10526]
 [200.08281]
 [199.47998]
 [203.3    ]
 [198.33502]
 [198.57149]
 [199.84637]
 [202.45912]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 25.] 
cards in discard: [29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 28. 30. 27. 30.  8.  0.  9.  8.  6.  4.  1. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 16.  0.  0.  6.] 
adversary cards in discard: [10. 11.  0.  3. 29.  6. 11.  6.  0.  8.  0.  0.] 
adversary owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0  8  0 11  3 10 11] -> size -> 22 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: 199.55386352539062



buy possibilites: [-1] 
expected returns: [[202.76811]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 25.] 
cards in discard: [29. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  0.  9.  8.  6.  4.  0. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 16.  0.  0.  6.] 
adversary cards in discard: [10. 11.  0.  3. 29.  6. 11.  6.  0.  8.  0.  0.] 
adversary owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0  8  0 11  3 10 11] -> size -> 22 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 283 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 203.3000030517578






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 3. 16.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  0.  0.  6.] 
cards in discard: [10. 11.  0.  3. 29.  6. 11.  6.  0.  8.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  0  3  6  3  6  6  6  0 29  0 16  0  8  0 11  3 10 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  0.  9.  8.  6.  4.  0. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  0. 25. 25.] 
adversary cards in discard: [29. 29. 29. 25.  3.  0.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6.] 
cards in discard: [10. 11.  0.  3. 29.  6. 11.  6.  0.  8.  0.  0. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8  0  8  0  0  6  3  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  0.  9.  8.  6.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  0. 25. 25.] 
adversary cards in discard: [29. 29. 29. 25.  3.  0.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [10. 11.  0.  3. 29.  6. 11.  6.  0.  8.  0.  0. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8  0  8  0  0  6  3  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 27. 30.  8.  0.  9.  8.  6.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  0. 25. 25.] 
adversary cards in discard: [29. 29. 29. 25.  3.  0.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [10. 11.  0.  3. 29.  6. 11.  6.  0.  8.  0.  0. 14.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8  0  8  0  0  6  3  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  0.  9.  8.  6.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  0. 25. 25.] 
adversary cards in discard: [29. 29. 29. 25.  3.  0.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [29.  3.  0. 25. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 25.] 
expected returns: [[188.86647]
 [189.7074 ]
 [189.94385]
 [189.94385]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0. 25. 25.] 
cards in discard: [29. 29. 29. 25.  3.  0.  0.  0. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  0.  9.  8.  6.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [8. 8. 6. 0. 3.] 
adversary cards in discard: [10. 11.  0.  3. 29.  6. 11.  6.  0.  8.  0.  0. 14.  3. 16.  0.  0.  6.] 
adversary owned cards: [ 8  0  8  0  0  6  3  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3] -> size -> 23 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 202.7681121826172



action possibilites: [-1] 
expected returns: [[193.88321]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0. 25. 29.  0.] 
cards in discard: [29. 29. 29. 25.  3.  0.  0.  0. 25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  0.  9.  8.  6.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [8. 8. 6. 0. 3.] 
adversary cards in discard: [10. 11.  0.  3. 29.  6. 11.  6.  0.  8.  0.  0. 14.  3. 16.  0.  0.  6.] 
adversary owned cards: [ 8  0  8  0  0  6  3  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3] -> size -> 23 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 189.3866424560547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[191.10132]
 [191.70415]
 [192.0212 ]
 [195.00032]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0. 25. 29.  0.] 
cards in discard: [29. 29. 29. 25.  3.  0.  0.  0. 25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 26. 30.  8.  0.  9.  8.  6.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [8. 8. 6. 0. 3.] 
adversary cards in discard: [10. 11.  0.  3. 29.  6. 11.  6.  0.  8.  0.  0. 14.  3. 16.  0.  0.  6.] 
adversary owned cards: [ 8  0  8  0  0  6  3  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3] -> size -> 23 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 193.88320922851562






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [8. 8. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 6. 0. 3.] 
cards in discard: [10. 11.  0.  3. 29.  6. 11.  6.  0.  8.  0.  0. 14.  3. 16.  0.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  8  0  0  6  3  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  0.  9.  8.  6.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0. 25. 29.  3.] 
adversary cards in discard: [29. 29. 29. 25.  3.  0.  0.  0. 25. 25. 29.  3.  0. 25. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [10. 11.  0.  3. 29.  6. 11.  6.  0.  8.  0.  0. 14.  3. 16.  0.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  0  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  0.  9.  8.  6.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0. 25. 29.  3.] 
adversary cards in discard: [29. 29. 29. 25.  3.  0.  0.  0. 25. 25. 29.  3.  0. 25. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [10. 11.  0.  3. 29.  6. 11.  6.  0.  8.  0.  0. 14.  3. 16.  0.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  0  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  0.  9.  8.  6.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0. 25. 29.  3.] 
adversary cards in discard: [29. 29. 29. 25.  3.  0.  0.  0. 25. 25. 29.  3.  0. 25. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [29.  0. 25. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29.] 
expected returns: [[172.82912]
 [173.67003]
 [173.90646]
 [173.67003]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 25. 29.  3.] 
cards in discard: [29. 29. 29. 25.  3.  0.  0.  0. 25. 25. 29.  3.  0. 25. 29.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  0.  9.  8.  6.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [6. 6. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3] -> size -> 20 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 195.00030517578125



action possibilites: [-1] 
expected returns: [[169.23697]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29.  3. 29.  0.] 
cards in discard: [29. 29. 29. 25.  3.  0.  0.  0. 25. 25. 29.  3.  0. 25. 29.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  0.  9.  8.  6.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [6. 6. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3] -> size -> 20 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 173.9064483642578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[165.70332]
 [166.30617]
 [166.62321]
 [169.60234]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 29.  3. 29.  0.] 
cards in discard: [29. 29. 29. 25.  3.  0.  0.  0. 25. 25. 29.  3.  0. 25. 29.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 26. 30.  8.  0.  9.  8.  6.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [6. 6. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3] -> size -> 20 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 169.23696899414062






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [6. 6. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  0.  9.  8.  6.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29. 25. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 26. 30.  8.  0.  9.  8.  6.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29. 25. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 0. 3.] 
cards in discard: [8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  0.  9.  8.  5.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29. 25. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [ 0. 29. 25. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29. 25.] 
expected returns: [[153.31339]
 [154.1543 ]
 [154.39075]
 [154.1543 ]
 [154.39075]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 25. 29. 25.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  0.  9.  8.  5.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 6.  0. 16.  8.  0.] 
adversary cards in discard: [8. 6. 6. 0. 0. 3.] 
adversary owned cards: [ 8  8  0  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8] -> size -> 21 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 169.60232543945312



action possibilites: [-1] 
expected returns: [[172.43767]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29. 25. 25.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  0.  9.  8.  5.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 6.  0. 16.  8.  0.] 
adversary cards in discard: [8. 6. 6. 0. 0. 3.] 
adversary owned cards: [ 8  8  0  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8] -> size -> 21 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 153.27378845214844





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[170.97191]
 [174.8709 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 29. 25. 25.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 28. 30. 26. 30.  8.  0.  9.  8.  5.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 6.  0. 16.  8.  0.] 
adversary cards in discard: [8. 6. 6. 0. 0. 3.] 
adversary owned cards: [ 8  8  0  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8] -> size -> 21 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 172.4376678466797






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [ 6.  0. 16.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 16.  8.  0.] 
cards in discard: [8. 6. 6. 0. 0. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  0.  9.  8.  5.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29. 29. 29. 29. 25.] 
adversary cards in discard: [25.  0. 29. 29. 25. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 16.  8.  0.] 
cards in discard: [8. 6. 6. 0. 0. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 26. 30.  8.  0.  9.  8.  5.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29. 29. 29. 29. 25.] 
adversary cards in discard: [25.  0. 29. 29. 25. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 16.  8.  0.] 
cards in discard: [8. 6. 6. 0. 0. 3. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 25. 30.  8.  0.  9.  8.  5.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29. 29. 29. 29. 25.] 
adversary cards in discard: [25.  0. 29. 29. 25. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [29. 29. 29. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29. 29. 25.] 
expected returns: [[179.17169]
 [180.01262]
 [180.01262]
 [180.01262]
 [180.01262]
 [180.24904]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29. 29. 25.] 
cards in discard: [25.  0. 29. 29. 25. 25.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 25. 30.  8.  0.  9.  8.  5.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3. 11.  8. 14.] 
adversary cards in discard: [ 8.  6.  6.  0.  0.  3.  3.  6.  0. 16.  8.  0.] 
adversary owned cards: [ 8  8  0  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8  3] -> size -> 22 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 174.87091064453125



action possibilites: [-1] 
expected returns: [[169.77583]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29. 29. 29.  3.] 
cards in discard: [25.  0. 29. 29. 25. 25.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 25. 30.  8.  0.  9.  8.  5.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3. 11.  8. 14.] 
adversary cards in discard: [ 8.  6.  6.  0.  0.  3.  3.  6.  0. 16.  8.  0.] 
adversary owned cards: [ 8  8  0  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8  3] -> size -> 22 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 178.98313903808594





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[166.19263]
 [170.09161]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29. 29. 29. 29.  3.] 
cards in discard: [25.  0. 29. 29. 25. 25.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 28. 30. 25. 30.  8.  0.  9.  8.  5.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3. 11.  8. 14.] 
adversary cards in discard: [ 8.  6.  6.  0.  0.  3.  3.  6.  0. 16.  8.  0.] 
adversary owned cards: [ 8  8  0  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8  3] -> size -> 22 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 169.7758331298828






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [29.  3. 11.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.  8. 14.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 11.  8. 14.] 
cards in discard: [ 8.  6.  6.  0.  0.  3.  3.  6.  0. 16.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 25. 30.  8.  0.  9.  8.  5.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0.  0. 25.  0.] 
adversary cards in discard: [25.  0. 29. 29. 25. 25.  3. 25. 29. 29. 29. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 14.] 
cards in discard: [ 8.  6.  6.  0.  0.  3.  3.  6.  0. 16.  8.  0. 11. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  8  0  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 25. 30.  8.  0.  9.  8.  5.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0.  0. 25.  0.] 
adversary cards in discard: [25.  0. 29. 29. 25. 25.  3. 25. 29. 29. 29. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8.] 
cards in discard: [ 8.  6.  6.  0.  0.  3.  3.  6.  0. 16.  8.  0. 11. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 8  8  0  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 28. 30. 25. 30.  8.  0.  9.  8.  5.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29. 25.  0.] 
adversary cards in discard: [25.  0. 29. 29. 25. 25.  3. 25. 29. 29. 29. 29. 29.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8.] 
cards in discard: [ 8.  6.  6.  0.  0.  3.  3.  6.  0. 16.  8.  0. 11. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 8  8  0  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 28. 30. 25. 30.  8.  0.  9.  8.  5.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29. 25.  0.] 
adversary cards in discard: [25.  0. 29. 29. 25. 25.  3. 25. 29. 29. 29. 29. 29.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8.] 
cards in discard: [ 8.  6.  6.  0.  0.  3.  3.  6.  0. 16.  8.  0. 11. 11.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 8  8  0  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8  3  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 25. 30.  8.  0.  9.  8.  5.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29. 25.  0.] 
adversary cards in discard: [25.  0. 29. 29. 25. 25.  3. 25. 29. 29. 29. 29. 29.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [29. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[154.5284 ]
 [155.36931]
 [155.60576]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  0.] 
cards in discard: [25.  0. 29. 29. 25. 25.  3. 25. 29. 29. 29. 29. 29.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 25. 30.  8.  0.  9.  8.  5.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  8. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8  3  1] -> size -> 23 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[  -5    0    0   90    0    0    0    0    0    0    0    0    0    0
 1262    0] 
sum of rewards: 1347 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 1.6772018671035767



action possibilites: [-1] 
expected returns: [[125.684364]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29. 25.] 
cards in discard: [25.  0. 29. 29. 25. 25.  3. 25. 29. 29. 29. 29. 29.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 25. 30.  8.  0.  9.  8.  5.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  8. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8  3  1] -> size -> 23 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 155.6057586669922





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[121.61472 ]
 [125.513725]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 29. 25.] 
cards in discard: [25.  0. 29. 29. 25. 25.  3. 25. 29. 29. 29. 29. 29.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 27. 30. 25. 30.  8.  0.  9.  8.  5.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 1.  8. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8  3  1] -> size -> 23 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 125.68436431884766






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [ 1.  8. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8  3  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 25. 30.  8.  0.  9.  8.  5.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [25.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8  3  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 27. 30. 25. 30.  8.  0.  9.  8.  5.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [25.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8. 10.  0.  0.] 
cards in discard: [1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8  3  1  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 26. 30. 25. 30.  8.  0.  9.  8.  5.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [25.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [25.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[166.39572]
 [167.47307]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 30.  8.  0.  9.  8.  5.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [16.  6.  0.  3.  0.] 
adversary cards in discard: [ 1.  1.  8. 10.  0.  0.] 
adversary owned cards: [ 8  8  0  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8  3  1  1] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 125.51372528076172



action possibilites: [-1] 
expected returns: [[180.54976]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 30.  8.  0.  9.  8.  5.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [16.  6.  0.  3.  0.] 
adversary cards in discard: [ 1.  1.  8. 10.  0.  0.] 
adversary owned cards: [ 8  8  0  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8  3  1  1] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 165.8908233642578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[179.70764]
 [181.21896]
 [180.31049]
 [182.25279]
 [181.23035]
 [180.62752]
 [179.48259]
 [179.71901]
 [180.99391]
 [183.60667]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 26. 30. 25. 30.  8.  0.  9.  8.  5.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [16.  6.  0.  3.  0.] 
adversary cards in discard: [ 1.  1.  8. 10.  0.  0.] 
adversary owned cards: [ 8  8  0  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8  3  1  1] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 180.5497589111328






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [16.  6.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6.  0.  3.  0.] 
cards in discard: [ 1.  1.  8. 10.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8  3  1  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 30.  8.  0.  9.  8.  5.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [25. 25. 29. 29.  0.] 
adversary cards in discard: [25.  3.  0.  0.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6.  0.  3.  0.] 
cards in discard: [ 1.  1.  8. 10.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8  3  1  1] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 26. 30. 25. 30.  8.  0.  9.  8.  5.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [25. 25. 29. 29.  0.] 
adversary cards in discard: [25.  3.  0.  0.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6.  0.  3.  0.] 
cards in discard: [ 1.  1.  8. 10.  0.  0.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8  3  1  1
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 30.  8.  0.  9.  8.  4.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [25. 25. 29. 29.  0.] 
adversary cards in discard: [25.  3.  0.  0.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [25. 25. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 29. 29.] 
expected returns: [[187.97334]
 [189.05069]
 [189.05069]
 [188.81424]
 [188.81424]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25. 29. 29.  0.] 
cards in discard: [25.  3.  0.  0.  0.  0. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 30.  8.  0.  9.  8.  4.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 8. 14.  6.  8.  8.] 
adversary cards in discard: [ 1.  1.  8. 10.  0.  0.  8. 16.  6.  0.  3.  0.] 
adversary owned cards: [ 8  8  0  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8  3  1  1
  8] -> size -> 25 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 183.6066436767578



action possibilites: [-1] 
expected returns: [[160.1614]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 29.  0. 25. 29.] 
cards in discard: [25.  3.  0.  0.  0.  0. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 30.  8.  0.  9.  8.  4.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 8. 14.  6.  8.  8.] 
adversary cards in discard: [ 1.  1.  8. 10.  0.  0.  8. 16.  6.  0.  3.  0.] 
adversary owned cards: [ 8  8  0  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8  3  1  1
  8] -> size -> 25 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 188.4934844970703





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[156.89793]
 [160.79695]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 29. 29.  0. 25. 29.] 
cards in discard: [25.  3.  0.  0.  0.  0. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 25. 30.  8.  0.  9.  8.  4.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 8. 14.  6.  8.  8.] 
adversary cards in discard: [ 1.  1.  8. 10.  0.  0.  8. 16.  6.  0.  3.  0.] 
adversary owned cards: [ 8  8  0  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8  3  1  1
  8] -> size -> 25 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 160.16140747070312






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [ 8. 14.  6.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  6.  8.  8.] 
cards in discard: [ 1.  1.  8. 10.  0.  0.  8. 16.  6.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8  3  1  1
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 30.  8.  0.  9.  8.  4.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29. 29. 29. 29. 25.] 
adversary cards in discard: [25.  3.  0.  0.  0.  0. 29. 25. 25. 29. 29.  0. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 14.  6.  8.  8.] 
cards in discard: [ 1.  1.  8. 10.  0.  0.  8. 16.  6.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8  3  1  1
  8] -> size -> 25 
action values: 1 
buys: 1 
player value: 0 
card supply: [22. 26. 30. 25. 30.  8.  0.  9.  8.  4.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29. 29. 29. 29. 25.] 
adversary cards in discard: [25.  3.  0.  0.  0.  0. 29. 25. 25. 29. 29.  0. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29. 29. 29. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29. 29. 25.] 
expected returns: [[145.36708]
 [146.208  ]
 [146.208  ]
 [146.208  ]
 [146.208  ]
 [146.44444]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29. 29. 25.] 
cards in discard: [25.  3.  0.  0.  0.  0. 29. 25. 25. 29. 29.  0. 25. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 30.  8.  0.  9.  8.  4.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [11.  3. 11.  6.  0.] 
adversary cards in discard: [ 1.  1.  8. 10.  0.  0.  8. 16.  6.  0.  3.  0.  8. 14.  6.  8.  8.] 
adversary owned cards: [ 8  8  0  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8  3  1  1
  8] -> size -> 25 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 160.7969512939453



action possibilites: [-1] 
expected returns: [[139.3825]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29. 29. 25. 29.] 
cards in discard: [25.  3.  0.  0.  0.  0. 29. 25. 25. 29. 29.  0. 25. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 30.  8.  0.  9.  8.  4.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [11.  3. 11.  6.  0.] 
adversary cards in discard: [ 1.  1.  8. 10.  0.  0.  8. 16.  6.  0.  3.  0.  8. 14.  6.  8.  8.] 
adversary owned cards: [ 8  8  0  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8  3  1  1
  8] -> size -> 25 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 146.44444274902344





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[135.29338]
 [139.1924 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29. 29. 29. 25. 29.] 
cards in discard: [25.  3.  0.  0.  0.  0. 29. 25. 25. 29. 29.  0. 25. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 26. 30. 25. 30.  8.  0.  9.  8.  4.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [11.  3. 11.  6.  0.] 
adversary cards in discard: [ 1.  1.  8. 10.  0.  0.  8. 16.  6.  0.  3.  0.  8. 14.  6.  8.  8.] 
adversary owned cards: [ 8  8  0  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8  3  1  1
  8] -> size -> 25 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 139.38250732421875






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [11.  3. 11.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 11.  6.  0.] 
cards in discard: [ 1.  1.  8. 10.  0.  0.  8. 16.  6.  0.  3.  0.  8. 14.  6.  8.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8  3  1  1
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 30.  8.  0.  9.  8.  4.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 11.  6.  0.] 
cards in discard: [ 1.  1.  8. 10.  0.  0.  8. 16.  6.  0.  3.  0.  8. 14.  6.  8.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8  3  1  1
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 25. 30.  8.  0.  9.  8.  4.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[167.70616]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 30.  8.  0.  9.  8.  4.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  8.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8  3  1  1
  8] -> size -> 25 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 139.19239807128906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[165.04791]
 [166.55925]
 [165.65074]
 [166.57063]
 [165.96777]
 [165.05928]
 [168.94691]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 26. 30. 25. 30.  8.  0.  9.  8.  4.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  8.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8  3  1  1
  8] -> size -> 25 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 166.1258087158203



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  3.  0. 29.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8  3  1  1
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 30.  8.  0.  9.  8.  4.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29. 25.  3.  0. 29.] 
adversary cards in discard: [0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8  3  1  1  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 30.  8.  0.  9.  8.  4.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29. 25.  3.  0. 29.] 
adversary cards in discard: [0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8  3  1  1  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 25. 30.  8.  0.  9.  8.  4.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29. 25.  3.  0. 29.] 
adversary cards in discard: [0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.] 
cards in discard: [0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8  3  1  1  8
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 25. 30.  8.  0.  9.  8.  4.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29. 25.  3.  0. 29.] 
adversary cards in discard: [0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [29. 25.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29.] 
expected returns: [[199.18573]
 [200.02666]
 [200.26309]
 [200.02666]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  3.  0. 29.] 
cards in discard: [0. 3. 3. 0. 0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 25. 30.  8.  0.  9.  8.  4.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  8.  1.  8. 11.] 
adversary cards in discard: [ 0.  8.  3.  0. 29.] 
adversary owned cards: [ 8  8  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8  3  1  1  8
  0] -> size -> 25 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 168.9468994140625



action possibilites: [-1] 
expected returns: [[222.90373]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0. 29.  0. 25.] 
cards in discard: [0. 3. 3. 0. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 25. 30.  8.  0.  9.  8.  4.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  8.  1.  8. 11.] 
adversary cards in discard: [ 0.  8.  3.  0. 29.] 
adversary owned cards: [ 8  8  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8  3  1  1  8
  0] -> size -> 25 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 199.29295349121094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[220.01335]
 [220.61617]
 [220.93323]
 [223.91234]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0. 29.  0. 25.] 
cards in discard: [0. 3. 3. 0. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 26. 30. 25. 30.  8.  0.  9.  8.  4.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  8.  1.  8. 11.] 
adversary cards in discard: [ 0.  8.  3.  0. 29.] 
adversary owned cards: [ 8  8  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8  3  1  1  8
  0] -> size -> 25 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 222.9037322998047






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  1.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  1.  8. 11.] 
cards in discard: [ 0.  8.  3.  0. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8  3  1  1  8
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 25. 30.  8.  0.  9.  8.  4.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29. 25. 29.  0. 25.] 
adversary cards in discard: [ 0.  3.  3.  0.  0. 25. 29.  3.  0. 29.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  1.  8. 11.] 
cards in discard: [ 0.  8.  3.  0. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8  3  1  1  8
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 26. 30. 25. 30.  8.  0.  9.  8.  4.  4.  0.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29. 25. 29.  0. 25.] 
adversary cards in discard: [ 0.  3.  3.  0.  0. 25. 29.  3.  0. 29.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  1.  8. 11.] 
cards in discard: [ 0.  8.  3.  0. 29. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8  3  1  1  8
  0 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 25. 30.  8.  0.  9.  8.  4.  4.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29. 25. 29.  0. 25.] 
adversary cards in discard: [ 0.  3.  3.  0.  0. 25. 29.  3.  0. 29.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [29. 25. 29.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29. 25.] 
expected returns: [[187.08046]
 [187.92134]
 [188.1578 ]
 [187.92134]
 [188.1578 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 29.  0. 25.] 
cards in discard: [ 0.  3.  3.  0.  0. 25. 29.  3.  0. 29.  0. 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 25. 30.  8.  0.  9.  8.  4.  4.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  8.  3.  1. 10.] 
adversary cards in discard: [ 0.  8.  3.  0. 29. 10.  0.  8.  1.  8. 11.] 
adversary owned cards: [ 8  8  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8  3  1  1  8
  0 10] -> size -> 26 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 223.91233825683594



action possibilites: [-1] 
expected returns: [[141.08727]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0. 25. 25. 29.] 
cards in discard: [ 0.  3.  3.  0.  0. 25. 29.  3.  0. 29.  0. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 25. 30.  8.  0.  9.  8.  4.  4.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  8.  3.  1. 10.] 
adversary cards in discard: [ 0.  8.  3.  0. 29. 10.  0.  8.  1.  8. 11.] 
adversary owned cards: [ 8  8  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8  3  1  1  8
  0 10] -> size -> 26 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 188.15782165527344





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[137.83012]
 [141.72914]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29.  0. 25. 25. 29.] 
cards in discard: [ 0.  3.  3.  0.  0. 25. 29.  3.  0. 29.  0. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 26. 30. 25. 30.  8.  0.  9.  8.  4.  4.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  8.  3.  1. 10.] 
adversary cards in discard: [ 0.  8.  3.  0. 29. 10.  0.  8.  1.  8. 11.] 
adversary owned cards: [ 8  8  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8  3  1  1  8
  0 10] -> size -> 26 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 141.08726501464844






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [ 3.  8.  3.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  3.  1. 10.] 
cards in discard: [ 0.  8.  3.  0. 29. 10.  0.  8.  1.  8. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  6  6  6  0 29  0 16  0  8  0 11  3 10 11 14  3  8  3  1  1  8
  0 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 25. 30.  8.  0.  9.  8.  4.  4.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 25. 29. 29.] 
adversary cards in discard: [ 0.  3.  3.  0.  0. 25. 29.  3.  0. 29.  0. 25. 25. 29. 29.  0. 25. 25.
 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 0.  8.  3.  0. 29. 10.  0.  8.  1.  8. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  0  6  6  6  0 29  0 16  0  8  0 11 11 14  3  8  3  1  8  0 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 25. 30.  8.  0.  9.  8.  4.  4.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 25. 29. 29.] 
adversary cards in discard: [ 0.  3.  3.  0.  0. 25. 29.  3.  0. 29.  0. 25. 25. 29. 29.  0. 25. 25.
 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 0.  8.  3.  0. 29. 10.  0.  8.  1.  8. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  0  6  6  6  0 29  0 16  0  8  0 11 11 14  3  8  3  1  8  0 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 26. 30. 25. 30.  8.  0.  9.  8.  4.  4.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 25. 29. 29.] 
adversary cards in discard: [ 0.  3.  3.  0.  0. 25. 29.  3.  0. 29.  0. 25. 25. 29. 29.  0. 25. 25.
 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [ 0. 29. 25. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29. 29.] 
expected returns: [[136.53137]
 [137.37228]
 [137.60873]
 [137.37228]
 [137.37228]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 25. 29. 29.] 
cards in discard: [ 0.  3.  3.  0.  0. 25. 29.  3.  0. 29.  0. 25. 25. 29. 29.  0. 25. 25.
 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 25. 30.  8.  0.  9.  8.  4.  4.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  6.  0. 14.  6.] 
adversary cards in discard: [ 0.  8.  3.  0. 29. 10.  0.  8.  1.  8. 11.  8.  3.] 
adversary owned cards: [ 8  8  0  6  6  6  0 29  0 16  0  8  0 11 11 14  3  8  3  1  8  0 10] -> size -> 23 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 141.7291259765625



action possibilites: [-1] 
expected returns: [[158.91214]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29. 29.  0. 29.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 25. 30.  8.  0.  9.  8.  4.  4.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  6.  0. 14.  6.] 
adversary cards in discard: [ 0.  8.  3.  0. 29. 10.  0.  8.  1.  8. 11.  8.  3.] 
adversary owned cards: [ 8  8  0  6  6  6  0 29  0 16  0  8  0 11 11 14  3  8  3  1  8  0 10] -> size -> 23 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 137.60874938964844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[157.49144]
 [158.09427]
 [158.41133]
 [161.39044]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 29. 29.  0. 29.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 26. 30. 25. 30.  8.  0.  9.  8.  4.  4.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11.  6.  0. 14.  6.] 
adversary cards in discard: [ 0.  8.  3.  0. 29. 10.  0.  8.  1.  8. 11.  8.  3.] 
adversary owned cards: [ 8  8  0  6  6  6  0 29  0 16  0  8  0 11 11 14  3  8  3  1  8  0 10] -> size -> 23 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 158.91213989257812






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [11.  6.  0. 14.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0. 14.  6.] 
cards in discard: [ 0.  8.  3.  0. 29. 10.  0.  8.  1.  8. 11.  8.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  6  6  6  0 29  0 16  0  8  0 11 11 14  3  8  3  1  8  0 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 25. 30.  8.  0.  9.  8.  4.  4.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [25. 29. 25.  3. 29.] 
adversary cards in discard: [25.  0. 29. 29. 29.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  0. 14.  6.] 
cards in discard: [ 0.  8.  3.  0. 29. 10.  0.  8.  1.  8. 11.  8.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  6  6  6  0 29  0 16  0  8  0 11 11 14  3  8  3  1  8  0 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 26. 30. 25. 30.  8.  0.  9.  8.  4.  4.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [25. 29. 25.  3. 29.] 
adversary cards in discard: [25.  0. 29. 29. 29.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [25. 29. 25.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25. 29.] 
expected returns: [[194.74269]
 [195.82004]
 [195.58357]
 [195.82004]
 [195.58357]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 25.  3. 29.] 
cards in discard: [25.  0. 29. 29. 29.  0. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 25. 30.  8.  0.  9.  8.  4.  4.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 6. 16.  0.  8.  0.] 
adversary cards in discard: [ 0.  8.  3.  0. 29. 10.  0.  8.  1.  8. 11.  8.  3. 11.  6.  0. 14.  6.] 
adversary owned cards: [ 8  8  0  6  6  6  0 29  0 16  0  8  0 11 11 14  3  8  3  1  8  0 10] -> size -> 23 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 161.39044189453125



action possibilites: [-1] 
expected returns: [[174.65274]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  3. 29. 25.  0.] 
cards in discard: [25.  0. 29. 29. 29.  0. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 25. 30.  8.  0.  9.  8.  4.  4.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 6. 16.  0.  8.  0.] 
adversary cards in discard: [ 0.  8.  3.  0. 29. 10.  0.  8.  1.  8. 11.  8.  3. 11.  6.  0. 14.  6.] 
adversary owned cards: [ 8  8  0  6  6  6  0 29  0 16  0  8  0 11 11 14  3  8  3  1  8  0 10] -> size -> 23 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 194.84986877441406





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[171.38402]
 [175.28302]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 25.  3. 29. 25.  0.] 
cards in discard: [25.  0. 29. 29. 29.  0. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 26. 30. 25. 30.  8.  0.  9.  8.  4.  4.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 6. 16.  0.  8.  0.] 
adversary cards in discard: [ 0.  8.  3.  0. 29. 10.  0.  8.  1.  8. 11.  8.  3. 11.  6.  0. 14.  6.] 
adversary owned cards: [ 8  8  0  6  6  6  0 29  0 16  0  8  0 11 11 14  3  8  3  1  8  0 10] -> size -> 23 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 174.65274047851562






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [ 6. 16.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 16.  0.  8.  0.] 
cards in discard: [ 0.  8.  3.  0. 29. 10.  0.  8.  1.  8. 11.  8.  3. 11.  6.  0. 14.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  6  6  6  0 29  0 16  0  8  0 11 11 14  3  8  3  1  8  0 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 25. 30.  8.  0.  9.  8.  4.  4.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0.  3. 25.  0.] 
adversary cards in discard: [25.  0. 29. 29. 29.  0. 29. 25. 29. 25.  3. 29. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 0.  8.  3.  0. 29. 10.  0.  8.  1.  8. 11.  8.  3. 11.  6.  0. 14.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  0  6  6  0 29  0  0  8  0 11 11 14  3  8  3  1  8  0 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 25. 30.  8.  0.  9.  8.  4.  4.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0.  3. 25.  0.] 
adversary cards in discard: [25.  0. 29. 29. 29.  0. 29. 25. 29. 25.  3. 29. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 0.  8.  3.  0. 29. 10.  0.  8.  1.  8. 11.  8.  3. 11.  6.  0. 14.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  0  6  6  0 29  0  0  8  0 11 11 14  3  8  3  1  8  0 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 26. 30. 25. 30.  8.  0.  9.  8.  4.  4.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0.  3. 25.  0.] 
adversary cards in discard: [25.  0. 29. 29. 29.  0. 29. 25. 29. 25.  3. 29. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 0.  8.  3.  0. 29. 10.  0.  8.  1.  8. 11.  8.  3. 11.  6.  0. 14.  6.
  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  0  6  6  0 29  0  0  8  0 11 11 14  3  8  3  1  8  0 10  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 26. 30. 25. 30.  8.  0.  9.  8.  4.  4.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0.  3. 25.  0.] 
adversary cards in discard: [25.  0. 29. 29. 29.  0. 29. 25. 29. 25.  3. 29. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [29.  0.  3. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[152.25847]
 [153.09938]
 [153.33583]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3. 25.  0.] 
cards in discard: [25.  0. 29. 29. 29.  0. 29. 25. 29. 25.  3. 29. 25.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 25. 30.  8.  0.  9.  8.  4.  4.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  6  6  0 29  0  0  8  0 11 11 14  3  8  3  1  8  0 10  0] -> size -> 22 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 175.2830352783203



action possibilites: [-1] 
expected returns: [[150.84052]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  0. 29. 29.] 
cards in discard: [25.  0. 29. 29. 29.  0. 29. 25. 29. 25.  3. 29. 25.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 25. 30.  8.  0.  9.  8.  4.  4.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  6  6  0 29  0  0  8  0 11 11 14  3  8  3  1  8  0 10  0] -> size -> 22 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 153.33583068847656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[146.79034]
 [147.39317]
 [147.71024]
 [150.68935]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.  0. 29. 29.] 
cards in discard: [25.  0. 29. 29. 29.  0. 29. 25. 29. 25.  3. 29. 25.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 26. 30. 25. 30.  8.  0.  9.  8.  4.  4.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  6  6  0 29  0  0  8  0 11 11 14  3  8  3  1  8  0 10  0] -> size -> 22 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 150.84051513671875






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  6  6  0 29  0  0  8  0 11 11 14  3  8  3  1  8  0 10  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 25. 30.  8.  0.  9.  8.  4.  4.  0.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 25.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  8  0  6  6  0 29  0  0  8  0 11 11 14  3  8  3  1  8  0 10  0 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 25. 30.  8.  0.  9.  8.  4.  4.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 25.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  8  0  6  6  0 29  0  0  8  0 11 11 14  3  8  3  1  8  0 10  0 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 26. 30. 25. 30.  8.  0.  9.  8.  4.  4.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 25.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  8  0  6  6  0 29  0  0  8  0 11 11 14  3  8  3  1  8  0 10  0 10 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 25. 30.  8.  0.  9.  7.  4.  4.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 25.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 0. 25.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[143.27107]
 [144.34843]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 25. 30.  8.  0.  9.  7.  4.  4.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  6. 10.  8.  8.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 8  8  0  6  6  0 29  0  0  8  0 11 11 14  3  8  3  1  8  0 10  0 10 11] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 150.68934631347656



action possibilites: [-1] 
expected returns: [[184.38904]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 25.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 25. 30.  8.  0.  9.  7.  4.  4.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  6. 10.  8.  8.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 8  8  0  6  6  0 29  0  0  8  0 11 11 14  3  8  3  1  8  0 10  0 10 11] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 142.7661895751953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[183.5469 ]
 [185.05827]
 [184.14975]
 [186.09206]
 [185.06964]
 [184.4668 ]
 [183.32187]
 [183.55832]
 [184.83322]
 [187.44594]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 25.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 26. 30. 25. 30.  8.  0.  9.  7.  4.  4.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  6. 10.  8.  8.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 8  8  0  6  6  0 29  0  0  8  0 11 11 14  3  8  3  1  8  0 10  0 10 11] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 184.3890380859375






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [ 0.  6. 10.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 10.  8.  8.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  6  6  0 29  0  0  8  0 11 11 14  3  8  3  1  8  0 10  0 10 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 25. 30.  8.  0.  9.  7.  4.  4.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29. 29.  3. 29.  0.] 
adversary cards in discard: [25.  0.  3.  0.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  6  0 29  0  0  8  0 11 11 14  3  8  3  1  8  0  0 10 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 25. 30.  8.  0.  9.  7.  4.  4.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29. 29.  3. 29.  0.] 
adversary cards in discard: [25.  0.  3.  0.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  6  0 29  0  0  8  0 11 11 14  3  8  3  1  8  0  0 10 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 26. 30. 25. 30.  8.  0.  9.  7.  4.  4.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29. 29.  3. 29.  0.] 
adversary cards in discard: [25.  0.  3.  0.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [29. 29.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[206.11977]
 [206.96068]
 [206.96068]
 [206.96068]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  3. 29.  0.] 
cards in discard: [25.  0.  3.  0.  0. 25.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 25. 30.  8.  0.  9.  7.  4.  4.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [14.  1.  8.  8.  6.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0.  8.  8.] 
adversary owned cards: [ 8  8  6  0 29  0  0  8  0 11 11 14  3  8  3  1  8  0  0 10 11] -> size -> 21 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 187.44593811035156



action possibilites: [-1. 29.] 
expected returns: [[205.38947]
 [206.23038]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3.] 
cards in discard: [25.  0.  3.  0.  0. 25.  0. 29.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 26. 30. 25. 30.  8.  0.  9.  7.  4.  4.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [14.  1.  8.  8.  6.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0.  8.  8.] 
adversary owned cards: [ 8  8  6  0 29  0  0  8  0 11 11 14  3  8  3  1  8  0  0 10 11] -> size -> 21 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 202.3459930419922



action possibilites: [-1.] 
expected returns: [[225.85263]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [25.  0.  3.  0.  0. 25.  0. 29.  0.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 2 
card supply: [20. 26. 30. 25. 30.  8.  0.  9.  7.  4.  4.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [14.  1.  8.  8.  6.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0.  8.  8.] 
adversary owned cards: [ 8  8  6  0 29  0  0  8  0 11 11 14  3  8  3  1  8  0  0 10 11] -> size -> 21 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 203.01844787597656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[222.5574 ]
 [223.16023]
 [223.47728]
 [226.45639]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [25.  0.  3.  0.  0. 25.  0. 29.  0.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 1 
buys: 1 
player value: 2 
card supply: [20. 26. 30. 25. 30.  8.  0.  9.  7.  4.  4.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [14.  1.  8.  8.  6.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0.  8.  8.] 
adversary owned cards: [ 8  8  6  0 29  0  0  8  0 11 11 14  3  8  3  1  8  0  0 10 11] -> size -> 21 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 225.85263061523438






         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [14.  1.  8.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  1.  8.  8.  6.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0.  8.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  6  0 29  0  0  8  0 11 11 14  3  8  3  1  8  0  0 10 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 25. 30.  8.  0.  9.  7.  4.  4.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29. 29. 25. 29. 25.] 
adversary cards in discard: [25.  0.  3.  0.  0. 25.  0. 29.  0.  3.  0. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  1.  8.  8.  6.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0.  8.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  6  0 29  0  0  8  0 11 11 14  3  8  3  1  8  0  0 10 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 26. 30. 25. 30.  8.  0.  9.  7.  4.  4.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29. 29. 25. 29. 25.] 
adversary cards in discard: [25.  0.  3.  0.  0. 25.  0. 29.  0.  3.  0. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  1.  8.  8.  6.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0.  8.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  6  0 29  0  0  8  0 11 11 14  3  8  3  1  8  0  0 10 11  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 26. 30. 25. 30.  8.  0.  9.  7.  4.  4.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29. 29. 25. 29. 25.] 
adversary cards in discard: [25.  0.  3.  0.  0. 25.  0. 29.  0.  3.  0. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [29. 29. 25. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 25. 29. 25.] 
expected returns: [[144.42148]
 [145.26239]
 [145.26239]
 [145.49883]
 [145.26239]
 [145.49883]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 25. 29. 25.] 
cards in discard: [25.  0.  3.  0.  0. 25.  0. 29.  0.  3.  0. 29. 29.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 25. 30.  8.  0.  9.  7.  4.  4.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 11.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0.  8.  8.  0. 14.  1.  8.  8.  6.] 
adversary owned cards: [ 8  8  6  0 29  0  0  8  0 11 11 14  3  8  3  1  8  0  0 10 11  0] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 226.45639038085938



action possibilites: [-1] 
expected returns: [[149.55577]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29. 25. 29. 29.] 
cards in discard: [25.  0.  3.  0.  0. 25.  0. 29.  0.  3.  0. 29. 29.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 25. 30.  8.  0.  9.  7.  4.  4.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 11.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0.  8.  8.  0. 14.  1.  8.  8.  6.] 
adversary owned cards: [ 8  8  6  0 29  0  0  8  0 11 11 14  3  8  3  1  8  0  0 10 11  0] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 145.49884033203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[145.46666]
 [149.36565]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29. 29. 25. 29. 29.] 
cards in discard: [25.  0.  3.  0.  0. 25.  0. 29.  0.  3.  0. 29. 29.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 26. 30. 25. 30.  8.  0.  9.  7.  4.  4.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 11.] 
adversary cards in discard: [10. 11. 11.  0.  3.  0.  0.  8.  8.  0. 14.  1.  8.  8.  6.] 
adversary owned cards: [ 8  8  6  0 29  0  0  8  0 11 11 14  3  8  3  1  8  0  0 10 11  0] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 149.55577087402344






         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 11.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0.  8.  8.  0. 14.  1.  8.  8.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  6  0 29  0  0  8  0 11 11 14  3  8  3  1  8  0  0 10 11  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 25. 30.  8.  0.  9.  7.  4.  4.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [25. 29. 25. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 11.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0.  8.  8.  0. 14.  1.  8.  8.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  6  0 29  0  0  8  0 11 11 14  3  8  3  1  8  0  0 10 11  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 26. 30. 25. 30.  8.  0.  9.  7.  4.  4.  0.  9. 10.  7. 10. 10.] 
adversary cards in hand: [25. 29. 25. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 11.] 
cards in discard: [10. 11. 11.  0.  3.  0.  0.  8.  8.  0. 14.  1.  8.  8.  6. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  6  0 29  0  0  8  0 11 11 14  3  8  3  1  8  0  0 10 11  0 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 25. 30.  8.  0.  9.  7.  4.  4.  0.  9. 10.  6. 10. 10.] 
adversary cards in hand: [25. 29. 25. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [25. 29. 25. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25. 25.] 
expected returns: [[143.2074 ]
 [144.28474]
 [144.04832]
 [144.28474]
 [144.28474]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 25. 25.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 25. 30.  8.  0.  9.  7.  4.  4.  0.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  8.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  6  0 29  0  0  8  0 11 11 14  3  8  3  1  8  0  0 10 11  0 10] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 149.3656463623047



action possibilites: [-1] 
expected returns: [[155.443]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 25.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 25. 30.  8.  0.  9.  7.  4.  4.  0.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  8.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  6  0 29  0  0  8  0 11 11 14  3  8  3  1  8  0  0 10 11  0 10] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 142.6014404296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[154.0223 ]
 [154.62512]
 [154.94218]
 [157.92131]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 25. 25.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 26. 30. 25. 30.  8.  0.  9.  7.  4.  4.  0.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  8.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  6  0 29  0  0  8  0 11 11 14  3  8  3  1  8  0  0 10 11  0 10] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 155.4429931640625






         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  8.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8.  8. 29.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  6  0 29  0  0  8  0 11 11 14  3  8  3  1  8  0  0 10 11  0 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 25. 30.  8.  0.  9.  7.  4.  4.  0.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0. 29.] 
adversary cards in discard: [25. 29. 25. 25.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  6  0  0  8  0 11 11 14  3  8  3  1  8  0  0 10 11  0 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 25. 30.  8.  0.  9.  7.  4.  4.  0.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0. 29.] 
adversary cards in discard: [25. 29. 25. 25.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  6  0  0  8  0 11 11 14  3  8  3  1  8  0  0 10 11  0 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 26. 30. 25. 30.  8.  0.  9.  7.  4.  4.  0.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0. 29.] 
adversary cards in discard: [25. 29. 25. 25.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 0. 29.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[204.71596]
 [205.55687]
 [205.55687]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0. 29.] 
cards in discard: [25. 29. 25. 25.  0.  0. 25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 25. 30.  8.  0.  9.  7.  4.  4.  0.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [8. 0. 8.] 
adversary owned cards: [ 8  8  6  0  0  8  0 11 11 14  3  8  3  1  8  0  0 10 11  0 10] -> size -> 21 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 157.92129516601562



action possibilites: [-1.] 
expected returns: [[177.39507]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [25. 29. 25. 25.  0.  0. 25. 29. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 26. 30. 25. 30.  8.  0.  9.  7.  4.  4.  0.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [8. 0. 8.] 
adversary owned cards: [ 8  8  6  0  0  8  0 11 11 14  3  8  3  1  8  0  0 10 11  0 10] -> size -> 21 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 200.9421844482422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[175.18097]
 [176.69232]
 [175.78381]
 [177.7261 ]
 [176.7037 ]
 [176.10088]
 [174.9559 ]
 [175.19235]
 [176.46727]
 [179.08   ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [25. 29. 25. 25.  0.  0. 25. 29. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 26. 30. 25. 30.  8.  0.  9.  7.  4.  4.  0.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [8. 0. 8.] 
adversary owned cards: [ 8  8  6  0  0  8  0 11 11 14  3  8  3  1  8  0  0 10 11  0 10] -> size -> 21 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 177.3950653076172






         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [8. 0. 8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  6  0  0  8  0 11 11 14  3  8  3  1  8  0  0 10 11  0 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 25. 30.  8.  0.  9.  7.  4.  4.  0.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 29. 29.  3.  3.] 
adversary cards in discard: [25. 29. 25. 25.  0.  0. 25. 29. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [8. 0. 8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  6  0  0  8  0 11 11 14  3  8  3  1  8  0  0 10 11  0 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 26. 30. 25. 30.  8.  0.  9.  7.  4.  4.  0.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 29. 29.  3.  3.] 
adversary cards in discard: [25. 29. 25. 25.  0.  0. 25. 29. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [ 8.  0.  8. 14.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  6  0  0  8  0 11 11 14  3  8  3  1  8  0  0 10 11  0 10 14] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 25. 30.  8.  0.  9.  7.  4.  4.  0.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 29. 29.  3.  3.] 
adversary cards in discard: [25. 29. 25. 25.  0.  0. 25. 29. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 0. 29. 29.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[159.32292]
 [160.16383]
 [160.16383]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29.  3.  3.] 
cards in discard: [25. 29. 25. 25.  0.  0. 25. 29. 29. 29.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 25. 30.  8.  0.  9.  7.  4.  4.  0.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 11.  1. 14.  3.] 
adversary cards in discard: [ 8.  0.  8. 14.  0.  0.  8.  0.  0.] 
adversary owned cards: [ 8  8  6  0  0  8  0 11 11 14  3  8  3  1  8  0  0 10 11  0 10 14] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 179.07998657226562



action possibilites: [-1. 29. 29.] 
expected returns: [[146.95753]
 [147.79845]
 [147.79845]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 29.] 
cards in discard: [25. 29. 25. 25.  0.  0. 25. 29. 29. 29.  0.  0.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 26. 30. 25. 30.  8.  0.  9.  7.  4.  4.  0.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 11.  1. 14.  3.] 
adversary cards in discard: [ 8.  0.  8. 14.  0.  0.  8.  0.  0.] 
adversary owned cards: [ 8  8  6  0  0  8  0 11 11 14  3  8  3  1  8  0  0 10 11  0 10 14] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 156.93524169921875



action possibilites: [-1. 29.] 
expected returns: [[158.68184]
 [159.52275]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.] 
cards in discard: [25. 29. 25. 25.  0.  0. 25. 29. 29. 29.  0.  0.  0.  0.  3.  3. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 2 
card supply: [19. 26. 30. 25. 30.  8.  0.  9.  7.  4.  4.  0.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 11.  1. 14.  3.] 
adversary cards in discard: [ 8.  0.  8. 14.  0.  0.  8.  0.  0.] 
adversary owned cards: [ 8  8  6  0  0  8  0 11 11 14  3  8  3  1  8  0  0 10 11  0 10 14] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 144.5698699951172



action possibilites: [-1.] 
expected returns: [[175.98357]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [25. 29. 25. 25.  0.  0. 25. 29. 29. 29.  0.  0.  0.  0.  3.  3. 25.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 3 
card supply: [19. 26. 30. 25. 30.  8.  0.  9.  7.  4.  4.  0.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 11.  1. 14.  3.] 
adversary cards in discard: [ 8.  0.  8. 14.  0.  0.  8.  0.  0.] 
adversary owned cards: [ 8  8  6  0  0  8  0 11 11 14  3  8  3  1  8  0  0 10 11  0 10 14] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: discard_n_cards - action 0
Learning step: 0
desired expected reward: 154.7828369140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[171.89447]
 [173.40579]
 [172.49728]
 [173.41718]
 [172.81433]
 [171.90585]
 [175.79343]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [25. 29. 25. 25.  0.  0. 25. 29. 29. 29.  0.  0.  0.  0.  3.  3. 25.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 1 
buys: 1 
player value: 3 
card supply: [19. 26. 30. 25. 30.  8.  0.  9.  7.  4.  4.  0.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 11.  1. 14.  3.] 
adversary cards in discard: [ 8.  0.  8. 14.  0.  0.  8.  0.  0.] 
adversary owned cards: [ 8  8  6  0  0  8  0 11 11 14  3  8  3  1  8  0  0 10 11  0 10 14] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 175.9835662841797






         -------------------- Turn: 55 -------------------- 
Player: 1 
cards in hand: [ 8. 11.  1. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 14.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  1. 14.  3.] 
cards in discard: [ 8.  0.  8. 14.  0.  0.  8.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  6  0  0  8  0 11 11 14  3  8  3  1  8  0  0 10 11  0 10 14] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 25. 30.  8.  0.  9.  7.  4.  4.  0.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 29. 29. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1. 14.  3.] 
cards in discard: [ 8.  0.  8. 14.  0.  0.  8.  0.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  8  6  0  0  8  0 11 11 14  3  8  3  1  8  0  0 10 11  0 10 14  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 25. 30.  8.  0.  9.  7.  3.  4.  0.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 29. 29. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1. 14.  3.] 
cards in discard: [ 8.  0.  8. 14.  0.  0.  8.  0.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  8  6  0  0  8  0 11 11 14  3  8  3  1  8  0  0 10 11  0 10 14  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 26. 30. 25. 30.  8.  0.  9.  7.  3.  4.  0.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 29. 29. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 3. 29. 29. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 25.] 
expected returns: [[143.89622]
 [144.73712]
 [144.73712]
 [144.97356]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 29. 25.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 25. 30.  8.  0.  9.  7.  3.  4.  0.  8. 10.  6. 10. 10.] 
adversary cards in hand: [11. 10.  6.  3.  8.] 
adversary cards in discard: [ 8.  0.  8. 14.  0.  0.  8.  0.  0.  8. 11.  8.  1. 14.  3.] 
adversary owned cards: [ 8  8  6  0  0  8  0 11 11 14  3  8  3  1  8  0  0 10 11  0 10 14  8] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 175.79344177246094



action possibilites: [-1] 
expected returns: [[159.97917]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 29.  0. 29. 25.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 25. 30.  8.  0.  9.  7.  3.  4.  0.  8. 10.  6. 10. 10.] 
adversary cards in hand: [11. 10.  6.  3.  8.] 
adversary cards in discard: [ 8.  0.  8. 14.  0.  0.  8.  0.  0.  8. 11.  8.  1. 14.  3.] 
adversary owned cards: [ 8  8  6  0  0  8  0 11 11 14  3  8  3  1  8  0  0 10 11  0 10 14  8] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 143.29025268554688





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[158.23087]
 [162.12987]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29. 29.  0. 29. 25.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 26. 30. 25. 30.  8.  0.  9.  7.  3.  4.  0.  8. 10.  6. 10. 10.] 
adversary cards in hand: [11. 10.  6.  3.  8.] 
adversary cards in discard: [ 8.  0.  8. 14.  0.  0.  8.  0.  0.  8. 11.  8.  1. 14.  3.] 
adversary owned cards: [ 8  8  6  0  0  8  0 11 11 14  3  8  3  1  8  0  0 10 11  0 10 14  8] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 159.9791717529297






         -------------------- Turn: 56 -------------------- 
Player: 1 
cards in hand: [11. 10.  6.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  6.  3.  8.] 
cards in discard: [ 8.  0.  8. 14.  0.  0.  8.  0.  0.  8. 11.  8.  1. 14.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  6  0  0  8  0 11 11 14  3  8  3  1  8  0  0 10 11  0 10 14  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 25. 30.  8.  0.  9.  7.  3.  4.  0.  8. 10.  6. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0. 29.] 
adversary cards in discard: [25.  3. 29. 29.  0. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [ 8.  0.  8. 14.  0.  0.  8.  0.  0.  8. 11.  8.  1. 14.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  0  0  8  0 11 14  8  3  1  8  0  0 10 11  0 10 14  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 26. 30. 25. 30.  8.  0.  9.  7.  3.  4.  0.  8. 10.  6. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0. 29.] 
adversary cards in discard: [25.  3. 29. 29.  0. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [ 8.  0.  8. 14.  0.  0.  8.  0.  0.  8. 11.  8.  1. 14.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  0  0  8  0 11 14  8  3  1  8  0  0 10 11  0 10 14  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 26. 30. 25. 30.  8.  0.  9.  7.  3.  4.  0.  8. 10.  6. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0. 29.] 
adversary cards in discard: [25.  3. 29. 29.  0. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [ 8.  0.  8. 14.  0.  0.  8.  0.  0.  8. 11.  8.  1. 14.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  0  0  8  0 11 14  8  3  1  8  0  0 10 11  0 10 14  8  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 25. 30.  8.  0.  9.  7.  3.  4.  0.  8. 10.  6. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0. 29.] 
adversary cards in discard: [25.  3. 29. 29.  0. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [29.  3.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[206.06633]
 [206.90724]
 [206.90724]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  0. 29.] 
cards in discard: [25.  3. 29. 29.  0. 29. 25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 25. 30.  8.  0.  9.  7.  3.  4.  0.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 14.  0. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0  8  0 11 14  8  3  1  8  0  0 10 11  0 10 14  8  0] -> size -> 21 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 162.12986755371094



action possibilites: [-1.] 
expected returns: [[201.97197]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [25.  3. 29. 29.  0. 29. 25.  0. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 26. 30. 25. 30.  8.  0.  9.  7.  3.  4.  0.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 14.  0. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0  8  0 11 14  8  3  1  8  0  0 10 11  0 10 14  8  0] -> size -> 21 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 202.29258728027344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[199.3853 ]
 [200.89667]
 [199.98817]
 [200.90802]
 [200.3052 ]
 [199.3967 ]
 [203.2843 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [25.  3. 29. 29.  0. 29. 25.  0. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 26. 30. 25. 30.  8.  0.  9.  7.  3.  4.  0.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 14.  0. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0  8  0 11 14  8  3  1  8  0  0 10 11  0 10 14  8  0] -> size -> 21 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 201.9719696044922






         -------------------- Turn: 57 -------------------- 
Player: 1 
cards in hand: [ 0. 14.  0. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0. 10. 11.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  8  0 11 14  8  3  1  8  0  0 10 11  0 10 14  8  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 25. 30.  8.  0.  9.  7.  3.  4.  0.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 25. 25.  0. 29.] 
adversary cards in discard: [25.  3. 29. 29.  0. 29. 25.  0. 29. 29.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1. 14. 11.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  8  0  0  8  0 11 14  8  3  1  8  0  0 10 11  0 10 14  8  0] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 25. 30.  8.  0.  9.  7.  3.  4.  0.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 25. 25.  0. 29.] 
adversary cards in discard: [25.  3. 29. 29.  0. 29. 25.  0. 29. 29.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 8  8  0  0  8  0 11 14  8  3  1  8  0  0 10 11  0 10 14  8  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 2 
card supply: [18. 26. 30. 25. 30.  8.  0.  9.  7.  3.  4.  0.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 25.  0.] 
adversary cards in discard: [25.  3. 29. 29.  0. 29. 25.  0. 29. 29.  3.  0.  0. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 8  8  0  0  8  0 11 14  8  3  1  8  0  0 10 11  0 10 14  8  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [18. 26. 30. 25. 30.  8.  0.  9.  7.  3.  4.  0.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 25.  0.] 
adversary cards in discard: [25.  3. 29. 29.  0. 29. 25.  0. 29. 29.  3.  0.  0. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.] 
cards in discard: [23.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 8  8  0  0  8  0 11 14  8  3  1  8  0  0 10 11  0 10 14  8  0 23] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 25. 30.  8.  0.  9.  7.  3.  4.  0.  8.  9.  6. 10. 10.] 
adversary cards in hand: [ 3. 25.  0.] 
adversary cards in discard: [25.  3. 29. 29.  0. 29. 25.  0. 29. 29.  3.  0.  0. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 3. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[127.75057]
 [128.82793]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  0.] 
cards in discard: [25.  3. 29. 29.  0. 29. 25.  0. 29. 29.  3.  0.  0. 25. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 25. 30.  8.  0.  9.  7.  3.  4.  0.  8.  9.  6. 10. 10.] 
adversary cards in hand: [ 8.  8. 10.  8.  0.] 
adversary cards in discard: [23. 10. 14.  0.  0. 11.  0.] 
adversary owned cards: [ 8  8  0  0  8  0 11 14  8  3  1  8  0  0 10 11  0 10 14  8  0 23] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[  -5    0    0   60    0    0    0    0    0    0    0    0    0    0
 1342    0] 
sum of rewards: 1397 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 70.52944946289062



action possibilites: [-1] 
expected returns: [[92.706245]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 29.] 
cards in discard: [25.  3. 29. 29.  0. 29. 25.  0. 29. 29.  3.  0.  0. 25. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 25. 30.  8.  0.  9.  7.  3.  4.  0.  8.  9.  6. 10. 10.] 
adversary cards in hand: [ 8.  8. 10.  8.  0.] 
adversary cards in discard: [23. 10. 14.  0.  0. 11.  0.] 
adversary owned cards: [ 8  8  0  0  8  0 11 14  8  3  1  8  0  0 10 11  0 10 14  8  0 23] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 128.8279266357422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[88.73426]
 [89.33709]
 [89.65415]
 [92.63326]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 29.] 
cards in discard: [25.  3. 29. 29.  0. 29. 25.  0. 29. 29.  3.  0.  0. 25. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 26. 30. 25. 30.  8.  0.  9.  7.  3.  4.  0.  8.  9.  6. 10. 10.] 
adversary cards in hand: [ 8.  8. 10.  8.  0.] 
adversary cards in discard: [23. 10. 14.  0.  0. 11.  0.] 
adversary owned cards: [ 8  8  0  0  8  0 11 14  8  3  1  8  0  0 10 11  0 10 14  8  0 23] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 92.70624542236328






         -------------------- Turn: 58 -------------------- 
Player: 1 
cards in hand: [ 8.  8. 10.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 10.  8.  0.] 
cards in discard: [23. 10. 14.  0.  0. 11.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  8  0 11 14  8  3  1  8  0  0 10 11  0 10 14  8  0 23] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 25. 30.  8.  0.  9.  7.  3.  4.  0.  8.  9.  6. 10. 10.] 
adversary cards in hand: [29. 25. 29.  0. 25.] 
adversary cards in discard: [25.  3. 29. 29.  0. 29. 25.  0. 29. 29.  3.  0.  0. 25. 29. 25.  3.  0.
  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8. 10.  8.  0.] 
cards in discard: [23. 10. 14.  0.  0. 11.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  8  0 11 14  8  3  1  8  0  0 10 11  0 10 14  8  0 23] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 26. 30. 25. 30.  8.  0.  9.  7.  3.  4.  0.  8.  9.  6. 10. 10.] 
adversary cards in hand: [29. 25. 29.  0. 25.] 
adversary cards in discard: [25.  3. 29. 29.  0. 29. 25.  0. 29. 29.  3.  0.  0. 25. 29. 25.  3.  0.
  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29. 25. 29.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29. 25.] 
expected returns: [[142.0497 ]
 [142.89061]
 [143.12704]
 [142.89061]
 [143.12704]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 29.  0. 25.] 
cards in discard: [25.  3. 29. 29.  0. 29. 25.  0. 29. 29.  3.  0.  0. 25. 29. 25.  3.  0.
  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 25. 30.  8.  0.  9.  7.  3.  4.  0.  8.  9.  6. 10. 10.] 
adversary cards in hand: [ 8.  8.  3.  1. 14.] 
adversary cards in discard: [23. 10. 14.  0.  0. 11.  0.  8.  8. 10.  8.  0.] 
adversary owned cards: [ 8  8  0  0  8  0 11 14  8  3  1  8  0  0 10 11  0 10 14  8  0 23] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 92.63326263427734



action possibilites: [-1] 
expected returns: [[147.0519]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0. 25.  0. 29.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 25. 30.  8.  0.  9.  7.  3.  4.  0.  8.  9.  6. 10. 10.] 
adversary cards in hand: [ 8.  8.  3.  1. 14.] 
adversary cards in discard: [23. 10. 14.  0.  0. 11.  0.  8.  8. 10.  8.  0.] 
adversary owned cards: [ 8  8  0  0  8  0 11 14  8  3  1  8  0  0 10 11  0 10 14  8  0 23] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 143.12704467773438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[145.73051]
 [146.33336]
 [146.6504 ]
 [149.62953]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29.  0. 25.  0. 29.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 26. 30. 25. 30.  8.  0.  9.  7.  3.  4.  0.  8.  9.  6. 10. 10.] 
adversary cards in hand: [ 8.  8.  3.  1. 14.] 
adversary cards in discard: [23. 10. 14.  0.  0. 11.  0.  8.  8. 10.  8.  0.] 
adversary owned cards: [ 8  8  0  0  8  0 11 14  8  3  1  8  0  0 10 11  0 10 14  8  0 23] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 147.05189514160156






         -------------------- Turn: 59 -------------------- 
Player: 1 
cards in hand: [ 8.  8.  3.  1. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  3.  1. 14.] 
cards in discard: [23. 10. 14.  0.  0. 11.  0.  8.  8. 10.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  8  0 11 14  8  3  1  8  0  0 10 11  0 10 14  8  0 23] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 25. 30.  8.  0.  9.  7.  3.  4.  0.  8.  9.  6. 10. 10.] 
adversary cards in hand: [ 0. 25. 29.  3. 29.] 
adversary cards in discard: [25. 29. 29.  0. 25.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1.] 
cards in discard: [23. 10. 14.  0.  0. 11.  0.  8.  8. 10.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  0  8  0 11  8  3  1  8  0  0 10 11  0 10 14  8  0 23] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 25. 30.  8.  0.  9.  7.  3.  4.  0.  8.  9.  6. 10. 10.] 
adversary cards in hand: [ 0. 25. 29.  3. 29.] 
adversary cards in discard: [25. 29. 29.  0. 25.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1.] 
cards in discard: [23. 10. 14.  0.  0. 11.  0.  8.  8. 10.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  0  8  0 11  8  3  1  8  0  0 10 11  0 10 14  8  0 23] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 26. 30. 25. 30.  8.  0.  9.  7.  3.  4.  0.  8.  9.  6. 10. 10.] 
adversary cards in hand: [ 0. 25. 29.  3. 29.] 
adversary cards in discard: [25. 29. 29.  0. 25.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1.] 
cards in discard: [23. 10. 14.  0.  0. 11.  0.  8.  8. 10.  8.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  0  8  0 11  8  3  1  8  0  0 10 11  0 10 14  8  0 23  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 24. 30.  8.  0.  9.  7.  3.  4.  0.  8.  9.  6. 10. 10.] 
adversary cards in hand: [ 0. 25. 29.  3. 29.] 
adversary cards in discard: [25. 29. 29.  0. 25.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 0. 25. 29.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 29.] 
expected returns: [[158.21823]
 [159.29558]
 [159.05913]
 [159.05913]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 29.  3. 29.] 
cards in discard: [25. 29. 29.  0. 25.  0. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 24. 30.  8.  0.  9.  7.  3.  4.  0.  8.  9.  6. 10. 10.] 
adversary cards in hand: [ 8.  0.  0.  0. 11.] 
adversary cards in discard: [23. 10. 14.  0.  0. 11.  0.  8.  8. 10.  8.  0.  3.  8.  3.  1.] 
adversary owned cards: [ 8  0  0  8  0 11  8  3  1  8  0  0 10 11  0 10 14  8  0 23  3] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 149.6295166015625



action possibilites: [-1] 
expected returns: [[172.42464]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3. 29.  3.  0.] 
cards in discard: [25. 29. 29.  0. 25.  0. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 24. 30.  8.  0.  9.  7.  3.  4.  0.  8.  9.  6. 10. 10.] 
adversary cards in hand: [ 8.  0.  0.  0. 11.] 
adversary cards in discard: [23. 10. 14.  0.  0. 11.  0.  8.  8. 10.  8.  0.  3.  8.  3.  1.] 
adversary owned cards: [ 8  0  0  8  0 11  8  3  1  8  0  0 10 11  0 10 14  8  0 23  3] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 157.9829864501953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[169.65529]
 [170.25813]
 [170.5752 ]
 [173.55429]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3. 29.  3.  0.] 
cards in discard: [25. 29. 29.  0. 25.  0. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 26. 30. 24. 30.  8.  0.  9.  7.  3.  4.  0.  8.  9.  6. 10. 10.] 
adversary cards in hand: [ 8.  0.  0.  0. 11.] 
adversary cards in discard: [23. 10. 14.  0.  0. 11.  0.  8.  8. 10.  8.  0.  3.  8.  3.  1.] 
adversary owned cards: [ 8  0  0  8  0 11  8  3  1  8  0  0 10 11  0 10 14  8  0 23  3] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 172.4246368408203






         -------------------- Turn: 60 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0.  0. 11.] 
cards in discard: [23. 10. 14.  0.  0. 11.  0.  8.  8. 10.  8.  0.  3.  8.  3.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  8  0 11  8  3  1  8  0  0 10 11  0 10 14  8  0 23  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 24. 30.  8.  0.  9.  7.  3.  4.  0.  8.  9.  6. 10. 10.] 
adversary cards in hand: [29.  0.  3. 29. 25.] 
adversary cards in discard: [25. 29. 29.  0. 25.  0. 29. 25.  0. 29.  3. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0.  0. 11.] 
cards in discard: [23. 10. 14.  0.  0. 11.  0.  8.  8. 10.  8.  0.  3.  8.  3.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  8  0 11  8  3  1  8  0  0 10 11  0 10 14  8  0 23  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 26. 30. 24. 30.  8.  0.  9.  7.  3.  4.  0.  8.  9.  6. 10. 10.] 
adversary cards in hand: [29.  0.  3. 29. 25.] 
adversary cards in discard: [25. 29. 29.  0. 25.  0. 29. 25.  0. 29.  3. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29.  0.  3. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 25.] 
expected returns: [[119.799   ]
 [120.639915]
 [120.639915]
 [120.876366]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3. 29. 25.] 
cards in discard: [25. 29. 29.  0. 25.  0. 29. 25.  0. 29.  3. 29.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 24. 30.  8.  0.  9.  7.  3.  4.  0.  8.  9.  6. 10. 10.] 
adversary cards in hand: [ 1.  0.  3. 11. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  8  0 11  8  3  1  8  0  0 10 11  0 10 14  8  0 23  3] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 173.55429077148438



action possibilites: [-1] 
expected returns: [[130.79608]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3. 29.  0. 29.] 
cards in discard: [25. 29. 29.  0. 25.  0. 29. 25.  0. 29.  3. 29.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 24. 30.  8.  0.  9.  7.  3.  4.  0.  8.  9.  6. 10. 10.] 
adversary cards in hand: [ 1.  0.  3. 11. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  8  0 11  8  3  1  8  0  0 10 11  0 10 14  8  0 23  3] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 120.8763656616211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[126.7459 ]
 [127.34874]
 [127.6658 ]
 [130.64491]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3. 29.  0. 29.] 
cards in discard: [25. 29. 29.  0. 25.  0. 29. 25.  0. 29.  3. 29.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 26. 30. 24. 30.  8.  0.  9.  7.  3.  4.  0.  8.  9.  6. 10. 10.] 
adversary cards in hand: [ 1.  0.  3. 11. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0  8  0 11  8  3  1  8  0  0 10 11  0 10 14  8  0 23  3] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 130.79608154296875






         -------------------- Turn: 61 -------------------- 
Player: 1 
cards in hand: [ 1.  0.  3. 11. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3. 11. 14.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  8  0 11  8  3  1  8  0  0 10 11  0 10 14  8  0 23  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 24. 30.  8.  0.  9.  7.  3.  4.  0.  8.  9.  6. 10. 10.] 
adversary cards in hand: [ 0. 29. 25. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3. 11. 14.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  8  0 11  8  3  1  8  0  0 10 11  0 10 14  8  0 23  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 26. 30. 24. 30.  8.  0.  9.  7.  3.  4.  0.  8.  9.  6. 10. 10.] 
adversary cards in hand: [ 0. 29. 25. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 29. 25. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 25.] 
expected returns: [[127.43848]
 [128.2794 ]
 [128.51582]
 [128.51582]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 25. 25.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 24. 30.  8.  0.  9.  7.  3.  4.  0.  8.  9.  6. 10. 10.] 
adversary cards in hand: [8. 3. 8. 8. 0.] 
adversary cards in discard: [ 1.  0.  3. 11. 14.] 
adversary owned cards: [ 8  0  0  8  0 11  8  3  1  8  0  0 10 11  0 10 14  8  0 23  3] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 130.64491271972656



action possibilites: [-1] 
expected returns: [[166.81757]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 25.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 24. 30.  8.  0.  9.  7.  3.  4.  0.  8.  9.  6. 10. 10.] 
adversary cards in hand: [8. 3. 8. 8. 0.] 
adversary cards in discard: [ 1.  0.  3. 11. 14.] 
adversary owned cards: [ 8  0  0  8  0 11  8  3  1  8  0  0 10 11  0 10 14  8  0 23  3] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 127.39886474609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[166.00702]
 [167.51833]
 [166.60982]
 [167.5297 ]
 [166.9269 ]
 [166.01839]
 [169.906  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 25.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 26. 30. 24. 30.  8.  0.  9.  7.  3.  4.  0.  8.  9.  6. 10. 10.] 
adversary cards in hand: [8. 3. 8. 8. 0.] 
adversary cards in discard: [ 1.  0.  3. 11. 14.] 
adversary owned cards: [ 8  0  0  8  0 11  8  3  1  8  0  0 10 11  0 10 14  8  0 23  3] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 166.81756591796875






         -------------------- Turn: 62 -------------------- 
Player: 1 
cards in hand: [8. 3. 8. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 8. 8. 0.] 
cards in discard: [ 1.  0.  3. 11. 14.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0  8  0 11  8  3  1  8  0  0 10 11  0 10 14  8  0 23  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 24. 30.  8.  0.  9.  7.  3.  4.  0.  8.  9.  6. 10. 10.] 
adversary cards in hand: [29. 29. 29. 25.  0.] 
adversary cards in discard: [25.  0. 29. 25.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0.] 
cards in discard: [ 1.  0.  3. 11. 14.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  8  0 11  8  3  1  8  0  0 10 11  0 10 14  8  0 23  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 30. 24. 30.  8.  0.  9.  7.  3.  4.  0.  8.  9.  6. 10. 10.] 
adversary cards in hand: [29. 29. 29. 25.  0.] 
adversary cards in discard: [25.  0. 29. 25.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0.] 
cards in discard: [ 1.  0.  3. 11. 14.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  8  0 11  8  3  1  8  0  0 10 11  0 10 14  8  0 23  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 26. 30. 24. 30.  8.  0.  9.  7.  3.  4.  0.  8.  9.  6. 10. 10.] 
adversary cards in hand: [29. 29. 29. 25.  0.] 
adversary cards in discard: [25.  0. 29. 25.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0.] 
cards in discard: [ 1.  0.  3. 11. 14.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  8  0 11  8  3  1  8  0  0 10 11  0 10 14  8  0 23  3  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 26. 30. 24. 30.  8.  0.  9.  7.  3.  4.  0.  8.  9.  6. 10. 10.] 
adversary cards in hand: [29. 29. 29. 25.  0.] 
adversary cards in discard: [25.  0. 29. 25.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [29. 29. 29. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29. 25.] 
expected returns: [[185.28519]
 [186.12608]
 [186.12608]
 [186.12608]
 [186.36253]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29. 25.  0.] 
cards in discard: [25.  0. 29. 25.  0.  0. 25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 24. 30.  8.  0.  9.  7.  3.  4.  0.  8.  9.  6. 10. 10.] 
adversary cards in hand: [10. 10. 23.  0.  8.] 
adversary cards in discard: [ 1.  0.  3. 11. 14.  0.  8.  3.  8.  0.] 
adversary owned cards: [ 0  0  8  0 11  8  3  1  8  0  0 10 11  0 10 14  8  0 23  3  0] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 169.90599060058594



action possibilites: [-1] 
expected returns: [[166.37947]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29.  0.  0. 29.] 
cards in discard: [25.  0. 29. 25.  0.  0. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 24. 30.  8.  0.  9.  7.  3.  4.  0.  8.  9.  6. 10. 10.] 
adversary cards in hand: [10. 10. 23.  0.  8.] 
adversary cards in discard: [ 1.  0.  3. 11. 14.  0.  8.  3.  8.  0.] 
adversary owned cards: [ 0  0  8  0 11  8  3  1  8  0  0 10 11  0 10 14  8  0 23  3  0] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 185.0499267578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[163.61014]
 [164.21297]
 [164.53001]
 [167.50914]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29. 29.  0.  0. 29.] 
cards in discard: [25.  0. 29. 25.  0.  0. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 26. 30. 24. 30.  8.  0.  9.  7.  3.  4.  0.  8.  9.  6. 10. 10.] 
adversary cards in hand: [10. 10. 23.  0.  8.] 
adversary cards in discard: [ 1.  0.  3. 11. 14.  0.  8.  3.  8.  0.] 
adversary owned cards: [ 0  0  8  0 11  8  3  1  8  0  0 10 11  0 10 14  8  0 23  3  0] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 166.3794708251953






         -------------------- Turn: 63 -------------------- 
Player: 1 
cards in hand: [10. 10. 23.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 23.  8.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 23.  0.  8.] 
cards in discard: [ 1.  0.  3. 11. 14.  0.  8.  3.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  8  3  1  8  0  0 10 11  0 10 14  8  0 23  3  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 24. 30.  8.  0.  9.  7.  3.  4.  0.  8.  9.  6. 10. 10.] 
adversary cards in hand: [29.  3.  0. 29. 25.] 
adversary cards in discard: [25.  0. 29. 25.  0.  0. 25. 25. 29. 29. 29.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1. 10. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  8.  0.] 
cards in discard: [ 1.  0.  3. 11. 14.  0.  8.  3.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  8  0 11  8  3  1  8  0  0 10 11  0 10 14  8  0 23  3  0] -> size -> 21 
action values: 1 
buys: 1 
player value: 1 
card supply: [17. 26. 30. 24. 30.  8.  0.  9.  7.  3.  4.  0.  8.  9.  6. 10. 10.] 
adversary cards in hand: [29.  3.  0. 29. 25.] 
adversary cards in discard: [25.  0. 29. 25.  0.  0. 25. 25. 29. 29. 29.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  8.  0.] 
cards in discard: [ 1.  0.  3. 11. 14.  0.  8.  3.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  8  0 11  8  3  1  8  0  0 10 11  0 10 14  8  0 23  3  0] -> size -> 21 
action values: 0 
buys: 2 
player value: 3 
card supply: [17. 26. 30. 24. 30.  8.  0.  9.  7.  3.  4.  0.  8.  9.  6. 10. 10.] 
adversary cards in hand: [29.  3.  0. 29. 25.] 
adversary cards in discard: [25.  0. 29. 25.  0.  0. 25. 25. 29. 29. 29.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 2 


buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  8.  0.] 
cards in discard: [ 1.  0.  3. 11. 14.  0.  8.  3.  8.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  8  0 11  8  3  1  8  0  0 10 11  0 10 14  8  0 23  3  0  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 26. 30. 24. 30.  8.  0.  9.  7.  2.  4.  0.  8.  9.  6. 10. 10.] 
adversary cards in hand: [29.  3.  0. 29. 25.] 
adversary cards in discard: [25.  0. 29. 25.  0.  0. 25. 25. 29. 29. 29.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [29.  3.  0. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 25.] 
expected returns: [[151.15598]
 [151.99687]
 [151.99687]
 [152.23332]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0. 29. 25.] 
cards in discard: [25.  0. 29. 25.  0.  0. 25. 25. 29. 29. 29.  0.  0. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 24. 30.  8.  0.  9.  7.  2.  4.  0.  8.  9.  6. 10. 10.] 
adversary cards in hand: [ 8.  0.  0.  0. 11.] 
adversary cards in discard: [ 1.  0.  3. 11. 14.  0.  8.  3.  8.  0.  8. 23. 10. 10.  0.  8.  0.] 
adversary owned cards: [ 0  0  8  0 11  8  3  1  8  0  0 10 11  0 10 14  8  0 23  3  0  8] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 167.50914001464844



action possibilites: [-1] 
expected returns: [[140.16454]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0. 29. 29.  0.] 
cards in discard: [25.  0. 29. 25.  0.  0. 25. 25. 29. 29. 29.  0.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 24. 30.  8.  0.  9.  7.  2.  4.  0.  8.  9.  6. 10. 10.] 
adversary cards in hand: [ 8.  0.  0.  0. 11.] 
adversary cards in discard: [ 1.  0.  3. 11. 14.  0.  8.  3.  8.  0.  8. 23. 10. 10.  0.  8.  0.] 
adversary owned cards: [ 0  0  8  0 11  8  3  1  8  0  0 10 11  0 10 14  8  0 23  3  0  8] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 152.23333740234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[136.11436]
 [136.71721]
 [137.03426]
 [140.01337]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0. 29. 29.  0.] 
cards in discard: [25.  0. 29. 25.  0.  0. 25. 25. 29. 29. 29.  0.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 26. 30. 24. 30.  8.  0.  9.  7.  2.  4.  0.  8.  9.  6. 10. 10.] 
adversary cards in hand: [ 8.  0.  0.  0. 11.] 
adversary cards in discard: [ 1.  0.  3. 11. 14.  0.  8.  3.  8.  0.  8. 23. 10. 10.  0.  8.  0.] 
adversary owned cards: [ 0  0  8  0 11  8  3  1  8  0  0 10 11  0 10 14  8  0 23  3  0  8] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 140.16453552246094






         -------------------- Turn: 64 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0.  0. 11.] 
cards in discard: [ 1.  0.  3. 11. 14.  0.  8.  3.  8.  0.  8. 23. 10. 10.  0.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  0 11  8  3  1  8  0  0 10 11  0 10 14  8  0 23  3  0  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 24. 30.  8.  0.  9.  7.  2.  4.  0.  8.  9.  6. 10. 10.] 
adversary cards in hand: [ 0. 29. 25.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0.] 
cards in discard: [ 1.  0.  3. 11. 14.  0.  8.  3.  8.  0.  8. 23. 10. 10.  0.  8.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  8  0 11  8  3  1  8  0  0 10 11  0 10 14  8  0 23  3  0  8  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 24. 30.  8.  0.  9.  7.  1.  4.  0.  8.  9.  6. 10. 10.] 
adversary cards in hand: [ 0. 29. 25.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0.] 
cards in discard: [ 1.  0.  3. 11. 14.  0.  8.  3.  8.  0.  8. 23. 10. 10.  0.  8.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  8  0 11  8  3  1  8  0  0 10 11  0 10 14  8  0 23  3  0  8  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 26. 30. 24. 30.  8.  0.  9.  7.  1.  4.  0.  8.  9.  6. 10. 10.] 
adversary cards in hand: [ 0. 29. 25.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
adversary victory points: 3
player victory points: 2 


Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 0 
Chapel: 0 
Witch: 6 
Poacher: 9 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 0. 29. 25.  3.  3.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 25 25 29 29 25 25 29 29 25 25 29
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 24. 30.  8.  0.  9.  7.  0.  4.  0.  8.  9.  6. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0.] 
adversary cards in discard: [ 1.  0.  3. 11. 14.  0.  8.  3.  8.  0.  8. 23. 10. 10.  0.  8.  0.  8.
  8.] 
adversary owned cards: [ 0  0  8  0 11  8  3  1  8  0  0 10 11  0 10 14  8  0 23  3  0  8  8  8] -> size -> 24 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0      30       0       0       0       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000025 

action type: buy - action -1.0
Learning step: 119995.3984375
desired expected reward: 120135.4140625



