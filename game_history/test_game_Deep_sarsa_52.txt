 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[60.361435]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0      -60        0        0       20        0
        0        0        0     -140        0        0       27        0] 
sum of rewards: -3000158 

action type: gain_card_n - action 5
Learning step: -300034.0625
desired expected reward: -299851.46875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[58.139748]
 [78.65604 ]
 [71.71022 ]
 [45.615913]
 [68.06759 ]
 [86.82008 ]
 [71.06355 ]
 [98.69945 ]
 [58.094086]
 [64.92355 ]
 [78.51528 ]
 [57.760826]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 59.17975997924805



buy possibilites: [-1] 
expected returns: [[33.5514]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 98.69944763183594






Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[58.841515]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [1. 0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 33.55139923095703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[58.406197]
 [78.36368 ]
 [72.053185]
 [45.616364]
 [85.47708 ]
 [71.33643 ]
 [65.24247 ]
 [58.148476]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [1. 0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 56.46232604980469



buy possibilites: [-1] 
expected returns: [[39.299618]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29.  3.  0.  0.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [1. 0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 85.47708129882812






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [1. 0. 3. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [1. 0. 3. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [1. 0. 3. 3. 0. 0. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[39.489067]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 39.299617767333984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[38.934135]
 [54.383724]
 [49.205746]
 [30.385746]
 [60.178513]
 [48.622036]
 [44.0078  ]
 [38.943005]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 38.003639221191406



buy possibilites: [-1] 
expected returns: [[28.1945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 60.17851257324219






Player: 1 
cards in hand: [8. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[71.05882]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  0.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [10.  8.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 28.194499969482422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 70.42762 ]
 [ 90.92209 ]
 [ 84.10075 ]
 [ 59.5914  ]
 [ 79.99189 ]
 [ 98.64243 ]
 [ 83.3383  ]
 [109.115814]
 [ 70.51835 ]
 [ 76.83088 ]
 [ 90.86629 ]
 [ 71.01466 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  0.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [10.  8.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 70.70452880859375



buy possibilites: [-1] 
expected returns: [[33.9744]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [11.  0.  0.  3.  3.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [10.  8.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 109.11581420898438






Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [10.  8.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [10.  8.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [10.  8.  0.  0.  3.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  0. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 11.] 
expected returns: [[ 7.358857]
 [23.013279]
 [29.646706]
 [23.013279]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 29. 11.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 8. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 33.97439956665039



action possibilites: [-1. 11. 11.] 
expected returns: [[16.55087 ]
 [36.891117]
 [36.891117]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 11.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  8. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 8. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 27.202510833740234



action possibilites: [-1] 
expected returns: [[25.374302]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  8. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 8. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 45.263038635253906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[27.481375]
 [42.83853 ]
 [38.034912]
 [18.070429]
 [48.857994]
 [37.419804]
 [32.790905]
 [27.690834]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3.] 
cards in discard: [10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  8. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 8. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 25.37430191040039



buy possibilites: [-1] 
expected returns: [[13.899004]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3.] 
cards in discard: [10. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  7.  8. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 8. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 89 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 48.857994079589844






Player: 1 
cards in hand: [3. 8. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 10  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  7.  8. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [10. 11. 29. 11.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  8 10  8] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  7.  8. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [10. 11. 29. 11.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11] -> size -> 16 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  8 10  8] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  7.  8. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [10. 11. 29. 11.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11] -> size -> 16 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  8 10  8  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7.  8. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [10. 11. 29. 11.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11] -> size -> 16 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[39.9388]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [10. 11. 29. 11.  0.  0. 11.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7.  8. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 3. 3. 0.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 10  8  0] -> size -> 11 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 13.899003982543945





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[40.23294 ]
 [57.73071 ]
 [52.235855]
 [30.46334 ]
 [64.07157 ]
 [51.530365]
 [46.124702]
 [40.614136]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [10. 11. 29. 11.  0.  0. 11.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7.  8. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 3. 3. 0.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 10  8  0] -> size -> 11 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 38.515220642089844



buy possibilites: [-1] 
expected returns: [[20.985435]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [10. 11. 29. 11.  0.  0. 11.  3. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  6.  8. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 3. 3. 0.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 10  8  0] -> size -> 11 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 79 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 64.07157897949219






Player: 1 
cards in hand: [0. 8. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 3. 0.] 
cards in discard: [0. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 10  8  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  6.  8. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11] -> size -> 17 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [0. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  8 10  8  0] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  6.  8. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11] -> size -> 17 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  8 10  8  0] -> size -> 8 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  6.  8. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11] -> size -> 17 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0. 8. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  8 10  8  0  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  6.  8. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11] -> size -> 17 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[20.912207]
 [47.10054 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  6.  8. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8 10  8  0  0] -> size -> 9 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 20.985435485839844



action possibilites: [-1. 11.] 
expected returns: [[42.152325]
 [65.48571 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  6.  8. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8 10  8  0  0] -> size -> 9 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 44.496971130371094



action possibilites: [-1] 
expected returns: [[19.920012]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  6.  8. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8 10  8  0  0] -> size -> 9 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 152 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 70.9972152709961





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[22.705938]
 [38.675465]
 [33.634914]
 [14.082695]
 [30.489124]
 [44.47102 ]
 [33.031944]
 [52.52291 ]
 [22.767849]
 [28.000542]
 [38.660027]
 [22.942772]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  6.  8. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8 10  8  0  0] -> size -> 9 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 19.920011520385742



buy possibilites: [-1] 
expected returns: [[18.623064]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  6.  8. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8 10  8  0  0] -> size -> 9 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 253 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 52.52291488647461






Player: 1 
cards in hand: [ 8.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8 10  8  0  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  6.  8. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  0. 11.  0.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29] -> size -> 19 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8 10  8  0  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  6.  8. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  0. 11.  0.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29] -> size -> 19 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 10.  0.] 
cards in discard: [8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8 10  8  0  0  8] -> size -> 10 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  6.  7. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  0. 11.  0.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29] -> size -> 19 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [10.  0.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[36.5124  ]
 [42.63543 ]
 [61.685623]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 11.  0.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  6.  7. 10.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8 10  8  0  0  8] -> size -> 10 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 18.623064041137695



action possibilites: [-1] 
expected returns: [[23.614159]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  6.  7. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8 10  8  0  0  8] -> size -> 10 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 132 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 64.7759017944336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[26.021791]
 [37.301136]
 [33.948715]
 [19.05805 ]
 [42.25463 ]
 [33.331047]
 [30.170471]
 [27.206322]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  6.  7. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8 10  8  0  0  8] -> size -> 10 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 23.614158630371094



buy possibilites: [-1] 
expected returns: [[10.294612]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  5.  7. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8 10  8  0  0  8] -> size -> 10 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 159 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 42.25462341308594






Player: 1 
cards in hand: [0. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8 10  8  0  0  8] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  5.  7. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 11. 11.  3.  0.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10. 11. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11] -> size -> 21 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8 10  8  0  0  8] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  5.  7. 10.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 11. 11.  3.  0.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10. 11. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11] -> size -> 21 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8 10  8  0  0  8 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  5.  7. 10.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 11. 11.  3.  0.] 
adversary cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10. 11. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11] -> size -> 21 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 3. 11. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[ 0.8556447]
 [14.800957 ]
 [14.800957 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 11.  3.  0.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10. 11. 11. 10.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  5.  7. 10.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  8. 10.  8.  0.] 
adversary cards in discard: [29.  0.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  8 10  8  0  0  8 29] -> size -> 11 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 10.294611930847168



action possibilites: [-1] 
expected returns: [[1.6735048]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3.  0.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10. 11. 11. 10.  0.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  5.  7. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  8. 10.  8.  0.] 
adversary cards in discard: [29.  0.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  8 10  8  0  0  8 29] -> size -> 11 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 132 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 15.240287780761719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 1.5428381]
 [-2.2856927]
 [ 2.6226807]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  3.  0.] 
cards in discard: [10. 29. 29. 11.  0.  3.  0.  0. 10. 11. 11. 10.  0.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  5.  7. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  8. 10.  8.  0.] 
adversary cards in discard: [29.  0.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  8 10  8  0  0  8 29] -> size -> 11 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 1.6735048294067383






Player: 1 
cards in hand: [ 0.  8. 10.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.  8.  0.] 
cards in discard: [29.  0.  8.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8 10  8  0  0  8 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  5.  7. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 11. 10.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10] -> size -> 22 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  8 10  8  0  0  8 29] -> size -> 11 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  5.  7. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 11. 10.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10] -> size -> 22 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  8 10  8  0  0  8 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  5.  7. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 11. 10.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10] -> size -> 22 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8. 0. 0.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  8 10  8  0  0  8 29  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  5.  7. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 11. 10.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10] -> size -> 22 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 3. 11. 10.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29.] 
expected returns: [[16.714619]
 [29.084179]
 [19.230701]
 [33.490685]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10.  3. 29.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  5.  7. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  8.  0.  0. 29.] 
adversary cards in discard: [ 0. 10.  0.  8.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  8 10  8  0  0  8 29  0] -> size -> 12 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 2.6226816177368164



action possibilites: [-1. 11. 10. 29.] 
expected returns: [[14.831909]
 [29.051155]
 [18.144672]
 [33.275288]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10.  3. 29.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  5.  7. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  8.  0.  0. 29.] 
adversary cards in discard: [ 0. 10.  0.  8.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  8 10  8  0  0  8 29  0] -> size -> 12 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 33.5087776184082



action possibilites: [-1. 11. 10.] 
expected returns: [[10.338776]
 [20.715603]
 [12.298668]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  5.  7. 10.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  8.  0.  0. 29.] 
adversary cards in discard: [ 0. 10.  0.  8.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  8 10  8  0  0  8 29  0] -> size -> 12 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 33.27528762817383



action possibilites: [-1] 
expected returns: [[29.245346]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  0.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  5.  7. 10.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  8.  0.  0. 29.] 
adversary cards in discard: [ 0. 10.  0.  8.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  8 10  8  0  0  8 29  0] -> size -> 12 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 172 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 23.12303924560547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[31.485397]
 [43.367764]
 [39.940018]
 [24.136015]
 [47.845985]
 [39.282196]
 [35.884224]
 [32.784603]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  0.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  5.  7. 10.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  8.  0.  0. 29.] 
adversary cards in discard: [ 0. 10.  0.  8.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  8 10  8  0  0  8 29  0] -> size -> 12 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: take_action - action -1
Learning step: 0
desired expected reward: 29.245346069335938



buy possibilites: [-1] 
expected returns: [[64.95908]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  0.] 
cards in discard: [10. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  4.  7. 10.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  8.  0.  0. 29.] 
adversary cards in discard: [ 0. 10.  0.  8.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  8 10  8  0  0  8 29  0] -> size -> 12 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0 54  0] 
sum of rewards: 199 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 47.845985412597656






Player: 1 
cards in hand: [ 0.  8.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0.  0. 29.] 
cards in discard: [ 0. 10.  0.  8.  8.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8 10  8  0  0  8 29  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  4.  7. 10.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [29. 10. 10. 11.  0.] 
adversary cards in discard: [10. 11. 29. 29. 11.  3. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11] -> size -> 24 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0.  0. 29.] 
cards in discard: [ 0. 10.  0.  8.  8.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8 10  8  0  0  8 29  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  4.  7. 10.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [29. 10. 10. 11.  0.] 
adversary cards in discard: [10. 11. 29. 29. 11.  3. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11] -> size -> 24 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0.  0. 29.] 
cards in discard: [ 0. 10.  0.  8.  8.  0.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8 10  8  0  0  8 29  0  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  4.  7. 10.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [29. 10. 10. 11.  0.] 
adversary cards in discard: [10. 11. 29. 29. 11.  3. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11] -> size -> 24 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [29. 10. 10. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10. 11.] 
expected returns: [[10.183748]
 [30.284725]
 [13.025982]
 [13.025982]
 [25.027344]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 10. 11.  0.] 
cards in discard: [10. 11. 29. 29. 11.  3. 10.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  4.  7. 10.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8 10  8  0  0  8 29  0  1] -> size -> 13 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 64.9590835571289



action possibilites: [-1. 10. 10. 11.] 
expected returns: [[ 7.9589357]
 [10.420161 ]
 [10.420161 ]
 [19.30079  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11.  0.  0.] 
cards in discard: [10. 11. 29. 29. 11.  3. 10.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  4.  7. 10.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8 10  8  0  0  8 29  0  1] -> size -> 13 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 24.914600372314453



action possibilites: [-1] 
expected returns: [[-4.1724277]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  0.] 
cards in discard: [10. 11. 29. 29. 11.  3. 10.  3.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  4.  7. 10.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8 10  8  0  0  8 29  0  1] -> size -> 13 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 152 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 22.03961181640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-2.188943 ]
 [ 7.8157625]
 [ 5.0307217]
 [-8.19519  ]
 [11.854006 ]
 [ 4.4202795]
 [ 1.6819763]
 [-1.3088055]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  0.] 
cards in discard: [10. 11. 29. 29. 11.  3. 10.  3.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  4.  7. 10.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8 10  8  0  0  8 29  0  1] -> size -> 13 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: -4.172427654266357



buy possibilites: [-1] 
expected returns: [[-16.266472]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  0.] 
cards in discard: [10. 11. 29. 29. 11.  3. 10.  3.  0. 10. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  3.  7. 10.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  8 10  8  0  0  8 29  0  1] -> size -> 13 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 179 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 11.853998184204102






Player: 1 
cards in hand: [0. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  8 10  8  0  0  8 29  0  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  3.  7. 10.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 11. 11.  0.  3.] 
adversary cards in discard: [10. 11. 29. 29. 11.  3. 10.  3.  0. 10. 11. 29. 11. 10. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11] -> size -> 26 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 10  8  0  0  8 29  0  1] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  3.  7. 10.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 11. 11.  0.  3.] 
adversary cards in discard: [10. 11. 29. 29. 11.  3. 10.  3.  0. 10. 11. 29. 11. 10. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11] -> size -> 26 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 10  8  0  0  8 29  0  1] -> size -> 9 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  3.  7. 10.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 11. 11.  0.  3.] 
adversary cards in discard: [10. 11. 29. 29. 11.  3. 10.  3.  0. 10. 11. 29. 11. 10. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11] -> size -> 26 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[23.683643]
 [31.141182]
 [31.141182]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  0.  3.] 
cards in discard: [10. 11. 29. 29. 11.  3. 10.  3.  0. 10. 11. 29. 11. 10. 10.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  3.  7. 10.  6. 10. 10.  3. 10. 10.] 
adversary cards in hand: [10.  1.  0.  8.  0.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 8 10  8  0  0  8 29  0  1] -> size -> 9 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.26647186279297



action possibilites: [-1] 
expected returns: [[5.0716667]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3.] 
cards in discard: [10. 11. 29. 29. 11.  3. 10.  3.  0. 10. 11. 29. 11. 10. 10.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  3.  7. 10.  6. 10. 10.  2. 10. 10.] 
adversary cards in hand: [10.  1.  0.  8.  0.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 8 10  8  0  0  8 29  0  1] -> size -> 9 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 132 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 32.66331100463867





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 0.30213547]
 [ 5.9590015 ]
 [-3.8762429 ]
 [ 5.1048546 ]
 [ 3.8192458 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.] 
cards in discard: [10. 11. 29. 29. 11.  3. 10.  3.  0. 10. 11. 29. 11. 10. 10.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 30. 30.  8. 10. 10.  3.  7. 10.  6. 10. 10.  2. 10. 10.] 
adversary cards in hand: [10.  1.  0.  8.  0.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 8 10  8  0  0  8 29  0  1] -> size -> 9 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 5.071666717529297



buy possibilites: [-1] 
expected returns: [[36.961555]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.] 
cards in discard: [10. 11. 29. 29. 11.  3. 10.  3.  0. 10. 11. 29. 11. 10. 10.  0.  0. 10.
  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8. 10. 10.  3.  7. 10.  6. 10. 10.  2. 10. 10.] 
adversary cards in hand: [10.  1.  0.  8.  0.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 8 10  8  0  0  8 29  0  1] -> size -> 9 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 151 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 5.95899772644043






Player: 1 
cards in hand: [10.  1.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  0.  8.  0.] 
cards in discard: [8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  8  0  0  8 29  0  1] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8. 10. 10.  3.  7. 10.  6. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 10. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3] -> size -> 28 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  0.  8.  0.] 
cards in discard: [8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  8  0  0  8 29  0  1] -> size -> 9 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 28. 30. 29. 30.  8. 10. 10.  3.  7. 10.  6. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 10. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3] -> size -> 28 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  0.  8.  0.] 
cards in discard: [8. 1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  8  0  0  8 29  0  1  1] -> size -> 10 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 29. 30.  8. 10. 10.  3.  7. 10.  6. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 0. 10. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3] -> size -> 28 
adversary victory points: 4
player victory points: 0 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[ 6.389559]
 [ 9.08386 ]
 [19.289051]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8. 10. 10.  3.  7. 10.  6. 10. 10.  2. 10. 10.] 
adversary cards in hand: [ 1.  8.  0. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  8  0  0  8 29  0  1  1] -> size -> 10 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 36.96155548095703



action possibilites: [-1] 
expected returns: [[51.628677]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8. 10. 10.  3.  7. 10.  6. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 1.  8.  0. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  8  0  0  8 29  0  1  1] -> size -> 10 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 162 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 19.955896377563477





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[53.33658 ]
 [66.659874]
 [62.91774 ]
 [44.87639 ]
 [71.69284 ]
 [62.128235]
 [58.38609 ]
 [55.04192 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 27. 30. 29. 30.  8. 10. 10.  3.  7. 10.  6. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 1.  8.  0. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  8  0  0  8 29  0  1  1] -> size -> 10 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 51.62867736816406



buy possibilites: [-1] 
expected returns: [[59.363594]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.] 
cards in discard: [10. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8. 10. 10.  2.  7. 10.  6. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 1.  8.  0. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 10  8  0  0  8 29  0  1  1] -> size -> 10 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 189 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 71.69284057617188






Player: 1 
cards in hand: [ 1.  8.  0. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  0. 29.  8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 10  8  0  0  8 29  0  1  1] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8. 10. 10.  2.  7. 10.  6. 10. 10.  1. 10. 10.] 
adversary cards in hand: [10.  0. 29. 11. 10.] 
adversary cards in discard: [10. 11. 11.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11] -> size -> 30 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0  8 29  0  1] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8. 10. 10.  2.  7. 10.  6. 10. 10.  1. 10. 10.] 
adversary cards in hand: [10.  0. 29. 11. 10.] 
adversary cards in discard: [10. 11. 11.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11] -> size -> 30 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0  8 29  0  1] -> size -> 7 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 27. 30. 29. 30.  8. 10. 10.  2.  7. 10.  6. 10. 10.  1. 10. 10.] 
adversary cards in hand: [10.  0. 29. 11. 10.] 
adversary cards in discard: [10. 11. 11.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11] -> size -> 30 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0  8 29  0  1  0] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8. 10. 10.  2.  7. 10.  6. 10. 10.  1. 10. 10.] 
adversary cards in hand: [10.  0. 29. 11. 10.] 
adversary cards in discard: [10. 11. 11.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11] -> size -> 30 
adversary victory points: 4
player victory points: 0 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [10.  0. 29. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11. 10.] 
expected returns: [[31.778397]
 [35.318813]
 [52.562088]
 [47.832523]
 [35.318813]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29. 11. 10.] 
cards in discard: [10. 11. 11.  0. 10.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 30.  8. 10. 10.  2.  7. 10.  6. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 8.  0. 10.  0.  1.] 
adversary cards in discard: [ 0.  8. 29.] 
adversary owned cards: [10  8  0  8 29  0  1  0] -> size -> 8 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 59.36359405517578



action possibilites: [-1. 10. 11. 10. 10.] 
expected returns: [[38.69017]
 [42.45368]
 [54.48616]
 [42.45368]
 [42.45368]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11. 10. 10.] 
cards in discard: [10. 11. 11.  0. 10.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 29. 30.  8. 10. 10.  2.  7. 10.  6. 10. 10.  1. 10. 10.] 
adversary cards in hand: [ 8.  0. 10.  0.  1.] 
adversary cards in discard: [ 0.  8. 29.] 
adversary owned cards: [10  8  0  8 29  0  1  0] -> size -> 8 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 45.135616302490234



action possibilites: [-1] 
expected returns: [[35.64302]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10. 10.] 
cards in discard: [10. 11. 11.  0. 10.  0.  0. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 29. 30.  8. 10. 10.  2.  7. 10.  6. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 8.  0. 10.  0.  1.] 
adversary cards in discard: [ 0.  8. 29.] 
adversary owned cards: [10  8  0  8 29  0  1  0] -> size -> 8 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 182 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 58.394248962402344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[45.818027]
 [53.466293]
 [37.913403]
 [53.01672 ]
 [46.19953 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10. 10.] 
cards in discard: [10. 11. 11.  0. 10.  0.  0. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 29. 30.  8. 10. 10.  2.  7. 10.  6. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 8.  0. 10.  0.  1.] 
adversary cards in discard: [ 0.  8. 29.] 
adversary owned cards: [10  8  0  8 29  0  1  0] -> size -> 8 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: 35.64302062988281



buy possibilites: [-1] 
expected returns: [[100.06238]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10. 10.] 
cards in discard: [10. 11. 11.  0. 10.  0.  0. 10.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 30.  8. 10. 10.  2.  7. 10.  6. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 8.  0. 10.  0.  1.] 
adversary cards in discard: [ 0.  8. 29.] 
adversary owned cards: [10  8  0  8 29  0  1  0] -> size -> 8 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0  16   0] 
sum of rewards: 201 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 53.466278076171875






Player: 1 
cards in hand: [ 8.  0. 10.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  0.  1.] 
cards in discard: [ 0.  8. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  8 29  0  1  0] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 30.  8. 10. 10.  2.  7. 10.  6. 10. 10.  0. 10. 10.] 
adversary cards in hand: [29. 10.  3. 29. 10.] 
adversary cards in discard: [10. 11. 11.  0. 10.  0.  0. 10.  3. 29. 11. 10.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3] -> size -> 32 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10.  0.  1.] 
cards in discard: [ 0.  8. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  8 29  0  1  0] -> size -> 8 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 27. 30. 28. 30.  8. 10. 10.  2.  7. 10.  6. 10. 10.  0. 10. 10.] 
adversary cards in hand: [29. 10.  3. 29. 10.] 
adversary cards in discard: [10. 11. 11.  0. 10.  0.  0. 10.  3. 29. 11. 10.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3] -> size -> 32 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10.  0.  1.] 
cards in discard: [ 0.  8. 29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  8 29  0  1  0  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 4 
card supply: [25. 27. 30. 28. 30.  8. 10. 10.  2.  7. 10.  6. 10. 10.  0. 10. 10.] 
adversary cards in hand: [29. 10.  3. 29. 10.] 
adversary cards in discard: [10. 11. 11.  0. 10.  0.  0. 10.  3. 29. 11. 10.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3] -> size -> 32 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [29. 10.  3. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 29. 10.] 
expected returns: [[66.28774 ]
 [74.171844]
 [64.46041 ]
 [74.171844]
 [64.46041 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  3. 29. 10.] 
cards in discard: [10. 11. 11.  0. 10.  0.  0. 10.  3. 29. 11. 10.  0. 10. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 28. 30.  8. 10. 10.  2.  7. 10.  6. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  8 29  0  1  0  0] -> size -> 9 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 100.0623779296875



action possibilites: [-1. 10. 10. 11.] 
expected returns: [[61.31147]
 [66.91601]
 [66.91601]
 [86.35385]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10. 11.] 
cards in discard: [10. 11. 11.  0. 10.  0.  0. 10.  3. 29. 11. 10.  0. 10. 10. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 28. 30.  8. 10. 10.  2.  7. 10.  6. 10. 10.  0. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  8 29  0  1  0  0] -> size -> 9 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 69.18098449707031



action possibilites: [-1] 
expected returns: [[43.91349]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10.] 
cards in discard: [10. 11. 11.  0. 10.  0.  0. 10.  3. 29. 11. 10.  0. 10. 10. 29. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 28. 30.  8. 10. 10.  2.  7. 10.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  8 29  0  1  0  0] -> size -> 9 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 249 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 91.88069152832031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[41.27655 ]
 [36.604477]
 [43.29453 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 10.] 
cards in discard: [10. 11. 11.  0. 10.  0.  0. 10.  3. 29. 11. 10.  0. 10. 10. 29. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 28. 30.  8. 10. 10.  2.  7. 10.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  8 29  0  1  0  0] -> size -> 9 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: 43.913490295410156






Player: 1 
cards in hand: [ 0. 29.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.  1.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  8 29  0  1  0  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 28. 30.  8. 10. 10.  2.  7. 10.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3. 11.  3. 11. 11.] 
adversary cards in discard: [10. 11. 11.  0. 10.  0.  0. 10.  3. 29. 11. 10.  0. 10. 10. 29. 15. 29.
 11. 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15] -> size -> 33 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  0.  1.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  8 29  0  1  0  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 27. 30. 28. 30.  8. 10. 10.  2.  7. 10.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3. 11.  3. 11. 11.] 
adversary cards in discard: [10. 11. 11.  0. 10.  0.  0. 10.  3. 29. 11. 10.  0. 10. 10. 29. 15. 29.
 11. 10.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15] -> size -> 33 
adversary victory points: 5
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  3. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11.] 
expected returns: [[14.257854]
 [18.988821]
 [18.988821]
 [18.988821]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3. 11. 11.] 
cards in discard: [10. 11. 11.  0. 10.  0.  0. 10.  3. 29. 11. 10.  0. 10. 10. 29. 15. 29.
 11. 10.  3. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 28. 30.  8. 10. 10.  2.  7. 10.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  0.  8.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  8 29  0  1  0  0] -> size -> 9 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 43.294559478759766



action possibilites: [-1] 
expected returns: [[43.499428]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11. 11.] 
cards in discard: [10. 11. 11.  0. 10.  0.  0. 10.  3. 29. 11. 10.  0. 10. 10. 29. 15. 29.
 11. 10.  3. 10. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 28. 30.  8. 10. 10.  2.  7. 10.  6. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  0.  8.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  8 29  0  1  0  0] -> size -> 9 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 229 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 22.052217483520508





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[43.195114]
 [33.965088]
 [43.57008 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 11. 11.] 
cards in discard: [10. 11. 11.  0. 10.  0.  0. 10.  3. 29. 11. 10.  0. 10. 10. 29. 15. 29.
 11. 10.  3. 10. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 27. 30. 28. 30.  8. 10. 10.  2.  7. 10.  6. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0.  0.  8.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  0  8 29  0  1  0  0] -> size -> 9 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 43.499427795410156






Player: 1 
cards in hand: [ 0.  0.  8.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8.  8. 10.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  8 29  0  1  0  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 28. 30.  8. 10. 10.  2.  7. 10.  6. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  3. 11.] 
adversary cards in discard: [10. 11. 11.  0. 10.  0.  0. 10.  3. 29. 11. 10.  0. 10. 10. 29. 15. 29.
 11. 10.  3. 10. 15. 11.  3.  3. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15] -> size -> 34 
adversary victory points: 5
player victory points: 0 


action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 8. 1.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  0  8 29  0  1  0  0] -> size -> 9 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 28. 30.  8. 10. 10.  2.  7. 10.  6. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  3. 11.] 
adversary cards in discard: [10. 11. 11.  0. 10.  0.  0. 10.  3. 29. 11. 10.  0. 10. 10. 29. 15. 29.
 11. 10.  3. 10. 15. 11.  3.  3. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15] -> size -> 34 
adversary victory points: 5
player victory points: 0 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [10  8 29  1  0  0] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 28. 30.  8. 10. 10.  2.  7. 10.  6. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  3. 11.] 
adversary cards in discard: [10. 11. 11.  0. 10.  0.  0. 10.  3. 29. 11. 10.  0. 10. 10. 29. 15. 29.
 11. 10.  3. 10. 15. 11.  3.  3. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15] -> size -> 34 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [10  8 29  1  0  0] -> size -> 6 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 27. 30. 28. 30.  8. 10. 10.  2.  7. 10.  6. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  3. 11.] 
adversary cards in discard: [10. 11. 11.  0. 10.  0.  0. 10.  3. 29. 11. 10.  0. 10. 10. 29. 15. 29.
 11. 10.  3. 10. 15. 11.  3.  3. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15] -> size -> 34 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [10  8 29  1  0  0  0] -> size -> 7 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 27. 30. 28. 30.  8. 10. 10.  2.  7. 10.  6. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  3. 11.] 
adversary cards in discard: [10. 11. 11.  0. 10.  0.  0. 10.  3. 29. 11. 10.  0. 10. 10. 29. 15. 29.
 11. 10.  3. 10. 15. 11.  3.  3. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15] -> size -> 34 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[49.76084 ]
 [52.376427]
 [69.78076 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3. 11.] 
cards in discard: [10. 11. 11.  0. 10.  0.  0. 10.  3. 29. 11. 10.  0. 10. 10. 29. 15. 29.
 11. 10.  3. 10. 15. 11.  3.  3. 11. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 28. 30.  8. 10. 10.  2.  7. 10.  6. 10. 10.  0. 10.  8.] 
adversary cards in hand: [ 1.  0.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [10  8 29  1  0  0  0] -> size -> 7 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 43.570098876953125



action possibilites: [-1] 
expected returns: [[29.849361]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3.] 
cards in discard: [10. 11. 11.  0. 10.  0.  0. 10.  3. 29. 11. 10.  0. 10. 10. 29. 15. 29.
 11. 10.  3. 10. 15. 11.  3.  3. 11. 11. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 28. 30.  8. 10. 10.  2.  7. 10.  6. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 1.  0.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [10  8 29  1  0  0  0] -> size -> 7 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 229 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 75.26797485351562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[27.246649]
 [34.992775]
 [22.06377 ]
 [34.171997]
 [29.817528]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.] 
cards in discard: [10. 11. 11.  0. 10.  0.  0. 10.  3. 29. 11. 10.  0. 10. 10. 29. 15. 29.
 11. 10.  3. 10. 15. 11.  3.  3. 11. 11. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 27. 30. 28. 30.  8. 10. 10.  2.  7. 10.  6. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 1.  0.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [10  8 29  1  0  0  0] -> size -> 7 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 29.849361419677734



buy possibilites: [-1] 
expected returns: [[41.841934]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.] 
cards in discard: [10. 11. 11.  0. 10.  0.  0. 10.  3. 29. 11. 10.  0. 10. 10. 29. 15. 29.
 11. 10.  3. 10. 15. 11.  3.  3. 11. 11. 15.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 30.  8. 10. 10.  2.  7. 10.  6. 10. 10.  0. 10.  7.] 
adversary cards in hand: [ 1.  0.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [10  8 29  1  0  0  0] -> size -> 7 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0 -10   0   0  16   0] 
sum of rewards: 201 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 34.99277877807617






Player: 1 
cards in hand: [ 1.  0.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 29  1  0  0  0] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 30.  8. 10. 10.  2.  7. 10.  6. 10. 10.  0. 10.  7.] 
adversary cards in hand: [11. 10. 10. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3] -> size -> 36 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 29  1  0  0  0] -> size -> 7 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 27. 30. 27. 30.  8. 10. 10.  2.  7. 10.  6. 10. 10.  0. 10.  7.] 
adversary cards in hand: [11. 10. 10. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3] -> size -> 36 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0.  0. 29.] 
cards in discard: [14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 29  1  0  0  0 14] -> size -> 8 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 27. 30.  8. 10. 10.  2.  7. 10.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [11. 10. 10. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3] -> size -> 36 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [11. 10. 10. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10. 15.] 
expected returns: [[26.3647  ]
 [41.19739 ]
 [28.5099  ]
 [28.5099  ]
 [36.442566]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 10. 15.  0.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 30.  8. 10. 10.  2.  7. 10.  6.  9. 10.  0. 10.  7.] 
adversary cards in hand: [ 0.  0.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8 29  1  0  0  0 14] -> size -> 8 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 41.84193420410156



action possibilites: [-1] 
expected returns: [[13.932394]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 15.  0.] 
cards in discard: [15.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 30.  8. 10. 10.  2.  7. 10.  6.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  0.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8 29  1  0  0  0 14] -> size -> 8 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0 -20   0   0  64   0] 
sum of rewards: 239 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 41.85334014892578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[15.343918]
 [ 9.753521]
 [17.862614]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 15.  0.] 
cards in discard: [15.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 27. 30. 27. 30.  8. 10. 10.  2.  7. 10.  6.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  0.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8 29  1  0  0  0 14] -> size -> 8 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 13.932394027709961






Player: 1 
cards in hand: [ 0.  0.  0.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  8. 10.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 29  1  0  0  0 14] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 27. 30.  8. 10. 10.  2.  7. 10.  6.  9. 10.  0. 10.  6.] 
adversary cards in hand: [11. 11. 15.  3.  3.] 
adversary cards in discard: [15. 11. 10. 10. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15] -> size -> 37 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  8. 10.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 29  1  0  0  0 14] -> size -> 8 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 27. 30. 27. 30.  8. 10. 10.  2.  7. 10.  6.  9. 10.  0. 10.  6.] 
adversary cards in hand: [11. 11. 15.  3.  3.] 
adversary cards in discard: [15. 11. 10. 10. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15] -> size -> 37 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  8. 10.] 
cards in discard: [3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 29  1  0  0  0 14  3] -> size -> 9 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 26. 30.  8. 10. 10.  2.  7. 10.  6.  9. 10.  0. 10.  6.] 
adversary cards in hand: [11. 11. 15.  3.  3.] 
adversary cards in discard: [15. 11. 10. 10. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15] -> size -> 37 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [11. 11. 15.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 15.] 
expected returns: [[55.09111]
 [70.0607 ]
 [70.0607 ]
 [65.43237]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 15.  3.  3.] 
cards in discard: [15. 11. 10. 10. 15.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8. 10. 10.  2.  7. 10.  6.  9. 10.  0. 10.  6.] 
adversary cards in hand: [ 0.  8. 14.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [10  8 29  1  0  0  0 14  3] -> size -> 9 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 17.86261749267578



action possibilites: [-1] 
expected returns: [[65.6112]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15.  3.  3.] 
cards in discard: [15. 11. 10. 10. 15.  0. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8. 10. 10.  2.  7. 10.  6.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 0.  8. 14.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [10  8 29  1  0  0  0 14  3] -> size -> 9 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0 -30   0   0  64   0] 
sum of rewards: 199 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 71.70953369140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[54.833786]
 [50.59599 ]
 [63.631653]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 15.  3.  3.] 
cards in discard: [15. 11. 10. 10. 15.  0. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8. 10. 10.  2.  7. 10.  6.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 0.  8. 14.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [10  8 29  1  0  0  0 14  3] -> size -> 9 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 65.61119842529297






Player: 1 
cards in hand: [ 0.  8. 14.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 29.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 14.  1. 29.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 29  1  0  0  0 14  3] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8. 10. 10.  2.  7. 10.  6.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 3. 11. 10. 11.  0.] 
adversary cards in discard: [15. 11. 10. 10. 15.  0. 15. 11. 11. 15.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15] -> size -> 38 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  1. 29.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [10  8 29  1  0  0  0 14  3] -> size -> 9 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 27. 30. 26. 30.  8. 10. 10.  2.  7. 10.  6.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 3. 11.  0.] 
adversary cards in discard: [15. 11. 10. 10. 15.  0. 15. 11. 11. 15.  3.  3. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15] -> size -> 38 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  1. 29.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [10  8 29  1  0  0  0 14  3] -> size -> 9 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 27. 30. 26. 30.  8. 10. 10.  2.  7. 10.  6.  9. 10.  0. 10.  5.] 
adversary cards in hand: [ 3. 11.  0.] 
adversary cards in discard: [15. 11. 10. 10. 15.  0. 15. 11. 11. 15.  3.  3. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15] -> size -> 38 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  1. 29.] 
cards in discard: [23.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [10  8 29  1  0  0  0 14  3 23] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8. 10. 10.  2.  7. 10.  6.  9.  9.  0. 10.  5.] 
adversary cards in hand: [ 3. 11.  0.] 
adversary cards in discard: [15. 11. 10. 10. 15.  0. 15. 11. 11. 15.  3.  3. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15] -> size -> 38 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[105.84787]
 [116.41327]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.] 
cards in discard: [15. 11. 10. 10. 15.  0. 15. 11. 11. 15.  3.  3. 11. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8. 10. 10.  2.  7. 10.  6.  9.  9.  0. 10.  5.] 
adversary cards in hand: [14.  3.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8 29  1  0  0  0 14  3 23] -> size -> 10 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0 -30   0   0 920   0] 
sum of rewards: 1035 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 58.42228698730469



action possibilites: [-1] 
expected returns: [[35.631054]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [15. 11. 10. 10. 15.  0. 15. 11. 11. 15.  3.  3. 11. 10. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8. 10. 10.  2.  7. 10.  6.  9.  9.  0. 10.  4.] 
adversary cards in hand: [14.  3.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8 29  1  0  0  0 14  3 23] -> size -> 10 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0 -40   0   0  64   0] 
sum of rewards: 189 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 118.56696319580078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[31.106659]
 [26.50711 ]
 [35.85028 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [15. 11. 10. 10. 15.  0. 15. 11. 11. 15.  3.  3. 11. 10. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 27. 30. 26. 30.  8. 10. 10.  2.  7. 10.  6.  9.  9.  0. 10.  4.] 
adversary cards in hand: [14.  3.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8 29  1  0  0  0 14  3 23] -> size -> 10 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 35.63105392456055






Player: 1 
cards in hand: [14.  3.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 29  1  0  0  0 14  3 23] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8. 10. 10.  2.  7. 10.  6.  9.  9.  0. 10.  4.] 
adversary cards in hand: [ 0. 10. 10. 15.  3.] 
adversary cards in discard: [15. 11. 10. 10. 15.  0. 15. 11. 11. 15.  3.  3. 11. 10. 15. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15] -> size -> 39 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [10  8 29  1  0  0  0 14  3 23] -> size -> 10 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 27. 30. 26. 30.  8. 10. 10.  2.  7. 10.  6.  9.  9.  0. 10.  4.] 
adversary cards in hand: [10. 15.  3.] 
adversary cards in discard: [15. 11. 10. 10. 15.  0. 15. 11. 11. 15.  3.  3. 11. 10. 15. 11.  3.  0.
  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15] -> size -> 39 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [10  8 29  1  0  0  0 14  3 23] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 27. 30. 26. 30.  8. 10. 10.  2.  7. 10.  6.  9.  9.  0. 10.  4.] 
adversary cards in hand: [10. 15.  3.] 
adversary cards in discard: [15. 11. 10. 10. 15.  0. 15. 11. 11. 15.  3.  3. 11. 10. 15. 11.  3.  0.
  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15] -> size -> 39 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.] 
cards in discard: [16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [10  8 29  1  0  0  0 14  3 23 16] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8. 10.  9.  2.  7. 10.  6.  9.  9.  0. 10.  4.] 
adversary cards in hand: [10. 15.  3.] 
adversary cards in discard: [15. 11. 10. 10. 15.  0. 15. 11. 11. 15.  3.  3. 11. 10. 15. 11.  3.  0.
  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15] -> size -> 39 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [10. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
expected returns: [[148.80649]
 [145.65247]
 [154.32362]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  3.] 
cards in discard: [15. 11. 10. 10. 15.  0. 15. 11. 11. 15.  3.  3. 11. 10. 15. 11.  3.  0.
  0. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8. 10.  9.  2.  7. 10.  6.  9.  9.  0. 10.  4.] 
adversary cards in hand: [29.  8. 23.  1.  0.] 
adversary cards in discard: [16. 14.  3.  0.  0. 10.] 
adversary owned cards: [10  8 29  1  0  0  0 14  3 23 16] -> size -> 11 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0 -40   0   0 984   0] 
sum of rewards: 1089 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 172.41651916503906



action possibilites: [-1] 
expected returns: [[118.15668]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.] 
cards in discard: [15. 11. 10. 10. 15.  0. 15. 11. 11. 15.  3.  3. 11. 10. 15. 11.  3.  0.
  0. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8. 10.  9.  2.  7. 10.  6.  9.  9.  0. 10.  4.] 
adversary cards in hand: [29.  8. 23.  1.  0.] 
adversary cards in discard: [16. 14.  3.  0.  0. 10.] 
adversary owned cards: [10  8 29  1  0  0  0 14  3 23 16] -> size -> 11 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 154.32363891601562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[109.05378]
 [101.16159]
 [120.10073]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.] 
cards in discard: [15. 11. 10. 10. 15.  0. 15. 11. 11. 15.  3.  3. 11. 10. 15. 11.  3.  0.
  0. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8. 10.  9.  2.  7. 10.  6.  9.  9.  0. 10.  4.] 
adversary cards in hand: [29.  8. 23.  1.  0.] 
adversary cards in discard: [16. 14.  3.  0.  0. 10.] 
adversary owned cards: [10  8 29  1  0  0  0 14  3 23 16] -> size -> 11 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 118.15667724609375






Player: 1 
cards in hand: [29.  8. 23.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8. 23.  1.  0.] 
cards in discard: [16. 14.  3.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 29  1  0  0  0 14  3 23 16] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8. 10.  9.  2.  7. 10.  6.  9.  9.  0. 10.  4.] 
adversary cards in hand: [ 3.  0.  3. 29.  0.] 
adversary cards in discard: [15. 11. 10. 10. 15.  0. 15. 11. 11. 15.  3.  3. 11. 10. 15. 11.  3.  0.
  0. 10. 15. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15] -> size -> 39 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1. 29.  8. 14.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  1.  0. 14.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [23.] 
owned cards: [10  8 29  1  0  0  0 14  3 23 16] -> size -> 11 
action values: 1 
buys: 1 
player value: 1 
card supply: [24. 27. 30. 26. 30.  8. 10.  9.  2.  7. 10.  6.  9.  9.  0. 10.  4.] 
adversary cards in hand: [ 3.  0.  3. 29.  0.] 
adversary cards in discard: [15. 11. 10. 10. 15.  0. 15. 11. 11. 15.  3.  3. 11. 10. 15. 11.  3.  0.
  0. 10. 15. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15] -> size -> 39 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 0. 3.] 
cards in discard: [14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [23. 29.] 
owned cards: [10  8 29  1  0  0  0 14  3 23 16] -> size -> 11 
action values: 1 
buys: 1 
player value: 2 
card supply: [24. 27. 30. 26. 30.  8. 10.  9.  2.  7. 10.  6.  9.  9.  0. 10.  4.] 
adversary cards in hand: [ 3.  0.  3. 29.  0.] 
adversary cards in discard: [15. 11. 10. 10. 15.  0. 15. 11. 11. 15.  3.  3. 11. 10. 15. 11.  3.  0.
  0. 10. 15. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15] -> size -> 39 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0. 3.] 
cards in discard: [14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [23. 29.] 
owned cards: [10  8 29  1  0  0  0 14  3 23 16] -> size -> 11 
action values: 0 
buys: 2 
player value: 5 
card supply: [24. 27. 30. 26. 30.  8. 10.  9.  2.  7. 10.  6.  9.  9.  0. 10.  4.] 
adversary cards in hand: [ 3.  0.  3. 29.  0.] 
adversary cards in discard: [15. 11. 10. 10. 15.  0. 15. 11. 11. 15.  3.  3. 11. 10. 15. 11.  3.  0.
  0. 10. 15. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15] -> size -> 39 
adversary victory points: 6
player victory points: 1 


buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0. 3.] 
cards in discard: [14.  4.] 
cards in deck: 4 
card top of deck: [] 
played cards: [23. 29.] 
owned cards: [10  8 29  1  0  0  0 14  3 23 16  4] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 27. 30. 26. 29.  8. 10.  9.  2.  7. 10.  6.  9.  9.  0. 10.  4.] 
adversary cards in hand: [ 3.  0.  3. 29.  0.] 
adversary cards in discard: [15. 11. 10. 10. 15.  0. 15. 11. 11. 15.  3.  3. 11. 10. 15. 11.  3.  0.
  0. 10. 15. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15] -> size -> 39 
adversary victory points: 6
player victory points: 4 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[11.349342]
 [14.305515]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 29.  0.] 
cards in discard: [15. 11. 10. 10. 15.  0. 15. 11. 11. 15.  3.  3. 11. 10. 15. 11.  3.  0.
  0. 10. 15. 10.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 29.  8. 10.  9.  2.  7. 10.  6.  9.  9.  0. 10.  4.] 
adversary cards in hand: [23. 16.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8 29  1  0  0  0 14  3 23 16  4] -> size -> 12 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 120.10075378417969



action possibilites: [-1.] 
expected returns: [[2.2002945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [15. 11. 10. 10. 15.  0. 15. 11. 11. 15.  3.  3. 11. 10. 15. 11.  3.  0.
  0. 10. 15. 10.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 26. 29.  8. 10.  9.  2.  7. 10.  6.  9.  9.  0. 10.  4.] 
adversary cards in hand: [23. 16.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8 29  1  0  0  0 14  3 23 16  4] -> size -> 12 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 12.659896850585938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
expected returns: [[ 4.441228  ]
 [-0.39448524]
 [ 0.87802744]
 [ 7.895397  ]
 [ 1.7151909 ]
 [-1.0878084 ]
 [ 1.002182  ]
 [-2.017757  ]
 [ 4.5117674 ]
 [-0.24789906]
 [ 4.9014606 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [15. 11. 10. 10. 15.  0. 15. 11. 11. 15.  3.  3. 11. 10. 15. 11.  3.  0.
  0. 10. 15. 10.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 27. 30. 26. 29.  8. 10.  9.  2.  7. 10.  6.  9.  9.  0. 10.  4.] 
adversary cards in hand: [23. 16.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8 29  1  0  0  0 14  3 23 16  4] -> size -> 12 
adversary victory points: 4
player victory points: 6 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 2.2002944946289062



buy possibilites: [-1] 
expected returns: [[17.655195]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [15. 11. 10. 10. 15.  0. 15. 11. 11. 15.  3.  3. 11. 10. 15. 11.  3.  0.
  0. 10. 15. 10.  3.  3.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6] -> size -> 40 
action values: 0 
buys: 0 
player value: 4 
card supply: [24. 27. 30. 26. 29.  8.  9.  9.  2.  7. 10.  6.  9.  9.  0. 10.  4.] 
adversary cards in hand: [23. 16.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  8 29  1  0  0  0 14  3 23 16  4] -> size -> 12 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[  -5.    0.    0.   30.    0.    0.   20.    0.    0.    0.    0.  -50.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: 0
desired expected reward: 7.895394325256348






Player: 1 
cards in hand: [23. 16.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 16. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23. 16.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [10  8 29  1  0  0  0 14  3 23 16  4] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 29.  8.  9.  9.  2.  7. 10.  6.  9.  9.  0. 10.  4.] 
adversary cards in hand: [11. 10.  0. 29. 10.] 
adversary cards in discard: [15. 11. 10. 10. 15.  0. 15. 11. 11. 15.  3.  3. 11. 10. 15. 11.  3.  0.
  0. 10. 15. 10.  3.  3.  6. 29.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6] -> size -> 40 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1. 23. 16.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23. 16.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8 29  1  0  0  0 14  3 23 16  4] -> size -> 12 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 29.  8.  9.  9.  2.  7. 10.  6.  9.  9.  0. 10.  4.] 
adversary cards in hand: [11. 10.  0. 29. 10.] 
adversary cards in discard: [15. 11. 10. 10. 15.  0. 15. 11. 11. 15.  3.  3. 11. 10. 15. 11.  3.  0.
  0. 10. 15. 10.  3.  3.  6. 29.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6] -> size -> 40 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0.  0.] 
cards in discard: [1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [10 29  1  0  0  0 14  3 23 16  4  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 26. 29.  8.  9.  9.  2.  7. 10.  6.  9.  9.  0. 10.  4.] 
adversary cards in hand: [11. 10.  0. 29. 10.] 
adversary cards in discard: [15. 11. 10. 10. 15.  0. 15. 11. 11. 15.  3.  3. 11. 10. 15. 11.  3.  0.
  0. 10. 15. 10.  3.  3.  6. 29.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6] -> size -> 40 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 16. 23.] 
owned cards: [10 29  1  0  0  0 14  3 23 16  4  1] -> size -> 12 
action values: 1 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 26. 29.  8.  9.  9.  2.  7. 10.  6.  9.  9.  0. 10.  4.] 
adversary cards in hand: [11. 10.  0. 29. 10.] 
adversary cards in discard: [15. 11. 10. 10. 15.  0. 15. 11. 11. 15.  3.  3. 11. 10. 15. 11.  3.  0.
  0. 10. 15. 10.  3.  3.  6. 29.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6] -> size -> 40 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 16. 23.] 
owned cards: [10 29  1  0  0  0 14  3 23 16  4  1] -> size -> 12 
action values: 0 
buys: 2 
player value: 4 
card supply: [24. 26. 30. 26. 29.  8.  9.  9.  2.  7. 10.  6.  9.  9.  0. 10.  4.] 
adversary cards in hand: [11. 10.  0. 29. 10.] 
adversary cards in discard: [15. 11. 10. 10. 15.  0. 15. 11. 11. 15.  3.  3. 11. 10. 15. 11.  3.  0.
  0. 10. 15. 10.  3.  3.  6. 29.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6] -> size -> 40 
adversary victory points: 5
player victory points: 4 


buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [1. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 16. 23.] 
owned cards: [10 29  1  0  0  0 14  3 23 16  4  1  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 26. 30. 26. 29.  8.  9.  9.  2.  7. 10.  6.  9.  9.  0. 10.  4.] 
adversary cards in hand: [11. 10.  0. 29. 10.] 
adversary cards in discard: [15. 11. 10. 10. 15.  0. 15. 11. 11. 15.  3.  3. 11. 10. 15. 11.  3.  0.
  0. 10. 15. 10.  3.  3.  6. 29.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6] -> size -> 40 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 1.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10. 16. 23.] 
owned cards: [10 29  1  0  0  0 14  3 23 16  4  1  0 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 26. 29.  8.  9.  9.  1.  7. 10.  6.  9.  9.  0. 10.  4.] 
adversary cards in hand: [11. 10.  0. 29. 10.] 
adversary cards in discard: [15. 11. 10. 10. 15.  0. 15. 11. 11. 15.  3.  3. 11. 10. 15. 11.  3.  0.
  0. 10. 15. 10.  3.  3.  6. 29.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6] -> size -> 40 
adversary victory points: 5
player victory points: 4 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [11. 10.  0. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29. 10.] 
expected returns: [[-16.131285]
 [-11.746826]
 [-16.692122]
 [-10.61516 ]
 [-16.692122]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0. 29. 10.] 
cards in discard: [15. 11. 10. 10. 15.  0. 15. 11. 11. 15.  3.  3. 11. 10. 15. 11.  3.  0.
  0. 10. 15. 10.  3.  3.  6. 29.  0.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 29.  8.  9.  9.  1.  7. 10.  6.  9.  9.  0. 10.  4.] 
adversary cards in hand: [ 3.  4.  1. 14. 29.] 
adversary cards in discard: [ 1.  0. 11. 10. 16. 23.  0.  0.  0.] 
adversary owned cards: [10 29  1  0  0  0 14  3 23 16  4  1  0 11] -> size -> 14 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 17.655195236206055



action possibilites: [-1. 11. 10. 10. 10.] 
expected returns: [[47.20149]
 [67.63668]
 [46.31368]
 [46.31368]
 [46.31368]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 10. 10.] 
cards in discard: [15. 11. 10. 10. 15.  0. 15. 11. 11. 15.  3.  3. 11. 10. 15. 11.  3.  0.
  0. 10. 15. 10.  3.  3.  6. 29.  0.  3.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 26. 29.  8.  9.  9.  1.  7. 10.  6.  9.  9.  0. 10.  4.] 
adversary cards in hand: [ 3.  4.  1. 14. 29.] 
adversary cards in discard: [ 1.  0. 11. 10. 16. 23.  0.  0.  0.] 
adversary owned cards: [10 29  1  0  0  0 14  3 23 16  4  1  0 11] -> size -> 14 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -14.186732292175293



action possibilites: [-1] 
expected returns: [[-9.4800415]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10.] 
cards in discard: [15. 11. 10. 10. 15.  0. 15. 11. 11. 15.  3.  3. 11. 10. 15. 11.  3.  0.
  0. 10. 15. 10.  3.  3.  6. 29.  0.  3.  0.  0.  0. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 26. 29.  8.  9.  9.  1.  7. 10.  6.  9.  9.  0. 10.  3.] 
adversary cards in hand: [ 3.  4.  1. 14. 29.] 
adversary cards in discard: [ 1.  0. 11. 10. 16. 23.  0.  0.  0.] 
adversary owned cards: [10 29  1  0  0  0 14  3 23 16  4  1  0 11] -> size -> 14 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0  30   0   0  40   0   0   0   0 -60   0   0  64   0] 
sum of rewards: 69 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 72.08132934570312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-13.004074]
 [-15.683477]
 [ -9.48003 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 10.] 
cards in discard: [15. 11. 10. 10. 15.  0. 15. 11. 11. 15.  3.  3. 11. 10. 15. 11.  3.  0.
  0. 10. 15. 10.  3.  3.  6. 29.  0.  3.  0.  0.  0. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 26. 30. 26. 29.  8.  9.  9.  1.  7. 10.  6.  9.  9.  0. 10.  3.] 
adversary cards in hand: [ 3.  4.  1. 14. 29.] 
adversary cards in discard: [ 1.  0. 11. 10. 16. 23.  0.  0.  0.] 
adversary owned cards: [10 29  1  0  0  0 14  3 23 16  4  1  0 11] -> size -> 14 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: -9.48004150390625






Player: 1 
cards in hand: [ 3.  4.  1. 14. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  4.  1. 14. 29.] 
cards in discard: [ 1.  0. 11. 10. 16. 23.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10 29  1  0  0  0 14  3 23 16  4  1  0 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 29.  8.  9.  9.  1.  7. 10.  6.  9.  9.  0. 10.  3.] 
adversary cards in hand: [10. 10. 11. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15] -> size -> 41 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  4.  1. 29.] 
cards in discard: [ 1.  0. 11. 10. 16. 23.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [10 29  1  0  0  0 14  3 23 16  4  1  0 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 26. 30. 26. 29.  8.  9.  9.  1.  7. 10.  6.  9.  9.  0. 10.  3.] 
adversary cards in hand: [10. 10. 11.] 
adversary cards in discard: [11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15] -> size -> 41 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  4.  1. 29.] 
cards in discard: [ 1.  0. 11. 10. 16. 23.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [10 29  1  0  0  0 14  3 23 16  4  1  0 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 26. 30. 26. 29.  8.  9.  9.  1.  7. 10.  6.  9.  9.  0. 10.  3.] 
adversary cards in hand: [10. 10. 11.] 
adversary cards in discard: [11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15] -> size -> 41 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  4.  1. 29.] 
cards in discard: [ 1.  0. 11. 10. 16. 23.  0.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [10 29  1  0  0  0 14  3 23 16  4  1  0 11  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 26. 30. 26. 29.  8.  9.  9.  1.  6. 10.  6.  9.  9.  0. 10.  3.] 
adversary cards in hand: [10. 10. 11.] 
adversary cards in discard: [11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15] -> size -> 41 
adversary victory points: 5
player victory points: 4 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [10. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.] 
expected returns: [[ 96.20107]
 [ 92.1903 ]
 [ 92.1903 ]
 [105.8425 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11.] 
cards in discard: [11. 29.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 29.  8.  9.  9.  1.  6. 10.  6.  9.  9.  0. 10.  3.] 
adversary cards in hand: [ 0. 11. 10. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [10 29  1  0  0  0 14  3 23 16  4  1  0 11  8] -> size -> 15 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[  -5    0    0   30    0    0    0    0    0    0    0  -60    0 -300
 1021    0] 
sum of rewards: 686 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 55.86125946044922



action possibilites: [-1] 
expected returns: [[66.033646]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.] 
cards in discard: [11. 29. 15.] 
cards in deck: 36 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 29.  8.  9.  9.  1.  6. 10.  6.  9.  9.  0. 10.  2.] 
adversary cards in hand: [ 0. 11. 10. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [10 29  1  0  0  0 14  3 23 16  4  1  0 11  8] -> size -> 15 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0 -70   0   0  64   0] 
sum of rewards: 39 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 111.77567291259766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[62.13124 ]
 [56.86556 ]
 [65.724655]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.] 
cards in discard: [11. 29. 15.] 
cards in deck: 36 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15] -> size -> 42 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 26. 30. 26. 29.  8.  9.  9.  1.  6. 10.  6.  9.  9.  0. 10.  2.] 
adversary cards in hand: [ 0. 11. 10. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [10 29  1  0  0  0 14  3 23 16  4  1  0 11  8] -> size -> 15 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 66.03364562988281






Player: 1 
cards in hand: [ 0. 11. 10. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10. 29.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [10 29  1  0  0  0 14  3 23 16  4  1  0 11  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 29.  8.  9.  9.  1.  6. 10.  6.  9.  9.  0. 10.  2.] 
adversary cards in hand: [29.  3.  6. 10.  3.] 
adversary cards in discard: [11. 29. 15. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15] -> size -> 42 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 29.  3.] 
cards in discard: [16.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [10 29  1  0  0  0 14  3 23 16  4  1  0 11  8 16] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 29.  8.  9.  8.  1.  6. 10.  6.  9.  9.  0. 10.  2.] 
adversary cards in hand: [29.  3.  6. 10.  3.] 
adversary cards in discard: [11. 29. 15. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15] -> size -> 42 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 29.  3.] 
cards in discard: [16.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [10 29  1  0  0  0 14  3 23 16  4  1  0 11  8 16] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 26. 30. 26. 29.  8.  9.  8.  1.  6. 10.  6.  9.  9.  0. 10.  2.] 
adversary cards in hand: [29.  3.  6. 10.  3.] 
adversary cards in discard: [11. 29. 15. 11. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15] -> size -> 42 
adversary victory points: 5
player victory points: 4 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [29.  3.  6. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[ 97.644646]
 [111.547104]
 [ 97.961754]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  6. 10.  3.] 
cards in discard: [11. 29. 15. 11. 10. 10.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 29.  8.  9.  8.  1.  6. 10.  6.  9.  9.  0. 10.  2.] 
adversary cards in hand: [ 0. 14. 16. 23.  1.] 
adversary cards in discard: [16. 11.  0. 10. 29.  3.] 
adversary owned cards: [10 29  1  0  0  0 14  3 23 16  4  1  0 11  8 16] -> size -> 16 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 65.7246322631836



action possibilites: [-1. 10.] 
expected returns: [[129.46745]
 [128.41568]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  3.  3.] 
cards in discard: [11. 29. 15. 11. 10. 10.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15] -> size -> 42 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 26. 29.  8.  9.  8.  1.  6. 10.  6.  9.  9.  0. 10.  2.] 
adversary cards in hand: [ 0. 14. 16. 23.  1.] 
adversary cards in discard: [16. 11.  0. 10. 29.  3.] 
adversary owned cards: [10 29  1  0  0  0 14  3 23 16  4  1  0 11  8 16] -> size -> 16 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 103.9592056274414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[123.51205]
 [116.65529]
 [130.90652]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  3.  3.] 
cards in discard: [11. 29. 15. 11. 10. 10.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15] -> size -> 42 
action values: 1 
buys: 1 
player value: 1 
card supply: [23. 26. 30. 26. 29.  8.  9.  8.  1.  6. 10.  6.  9.  9.  0. 10.  2.] 
adversary cards in hand: [ 0. 14. 16. 23.  1.] 
adversary cards in discard: [16. 11.  0. 10. 29.  3.] 
adversary owned cards: [10 29  1  0  0  0 14  3 23 16  4  1  0 11  8 16] -> size -> 16 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 129.4674530029297






Player: 1 
cards in hand: [ 0. 14. 16. 23.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16. 23.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 16. 23.  1.] 
cards in discard: [16. 11.  0. 10. 29.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10 29  1  0  0  0 14  3 23 16  4  1  0 11  8 16] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 29.  8.  9.  8.  1.  6. 10.  6.  9.  9.  0. 10.  2.] 
adversary cards in hand: [ 3. 11.  0. 10.  0.] 
adversary cards in discard: [11. 29. 15. 11. 10. 10.  3. 29.  6. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15] -> size -> 42 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 23.  1.] 
cards in discard: [16. 11.  0. 10. 29.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [10 29  1  0  0  0 14  3 23 16  4  1  0 11  8 16] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 26. 30. 26. 29.  8.  9.  8.  1.  6. 10.  6.  9.  9.  0. 10.  2.] 
adversary cards in hand: [ 3. 11.  0.] 
adversary cards in discard: [11. 29. 15. 11. 10. 10.  3. 29.  6. 10.  3.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15] -> size -> 42 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16. 23.  1.] 
cards in discard: [16. 11.  0. 10. 29.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [10 29  1  0  0  0 14  3 23 16  4  1  0 11  8 16] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 26. 30. 26. 29.  8.  9.  8.  1.  6. 10.  6.  9.  9.  0. 10.  2.] 
adversary cards in hand: [ 3. 11.  0.] 
adversary cards in discard: [11. 29. 15. 11. 10. 10.  3. 29.  6. 10.  3.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15] -> size -> 42 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16. 23.  1.] 
cards in discard: [16. 11.  0. 10. 29.  3. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [10 29  1  0  0  0 14  3 23 16  4  1  0 11  8 16 16] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 26. 29.  8.  9.  7.  1.  6. 10.  6.  9.  9.  0. 10.  2.] 
adversary cards in hand: [ 3. 11.  0.] 
adversary cards in discard: [11. 29. 15. 11. 10. 10.  3. 29.  6. 10.  3.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15] -> size -> 42 
adversary victory points: 5
player victory points: 4 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[189.32095]
 [184.69618]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.] 
cards in discard: [11. 29. 15. 11. 10. 10.  3. 29.  6. 10.  3.  3.  0. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 29.  8.  9.  7.  1.  6. 10.  6.  9.  9.  0. 10.  2.] 
adversary cards in hand: [0. 0. 1. 4. 8.] 
adversary cards in discard: [16. 11.  0. 10. 29.  3. 16. 14.  0. 16. 23.  1.] 
adversary owned cards: [10 29  1  0  0  0 14  3 23 16  4  1  0 11  8 16 16] -> size -> 17 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[  -5    0    0   30    0    0    0    0    0    0    0  -70    0 -300
 1085    0] 
sum of rewards: 740 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -11.714393615722656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[179.56824]
 [175.6352 ]
 [193.47939]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.] 
cards in discard: [11. 29. 15. 11. 10. 10.  3. 29.  6. 10.  3.  3.  0. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 26. 30. 26. 29.  8.  9.  7.  1.  6. 10.  6.  9.  9.  0. 10.  2.] 
adversary cards in hand: [0. 0. 1. 4. 8.] 
adversary cards in discard: [16. 11.  0. 10. 29.  3. 16. 14.  0. 16. 23.  1.] 
adversary owned cards: [10 29  1  0  0  0 14  3 23 16  4  1  0 11  8 16 16] -> size -> 17 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 189.3209686279297



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 1. 4. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 4. 8.] 
cards in discard: [16. 11.  0. 10. 29.  3. 16. 14.  0. 16. 23.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10 29  1  0  0  0 14  3 23 16  4  1  0 11  8 16 16] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 29.  8.  9.  7.  1.  6. 10.  6.  9.  9.  0. 10.  2.] 
adversary cards in hand: [11. 15. 11.  0. 10.] 
adversary cards in discard: [11. 29. 15. 11. 10. 10.  3. 29.  6. 10.  3.  3.  0. 10.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15] -> size -> 42 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 4.] 
cards in discard: [16. 11.  0. 10. 29.  3. 16. 14.  0. 16. 23.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 29  0  0  0 14  3 23 16  4  1  0 11  8 16 16] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 29.  8.  9.  7.  1.  6. 10.  6.  9.  9.  0. 10.  2.] 
adversary cards in hand: [11. 15. 11.  0. 10.] 
adversary cards in discard: [11. 29. 15. 11. 10. 10.  3. 29.  6. 10.  3.  3.  0. 10.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15] -> size -> 42 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 4.] 
cards in discard: [16. 11.  0. 10. 29.  3. 16. 14.  0. 16. 23.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 29  0  0  0 14  3 23 16  4  1  0 11  8 16 16] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 26. 30. 26. 29.  8.  9.  7.  1.  6. 10.  6.  9.  9.  0. 10.  2.] 
adversary cards in hand: [11. 15. 11.  0. 10.] 
adversary cards in discard: [11. 29. 15. 11. 10. 10.  3. 29.  6. 10.  3.  3.  0. 10.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15] -> size -> 42 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 4.] 
cards in discard: [16. 11.  0. 10. 29.  3. 16. 14.  0. 16. 23.  1.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 29  0  0  0 14  3 23 16  4  1  0 11  8 16 16  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 29.  8.  9.  7.  1.  5. 10.  6.  9.  9.  0. 10.  2.] 
adversary cards in hand: [11. 15. 11.  0. 10.] 
adversary cards in discard: [11. 29. 15. 11. 10. 10.  3. 29.  6. 10.  3.  3.  0. 10.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15] -> size -> 42 
adversary victory points: 5
player victory points: 4 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [11. 15. 11.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 11. 10.] 
expected returns: [[91.230865]
 [84.75665 ]
 [82.773834]
 [84.75665 ]
 [82.678856]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15. 11.  0. 10.] 
cards in discard: [11. 29. 15. 11. 10. 10.  3. 29.  6. 10.  3.  3.  0. 10.  3. 11.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 29.  8.  9.  7.  1.  5. 10.  6.  9.  9.  0. 10.  2.] 
adversary cards in hand: [11. 16. 14.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [10 29  0  0  0 14  3 23 16  4  1  0 11  8 16 16  8] -> size -> 17 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 193.47943115234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[79.70341]
 [80.85083]
 [90.92647]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 15. 11.  0. 10.] 
cards in discard: [11. 29. 15. 11. 10. 10.  3. 29.  6. 10.  3.  3.  0. 10.  3. 11.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 26. 30. 26. 29.  8.  9.  7.  1.  5. 10.  6.  9.  9.  0. 10.  2.] 
adversary cards in hand: [11. 16. 14.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [10 29  0  0  0 14  3 23 16  4  1  0 11  8 16 16  8] -> size -> 17 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 91.23085021972656



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11. 16. 14.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16. 14. 16.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 16. 14.  0. 16.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [10 29  0  0  0 14  3 23 16  4  1  0 11  8 16 16  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 26. 29.  8.  9.  7.  1.  5. 10.  6.  9.  9.  0. 10.  2.] 
adversary cards in hand: [11. 15.  3. 15. 15.] 
adversary cards in discard: [11. 29. 15. 11. 10. 10.  3. 29.  6. 10.  3.  3.  0. 10.  3. 11.  0. 11.
 15. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15] -> size -> 42 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 16.  0. 16.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [10 29  0  0  0 14  3 23 16  4  1  0 11  8 16 16  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 26. 30. 26. 29.  8.  9.  7.  1.  5. 10.  6.  9.  9.  0. 10.  2.] 
adversary cards in hand: [ 3. 15. 15.] 
adversary cards in discard: [11. 29. 15. 11. 10. 10.  3. 29.  6. 10.  3.  3.  0. 10.  3. 11.  0. 11.
 15. 11.  0. 10. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15] -> size -> 42 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 16.  0. 16.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [10 29  0  0  0 14  3 23 16  4  1  0 11  8 16 16  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 26. 30. 26. 29.  8.  9.  7.  1.  5. 10.  6.  9.  9.  0. 10.  2.] 
adversary cards in hand: [ 3. 15. 15.] 
adversary cards in discard: [11. 29. 15. 11. 10. 10.  3. 29.  6. 10.  3.  3.  0. 10.  3. 11.  0. 11.
 15. 11.  0. 10. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15] -> size -> 42 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 16.  0. 16.] 
cards in discard: [1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [10 29  0  0  0 14  3 23 16  4  1  0 11  8 16 16  8  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 26. 29.  8.  9.  7.  1.  5. 10.  6.  9.  9.  0. 10.  2.] 
adversary cards in hand: [ 3. 15. 15.] 
adversary cards in discard: [11. 29. 15. 11. 10. 10.  3. 29.  6. 10.  3.  3.  0. 10.  3. 11.  0. 11.
 15. 11.  0. 10. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15] -> size -> 42 
adversary victory points: 5
player victory points: 4 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 3. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
expected returns: [[23.873583]
 [24.894766]
 [24.894766]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 15.] 
cards in discard: [11. 29. 15. 11. 10. 10.  3. 29.  6. 10.  3.  3.  0. 10.  3. 11.  0. 11.
 15. 11.  0. 10. 11. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 26. 29.  8.  9.  7.  1.  5. 10.  6.  9.  9.  0. 10.  2.] 
adversary cards in hand: [ 0.  0.  8. 10. 16.] 
adversary cards in discard: [ 1. 14. 11. 16.  0. 16.] 
adversary owned cards: [10 29  0  0  0 14  3 23 16  4  1  0 11  8 16 16  8  1] -> size -> 18 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[  -5    0    0   30    0    0    0    0    0    0    0  -70    0 -300
 1085    0] 
sum of rewards: 740 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -7.712290287017822



action possibilites: [-1] 
expected returns: [[12.156696]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.] 
cards in discard: [11. 29. 15. 11. 10. 10.  3. 29.  6. 10.  3.  3.  0. 10.  3. 11.  0. 11.
 15. 11.  0. 10. 11. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 26. 29.  8.  9.  7.  1.  5. 10.  6.  9.  9.  0. 10.  2.] 
adversary cards in hand: [ 0.  0.  8. 10. 16.] 
adversary cards in discard: [ 1. 14. 11. 16.  0. 16.] 
adversary owned cards: [10 29  0  0  0 14  3 23 16  4  1  0 11  8 16 16  8  1] -> size -> 18 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 24.894756317138672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 8.164635  ]
 [-0.19654012]
 [12.664188  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.] 
cards in discard: [11. 29. 15. 11. 10. 10.  3. 29.  6. 10.  3.  3.  0. 10.  3. 11.  0. 11.
 15. 11.  0. 10. 11. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15] -> size -> 42 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 25. 30. 26. 29.  8.  9.  7.  1.  5. 10.  6.  9.  9.  0. 10.  2.] 
adversary cards in hand: [ 0.  0.  8. 10. 16.] 
adversary cards in discard: [ 1. 14. 11. 16.  0. 16.] 
adversary owned cards: [10 29  0  0  0 14  3 23 16  4  1  0 11  8 16 16  8  1] -> size -> 18 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 12.156696319580078






Player: 1 
cards in hand: [ 0.  0.  8. 10. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 16.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 10. 16.] 
cards in discard: [ 1. 14. 11. 16.  0. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [10 29  0  0  0 14  3 23 16  4  1  0 11  8 16 16  8  1] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 26. 29.  8.  9.  7.  1.  5. 10.  6.  9.  9.  0. 10.  2.] 
adversary cards in hand: [ 0.  3. 10. 29.  0.] 
adversary cards in discard: [11. 29. 15. 11. 10. 10.  3. 29.  6. 10.  3.  3.  0. 10.  3. 11.  0. 11.
 15. 11.  0. 10. 11. 15. 15.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15] -> size -> 42 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1.  8. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 16.  1.] 
cards in discard: [ 1. 14. 11. 16.  0. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 29  0  0  0 14  3 23 16  4  1  0 11  8 16 16  8  1] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 26. 29.  8.  9.  7.  1.  5. 10.  6.  9.  9.  0. 10.  2.] 
adversary cards in hand: [ 0.  3. 10. 29.  0.] 
adversary cards in discard: [11. 29. 15. 11. 10. 10.  3. 29.  6. 10.  3.  3.  0. 10.  3. 11.  0. 11.
 15. 11.  0. 10. 11. 15. 15.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15] -> size -> 42 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 16.  1.] 
cards in discard: [ 1. 14. 11. 16.  0. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 29  0  0  0 14  3 23 16  4  1  0 11  8 16 16  8  1] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 25. 30. 26. 29.  8.  9.  7.  1.  5. 10.  6.  9.  9.  0. 10.  2.] 
adversary cards in hand: [ 0.  3. 10. 29.  0.] 
adversary cards in discard: [11. 29. 15. 11. 10. 10.  3. 29.  6. 10.  3.  3.  0. 10.  3. 11.  0. 11.
 15. 11.  0. 10. 11. 15. 15.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15] -> size -> 42 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 16.  1.] 
cards in discard: [ 1. 14. 11. 16.  0. 16. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 29  0  0  0 14  3 23 16  4  1  0 11  8 16 16  8  1 14] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 26. 29.  8.  9.  7.  1.  5. 10.  6.  8.  9.  0. 10.  2.] 
adversary cards in hand: [ 0.  3. 10. 29.  0.] 
adversary cards in discard: [11. 29. 15. 11. 10. 10.  3. 29.  6. 10.  3.  3.  0. 10.  3. 11.  0. 11.
 15. 11.  0. 10. 11. 15. 15.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15] -> size -> 42 
adversary victory points: 5
player victory points: 4 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 10. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[16.885952]
 [16.680763]
 [28.416527]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10. 29.  0.] 
cards in discard: [11. 29. 15. 11. 10. 10.  3. 29.  6. 10.  3.  3.  0. 10.  3. 11.  0. 11.
 15. 11.  0. 10. 11. 15. 15.  3. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 26. 29.  8.  9.  7.  1.  5. 10.  6.  8.  9.  0. 10.  2.] 
adversary cards in hand: [ 4. 29. 23.  0.  3.] 
adversary cards in discard: [ 1. 14. 11. 16.  0. 16. 14. 10.  0.  0.  8. 16.  1.] 
adversary owned cards: [10 29  0  0  0 14  3 23 16  4  1  0 11  8 16 16  8  1 14] -> size -> 19 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 12.664163589477539



action possibilites: [-1. 10. 15.] 
expected returns: [[-5.118499]
 [-5.960432]
 [-2.00448 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 15.] 
cards in discard: [11. 29. 15. 11. 10. 10.  3. 29.  6. 10.  3.  3.  0. 10.  3. 11.  0. 11.
 15. 11.  0. 10. 11. 15. 15.  3. 15.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11
 10 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15] -> size -> 42 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 25. 30. 26. 29.  8.  9.  7.  1.  5. 10.  6.  8.  9.  0. 10.  2.] 
adversary cards in hand: [ 4. 29. 23.  0.  3.] 
adversary cards in discard: [ 1. 14. 11. 16.  0. 16. 14. 10.  0.  0.  8. 16.  1.] 
adversary owned cards: [10 29  0  0  0 14  3 23 16  4  1  0 11  8 16 16  8  1 14] -> size -> 19 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 21.799638748168945



action possibilites: [-1] 
expected returns: [[49.59659]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.] 
cards in discard: [11. 29. 15. 11. 10. 10.  3. 29.  6. 10.  3.  3.  0. 10.  3. 11.  0. 11.
 15. 11.  0. 10. 11. 15. 15.  3. 15.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15] -> size -> 41 
action values: 0 
buys: 0 
player value: 4 
card supply: [23. 25. 30. 26. 29.  8.  9.  7.  1.  5. 10.  6.  8.  9.  0. 10.  2.] 
adversary cards in hand: [ 4. 29. 23.  0.  3.] 
adversary cards in discard: [ 1. 14. 11. 16.  0. 16. 14. 10.  0.  0.  8. 16.  1.] 
adversary owned cards: [10 29  0  0  0 14  3 23 16  4  1  0 11  8 16 16  8  1 14] -> size -> 19 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: -2.0044636726379395





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[40.35435 ]
 [55.51273 ]
 [52.609154]
 [35.990738]
 [33.67889 ]
 [45.435555]
 [63.2743  ]
 [50.37205 ]
 [71.046585]
 [65.76525 ]
 [41.32719 ]
 [52.1965  ]
 [38.07209 ]
 [57.133015]
 [49.596565]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [11. 29. 15. 11. 10. 10.  3. 29.  6. 10.  3.  3.  0. 10.  3. 11.  0. 11.
 15. 11.  0. 10. 11. 15. 15.  3. 15.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15] -> size -> 41 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 25. 30. 26. 29.  8.  9.  7.  1.  5. 10.  6.  8.  9.  0. 10.  2.] 
adversary cards in hand: [ 4. 29. 23.  0.  3.] 
adversary cards in discard: [ 1. 14. 11. 16.  0. 16. 14. 10.  0.  0.  8. 16.  1.] 
adversary owned cards: [10 29  0  0  0 14  3 23 16  4  1  0 11  8 16 16  8  1 14] -> size -> 19 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 49.596588134765625



buy possibilites: [-1] 
expected returns: [[20.771366]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [11. 29. 15. 11. 10. 10.  3. 29.  6. 10.  3.  3.  0. 10.  3. 11.  0. 11.
 15. 11.  0. 10. 11. 15. 15.  3. 15.  3. 25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 26. 29.  8.  9.  7.  1.  5.  9.  6.  8.  9.  0. 10.  2.] 
adversary cards in hand: [ 4. 29. 23.  0.  3.] 
adversary cards in discard: [ 1. 14. 11. 16.  0. 16. 14. 10.  0.  0.  8. 16.  1.] 
adversary owned cards: [10 29  0  0  0 14  3 23 16  4  1  0 11  8 16 16  8  1 14] -> size -> 19 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0  30   0   0  40   0   0   0   0 -70   0   0 250   0] 
sum of rewards: 245 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 71.04660034179688






Player: 1 
cards in hand: [ 4. 29. 23.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4. 29. 23.  0.  3.] 
cards in discard: [ 1. 14. 11. 16.  0. 16. 14. 10.  0.  0.  8. 16.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [10 29  0  0  0 14  3 23 16  4  1  0 11  8 16 16  8  1 14] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 26. 29.  8.  9.  7.  1.  5.  9.  6.  8.  9.  0. 10.  2.] 
adversary cards in hand: [ 0. 15. 10. 11. 10.] 
adversary cards in discard: [11. 29. 15. 11. 10. 10.  3. 29.  6. 10.  3.  3.  0. 10.  3. 11.  0. 11.
 15. 11.  0. 10. 11. 15. 15.  3. 15.  3. 25. 29. 15. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25] -> size -> 42 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4. 29. 23.  0.  3.] 
cards in discard: [ 1. 14. 11. 16.  0. 16. 14. 10.  0.  0.  8. 16.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [10 29  0  0  0 14  3 23 16  4  1  0 11  8 16 16  8  1 14] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 25. 30. 26. 29.  8.  9.  7.  1.  5.  9.  6.  8.  9.  0. 10.  2.] 
adversary cards in hand: [ 0. 15. 10. 11. 10.] 
adversary cards in discard: [11. 29. 15. 11. 10. 10.  3. 29.  6. 10.  3.  3.  0. 10.  3. 11.  0. 11.
 15. 11.  0. 10. 11. 15. 15.  3. 15.  3. 25. 29. 15. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25] -> size -> 42 
adversary victory points: 5
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 0. 15. 10. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 11. 10.] 
expected returns: [[107.19372]
 [109.95526]
 [103.18288]
 [114.58646]
 [103.18288]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 10. 11. 10.] 
cards in discard: [11. 29. 15. 11. 10. 10.  3. 29.  6. 10.  3.  3.  0. 10.  3. 11.  0. 11.
 15. 11.  0. 10. 11. 15. 15.  3. 15.  3. 25. 29. 15. 10.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 26. 29.  8.  9.  7.  1.  5.  9.  6.  8.  9.  0. 10.  2.] 
adversary cards in hand: [ 1. 29.  0. 16.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10 29  0  0  0 14  3 23 16  4  1  0 11  8 16 16  8  1 14] -> size -> 19 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 20.771366119384766



action possibilites: [-1] 
expected returns: [[18.25459]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 10. 10.] 
cards in discard: [11. 29. 15. 11. 10. 10.  3. 29.  6. 10.  3.  3.  0. 10.  3. 11.  0. 11.
 15. 11.  0. 10. 11. 15. 15.  3. 15.  3. 25. 29. 15. 10.  0. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 26. 29.  8.  9.  7.  1.  5.  9.  6.  8.  9.  0. 10.  1.] 
adversary cards in hand: [ 1. 29.  0. 16.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10 29  0  0  0 14  3 23 16  4  1  0 11  8 16 16  8  1 14] -> size -> 19 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0 -80   0   0  64   0] 
sum of rewards: 29 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 116.05723571777344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[14.649879]
 [10.192047]
 [18.254566]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 10. 10.] 
cards in discard: [11. 29. 15. 11. 10. 10.  3. 29.  6. 10.  3.  3.  0. 10.  3. 11.  0. 11.
 15. 11.  0. 10. 11. 15. 15.  3. 15.  3. 25. 29. 15. 10.  0. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 25. 30. 26. 29.  8.  9.  7.  1.  5.  9.  6.  8.  9.  0. 10.  1.] 
adversary cards in hand: [ 1. 29.  0. 16.  8.] 
adversary cards in discard: [] 
adversary owned cards: [10 29  0  0  0 14  3 23 16  4  1  0 11  8 16 16  8  1 14] -> size -> 19 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 18.254589080810547






Player: 1 
cards in hand: [ 1. 29.  0. 16.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  0. 16.  8.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [10 29  0  0  0 14  3 23 16  4  1  0 11  8 16 16  8  1 14] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 26. 29.  8.  9.  7.  1.  5.  9.  6.  8.  9.  0. 10.  1.] 
adversary cards in hand: [11. 15. 10. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15] -> size -> 43 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.  0. 16.  8.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [10 29  0  0  0 14  3 23 16  4  1  0 11  8 16 16  8  1 14] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 25. 30. 26. 29.  8.  9.  7.  1.  5.  9.  6.  8.  9.  0. 10.  1.] 
adversary cards in hand: [11. 15. 10. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15] -> size -> 43 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.  0. 16.  8.] 
cards in discard: [8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [10 29  0  0  0 14  3 23 16  4  1  0 11  8 16 16  8  1 14  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 25. 30. 26. 29.  8.  9.  7.  1.  4.  9.  6.  8.  9.  0. 10.  1.] 
adversary cards in hand: [11. 15. 10. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15] -> size -> 43 
adversary victory points: 5
player victory points: 4 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [11. 15. 10. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 10. 11.] 
expected returns: [[ 89.6199  ]
 [100.930916]
 [ 97.36563 ]
 [ 91.15999 ]
 [100.930916]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15. 10. 11.  0.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 26. 29.  8.  9.  7.  1.  4.  9.  6.  8.  9.  0. 10.  1.] 
adversary cards in hand: [23. 10.  0.  0. 16.] 
adversary cards in discard: [ 8.  1. 29.  0. 16.  8.] 
adversary owned cards: [10 29  0  0  0 14  3 23 16  4  1  0 11  8 16 16  8  1 14  8] -> size -> 20 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 18.254589080810547



action possibilites: [-1] 
expected returns: [[50.276146]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 11.  0.] 
cards in discard: [15.] 
cards in deck: 38 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 26. 29.  8.  9.  7.  1.  4.  9.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [23. 10.  0.  0. 16.] 
adversary cards in discard: [ 8.  1. 29.  0. 16.  8.] 
adversary owned cards: [10 29  0  0  0 14  3 23 16  4  1  0 11  8 16 16  8  1 14  8] -> size -> 20 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0 -90   0   0  64   0] 
sum of rewards: 19 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 103.44583129882812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[47.63965 ]
 [43.049736]
 [51.169956]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10. 11.  0.] 
cards in discard: [15.] 
cards in deck: 38 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15] -> size -> 44 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 25. 30. 26. 29.  8.  9.  7.  1.  4.  9.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [23. 10.  0.  0. 16.] 
adversary cards in discard: [ 8.  1. 29.  0. 16.  8.] 
adversary owned cards: [10 29  0  0  0 14  3 23 16  4  1  0 11  8 16 16  8  1 14  8] -> size -> 20 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 50.276145935058594






Player: 1 
cards in hand: [23. 10.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 10. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23. 10.  0.  0. 16.] 
cards in discard: [ 8.  1. 29.  0. 16.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [10 29  0  0  0 14  3 23 16  4  1  0 11  8 16 16  8  1 14  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 26. 29.  8.  9.  7.  1.  4.  9.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [ 0. 15. 11. 11. 29.] 
adversary cards in discard: [15. 11. 15. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15] -> size -> 44 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23. 10.  0.] 
cards in discard: [ 8.  1. 29.  0. 16.  8.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [10 29  0  0 14  3 23 16  4  1  0 11  8 16 16  8  1 14  8  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 25. 29.  8.  9.  7.  1.  4.  9.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [ 0. 15. 11. 11. 29.] 
adversary cards in discard: [15. 11. 15. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15] -> size -> 44 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23. 10.  0.] 
cards in discard: [ 8.  1. 29.  0. 16.  8.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [10 29  0  0 14  3 23 16  4  1  0 11  8 16 16  8  1 14  8  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 25. 30. 25. 29.  8.  9.  7.  1.  4.  9.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [ 0. 15. 11. 11. 29.] 
adversary cards in discard: [15. 11. 15. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15] -> size -> 44 
adversary victory points: 5
player victory points: 5 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 0. 15. 11. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 11. 29.] 
expected returns: [[139.95908]
 [142.49239]
 [145.55815]
 [145.55815]
 [146.05882]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 11. 11. 29.] 
cards in discard: [15. 11. 15. 10. 11.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 25. 29.  8.  9.  7.  1.  4.  9.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [14. 11.  0. 14. 16.] 
adversary cards in discard: [ 8.  1. 29.  0. 16.  8.  3. 16. 23. 10.  0.] 
adversary owned cards: [10 29  0  0 14  3 23 16  4  1  0 11  8 16 16  8  1 14  8  3] -> size -> 20 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 51.16996765136719



action possibilites: [-1. 15. 11. 15.] 
expected returns: [[100.146965]
 [107.86731 ]
 [112.47756 ]
 [107.86731 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11. 15.] 
cards in discard: [15. 11. 15. 10. 11.  0.  0. 11.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15] -> size -> 44 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 25. 30. 25. 29.  8.  9.  7.  1.  4.  9.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [14. 11.  0. 14. 16.] 
adversary cards in discard: [ 8.  1. 29.  0. 16.  8.  3. 16. 23. 10.  0.] 
adversary owned cards: [10 29  0  0 14  3 23 16  4  1  0 11  8 16 16  8  1 14  8  3] -> size -> 20 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 141.7057647705078



action possibilites: [-1] 
expected returns: [[92.84575]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.] 
cards in discard: [15. 11. 15. 10. 11.  0.  0. 11.  1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 24. 30. 25. 29.  8.  9.  7.  1.  4.  9.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [14. 11.  0. 14. 16.] 
adversary cards in discard: [ 8.  1. 29.  0. 16.  8.  3. 16. 23. 10.  0.] 
adversary owned cards: [10 29  0  0 14  3 23 16  4  1  0 11  8 16 16  8  1 14  8  3] -> size -> 20 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[  -5    0    0    0    0    0   40    0    0    0    0 -100    0    0
   27    0] 
sum of rewards: -38 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 108.82977294921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[84.77795 ]
 [77.89542 ]
 [92.111694]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15.] 
cards in discard: [15. 11. 15. 10. 11.  0.  0. 11.  1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 24. 30. 25. 29.  8.  9.  7.  1.  4.  9.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [14. 11.  0. 14. 16.] 
adversary cards in discard: [ 8.  1. 29.  0. 16.  8.  3. 16. 23. 10.  0.] 
adversary owned cards: [10 29  0  0 14  3 23 16  4  1  0 11  8 16 16  8  1 14  8  3] -> size -> 20 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 92.84574890136719






Player: 1 
cards in hand: [14. 11.  0. 14. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11. 14. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 11.  0. 14. 16.] 
cards in discard: [ 8.  1. 29.  0. 16.  8.  3. 16. 23. 10.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10 29  0  0 14  3 23 16  4  1  0 11  8 16 16  8  1 14  8  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 25. 29.  8.  9.  7.  1.  4.  9.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [10. 29. 11. 10.  3.] 
adversary cards in discard: [15. 11. 15. 10. 11.  0.  0. 11.  1. 29. 11. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1] -> size -> 45 
adversary victory points: 5
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0. 14.] 
cards in discard: [ 8.  1. 29.  0. 16.  8.  3. 16. 23. 10.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [10 29  0  0 14  3 23 16  4  1  0  8 16 16  8  1 14  8  3  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 25. 29.  8.  9.  7.  1.  4.  9.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [10. 29. 11. 10.  3.] 
adversary cards in discard: [15. 11. 15. 10. 11.  0.  0. 11.  1. 29. 11. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1] -> size -> 45 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0. 14.] 
cards in discard: [ 8.  1. 29.  0. 16.  8.  3. 16. 23. 10.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [10 29  0  0 14  3 23 16  4  1  0  8 16 16  8  1 14  8  3  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 24. 30. 25. 29.  8.  9.  7.  1.  4.  9.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [10. 29. 11. 10.  3.] 
adversary cards in discard: [15. 11. 15. 10. 11.  0.  0. 11.  1. 29. 11. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1] -> size -> 45 
adversary victory points: 5
player victory points: 5 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [10. 29. 11. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11. 10.] 
expected returns: [[252.064  ]
 [247.29381]
 [247.5058 ]
 [255.07303]
 [247.29381]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 11. 10.  3.] 
cards in discard: [15. 11. 15. 10. 11.  0.  0. 11.  1. 29. 11. 15. 15.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 25. 29.  8.  9.  7.  1.  4.  9.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [29.  3.  8.  1.  4.] 
adversary cards in discard: [] 
adversary owned cards: [10 29  0  0 14  3 23 16  4  1  0  8 16 16  8  1 14  8  3  0] -> size -> 20 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 92.11175537109375



action possibilites: [-1] 
expected returns: [[134.3222]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 10.  3.] 
cards in discard: [15. 11. 15. 10. 11.  0.  0. 11.  1. 29. 11. 15. 15.  1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1  1] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 25. 29.  8.  9.  7.  1.  4.  9.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [29.  3.  8.  1.  4.] 
adversary cards in discard: [] 
adversary owned cards: [10 29  0  0 14  3 23 16  4  1  0  8 16 16  8  1 14  8  3  0] -> size -> 20 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0 -110    0    0
   27    0] 
sum of rewards: -68 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 251.48526000976562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[129.4133 ]
 [129.7178 ]
 [139.27705]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29. 10.  3.] 
cards in discard: [15. 11. 15. 10. 11.  0.  0. 11.  1. 29. 11. 15. 15.  1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1  1] -> size -> 46 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 23. 30. 25. 29.  8.  9.  7.  1.  4.  9.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [29.  3.  8.  1.  4.] 
adversary cards in discard: [] 
adversary owned cards: [10 29  0  0 14  3 23 16  4  1  0  8 16 16  8  1 14  8  3  0] -> size -> 20 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 134.32220458984375






Player: 1 
cards in hand: [29.  3.  8.  1.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  8.  1.  4.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [10 29  0  0 14  3 23 16  4  1  0  8 16 16  8  1 14  8  3  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 25. 29.  8.  9.  7.  1.  4.  9.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [ 3.  3. 15.  3. 10.] 
adversary cards in discard: [15. 11. 15. 10. 11.  0.  0. 11.  1. 29. 11. 15. 15.  1. 11. 10. 29. 10.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1  1] -> size -> 46 
adversary victory points: 5
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  1.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 29  0  0 14  3 23 16  1  0  8 16 16  8  1 14  8  3  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 25. 29.  8.  9.  7.  1.  4.  9.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [ 3.  3. 15.  3. 10.] 
adversary cards in discard: [15. 11. 15. 10. 11.  0.  0. 11.  1. 29. 11. 15. 15.  1. 11. 10. 29. 10.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1  1] -> size -> 46 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  1.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 29  0  0 14  3 23 16  1  0  8 16 16  8  1 14  8  3  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 23. 30. 25. 29.  8.  9.  7.  1.  4.  9.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [ 3.  3. 15.  3. 10.] 
adversary cards in discard: [15. 11. 15. 10. 11.  0.  0. 11.  1. 29. 11. 15. 15.  1. 11. 10. 29. 10.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1  1] -> size -> 46 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  1.] 
cards in discard: [0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 29  0  0 14  3 23 16  1  0  8 16 16  8  1 14  8  3  0  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 23. 30. 25. 29.  8.  9.  7.  1.  4.  9.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [ 3.  3. 15.  3. 10.] 
adversary cards in discard: [15. 11. 15. 10. 11.  0.  0. 11.  1. 29. 11. 15. 15.  1. 11. 10. 29. 10.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1  1] -> size -> 46 
adversary victory points: 5
player victory points: 2 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [ 3.  3. 15.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
expected returns: [[40.67347 ]
 [45.159157]
 [40.80539 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 15.  3. 10.] 
cards in discard: [15. 11. 15. 10. 11.  0.  0. 11.  1. 29. 11. 15. 15.  1. 11. 10. 29. 10.
  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1  1] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 25. 29.  8.  9.  7.  1.  4.  9.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [10. 16. 16. 14.  1.] 
adversary cards in discard: [ 0.  8. 29.  3.  1.] 
adversary owned cards: [10 29  0  0 14  3 23 16  1  0  8 16 16  8  1 14  8  3  0  0] -> size -> 20 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 139.27713012695312



action possibilites: [-1] 
expected returns: [[10.522827]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3. 10.] 
cards in discard: [15. 11. 15. 10. 11.  0.  0. 11.  1. 29. 11. 15. 15.  1. 11. 10. 29. 10.
  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1  1] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 25. 29.  8.  9.  7.  1.  4.  9.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [10. 16. 16. 14.  1.] 
adversary cards in discard: [ 0.  8. 29.  3.  1.] 
adversary owned cards: [10 29  0  0 14  3 23 16  1  0  8 16 16  8  1 14  8  3  0  0] -> size -> 20 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 45.15917205810547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 7.255686]
 [ 6.556573]
 [10.731419]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3. 10.] 
cards in discard: [15. 11. 15. 10. 11.  0.  0. 11.  1. 29. 11. 15. 15.  1. 11. 10. 29. 10.
  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1  1] -> size -> 46 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 23. 30. 25. 29.  8.  9.  7.  1.  4.  9.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [10. 16. 16. 14.  1.] 
adversary cards in discard: [ 0.  8. 29.  3.  1.] 
adversary owned cards: [10 29  0  0 14  3 23 16  1  0  8 16 16  8  1 14  8  3  0  0] -> size -> 20 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 10.5228271484375






Player: 1 
cards in hand: [10. 16. 16. 14.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16. 16. 14.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 16. 16. 14.  1.] 
cards in discard: [ 0.  8. 29.  3.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [10 29  0  0 14  3 23 16  1  0  8 16 16  8  1 14  8  3  0  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 25. 29.  8.  9.  7.  1.  4.  9.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [10.  6. 10.  0.  3.] 
adversary cards in discard: [15. 11. 15. 10. 11.  0.  0. 11.  1. 29. 11. 15. 15.  1. 11. 10. 29. 10.
  3. 15.  3.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1  1] -> size -> 46 
adversary victory points: 5
player victory points: 2 


action possibilites: [-1. 16. 16. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 16. 14.  1.  0.] 
cards in discard: [ 0.  8. 29.  3.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [10 29  0  0 14  3 23 16  1  0  8 16 16  8  1 14  8  3  0  0] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 25. 29.  8.  9.  7.  1.  4.  9.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [10.  6. 10.  0.  3.] 
adversary cards in discard: [15. 11. 15. 10. 11.  0.  0. 11.  1. 29. 11. 15. 15.  1. 11. 10. 29. 10.
  3. 15.  3.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1  1] -> size -> 46 
adversary victory points: 5
player victory points: 2 


action possibilites: [-1. 16. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 16.  1.  0.] 
cards in discard: [ 0.  8. 29.  3.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [10 29  0  0 14  3 23 16  1  0  8 16 16  8  1 14  8  3  0  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 2 
card supply: [21. 23. 30. 25. 29.  8.  9.  7.  1.  4.  9.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [10.  6. 10.] 
adversary cards in discard: [15. 11. 15. 10. 11.  0.  0. 11.  1. 29. 11. 15. 15.  1. 11. 10. 29. 10.
  3. 15.  3.  3.  3. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1  1] -> size -> 46 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 16.  1.  0.] 
cards in discard: [ 0.  8. 29.  3.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [10 29  0  0 14  3 23 16  1  0  8 16 16  8  1 14  8  3  0  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 23. 30. 25. 29.  8.  9.  7.  1.  4.  9.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [10.  6. 10.] 
adversary cards in discard: [15. 11. 15. 10. 11.  0.  0. 11.  1. 29. 11. 15. 15.  1. 11. 10. 29. 10.
  3. 15.  3.  3.  3. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1  1] -> size -> 46 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 16.  1.  0.] 
cards in discard: [ 0.  8. 29.  3.  1. 25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [10 29  0  0 14  3 23 16  1  0  8 16 16  8  1 14  8  3  0  0 25] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 25. 29.  8.  9.  7.  1.  4.  8.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [10.  6. 10.] 
adversary cards in discard: [15. 11. 15. 10. 11.  0.  0. 11.  1. 29. 11. 15. 15.  1. 11. 10. 29. 10.
  3. 15.  3.  3.  3. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1  1] -> size -> 46 
adversary victory points: 5
player victory points: 2 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [10.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[-16.985865]
 [-18.225807]
 [-18.225807]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6. 10.] 
cards in discard: [15. 11. 15. 10. 11.  0.  0. 11.  1. 29. 11. 15. 15.  1. 11. 10. 29. 10.
  3. 15.  3.  3.  3. 10.  0.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1  1] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 25. 29.  8.  9.  7.  1.  4.  8.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [14.  0.  8.  0.  3.] 
adversary cards in discard: [ 0.  8. 29.  3.  1. 25. 10. 14. 16. 16.  1.  0.] 
adversary owned cards: [10 29  0  0 14  3 23 16  1  0  8 16 16  8  1 14  8  3  0  0 25] -> size -> 21 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[  -5    0    0   90    0    0    0    0    0    0    0 -110    0 -300
 1357    0] 
sum of rewards: 1032 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -11.937768936157227





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-19.99646 ]
 [-21.631538]
 [-16.985865]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6. 10.] 
cards in discard: [15. 11. 15. 10. 11.  0.  0. 11.  1. 29. 11. 15. 15.  1. 11. 10. 29. 10.
  3. 15.  3.  3.  3. 10.  0.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1  1] -> size -> 46 
action values: 1 
buys: 1 
player value: 0 
card supply: [21. 23. 30. 25. 29.  8.  9.  7.  1.  4.  8.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [14.  0.  8.  0.  3.] 
adversary cards in discard: [ 0.  8. 29.  3.  1. 25. 10. 14. 16. 16.  1.  0.] 
adversary owned cards: [10 29  0  0 14  3 23 16  1  0  8 16 16  8  1 14  8  3  0  0 25] -> size -> 21 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -16.985851287841797



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [14.  0.  8.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  8.  0.  3.] 
cards in discard: [ 0.  8. 29.  3.  1. 25. 10. 14. 16. 16.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [10 29  0  0 14  3 23 16  1  0  8 16 16  8  1 14  8  3  0  0 25] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 25. 29.  8.  9.  7.  1.  4.  8.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [10. 11. 15. 15.  3.] 
adversary cards in discard: [15. 11. 15. 10. 11.  0.  0. 11.  1. 29. 11. 15. 15.  1. 11. 10. 29. 10.
  3. 15.  3.  3.  3. 10.  0.  3. 10.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1  1] -> size -> 46 
adversary victory points: 5
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 0.  8. 29.  3.  1. 25. 10. 14. 16. 16.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 29  3 23 16  1  0  8 16 16  8  1 14  8  3  0  0 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 25. 29.  8.  9.  7.  1.  4.  8.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [10. 11. 15. 15.  3.] 
adversary cards in discard: [15. 11. 15. 10. 11.  0.  0. 11.  1. 29. 11. 15. 15.  1. 11. 10. 29. 10.
  3. 15.  3.  3.  3. 10.  0.  3. 10.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1  1] -> size -> 46 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 0.  8. 29.  3.  1. 25. 10. 14. 16. 16.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 29  3 23 16  1  0  8 16 16  8  1 14  8  3  0  0 25] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 23. 30. 25. 29.  8.  9.  7.  1.  4.  8.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [10. 11. 15. 15.  3.] 
adversary cards in discard: [15. 11. 15. 10. 11.  0.  0. 11.  1. 29. 11. 15. 15.  1. 11. 10. 29. 10.
  3. 15.  3.  3.  3. 10.  0.  3. 10.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1  1] -> size -> 46 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 0.  8. 29.  3.  1. 25. 10. 14. 16. 16.  1.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [10 29  3 23 16  1  0  8 16 16  8  1 14  8  3  0  0 25  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 25. 29.  8.  9.  7.  1.  4.  8.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [10. 11. 15. 15.  3.] 
adversary cards in discard: [15. 11. 15. 10. 11.  0.  0. 11.  1. 29. 11. 15. 15.  1. 11. 10. 29. 10.
  3. 15.  3.  3.  3. 10.  0.  3. 10.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1  1] -> size -> 46 
adversary victory points: 5
player victory points: 2 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [10. 11. 15. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 15. 15.] 
expected returns: [[-15.851696]
 [-15.759939]
 [ -9.997288]
 [-13.19017 ]
 [-13.19017 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 15. 15.  3.] 
cards in discard: [15. 11. 15. 10. 11.  0.  0. 11.  1. 29. 11. 15. 15.  1. 11. 10. 29. 10.
  3. 15.  3.  3.  3. 10.  0.  3. 10.  6. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1  1] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 25. 29.  8.  9.  7.  1.  4.  8.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [ 0.  0.  8. 16. 23.] 
adversary cards in discard: [] 
adversary owned cards: [10 29  3 23 16  1  0  8 16 16  8  1 14  8  3  0  0 25  0] -> size -> 19 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -16.985851287841797



action possibilites: [-1] 
expected returns: [[52.46538]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15. 15.  3.] 
cards in discard: [15. 11. 15. 10. 11.  0.  0. 11.  1. 29. 11. 15. 15.  1. 11. 10. 29. 10.
  3. 15.  3.  3.  3. 10.  0.  3. 10.  6. 10.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1  1  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 22. 30. 25. 29.  8.  9.  7.  1.  4.  8.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [ 0.  0.  8. 16. 23.] 
adversary cards in discard: [] 
adversary owned cards: [10 29  3 23 16  1  0  8 16 16  8  1 14  8  3  0  0 25  0] -> size -> 19 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[  -5    0    0   90    0    0   20    0    0    0    0 -120    0    0
   27    0] 
sum of rewards: 12 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -13.381572723388672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[49.208195]
 [36.70793 ]
 [52.46537 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15. 15.  3.] 
cards in discard: [15. 11. 15. 10. 11.  0.  0. 11.  1. 29. 11. 15. 15.  1. 11. 10. 29. 10.
  3. 15.  3.  3.  3. 10.  0.  3. 10.  6. 10.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1  1  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 22. 30. 25. 29.  8.  9.  7.  1.  4.  8.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [ 0.  0.  8. 16. 23.] 
adversary cards in discard: [] 
adversary owned cards: [10 29  3 23 16  1  0  8 16 16  8  1 14  8  3  0  0 25  0] -> size -> 19 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 52.46538162231445






Player: 1 
cards in hand: [ 0.  0.  8. 16. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 23.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 16. 23.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [10 29  3 23 16  1  0  8 16 16  8  1 14  8  3  0  0 25  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 22. 30. 25. 29.  8.  9.  7.  1.  4.  8.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [11. 10. 15.  0. 25.] 
adversary cards in discard: [15. 11. 15. 10. 11.  0.  0. 11.  1. 29. 11. 15. 15.  1. 11. 10. 29. 10.
  3. 15.  3.  3.  3. 10.  0.  3. 10.  6. 10.  1. 11. 10. 15. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1  1  1] -> size -> 47 
adversary victory points: 5
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [10 29  3 16  1  0  8 16 16  8  1 14  8  3  0  0 25  0  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 22. 30. 25. 29.  8.  8.  7.  1.  4.  8.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [11. 10. 15.  0. 25.] 
adversary cards in discard: [15. 11. 15. 10. 11.  0.  0. 11.  1. 29. 11. 15. 15.  1. 11. 10. 29. 10.
  3. 15.  3.  3.  3. 10.  0.  3. 10.  6. 10.  1. 11. 10. 15. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1  1  1] -> size -> 47 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [10 29  3 16  1  0  8 16 16  8  1 14  8  3  0  0 25  0  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 22. 30. 25. 29.  8.  8.  7.  1.  4.  8.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [11. 10. 15.  0. 25.] 
adversary cards in discard: [15. 11. 15. 10. 11.  0.  0. 11.  1. 29. 11. 15. 15.  1. 11. 10. 29. 10.
  3. 15.  3.  3.  3. 10.  0.  3. 10.  6. 10.  1. 11. 10. 15. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1  1  1] -> size -> 47 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [6. 8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [10 29  3 16  1  0  8 16 16  8  1 14  8  3  0  0 25  0  6  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 22. 30. 25. 29.  8.  8.  7.  1.  3.  8.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [11. 10. 15.  0. 25.] 
adversary cards in discard: [15. 11. 15. 10. 11.  0.  0. 11.  1. 29. 11. 15. 15.  1. 11. 10. 29. 10.
  3. 15.  3.  3.  3. 10.  0.  3. 10.  6. 10.  1. 11. 10. 15. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1  1  1] -> size -> 47 
adversary victory points: 5
player victory points: 1 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [11. 10. 15.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 15. 25.] 
expected returns: [[-21.873657]
 [-20.81012 ]
 [-23.125776]
 [-21.826511]
 [-18.913563]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 15.  0. 25.] 
cards in discard: [15. 11. 15. 10. 11.  0.  0. 11.  1. 29. 11. 15. 15.  1. 11. 10. 29. 10.
  3. 15.  3.  3.  3. 10.  0.  3. 10.  6. 10.  1. 11. 10. 15. 15.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1  1  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 22. 30. 25. 29.  8.  8.  7.  1.  3.  8.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [16.  0.  1.  3. 29.] 
adversary cards in discard: [ 6.  8. 16.  0.  0.  8.] 
adversary owned cards: [10 29  3 16  1  0  8 16 16  8  1 14  8  3  0  0 25  0  6  8] -> size -> 20 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 52.46538162231445



action possibilites: [-1] 
expected returns: [[-2.8735585]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 15.  0. 15.  0.] 
cards in discard: [15. 11. 15. 10. 11.  0.  0. 11.  1. 29. 11. 15. 15.  1. 11. 10. 29. 10.
  3. 15.  3.  3.  3. 10.  0.  3. 10.  6. 10.  1. 11. 10. 15. 15.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1  1  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 22. 30. 25. 29.  8.  7.  7.  1.  3.  8.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [16.  0.  1.  3. 29.] 
adversary cards in discard: [ 6.  8. 16.  0.  0.  8.  6.] 
adversary owned cards: [10 29  3 16  1  0  8 16 16  8  1 14  8  3  0  0 25  0  6  8  6] -> size -> 21 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -18.913543701171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ -8.628085  ]
 [  1.0483999 ]
 [-14.709147  ]
 [ -0.10180593]
 [ -2.8735757 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 15.  0. 15.  0.] 
cards in discard: [15. 11. 15. 10. 11.  0.  0. 11.  1. 29. 11. 15. 15.  1. 11. 10. 29. 10.
  3. 15.  3.  3.  3. 10.  0.  3. 10.  6. 10.  1. 11. 10. 15. 15.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1  1  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 22. 30. 25. 29.  8.  7.  7.  1.  3.  8.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [16.  0.  1.  3. 29.] 
adversary cards in discard: [ 6.  8. 16.  0.  0.  8.  6.] 
adversary owned cards: [10 29  3 16  1  0  8 16 16  8  1 14  8  3  0  0 25  0  6  8  6] -> size -> 21 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: -2.873558521270752



buy possibilites: [-1] 
expected returns: [[74.24407]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 15.  0. 15.  0.] 
cards in discard: [15. 11. 15. 10. 11.  0.  0. 11.  1. 29. 11. 15. 15.  1. 11. 10. 29. 10.
  3. 15.  3.  3.  3. 10.  0.  3. 10.  6. 10.  1. 11. 10. 15. 15.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1  1  1  3] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 22. 30. 24. 29.  8.  7.  7.  1.  3.  8.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [16.  0.  1.  3. 29.] 
adversary cards in discard: [ 6.  8. 16.  0.  0.  8.  6.] 
adversary owned cards: [10 29  3 16  1  0  8 16 16  8  1 14  8  3  0  0 25  0  6  8  6] -> size -> 21 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[  -5    0    0  150    0    0   20    0    0    0    0 -130    0    0
   16    0] 
sum of rewards: 51 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 1.0484333038330078






Player: 1 
cards in hand: [16.  0.  1.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  1.  3. 29.] 
cards in discard: [ 6.  8. 16.  0.  0.  8.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [10 29  3 16  1  0  8 16 16  8  1 14  8  3  0  0 25  0  6  8  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 22. 30. 24. 29.  8.  7.  7.  1.  3.  8.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [10. 11. 29. 15.  0.] 
adversary cards in discard: [15. 11. 15. 10. 11.  0.  0. 11.  1. 29. 11. 15. 15.  1. 11. 10. 29. 10.
  3. 15.  3.  3.  3. 10.  0.  3. 10.  6. 10.  1. 11. 10. 15. 15.  3.  3.
 25. 11. 10. 15.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1  1  1  3] -> size -> 48 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.] 
cards in discard: [ 6.  8. 16.  0.  0.  8.  6.  1.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [10 29  3 16  1  0  8 16 16  8  1 14  8  3  0  0 25  0  6  8  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 22. 30. 24. 29.  8.  7.  7.  1.  3.  8.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [10. 11. 29. 15.  0.] 
adversary cards in discard: [15. 11. 15. 10. 11.  0.  0. 11.  1. 29. 11. 15. 15.  1. 11. 10. 29. 10.
  3. 15.  3.  3.  3. 10.  0.  3. 10.  6. 10.  1. 11. 10. 15. 15.  3.  3.
 25. 11. 10. 15.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1  1  1  3] -> size -> 48 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 6.  8. 16.  0.  0.  8.  6.  1.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [10 29  3 16  1  8 16 16  8  1 14  8  3  0  0 25  0  6  8  6  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 22. 30. 23. 29.  8.  7.  7.  1.  3.  8.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [10. 11. 29. 15.  0.] 
adversary cards in discard: [15. 11. 15. 10. 11.  0.  0. 11.  1. 29. 11. 15. 15.  1. 11. 10. 29. 10.
  3. 15.  3.  3.  3. 10.  0.  3. 10.  6. 10.  1. 11. 10. 15. 15.  3.  3.
 25. 11. 10. 15.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1  1  1  3] -> size -> 48 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 6.  8. 16.  0.  0.  8.  6.  1.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [10 29  3 16  1  8 16 16  8  1 14  8  3  0  0 25  0  6  8  6  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 22. 30. 23. 29.  8.  7.  7.  1.  3.  8.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [10. 11. 29. 15.  0.] 
adversary cards in discard: [15. 11. 15. 10. 11.  0.  0. 11.  1. 29. 11. 15. 15.  1. 11. 10. 29. 10.
  3. 15.  3.  3.  3. 10.  0.  3. 10.  6. 10.  1. 11. 10. 15. 15.  3.  3.
 25. 11. 10. 15.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1  1  1  3] -> size -> 48 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 6.  8. 16.  0.  0.  8.  6.  1.  3.  3.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [10 29  3 16  1  8 16 16  8  1 14  8  3  0  0 25  0  6  8  6  3  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 22. 30. 23. 29.  8.  7.  7.  1.  2.  8.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [10. 11. 29. 15.  0.] 
adversary cards in discard: [15. 11. 15. 10. 11.  0.  0. 11.  1. 29. 11. 15. 15.  1. 11. 10. 29. 10.
  3. 15.  3.  3.  3. 10.  0.  3. 10.  6. 10.  1. 11. 10. 15. 15.  3.  3.
 25. 11. 10. 15.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1  1  1  3] -> size -> 48 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [10. 11. 29. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 29. 15.] 
expected returns: [[-2.6542244]
 [-1.2039163]
 [ 5.945363 ]
 [ 8.681874 ]
 [ 3.379599 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 29. 15.  0.] 
cards in discard: [15. 11. 15. 10. 11.  0.  0. 11.  1. 29. 11. 15. 15.  1. 11. 10. 29. 10.
  3. 15.  3.  3.  3. 10.  0.  3. 10.  6. 10.  1. 11. 10. 15. 15.  3.  3.
 25. 11. 10. 15.  0. 15.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1  1  1  3] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 22. 30. 23. 29.  8.  7.  7.  1.  2.  8.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [ 1. 16.  8. 25.  3.] 
adversary cards in discard: [ 6.  8. 16.  0.  0.  8.  6.  1.  3.  3.  8. 29. 16.  0.] 
adversary owned cards: [10 29  3 16  1  8 16 16  8  1 14  8  3  0  0 25  0  6  8  6  3  8] -> size -> 22 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 74.24407196044922



action possibilites: [-1. 11. 15.] 
expected returns: [[-6.5064507]
 [ 0.9851961]
 [-2.2298863]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15.  0.] 
cards in discard: [10.  3.] 
cards in deck: 42 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1  1  1  3] -> size -> 48 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 22. 30. 23. 29.  8.  7.  7.  1.  2.  8.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [ 1. 16.  8. 25.  3.] 
adversary cards in discard: [ 6.  8. 16.  0.  0.  8.  6.  1.  3.  3.  8. 29. 16.  0.] 
adversary owned cards: [10 29  3 16  1  8 16 16  8  1 14  8  3  0  0 25  0  6  8  6  3  8] -> size -> 22 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 7.919166564941406



action possibilites: [-1] 
expected returns: [[-0.648741]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.] 
cards in discard: [10.  3.  1.] 
cards in deck: 42 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1  1  1  3
  1] -> size -> 49 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 21. 30. 23. 29.  8.  7.  7.  1.  2.  8.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [ 1. 16.  8. 25.  3.] 
adversary cards in discard: [ 6.  8. 16.  0.  0.  8.  6.  1.  3.  3.  8. 29. 16.  0.] 
adversary owned cards: [10 29  3 16  1  8 16 16  8  1 14  8  3  0  0 25  0  6  8  6  3  8] -> size -> 22 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[  -5    0    0  150    0    0   40    0    0    0    0 -140    0    0
   27    0] 
sum of rewards: 72 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -1.440258264541626





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ -4.5094595]
 [  3.8388724]
 [-10.074589 ]
 [  2.7894936]
 [ -1.503366 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.] 
cards in discard: [10.  3.  1.] 
cards in deck: 42 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1  1  1  3
  1] -> size -> 49 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 21. 30. 23. 29.  8.  7.  7.  1.  2.  8.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [ 1. 16.  8. 25.  3.] 
adversary cards in discard: [ 6.  8. 16.  0.  0.  8.  6.  1.  3.  3.  8. 29. 16.  0.] 
adversary owned cards: [10 29  3 16  1  8 16 16  8  1 14  8  3  0  0 25  0  6  8  6  3  8] -> size -> 22 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: -0.6487410068511963



buy possibilites: [-1] 
expected returns: [[42.55842]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.] 
cards in discard: [10.  3.  1.  3.] 
cards in deck: 42 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1  1  1  3
  1  3] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 22. 29.  8.  7.  7.  1.  2.  8.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [ 1. 16.  8. 25.  3.] 
adversary cards in discard: [ 6.  8. 16.  0.  0.  8.  6.  1.  3.  3.  8. 29. 16.  0.] 
adversary owned cards: [10 29  3 16  1  8 16 16  8  1 14  8  3  0  0 25  0  6  8  6  3  8] -> size -> 22 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  180    0    0   40    0    0    0    0 -150    0    0
   16    0] 
sum of rewards: 81 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 3.838883399963379






Player: 1 
cards in hand: [ 1. 16.  8. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 25.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 16.  8. 25.  3.] 
cards in discard: [ 6.  8. 16.  0.  0.  8.  6.  1.  3.  3.  8. 29. 16.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [10 29  3 16  1  8 16 16  8  1 14  8  3  0  0 25  0  6  8  6  3  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 22. 29.  8.  7.  7.  1.  2.  8.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [ 3.  1.  3. 15.  0.] 
adversary cards in discard: [10.  3.  1.  3. 29. 11. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1  1  1  3
  1  3] -> size -> 50 
adversary victory points: 7
player victory points: 1 


Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 5 
Duchy: 0 
Province: 0 
Curse: 1 

Remodel: 0 
Workshop: 8 
Chapel: 0 
Witch: 1 
Poacher: 3 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 3.  1.  3. 15.  0.] 
cards in discard: [10.  3.  1.  3. 29. 11. 15.  0.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29 11 11 29 10 11 11 10 29 10 11 10 10 11 10
 11 10  3 10 11 10  3 15 15 15  3 15 15 15  6 15 15 25 15 15  1  1  1  3
  1  3] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 22. 29.  8.  7.  7.  0.  2.  8.  6.  8.  9.  0. 10.  0.] 
adversary cards in hand: [ 8. 25.  3.] 
adversary cards in discard: [ 6.  8. 16.  0.  0.  8.  6.  1.  3.  3.  8. 29. 16.  0. 11.] 
adversary owned cards: [10 29  3 16  8 16 16  8  1 14  8  3  0  0 25  0  6  8  6  3  8 11] -> size -> 22 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[     -5 3000000       0     180       0       0       0       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000175 

action type: buy - action -1
Learning step: 300013.25
desired expected reward: 300055.8125



