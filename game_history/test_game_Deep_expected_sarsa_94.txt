 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[61.130318]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [3. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0      60       0       0       0       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000055 

action type: buy - action -1.0
Learning step: 120011.6796875
desired expected reward: 119774.7265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[39.695213]
 [62.224564]
 [57.489113]
 [11.083741]
 [84.37518 ]
 [65.89533 ]
 [61.119476]
 [59.236534]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [3. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 59.37199401855469



buy possibilites: [-1] 
expected returns: [[63.515953]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [3. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0  54   0] 
sum of rewards: 19 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 84.37519073486328






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [3. 3. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [3. 3. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 3.  3.  0.  3.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[61.29441]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  0.  3.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 63.515953063964844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[41.463345]
 [64.24401 ]
 [59.43364 ]
 [15.585732]
 [60.98825 ]
 [86.22165 ]
 [67.92682 ]
 [87.54414 ]
 [40.137325]
 [63.11644 ]
 [62.88434 ]
 [61.321564]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  0.  3.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 56.0516357421875



buy possibilites: [-1] 
expected returns: [[74.61012]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  0.  3.  3.  0.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 93 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 87.54414367675781






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0.  3.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[68.68203]
 [95.06247]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10.  3.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 74.61012268066406



action possibilites: [-1.] 
expected returns: [[84.018394]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10.  3.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 91.72411346435547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 70.08009 ]
 [ 91.380974]
 [ 87.02906 ]
 [ 42.339996]
 [ 88.615   ]
 [110.36482 ]
 [ 94.61632 ]
 [111.74068 ]
 [ 68.56805 ]
 [ 90.26441 ]
 [ 90.05434 ]
 [ 89.401886]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10.  3.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 84.01839447021484



buy possibilites: [-1] 
expected returns: [[73.73644]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10.  3.] 
adversary cards in discard: [10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 113 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 111.74067687988281






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10.  3.] 
cards in discard: [10.  3.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [29. 29.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.  3.] 
cards in discard: [10.  3.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [29. 29.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.  3.] 
cards in discard: [10.  3.  0.  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [29. 29.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 3. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[ 77.60941]
 [100.74607]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.  0.] 
cards in discard: [29. 29.  0.  3.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 73.73644256591797



action possibilites: [-1] 
expected returns: [[82.08212]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [29. 29.  0.  3.  0.  0.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 97.71247863769531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 70.82398 ]
 [ 91.45052 ]
 [ 87.00263 ]
 [ 45.877277]
 [111.250656]
 [ 94.77819 ]
 [ 90.32404 ]
 [ 89.38237 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [29. 29.  0.  3.  0.  0.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 82.08212280273438



buy possibilites: [-1] 
expected returns: [[76.53278]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [29. 29.  0.  3.  0.  0.  3. 10. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 111.25064849853516






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0.  3. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[70.24629]
 [90.36077]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  3.  0.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 76.53278350830078



action possibilites: [-1.] 
expected returns: [[77.23003]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  3.  0.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 86.5241470336914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 66.41523]
 [ 85.75711]
 [ 81.44012]
 [ 44.48412]
 [ 83.08656]
 [104.21758]
 [ 88.92797]
 [105.65361]
 [ 65.12666]
 [ 84.611  ]
 [ 84.40059]
 [ 84.08881]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10.  9.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  3.  0.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 77.23002624511719



buy possibilites: [-1] 
expected returns: [[98.62104]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  3.  0.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 113 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 105.65359497070312






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  3.  0.] 
cards in discard: [25.  0.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [29. 29.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29] -> size -> 16 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0. 10.] 
cards in discard: [25.  0.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [29. 29.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29] -> size -> 16 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  0. 10.] 
cards in discard: [25.  0.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8. 10.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [29. 29.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29] -> size -> 16 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  0. 10.] 
cards in discard: [25.  0.  0.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  8. 10.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [29. 29.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29] -> size -> 16 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[118.005875]
 [118.40486 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [29. 29.  0.  3.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  8. 10.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [25.  0.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 98.62104034423828



action possibilites: [-1.] 
expected returns: [[119.21494]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29. 29.  0.  3.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  8. 10.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [25.  0.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 114.75393676757812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[103.67988]
 [124.12401]
 [119.58137]
 [ 79.25349]
 [121.34374]
 [143.39581]
 [127.44714]
 [144.976  ]
 [102.28302]
 [122.90451]
 [122.72232]
 [122.54137]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29. 29.  0.  3.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  8. 10.  9.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [25.  0.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 119.2149429321289



buy possibilites: [-1] 
expected returns: [[138.31679]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29. 29.  0.  3.  3.  0.  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  8. 10.  9.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [25.  0.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 113 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 144.97598266601562






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [25.  0.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  8. 10.  9.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 29] -> size -> 17 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  8. 10.  9.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 11. 11.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 29  6] -> size -> 18 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  8. 10.  9.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 11. 11.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 29  6] -> size -> 18 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3. 0.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  8. 10.  9.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 11. 11.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 29  6] -> size -> 18 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0. 29. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11.] 
expected returns: [[71.36177 ]
 [90.6768  ]
 [89.340576]
 [89.340576]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 11. 11.] 
cards in discard: [6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 29  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  8. 10.  9.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  0.] 
adversary cards in discard: [ 0. 25.  0.  0.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0] -> size -> 17 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5    0    0  -60    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -365 

action type: buy - action -1
Learning step: 0
desired expected reward: 138.31678771972656



action possibilites: [-1. 11. 11.] 
expected returns: [[74.65589]
 [92.01099]
 [92.01099]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 11.  3.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 29  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  8. 10.  9.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  0.] 
adversary cards in discard: [ 0. 25.  0.  0.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0] -> size -> 17 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 86.52311706542969



action possibilites: [-1] 
expected returns: [[87.143555]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.] 
cards in discard: [ 6. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 29  6 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  8. 10.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  0.] 
adversary cards in discard: [ 0. 25.  0.  0.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0] -> size -> 17 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 2 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 95.93135833740234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 73.29802 ]
 [ 93.01768 ]
 [ 88.57929 ]
 [ 50.650684]
 [112.01615 ]
 [ 96.27697 ]
 [ 91.83856 ]
 [ 91.3757  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3.] 
cards in discard: [ 6. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 29  6 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  8. 10.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  0.] 
adversary cards in discard: [ 0. 25.  0.  0.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0] -> size -> 17 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 87.1435546875



buy possibilites: [-1] 
expected returns: [[137.07565]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3.] 
cards in discard: [ 6. 10. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 29  6 10 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  7. 10.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  0.] 
adversary cards in discard: [ 0. 25.  0.  0.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0] -> size -> 17 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 29 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 112.01615142822266






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  0.] 
cards in discard: [ 0. 25.  0.  0.  3.  3.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  7. 10.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  0. 29.] 
adversary cards in discard: [ 6. 10. 11. 29. 11.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 29  6 10 11] -> size -> 20 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0. 25.  0.  0.  3.  3.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  7. 10.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  0. 29.] 
adversary cards in discard: [ 6. 10. 11. 29. 11.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 29  6 10 11] -> size -> 20 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0. 25.  0.  0.  3.  3.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  7. 10.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  0. 29.] 
adversary cards in discard: [ 6. 10. 11. 29. 11.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 29  6 10 11] -> size -> 20 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0. 25.  0.  0.  3.  3.  3.  0. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  7. 10.  9.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  0. 29.] 
adversary cards in discard: [ 6. 10. 11. 29. 11.  0.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 29  6 10 11] -> size -> 20 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [ 3.  0.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[134.97952]
 [156.1625 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  0. 29.] 
cards in discard: [ 6. 10. 11. 29. 11.  0.  0. 11.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 29  6 10 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  7. 10.  9.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [25.  0.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14] -> size -> 18 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 137.07565307617188



action possibilites: [-1.] 
expected returns: [[116.888504]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 6. 10. 11. 29. 11.  0.  0. 11.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 29  6 10 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  7. 10.  9.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [25.  0.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14] -> size -> 18 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 150.1850128173828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[104.1683  ]
 [123.27133 ]
 [119.117325]
 [ 81.11449 ]
 [120.648895]
 [141.50372 ]
 [126.35115 ]
 [142.89066 ]
 [102.93078 ]
 [122.197136]
 [122.02203 ]
 [121.47783 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 6. 10. 11. 29. 11.  0.  0. 11.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 29  6 10 11] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  7. 10.  9.  6.  9. 10.  6. 10. 10.] 
adversary cards in hand: [25.  0.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14] -> size -> 18 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 116.88850402832031



buy possibilites: [-1] 
expected returns: [[110.986176]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 6. 10. 11. 29. 11.  0.  0. 11.  3. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 29  6 10 11 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  7. 10.  9.  5.  9. 10.  6. 10. 10.] 
adversary cards in hand: [25.  0.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14] -> size -> 18 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 83 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 142.89065551757812






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [25.  0.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0. 10.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  7. 10.  9.  5.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 29. 10.  0. 29.] 
adversary cards in discard: [ 6. 10. 11. 29. 11.  0.  0. 11.  3. 29. 29.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 29  6 10 11 29] -> size -> 21 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0. 10.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  7. 10.  9.  5.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 29. 10.  0. 29.] 
adversary cards in discard: [ 6. 10. 11. 29. 11.  0.  0. 11.  3. 29. 29.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 29  6 10 11 29] -> size -> 21 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0. 10.  3.] 
cards in discard: [0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 30. 30. 29. 30.  8.  9. 10.  7. 10.  9.  5.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 29. 10.  0. 29.] 
adversary cards in discard: [ 6. 10. 11. 29. 11.  0.  0. 11.  3. 29. 29.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 29  6 10 11 29] -> size -> 21 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [ 0. 29. 10.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 29.] 
expected returns: [[20.677818]
 [41.156837]
 [21.39518 ]
 [41.156837]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10.  0. 29.] 
cards in discard: [ 6. 10. 11. 29. 11.  0.  0. 11.  3. 29. 29.  3.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 29  6 10 11 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 30.  8.  9. 10.  7. 10.  9.  5.  9. 10.  6. 10. 10.] 
adversary cards in hand: [14.  3.  0.  0.  0.] 
adversary cards in discard: [ 0. 25.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 110.98617553710938



action possibilites: [-1. 10. 29.] 
expected returns: [[ 84.12642 ]
 [ 84.38113 ]
 [104.998764]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 29  6 10 11 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 29. 30.  8.  9. 10.  7. 10.  9.  5.  9. 10.  6. 10. 10.] 
adversary cards in hand: [14.  3.  0.  0.  0.] 
adversary cards in discard: [ 0. 25.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 39.658958435058594



action possibilites: [-1. 10.] 
expected returns: [[121.2873 ]
 [121.48288]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  6.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 29  6 10 11 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 30. 30. 29. 30.  8.  9. 10.  7. 10.  9.  5.  9. 10.  6. 10. 10.] 
adversary cards in hand: [14.  3.  0.  0.  0.] 
adversary cards in discard: [ 0. 25.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 104.99876403808594



action possibilites: [-1.] 
expected returns: [[126.11615]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 29  6 10 11 29] -> size -> 21 
action values: 2 
buys: 0 
player value: 2 
card supply: [26. 30. 30. 29. 30.  8.  9. 10.  7. 10.  9.  5.  9. 10.  6. 10. 10.] 
adversary cards in hand: [14.  3.  0.  0.  0.] 
adversary cards in discard: [ 0. 25.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 121.48289489746094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[111.93698 ]
 [131.53961 ]
 [107.63204 ]
 [127.0995  ]
 [ 92.710434]
 [ 88.573715]
 [128.84082 ]
 [150.31877 ]
 [134.77875 ]
 [172.80766 ]
 [151.88254 ]
 [110.57754 ]
 [124.20358 ]
 [130.3386  ]
 [104.826836]
 [130.1415  ]
 [130.05956 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 29  6 10 11 29] -> size -> 21 
action values: 0 
buys: 1 
player value: 6 
card supply: [26. 30. 30. 29. 30.  8.  9. 10.  7. 10.  9.  5.  9. 10.  6. 10. 10.] 
adversary cards in hand: [14.  3.  0.  0.  0.] 
adversary cards in discard: [ 0. 25.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 126.11614990234375



buy possibilites: [-1] 
expected returns: [[133.85504]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 29  6 10 11 29 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 29. 30.  8.  9. 10.  7. 10.  8.  5.  9. 10.  6. 10. 10.] 
adversary cards in hand: [14.  3.  0.  0.  0.] 
adversary cards in discard: [ 0. 25.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5.    0.    0.  -60.    0.    0.   60.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 57.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 172.8076629638672






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [14.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0.  0.  0.] 
cards in discard: [ 0. 25.  0.  0. 10.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 30.  8.  9. 10.  7. 10.  8.  5.  9. 10.  6. 10. 10.] 
adversary cards in hand: [11. 29. 11. 29.  0.] 
adversary cards in discard: [25. 29. 29. 10.  0.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 29  6 10 11 29 25] -> size -> 22 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 0. 25.  0.  0. 10.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 30. 30. 29. 30.  8.  9. 10.  7. 10.  8.  5.  9. 10.  6. 10. 10.] 
adversary cards in hand: [11. 29.  0.] 
adversary cards in discard: [25. 29. 29. 10.  0.  0.  0.  6.  0. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 29  6 10 11 29 25] -> size -> 22 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 0. 25.  0.  0. 10.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 30. 30. 29. 30.  8.  9. 10.  7. 10.  8.  5.  9. 10.  6. 10. 10.] 
adversary cards in hand: [11. 29.  0.] 
adversary cards in discard: [25. 29. 29. 10.  0.  0.  0.  6.  0. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 29  6 10 11 29 25] -> size -> 22 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [11. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[ 86.84119 ]
 [104.933556]
 [106.31494 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  0.] 
cards in discard: [25. 29. 29. 10.  0.  0.  0.  6.  0. 11. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 29  6 10 11 29 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 30.  8.  9. 10.  7. 10.  8.  5.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 0. 25.  0.  0. 10.  3. 14.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5    0    0  -60    0    0    0    0    0    0    0    0    0 -300
  401    0] 
sum of rewards: 36 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -44.63621139526367



action possibilites: [-1. 11.] 
expected returns: [[ 96.88672 ]
 [115.028786]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.] 
cards in discard: [25. 29. 29. 10.  0.  0.  0.  6.  0. 11. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 29  6 10 11 29 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 29. 30.  8.  9. 10.  7. 10.  8.  5.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 0. 25.  0.  0. 10.  3. 14.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 101.94782257080078



action possibilites: [-1] 
expected returns: [[93.194016]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [25. 29. 29. 10.  0.  0.  0.  6.  0. 11. 29. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 29  6 10 11 29 25 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 29. 30.  8.  9. 10.  7. 10.  8.  5.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 0. 25.  0.  0. 10.  3. 14.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 2 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 119.07566833496094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[77.63016 ]
 [91.38169 ]
 [56.250946]
 [98.21658 ]
 [93.914604]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [25. 29. 29. 10.  0.  0.  0.  6.  0. 11. 29. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 29  6 10 11 29 25 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 29. 30.  8.  9. 10.  7. 10.  8.  5.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 0. 25.  0.  0. 10.  3. 14.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 93.19401550292969



buy possibilites: [-1] 
expected returns: [[49.850388]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [25. 29. 29. 10.  0.  0.  0.  6.  0. 11. 29. 10.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 29  6 10 11 29 25 10  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 30.  8.  9. 10.  7.  9.  8.  5.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [ 0. 25.  0.  0. 10.  3. 14.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0] -> size -> 19 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0  16   0] 
sum of rewards: -9 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 98.21658325195312






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 0. 25.  0.  0. 10.  3. 14.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 30.  8.  9. 10.  7.  9.  8.  5.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0. 11.] 
adversary cards in discard: [25. 29. 29. 10.  0.  0.  0.  6.  0. 11. 29. 10.  8. 29. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 29  6 10 11 29 25 10  8] -> size -> 24 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 0. 25.  0.  0. 10.  3. 14.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 29. 30.  8.  9. 10.  7.  9.  8.  5.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0. 11.] 
adversary cards in discard: [25. 29. 29. 10.  0.  0.  0.  6.  0. 11. 29. 10.  8. 29. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 29  6 10 11 29 25 10  8] -> size -> 24 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [ 0. 25.  0.  0. 10.  3. 14.  3.  0.  0.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8.  9. 10.  7.  9.  8.  5.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0. 11.] 
adversary cards in discard: [25. 29. 29. 10.  0.  0.  0.  6.  0. 11. 29. 10.  8. 29. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 29  6 10 11 29 25 10  8] -> size -> 24 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [ 3. 10.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[26.990643]
 [27.370667]
 [42.09648 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0. 11.] 
cards in discard: [25. 29. 29. 10.  0.  0.  0.  6.  0. 11. 29. 10.  8. 29. 11.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 29  6 10 11 29 25 10  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8.  9. 10.  7.  9.  8.  5.  9. 10.  5. 10. 10.] 
adversary cards in hand: [14.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 49.85038757324219



action possibilites: [-1] 
expected returns: [[31.006367]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [25. 29. 29. 10.  0.  0.  0.  6.  0. 11. 29. 10.  8. 29. 11.  0.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 29  6 10 11 29 25 10  8
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8.  9. 10.  7.  9.  8.  5.  9. 10.  4. 10. 10.] 
adversary cards in hand: [14.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -18 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 45.698020935058594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[17.458794 ]
 [27.809093 ]
 [ 1.6320963]
 [32.973778 ]
 [29.84494  ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [25. 29. 29. 10.  0.  0.  0.  6.  0. 11. 29. 10.  8. 29. 11.  0.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 29  6 10 11 29 25 10  8
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 29. 30.  8.  9. 10.  7.  9.  8.  5.  9. 10.  4. 10. 10.] 
adversary cards in hand: [14.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 31.006366729736328



buy possibilites: [-1] 
expected returns: [[3.0246687]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [25. 29. 29. 10.  0.  0.  0.  6.  0. 11. 29. 10.  8. 29. 11.  0.  3. 10.
  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 29  6 10 11 29 25 10  8
 10  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8.  9. 10.  7.  8.  8.  5.  9. 10.  4. 10. 10.] 
adversary cards in hand: [14.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -29 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 32.97377395629883






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [14.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8.  9. 10.  7.  8.  8.  5.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  3.  8. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 29  6 10 11 29 25 10  8
 10  8] -> size -> 26 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 29. 30.  8.  9. 10.  7.  8.  8.  5.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  3.  8. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 29  6 10 11 29 25 10  8
 10  8] -> size -> 26 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  0. 10.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8.  9. 10.  7.  8.  8.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 3.  3.  8. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 29  6 10 11 29 25 10  8
 10  8] -> size -> 26 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [ 3.  3.  8. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[ 99.703064]
 [103.939896]
 [120.02545 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  8. 29.  3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 29  6 10 11 29 25 10  8
 10  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8.  9. 10.  7.  8.  8.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  3.  1. 10.  0.] 
adversary cards in discard: [10. 14.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10] -> size -> 21 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 3.0246686935424805



action possibilites: [-1.  8.  8.] 
expected returns: [[82.820694]
 [87.13281 ]
 [87.13281 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8. 3. 8.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 29 29  6 10 11 29 25 10  8
 10  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 29. 30.  8.  9. 10.  7.  8.  8.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  3.  1. 10.  0.] 
adversary cards in discard: [10. 14.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10] -> size -> 21 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 114.17523956298828



action possibilites: [-1] 
expected returns: [[84.25877]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 10 11 29 29  6 10 11 29 25 10  8 10
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 29. 30.  8.  9. 10.  7.  8.  8.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  3.  1. 10.  0.] 
adversary cards in discard: [10. 14.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10] -> size -> 21 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 83.33206176757812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[71.71489 ]
 [50.020798]
 [88.84085 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 10 11 29 29  6 10 11 29 25 10  8 10
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 29. 30.  8.  9. 10.  7.  8.  8.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  3.  1. 10.  0.] 
adversary cards in discard: [10. 14.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10] -> size -> 21 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 84.25877380371094






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  1. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1. 10.  0.] 
cards in discard: [10. 14.  0.  0.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8.  9. 10.  7.  8.  8.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 6. 29. 29.  0. 29.] 
adversary cards in discard: [29.  8.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 10 11 29 29  6 10 11 29 25 10  8 10
  8] -> size -> 25 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1. 10.  0.] 
cards in discard: [10. 14.  0.  0.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 29. 30.  8.  9. 10.  7.  8.  8.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 6. 29. 29.  0. 29.] 
adversary cards in discard: [29.  8.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 10 11 29 29  6 10 11 29 25 10  8 10
  8] -> size -> 25 
adversary victory points: 1
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 6. 29. 29.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[ 84.47635]
 [105.2894 ]
 [105.2894 ]
 [105.2894 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29. 29.  0. 29.] 
cards in discard: [29.  8.  3.  3.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 10 11 29 29  6 10 11 29 25 10  8 10
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8.  9. 10.  7.  8.  8.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  0.  3.] 
adversary cards in discard: [10. 14.  0.  0.  0. 10.  0.  3.  1. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10] -> size -> 21 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 88.84086608886719



action possibilites: [-1. 29. 29. 10.] 
expected returns: [[ 92.2552 ]
 [113.33667]
 [113.33667]
 [ 92.63354]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29.  0. 29. 10.] 
cards in discard: [29.  8.  3.  3.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 10 11 29 29  6 10 11 29 25 10  8 10
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 29. 30.  8.  9. 10.  7.  8.  8.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  0.  3.] 
adversary cards in discard: [10. 14.  0.  0.  0. 10.  0.  3.  1. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10] -> size -> 21 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 100.36332702636719



action possibilites: [-1. 29. 10.] 
expected returns: [[114.76868]
 [134.77657]
 [115.09358]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 29. 10.  0.] 
cards in discard: [29.  8.  3.  3.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 10 11 29 29  6 10 11 29 25 10  8 10
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 29. 30.  8.  9. 10.  7.  8.  8.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  0.  3.] 
adversary cards in discard: [10. 14.  0.  0.  0. 10.  0.  3.  1. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10] -> size -> 21 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 113.336669921875



action possibilites: [-1. 10.] 
expected returns: [[104.12654]
 [104.53589]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10.  0.  0.] 
cards in discard: [29.  8.  3.  3.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 10 11 29 29  6 10 11 29 25 10  8 10
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 3 
card supply: [26. 29. 30. 29. 30.  8.  9. 10.  7.  8.  8.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  0.  3.] 
adversary cards in discard: [10. 14.  0.  0.  0. 10.  0.  3.  1. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10] -> size -> 21 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 134.77658081054688



action possibilites: [-1. 10.] 
expected returns: [[120.81357]
 [121.09787]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0.  0. 10.] 
cards in discard: [29.  8.  3.  3.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 10 11 29 29  6 10 11 29 25 10  8 10
  8] -> size -> 25 
action values: 2 
buys: 0 
player value: 3 
card supply: [26. 29. 30. 29. 30.  8.  9. 10.  7.  8.  8.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  0.  3.] 
adversary cards in discard: [10. 14.  0.  0.  0. 10.  0.  3.  1. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10] -> size -> 21 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 104.535888671875



action possibilites: [-1.] 
expected returns: [[118.17489]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [29.  8.  3.  3.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 10 11 29 29  6 10 11 29 25 10  8 10
  8] -> size -> 25 
action values: 3 
buys: 0 
player value: 3 
card supply: [26. 29. 30. 29. 30.  8.  9. 10.  7.  8.  8.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  0.  3.] 
adversary cards in discard: [10. 14.  0.  0.  0. 10.  0.  3.  1. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10] -> size -> 21 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 121.0978775024414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[100.25067 ]
 [117.90324 ]
 [ 96.32162 ]
 [113.97418 ]
 [ 82.56655 ]
 [ 78.709694]
 [115.51595 ]
 [134.79788 ]
 [120.76648 ]
 [155.46352 ]
 [136.21938 ]
 [ 99.027306]
 [111.42933 ]
 [116.83743 ]
 [ 93.77678 ]
 [116.67983 ]
 [116.566765]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [29.  8.  3.  3.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 10 11 29 29  6 10 11 29 25 10  8 10
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 7 
card supply: [26. 29. 30. 29. 30.  8.  9. 10.  7.  8.  8.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  0.  3.] 
adversary cards in discard: [10. 14.  0.  0.  0. 10.  0.  3.  1. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10] -> size -> 21 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 118.17488861083984



buy possibilites: [-1] 
expected returns: [[83.70822]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [29.  8.  3.  3.  8. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 10 11 29 29  6 10 11 29 25 10  8 10
  8 25] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 29. 30.  8.  9. 10.  7.  8.  7.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  0.  3.] 
adversary cards in discard: [10. 14.  0.  0.  0. 10.  0.  3.  1. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10] -> size -> 21 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5.    0.    0.  -90.    0.    0.  100.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 67.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 155.46351623535156






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 25.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.  0.  3.] 
cards in discard: [10. 14.  0.  0.  0. 10.  0.  3.  1. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8.  9. 10.  7.  8.  7.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [25. 11.  0. 29. 11.] 
adversary cards in discard: [29.  8.  3.  3.  8. 25. 29. 29. 29. 10. 10.  6.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 10 11 29 29  6 10 11 29 25 10  8 10
  8 25] -> size -> 26 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3. 0.] 
cards in discard: [10. 14.  0.  0.  0. 10.  0.  3.  1. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8.  8. 10.  7.  8.  7.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [25. 11.  0. 29. 11.] 
adversary cards in discard: [29.  8.  3.  3.  8. 25. 29. 29. 29. 10. 10.  6.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 10 11 29 29  6 10 11 29 25 10  8 10
  8 25  6] -> size -> 27 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3. 0.] 
cards in discard: [10. 14.  0.  0.  0. 10.  0.  3.  1. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 29. 30.  8.  8. 10.  7.  8.  7.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [25. 11.  0. 29. 11.] 
adversary cards in discard: [29.  8.  3.  3.  8. 25. 29. 29. 29. 10. 10.  6.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 10 11 29 29  6 10 11 29 25 10  8 10
  8 25  6] -> size -> 27 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3. 0.] 
cards in discard: [10. 14.  0.  0.  0. 10.  0.  3.  1. 10.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 29. 30.  8.  8. 10.  7.  8.  7.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [25. 11.  0. 29. 11.] 
adversary cards in discard: [29.  8.  3.  3.  8. 25. 29. 29. 29. 10. 10.  6.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 10 11 29 29  6 10 11 29 25 10  8 10
  8 25  6] -> size -> 27 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [25. 11.  0. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 29. 11.] 
expected returns: [[-8.020099 ]
 [15.069968 ]
 [ 2.6702242]
 [ 3.6408253]
 [ 2.6702242]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11.  0. 29. 11.] 
cards in discard: [29.  8.  3.  3.  8. 25. 29. 29. 29. 10. 10.  6.  0.  0.  0.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 10 11 29 29  6 10 11 29 25 10  8 10
  8 25  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  8. 10.  7.  8.  7.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1] -> size -> 22 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -425 

action type: buy - action -1
Learning step: 0
desired expected reward: 83.70822143554688



action possibilites: [-1] 
expected returns: [[1.9486027]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 29. 11. 10. 11.] 
cards in discard: [29.  8.  3.  3.  8. 25. 29. 29. 29. 10. 10.  6.  0.  0.  0.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 10 11 29 29  6 10 11 29 25 10  8 10
  8 25  6] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  7. 10.  7.  8.  7.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6] -> size -> 23 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 15.069958686828613





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -9.170637 ]
 [-21.543163 ]
 [  1.5103111]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 29. 11. 10. 11.] 
cards in discard: [29.  8.  3.  3.  8. 25. 29. 29. 29. 10. 10.  6.  0.  0.  0.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 10 11 29 29  6 10 11 29 25 10  8 10
  8 25  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 29. 30.  8.  7. 10.  7.  8.  7.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6] -> size -> 23 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 1.9486026763916016






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  7. 10.  7.  8.  7.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [29.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 10 11 29 29  6 10 11 29 25 10  8 10
  8 25  6] -> size -> 27 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 28. 30. 29. 30.  8.  7. 10.  7.  8.  7.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [29.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 10 11 29 29  6 10 11 29 25 10  8 10
  8 25  6] -> size -> 27 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [6. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 4 
card supply: [25. 28. 30. 29. 30.  8.  7. 10.  7.  8.  7.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [29.  0. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 10 11 29 29  6 10 11 29 25 10  8 10
  8 25  6] -> size -> 27 
adversary victory points: 0
player victory points: 3 





Player: 0 
cards in hand: [29.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[ 88.728165]
 [106.787445]
 [ 88.78406 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 10 11 29 29  6 10 11 29 25 10  8 10
  8 25  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  7. 10.  7.  8.  7.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [6. 0. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0] -> size -> 24 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 1.5103039741516113



action possibilites: [-1. 10. 29.] 
expected returns: [[59.238586]
 [59.390755]
 [79.81768 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 10 11 29 29  6 10 11 29 25 10  8 10
  8 25  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 29. 30.  8.  7. 10.  7.  8.  7.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [6. 0. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0] -> size -> 24 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 103.40509033203125



action possibilites: [-1. 10.  8.] 
expected returns: [[128.60751]
 [129.06607]
 [133.54001]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 29 10 11 29 29  6 10 11 29 25 10  8 10
  8 25  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 28. 30. 29. 30.  8.  7. 10.  7.  8.  7.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [6. 0. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0] -> size -> 24 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 79.81768035888672



action possibilites: [-1] 
expected returns: [[87.54697]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 28. 30. 29. 30.  8.  7. 10.  7.  8.  7.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [6. 0. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0] -> size -> 24 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: trash_cards_n_from_hand - action 8
Learning step: 0
desired expected reward: 134.13211059570312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[77.27861 ]
 [89.40734 ]
 [58.202824]
 [95.64395 ]
 [92.35524 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 29. 30.  8.  7. 10.  7.  8.  7.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [6. 0. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0] -> size -> 24 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 87.54696655273438



buy possibilites: [-1] 
expected returns: [[73.246254]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  7. 10.  7.  7.  7.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [6. 0. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0] -> size -> 24 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  60   0   0   0   0   0   0   0  16   0] 
sum of rewards: -19 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 95.64396667480469






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  3.] 
cards in discard: [6. 0. 0. 0. 0. 0. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  7. 10.  7.  7.  7.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 25.  3.  0. 10.] 
adversary cards in discard: [ 8. 29. 29.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6  8] -> size -> 24 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 25.] 
cards in discard: [6. 0. 0. 0. 0. 0. 3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  7. 10.  7.  7.  7.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 25.  3.  0. 10.] 
adversary cards in discard: [ 8. 29. 29.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6  8] -> size -> 24 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 25.] 
cards in discard: [6. 0. 0. 0. 0. 0. 3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 29. 30.  8.  7. 10.  7.  7.  7.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 25.  3.  0. 10.] 
adversary cards in discard: [ 8. 29. 29.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6  8] -> size -> 24 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 25.] 
cards in discard: [6. 0. 0. 0. 0. 0. 3. 1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 30.  8.  7. 10.  7.  7.  7.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 25.  3.  0. 10.] 
adversary cards in discard: [ 8. 29. 29.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6  8] -> size -> 24 
adversary victory points: 0
player victory points: 3 





Player: 0 
cards in hand: [ 0. 25.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
expected returns: [[41.763123]
 [81.28878 ]
 [41.85875 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3.  0. 10.] 
cards in discard: [ 8. 29. 29.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 30.  8.  7. 10.  7.  7.  7.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [10.  0. 10.  0. 14.] 
adversary cards in discard: [ 6.  0.  0.  0.  0.  0.  3.  1. 10.  0.  0.  0.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1] -> size -> 25 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 73.24625396728516



action possibilites: [-1] 
expected returns: [[38.53319]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10.  0. 11.] 
cards in discard: [ 8. 29. 29.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 30.  8.  6. 10.  7.  7.  7.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [10.  0. 10.  0. 14.] 
adversary cards in discard: [ 6.  0.  0.  0.  0.  0.  3.  1. 10.  0.  0.  0.  3. 25.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6] -> size -> 26 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 77.28118133544922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[19.228432 ]
 [36.826557 ]
 [32.87531  ]
 [-1.9902515]
 [54.072414 ]
 [39.79737  ]
 [35.735195 ]
 [35.4954   ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.  0. 11.] 
cards in discard: [ 8. 29. 29.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 27. 30. 29. 30.  8.  6. 10.  7.  7.  7.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [10.  0. 10.  0. 14.] 
adversary cards in discard: [ 6.  0.  0.  0.  0.  0.  3.  1. 10.  0.  0.  0.  3. 25.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6] -> size -> 26 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 38.5331916809082



buy possibilites: [-1] 
expected returns: [[34.240257]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.  0. 11.] 
cards in discard: [ 8. 29. 29.  8. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6  8
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 30.  8.  6. 10.  6.  7.  7.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [10.  0. 10.  0. 14.] 
adversary cards in discard: [ 6.  0.  0.  0.  0.  0.  3.  1. 10.  0.  0.  0.  3. 25.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6] -> size -> 26 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: -21 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 54.072410583496094






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [10.  0. 10.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 14.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  0. 14.] 
cards in discard: [ 6.  0.  0.  0.  0.  0.  3.  1. 10.  0.  0.  0.  3. 25.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 30.  8.  6. 10.  6.  7.  7.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [29.  6. 11.  8. 25.] 
adversary cards in discard: [ 8. 29. 29.  8. 11. 25.  0.  3.  0. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6  8
 11] -> size -> 25 
adversary victory points: 0
player victory points: 2 


action possibilites: [-1. 10. 14.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 14.  3.] 
cards in discard: [ 6.  0.  0.  0.  0.  0.  3.  1. 10.  0.  0.  0.  3. 25.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 30.  8.  6. 10.  6.  7.  7.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [29.  6. 11.  8. 25.] 
adversary cards in discard: [ 8. 29. 29.  8. 11. 25.  0.  3.  0. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6  8
 11] -> size -> 25 
adversary victory points: 0
player victory points: 2 


action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  3.  0.] 
cards in discard: [ 6.  0.  0.  0.  0.  0.  3.  1. 10.  0.  0.  0.  3. 25.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6] -> size -> 26 
action values: 3 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 29. 30.  8.  6. 10.  6.  7.  7.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [29.  6. 11.  8. 25.] 
adversary cards in discard: [ 8. 29. 29.  8. 11. 25.  0.  3.  0. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6  8
 11] -> size -> 25 
adversary victory points: 0
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 6.  0.  0.  0.  0.  0.  3.  1. 10.  0.  0.  0.  3. 25.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 10. 14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6] -> size -> 26 
action values: 2 
buys: 0 
player value: 2 
card supply: [25. 27. 30. 29. 30.  8.  6. 10.  6.  7.  7.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 6. 11. 25.] 
adversary cards in discard: [ 8. 29. 29.  8. 11. 25.  0.  3.  0. 10.  0. 11. 29.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6  8
 11] -> size -> 25 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 6.  0.  0.  0.  0.  0.  3.  1. 10.  0.  0.  0.  3. 25.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 10. 14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 27. 30. 29. 30.  8.  6. 10.  6.  7.  7.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 6. 11. 25.] 
adversary cards in discard: [ 8. 29. 29.  8. 11. 25.  0.  3.  0. 10.  0. 11. 29.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6  8
 11] -> size -> 25 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 6.  0.  0.  0.  0.  0.  3.  1. 10.  0.  0.  0.  3. 25.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 10. 14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 5 
card supply: [24. 27. 30. 29. 30.  8.  6. 10.  6.  7.  7.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 6. 11. 25.] 
adversary cards in discard: [ 8. 29. 29.  8. 11. 25.  0.  3.  0. 10.  0. 11. 29.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6  8
 11] -> size -> 25 
adversary victory points: 0
player victory points: 2 





Player: 0 
cards in hand: [ 6. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[42.3412 ]
 [58.66832]
 [78.06204]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11. 25.] 
cards in discard: [ 8. 29. 29.  8. 11. 25.  0.  3.  0. 10.  0. 11. 29.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6  8
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 30.  8.  6. 10.  6.  7.  7.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [0. 0. 1. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0] -> size -> 27 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: discard_down_to_3_cards - action 9
Learning step: 0
desired expected reward: -52.61444854736328



action possibilites: [-1] 
expected returns: [[15.748445]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  3. 29.] 
cards in discard: [ 8. 29. 29.  8. 11. 25.  0.  3.  0. 10.  0. 11. 29.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6  8
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 30.  8.  5. 10.  6.  7.  7.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [0. 0. 1. 1. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6] -> size -> 28 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 78.06204223632812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[  0.48741627]
 [-17.69251   ]
 [ 14.258203  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  3. 29.] 
cards in discard: [ 8. 29. 29.  8. 11. 25.  0.  3.  0. 10.  0. 11. 29.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6  8
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 27. 30. 29. 30.  8.  5. 10.  6.  7.  7.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [0. 0. 1. 1. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6] -> size -> 28 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 15.748444557189941






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [0. 0. 1. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 1. 3.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 30.  8.  5. 10.  6.  7.  7.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [11.  0.  6. 10. 29.] 
adversary cards in discard: [ 8. 29. 29.  8. 11. 25.  0.  3.  0. 10.  0. 11. 29.  8. 25.  6. 11.  3.
 29.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6  8
 11] -> size -> 25 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 1. 3.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 6 
card supply: [24. 27. 30. 29. 30.  8.  5. 10.  6.  7.  7.  5.  9. 10.  3. 10. 10.] 
adversary cards in hand: [11.  0.  6. 10. 29.] 
adversary cards in discard: [ 8. 29. 29.  8. 11. 25.  0.  3.  0. 10.  0. 11. 29.  8. 25.  6. 11.  3.
 29.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6  8
 11] -> size -> 25 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 1. 3.] 
cards in discard: [ 6. 23.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 29. 30.  8.  5. 10.  6.  7.  7.  5.  9.  9.  3. 10. 10.] 
adversary cards in hand: [11.  0.  6. 10. 29.] 
adversary cards in discard: [ 8. 29. 29.  8. 11. 25.  0.  3.  0. 10.  0. 11. 29.  8. 25.  6. 11.  3.
 29.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6  8
 11] -> size -> 25 
adversary victory points: 0
player victory points: 1 





Player: 0 
cards in hand: [11.  0.  6. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29.] 
expected returns: [[-6.627433 ]
 [ 3.9435186]
 [-6.936847 ]
 [ 4.9292574]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6. 10. 29.] 
cards in discard: [ 8. 29. 29.  8. 11. 25.  0.  3.  0. 10.  0. 11. 29.  8. 25.  6. 11.  3.
 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6  8
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 30.  8.  5. 10.  6.  7.  7.  5.  9.  9.  3. 10. 10.] 
adversary cards in hand: [0. 0. 6. 0. 1.] 
adversary cards in discard: [ 6. 23.  0.  0.  1.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23] -> size -> 29 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 14.258196830749512



action possibilites: [-1. 11. 10. 10.] 
expected returns: [[-9.319975]
 [ 2.333632]
 [-9.480411]
 [-9.480411]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6. 10. 10.] 
cards in discard: [ 8. 29. 29.  8. 11. 25.  0.  3.  0. 10.  0. 11. 29.  8. 25.  6. 11.  3.
 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6  8
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 29. 30.  8.  5. 10.  6.  7.  7.  5.  9.  9.  3. 10. 10.] 
adversary cards in hand: [0. 0. 6. 0. 1.] 
adversary cards in discard: [ 6. 23.  0.  0.  1.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23] -> size -> 29 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 4.929241180419922



action possibilites: [-1] 
expected returns: [[-12.206288]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 10. 10.] 
cards in discard: [ 8. 29. 29.  8. 11. 25.  0.  3.  0. 10.  0. 11. 29.  8. 25.  6. 11.  3.
 29. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6  8
 11 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 29. 30.  8.  5. 10.  6.  7.  7.  5.  9.  9.  2. 10. 10.] 
adversary cards in hand: [0. 0. 6. 0. 1.] 
adversary cards in discard: [ 6. 23.  0.  0.  1.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23] -> size -> 29 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 5.1355390548706055





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-21.847202]
 [-14.364682]
 [-33.495018]
 [-10.073275]
 [-12.302783]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 10. 10.] 
cards in discard: [ 8. 29. 29.  8. 11. 25.  0.  3.  0. 10.  0. 11. 29.  8. 25.  6. 11.  3.
 29. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6  8
 11 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 27. 30. 29. 30.  8.  5. 10.  6.  7.  7.  5.  9.  9.  2. 10. 10.] 
adversary cards in hand: [0. 0. 6. 0. 1.] 
adversary cards in discard: [ 6. 23.  0.  0.  1.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23] -> size -> 29 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: -12.20628833770752



buy possibilites: [-1] 
expected returns: [[-12.677919]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 10. 10.] 
cards in discard: [ 8. 29. 29.  8. 11. 25.  0.  3.  0. 10.  0. 11. 29.  8. 25.  6. 11.  3.
 29. 10.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6  8
 11 10  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 30.  8.  5. 10.  6.  6.  7.  5.  9.  9.  2. 10. 10.] 
adversary cards in hand: [0. 0. 6. 0. 1.] 
adversary cards in discard: [ 6. 23.  0.  0.  1.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23] -> size -> 29 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  16   0] 
sum of rewards: 21 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -10.073273658752441






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [0. 0. 6. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 1.] 
cards in discard: [ 6. 23.  0.  0.  1.  1.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 30.  8.  5. 10.  6.  6.  7.  5.  9.  9.  2. 10. 10.] 
adversary cards in hand: [ 0. 29.  8. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6  8
 11 10  8] -> size -> 27 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 1.] 
cards in discard: [ 6. 23.  0.  0.  1.  1.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23] -> size -> 29 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 27. 30. 29. 30.  8.  5. 10.  6.  6.  7.  5.  9.  9.  2. 10. 10.] 
adversary cards in hand: [ 0. 29.  8. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6  8
 11 10  8] -> size -> 27 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 1.] 
cards in discard: [ 6. 23.  0.  0.  1.  1.  3. 14.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 29. 30.  8.  5. 10.  6.  6.  7.  5.  8.  9.  2. 10. 10.] 
adversary cards in hand: [ 0. 29.  8. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6  8
 11 10  8] -> size -> 27 
adversary victory points: 0
player victory points: 1 





Player: 0 
cards in hand: [ 0. 29.  8. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 11.] 
expected returns: [[36.87803 ]
 [53.165997]
 [40.04239 ]
 [51.9233  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  8. 11.  3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6  8
 11 10  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 30.  8.  5. 10.  6.  6.  7.  5.  8.  9.  2. 10. 10.] 
adversary cards in hand: [ 0. 10. 10. 10.  0.] 
adversary cards in discard: [ 6. 23.  0.  0.  1.  1.  3. 14.  0.  0.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14] -> size -> 30 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: -12.677919387817383



action possibilites: [-1.  8. 11. 25.] 
expected returns: [[ 4.040843 ]
 [ 7.3159647]
 [19.062786 ]
 [35.718952 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11.  3. 25.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6  8
 11 10  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 29. 30.  8.  5. 10.  6.  6.  7.  5.  8.  9.  2. 10. 10.] 
adversary cards in hand: [ 0. 10. 10. 10.  0.] 
adversary cards in discard: [ 6. 23.  0.  0.  1.  1.  3. 14.  0.  0.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14] -> size -> 30 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 51.99626922607422



action possibilites: [-1] 
expected returns: [[16.054276]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11.  3. 29.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6  8
 11 10  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 29. 30.  8.  4. 10.  6.  6.  7.  5.  8.  9.  2. 10. 10.] 
adversary cards in hand: [ 0. 10. 10. 10.  0.] 
adversary cards in discard: [ 6. 23.  0.  0.  1.  1.  3. 14.  0.  0.  6.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6] -> size -> 31 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 35.71895217895508





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[  3.6571445]
 [ 18.193787 ]
 [ 14.906461 ]
 [-13.169819 ]
 [ 31.846882 ]
 [ 20.562965 ]
 [ 17.275654 ]
 [ 17.194233 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 11.  3. 29.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6  8
 11 10  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 27. 30. 29. 30.  8.  4. 10.  6.  6.  7.  5.  8.  9.  2. 10. 10.] 
adversary cards in hand: [ 0. 10. 10. 10.  0.] 
adversary cards in discard: [ 6. 23.  0.  0.  1.  1.  3. 14.  0.  0.  6.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6] -> size -> 31 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 16.054275512695312



buy possibilites: [-1] 
expected returns: [[41.640297]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 11.  3. 29.  0.] 
cards in discard: [11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6  8
 11 10  8 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 30.  8.  4. 10.  5.  6.  7.  5.  8.  9.  2. 10. 10.] 
adversary cards in hand: [ 0. 10. 10. 10.  0.] 
adversary cards in discard: [ 6. 23.  0.  0.  1.  1.  3. 14.  0.  0.  6.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6] -> size -> 31 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 59 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 31.84688949584961






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 0. 10. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10. 10.  0.] 
cards in discard: [ 6. 23.  0.  0.  1.  1.  3. 14.  0.  0.  6.  0.  1.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 30.  8.  4. 10.  5.  6.  7.  5.  8.  9.  2. 10. 10.] 
adversary cards in hand: [ 3. 11. 10. 11.  6.] 
adversary cards in discard: [11. 29. 25.  0.  8. 11.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6  8
 11 10  8 11] -> size -> 28 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.  0.  0.] 
cards in discard: [ 6. 23.  0.  0.  1.  1.  3. 14.  0.  0.  6.  0.  1.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 30.  8.  4. 10.  5.  6.  7.  5.  8.  9.  2. 10. 10.] 
adversary cards in hand: [ 3. 11. 10. 11.  6.] 
adversary cards in discard: [11. 29. 25.  0.  8. 11.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6  8
 11 10  8 11] -> size -> 28 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  0.] 
cards in discard: [ 6. 23.  0.  0.  1.  1.  3. 14.  0.  0.  6.  0.  1.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6] -> size -> 31 
action values: 3 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 30.  8.  4. 10.  5.  6.  7.  5.  8.  9.  2. 10. 10.] 
adversary cards in hand: [ 3. 11. 10. 11.  6.] 
adversary cards in discard: [11. 29. 25.  0.  8. 11.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6  8
 11 10  8 11] -> size -> 28 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 6. 23.  0.  0.  1.  1.  3. 14.  0.  0.  6.  0.  1.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6] -> size -> 31 
action values: 4 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 30.  8.  4. 10.  5.  6.  7.  5.  8.  9.  2. 10. 10.] 
adversary cards in hand: [ 3. 11. 10. 11.  6.] 
adversary cards in discard: [11. 29. 25.  0.  8. 11.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6  8
 11 10  8 11] -> size -> 28 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 6. 23.  0.  0.  1.  1.  3. 14.  0.  0.  6.  0.  1.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 27. 30. 29. 30.  8.  4. 10.  5.  6.  7.  5.  8.  9.  2. 10. 10.] 
adversary cards in hand: [ 3. 11. 10. 11.  6.] 
adversary cards in discard: [11. 29. 25.  0.  8. 11.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6  8
 11 10  8 11] -> size -> 28 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 6. 23.  0.  0.  1.  1.  3. 14.  0.  0.  6.  0.  1.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 4 
card supply: [23. 27. 30. 29. 30.  8.  4. 10.  5.  6.  7.  5.  8.  9.  2. 10. 10.] 
adversary cards in hand: [ 3. 11. 10. 11.  6.] 
adversary cards in discard: [11. 29. 25.  0.  8. 11.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6  8
 11 10  8 11] -> size -> 28 
adversary victory points: 0
player victory points: 0 





Player: 0 
cards in hand: [ 3. 11. 10. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11.] 
expected returns: [[32.595184]
 [50.14238 ]
 [32.8677  ]
 [50.14238 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10. 11.  6.] 
cards in discard: [11. 29. 25.  0.  8. 11.  3. 29.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6  8
 11 10  8 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 29. 30.  8.  4. 10.  5.  6.  7.  5.  8.  9.  2. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 0.] 
adversary cards in discard: [ 6. 23.  0.  0.  1.  1.  3. 14.  0.  0.  6.  0.  1.  6.  0. 10. 10. 10.
  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0] -> size -> 32 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 41.640296936035156



action possibilites: [-1] 
expected returns: [[19.211727]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11.  6.] 
cards in discard: [11. 29. 25.  0.  8. 11.  3. 29.  0. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6  8
 11 10  8 11 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 29. 30.  8.  4. 10.  5.  6.  7.  5.  8.  9.  1. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 0.] 
adversary cards in discard: [ 6. 23.  0.  0.  1.  1.  3. 14.  0.  0.  6.  0.  1.  6.  0. 10. 10. 10.
  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0] -> size -> 32 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 53.98678970336914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 7.1988792]
 [-7.808648 ]
 [19.250397 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 11.  6.] 
cards in discard: [11. 29. 25.  0.  8. 11.  3. 29.  0. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6  8
 11 10  8 11 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 27. 30. 29. 30.  8.  4. 10.  5.  6.  7.  5.  8.  9.  1. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 0.] 
adversary cards in discard: [ 6. 23.  0.  0.  1.  1.  3. 14.  0.  0.  6.  0.  1.  6.  0. 10. 10. 10.
  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0] -> size -> 32 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 19.211727142333984






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 6. 0.] 
cards in discard: [ 6. 23.  0.  0.  1.  1.  3. 14.  0.  0.  6.  0.  1.  6.  0. 10. 10. 10.
  0.  0.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 29. 30.  8.  4. 10.  5.  6.  7.  5.  8.  9.  1. 10. 10.] 
adversary cards in hand: [ 6. 10. 10.  8.  0.] 
adversary cards in discard: [11. 29. 25.  0.  8. 11.  3. 29.  0. 10. 11.  3. 10. 11.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6  8
 11 10  8 11 10] -> size -> 29 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 0.] 
cards in discard: [ 6. 23.  0.  0.  1.  1.  3. 14.  0.  0.  6.  0.  1.  6.  0. 10. 10. 10.
  0.  0.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 27. 30. 29. 30.  8.  4. 10.  5.  6.  7.  5.  8.  9.  1. 10. 10.] 
adversary cards in hand: [ 6. 10. 10.  8.  0.] 
adversary cards in discard: [11. 29. 25.  0.  8. 11.  3. 29.  0. 10. 11.  3. 10. 11.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6  8
 11 10  8 11 10] -> size -> 29 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 0.] 
cards in discard: [ 6. 23.  0.  0.  1.  1.  3. 14.  0.  0.  6.  0.  1.  6.  0. 10. 10. 10.
  0.  0.  0.  0.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 28. 30.  8.  4. 10.  5.  6.  7.  5.  8.  9.  1. 10. 10.] 
adversary cards in hand: [ 6. 10. 10.  8.  0.] 
adversary cards in discard: [11. 29. 25.  0.  8. 11.  3. 29.  0. 10. 11.  3. 10. 11.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6  8
 11 10  8 11 10] -> size -> 29 
adversary victory points: 0
player victory points: 1 





Player: 0 
cards in hand: [ 6. 10. 10.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.  8.] 
expected returns: [[-8.888554]
 [-9.031283]
 [-9.031283]
 [-6.414864]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10. 10.  8.  0.] 
cards in discard: [11. 29. 25.  0.  8. 11.  3. 29.  0. 10. 11.  3. 10. 11.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 29 29 11 29 29  6 10 11 29 25 10  8 10  8 25  6  8
 11 10  8 11 10] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 28. 30.  8.  4. 10.  5.  6.  7.  5.  8.  9.  1. 10. 10.] 
adversary cards in hand: [ 6.  3.  0. 14. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3] -> size -> 33 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 19.250396728515625



action possibilites: [-1] 
expected returns: [[49.84547]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [11. 29. 25.  0.  8. 11.  3. 29.  0. 10. 11.  3. 10. 11.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 28. 30.  8.  4. 10.  5.  6.  7.  5.  8.  9.  1. 10. 10.] 
adversary cards in hand: [ 6.  3.  0. 14. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3] -> size -> 33 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 5.312392234802246





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[34.49736]
 [18.03638]
 [48.02243]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [11. 29. 25.  0.  8. 11.  3. 29.  0. 10. 11.  3. 10. 11.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 27. 30. 28. 30.  8.  4. 10.  5.  6.  7.  5.  8.  9.  1. 10. 10.] 
adversary cards in hand: [ 6.  3.  0. 14. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3] -> size -> 33 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 49.8454704284668






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 6.  3.  0. 14. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  0. 14. 25.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 28. 30.  8.  4. 10.  5.  6.  7.  5.  8.  9.  1. 10. 10.] 
adversary cards in hand: [ 8. 29. 10. 29.  0.] 
adversary cards in discard: [11. 29. 25.  0.  8. 11.  3. 29.  0. 10. 11.  3. 10. 11.  6.  8. 10.] 
adversary owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10] -> size -> 26 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  0. 14.  0.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 28. 30.  8.  3. 10.  5.  6.  7.  5.  8.  9.  1. 10. 10.] 
adversary cards in hand: [ 8. 29. 10. 29.  0.] 
adversary cards in discard: [11. 29. 25.  0.  8. 11.  3. 29.  0. 10. 11.  3. 10. 11.  6.  8. 10.  6.] 
adversary owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6] -> size -> 27 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  0. 14.  0.  0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 27. 30. 28. 30.  8.  3. 10.  5.  6.  7.  5.  8.  9.  1. 10. 10.] 
adversary cards in hand: [ 8. 29. 10. 29.  0.] 
adversary cards in discard: [11. 29. 25.  0.  8. 11.  3. 29.  0. 10. 11.  3. 10. 11.  6.  8. 10.  6.] 
adversary owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6] -> size -> 27 
adversary victory points: 1
player victory points: 1 





Player: 0 
cards in hand: [ 8. 29. 10. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 10. 29.] 
expected returns: [[ 4.266798 ]
 [ 7.2863913]
 [18.372528 ]
 [ 4.3662033]
 [18.372528 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29. 10. 29.  0.] 
cards in discard: [11. 29. 25.  0.  8. 11.  3. 29.  0. 10. 11.  3. 10. 11.  6.  8. 10.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 28. 30.  8.  3. 10.  5.  6.  7.  5.  8.  9.  1. 10. 10.] 
adversary cards in hand: [3. 1. 0. 6. 0.] 
adversary cards in discard: [25.  6.  3.  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3] -> size -> 33 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[  -5    0    0  -30    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -335 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 48.022422790527344



action possibilites: [-1.  8. 10. 29. 25.] 
expected returns: [[6.1403751e-02]
 [2.7746124e+00]
 [3.6835670e-03]
 [1.3362721e+01]
 [2.6612183e+01]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 29.  0. 25.] 
cards in discard: [11. 29. 25.  0.  8. 11.  3. 29.  0. 10. 11.  3. 10. 11.  6.  8. 10.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 28. 30.  8.  3. 10.  5.  6.  7.  5.  8.  9.  1. 10. 10.] 
adversary cards in hand: [3. 1. 0. 6. 0.] 
adversary cards in discard: [25.  6.  3.  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3] -> size -> 33 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 18.37252426147461



action possibilites: [-1] 
expected returns: [[-19.482697]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 29.  0. 29. 11.] 
cards in discard: [11. 29. 25.  0.  8. 11.  3. 29.  0. 10. 11.  3. 10. 11.  6.  8. 10.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 28. 30.  8.  2. 10.  5.  6.  7.  5.  8.  9.  1. 10. 10.] 
adversary cards in hand: [3. 1. 0. 6. 0.] 
adversary cards in discard: [25.  6.  3.  0. 14.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6] -> size -> 34 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 26.612194061279297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-30.191635]
 [-21.771687]
 [-43.29031 ]
 [-17.346474]
 [-19.744596]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 29.  0. 29. 11.] 
cards in discard: [11. 29. 25.  0.  8. 11.  3. 29.  0. 10. 11.  3. 10. 11.  6.  8. 10.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 27. 30. 28. 30.  8.  2. 10.  5.  6.  7.  5.  8.  9.  1. 10. 10.] 
adversary cards in hand: [3. 1. 0. 6. 0.] 
adversary cards in discard: [25.  6.  3.  0. 14.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6] -> size -> 34 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: -19.482696533203125



buy possibilites: [-1] 
expected returns: [[-16.811428]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 29.  0. 29. 11.] 
cards in discard: [11. 29. 25.  0.  8. 11.  3. 29.  0. 10. 11.  3. 10. 11.  6.  8. 10.  6.
  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 28. 30.  8.  2. 10.  5.  5.  7.  5.  8.  9.  1. 10. 10.] 
adversary cards in hand: [3. 1. 0. 6. 0.] 
adversary cards in discard: [25.  6.  3.  0. 14.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6] -> size -> 34 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  16   0] 
sum of rewards: 21 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -17.346458435058594






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [3. 1. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 6. 0.] 
cards in discard: [25.  6.  3.  0. 14.  0.  0.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 28. 30.  8.  2. 10.  5.  5.  7.  5.  8.  9.  1. 10. 10.] 
adversary cards in hand: [29.  3. 11. 25.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8] -> size -> 28 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 6. 0.] 
cards in discard: [25.  6.  3.  0. 14.  0.  0.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 27. 30. 28. 30.  8.  2. 10.  5.  5.  7.  5.  8.  9.  1. 10. 10.] 
adversary cards in hand: [29.  3. 11. 25.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8] -> size -> 28 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 6. 0.] 
cards in discard: [25.  6.  3.  0. 14.  0.  0.  6.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 27. 30. 28. 30.  8.  2. 10.  5.  4.  7.  5.  8.  9.  1. 10. 10.] 
adversary cards in hand: [29.  3. 11. 25.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8] -> size -> 28 
adversary victory points: 0
player victory points: 0 





Player: 0 
cards in hand: [29.  3. 11. 25.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 25.  8.] 
expected returns: [[-7.668644 ]
 [ 3.8607006]
 [ 2.766243 ]
 [15.0797415]
 [-5.6485996]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 11. 25.  8.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 28. 30.  8.  2. 10.  5.  4.  7.  5.  8.  9.  1. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  1. 10.] 
adversary cards in discard: [25.  6.  3.  0. 14.  0.  0.  6.  8.  3.  1.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8] -> size -> 35 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -16.81142807006836



action possibilites: [-1] 
expected returns: [[-14.074523]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 11.  8. 11.  6.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 28. 30.  8.  1. 10.  5.  4.  7.  5.  8.  9.  1. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  1. 10.] 
adversary cards in discard: [25.  6.  3.  0. 14.  0.  0.  6.  8.  3.  1.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8  6] -> size -> 36 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 15.079747200012207





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-25.77967 ]
 [-39.673836]
 [-14.763867]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3. 11.  8. 11.  6.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 27. 30. 28. 30.  8.  1. 10.  5.  4.  7.  5.  8.  9.  1. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  1. 10.] 
adversary cards in discard: [25.  6.  3.  0. 14.  0.  0.  6.  8.  3.  1.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8  6] -> size -> 36 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -14.074522972106934






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  1. 10.] 
cards in discard: [25.  6.  3.  0. 14.  0.  0.  6.  8.  3.  1.  0.  6.  0.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8  6] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 28. 30.  8.  1. 10.  5.  4.  7.  5.  8.  9.  1. 10. 10.] 
adversary cards in hand: [10.  8. 29. 11. 29.] 
adversary cards in discard: [25. 29.  3. 11.  8. 11.  6.] 
adversary owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8] -> size -> 28 
adversary victory points: 0
player victory points: -1 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 10.  6.] 
cards in discard: [25.  6.  3.  0. 14.  0.  0.  6.  8.  3.  1.  0.  6.  0.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8  6] -> size -> 36 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 28. 30.  8.  1. 10.  5.  4.  7.  5.  8.  9.  1. 10. 10.] 
adversary cards in hand: [10.  8. 29. 11. 29.] 
adversary cards in discard: [25. 29.  3. 11.  8. 11.  6.] 
adversary owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8] -> size -> 28 
adversary victory points: 0
player victory points: -1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 6. 0.] 
cards in discard: [25.  6.  3.  0. 14.  0.  0.  6.  8.  3.  1.  0.  6.  0.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8  6] -> size -> 36 
action values: 3 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 28. 30.  8.  1. 10.  5.  4.  7.  5.  8.  9.  1. 10. 10.] 
adversary cards in hand: [10.  8. 29. 11. 29.] 
adversary cards in discard: [25. 29.  3. 11.  8. 11.  6.] 
adversary owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8] -> size -> 28 
adversary victory points: 0
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 6. 0.] 
cards in discard: [25.  6.  3.  0. 14.  0.  0.  6.  8.  3.  1.  0.  6.  0.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8  6] -> size -> 36 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 27. 30. 28. 30.  8.  1. 10.  5.  4.  7.  5.  8.  9.  1. 10. 10.] 
adversary cards in hand: [10.  8. 29. 11. 29.] 
adversary cards in discard: [25. 29.  3. 11.  8. 11.  6.] 
adversary owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8] -> size -> 28 
adversary victory points: 0
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 6. 0.] 
cards in discard: [25.  6.  3.  0. 14.  0.  0.  6.  8.  3.  1.  0.  6.  0.  6.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8  6  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 5 
card supply: [22. 27. 30. 28. 30.  8.  1. 10.  5.  4.  7.  5.  8.  9.  1. 10. 10.] 
adversary cards in hand: [10.  8. 29. 11. 29.] 
adversary cards in discard: [25. 29.  3. 11.  8. 11.  6.] 
adversary owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8] -> size -> 28 
adversary victory points: 0
player victory points: -1 





Player: 0 
cards in hand: [10.  8. 29. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 29. 11. 29.] 
expected returns: [[33.787014]
 [33.282116]
 [36.263214]
 [47.120457]
 [45.929573]
 [47.120457]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 29. 11. 29.] 
cards in discard: [25. 29.  3. 11.  8. 11.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 28. 30.  8.  1. 10.  5.  4.  7.  5.  8.  9.  1. 10. 10.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [25.  6.  3.  0. 14.  0.  0.  6.  8.  3.  1.  0.  6.  0.  6.  0. 10. 10.
  0.  0.  1.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8  6  0] -> size -> 37 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -14.763873100280762



action possibilites: [-1. 10.  8. 11. 29. 10.] 
expected returns: [[10.979402]
 [10.690093]
 [13.777442]
 [24.123943]
 [25.32058 ]
 [10.690093]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 11. 29. 10.] 
cards in discard: [25. 29.  3. 11.  8. 11.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 28. 30.  8.  1. 10.  5.  4.  7.  5.  8.  9.  1. 10. 10.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [25.  6.  3.  0. 14.  0.  0.  6.  8.  3.  1.  0.  6.  0.  6.  0. 10. 10.
  0.  0.  1.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8  6  0] -> size -> 37 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 47.120445251464844



action possibilites: [-1. 10.  8. 11. 10.] 
expected returns: [[-0.08840609]
 [-0.5117655 ]
 [ 2.5910034 ]
 [13.806457  ]
 [-0.5117655 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 11. 10.  0.] 
cards in discard: [25. 29.  3. 11.  8. 11.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 2 
card supply: [22. 27. 30. 28. 30.  8.  1. 10.  5.  4.  7.  5.  8.  9.  1. 10. 10.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [25.  6.  3.  0. 14.  0.  0.  6.  8.  3.  1.  0.  6.  0.  6.  0. 10. 10.
  0.  0.  1.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8  6  0] -> size -> 37 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 25.32056427001953



action possibilites: [-1] 
expected returns: [[-11.634649]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 10.  0.] 
cards in discard: [25. 29.  3. 11.  8. 11.  6. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 27. 30. 28. 30.  8.  1. 10.  5.  4.  7.  5.  8.  9.  0. 10. 10.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [25.  6.  3.  0. 14.  0.  0.  6.  8.  3.  1.  0.  6.  0.  6.  0. 10. 10.
  0.  0.  1.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8  6  0] -> size -> 37 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 112 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 17.300704956054688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[-23.030556 ]
 [-11.115767 ]
 [-14.0293   ]
 [-35.954063 ]
 [  0.9104099]
 [ -9.047605 ]
 [-11.776695 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 10.  0.] 
cards in discard: [25. 29.  3. 11.  8. 11.  6. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 27. 30. 28. 30.  8.  1. 10.  5.  4.  7.  5.  8.  9.  0. 10. 10.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [25.  6.  3.  0. 14.  0.  0.  6.  8.  3.  1.  0.  6.  0.  6.  0. 10. 10.
  0.  0.  1.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8  6  0] -> size -> 37 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1
Learning step: 0
desired expected reward: -11.634649276733398



buy possibilites: [-1] 
expected returns: [[2.275774]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 10.  0.] 
cards in discard: [25. 29.  3. 11.  8. 11.  6. 10. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8 10 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 28. 30.  8.  1. 10.  4.  4.  7.  5.  8.  9.  0. 10. 10.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [25.  6.  3.  0. 14.  0.  0.  6.  8.  3.  1.  0.  6.  0.  6.  0. 10. 10.
  0.  0.  1.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8  6  0] -> size -> 37 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0 54  0] 
sum of rewards: 139 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 0.9104032516479492






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [0. 0. 1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [25.  6.  3.  0. 14.  0.  0.  6.  8.  3.  1.  0.  6.  0.  6.  0. 10. 10.
  0.  0.  1.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8  6  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 28. 30.  8.  1. 10.  4.  4.  7.  5.  8.  9.  0. 10. 10.] 
adversary cards in hand: [10.  0.  0. 10. 11.] 
adversary cards in discard: [25. 29.  3. 11.  8. 11.  6. 10. 11. 29. 29. 11. 10.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8 10 11] -> size -> 30 
adversary victory points: 0
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [25.  6.  3.  0. 14.  0.  0.  6.  8.  3.  1.  0.  6.  0.  6.  0. 10. 10.
  0.  0.  1.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8  6  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 27. 30. 28. 30.  8.  1. 10.  4.  4.  7.  5.  8.  9.  0. 10. 10.] 
adversary cards in hand: [10.  0.  0. 10. 11.] 
adversary cards in discard: [25. 29.  3. 11.  8. 11.  6. 10. 11. 29. 29. 11. 10.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8 10 11] -> size -> 30 
adversary victory points: 0
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [25.  6.  3.  0. 14.  0.  0.  6.  8.  3.  1.  0.  6.  0.  6.  0. 10. 10.
  0.  0.  1.  6.  0. 16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8  6  0 16] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 28. 30.  8.  1.  9.  4.  4.  7.  5.  8.  9.  0. 10. 10.] 
adversary cards in hand: [10.  0.  0. 10. 11.] 
adversary cards in discard: [25. 29.  3. 11.  8. 11.  6. 10. 11. 29. 29. 11. 10.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8 10 11] -> size -> 30 
adversary victory points: 0
player victory points: -1 





Player: 0 
cards in hand: [10.  0.  0. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.] 
expected returns: [[-12.610266  ]
 [-12.831564  ]
 [-12.831564  ]
 [ -0.32955408]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 10. 11.] 
cards in discard: [25. 29.  3. 11.  8. 11.  6. 10. 11. 29. 29. 11. 10.  8. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8 10 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 28. 30.  8.  1.  9.  4.  4.  7.  5.  8.  9.  0. 10. 10.] 
adversary cards in hand: [ 0.  6.  0. 23.  0.] 
adversary cards in discard: [25.  6.  3.  0. 14.  0.  0.  6.  8.  3.  1.  0.  6.  0.  6.  0. 10. 10.
  0.  0.  1.  6.  0. 16.  0.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8  6  0 16] -> size -> 38 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 2.2757740020751953



action possibilites: [-1] 
expected returns: [[-29.971603]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 10.] 
cards in discard: [25. 29.  3. 11.  8. 11.  6. 10. 11. 29. 29. 11. 10.  8. 10.  0. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8 10 11 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 28. 30.  8.  1.  9.  4.  4.  7.  5.  8.  9.  0. 10.  9.] 
adversary cards in hand: [ 0.  6.  0. 23.  0.] 
adversary cards in discard: [25.  6.  3.  0. 14.  0.  0.  6.  8.  3.  1.  0.  6.  0.  6.  0. 10. 10.
  0.  0.  1.  6.  0. 16.  0.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8  6  0 16] -> size -> 38 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 109 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 2.577296257019043





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-41.061234]
 [-32.383854]
 [-54.166862]
 [-27.861187]
 [-30.21059 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 10.] 
cards in discard: [25. 29.  3. 11.  8. 11.  6. 10. 11. 29. 29. 11. 10.  8. 10.  0. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8 10 11 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 27. 30. 28. 30.  8.  1.  9.  4.  4.  7.  5.  8.  9.  0. 10.  9.] 
adversary cards in hand: [ 0.  6.  0. 23.  0.] 
adversary cards in discard: [25.  6.  3.  0. 14.  0.  0.  6.  8.  3.  1.  0.  6.  0.  6.  0. 10. 10.
  0.  0.  1.  6.  0. 16.  0.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8  6  0 16] -> size -> 38 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: -29.971603393554688



buy possibilites: [-1] 
expected returns: [[-32.527355]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 10.] 
cards in discard: [25. 29.  3. 11.  8. 11.  6. 10. 11. 29. 29. 11. 10.  8. 10.  0. 15.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8 10 11 15  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 28. 30.  8.  1.  9.  4.  3.  7.  5.  8.  9.  0. 10.  9.] 
adversary cards in hand: [ 0.  6.  0. 23.  0.] 
adversary cards in discard: [25.  6.  3.  0. 14.  0.  0.  6.  8.  3.  1.  0.  6.  0.  6.  0. 10. 10.
  0.  0.  1.  6.  0. 16.  0.  0.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8  6  0 16] -> size -> 38 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 61 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -27.861194610595703






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 0.  6.  0. 23.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 23.  0.] 
cards in discard: [25.  6.  3.  0. 14.  0.  0.  6.  8.  3.  1.  0.  6.  0.  6.  0. 10. 10.
  0.  0.  1.  6.  0. 16.  0.  0.  1.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8  6  0 16] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 28. 30.  8.  1.  9.  4.  3.  7.  5.  8.  9.  0. 10.  9.] 
adversary cards in hand: [ 8.  8. 11.  6.  8.] 
adversary cards in discard: [25. 29.  3. 11.  8. 11.  6. 10. 11. 29. 29. 11. 10.  8. 10.  0. 15.  8.
 11. 10.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8 10 11 15  8] -> size -> 32 
adversary victory points: 0
player victory points: -1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 3.] 
cards in discard: [25.  6.  3.  0. 14.  0.  0.  6.  8.  3.  1.  0.  6.  0.  6.  0. 10. 10.
  0.  0.  1.  6.  0. 16.  0.  0.  1.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8  6  0 16] -> size -> 38 
action values: 1 
buys: 1 
player value: 1 
card supply: [22. 27. 30. 28. 30.  8.  1.  9.  4.  3.  7.  5.  8.  9.  0. 10.  9.] 
adversary cards in hand: [ 8.  8. 11.  6.  8.] 
adversary cards in discard: [25. 29.  3. 11.  8. 11.  6. 10. 11. 29. 29. 11. 10.  8. 10.  0. 15.  8.
 11. 10.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8 10 11 15  8] -> size -> 32 
adversary victory points: 0
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 3.] 
cards in discard: [25.  6.  3.  0. 14.  0.  0.  6.  8.  3.  1.  0.  6.  0.  6.  0. 10. 10.
  0.  0.  1.  6.  0. 16.  0.  0.  1.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8  6  0 16] -> size -> 38 
action values: 0 
buys: 2 
player value: 4 
card supply: [22. 27. 30. 28. 30.  8.  1.  9.  4.  3.  7.  5.  8.  9.  0. 10.  9.] 
adversary cards in hand: [ 8.  8. 11.  6.  8.] 
adversary cards in discard: [25. 29.  3. 11.  8. 11.  6. 10. 11. 29. 29. 11. 10.  8. 10.  0. 15.  8.
 11. 10.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8 10 11 15  8] -> size -> 32 
adversary victory points: 0
player victory points: -1 


buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 3.] 
cards in discard: [25.  6.  3.  0. 14.  0.  0.  6.  8.  3.  1.  0.  6.  0.  6.  0. 10. 10.
  0.  0.  1.  6.  0. 16.  0.  0.  1.  3.  0. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8  6  0 16 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 27. 30. 28. 30.  8.  1.  9.  4.  3.  7.  5.  8.  9.  0. 10.  8.] 
adversary cards in hand: [ 8.  8. 11.  6.  8.] 
adversary cards in discard: [25. 29.  3. 11.  8. 11.  6. 10. 11. 29. 29. 11. 10.  8. 10.  0. 15.  8.
 11. 10.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8 10 11 15  8] -> size -> 32 
adversary victory points: 0
player victory points: -1 





Player: 0 
cards in hand: [ 8.  8. 11.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11.  8.] 
expected returns: [[-13.542709]
 [-12.280241]
 [-12.280241]
 [ -5.688413]
 [-12.280241]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 11.  6.  8.] 
cards in discard: [25. 29.  3. 11.  8. 11.  6. 10. 11. 29. 29. 11. 10.  8. 10.  0. 15.  8.
 11. 10.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8 10 11 15  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 28. 30.  8.  1.  9.  4.  3.  7.  5.  8.  9.  0. 10.  8.] 
adversary cards in hand: [16.  3.  3. 14. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8  6  0 16 15] -> size -> 39 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -32.5273551940918



action possibilites: [-1] 
expected returns: [[-33.49591]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 6. 8.] 
cards in discard: [25. 29.  3. 11.  8. 11.  6. 10. 11. 29. 29. 11. 10.  8. 10.  0. 15.  8.
 11. 10.  0.  0. 10. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8 10 11 15  8 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 28. 30.  8.  1.  9.  4.  3.  7.  5.  8.  9.  0. 10.  7.] 
adversary cards in hand: [16.  3.  3. 14. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8  6  0 16 15] -> size -> 39 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 64  0] 
sum of rewards: 109 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -3.455270767211914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-42.025833]
 [-52.708214]
 [-33.455173]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 6. 8.] 
cards in discard: [25. 29.  3. 11.  8. 11.  6. 10. 11. 29. 29. 11. 10.  8. 10.  0. 15.  8.
 11. 10.  0.  0. 10. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8 10 11 15  8 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 27. 30. 28. 30.  8.  1.  9.  4.  3.  7.  5.  8.  9.  0. 10.  7.] 
adversary cards in hand: [16.  3.  3. 14. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8  6  0 16 15] -> size -> 39 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: -33.49591064453125






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [16.  3.  3. 14. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  3. 14. 10.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8  6  0 16 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 28. 30.  8.  1.  9.  4.  3.  7.  5.  8.  9.  0. 10.  7.] 
adversary cards in hand: [15. 25. 29. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8 10 11 15  8 15] -> size -> 33 
adversary victory points: 0
player victory points: -1 


action possibilites: [-1. 16. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  3. 14.  3.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8  6  0 16 15] -> size -> 39 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 28. 30.  8.  1.  9.  4.  3.  7.  5.  8.  9.  0. 10.  7.] 
adversary cards in hand: [15. 25. 29. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8 10 11 15  8 15] -> size -> 33 
adversary victory points: 0
player victory points: -1 


action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  3.  3.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8  6  0 16 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 2 
card supply: [22. 27. 30. 28. 30.  8.  1.  9.  4.  3.  7.  5.  8.  9.  0. 10.  7.] 
adversary cards in hand: [15. 29. 29.] 
adversary cards in discard: [25.  3.] 
adversary owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8 10 11 15  8 15] -> size -> 33 
adversary victory points: 0
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  3.  3.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8  6  0 16 15] -> size -> 39 
action values: 1 
buys: 1 
player value: 2 
card supply: [22. 27. 30. 28. 30.  8.  1.  9.  4.  3.  7.  5.  8.  9.  0. 10.  7.] 
adversary cards in hand: [15. 29. 29.] 
adversary cards in discard: [25.  3.] 
adversary owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8 10 11 15  8 15] -> size -> 33 
adversary victory points: 0
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  3.  3.] 
cards in discard: [3.] 
cards in deck: 33 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8  6  0 16 15  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8.  1.  9.  4.  3.  7.  5.  8.  9.  0. 10.  7.] 
adversary cards in hand: [15. 29. 29.] 
adversary cards in discard: [25.  3.] 
adversary owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8 10 11 15  8 15] -> size -> 33 
adversary victory points: 0
player victory points: 0 





Player: 0 
cards in hand: [15. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29. 29.] 
expected returns: [[37.039787]
 [36.707916]
 [51.006218]
 [51.006218]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29. 29.] 
cards in discard: [25.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8 10 11 15  8 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8.  1.  9.  4.  3.  7.  5.  8.  9.  0. 10.  7.] 
adversary cards in hand: [1. 0. 6. 0. 0.] 
adversary cards in discard: [ 3. 10. 14. 16.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8  6  0 16 15  3] -> size -> 40 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -102.4251937866211



action possibilites: [-1. 29. 15.] 
expected returns: [[37.20134]
 [50.27436]
 [36.71048]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 15.] 
cards in discard: [25.  3. 15.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8 10 11 15  8 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 27. 30.  8.  1.  9.  4.  3.  7.  5.  8.  9.  0. 10.  7.] 
adversary cards in hand: [1. 0. 6. 0. 0.] 
adversary cards in discard: [ 3. 10. 14. 16.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8  6  0 16 15  3] -> size -> 40 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 37.67616271972656



action possibilites: [-1. 11.] 
expected returns: [[46.35383]
 [59.62262]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [25.  3. 15. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8 10 11 15  8 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 2 
card supply: [22. 27. 30. 27. 30.  8.  1.  9.  4.  3.  7.  5.  8.  9.  0. 10.  7.] 
adversary cards in hand: [1. 0. 6. 0. 0.] 
adversary cards in discard: [ 3. 10. 14. 16.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8  6  0 16 15  3] -> size -> 40 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 37.67494201660156



action possibilites: [-1] 
expected returns: [[20.97033]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [25.  3. 15. 15. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8 10 11 15  8 15 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 27. 30. 27. 30.  8.  1.  9.  4.  3.  7.  5.  8.  9.  0. 10.  6.] 
adversary cards in hand: [1. 0. 6. 0. 0.] 
adversary cards in discard: [ 3. 10. 14. 16.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8  6  0 16 15  3] -> size -> 40 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0 64  0] 
sum of rewards: 119 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 62.66033935546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[10.748284 ]
 [18.767685 ]
 [-2.3475518]
 [23.004776 ]
 [20.976414 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [25.  3. 15. 15. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8 10 11 15  8 15 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 27. 30. 27. 30.  8.  1.  9.  4.  3.  7.  5.  8.  9.  0. 10.  6.] 
adversary cards in hand: [1. 0. 6. 0. 0.] 
adversary cards in discard: [ 3. 10. 14. 16.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8  6  0 16 15  3] -> size -> 40 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 20.97032928466797



buy possibilites: [-1] 
expected returns: [[9.201861]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [25.  3. 15. 15. 15.  8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8 10 11 15  8 15 15  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8.  1.  9.  4.  2.  7.  5.  8.  9.  0. 10.  6.] 
adversary cards in hand: [1. 0. 6. 0. 0.] 
adversary cards in discard: [ 3. 10. 14. 16.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8  6  0 16 15  3] -> size -> 40 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0 16  0] 
sum of rewards: 71 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 23.0047607421875






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [1. 0. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 6. 0. 0.] 
cards in discard: [ 3. 10. 14. 16.  3.  3.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8  6  0 16 15  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8.  1.  9.  4.  2.  7.  5.  8.  9.  0. 10.  6.] 
adversary cards in hand: [ 6.  0. 25. 29.  0.] 
adversary cards in discard: [25.  3. 15. 15. 15.  8. 29. 29. 11.] 
adversary owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8 10 11 15  8 15 15  8] -> size -> 35 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6. 0. 0.] 
cards in discard: [ 3. 10. 14. 16.  3.  3.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8  6  0 16 15  3] -> size -> 40 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 27. 30. 27. 30.  8.  1.  9.  4.  2.  7.  5.  8.  9.  0. 10.  6.] 
adversary cards in hand: [ 6.  0. 25. 29.  0.] 
adversary cards in discard: [25.  3. 15. 15. 15.  8. 29. 29. 11.] 
adversary owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8 10 11 15  8 15 15  8] -> size -> 35 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6. 0. 0.] 
cards in discard: [ 3. 10. 14. 16.  3.  3.  3. 29.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8  6  0 16 15  3 29] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 27. 30.  8.  1.  9.  4.  2.  7.  4.  8.  9.  0. 10.  6.] 
adversary cards in hand: [ 6.  0. 25. 29.  0.] 
adversary cards in discard: [25.  3. 15. 15. 15.  8. 29. 29. 11.] 
adversary owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8 10 11 15  8 15 15  8] -> size -> 35 
adversary victory points: 0
player victory points: 0 





Player: 0 
cards in hand: [ 6.  0. 25. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[-7.9718843]
 [16.227993 ]
 [ 3.7696247]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 25. 29.  0.] 
cards in discard: [25.  3. 15. 15. 15.  8. 29. 29. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8 10 11 15  8 15 15  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8.  1.  9.  4.  2.  7.  4.  8.  9.  0. 10.  6.] 
adversary cards in hand: [ 3. 15. 10.  0.  0.] 
adversary cards in discard: [ 3. 10. 14. 16.  3.  3.  3. 29.  1.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8  6  0 16 15  3 29] -> size -> 41 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 9.201861381530762



action possibilites: [-1] 
expected returns: [[3.707446]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 29.  0.  8. 11.] 
cards in discard: [25.  3. 15. 15. 15.  8. 29. 29. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8 10 11 15  8 15 15  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8.  0.  9.  4.  2.  7.  4.  8.  9.  0. 10.  6.] 
adversary cards in hand: [ 3. 15. 10.  0.  0.] 
adversary cards in discard: [ 3. 10. 14. 16.  3.  3.  3. 29.  1.  0.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8  6  0 16 15  3 29  6] -> size -> 42 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 16.227977752685547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-7.1204233 ]
 [ 0.47397995]
 [ 4.646759  ]
 [ 2.8005552 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 29.  0.  8. 11.] 
cards in discard: [25.  3. 15. 15. 15.  8. 29. 29. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8 10 11 15  8 15 15  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 27. 30. 27. 30.  8.  0.  9.  4.  2.  7.  4.  8.  9.  0. 10.  6.] 
adversary cards in hand: [ 3. 15. 10.  0.  0.] 
adversary cards in discard: [ 3. 10. 14. 16.  3.  3.  3. 29.  1.  0.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8  6  0 16 15  3 29  6] -> size -> 42 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 3.7074460983276367



buy possibilites: [-1] 
expected returns: [[7.3101997]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 29.  0.  8. 11.] 
cards in discard: [25.  3. 15. 15. 15.  8. 29. 29. 11.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8 10 11 15  8 15 15  8  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8.  0.  9.  4.  1.  7.  4.  8.  9.  0. 10.  6.] 
adversary cards in hand: [ 3. 15. 10.  0.  0.] 
adversary cards in discard: [ 3. 10. 14. 16.  3.  3.  3. 29.  1.  0.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8  6  0 16 15  3 29  6] -> size -> 42 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -10   0   0  16   0] 
sum of rewards: 21 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 4.646760940551758






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [ 3. 15. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 10.  0.  0.] 
cards in discard: [ 3. 10. 14. 16.  3.  3.  3. 29.  1.  0.  6.  0.  0.  6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8  6  0 16 15  3 29  6] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8.  0.  9.  4.  1.  7.  4.  8.  9.  0. 10.  6.] 
adversary cards in hand: [ 8. 10.  8. 11. 10.] 
adversary cards in discard: [25.  3. 15. 15. 15.  8. 29. 29. 11.  8. 25.  6.  0. 29.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8 10 11 15  8 15 15  8  8] -> size -> 36 
adversary victory points: 0
player victory points: -1 


action possibilites: [-1. 15. 23.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0.  0. 23.] 
cards in discard: [ 3. 10. 14. 16.  3.  3.  3. 29.  1.  0.  6.  0.  0.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0
  1  6  0  6 23 14  6  0  3  6  8  6  0 16 15  3 29  6] -> size -> 42 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8.  0.  9.  4.  1.  7.  4.  8.  9.  0. 10.  6.] 
adversary cards in hand: [ 8. 10.  8. 11. 10.] 
adversary cards in discard: [25.  3. 15. 15. 15.  8. 29. 29. 11.  8. 25.  6.  0. 29.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8 10 11 15  8 15 15  8  8] -> size -> 36 
adversary victory points: 0
player victory points: -1 


action possibilites: [-1. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 23.] 
cards in discard: [ 3. 10. 14. 16.  3.  3.  3. 29.  1.  0.  6.  0.  0.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0  1
  6  0  6 23 14  6  0  3  6  8  6  0 16 15  3 29  6] -> size -> 41 
action values: 1 
buys: 0 
player value: 3 
card supply: [22. 27. 30. 27. 30.  8.  0.  9.  4.  1.  7.  4.  8.  9.  0. 10.  6.] 
adversary cards in hand: [ 8. 10.  8. 11. 10.] 
adversary cards in discard: [25.  3. 15. 15. 15.  8. 29. 29. 11.  8. 25.  6.  0. 29.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8 10 11 15  8 15 15  8  8] -> size -> 36 
adversary victory points: 0
player victory points: -1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1.] 
cards in discard: [ 3. 10. 14. 16.  3.  3.  3. 29.  1.  0.  6.  0.  0.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10. 15. 23.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0  1
  6  0  6 23 14  6  0  3  6  8  6  0 16 15  3 29  6] -> size -> 41 
action values: 1 
buys: 1 
player value: 4 
card supply: [22. 27. 30. 27. 30.  8.  0.  9.  4.  1.  7.  4.  8.  9.  0. 10.  6.] 
adversary cards in hand: [ 8. 10.  8. 11. 10.] 
adversary cards in discard: [25.  3. 15. 15. 15.  8. 29. 29. 11.  8. 25.  6.  0. 29.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8 10 11 15  8 15 15  8  8] -> size -> 36 
adversary victory points: 0
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1.] 
cards in discard: [ 3. 10. 14. 16.  3.  3.  3. 29.  1.  0.  6.  0.  0.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10. 15. 23.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0  1
  6  0  6 23 14  6  0  3  6  8  6  0 16 15  3 29  6] -> size -> 41 
action values: 0 
buys: 2 
player value: 7 
card supply: [22. 27. 30. 27. 30.  8.  0.  9.  4.  1.  7.  4.  8.  9.  0. 10.  6.] 
adversary cards in hand: [ 8. 10.  8. 11. 10.] 
adversary cards in discard: [25.  3. 15. 15. 15.  8. 29. 29. 11.  8. 25.  6.  0. 29.  0.  8. 11.] 
adversary owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8 10 11 15  8 15 15  8  8] -> size -> 36 
adversary victory points: 0
player victory points: -1 


Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 6 
Chapel: 8 
Witch: 2 
Poacher: 5 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 8. 10.  8. 11. 10.] 
cards in discard: [25.  3. 15. 15. 15.  8. 29. 29. 11.  8. 25.  6.  0. 29.  0.  8. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 11 29 29 11 29 29 11 29 25 10  8 10  8 25  6  8 11 10  8
 11 10  6  8 10 11 15  8 15 15  8  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 30.  8.  0.  9.  4.  0.  7.  4.  8.  9.  0. 10.  6.] 
adversary cards in hand: [3. 0. 1.] 
adversary cards in discard: [ 3. 10. 14. 16.  3.  3.  3. 29.  1.  0.  6.  0.  0.  6.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3 10 10  0 25  0  0 14  0  1 10  1  6  0  1
  6  0  6 23 14  6  0  3  6  8  6  0 16 15  3 29  6  8] -> size -> 42 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[     -5 3000000       0      30       0       0       0       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000025 

action type: buy - action -1
Learning step: 120000.7109375
desired expected reward: 120008.0234375



