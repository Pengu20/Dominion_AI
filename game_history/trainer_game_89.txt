 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[278.09616]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    1  -10    0    0    0    0    0    0    0  -14    0    0
    9    0] 
sum of rewards: -519 

action type: buy - action 10.0
Learning step: -26.31746482849121
desired expected reward: -18.96817970275879





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[249.46196]
 [268.68875]
 [261.25894]
 [210.14207]
 [280.32196]
 [263.8312 ]
 [258.92392]
 [282.82596]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.24750804901123
desired expected reward: 271.8314208984375



buy possibilites: [-1] 
expected returns: [[255.9996]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 0.0 

action type: buy - action 8.0
Learning step: -7.4315690994262695
desired expected reward: 256.3996276855469






Player: 1 
cards in hand: [3. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [8. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [8. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[286.63766]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [8. 3. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -6.419167518615723
desired expected reward: 249.58042907714844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[264.13263]
 [279.6822 ]
 [271.60782]
 [235.25204]
 [269.9998 ]
 [289.5943 ]
 [276.28168]
 [274.3099 ]
 [248.76434]
 [270.54523]
 [262.3853 ]
 [290.50003]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [8. 3. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.42250919342041
desired expected reward: 279.6136169433594



buy possibilites: [-1] 
expected returns: [[273.75946]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [8. 3. 0. 3. 0. 0. 6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 6] -> size -> 12 
action values: 0 
buys: 0 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -313.0 

action type: buy - action 6.0
Learning step: -21.253015518188477
desired expected reward: 213.9990234375






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3. 3. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 6] -> size -> 12 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3. 3. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 6] -> size -> 12 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 3.  3.  0.  3.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 6] -> size -> 12 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[267.54126]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -8.375082015991211
desired expected reward: 265.3843688964844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[242.26071]
 [256.74344]
 [249.40094]
 [210.51176]
 [264.79633]
 [254.2117 ]
 [248.83244]
 [264.62772]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 6] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -8.287057876586914
desired expected reward: 256.7303466796875



buy possibilites: [-1] 
expected returns: [[283.55026]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 6 1] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: 5 

action type: buy - action 1.0
Learning step: -6.2072906494140625
desired expected reward: 250.53614807128906






Player: 1 
cards in hand: [ 0.  0. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 6.] 
adversary cards in discard: [1. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 6 1] -> size -> 13 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8.  9. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 6.] 
adversary cards in discard: [1. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 6 1] -> size -> 13 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.  3.] 
cards in discard: [8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8.  9. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 6.] 
adversary cards in discard: [1. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 6 1] -> size -> 13 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 8. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[291.61557]
 [277.41708]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 3. 6.] 
cards in discard: [1. 3. 0. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 6 1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 8.  0.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -8.450111389160156
desired expected reward: 275.10015869140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[263.3192 ]
 [272.9506 ]
 [226.72209]
 [276.2622 ]
 [291.64563]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 3. 6.] 
cards in discard: [1. 3. 0. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 6 1] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8.  9. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 8.  0.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -9.170084953308105
desired expected reward: 281.4310607910156



buy possibilites: [-1] 
expected returns: [[263.4647]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 3. 6.] 
cards in discard: [1. 3. 0. 0. 3. 0. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 6 1 6] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8.  8. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 8.  0.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8] -> size -> 12 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -324.0 

action type: buy - action 6.0
Learning step: -21.6081485748291
desired expected reward: 205.1139373779297






Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 8.  0.  0. 11.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  8. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 6. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 6 1 6] -> size -> 14 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 8.  0.  0. 11.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8.  8. 10.  9.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 6. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 6 1 6] -> size -> 14 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 8.  0.  0. 11.  0.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  8. 10.  9.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 6. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 6 1 6] -> size -> 14 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [0. 6. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[279.06805]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 6 1 6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  8. 10.  9.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  3.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8 10] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -8.123952865600586
desired expected reward: 255.3407440185547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[249.2755 ]
 [266.6304 ]
 [258.03635]
 [210.20831]
 [274.30246]
 [263.0039 ]
 [255.53442]
 [273.16092]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 6 1 6] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8.  8. 10.  9.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  3.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8 10] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -9.306424140930176
desired expected reward: 268.439453125



buy possibilites: [-1] 
expected returns: [[219.54549]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 0.] 
cards in discard: [11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6  1  6 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  8. 10.  8.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  3.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8 10] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -6 

action type: buy - action 11.0
Learning step: -9.075350761413574
desired expected reward: 265.2271423339844






Player: 1 
cards in hand: [10.  3.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3. 11.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  8. 10.  8.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 8.] 
adversary cards in discard: [11.  0.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6  1  6 11] -> size -> 15 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11.  0.  8.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8 10] -> size -> 13 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  8. 10.  8.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 8.] 
adversary cards in discard: [11.  0.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6  1  6 11] -> size -> 15 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 8.] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  8 10  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8.  8. 10.  8.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 8.] 
adversary cards in discard: [11.  0.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6  1  6 11] -> size -> 15 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 11.  8.] 
owned cards: [ 0  0  0  0  0  0  3 11  8 10  1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8.  8. 10.  8.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 8.] 
adversary cards in discard: [11.  0.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6  1  6 11] -> size -> 15 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 11.  8.] 
owned cards: [ 0  0  0  0  0  0  3 11  8 10  1] -> size -> 11 
action values: 0 
buys: 1 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8.  8. 10.  8.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 3. 0. 0. 8.] 
adversary cards in discard: [11.  0.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6  1  6 11] -> size -> 15 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [1. 3. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[280.7886 ]
 [268.79718]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 0. 8.] 
cards in discard: [11.  0.  6.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6  1  6 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8.  8. 10.  8.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 1. 10. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  8 10  1] -> size -> 11 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1
Learning step: -5.0038042068481445
desired expected reward: 214.54168701171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[250.10728]
 [265.1895 ]
 [258.7145 ]
 [214.43916]
 [255.97256]
 [273.17825]
 [261.55466]
 [259.6687 ]
 [231.7041 ]
 [256.78354]
 [248.5459 ]
 [274.14117]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 8.] 
cards in discard: [11.  0.  6.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6  1  6 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 30. 30.  8.  8. 10.  8.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 1. 10. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  8 10  1] -> size -> 11 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: take_action - action -1.0
Learning step: -8.472500801086426
desired expected reward: 271.68072509765625



buy possibilites: [-1] 
expected returns: [[242.74066]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 8.] 
cards in discard: [11.  0.  6.  3.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6  1  6 11  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 29. 30.  8.  8. 10.  8.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 1. 10. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  8 10  1] -> size -> 11 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5.  0.  2. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 9.0 

action type: buy - action 3.0
Learning step: -6.162795543670654
desired expected reward: 235.32640075683594






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 1. 10. 11.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 11  8 10  1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  8. 10.  8.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 3. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6  1  6 11  3] -> size -> 16 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 1. 10. 11.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 11  8 10  1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 29. 30.  8.  8. 10.  8.  8. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 3. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6  1  6 11  3] -> size -> 16 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 1. 10. 11.  8. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 11  8 10  1 14] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  8. 10.  8.  8. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [1. 3. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6  1  6 11  3] -> size -> 16 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [1. 3. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[218.0081]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6  1  6 11  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  8. 10.  8.  8. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 14.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  8 10  1 14] -> size -> 12 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1
Learning step: -6.881065368652344
desired expected reward: 235.85958862304688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[194.87599]
 [209.35066]
 [202.7295 ]
 [161.66286]
 [200.50984]
 [217.66603]
 [206.40837]
 [204.49062]
 [178.78857]
 [201.75235]
 [193.84496]
 [218.90443]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6  1  6 11  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 29. 30.  8.  8. 10.  8.  8. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 14.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  8 10  1 14] -> size -> 12 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: take_action - action -1.0
Learning step: -6.052905559539795
desired expected reward: 211.9901123046875



buy possibilites: [-1] 
expected returns: [[192.60509]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 6. 0. 0.] 
cards in discard: [11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 29. 30.  8.  8. 10.  7.  8. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 14.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  8 10  1 14] -> size -> 12 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5.   0.   2.  10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 11.5 

action type: buy - action 11.0
Learning step: -5.9746880531311035
desired expected reward: 211.6913604736328






Player: 1 
cards in hand: [ 0. 14.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 11  8 10  1 14] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  8. 10.  7.  8. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3. 11.  8.  3.] 
adversary cards in discard: [11.  1.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11] -> size -> 17 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 11  8 10  1 14] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 29. 30.  8.  8. 10.  7.  8. 10. 10.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3. 11.  8.  3.] 
adversary cards in discard: [11.  1.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11] -> size -> 17 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  8.  0.  0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 11  8 10  1 14 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  8. 10.  7.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3. 11.  8.  3.] 
adversary cards in discard: [11.  1.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11] -> size -> 17 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 3.  3. 11.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[205.16624]
 [204.20886]
 [193.03336]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11.  8.  3.] 
cards in discard: [11.  1.  3.  6.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  8. 10.  7.  8. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [10.  0. 14.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  8 10  1 14 10] -> size -> 13 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1
Learning step: -4.806381702423096
desired expected reward: 187.7987060546875



action possibilites: [-1] 
expected returns: [[166.66028]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8. 3.] 
cards in discard: [11.  1.  3.  6.  0.  0. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  8. 10.  7.  8. 10. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [10.  0. 14.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  8 10  1 14 10] -> size -> 13 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 43 

action type: gain_card_n - action 8
Learning step: -3.663980484008789
desired expected reward: 187.6127471923828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[156.5168 ]
 [135.44652]
 [169.0928 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 3.] 
cards in discard: [11.  1.  3.  6.  0.  0. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  8. 10.  7.  8. 10. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [10.  0. 14.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  8 10  1 14 10] -> size -> 13 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: take_action - action -1
Learning step: -3.5124340057373047
desired expected reward: 163.14784240722656



buy possibilites: [-1] 
expected returns: [[158.86055]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 3.] 
cards in discard: [11.  1.  3.  6.  0.  0. 14.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  7.  8. 10. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [10.  0. 14.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  8 10  1 14 10] -> size -> 13 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[ -5   0   2  10   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: buy - action 0.0
Learning step: -4.401477813720703
desired expected reward: 152.11532592773438






Player: 1 
cards in hand: [ 3.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0.  0.] 
cards in discard: [10.  0. 14.  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 11  8 10  1 14 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  7.  8. 10. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [11.  1.  3.  6.  0.  0. 14.  0. 11.  3.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0] -> size -> 19 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  0.  0.] 
cards in discard: [10.  0. 14.  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 11  8 10  1 14 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  7.  8. 10. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [11.  1.  3.  6.  0.  0. 14.  0. 11.  3.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0] -> size -> 19 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  0.  0.] 
cards in discard: [10.  0. 14.  8.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 11  8 10  1 14 10  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 28. 30.  8.  8. 10.  7.  8. 10. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [11.  1.  3.  6.  0.  0. 14.  0. 11.  3.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0] -> size -> 19 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [6. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[163.24686]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [11.  1.  3.  6.  0.  0. 14.  0. 11.  3.  3.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  8. 10.  7.  8. 10. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 10. 10.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  8 10  1 14 10  3] -> size -> 14 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: -4.467994213104248
desired expected reward: 154.39256286621094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[148.12802]
 [159.89531]
 [154.67834]
 [123.36398]
 [152.66512]
 [165.3569 ]
 [156.96123]
 [155.29753]
 [135.1025 ]
 [152.73268]
 [146.50662]
 [164.83571]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [11.  1.  3.  6.  0.  0. 14.  0. 11.  3.  3.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 28. 30.  8.  8. 10.  7.  8. 10. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 10. 10.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  8 10  1 14 10  3] -> size -> 14 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -4.789968490600586
desired expected reward: 156.32264709472656



buy possibilites: [-1] 
expected returns: [[170.91115]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [11.  1.  3.  6.  0.  0. 14.  0. 11.  3.  3.  8.  3.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 27. 30. 28. 30.  8.  8. 10.  7.  8. 10. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 10. 10.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  8 10  1 14 10  3] -> size -> 14 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5.   0.   2.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 1.5 

action type: buy - action 1.0
Learning step: -4.074265956878662
desired expected reward: 155.82106018066406






Player: 1 
cards in hand: [ 0.  0. 10. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 10.  1.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 11  8 10  1 14 10  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8.  8. 10.  7.  8. 10. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [8. 0. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1] -> size -> 20 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  1.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3 11  8 10  1 14 10  3] -> size -> 14 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8.  8. 10.  7.  8. 10. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [8. 0. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1] -> size -> 20 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  1.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3 11  8 10  1 14 10  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 27. 30. 28. 30.  8.  8. 10.  7.  8. 10. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [8. 0. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1] -> size -> 20 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  1.  0.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3 11  8 10  1 14 10  3  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 5 
card supply: [28. 27. 30. 28. 30.  8.  8. 10.  7.  8. 10. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [8. 0. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1] -> size -> 20 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [8. 0. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[188.68114]
 [175.74939]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 6. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  8. 10.  7.  8. 10. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  8. 14.  0.  0.] 
adversary cards in discard: [ 0. 10.  0.  0. 10.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  8 10  1 14 10  3  0] -> size -> 15 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: -4.625267028808594
desired expected reward: 166.285888671875



action possibilites: [-1] 
expected returns: [[218.29512]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  8. 10.  7.  8. 10. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  8. 14.  0.  0.] 
adversary cards in discard: [ 0. 10.  0.  0. 10.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  8 10  1 14 10  3  0] -> size -> 15 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: trash_cards_n_from_hand - action 0
Learning step: -2.194761037826538
desired expected reward: 156.93325805664062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[193.99597]
 [163.93762]
 [214.78368]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 27. 30. 28. 30.  8.  8. 10.  7.  8. 10. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  8. 14.  0.  0.] 
adversary cards in discard: [ 0. 10.  0.  0. 10.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  8 10  1 14 10  3  0] -> size -> 15 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1
Learning step: -5.749758243560791
desired expected reward: 212.5453643798828



buy possibilites: [-1] 
expected returns: [[210.29938]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0.] 
cards in discard: [0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 28. 30.  8.  8. 10.  7.  8. 10. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  8. 14.  0.  0.] 
adversary cards in discard: [ 0. 10.  0.  0. 10.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  8 10  1 14 10  3  0] -> size -> 15 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2.   0.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -13.0 

action type: buy - action 0.0
Learning step: -5.223758697509766
desired expected reward: 180.88613891601562






Player: 1 
cards in hand: [ 3.  8. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 14.  0.  0.] 
cards in discard: [ 0. 10.  0.  0. 10.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 11  8 10  1 14 10  3  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 30.  8.  8. 10.  7.  8. 10. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 1. 14.  3.  3. 11.] 
adversary cards in discard: [0. 8. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0] -> size -> 20 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 14.  0.  0.] 
cards in discard: [ 0. 10.  0.  0. 10.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 11  8 10  1 14 10  3  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 28. 30.  8.  8. 10.  7.  8. 10. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 1. 14.  3.  3. 11.] 
adversary cards in discard: [0. 8. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0] -> size -> 20 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 14.  0.  0.] 
cards in discard: [ 0. 10.  0.  0. 10.  1.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 11  8 10  1 14 10  3  0  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 30.  8.  8. 10.  7.  7. 10. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 1. 14.  3.  3. 11.] 
adversary cards in discard: [0. 8. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0] -> size -> 20 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 1. 14.  3.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
expected returns: [[161.55072]
 [123.87414]
 [157.75905]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 14.  3.  3. 11.] 
cards in discard: [0. 8. 3. 6. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 28. 30.  8.  8. 10.  7.  7. 10. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  8.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  8 10  1 14 10  3  0  8] -> size -> 16 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: -7.415658473968506
desired expected reward: 202.8837127685547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[134.65234]
 [143.69475]
 [108.81802]
 [144.86678]
 [159.53424]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 14.  3.  3. 11.] 
cards in discard: [0. 8. 3. 6. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 28. 30.  8.  8. 10.  7.  7. 10. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  8.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  8 10  1 14 10  3  0  8] -> size -> 16 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -4.876224517822266
desired expected reward: 152.23793029785156



buy possibilites: [-1] 
expected returns: [[155.03456]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 14.  3.  3. 11.] 
cards in discard: [0. 8. 3. 6. 0. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  8. 10.  7.  7. 10. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  8.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  8 10  1 14 10  3  0  8] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 16 

action type: buy - action 3.0
Learning step: -2.896460771560669
desired expected reward: 140.79830932617188






Player: 1 
cards in hand: [ 8.  8.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  0.  3. 11.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 11  8 10  1 14 10  3  0  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  8. 10.  7.  7. 10. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [11.  3.  0.  1.  0.] 
adversary cards in discard: [ 0.  8.  3.  6.  0.  3.  1. 14.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3] -> size -> 21 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  8. 10.  7.  7. 10. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [11.  3.  0.  1.  0.] 
adversary cards in discard: [ 0.  8.  3.  6.  0.  3.  1. 14.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3] -> size -> 21 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 27. 30. 27. 30.  8.  8. 10.  7.  7. 10. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [11.  3.  0.  1.  0.] 
adversary cards in discard: [ 0.  8.  3.  6.  0.  3.  1. 14.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3] -> size -> 21 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [11.  3.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[138.49522]
 [138.71254]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  1.  0.] 
cards in discard: [ 0.  8.  3.  6.  0.  3.  1. 14.  3.  3. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  8. 10.  7.  7. 10. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [10.  0. 10.  0.  3.] 
adversary cards in discard: [ 8.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8] -> size -> 14 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: buy - action -1
Learning step: -3.6927757263183594
desired expected reward: 151.34178161621094



action possibilites: [-1] 
expected returns: [[143.6621]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 0.] 
cards in discard: [ 0.  8.  3.  6.  0.  3.  1. 14.  3.  3. 11.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  7. 10.  7.  7. 10. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [10.  0. 10.  0.  3.] 
adversary cards in discard: [ 8.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8] -> size -> 14 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[  -5    0    2   10    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -273 

action type: gain_card_n - action 3
Learning step: -16.864595413208008
desired expected reward: 112.07525634765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[133.5461 ]
 [146.60371]
 [139.69316]
 [105.30592]
 [138.59247]
 [152.12526]
 [144.15471]
 [142.10751]
 [118.1527 ]
 [138.2784 ]
 [131.06917]
 [150.18855]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0.] 
cards in discard: [ 0.  8.  3.  6.  0.  3.  1. 14.  3.  3. 11.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 27. 30. 27. 30.  8.  7. 10.  7.  7. 10. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [10.  0. 10.  0.  3.] 
adversary cards in discard: [ 8.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8] -> size -> 14 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: take_action - action -1
Learning step: -2.7457330226898193
desired expected reward: 140.91636657714844






Player: 1 
cards in hand: [10.  0. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  0.  3.] 
cards in discard: [ 8.  0. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  7. 10.  7.  7. 10. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [ 0.  8.  3.  6.  0.  3.  1. 14.  3.  3. 11.  6. 11.  3.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6] -> size -> 22 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [ 8.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8] -> size -> 14 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  7. 10.  7.  7. 10. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [ 0.  8.  3.  6.  0.  3.  1. 14.  3.  3. 11.  6. 11.  3.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6] -> size -> 22 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [ 8.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 27. 30. 27. 30.  8.  7. 10.  7.  7. 10. 10.  8. 10.  8. 10. 10.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [ 0.  8.  3.  6.  0.  3.  1. 14.  3.  3. 11.  6. 11.  3.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6] -> size -> 22 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [ 8.  0. 11. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  7. 10.  7.  7. 10. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [ 0.  8.  3.  6.  0.  3.  1. 14.  3.  3. 11.  6. 11.  3.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6] -> size -> 22 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [0. 6. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[144.31645]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [ 0.  8.  3.  6.  0.  3.  1. 14.  3.  3. 11.  6. 11.  3.  0.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  7. 10.  7.  7. 10. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 14.  0.  0.  1.] 
adversary cards in discard: [ 8.  0. 11. 10. 10.  0. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8 10] -> size -> 15 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1.0
Learning step: -3.9326932430267334
desired expected reward: 146.255859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[122.87685]
 [132.51297]
 [129.12897]
 [103.54844]
 [126.53228]
 [137.60016]
 [129.41934]
 [128.19983]
 [113.24742]
 [126.92889]
 [122.16741]
 [138.9058 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [ 0.  8.  3.  6.  0.  3.  1. 14.  3.  3. 11.  6. 11.  3.  0.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 27. 30. 27. 30.  8.  7. 10.  7.  7. 10. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 14.  0.  0.  1.] 
adversary cards in discard: [ 8.  0. 11. 10. 10.  0. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8 10] -> size -> 15 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: take_action - action -1.0
Learning step: -3.9766011238098145
desired expected reward: 139.43382263183594



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 14.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  0.  1.] 
cards in discard: [ 8.  0. 11. 10. 10.  0. 10.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  7. 10.  7.  7. 10. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  3.  0. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6] -> size -> 22 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1.] 
cards in discard: [ 8.  0. 11. 10. 10.  0. 10.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 27. 30. 27. 30.  8.  7. 10.  7.  7. 10. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  3. 11.] 
adversary cards in discard: [ 0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6] -> size -> 22 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1.] 
cards in discard: [ 8.  0. 11. 10. 10.  0. 10.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 7 
card supply: [27. 27. 30. 27. 30.  8.  7. 10.  7.  7. 10. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  3. 11.] 
adversary cards in discard: [ 0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6] -> size -> 22 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1.] 
cards in discard: [ 8.  0. 11. 10. 10.  0. 10.  0.  3.  0. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8 10 16] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 27. 30. 27. 30.  8.  7.  9.  7.  7. 10. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  3. 11.] 
adversary cards in discard: [ 0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6] -> size -> 22 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 8.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[158.16386]
 [148.61905]
 [157.55438]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 11.] 
cards in discard: [ 0. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  7.  9.  7.  7. 10. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8. 16. 14.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8 10 16] -> size -> 16 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[  -5    0    2   10    0    0    0  -30    0    0    0    0    0 -900
   34    0] 
sum of rewards: -889 

action type: discard_down_to_3_cards - action 2
Learning step: -45.7934455871582
desired expected reward: 49.25477981567383



action possibilites: [-1] 
expected returns: [[96.255196]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3.] 
cards in discard: [ 0. 11. 16.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  7.  8.  7.  7. 10. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8. 16. 14.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8 10 16] -> size -> 16 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 43 

action type: gain_card_n - action 4
Learning step: -1.6758159399032593
desired expected reward: 118.15533447265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[73.927734]
 [52.648434]
 [97.934425]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3.] 
cards in discard: [ 0. 11. 16.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  7.  8.  7.  7. 10. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8. 16. 14.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8 10 16] -> size -> 16 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: take_action - action -1
Learning step: -1.7599529027938843
desired expected reward: 94.4952392578125






Player: 1 
cards in hand: [ 8. 16. 14.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 14. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16. 14.  3. 10.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8 10 16] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  7.  8.  7.  7. 10. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  6.  1. 14.  0.] 
adversary cards in discard: [ 0. 11. 16. 11.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16] -> size -> 23 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 16. 14.  3. 10.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8 10 16] -> size -> 16 
action values: 1 
buys: 1 
player value: 0 
card supply: [27. 27. 30. 27. 30.  8.  7.  8.  7.  7. 10. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  6.  1. 14.  0.] 
adversary cards in discard: [ 0. 11. 16. 11.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16] -> size -> 23 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 16. 14.  3. 10.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8 10 16  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  7.  8.  7.  7. 10. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  6.  1. 14.  0.] 
adversary cards in discard: [ 0. 11. 16. 11.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16] -> size -> 23 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 3.  6.  1. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[127.53942]
 [ 90.42626]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  1. 14.  0.] 
cards in discard: [ 0. 11. 16. 11.  8.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 27. 30.  8.  7.  8.  7.  7. 10. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [ 0.  8. 16. 14.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8 10 16  0] -> size -> 17 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1.0
Learning step: -2.113802909851074
desired expected reward: 95.82063293457031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 98.75272 ]
 [113.01145 ]
 [108.26979 ]
 [ 73.15674 ]
 [120.891914]
 [108.57836 ]
 [105.3508  ]
 [122.41994 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  1. 14.  0.] 
cards in discard: [ 0. 11. 16. 11.  8.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 27. 30.  8.  7.  8.  7.  7. 10. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [ 0.  8. 16. 14.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8 10 16  0] -> size -> 17 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: take_action - action -1.0
Learning step: -3.2575128078460693
desired expected reward: 116.99435424804688



buy possibilites: [-1] 
expected returns: [[116.909775]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  1. 14.  0.] 
cards in discard: [ 0. 11. 16. 11.  8.  3.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 26. 30.  8.  7.  8.  7.  7. 10. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [ 0.  8. 16. 14.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8 10 16  0] -> size -> 17 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 20.0 

action type: buy - action 3.0
Learning step: -1.78302001953125
desired expected reward: 106.48677825927734






Player: 1 
cards in hand: [10.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  0.] 
cards in discard: [ 0.  8. 16. 14.  3. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8 10 16  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 30.  8.  7.  8.  7.  7. 10. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [6. 3. 0. 3. 0.] 
adversary cards in discard: [ 0. 11. 16. 11.  8.  3.  3.  3.  6.  1. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3] -> size -> 24 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [ 0.  8. 16. 14.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8 10 16  0] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 30.  8.  7.  8.  7.  7. 10. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [6. 3. 0. 3. 0.] 
adversary cards in discard: [ 0. 11. 16. 11.  8.  3.  3.  3.  6.  1. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3] -> size -> 24 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [ 0.  8. 16. 14.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8 10 16  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 6 
card supply: [26. 27. 30. 26. 30.  8.  7.  8.  7.  7. 10. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [6. 3. 0. 3. 0.] 
adversary cards in discard: [ 0. 11. 16. 11.  8.  3.  3.  3.  6.  1. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3] -> size -> 24 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [ 0.  8. 16. 14.  3. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8 10 16  0  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 6 
card supply: [25. 27. 30. 26. 30.  8.  7.  8.  7.  7. 10. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [6. 3. 0. 3. 0.] 
adversary cards in discard: [ 0. 11. 16. 11.  8.  3.  3.  3.  6.  1. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3] -> size -> 24 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [6. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[85.232285]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 3. 0.] 
cards in discard: [ 0. 11. 16. 11.  8.  3.  3.  3.  6.  1. 14.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 26. 30.  8.  7.  8.  7.  7. 10. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0. 11.] 
adversary cards in discard: [ 0.  8. 16. 14.  3. 10.  0. 10.  0.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8 10 16  0  0] -> size -> 18 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: buy - action -1
Learning step: -3.0647594928741455
desired expected reward: 113.84501647949219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[66.5862  ]
 [75.4692  ]
 [43.05547 ]
 [76.03011 ]
 [84.763054]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 3. 0.] 
cards in discard: [ 0. 11. 16. 11.  8.  3.  3.  3.  6.  1. 14.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 27. 30. 26. 30.  8.  7.  8.  7.  7. 10. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0. 11.] 
adversary cards in discard: [ 0.  8. 16. 14.  3. 10.  0. 10.  0.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8 10 16  0  0] -> size -> 18 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1.0
Learning step: -1.7100279331207275
desired expected reward: 81.87794494628906



buy possibilites: [-1] 
expected returns: [[75.94414]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 3. 0.] 
cards in discard: [ 0. 11. 16. 11.  8.  3.  3.  3.  6.  1. 14.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 27. 30. 26. 30.  8.  6.  8.  7.  7. 10. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0. 11.] 
adversary cards in discard: [ 0.  8. 16. 14.  3. 10.  0. 10.  0.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8 10 16  0  0] -> size -> 18 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.   10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -293.0 

action type: buy - action 6.0
Learning step: -15.09403133392334
desired expected reward: 27.961437225341797






Player: 1 
cards in hand: [10.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0. 11.] 
cards in discard: [ 0.  8. 16. 14.  3. 10.  0. 10.  0.  0.  0.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8 10 16  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 26. 30.  8.  6.  8.  7.  7. 10. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 6. 0. 1. 0.] 
adversary cards in discard: [ 0. 11. 16. 11.  8.  3.  3.  3.  6.  1. 14.  0.  6.  6.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6] -> size -> 25 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0. 11.] 
cards in discard: [ 0.  8. 16. 14.  3. 10.  0. 10.  0.  0.  0.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8 10 16  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 27. 30. 26. 30.  8.  6.  8.  7.  7. 10. 10.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 6. 0. 1. 0.] 
adversary cards in discard: [ 0. 11. 16. 11.  8.  3.  3.  3.  6.  1. 14.  0.  6.  6.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6] -> size -> 25 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0. 11.] 
cards in discard: [ 0.  8. 16. 14.  3. 10.  0. 10.  0.  0.  0.  0.  1. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 26. 30.  8.  6.  8.  7.  7. 10. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [0. 6. 0. 1. 0.] 
adversary cards in discard: [ 0. 11. 16. 11.  8.  3.  3.  3.  6.  1. 14.  0.  6.  6.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6] -> size -> 25 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [0. 6. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[77.12956]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 1. 0.] 
cards in discard: [ 0. 11. 16. 11.  8.  3.  3.  3.  6.  1. 14.  0.  6.  6.  3.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 26. 30.  8.  6.  8.  7.  7. 10. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10] -> size -> 19 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1
Learning step: -1.7117918729782104
desired expected reward: 74.23234558105469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[59.162167]
 [67.954544]
 [64.752174]
 [47.495872]
 [41.892155]
 [62.550087]
 [72.54421 ]
 [65.23514 ]
 [78.116325]
 [64.10777 ]
 [50.307934]
 [54.996403]
 [63.03353 ]
 [45.48572 ]
 [58.63042 ]
 [73.848465]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 1. 0.] 
cards in discard: [ 0. 11. 16. 11.  8.  3.  3.  3.  6.  1. 14.  0.  6.  6.  3.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 27. 30. 26. 30.  8.  6.  8.  7.  7. 10. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10] -> size -> 19 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: take_action - action -1.0
Learning step: -2.1278913021087646
desired expected reward: 75.00167083740234



buy possibilites: [-1] 
expected returns: [[69.375244]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 1. 0.] 
cards in discard: [ 0. 11. 16. 11.  8.  3.  3.  3.  6.  1. 14.  0.  6.  6.  3.  0.  3.  0.
 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 26. 30.  8.  6.  8.  7.  7.  9. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10] -> size -> 19 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0 50  0] 
sum of rewards: 57 

action type: buy - action 25.0
Learning step: 0.5051265954971313
desired expected reward: 78.62145233154297






Player: 1 
cards in hand: [ 0. 10.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0. 14.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 26. 30.  8.  6.  8.  7.  7.  9. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 11.  6.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25] -> size -> 26 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1. 14. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 14. 11.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10] -> size -> 19 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 26. 30.  8.  6.  8.  7.  7.  9. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 11.  6.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25] -> size -> 26 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 14.] 
cards in discard: [11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 26. 30.  8.  6.  8.  6.  7.  9. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 11.  6.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25] -> size -> 26 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 14.] 
cards in discard: [11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 27. 30. 26. 30.  8.  6.  8.  6.  7.  9. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 11.  6.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25] -> size -> 26 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 14.] 
cards in discard: [11.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 30.  8.  6.  8.  6.  7.  9. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 11.  6.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25] -> size -> 26 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  6.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[101.827484]
 [101.6009  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  6.  3.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 30.  8.  6.  8.  6.  7.  9. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [10.  8.  0. 10.  1.] 
adversary cards in discard: [11.  1. 10. 11.  0.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1] -> size -> 21 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1
Learning step: -0.864715576171875
desired expected reward: 68.51052856445312



action possibilites: [-1] 
expected returns: [[123.137856]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 0.] 
cards in discard: [1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 26. 30.  8.  6.  8.  6.  7.  9. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [10.  8.  0. 10.  1.] 
adversary cards in discard: [11.  1. 10. 11.  0.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1] -> size -> 21 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 36 

action type: gain_card_n - action 1
Learning step: -0.1321842223405838
desired expected reward: 93.92353057861328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[103.863464]
 [ 75.17858 ]
 [128.41708 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 0.] 
cards in discard: [1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 25. 30. 26. 30.  8.  6.  8.  6.  7.  9. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [10.  8.  0. 10.  1.] 
adversary cards in discard: [11.  1. 10. 11.  0.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1] -> size -> 21 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: take_action - action -1
Learning step: -2.479644536972046
desired expected reward: 120.65821075439453



buy possibilites: [-1] 
expected returns: [[156.23267]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 0.] 
cards in discard: [1. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 25. 30. 26. 30.  8.  6.  8.  6.  7.  9. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [10.  8.  0. 10.  1.] 
adversary cards in discard: [11.  1. 10. 11.  0.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1] -> size -> 21 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2.  10.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -3.0 

action type: buy - action 0.0
Learning step: -1.827938437461853
desired expected reward: 102.0355224609375






Player: 1 
cards in hand: [10.  8.  0. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0. 10.  1.] 
cards in discard: [11.  1. 10. 11.  0.  0.  0. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 26. 30.  8.  6.  8.  6.  7.  9. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  0. 14. 11.  0.] 
adversary cards in discard: [ 1.  0. 11.  3.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0] -> size -> 28 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  1.  0.] 
cards in discard: [11.  1. 10. 11.  0.  0.  0. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 26. 30.  8.  6.  8.  6.  7.  9. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  0. 14. 11.  0.] 
adversary cards in discard: [ 1.  0. 11.  3.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0] -> size -> 28 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 1. 0. 0.] 
cards in discard: [11.  1. 10. 11.  0.  0.  0. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1] -> size -> 21 
action values: 3 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 26. 30.  8.  6.  8.  6.  7.  9. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  0. 14. 11.  0.] 
adversary cards in discard: [ 1.  0. 11.  3.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0] -> size -> 28 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [11.  1. 10. 11.  0.  0.  0. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 10.  8.] 
owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 26. 30.  8.  6.  8.  6.  7.  9. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  0. 14. 11.  0.] 
adversary cards in discard: [ 1.  0. 11.  3.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0] -> size -> 28 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [11.  1. 10. 11.  0.  0.  0. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 10.  8.] 
owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 25. 30. 26. 30.  8.  6.  8.  6.  7.  9. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  0. 14. 11.  0.] 
adversary cards in discard: [ 1.  0. 11.  3.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0] -> size -> 28 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [11.  1. 10. 11.  0.  0.  0. 14.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 10.  8.] 
owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 26. 30.  8.  6.  8.  6.  6.  9. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  0. 14. 11.  0.] 
adversary cards in discard: [ 1.  0. 11.  3.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0] -> size -> 28 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 6.  0. 14. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
expected returns: [[79.36376 ]
 [50.228706]
 [78.88962 ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 14. 11.  0.] 
cards in discard: [ 1.  0. 11.  3.  6.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 26. 30.  8.  6.  8.  6.  6.  9. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [11.  1. 10. 11.  0.  0.  0. 14.  8. 10. 10.  8.  1.] 
adversary owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8] -> size -> 19 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1
Learning step: -5.925075054168701
desired expected reward: 150.30758666992188



action possibilites: [-1] 
expected returns: [[118.014]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 11.  0.] 
cards in discard: [ 1.  0. 11.  3.  6.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 25. 30. 26. 30.  8.  6.  8.  6.  6.  9. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.] 
adversary cards in discard: [11.  1. 10. 11.  0.  0.  0. 14.  8. 10. 10.  8.  1.  0.  0.] 
adversary owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8] -> size -> 19 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: take_action - action 14.0
Learning step: 1.5576738119125366
desired expected reward: 50.510498046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 96.023544]
 [108.06    ]
 [104.0205  ]
 [ 73.105705]
 [100.61506 ]
 [115.26745 ]
 [104.42475 ]
 [102.86955 ]
 [ 84.19766 ]
 [101.63245 ]
 [ 95.4621  ]
 [116.87484 ]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 11.  0.] 
cards in discard: [ 1.  0. 11.  3.  6.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 25. 30. 26. 30.  8.  6.  8.  6.  6.  9. 10.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.] 
adversary cards in discard: [11.  1. 10. 11.  0.  0.  0. 14.  8. 10. 10.  8.  1.  0.  0.] 
adversary owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8] -> size -> 19 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: take_action - action -1
Learning step: -2.2822225093841553
desired expected reward: 115.73178100585938



buy possibilites: [-1] 
expected returns: [[83.95554]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 11.  0.] 
cards in discard: [ 1.  0. 11.  3.  6.  3.  0. 14.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 26. 30.  8.  6.  8.  6.  6.  9. 10.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.] 
adversary cards in discard: [11.  1. 10. 11.  0.  0.  0. 14.  8. 10. 10.  8.  1.  0.  0.] 
adversary owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8] -> size -> 19 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0 32  0] 
sum of rewards: 59 

action type: buy - action 14.0
Learning step: 0.6986026763916016
desired expected reward: 83.50654602050781






Player: 1 
cards in hand: [ 0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.] 
cards in discard: [11.  1. 10. 11.  0.  0.  0. 14.  8. 10. 10.  8.  1.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 26. 30.  8.  6.  8.  6.  6.  9. 10.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 8.  0.  6.  1. 16.] 
adversary cards in discard: [ 1.  0. 11.  3.  6.  3.  0. 14. 14.  6.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14] -> size -> 29 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.] 
cards in discard: [11.  1. 10. 11.  0.  0.  0. 14.  8. 10. 10.  8.  1.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 25. 30. 26. 30.  8.  6.  8.  6.  6.  9. 10.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 8.  0.  6.  1. 16.] 
adversary cards in discard: [ 1.  0. 11.  3.  6.  3.  0. 14. 14.  6.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14] -> size -> 29 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.] 
cards in discard: [11.  1. 10. 11.  0.  0.  0. 14.  8. 10. 10.  8.  1.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 25. 30. 26. 30.  8.  6.  8.  6.  6.  9. 10.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 8.  0.  6.  1. 16.] 
adversary cards in discard: [ 1.  0. 11.  3.  6.  3.  0. 14. 14.  6.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14] -> size -> 29 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 8.  0.  6.  1. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
expected returns: [[58.206158]
 [47.84933 ]
 [43.939507]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  6.  1. 16.] 
cards in discard: [ 1.  0. 11.  3.  6.  3.  0. 14. 14.  6.  0. 11.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 26. 30.  8.  6.  8.  6.  6.  9. 10.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10. 11.  1. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0] -> size -> 20 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1
Learning step: -2.7160708904266357
desired expected reward: 81.23947143554688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[40.200283]
 [51.253292]
 [46.748856]
 [23.269547]
 [57.262634]
 [47.19955 ]
 [44.287437]
 [57.551983]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  6.  1. 16.] 
cards in discard: [ 1.  0. 11.  3.  6.  3.  0. 14. 14.  6.  0. 11.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 25. 30. 26. 30.  8.  6.  8.  6.  6.  9. 10.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10. 11.  1. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0] -> size -> 20 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: take_action - action -1.0
Learning step: -1.5164297819137573
desired expected reward: 56.689720153808594



buy possibilites: [-1] 
expected returns: [[-9.046621]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  6.  1. 16.] 
cards in discard: [ 1.  0. 11.  3.  6.  3.  0. 14. 14.  6.  0. 11.  0.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 25. 30. 26. 30.  8.  6.  8.  6.  5.  9. 10.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10. 11.  1. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0] -> size -> 20 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5.  0.  2. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 9.0 

action type: buy - action 8.0
Learning step: -2.1135261058807373
desired expected reward: 45.08601760864258






Player: 1 
cards in hand: [ 0. 10. 11.  1. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 16.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  1. 16.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 26. 30.  8.  6.  8.  6.  5.  9. 10.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 25.  0.  0.  3.] 
adversary cards in discard: [ 1.  0. 11.  3.  6.  3.  0. 14. 14.  6.  0. 11.  0.  8.  8.  0.  6.  1.
 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8] -> size -> 30 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  1. 16.] 
cards in discard: [0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 26. 30.  8.  6.  8.  6.  5.  9. 10.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 25.  0.  0.  3.] 
adversary cards in discard: [ 1.  0. 11.  3.  6.  3.  0. 14. 14.  6.  0. 11.  0.  8.  8.  0.  6.  1.
 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8] -> size -> 30 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  1. 16.] 
cards in discard: [0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 25. 30. 26. 30.  8.  6.  8.  6.  5.  9. 10.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 25.  0.  0.  3.] 
adversary cards in discard: [ 1.  0. 11.  3.  6.  3.  0. 14. 14.  6.  0. 11.  0.  8.  8.  0.  6.  1.
 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8] -> size -> 30 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  1. 16.] 
cards in discard: [ 0. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 26. 30.  8.  6.  8.  5.  5.  9. 10.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 25.  0.  0.  3.] 
adversary cards in discard: [ 1.  0. 11.  3.  6.  3.  0. 14. 14.  6.  0. 11.  0.  8.  8.  0.  6.  1.
 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8] -> size -> 30 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 3. 25.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[66.64346]
 [76.17987]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  0.  0.  3.] 
cards in discard: [ 1.  0. 11.  3.  6.  3.  0. 14. 14.  6.  0. 11.  0.  8.  8.  0.  6.  1.
 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 26. 30.  8.  6.  8.  5.  5.  9. 10.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  8.  0.  0. 11.] 
adversary cards in discard: [ 0. 11. 11.  0. 10.  1. 16.] 
adversary owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11] -> size -> 22 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1
Learning step: 2.413011312484741
desired expected reward: -6.633609771728516



action possibilites: [-1] 
expected returns: [[3.0585504]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0. 6.] 
cards in discard: [ 1.  0. 11.  3.  6.  3.  0. 14. 14.  6.  0. 11.  0.  8.  8.  0.  6.  1.
 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 26. 30.  8.  5.  8.  5.  5.  9. 10.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  8.  0.  0. 11.] 
adversary cards in discard: [ 0. 11. 11.  0. 10.  1. 16.  6.] 
adversary owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6] -> size -> 23 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 28 

action type: take_action - action 25.0
Learning step: -2.3401763439178467
desired expected reward: 73.8396987915039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-0.79742455]
 [ 2.2070327 ]
 [ 1.1811285 ]
 [-4.5659914 ]
 [ 4.301697  ]
 [ 1.3549147 ]
 [ 0.77623796]
 [ 5.019889  ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0. 6.] 
cards in discard: [ 1.  0. 11.  3.  6.  3.  0. 14. 14.  6.  0. 11.  0.  8.  8.  0.  6.  1.
 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 25. 30. 26. 30.  8.  5.  8.  5.  5.  9. 10.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  8.  0.  0. 11.] 
adversary cards in discard: [ 0. 11. 11.  0. 10.  1. 16.  6.] 
adversary owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6] -> size -> 23 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: take_action - action -1
Learning step: 1.2268790006637573
desired expected reward: 4.28542947769165



buy possibilites: [-1] 
expected returns: [[5.7535095]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0. 6.] 
cards in discard: [ 1.  0. 11.  3.  6.  3.  0. 14. 14.  6.  0. 11.  0.  8.  8.  0.  6.  1.
 16.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 25. 30. 26. 30.  8.  5.  8.  5.  4.  9. 10.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  8.  0.  0. 11.] 
adversary cards in discard: [ 0. 11. 11.  0. 10.  1. 16.  6.] 
adversary owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6] -> size -> 23 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5.  0.  2. 10.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 29.0 

action type: buy - action 8.0
Learning step: 1.5117080211639404
desired expected reward: 2.8666274547576904






Player: 1 
cards in hand: [ 3.  8.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0.  0. 11.] 
cards in discard: [ 0. 11. 11.  0. 10.  1. 16.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 26. 30.  8.  5.  8.  5.  4.  9. 10.  7. 10.  6. 10. 10.] 
adversary cards in hand: [11.  0.  1.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8] -> size -> 31 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [ 0. 11. 11.  0. 10.  1. 16.  6. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 26. 30.  8.  5.  8.  4.  4.  9. 10.  7. 10.  6. 10. 10.] 
adversary cards in hand: [11.  0.  1.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8] -> size -> 31 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [ 0. 11. 11.  0. 10.  1. 16.  6. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 25. 30. 26. 30.  8.  5.  8.  4.  4.  9. 10.  7. 10.  6. 10. 10.] 
adversary cards in hand: [11.  0.  1.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8] -> size -> 31 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [11.  0.  1.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[54.875866]
 [52.976604]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  1.  3.  3.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 26. 30.  8.  5.  8.  4.  4.  9. 10.  7. 10.  6. 10. 10.] 
adversary cards in hand: [14. 10.  0. 10.  1.] 
adversary cards in discard: [ 0. 11. 11.  0. 10.  1. 16.  6. 11. 11.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11] -> size -> 24 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1
Learning step: 1.7192944288253784
desired expected reward: 7.472804069519043





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[37.91194 ]
 [46.863632]
 [44.276314]
 [15.464549]
 [51.84864 ]
 [44.43883 ]
 [42.937656]
 [53.747902]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  1.  3.  3.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 25. 30. 26. 30.  8.  5.  8.  4.  4.  9. 10.  7. 10.  6. 10. 10.] 
adversary cards in hand: [14. 10.  0. 10.  1.] 
adversary cards in discard: [ 0. 11. 11.  0. 10.  1. 16.  6. 11. 11.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11] -> size -> 24 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -0.8166252374649048
desired expected reward: 51.68964767456055



buy possibilites: [-1] 
expected returns: [[80.46486]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  1.  3.  3.] 
cards in discard: [0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 25. 30. 26. 30.  8.  5.  8.  4.  4.  9. 10.  7. 10.  6. 10. 10.] 
adversary cards in hand: [14. 10.  0. 10.  1.] 
adversary cards in discard: [ 0. 11. 11.  0. 10.  1. 16.  6. 11. 11.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11] -> size -> 24 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2.  20.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -13.0 

action type: buy - action 0.0
Learning step: -0.7351375818252563
desired expected reward: 37.17679977416992






Player: 1 
cards in hand: [14. 10.  0. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 10.  0. 10.  1.] 
cards in discard: [ 0. 11. 11.  0. 10.  1. 16.  6. 11. 11.  3.  8.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 26. 30.  8.  5.  8.  4.  4.  9. 10.  7. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 6. 0. 3.] 
adversary cards in discard: [ 0. 11.  0.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0] -> size -> 32 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1. 14. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0. 10.  1.  0.] 
cards in discard: [ 0. 11. 11.  0. 10.  1. 16.  6. 11. 11.  3.  8.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 26. 30.  8.  5.  8.  4.  4.  9. 10.  7. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 6. 0. 3.] 
adversary cards in discard: [ 0. 11.  0.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0] -> size -> 32 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0. 10.  1.  0.] 
cards in discard: [ 0. 11. 11.  0. 10.  1. 16.  6. 11. 11.  3.  8.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 25. 30. 26. 30.  8.  5.  8.  4.  4.  9. 10.  7. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 6. 0. 3.] 
adversary cards in discard: [ 0. 11.  0.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0] -> size -> 32 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0. 10.  1.  0.] 
cards in discard: [ 0. 11. 11.  0. 10.  1. 16.  6. 11. 11.  3.  8.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 25. 30. 26. 30.  8.  5.  8.  4.  4.  9. 10.  7. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 6. 0. 3.] 
adversary cards in discard: [ 0. 11.  0.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0] -> size -> 32 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [0. 3. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[88.722824]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 0. 3.] 
cards in discard: [ 0. 11.  0.  1.  3.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 26. 30.  8.  5.  8.  4.  4.  9. 10.  7. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10] -> size -> 25 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1
Learning step: -1.176979422569275
desired expected reward: 79.28787994384766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[77.0882  ]
 [82.036316]
 [60.40587 ]
 [82.985306]
 [89.7887  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 3.] 
cards in discard: [ 0. 11.  0.  1.  3.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 25. 30. 26. 30.  8.  5.  8.  4.  4.  9. 10.  7. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10] -> size -> 25 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -1.8114643096923828
desired expected reward: 86.91136169433594



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 10.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 26. 30.  8.  5.  8.  4.  4.  9. 10.  7. 10.  5. 10. 10.] 
adversary cards in hand: [14. 14.  6.  8.  1.] 
adversary cards in discard: [ 0. 11.  0.  1.  3.  3.  0.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0] -> size -> 32 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 26. 30.  8.  5.  8.  4.  4.  9. 10.  7. 10.  5. 10. 10.] 
adversary cards in hand: [14. 14.  6.  8.  1.] 
adversary cards in discard: [ 0. 11.  0.  1.  3.  3.  0.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0] -> size -> 32 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 25. 30. 26. 30.  8.  5.  8.  4.  4.  9. 10.  7. 10.  5. 10. 10.] 
adversary cards in hand: [14. 14.  6.  8.  1.] 
adversary cards in discard: [ 0. 11.  0.  1.  3.  3.  0.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0] -> size -> 32 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 4 
card supply: [20. 25. 30. 26. 30.  8.  5.  8.  4.  4.  9. 10.  7. 10.  5. 10. 10.] 
adversary cards in hand: [14. 14.  6.  8.  1.] 
adversary cards in discard: [ 0. 11.  0.  1.  3.  3.  0.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0] -> size -> 32 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [14. 14.  6.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14.  8.] 
expected returns: [[ -0.74492025]
 [-17.12188   ]
 [-17.12188   ]
 [ -5.6950445 ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 14.  6.  8.  1.] 
cards in discard: [ 0. 11.  0.  1.  3.  3.  0.  3.  6.  0.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 26. 30.  8.  5.  8.  4.  4.  9. 10.  7. 10.  5. 10. 10.] 
adversary cards in hand: [11. 10. 11.  0. 11.] 
adversary cards in discard: [ 0. 10.  0.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10  0] -> size -> 26 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1.0
Learning step: -3.860537052154541
desired expected reward: 85.92817687988281



action possibilites: [-1] 
expected returns: [[27.614983]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6.  8.  1.] 
cards in discard: [ 0. 11.  0.  1.  3.  3.  0.  3.  6.  0.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 25. 30. 26. 30.  8.  5.  8.  4.  4.  9. 10.  7. 10.  5. 10. 10.] 
adversary cards in hand: [10.  0. 11.] 
adversary cards in discard: [ 0. 10.  0.  0.  0.  8.  0. 11. 11.] 
adversary owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10  0] -> size -> 26 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: take_action - action 14.0
Learning step: 3.3274307250976562
desired expected reward: -13.794445037841797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 10.195062 ]
 [ 23.098381 ]
 [ 19.502094 ]
 [-11.969183 ]
 [ 16.353172 ]
 [ 28.529255 ]
 [ 20.042843 ]
 [ 18.437962 ]
 [ -6.0857134]
 [ 16.913902 ]
 [  8.319022 ]
 [ 28.787159 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.  8.  1.] 
cards in discard: [ 0. 11.  0.  1.  3.  3.  0.  3.  6.  0.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 25. 30. 26. 30.  8.  5.  8.  4.  4.  9. 10.  7. 10.  5. 10. 10.] 
adversary cards in hand: [10.  0. 11.] 
adversary cards in discard: [ 0. 10.  0.  0.  0.  8.  0. 11. 11.] 
adversary owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10  0] -> size -> 26 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: take_action - action -1
Learning step: 0.8038503527641296
desired expected reward: 28.418832778930664



buy possibilites: [-1] 
expected returns: [[91.23323]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.  8.  1.] 
cards in discard: [ 0. 11.  0.  1.  3.  3.  0.  3.  6.  0.  3. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 25. 30. 26. 30.  8.  5.  8.  3.  4.  9. 10.  7. 10.  5. 10. 10.] 
adversary cards in hand: [10.  0. 11.] 
adversary cards in discard: [ 0. 10.  0.  0.  0.  8.  0. 11. 11.] 
adversary owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10  0] -> size -> 26 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5.   0.   2.  20.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 41.5 

action type: buy - action 11.0
Learning step: 2.6537606716156006
desired expected reward: 32.13350296020508






Player: 1 
cards in hand: [10.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.] 
cards in discard: [ 0. 10.  0.  0.  0.  8.  0. 11. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 26. 30.  8.  5.  8.  3.  4.  9. 10.  7. 10.  5. 10. 10.] 
adversary cards in hand: [16.  3. 25.  0.  6.] 
adversary cards in discard: [ 0. 11.  0.  1.  3.  3.  0.  3.  6.  0.  3. 11. 14. 14.  6.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11] -> size -> 33 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11.] 
cards in discard: [ 0. 10.  0.  0.  0.  8.  0. 11. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 25. 30. 26. 30.  8.  5.  8.  3.  4.  9. 10.  7. 10.  5. 10. 10.] 
adversary cards in hand: [16.  3. 25.  0.  6.] 
adversary cards in discard: [ 0. 11.  0.  1.  3.  3.  0.  3.  6.  0.  3. 11. 14. 14.  6.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11] -> size -> 33 
adversary victory points: 2
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [16.  3. 25.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 25.] 
expected returns: [[ 97.1736 ]
 [ 84.53413]
 [102.55321]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3. 25.  0.  6.] 
cards in discard: [ 0. 11.  0.  1.  3.  3.  0.  3.  6.  0.  3. 11. 14. 14.  6.  8.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 26. 30.  8.  5.  8.  3.  4.  9. 10.  7. 10.  5. 10. 10.] 
adversary cards in hand: [10.  1.  8. 11.  6.] 
adversary cards in discard: [ 0. 10.  0.  0.  0.  8.  0. 11. 11. 10.  0. 11.] 
adversary owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10  0] -> size -> 26 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1
Learning step: -1.5732964277267456
desired expected reward: 89.6599349975586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[79.74285]
 [53.81084]
 [96.26501]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3. 25.  0.  6.] 
cards in discard: [ 0. 11.  0.  1.  3.  3.  0.  3.  6.  0.  3. 11. 14. 14.  6.  8.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 25. 30. 26. 30.  8.  5.  8.  3.  4.  9. 10.  7. 10.  5. 10. 10.] 
adversary cards in hand: [10.  1.  8. 11.  6.] 
adversary cards in discard: [ 0. 10.  0.  0.  0.  8.  0. 11. 11. 10.  0. 11.] 
adversary owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10  0] -> size -> 26 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -2.268888235092163
desired expected reward: 94.90471649169922



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10.  1.  8. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  8. 11.  6.] 
cards in discard: [ 0. 10.  0.  0.  0.  8.  0. 11. 11. 10.  0. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 26. 30.  8.  5.  8.  3.  4.  9. 10.  7. 10.  5. 10. 10.] 
adversary cards in hand: [ 8.  3.  0. 11.  0.] 
adversary cards in discard: [ 0. 11.  0.  1.  3.  3.  0.  3.  6.  0.  3. 11. 14. 14.  6.  8.  1. 16.
  3. 25.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11] -> size -> 33 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  8.  6.] 
cards in discard: [ 0. 10.  0.  0.  0.  8.  0. 11. 11. 10.  0. 11.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10  0  6] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 26. 30.  8.  4.  8.  3.  4.  9. 10.  7. 10.  5. 10. 10.] 
adversary cards in hand: [ 8.  3.  0. 11.  0.] 
adversary cards in discard: [ 0. 11.  0.  1.  3.  3.  0.  3.  6.  0.  3. 11. 14. 14.  6.  8.  1. 16.
  3. 25.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11] -> size -> 33 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  8.  6.] 
cards in discard: [ 0. 10.  0.  0.  0.  8.  0. 11. 11. 10.  0. 11.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10  0  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 25. 30. 26. 30.  8.  4.  8.  3.  4.  9. 10.  7. 10.  5. 10. 10.] 
adversary cards in hand: [ 8.  3.  0. 11.  0.] 
adversary cards in discard: [ 0. 11.  0.  1.  3.  3.  0.  3.  6.  0.  3. 11. 14. 14.  6.  8.  1. 16.
  3. 25.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11] -> size -> 33 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  8.  6.] 
cards in discard: [ 0. 10.  0.  0.  0.  8.  0. 11. 11. 10.  0. 11.  6.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10  0  6  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 26. 30.  8.  4.  8.  3.  3.  9. 10.  7. 10.  5. 10. 10.] 
adversary cards in hand: [ 8.  3.  0. 11.  0.] 
adversary cards in discard: [ 0. 11.  0.  1.  3.  3.  0.  3.  6.  0.  3. 11. 14. 14.  6.  8.  1. 16.
  3. 25.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11] -> size -> 33 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 8.  3.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[38.70944 ]
 [31.535877]
 [39.12911 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0. 11.  0.] 
cards in discard: [ 0. 11.  0.  1.  3.  3.  0.  3.  6.  0.  3. 11. 14. 14.  6.  8.  1. 16.
  3. 25.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 26. 30.  8.  4.  8.  3.  3.  9. 10.  7. 10.  5. 10. 10.] 
adversary cards in hand: [10.  0.  0. 14.  1.] 
adversary cards in discard: [ 0. 10.  0.  0.  0.  8.  0. 11. 11. 10.  0. 11.  6.  8. 11. 10.  1.  8.
  6.] 
adversary owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10  0  6  8] -> size -> 28 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: buy - action -1.0
Learning step: -2.640747308731079
desired expected reward: 93.62425231933594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[22.056973 ]
 [29.869366 ]
 [ 5.6754956]
 [32.882317 ]
 [39.041668 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  0. 11.  0.] 
cards in discard: [ 0. 11.  0.  1.  3.  3.  0.  3.  6.  0.  3. 11. 14. 14.  6.  8.  1. 16.
  3. 25.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 25. 30. 26. 30.  8.  4.  8.  3.  3.  9. 10.  7. 10.  5. 10. 10.] 
adversary cards in hand: [10.  0.  0. 14.  1.] 
adversary cards in discard: [ 0. 10.  0.  0.  0.  8.  0. 11. 11. 10.  0. 11.  6.  8. 11. 10.  1.  8.
  6.] 
adversary owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10  0  6  8] -> size -> 28 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: take_action - action -1.0
Learning step: 0.008188056759536266
desired expected reward: 38.717613220214844



buy possibilites: [-1] 
expected returns: [[48.68678]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  0. 11.  0.] 
cards in discard: [ 0. 11.  0.  1.  3.  3.  0.  3.  6.  0.  3. 11. 14. 14.  6.  8.  1. 16.
  3. 25.  0.  6.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 25. 30. 26. 30.  8.  4.  8.  3.  3.  9. 10.  7. 10.  5. 10. 10.] 
adversary cards in hand: [10.  0.  0. 14.  1.] 
adversary cards in discard: [ 0. 10.  0.  0.  0.  8.  0. 11. 11. 10.  0. 11.  6.  8. 11. 10.  1.  8.
  6.] 
adversary owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10  0  6  8] -> size -> 28 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2.  30.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -3.0 

action type: buy - action 0.0
Learning step: -0.15739546716213226
desired expected reward: 21.89956283569336






Player: 1 
cards in hand: [10.  0.  0. 14.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 14.  1.] 
cards in discard: [ 0. 10.  0.  0.  0.  8.  0. 11. 11. 10.  0. 11.  6.  8. 11. 10.  1.  8.
  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10  0  6  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 26. 30.  8.  4.  8.  3.  3.  9. 10.  7. 10.  5. 10. 10.] 
adversary cards in hand: [1. 8. 0. 0. 6.] 
adversary cards in discard: [ 0. 11.  0.  1.  3.  3.  0.  3.  6.  0.  3. 11. 14. 14.  6.  8.  1. 16.
  3. 25.  0.  6.  0.  8.  3.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0] -> size -> 34 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1. 14. 16.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  1. 16.] 
cards in discard: [ 0. 10.  0.  0.  0.  8.  0. 11. 11. 10.  0. 11.  6.  8. 11. 10.  1.  8.
  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10  0  6  8] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 26. 30.  8.  4.  8.  3.  3.  9. 10.  7. 10.  5. 10. 10.] 
adversary cards in hand: [1. 8. 0. 0. 6.] 
adversary cards in discard: [ 0. 11.  0.  1.  3.  3.  0.  3.  6.  0.  3. 11. 14. 14.  6.  8.  1. 16.
  3. 25.  0.  6.  0.  8.  3.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0] -> size -> 34 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 16.] 
cards in discard: [ 0. 10.  0.  0.  0.  8.  0. 11. 11. 10.  0. 11.  6.  8. 11. 10.  1.  8.
  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10  0  6  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 2 
card supply: [19. 25. 30. 26. 30.  8.  4.  8.  3.  3.  9. 10.  7. 10.  5. 10. 10.] 
adversary cards in hand: [1. 8. 0.] 
adversary cards in discard: [ 0. 11.  0.  1.  3.  3.  0.  3.  6.  0.  3. 11. 14. 14.  6.  8.  1. 16.
  3. 25.  0.  6.  0.  8.  3.  0. 11.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0] -> size -> 34 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1. 16.] 
cards in discard: [ 0. 10.  0.  0.  0.  8.  0. 11. 11. 10.  0. 11.  6.  8. 11. 10.  1.  8.
  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10  0  6  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 6 
card supply: [19. 25. 30. 26. 30.  8.  4.  8.  3.  3.  9. 10.  7. 10.  5. 10. 10.] 
adversary cards in hand: [1. 8. 0.] 
adversary cards in discard: [ 0. 11.  0.  1.  3.  3.  0.  3.  6.  0.  3. 11. 14. 14.  6.  8.  1. 16.
  3. 25.  0.  6.  0.  8.  3.  0. 11.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0] -> size -> 34 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1. 16.] 
cards in discard: [ 0. 10.  0.  0.  0.  8.  0. 11. 11. 10.  0. 11.  6.  8. 11. 10.  1.  8.
  6. 22.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10  0  6  8 22] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 25. 30. 26. 30.  8.  4.  8.  3.  3.  9. 10.  7. 10.  5.  9. 10.] 
adversary cards in hand: [1. 8. 0.] 
adversary cards in discard: [ 0. 11.  0.  1.  3.  3.  0.  3.  6.  0.  3. 11. 14. 14.  6.  8.  1. 16.
  3. 25.  0.  6.  0.  8.  3.  0. 11.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0] -> size -> 34 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [1. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[14.141062 ]
 [ 7.7381635]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 0.] 
cards in discard: [ 0. 11.  0.  1.  3.  3.  0.  3.  6.  0.  3. 11. 14. 14.  6.  8.  1. 16.
  3. 25.  0.  6.  0.  8.  3.  0. 11.  0.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 26. 30.  8.  4.  8.  3.  3.  9. 10.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10  0  6  8 22] -> size -> 29 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[  -5    0    2   30    0    0    0  -60    0    0    0    0    0 -600
   70    0] 
sum of rewards: -563 

action type: discard_down_to_3_cards - action 3
Learning step: -29.362136840820312
desired expected reward: -0.14391708374023438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ -7.0887647]
 [  9.993084 ]
 [  1.9608564]
 [-29.530012 ]
 [ 14.983402 ]
 [  5.8082767]
 [ -1.4725016]
 [ 13.312586 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8. 0.] 
cards in discard: [ 0. 11.  0.  1.  3.  3.  0.  3.  6.  0.  3. 11. 14. 14.  6.  8.  1. 16.
  3. 25.  0.  6.  0.  8.  3.  0. 11.  0.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 25. 30. 26. 30.  8.  4.  8.  3.  3.  9. 10.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10  0  6  8 22] -> size -> 29 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: take_action - action -1.0
Learning step: 0.6768472790718079
desired expected reward: 14.817890167236328



buy possibilites: [-1] 
expected returns: [[-9.965929]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8. 0.] 
cards in discard: [ 0. 11.  0.  1.  3.  3.  0.  3.  6.  0.  3. 11. 14. 14.  6.  8.  1. 16.
  3. 25.  0.  6.  0.  8.  3.  0. 11.  0.  0.  6. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 26. 30.  8.  4.  8.  2.  3.  9. 10.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10  0  6  8 22] -> size -> 29 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 45 

action type: buy - action 11.0
Learning step: 1.2765965461730957
desired expected reward: 16.25999641418457






Player: 1 
cards in hand: [ 0.  0.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  3.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10  0  6  8 22] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 26. 30.  8.  4.  8.  2.  3.  9. 10.  7. 10.  5.  9. 10.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0 11] -> size -> 35 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  3.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10  0  6  8 22] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 25. 30. 26. 30.  8.  4.  8.  2.  3.  9. 10.  7. 10.  5.  9. 10.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0 11] -> size -> 35 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  3.] 
cards in discard: [1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10  0  6  8 22  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 26. 30.  8.  4.  8.  2.  3.  9. 10.  7. 10.  5.  9. 10.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0 11] -> size -> 35 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [11.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[13.213001]
 [11.611578]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 26. 30.  8.  4.  8.  2.  3.  9. 10.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 6. 16. 10. 10. 11.] 
adversary cards in discard: [ 1.  0.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10  0  6  8 22  1] -> size -> 30 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: buy - action -1
Learning step: 2.1282308101654053
desired expected reward: -7.837697982788086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 7.932836 ]
 [10.866793 ]
 [10.325872 ]
 [ 2.6060538]
 [ 9.073669 ]
 [13.918243 ]
 [ 9.8089695]
 [ 9.566368 ]
 [ 5.6678977]
 [ 9.853821 ]
 [ 8.406361 ]
 [15.711693 ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0 11] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 24. 30. 26. 30.  8.  4.  8.  2.  3.  9. 10.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 6. 16. 10. 10. 11.] 
adversary cards in discard: [ 1.  0.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10  0  6  8 22  1] -> size -> 30 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: take_action - action -1.0
Learning step: 0.9077314734458923
desired expected reward: 14.12073040008545



buy possibilites: [-1] 
expected returns: [[13.256615]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [16.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0 11 16] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 26. 30.  8.  4.  7.  2.  3.  9. 10.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 6. 16. 10. 10. 11.] 
adversary cards in discard: [ 1.  0.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10  0  6  8 22  1] -> size -> 30 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0  0  0  0  0  0 -1  0  0 32  0] 
sum of rewards: 58 

action type: buy - action 16.0
Learning step: 2.7445905208587646
desired expected reward: 11.818262100219727






Player: 1 
cards in hand: [ 6. 16. 10. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10. 10. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 16. 10. 10. 11.] 
cards in discard: [ 1.  0.  0.  0. 10.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10  0  6  8 22  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 26. 30.  8.  4.  7.  2.  3.  9. 10.  7. 10.  5.  9. 10.] 
adversary cards in hand: [11.  8.  0. 25.  0.] 
adversary cards in discard: [16. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0 11 16] -> size -> 36 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 16. 10. 10.] 
cards in discard: [ 1.  0.  0.  0. 10.  3.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10  0  6  8 22  1  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 26. 30.  8.  4.  7.  2.  2.  9. 10.  7. 10.  5.  9. 10.] 
adversary cards in hand: [11.  8.  0. 25.  0.] 
adversary cards in discard: [16. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0 11 16] -> size -> 36 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 16. 10. 10.] 
cards in discard: [ 1.  0.  0.  0. 10.  3.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10  0  6  8 22  1  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 24. 30. 26. 30.  8.  4.  7.  2.  2.  9. 10.  7. 10.  5.  9. 10.] 
adversary cards in hand: [11.  8.  0. 25.  0.] 
adversary cards in discard: [16. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0 11 16] -> size -> 36 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 16. 10. 10.] 
cards in discard: [ 1.  0.  0.  0. 10.  3.  8.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10  0  6  8 22  1  8  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 26. 30.  8.  4.  7.  2.  2.  9. 10.  7. 10.  5.  9. 10.] 
adversary cards in hand: [11.  8.  0. 25.  0.] 
adversary cards in discard: [16. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0 11 16] -> size -> 36 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [11.  8.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 25.] 
expected returns: [[57.651524]
 [57.772568]
 [51.209824]
 [63.23589 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0. 25.  0.] 
cards in discard: [16. 11.  0.  0.  0.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0 11 16] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 26. 30.  8.  4.  7.  2.  2.  9. 10.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 0. 14.  1.  6. 10.] 
adversary cards in discard: [ 1.  0.  0.  0. 10.  3.  8.  0. 11.  6. 16. 10. 10.] 
adversary owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10  0  6  8 22  1  8  0] -> size -> 32 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: buy - action -1
Learning step: 1.984926462173462
desired expected reward: 15.241540908813477



action possibilites: [-1] 
expected returns: [[55.107315]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 25.  0.] 
cards in discard: [16. 11.  0.  0.  0.  0.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0 11 16  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 26. 30.  8.  4.  7.  2.  2.  9. 10.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 0. 14.  1.  6. 10.] 
adversary cards in discard: [ 1.  0.  0.  0. 10.  3.  8.  0. 11.  6. 16. 10. 10.] 
adversary owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10  0  6  8 22  1  8  0] -> size -> 32 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0 20  0  0  0  0 -2  0  0  9  0] 
sum of rewards: 54 

action type: gain_card_n - action 1
Learning step: 1.2864760160446167
desired expected reward: 55.00715255737305





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[41.64476 ]
 [45.165398]
 [32.452442]
 [45.092903]
 [51.551086]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 25.  0.] 
cards in discard: [16. 11.  0.  0.  0.  0.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0 11 16  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 23. 30. 26. 30.  8.  4.  7.  2.  2.  9. 10.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 0. 14.  1.  6. 10.] 
adversary cards in discard: [ 1.  0.  0.  0. 10.  3.  8.  0. 11.  6. 16. 10. 10.] 
adversary owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10  0  6  8 22  1  8  0] -> size -> 32 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 47 

action type: take_action - action -1
Learning step: 0.5730907320976257
desired expected reward: 55.68040466308594



buy possibilites: [-1] 
expected returns: [[14.081605]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 25.  0.] 
cards in discard: [16. 11.  0.  0.  0.  0.  1.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0 11 16  1  6] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 23. 30. 26. 30.  8.  3.  7.  2.  2.  9. 10.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 0. 14.  1.  6. 10.] 
adversary cards in discard: [ 1.  0.  0.  0. 10.  3.  8.  0. 11.  6. 16. 10. 10.] 
adversary owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10  0  6  8 22  1  8  0] -> size -> 32 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.   20.    0.    0.   20.    0.    0.    0.    0.   -3.
    0. -300.    0.    0.] 
sum of rewards: -267.0 

action type: buy - action 6.0
Learning step: -14.655786514282227
desired expected reward: 17.796659469604492






Player: 1 
cards in hand: [ 0. 14.  1.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  1.  6. 10.] 
cards in discard: [ 1.  0.  0.  0. 10.  3.  8.  0. 11.  6. 16. 10. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10  0  6  8 22  1  8  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 26. 30.  8.  3.  7.  2.  2.  9. 10.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 1. 14.  6.  0.  1.] 
adversary cards in discard: [16. 11.  0.  0.  0.  0.  1.  6. 11.  8.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0 11 16  1  6] -> size -> 38 
adversary victory points: 1
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  6. 10.] 
cards in discard: [ 1.  0.  0.  0. 10.  3.  8.  0. 11.  6. 16. 10. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10  0  6  8 22  1  8  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 23. 30. 26. 30.  8.  3.  7.  2.  2.  9. 10.  7. 10.  5.  9. 10.] 
adversary cards in hand: [6. 0. 1.] 
adversary cards in discard: [16. 11.  0.  0.  0.  0.  1.  6. 11.  8.  0. 25.  0.  1. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0 11 16  1  6] -> size -> 38 
adversary victory points: 1
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  6. 10.] 
cards in discard: [ 1.  0.  0.  0. 10.  3.  8.  0. 11.  6. 16. 10. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10  0  6  8 22  1  8  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 5 
card supply: [18. 23. 30. 26. 30.  8.  3.  7.  2.  2.  9. 10.  7. 10.  5.  9. 10.] 
adversary cards in hand: [6. 0. 1.] 
adversary cards in discard: [16. 11.  0.  0.  0.  0.  1.  6. 11.  8.  0. 25.  0.  1. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0 11 16  1  6] -> size -> 38 
adversary victory points: 1
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  6. 10.] 
cards in discard: [ 1.  0.  0.  0. 10.  3.  8.  0. 11.  6. 16. 10. 10. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10  0  6  8 22  1  8  0 29] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 23. 30. 26. 30.  8.  3.  7.  2.  2.  9.  9.  7. 10.  5.  9. 10.] 
adversary cards in hand: [6. 0. 1.] 
adversary cards in discard: [16. 11.  0.  0.  0.  0.  1.  6. 11.  8.  0. 25.  0.  1. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0 11 16  1  6] -> size -> 38 
adversary victory points: 1
player victory points: -1 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [6. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[23.564478]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 1.] 
cards in discard: [16. 11.  0.  0.  0.  0.  1.  6. 11.  8.  0. 25.  0.  1. 14.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0 11 16  1  6] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 26. 30.  8.  3.  7.  2.  2.  9.  9.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 0.  8.  1.  0. 22.] 
adversary cards in discard: [ 1.  0.  0.  0. 10.  3.  8.  0. 11.  6. 16. 10. 10. 29. 14.  0.  1.  6.
 10.] 
adversary owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10  0  6  8 22  1  8  0 29] -> size -> 33 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[  -5    0    1   20    0    0    0  -30    0    0    0   -3    0 -900
   86    0] 
sum of rewards: -831 

action type: discard_down_to_3_cards - action 4
Learning step: -41.97723388671875
desired expected reward: -22.828550338745117





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[15.568013]
 [22.104128]
 [18.3412  ]
 [ 7.243704]
 [24.721779]
 [20.817238]
 [17.581644]
 [23.833714]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1.] 
cards in discard: [16. 11.  0.  0.  0.  0.  1.  6. 11.  8.  0. 25.  0.  1. 14.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0 11 16  1  6] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 23. 30. 26. 30.  8.  3.  7.  2.  2.  9.  9.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 0.  8.  1.  0. 22.] 
adversary cards in discard: [ 1.  0.  0.  0. 10.  3.  8.  0. 11.  6. 16. 10. 10. 29. 14.  0.  1.  6.
 10.] 
adversary owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10  0  6  8 22  1  8  0 29] -> size -> 33 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  1 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: take_action - action -1.0
Learning step: 0.04913053661584854
desired expected reward: 23.613609313964844



buy possibilites: [-1] 
expected returns: [[28.924047]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1.] 
cards in discard: [16. 11.  0.  0.  0.  0.  1.  6. 11.  8.  0. 25.  0.  1. 14. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0 11 16  1  6 11] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 26. 30.  8.  3.  7.  1.  2.  9.  9.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 0.  8.  1.  0. 22.] 
adversary cards in discard: [ 1.  0.  0.  0. 10.  3.  8.  0. 11.  6. 16. 10. 10. 29. 14.  0.  1.  6.
 10.] 
adversary owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10  0  6  8 22  1  8  0 29] -> size -> 33 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  1 20  0  0  0  0  0  0  0 -4  0  0 18  0] 
sum of rewards: 30 

action type: buy - action 11.0
Learning step: 0.9147030711174011
desired expected reward: 25.636465072631836






Player: 1 
cards in hand: [ 0.  8.  1.  0. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  1.  0. 22.] 
cards in discard: [ 1.  0.  0.  0. 10.  3.  8.  0. 11.  6. 16. 10. 10. 29. 14.  0.  1.  6.
 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11
 10  0  6  8 22  1  8  0 29] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 26. 30.  8.  3.  7.  1.  2.  9.  9.  7. 10.  5.  9. 10.] 
adversary cards in hand: [3. 3. 0. 6. 0.] 
adversary cards in discard: [16. 11.  0.  0.  0.  0.  1.  6. 11.  8.  0. 25.  0.  1. 14. 11.  6.  0.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0 11 16  1  6 11] -> size -> 39 
adversary victory points: 1
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 22.] 
cards in discard: [ 1.  0.  0.  0. 10.  3.  8.  0. 11.  6. 16. 10. 10. 29. 14.  0.  1.  6.
 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10
  0  6  8 22  1  8  0 29] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 26. 30.  8.  3.  7.  1.  2.  9.  9.  7. 10.  5.  9. 10.] 
adversary cards in hand: [3. 3. 0. 6. 0.] 
adversary cards in discard: [16. 11.  0.  0.  0.  0.  1.  6. 11.  8.  0. 25.  0.  1. 14. 11.  6.  0.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0 11 16  1  6 11] -> size -> 39 
adversary victory points: 1
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 22.] 
cards in discard: [ 1.  0.  0.  0. 10.  3.  8.  0. 11.  6. 16. 10. 10. 29. 14.  0.  1.  6.
 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10
  0  6  8 22  1  8  0 29] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 23. 30. 26. 30.  8.  3.  7.  1.  2.  9.  9.  7. 10.  5.  9. 10.] 
adversary cards in hand: [3. 3. 0. 6. 0.] 
adversary cards in discard: [16. 11.  0.  0.  0.  0.  1.  6. 11.  8.  0. 25.  0.  1. 14. 11.  6.  0.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0 11 16  1  6 11] -> size -> 39 
adversary victory points: 1
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 22.] 
cards in discard: [ 1.  0.  0.  0. 10.  3.  8.  0. 11.  6. 16. 10. 10. 29. 14.  0.  1.  6.
 10.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10
  0  6  8 22  1  8  0 29  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 26. 30.  8.  3.  7.  1.  2.  9.  9.  7. 10.  5.  9. 10.] 
adversary cards in hand: [3. 3. 0. 6. 0.] 
adversary cards in discard: [16. 11.  0.  0.  0.  0.  1.  6. 11.  8.  0. 25.  0.  1. 14. 11.  6.  0.
  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0 11 16  1  6 11] -> size -> 39 
adversary victory points: 1
player victory points: -1 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[4.547353]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 6. 0.] 
cards in discard: [16. 11.  0.  0.  0.  0.  1.  6. 11.  8.  0. 25.  0.  1. 14. 11.  6.  0.
  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0 11 16  1  6 11] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 26. 30.  8.  3.  7.  1.  2.  9.  9.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 0.  0.  8. 11.  0.] 
adversary cards in discard: [ 1.  0.  0.  0. 10.  3.  8.  0. 11.  6. 16. 10. 10. 29. 14.  0.  1.  6.
 10.  1.  8.  1.  0. 22.] 
adversary owned cards: [ 0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10
  0  6  8 22  1  8  0 29  1] -> size -> 33 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  1 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: buy - action -1
Learning step: -0.5438869595527649
desired expected reward: 28.38016128540039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 0.02458215]
 [ 0.8979709 ]
 [-3.9844966 ]
 [ 0.8505728 ]
 [ 2.211838  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 6. 0.] 
cards in discard: [16. 11.  0.  0.  0.  0.  1.  6. 11.  8.  0. 25.  0.  1. 14. 11.  6.  0.
  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0 11 16  1  6 11] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 22. 30. 26. 30.  8.  3.  7.  1.  2.  9.  9.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 0.  0.  8. 11.  0.] 
adversary cards in discard: [ 1.  0.  0.  0. 10.  3.  8.  0. 11.  6. 16. 10. 10. 29. 14.  0.  1.  6.
 10.  1.  8.  1.  0. 22.] 
adversary owned cards: [ 0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10
  0  6  8 22  1  8  0 29  1] -> size -> 33 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  1 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: take_action - action -1.0
Learning step: 0.5744516849517822
desired expected reward: 5.121804237365723



buy possibilites: [-1] 
expected returns: [[-1.1213887]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 6. 0.] 
cards in discard: [16. 11.  0.  0.  0.  0.  1.  6. 11.  8.  0. 25.  0.  1. 14. 11.  6.  0.
  1.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 22. 30. 26. 30.  8.  3.  7.  1.  2.  9.  9.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 0.  0.  8. 11.  0.] 
adversary cards in discard: [ 1.  0.  0.  0. 10.  3.  8.  0. 11.  6. 16. 10. 10. 29. 14.  0.  1.  6.
 10.  1.  8.  1.  0. 22.] 
adversary owned cards: [ 0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10
  0  6  8 22  1  8  0 29  1] -> size -> 33 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1.  20.   0.   0.   0. -30.   0.   0.   0.  -5.   0.   0.
   0.   0.] 
sum of rewards: -19.0 

action type: buy - action 0.0
Learning step: -0.9764599800109863
desired expected reward: -0.9518857002258301






Player: 1 
cards in hand: [ 0.  0.  8. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 11.  0.] 
cards in discard: [ 1.  0.  0.  0. 10.  3.  8.  0. 11.  6. 16. 10. 10. 29. 14.  0.  1.  6.
 10.  1.  8.  1.  0. 22.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10
  0  6  8 22  1  8  0 29  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 22. 30. 26. 30.  8.  3.  7.  1.  2.  9.  9.  7. 10.  5.  9. 10.] 
adversary cards in hand: [3. 8. 0. 6. 6.] 
adversary cards in discard: [16. 11.  0.  0.  0.  0.  1.  6. 11.  8.  0. 25.  0.  1. 14. 11.  6.  0.
  1.  0.  3.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0] -> size -> 40 
adversary victory points: 1
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 1.  0.  0.  0. 10.  3.  8.  0. 11.  6. 16. 10. 10. 29. 14.  0.  1.  6.
 10.  1.  8.  1.  0. 22.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8
 22  1  8  0 29  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 22. 30. 26. 30.  8.  3.  7.  1.  2.  9.  9.  7. 10.  5.  9. 10.] 
adversary cards in hand: [3. 8. 0. 6. 6.] 
adversary cards in discard: [16. 11.  0.  0.  0.  0.  1.  6. 11.  8.  0. 25.  0.  1. 14. 11.  6.  0.
  1.  0.  3.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0] -> size -> 40 
adversary victory points: 1
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 1.  0.  0.  0. 10.  3.  8.  0. 11.  6. 16. 10. 10. 29. 14.  0.  1.  6.
 10.  1.  8.  1.  0. 22.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8
 22  1  8  0 29  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 22. 30. 26. 30.  8.  3.  7.  1.  2.  9.  9.  7. 10.  5.  9. 10.] 
adversary cards in hand: [3. 8. 0. 6. 6.] 
adversary cards in discard: [16. 11.  0.  0.  0.  0.  1.  6. 11.  8.  0. 25.  0.  1. 14. 11.  6.  0.
  1.  0.  3.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0] -> size -> 40 
adversary victory points: 1
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 1.  0.  0.  0. 10.  3.  8.  0. 11.  6. 16. 10. 10. 29. 14.  0.  1.  6.
 10.  1.  8.  1.  0. 22.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8
 22  1  8  0 29  1  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 22. 30. 26. 30.  8.  3.  7.  1.  2.  9.  9.  7. 10.  5.  9. 10.] 
adversary cards in hand: [3. 8. 0. 6. 6.] 
adversary cards in discard: [16. 11.  0.  0.  0.  0.  1.  6. 11.  8.  0. 25.  0.  1. 14. 11.  6.  0.
  1.  0.  3.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0] -> size -> 40 
adversary victory points: 1
player victory points: -1 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [3. 8. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[ -6.3627934]
 [-11.368724 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 6. 6.] 
cards in discard: [16. 11.  0.  0.  0.  0.  1.  6. 11.  8.  0. 25.  0.  1. 14. 11.  6.  0.
  1.  0.  3.  3.  0.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 22. 30. 26. 30.  8.  3.  7.  1.  2.  9.  9.  7. 10.  5.  9. 10.] 
adversary cards in hand: [16.  8. 10. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8
 22  1  8  0 29  1  0] -> size -> 31 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  1 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: buy - action -1
Learning step: 0.6586463451385498
desired expected reward: -0.46274232864379883





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-11.360825]
 [-16.26063 ]
 [ -5.26427 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 6. 6.] 
cards in discard: [16. 11.  0.  0.  0.  0.  1.  6. 11.  8.  0. 25.  0.  1. 14. 11.  6.  0.
  1.  0.  3.  3.  0.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 22. 30. 26. 30.  8.  3.  7.  1.  2.  9.  9.  7. 10.  5.  9. 10.] 
adversary cards in hand: [16.  8. 10. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8
 22  1  8  0 29  1  0] -> size -> 31 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  1 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: take_action - action -1.0
Learning step: 0.8761779069900513
desired expected reward: -5.4866132736206055



buy possibilites: [-1] 
expected returns: [[5.2577944]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 6. 6.] 
cards in discard: [16. 11.  0.  0.  0.  0.  1.  6. 11.  8.  0. 25.  0.  1. 14. 11.  6.  0.
  1.  0.  3.  3.  0.  6.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 22. 30. 26. 30.  8.  2.  7.  1.  2.  9.  9.  7. 10.  5.  9. 10.] 
adversary cards in hand: [16.  8. 10. 11. 11.] 
adversary cards in discard: [] 
adversary owned cards: [10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8
 22  1  8  0 29  1  0] -> size -> 31 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.   10.    0.    0.    0.    0.    0.    0.    0.   -6.
    0. -300.    0.    0.] 
sum of rewards: -301.0 

action type: buy - action 6.0
Learning step: -14.118669509887695
desired expected reward: -30.379289627075195






Player: 1 
cards in hand: [16.  8. 10. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 10. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8. 10. 11. 11.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8
 22  1  8  0 29  1  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 22. 30. 26. 30.  8.  2.  7.  1.  2.  9.  9.  7. 10.  5.  9. 10.] 
adversary cards in hand: [11.  1.  3. 16.  3.] 
adversary cards in discard: [16. 11.  0.  0.  0.  0.  1.  6. 11.  8.  0. 25.  0.  1. 14. 11.  6.  0.
  1.  0.  3.  3.  0.  6.  0.  6.  3.  8.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6] -> size -> 41 
adversary victory points: 0
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8. 10. 11.] 
cards in discard: [14.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8
 22  1  8  0 29  1  0 14] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 22. 30. 26. 30.  8.  2.  7.  1.  2.  9.  9.  6. 10.  5.  9. 10.] 
adversary cards in hand: [11.  1.  3. 16.  3.] 
adversary cards in discard: [16. 11.  0.  0.  0.  0.  1.  6. 11.  8.  0. 25.  0.  1. 14. 11.  6.  0.
  1.  0.  3.  3.  0.  6.  0.  6.  3.  8.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6] -> size -> 41 
adversary victory points: 0
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  8. 10. 11.] 
cards in discard: [14.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8
 22  1  8  0 29  1  0 14] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 22. 30. 26. 30.  8.  2.  7.  1.  2.  9.  9.  6. 10.  5.  9. 10.] 
adversary cards in hand: [11.  1.  3. 16.  3.] 
adversary cards in discard: [16. 11.  0.  0.  0.  0.  1.  6. 11.  8.  0. 25.  0.  1. 14. 11.  6.  0.
  1.  0.  3.  3.  0.  6.  0.  6.  3.  8.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6] -> size -> 41 
adversary victory points: 0
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  8. 10. 11.] 
cards in discard: [14.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8
 22  1  8  0 29  1  0 14  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 22. 30. 26. 30.  8.  2.  7.  1.  2.  9.  9.  6. 10.  5.  9. 10.] 
adversary cards in hand: [11.  1.  3. 16.  3.] 
adversary cards in discard: [16. 11.  0.  0.  0.  0.  1.  6. 11.  8.  0. 25.  0.  1. 14. 11.  6.  0.
  1.  0.  3.  3.  0.  6.  0.  6.  3.  8.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6] -> size -> 41 
adversary victory points: 0
player victory points: -1 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [11.  1.  3. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
expected returns: [[-2.1950874]
 [-2.717432 ]
 [-5.927286 ]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  3. 16.  3.] 
cards in discard: [16. 11.  0.  0.  0.  0.  1.  6. 11.  8.  0. 25.  0.  1. 14. 11.  6.  0.
  1.  0.  3.  3.  0.  6.  0.  6.  3.  8.  0.  6.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3
  6 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 22. 30. 26. 30.  8.  2.  7.  1.  2.  9.  9.  6. 10.  5.  9. 10.] 
adversary cards in hand: [ 0.  0. 22.  8.  0.] 
adversary cards in discard: [14.  0. 11. 16.  8. 10. 11.] 
adversary owned cards: [10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8
 22  1  8  0 29  1  0 14  0] -> size -> 33 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 5 

action type: buy - action -1
Learning step: -0.09302305430173874
desired expected reward: 5.164771556854248



action possibilites: [-1] 
expected returns: [[13.099926]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  3.] 
cards in discard: [16. 11.  0.  0.  0.  0.  1.  6. 11.  8.  0. 25.  0.  1. 14. 11.  6.  0.
  1.  0.  3.  3.  0.  6.  0.  6.  3.  8.  0.  6.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 22. 30. 26. 30.  8.  2.  7.  1.  2.  9.  9.  6. 10.  5.  9. 10.] 
adversary cards in hand: [ 0.  0. 22.  8.  0.] 
adversary cards in discard: [14.  0. 11. 16.  8. 10. 11.] 
adversary owned cards: [10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8
 22  1  8  0 29  1  0 14  0] -> size -> 33 
adversary victory points: -1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1   0   0   0  20 -30   0   0   0  -6   0   0   0   0] 
sum of rewards: -22 

action type: gain_card_n - action 0
Learning step: -1.9533214569091797
desired expected reward: 21.00429916381836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 7.891698 ]
 [10.044984 ]
 [ 5.8185387]
 [ 9.182166 ]
 [13.09992  ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  3.] 
cards in discard: [16. 11.  0.  0.  0.  0.  1.  6. 11.  8.  0. 25.  0.  1. 14. 11.  6.  0.
  1.  0.  3.  3.  0.  6.  0.  6.  3.  8.  0.  6.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 22. 30. 26. 30.  8.  2.  7.  1.  2.  9.  9.  6. 10.  5.  9. 10.] 
adversary cards in hand: [ 0.  0. 22.  8.  0.] 
adversary cards in discard: [14.  0. 11. 16.  8. 10. 11.] 
adversary owned cards: [10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8
 22  1  8  0 29  1  0 14  0] -> size -> 33 
adversary victory points: -1
player victory points: -1 

Reward from previous game state: 
[-5  0 -1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 14 

action type: take_action - action -1
Learning step: 0.2553696632385254
desired expected reward: 13.355295181274414



buy possibilites: [-1] 
expected returns: [[-1.424224]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  3.] 
cards in discard: [16. 11.  0.  0.  0.  0.  1.  6. 11.  8.  0. 25.  0.  1. 14. 11.  6.  0.
  1.  0.  3.  3.  0.  6.  0.  6.  3.  8.  0.  6.  6.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 22. 30. 26. 30.  8.  1.  7.  1.  2.  9.  9.  6. 10.  5.  9. 10.] 
adversary cards in hand: [ 0.  0. 22.  8.  0.] 
adversary cards in discard: [14.  0. 11. 16.  8. 10. 11.] 
adversary owned cards: [10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8
 22  1  8  0 29  1  0 14  0] -> size -> 33 
adversary victory points: -1
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2.  -10.    0.    0.   20.    0.    0.    0.    0.   -7.
    0. -300.    0.    0.] 
sum of rewards: -304.0 

action type: buy - action 6.0
Learning step: -15.522972106933594
desired expected reward: -9.704424858093262






Player: 1 
cards in hand: [ 0.  0. 22.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 22.  8.  0.] 
cards in discard: [14.  0. 11. 16.  8. 10. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8
 22  1  8  0 29  1  0 14  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 22. 30. 26. 30.  8.  1.  7.  1.  2.  9.  9.  6. 10.  5.  9. 10.] 
adversary cards in hand: [ 8. 14.  0.  3. 11.] 
adversary cards in discard: [16. 11.  0.  0.  0.  0.  1.  6. 11.  8.  0. 25.  0.  1. 14. 11.  6.  0.
  1.  0.  3.  3.  0.  6.  0.  6.  3.  8.  0.  6.  6.  0.  6. 16. 11.  1.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6] -> size -> 42 
adversary victory points: -2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 22.  8.  0.] 
cards in discard: [14.  0. 11. 16.  8. 10. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8
 22  1  8  0 29  1  0 14  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 22. 30. 26. 30.  8.  1.  7.  1.  2.  9.  9.  6. 10.  5.  9. 10.] 
adversary cards in hand: [ 8. 14.  0.  3. 11.] 
adversary cards in discard: [16. 11.  0.  0.  0.  0.  1.  6. 11.  8.  0. 25.  0.  1. 14. 11.  6.  0.
  1.  0.  3.  3.  0.  6.  0.  6.  3.  8.  0.  6.  6.  0.  6. 16. 11.  1.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6] -> size -> 42 
adversary victory points: -2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 22.  8.  0.] 
cards in discard: [14.  0. 11. 16.  8. 10. 11.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8
 22  1  8  0 29  1  0 14  0  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 22. 30. 26. 30.  8.  1.  7.  1.  1.  9.  9.  6. 10.  5.  9. 10.] 
adversary cards in hand: [ 8. 14.  0.  3. 11.] 
adversary cards in discard: [16. 11.  0.  0.  0.  0.  1.  6. 11.  8.  0. 25.  0.  1. 14. 11.  6.  0.
  1.  0.  3.  3.  0.  6.  0.  6.  3.  8.  0.  6.  6.  0.  6. 16. 11.  1.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6] -> size -> 42 
adversary victory points: -2
player victory points: -1 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [ 8. 14.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 11.] 
expected returns: [[36.893204]
 [34.007275]
 [23.934965]
 [38.16231 ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  0.  3. 11.] 
cards in discard: [16. 11.  0.  0.  0.  0.  1.  6. 11.  8.  0. 25.  0.  1. 14. 11.  6.  0.
  1.  0.  3.  3.  0.  6.  0.  6.  3.  8.  0.  6.  6.  0.  6. 16. 11.  1.
  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 22. 30. 26. 30.  8.  1.  7.  1.  1.  9.  9.  6. 10.  5.  9. 10.] 
adversary cards in hand: [ 8. 10. 29.  0. 10.] 
adversary cards in discard: [14.  0. 11. 16.  8. 10. 11.  8.  0.  0. 22.  8.  0.] 
adversary owned cards: [10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8
 22  1  8  0 29  1  0 14  0  8] -> size -> 34 
adversary victory points: -1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: buy - action -1
Learning step: -0.02663988433778286
desired expected reward: -1.4508639574050903



action possibilites: [-1] 
expected returns: [[-4.007944]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3. 11.] 
cards in discard: [16. 11.  0.  0.  0.  0.  1.  6. 11.  8.  0. 25.  0.  1. 14. 11.  6.  0.
  1.  0.  3.  3.  0.  6.  0.  6.  3.  8.  0.  6.  6.  0.  6. 16. 11.  1.
  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 22. 30. 26. 30.  8.  1.  7.  1.  1.  9.  9.  6. 10.  5.  9. 10.] 
adversary cards in hand: [ 8. 10. 10.] 
adversary cards in discard: [14.  0. 11. 16.  8. 10. 11.  8.  0.  0. 22.  8.  0. 29.  0.] 
adversary owned cards: [10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8
 22  1  8  0 29  1  0 14  0  8] -> size -> 34 
adversary victory points: -1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 3 

action type: take_action - action 14.0
Learning step: -1.1369270086288452
desired expected reward: 22.798036575317383





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-4.9942865]
 [-3.1409092]
 [-3.736132 ]
 [-7.314578 ]
 [-2.9279008]
 [-3.957801 ]
 [-4.754511 ]
 [-4.007936 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3. 11.] 
cards in discard: [16. 11.  0.  0.  0.  0.  1.  6. 11.  8.  0. 25.  0.  1. 14. 11.  6.  0.
  1.  0.  3.  3.  0.  6.  0.  6.  3.  8.  0.  6.  6.  0.  6. 16. 11.  1.
  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 22. 30. 26. 30.  8.  1.  7.  1.  1.  9.  9.  6. 10.  5.  9. 10.] 
adversary cards in hand: [ 8. 10. 10.] 
adversary cards in discard: [14.  0. 11. 16.  8. 10. 11.  8.  0.  0. 22.  8.  0. 29.  0.] 
adversary owned cards: [10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8
 22  1  8  0 29  1  0 14  0  8] -> size -> 34 
adversary victory points: -1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 3 

action type: take_action - action -1
Learning step: 0.2535983622074127
desired expected reward: -3.754345655441284






Player: 1 
cards in hand: [ 8. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 10.] 
cards in discard: [14.  0. 11. 16.  8. 10. 11.  8.  0.  0. 22.  8.  0. 29.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8
 22  1  8  0 29  1  0 14  0  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 22. 30. 26. 30.  8.  1.  7.  1.  1.  9.  9.  6. 10.  5.  9. 10.] 
adversary cards in hand: [14.  3.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6] -> size -> 42 
adversary victory points: -2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 10.] 
cards in discard: [14.  0. 11. 16.  8. 10. 11.  8.  0.  0. 22.  8.  0. 29.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8
 22  1  8  0 29  1  0 14  0  8] -> size -> 34 
action values: 1 
buys: 1 
player value: 0 
card supply: [14. 22. 30. 26. 30.  8.  1.  7.  1.  1.  9.  9.  6. 10.  5.  9. 10.] 
adversary cards in hand: [14.  3.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6] -> size -> 42 
adversary victory points: -2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10. 10.] 
cards in discard: [14.  0. 11. 16.  8. 10. 11.  8.  0.  0. 22.  8.  0. 29.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8
 22  1  8  0 29  1  0 14  0  8  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 22. 30. 26. 30.  8.  1.  7.  1.  1.  9.  9.  6. 10.  5.  9. 10.] 
adversary cards in hand: [14.  3.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6] -> size -> 42 
adversary victory points: -2
player victory points: -1 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [14.  3.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[19.553797]
 [13.135023]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 22. 30. 26. 30.  8.  1.  7.  1.  1.  9.  9.  6. 10.  5.  9. 10.] 
adversary cards in hand: [1. 1. 0. 8. 6.] 
adversary cards in discard: [14.  0. 11. 16.  8. 10. 11.  8.  0.  0. 22.  8.  0. 29.  0.  0.  8. 10.
 10.] 
adversary owned cards: [10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8
 22  1  8  0 29  1  0 14  0  8  0] -> size -> 35 
adversary victory points: -1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: buy - action -1.0
Learning step: -0.2792166769504547
desired expected reward: -4.287160873413086



action possibilites: [-1] 
expected returns: [[20.26149]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 22. 30. 26. 30.  8.  1.  7.  1.  1.  9.  9.  6. 10.  5.  9. 10.] 
adversary cards in hand: [0. 8. 6.] 
adversary cards in discard: [14.  0. 11. 16.  8. 10. 11.  8.  0.  0. 22.  8.  0. 29.  0.  0.  8. 10.
 10.  1.  1.] 
adversary owned cards: [10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8
 22  1  8  0 29  1  0 14  0  8  0] -> size -> 35 
adversary victory points: -1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 3 

action type: take_action - action 14.0
Learning step: -0.05086774751543999
desired expected reward: 13.08415699005127





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[20.476873]
 [22.128   ]
 [21.19777 ]
 [12.829145]
 [21.038744]
 [22.854395]
 [21.787264]
 [21.561016]
 [16.425364]
 [21.150248]
 [20.301788]
 [22.895721]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6] -> size -> 42 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 22. 30. 26. 30.  8.  1.  7.  1.  1.  9.  9.  6. 10.  5.  9. 10.] 
adversary cards in hand: [0. 8. 6.] 
adversary cards in discard: [14.  0. 11. 16.  8. 10. 11.  8.  0.  0. 22.  8.  0. 29.  0.  0.  8. 10.
 10.  1.  1.] 
adversary owned cards: [10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8
 22  1  8  0 29  1  0 14  0  8  0] -> size -> 35 
adversary victory points: -1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 3 

action type: take_action - action -1
Learning step: -0.402301549911499
desired expected reward: 19.859188079833984






Player: 1 
cards in hand: [0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6.] 
cards in discard: [14.  0. 11. 16.  8. 10. 11.  8.  0.  0. 22.  8.  0. 29.  0.  0.  8. 10.
 10.  1.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8
 22  1  8  0 29  1  0 14  0  8  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 22. 30. 26. 30.  8.  1.  7.  1.  1.  9.  9.  6. 10.  5.  9. 10.] 
adversary cards in hand: [ 0.  0.  0. 11. 11.] 
adversary cards in discard: [14.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6] -> size -> 42 
adversary victory points: -2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6.] 
cards in discard: [14.  0. 11. 16.  8. 10. 11.  8.  0.  0. 22.  8.  0. 29.  0.  0.  8. 10.
 10.  1.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8
 22  1  8  0 29  1  0 14  0  8  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 22. 30. 26. 30.  8.  1.  7.  1.  1.  9.  9.  6. 10.  5.  9. 10.] 
adversary cards in hand: [ 0.  0.  0. 11. 11.] 
adversary cards in discard: [14.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6] -> size -> 42 
adversary victory points: -2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6.] 
cards in discard: [14.  0. 11. 16.  8. 10. 11.  8.  0.  0. 22.  8.  0. 29.  0.  0.  8. 10.
 10.  1.  1.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8
 22  1  8  0 29  1  0 14  0  8  0  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 22. 30. 26. 30.  8.  1.  7.  1.  1.  9.  9.  6. 10.  5.  9. 10.] 
adversary cards in hand: [ 0.  0.  0. 11. 11.] 
adversary cards in discard: [14.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6] -> size -> 42 
adversary victory points: -2
player victory points: -1 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[11.201833]
 [ 9.377666]
 [ 9.377666]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11. 11.] 
cards in discard: [14.  3.  0.  3.  0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 26. 30.  8.  1.  7.  1.  1.  9.  9.  6. 10.  5.  9. 10.] 
adversary cards in hand: [ 1.  3. 14.  0.  1.] 
adversary cards in discard: [14.  0. 11. 16.  8. 10. 11.  8.  0.  0. 22.  8.  0. 29.  0.  0.  8. 10.
 10.  1.  1.  0.  0.  8.  6.] 
adversary owned cards: [10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8
 22  1  8  0 29  1  0 14  0  8  0  0] -> size -> 36 
adversary victory points: -1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: buy - action -1.0
Learning step: -1.7691081762313843
desired expected reward: 21.12661361694336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[  0.44052124]
 [  7.411625  ]
 [  6.232871  ]
 [-19.195541  ]
 [ 12.771538  ]
 [  3.9602077 ]
 [  3.7101085 ]
 [ 14.289339  ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11. 11.] 
cards in discard: [14.  3.  0.  3.  0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 22. 30. 26. 30.  8.  1.  7.  1.  1.  9.  9.  6. 10.  5.  9. 10.] 
adversary cards in hand: [ 1.  3. 14.  0.  1.] 
adversary cards in discard: [14.  0. 11. 16.  8. 10. 11.  8.  0.  0. 22.  8.  0. 29.  0.  0.  8. 10.
 10.  1.  1.  0.  0.  8.  6.] 
adversary owned cards: [10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8
 22  1  8  0 29  1  0 14  0  8  0  0] -> size -> 36 
adversary victory points: -1
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -17 

action type: take_action - action -1.0
Learning step: -1.318084955215454
desired expected reward: 9.883742332458496



buy possibilites: [-1] 
expected returns: [[12.871643]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11. 11.] 
cards in discard: [14.  3.  0.  3.  0.  3.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6  3] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 22. 30. 25. 30.  8.  1.  7.  1.  1.  9.  9.  6. 10.  5.  9. 10.] 
adversary cards in hand: [ 1.  3. 14.  0.  1.] 
adversary cards in discard: [14.  0. 11. 16.  8. 10. 11.  8.  0.  0. 22.  8.  0. 29.  0.  0.  8. 10.
 10.  1.  1.  0.  0.  8.  6.] 
adversary owned cards: [10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8
 22  1  8  0 29  1  0 14  0  8  0  0] -> size -> 36 
adversary victory points: -1
player victory points: -1 

Reward from previous game state: 
[-5.  0. -1.  0.  0.  0.  0.  0.  0.  0.  0. -8.  0.  0.  2.  0.] 
sum of rewards: -12.0 

action type: buy - action 3.0
Learning step: -0.6220306754112244
desired expected reward: 5.6108222007751465






Player: 1 
cards in hand: [ 1.  3. 14.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 14.  0.  1.] 
cards in discard: [14.  0. 11. 16.  8. 10. 11.  8.  0.  0. 22.  8.  0. 29.  0.  0.  8. 10.
 10.  1.  1.  0.  0.  8.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8
 22  1  8  0 29  1  0 14  0  8  0  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 25. 30.  8.  1.  7.  1.  1.  9.  9.  6. 10.  5.  9. 10.] 
adversary cards in hand: [16.  0.  1.  8.  0.] 
adversary cards in discard: [14.  3.  0.  3.  0.  3.  0.  0.  0. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6  3] -> size -> 43 
adversary victory points: -1
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 14.  0.  1.] 
cards in discard: [14.  0. 11. 16.  8. 10. 11.  8.  0.  0. 22.  8.  0. 29.  0.  0.  8. 10.
 10.  1.  1.  0.  0.  8.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8
 22  1  8  0 29  1  0 14  0  8  0  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 5 
card supply: [12. 22. 30. 25. 30.  8.  1.  7.  1.  1.  9.  9.  6. 10.  5.  9. 10.] 
adversary cards in hand: [16.  0.  1.  8.  0.] 
adversary cards in discard: [14.  3.  0.  3.  0.  3.  0.  0.  0. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6  3] -> size -> 43 
adversary victory points: -1
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 14.  0.  1.] 
cards in discard: [14.  0. 11. 16.  8. 10. 11.  8.  0.  0. 22.  8.  0. 29.  0.  0.  8. 10.
 10.  1.  1.  0.  0.  8.  6. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8
 22  1  8  0 29  1  0 14  0  8  0  0 11] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 22. 30. 25. 30.  8.  1.  7.  0.  1.  9.  9.  6. 10.  5.  9. 10.] 
adversary cards in hand: [16.  0.  1.  8.  0.] 
adversary cards in discard: [14.  3.  0.  3.  0.  3.  0.  0.  0. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6  3] -> size -> 43 
adversary victory points: -1
player victory points: -1 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [16.  0.  1.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
expected returns: [[70.400566]
 [64.00881 ]
 [65.58293 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  1.  8.  0.] 
cards in discard: [14.  3.  0.  3.  0.  3.  0.  0.  0. 11. 11.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 25. 30.  8.  1.  7.  0.  1.  9.  9.  6. 10.  5.  9. 10.] 
adversary cards in hand: [10. 10.  6. 11.  0.] 
adversary cards in discard: [14.  0. 11. 16.  8. 10. 11.  8.  0.  0. 22.  8.  0. 29.  0.  0.  8. 10.
 10.  1.  1.  0.  0.  8.  6. 11.  1.  3. 14.  0.  1.] 
adversary owned cards: [10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8
 22  1  8  0 29  1  0 14  0  8  0  0 11] -> size -> 37 
adversary victory points: -1
player victory points: -1 

Reward from previous game state: 
[-5  0 -1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -6 

action type: buy - action -1
Learning step: 0.5594302415847778
desired expected reward: 13.431073188781738





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[64.694405]
 [70.207664]
 [67.078224]
 [52.502415]
 [66.93954 ]
 [68.72536 ]
 [67.94421 ]
 [57.964264]
 [65.92166 ]
 [63.00311 ]
 [71.9505  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  1.  8.  0.] 
cards in discard: [14.  3.  0.  3.  0.  3.  0.  0.  0. 11. 11.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6  3] -> size -> 43 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 22. 30. 25. 30.  8.  1.  7.  0.  1.  9.  9.  6. 10.  5.  9. 10.] 
adversary cards in hand: [10. 10.  6. 11.  0.] 
adversary cards in discard: [14.  0. 11. 16.  8. 10. 11.  8.  0.  0. 22.  8.  0. 29.  0.  0.  8. 10.
 10.  1.  1.  0.  0.  8.  6. 11.  1.  3. 14.  0.  1.] 
adversary owned cards: [10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8
 22  1  8  0 29  1  0 14  0  8  0  0 11] -> size -> 37 
adversary victory points: -1
player victory points: -1 

Reward from previous game state: 
[-5  0 -1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -6 

action type: take_action - action -1.0
Learning step: -2.3480114936828613
desired expected reward: 68.05255126953125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10. 10.  6. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  6. 11.  0.] 
cards in discard: [14.  0. 11. 16.  8. 10. 11.  8.  0.  0. 22.  8.  0. 29.  0.  0.  8. 10.
 10.  1.  1.  0.  0.  8.  6. 11.  1.  3. 14.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8
 22  1  8  0 29  1  0 14  0  8  0  0 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 25. 30.  8.  1.  7.  0.  1.  9.  9.  6. 10.  5.  9. 10.] 
adversary cards in hand: [ 6.  3.  3. 16.  6.] 
adversary cards in discard: [14.  3.  0.  3.  0.  3.  0.  0.  0. 11. 11. 16.  0.  1.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6  3] -> size -> 43 
adversary victory points: -1
player victory points: -1 


action possibilites: [-1. 10. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6. 11.  0.  0.] 
cards in discard: [14.  0. 11. 16.  8. 10. 11.  8.  0.  0. 22.  8.  0. 29.  0.  0.  8. 10.
 10.  1.  1.  0.  0.  8.  6. 11.  1.  3. 14.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8
 22  1  8  0 29  1  0 14  0  8  0  0 11] -> size -> 37 
action values: 2 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 25. 30.  8.  1.  7.  0.  1.  9.  9.  6. 10.  5.  9. 10.] 
adversary cards in hand: [ 6.  3.  3. 16.  6.] 
adversary cards in discard: [14.  3.  0.  3.  0.  3.  0.  0.  0. 11. 11. 16.  0.  1.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6  3] -> size -> 43 
adversary victory points: -1
player victory points: -1 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8
 22  1  8  0 29  1  0 14  0  8  0  0 11] -> size -> 37 
action values: 3 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 25. 30.  8.  1.  7.  0.  1.  9.  9.  6. 10.  5.  9. 10.] 
adversary cards in hand: [ 6.  3.  3. 16.  6.] 
adversary cards in discard: [14.  3.  0.  3.  0.  3.  0.  0.  0. 11. 11. 16.  0.  1.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6  3] -> size -> 43 
adversary victory points: -1
player victory points: -1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [16.] 
cards in deck: 30 
card top of deck: [] 
played cards: [10. 10. 11.] 
owned cards: [10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8
 22  1  8  0 29  1  0 14  0  8  0  0 11 16] -> size -> 38 
action values: 2 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 25. 30.  8.  1.  6.  0.  1.  9.  9.  6. 10.  5.  9. 10.] 
adversary cards in hand: [ 6.  3.  3. 16.  6.] 
adversary cards in discard: [14.  3.  0.  3.  0.  3.  0.  0.  0. 11. 11. 16.  0.  1.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6  3] -> size -> 43 
adversary victory points: -1
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [16.] 
cards in deck: 30 
card top of deck: [] 
played cards: [10. 10. 11.] 
owned cards: [10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8
 22  1  8  0 29  1  0 14  0  8  0  0 11 16] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 22. 30. 25. 30.  8.  1.  6.  0.  1.  9.  9.  6. 10.  5.  9. 10.] 
adversary cards in hand: [ 6.  3.  3. 16.  6.] 
adversary cards in discard: [14.  3.  0.  3.  0.  3.  0.  0.  0. 11. 11. 16.  0.  1.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6  3] -> size -> 43 
adversary victory points: -1
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [16.  1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [10. 10. 11.] 
owned cards: [10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8
 22  1  8  0 29  1  0 14  0  8  0  0 11 16  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 25. 30.  8.  1.  6.  0.  1.  9.  9.  6. 10.  5.  9. 10.] 
adversary cards in hand: [ 6.  3.  3. 16.  6.] 
adversary cards in discard: [14.  3.  0.  3.  0.  3.  0.  0.  0. 11. 11. 16.  0.  1.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6  3] -> size -> 43 
adversary victory points: -1
player victory points: -1 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 6.  3.  3. 16.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[27.840034]
 [24.576277]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  3. 16.  6.] 
cards in discard: [14.  3.  0.  3.  0.  3.  0.  0.  0. 11. 11. 16.  0.  1.  8.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 25. 30.  8.  1.  6.  0.  1.  9.  9.  6. 10.  5.  9. 10.] 
adversary cards in hand: [16. 29.  8.  8.  0.] 
adversary cards in discard: [16.  1. 10. 10. 11.  6.  0.  0.  0.] 
adversary owned cards: [10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8
 22  1  8  0 29  1  0 14  0  8  0  0 11 16  1] -> size -> 39 
adversary victory points: -1
player victory points: -1 

Reward from previous game state: 
[-5  0 -1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -6 

action type: buy - action -1.0
Learning step: -3.306500196456909
desired expected reward: 68.64398956298828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[22.981073]
 [14.76543 ]
 [27.875835]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  3. 16.  6.] 
cards in discard: [14.  3.  0.  3.  0.  3.  0.  0.  0. 11. 11. 16.  0.  1.  8.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6  3] -> size -> 43 
action values: 1 
buys: 1 
player value: 0 
card supply: [12. 21. 30. 25. 30.  8.  1.  6.  0.  1.  9.  9.  6. 10.  5.  9. 10.] 
adversary cards in hand: [16. 29.  8.  8.  0.] 
adversary cards in discard: [16.  1. 10. 10. 11.  6.  0.  0.  0.] 
adversary owned cards: [10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8
 22  1  8  0 29  1  0 14  0  8  0  0 11 16  1] -> size -> 39 
adversary victory points: -1
player victory points: -1 

Reward from previous game state: 
[-5  0 -1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -6 

action type: take_action - action -1.0
Learning step: -1.1949033737182617
desired expected reward: 26.645137786865234



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [16. 29.  8.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29.  8.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 29.  8.  8.  0.] 
cards in discard: [16.  1. 10. 10. 11.  6.  0.  0.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8
 22  1  8  0 29  1  0 14  0  8  0  0 11 16  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 25. 30.  8.  1.  6.  0.  1.  9.  9.  6. 10.  5.  9. 10.] 
adversary cards in hand: [1. 0. 6. 6. 0.] 
adversary cards in discard: [14.  3.  0.  3.  0.  3.  0.  0.  0. 11. 11. 16.  0.  1.  8.  0.  6.  3.
  3. 16.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6  3] -> size -> 43 
adversary victory points: -1
player victory points: -1 


action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 0.] 
cards in discard: [16.  1. 10. 10. 11.  6.  0.  0.  0. 16.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [10  1 14 10  3  0  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8
 22  1  8  0 29  1  0 14  0  8  0  0 11 16  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [12. 21. 30. 25. 30.  8.  1.  6.  0.  1.  9.  9.  6. 10.  5.  9. 10.] 
adversary cards in hand: [1. 0. 6. 6. 0.] 
adversary cards in discard: [14.  3.  0.  3.  0.  3.  0.  0.  0. 11. 11. 16.  0.  1.  8.  0.  6.  3.
  3. 16.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6  3] -> size -> 43 
adversary victory points: -1
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [16.  1. 10. 10. 11.  6.  0.  0.  0. 16.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [10  1 14 10  3  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8 22
  1  8  0 29  1  0 14  0  8  0  0 11 16  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 21. 30. 25. 30.  8.  1.  6.  0.  1.  9.  9.  6. 10.  5.  9. 10.] 
adversary cards in hand: [1. 0. 6. 6. 0.] 
adversary cards in discard: [14.  3.  0.  3.  0.  3.  0.  0.  0. 11. 11. 16.  0.  1.  8.  0.  6.  3.
  3. 16.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6  3] -> size -> 43 
adversary victory points: -1
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [16.  1. 10. 10. 11.  6.  0.  0.  0. 16.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [10  1 14 10  3  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8 22
  1  8  0 29  1  0 14  0  8  0  0 11 16  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 21. 30. 25. 30.  8.  1.  6.  0.  1.  9.  9.  6. 10.  5.  9. 10.] 
adversary cards in hand: [1. 0. 6. 6. 0.] 
adversary cards in discard: [14.  3.  0.  3.  0.  3.  0.  0.  0. 11. 11. 16.  0.  1.  8.  0.  6.  3.
  3. 16.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6  3] -> size -> 43 
adversary victory points: -1
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [16.  1. 10. 10. 11.  6.  0.  0.  0. 16.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [10  1 14 10  3  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8 22
  1  8  0 29  1  0 14  0  8  0  0 11 16  1  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 24. 30.  8.  1.  6.  0.  1.  9.  9.  6. 10.  5.  9. 10.] 
adversary cards in hand: [1. 0. 6. 6. 0.] 
adversary cards in discard: [14.  3.  0.  3.  0.  3.  0.  0.  0. 11. 11. 16.  0.  1.  8.  0.  6.  3.
  3. 16.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6  3] -> size -> 43 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [1. 0. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[58.88629]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 6. 6. 0.] 
cards in discard: [14.  3.  0.  3.  0.  3.  0.  0.  0. 11. 11. 16.  0.  1.  8.  0.  6.  3.
  3. 16.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 24. 30.  8.  1.  6.  0.  1.  9.  9.  6. 10.  5.  9. 10.] 
adversary cards in hand: [14. 14.  1.  8.  0.] 
adversary cards in discard: [16.  1. 10. 10. 11.  6.  0.  0.  0. 16.  3. 29.  8.  8.  0.] 
adversary owned cards: [10  1 14 10  3  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8 22
  1  8  0 29  1  0 14  0  8  0  0 11 16  1  3] -> size -> 39 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1.0
Learning step: -0.8688503503799438
desired expected reward: 27.006986618041992





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[35.518703]
 [43.151646]
 [40.01237 ]
 [22.600323]
 [38.366776]
 [40.945835]
 [39.90121 ]
 [28.306648]
 [38.64986 ]
 [34.754784]
 [47.94958 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6. 6. 0.] 
cards in discard: [14.  3.  0.  3.  0.  3.  0.  0.  0. 11. 11. 16.  0.  1.  8.  0.  6.  3.
  3. 16.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6  3] -> size -> 43 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 21. 30. 24. 30.  8.  1.  6.  0.  1.  9.  9.  6. 10.  5.  9. 10.] 
adversary cards in hand: [14. 14.  1.  8.  0.] 
adversary cards in discard: [16.  1. 10. 10. 11.  6.  0.  0.  0. 16.  3. 29.  8.  8.  0.] 
adversary owned cards: [10  1 14 10  3  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8 22
  1  8  0 29  1  0 14  0  8  0  0 11 16  1  3] -> size -> 39 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -2.824139356613159
desired expected reward: 54.613040924072266



buy possibilites: [-1] 
expected returns: [[32.58597]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6. 6. 0.] 
cards in discard: [14.  3.  0.  3.  0.  3.  0.  0.  0. 11. 11. 16.  0.  1.  8.  0.  6.  3.
  3. 16.  6. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6  3 15] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 24. 30.  8.  1.  6.  0.  1.  9.  9.  6. 10.  5.  9.  9.] 
adversary cards in hand: [14. 14.  1.  8.  0.] 
adversary cards in discard: [16.  1. 10. 10. 11.  6.  0.  0.  0. 16.  3. 29.  8.  8.  0.] 
adversary owned cards: [10  1 14 10  3  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8 22
  1  8  0 29  1  0 14  0  8  0  0 11 16  1  3] -> size -> 39 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0  -9   0   0  32   0] 
sum of rewards: 7 

action type: buy - action 15.0
Learning step: -0.6545552611351013
desired expected reward: 34.10023498535156






Player: 1 
cards in hand: [14. 14.  1.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 14.  1.  8.  0.] 
cards in discard: [16.  1. 10. 10. 11.  6.  0.  0.  0. 16.  3. 29.  8.  8.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [10  1 14 10  3  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8 22
  1  8  0 29  1  0 14  0  8  0  0 11 16  1  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 24. 30.  8.  1.  6.  0.  1.  9.  9.  6. 10.  5.  9.  9.] 
adversary cards in hand: [ 0.  0. 14.  0.  6.] 
adversary cards in discard: [14.  3.  0.  3.  0.  3.  0.  0.  0. 11. 11. 16.  0.  1.  8.  0.  6.  3.
  3. 16.  6. 15.  1.  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6  3 15] -> size -> 44 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 14.  1.  8.  0.] 
cards in discard: [16.  1. 10. 10. 11.  6.  0.  0.  0. 16.  3. 29.  8.  8.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [10  1 14 10  3  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8 22
  1  8  0 29  1  0 14  0  8  0  0 11 16  1  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 21. 30. 24. 30.  8.  1.  6.  0.  1.  9.  9.  6. 10.  5.  9.  9.] 
adversary cards in hand: [ 0.  0. 14.  0.  6.] 
adversary cards in discard: [14.  3.  0.  3.  0.  3.  0.  0.  0. 11. 11. 16.  0.  1.  8.  0.  6.  3.
  3. 16.  6. 15.  1.  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6  3 15] -> size -> 44 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 14.  1.  8.  0.] 
cards in discard: [16.  1. 10. 10. 11.  6.  0.  0.  0. 16.  3. 29.  8.  8.  0. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [10  1 14 10  3  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8 22
  1  8  0 29  1  0 14  0  8  0  0 11 16  1  3 10] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 24. 30.  8.  1.  6.  0.  1.  9.  9.  6. 10.  4.  9.  9.] 
adversary cards in hand: [ 0.  0. 14.  0.  6.] 
adversary cards in discard: [14.  3.  0.  3.  0.  3.  0.  0.  0. 11. 11. 16.  0.  1.  8.  0.  6.  3.
  3. 16.  6. 15.  1.  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6  3 15] -> size -> 44 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 14.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[ 6.934669]
 [-9.546759]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  0.  6.] 
cards in discard: [14.  3.  0.  3.  0.  3.  0.  0.  0. 11. 11. 16.  0.  1.  8.  0.  6.  3.
  3. 16.  6. 15.  1.  0.  6.  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6  3 15] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 24. 30.  8.  1.  6.  0.  1.  9.  9.  6. 10.  4.  9.  9.] 
adversary cards in hand: [ 6.  1.  0. 11. 11.] 
adversary cards in discard: [16.  1. 10. 10. 11.  6.  0.  0.  0. 16.  3. 29.  8.  8.  0. 10. 14. 14.
  1.  8.  0.] 
adversary owned cards: [10  1 14 10  3  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8 22
  1  8  0 29  1  0 14  0  8  0  0 11 16  1  3 10] -> size -> 40 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1
Learning step: -2.451913833618164
desired expected reward: 30.134057998657227





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[ -6.392272 ]
 [ -0.765733 ]
 [ -0.5097592]
 [-10.704528 ]
 [ -4.1181808]
 [ -2.8854482]
 [  6.93467  ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  0.  6.] 
cards in discard: [14.  3.  0.  3.  0.  3.  0.  0.  0. 11. 11. 16.  0.  1.  8.  0.  6.  3.
  3. 16.  6. 15.  1.  0.  6.  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6  3 15] -> size -> 44 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 21. 30. 24. 30.  8.  1.  6.  0.  1.  9.  9.  6. 10.  4.  9.  9.] 
adversary cards in hand: [ 6.  1.  0. 11. 11.] 
adversary cards in discard: [16.  1. 10. 10. 11.  6.  0.  0.  0. 16.  3. 29.  8.  8.  0. 10. 14. 14.
  1.  8.  0.] 
adversary owned cards: [10  1 14 10  3  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8 22
  1  8  0 29  1  0 14  0  8  0  0 11 16  1  3 10] -> size -> 40 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -1.1981481313705444
desired expected reward: 5.736547470092773



buy possibilites: [-1] 
expected returns: [[15.428728]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  0.  6.] 
cards in discard: [14.  3.  0.  3.  0.  3.  0.  0.  0. 11. 11. 16.  0.  1.  8.  0.  6.  3.
  3. 16.  6. 15.  1.  0.  6.  6.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6  3 15  3] -> size -> 45 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 21. 30. 23. 30.  8.  1.  6.  0.  1.  9.  9.  6. 10.  4.  9.  9.] 
adversary cards in hand: [ 6.  1.  0. 11. 11.] 
adversary cards in discard: [16.  1. 10. 10. 11.  6.  0.  0.  0. 16.  3. 29.  8.  8.  0. 10. 14. 14.
  1.  8.  0.] 
adversary owned cards: [10  1 14 10  3  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8 22
  1  8  0 29  1  0 14  0  8  0  0 11 16  1  3 10] -> size -> 40 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. -10.   0.   0.
   2.   0.] 
sum of rewards: -13.0 

action type: buy - action 3.0
Learning step: -0.27736636996269226
desired expected reward: -0.7871122360229492






Player: 1 
cards in hand: [ 6.  1.  0. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  1.  0. 11. 11.] 
cards in discard: [16.  1. 10. 10. 11.  6.  0.  0.  0. 16.  3. 29.  8.  8.  0. 10. 14. 14.
  1.  8.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [10  1 14 10  3  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8 22
  1  8  0 29  1  0 14  0  8  0  0 11 16  1  3 10] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 23. 30.  8.  1.  6.  0.  1.  9.  9.  6. 10.  4.  9.  9.] 
adversary cards in hand: [ 1.  0. 11. 25. 11.] 
adversary cards in discard: [14.  3.  0.  3.  0.  3.  0.  0.  0. 11. 11. 16.  0.  1.  8.  0.  6.  3.
  3. 16.  6. 15.  1.  0.  6.  6.  0.  3.  0.  0. 14.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6  3 15  3] -> size -> 45 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  1.  0. 11.] 
cards in discard: [16.  1. 10. 10. 11.  6.  0.  0.  0. 16.  3. 29.  8.  8.  0. 10. 14. 14.
  1.  8.  0.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  1 14 10  3  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8 22
  1  8  0 29  1  0 14  0  8  0  0 11 16  1  3 10  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 23. 30.  8.  1.  6.  0.  0.  9.  9.  6. 10.  4.  9.  9.] 
adversary cards in hand: [ 1.  0. 11. 25. 11.] 
adversary cards in discard: [14.  3.  0.  3.  0.  3.  0.  0.  0. 11. 11. 16.  0.  1.  8.  0.  6.  3.
  3. 16.  6. 15.  1.  0.  6.  6.  0.  3.  0.  0. 14.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6  3 15  3] -> size -> 45 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1.  0. 11.] 
cards in discard: [16.  1. 10. 10. 11.  6.  0.  0.  0. 16.  3. 29.  8.  8.  0. 10. 14. 14.
  1.  8.  0.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  1 14 10  3  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8 22
  1  8  0 29  1  0 14  0  8  0  0 11 16  1  3 10  8] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 21. 30. 23. 30.  8.  1.  6.  0.  0.  9.  9.  6. 10.  4.  9.  9.] 
adversary cards in hand: [ 1.  0. 11. 25. 11.] 
adversary cards in discard: [14.  3.  0.  3.  0.  3.  0.  0.  0. 11. 11. 16.  0.  1.  8.  0.  6.  3.
  3. 16.  6. 15.  1.  0.  6.  6.  0.  3.  0.  0. 14.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6  3 15  3] -> size -> 45 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1.  0. 11.] 
cards in discard: [16.  1. 10. 10. 11.  6.  0.  0.  0. 16.  3. 29.  8.  8.  0. 10. 14. 14.
  1.  8.  0.  8. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  1 14 10  3  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8 22
  1  8  0 29  1  0 14  0  8  0  0 11 16  1  3 10  8 10] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 23. 30.  8.  1.  6.  0.  0.  9.  9.  6. 10.  3.  9.  9.] 
adversary cards in hand: [ 1.  0. 11. 25. 11.] 
adversary cards in discard: [14.  3.  0.  3.  0.  3.  0.  0.  0. 11. 11. 16.  0.  1.  8.  0.  6.  3.
  3. 16.  6. 15.  1.  0.  6.  6.  0.  3.  0.  0. 14.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6  3 15  3] -> size -> 45 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [ 1.  0. 11. 25. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 11.] 
expected returns: [[-12.307676]
 [-13.411732]
 [-15.393862]
 [-13.411732]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 11. 25. 11.] 
cards in discard: [14.  3.  0.  3.  0.  3.  0.  0.  0. 11. 11. 16.  0.  1.  8.  0.  6.  3.
  3. 16.  6. 15.  1.  0.  6.  6.  0.  3.  0.  0. 14.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6  3 15  3] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 23. 30.  8.  1.  6.  0.  0.  9.  9.  6. 10.  3.  9.  9.] 
adversary cards in hand: [10. 11.  8.  0. 22.] 
adversary cards in discard: [16.  1. 10. 10. 11.  6.  0.  0.  0. 16.  3. 29.  8.  8.  0. 10. 14. 14.
  1.  8.  0.  8. 10. 11.  6.  1.  0. 11.] 
adversary owned cards: [10  1 14 10  3  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8 22
  1  8  0 29  1  0 14  0  8  0  0 11 16  1  3 10  8 10] -> size -> 42 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -1.3270519971847534
desired expected reward: 14.101675987243652



Player 0 won the game! 



Player 0 bought cards:
Copper: 6 
Silver: 2 
Gold: 0 
Estate: 5 
Duchy: 0 
Province: 0 
Curse: 6 

Remodel: 1 
Workshop: 5 
Chapel: 3 
Witch: 1 
Poacher: 0 
Militia: 1 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 1 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 1.  0. 11. 11.  3.  6.] 
cards in discard: [14.  3.  0.  3.  0.  3.  0.  0.  0. 11. 11. 16.  0.  1.  8.  0.  6.  3.
  3. 16.  6. 15.  1.  0.  6.  6.  0.  3.  0.  0. 14.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  8  6  1  6 11  3 11 14  0  1  0  3  6 16  3  6
 25  1  0 14  8  8  0 11  0 11 16  1  6 11  0  6  0  6  3 15  3] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 21. 30. 23. 30.  8.  0.  6.  0.  0.  9.  9.  6. 10.  3.  9.  9.] 
adversary cards in hand: [10. 11.  8.  0. 22.] 
adversary cards in discard: [16.  1. 10. 10. 11.  6.  0.  0.  0. 16.  3. 29.  8.  8.  0. 10. 14. 14.
  1.  8.  0.  8. 10. 11.  6.  1.  0. 11.  6.] 
adversary owned cards: [10  1 14 10  3  8 10 16  0  0 10 11  1  8  0  0 11  6 11 10  0  6  8 22
  1  8  0 29  1  0 14  0  8  0  0 11 16  1  3 10  8 10  6] -> size -> 43 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[ -5 500   0   0   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 515 

action type: take_action - action 25.0
Learning step: 26.51969337463379
desired expected reward: 11.125833511352539



